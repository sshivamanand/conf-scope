filename,title,introduction,references,folder_label,folder_label_binary
104.pdf.json,,,"Efficient string matching: an aid to bibliographic search | An efficient digital search algorithm by using a double-array structure | Efficient string matching: an a d to bibliogr phic search | An efficient digit l search algorithm by using a double-array structure | Joint representation learning of text and knowledge for knowledg graph completion | Efficie t string matching: an aid to bibliographic search | An efficie t digital search algorithm by using a doubl -array structure | Joint representation learning of text and knowledg for knowledge graph completion | Efficie t string matching: a aid to bibliographic search | An efficient digital search algorit m by usi g doub e-array structure | Joint representation l arning of text and knowledge for knowledge graph completion | Effi cie t string match ng: an id to bibliog phic earch | An efficient digital search algorit by usi g doub e-array structure | J int representation learning of text and knowledge for knowledge g aph completion | Efficient string matching: an aid to bibliogr phic search | An efficient digita search algorithm by using a double-array structure | Joint representation learni g of text d knowledge for knowledge graph completion | Confid tia Review Copy. DO NOT DISTRIBUTE. predict the context words by maximizing the following objective functi | 2016) designs a list of features | Graph ranking for collective named entity disambiguation | Learning relatedness measures for entity linking | A unified model for word sense representation and disambiguation | Large-scale named entity disambiguation based on wikipedia data | Joint representation learning of text and knowledge for knowledge graph completion | Robust disambiguation of named entities in text | Improving word representations via global context and multiple word prototypes | Leveraging deep neural networks and knowledge graphs for entity disambiguation | Cumulated gain-based evaluation of ir techniques | Collective annotation of wikipedia entities in web text | Do multi-sense embeddings improve natural language understanding? In Proc | Embedding words and senses together via joint knowledgeenhanced training | Entity disambiguation based on a | Efficient estimation of word representations in vector space | Distributed representations of words and phrases and their compositionality | Efficient nonparametric estimation of multiple embeddings per word in vector space | Personalized page rank for named entity disambiguation | Multi-prototype vector-space models of word meaning | Introduction to information retrieval | Entity linking with a knowledge base: Issues, techniques, and solutions | A probabilistic model for learning multi-prototype word embeddings | Representing text for joint embedding of text and knowledge bases | Knowledge graph and text jointly embedding | Text-enhanced representation learning for knowledge graph | Connecting language and knowledge bases with embedding models for relation extraction | Knowledge representation via joint learning of sequential text and knowledge graphs | Confidential Review Copy",acl,100
105.pdf.json,Morphological Inflection Generation with Hard Monotonic Attention,"Morphological inflection generation involves generating a target word (e.g. “härtestem”, the German word for “hardest”), given a source word (e.g. “hart”, the German word for “hard”) and the morpho-syntactic attributes of the target (POS=adjective, gender=masculine, type=superlative, etc.). The task is important for many down-stream NLP tasks such as machine translation, especially for dealing with data sparsity in morphologically rich languages where a lemma can be inflected into many different word forms. Several studies have shown that translating into lemmas in the target language and then applying inflection generation as a post-processing step is beneficial for phrase-based machine translation (Minkov et al., 2007; Toutanova et al., 2008; Clifton and Sarkar, 2011; Fraser et al., 2012; Chahuneau et al., 2013) and more recently for neural machine translation (Garcı́a-Martı́nez et al., 2016). The task was traditionally tackled with hand engineered finite state transducers (FST) (Koskenniemi, 1983; Kaplan and Kay, 1994) which rely on expert knowledge, or using trainable weighted finite state transducers (Mohri et al., 1997; Eisner, 2002) which combine expert knowledge with datadriven parameter tuning. Many other machinelearning based methods (Yarowsky and Wicentowski, 2000; Dreyer and Eisner, 2011; Durrett and DeNero, 2013; Hulden et al., 2014; Ahlberg et al., 2015; Nicolai et al., 2015) were proposed for the task, although with specific assumptions about the set of possible processes that are needed to create the output sequence. More recently, the task was tackled using neural sequence to sequence learning over character sequences with impressive results (Faruqui et al., 2016). The vanilla encoder-decoder models as used by Faruqui et al. compress the input sequence to a single, fixed-sized continuous representation. Instead, soft-attention based sequence to sequence learning paradigm (Bahdanau et al., 2014) allows directly conditioning on the entire input seque",Paradigm classification in supervised learning of morphology | The {CELEX} lexical data base on {CDROM | Neural machine translation by jointly learning to align and translate | End-to-end attentionbased large vocabulary speech recognition | Translating into morphologically rich languages with synthetic phrases | Attention-based models for speech recognition | Combining morpheme-based machine translation with postprocessing morpheme prediction | The SIGMORPHON 2016 shared task— morphological reinflection | Discovering morphological paradigms from plain text using a dirichlet process mixture model | Latent-variable modeling of string transductions with finite-state methods | Supervised learning of complete morphological paradigms | Parameter estimation for probabilistic finite-state transducers | Morphological inflection generation using character sequence to sequence learning | Modeling inflection and wordformation in smt | Factored neural machine translation | Framewise phoneme classification with bidirectional LSTM and other neural network architectures | Sequence transduction with recurrent neural networks | Semi-supervised learning of morphological paradigms and lexicons | A neural transducer | Neural multi-source morphological reinflection | Med: The lmu system for the sigmorphon 2016 shared task on morphological reinflection | Singlemodel encoder-decoder with explicit morphological representation for reinflection | Regular models of phonological rule systems | Two-level morphology: A general computational model of word-form recognition and production | Segmental recurrent neural networks for end-to-end speech recognition | Effective approaches to attentionbased neural machine translation | Generating complex morphology for machine translation | A rational design for a weighted finite-state transducer library | Inflection generation as discriminative string transduction | Weighting finite-state transductions with neural context | Noise-aware character alignment for bootstrapping statistical machine transliteration from bilingual corpora | Applying morphology generation models to machine translation | Minimally supervised morphological analysis by multimodal alignment | Online segment to segment neural transduction | Adadelta: an adaptive learning rate method | 2016) which also performed a similar ensembling technique. For the character level alignment process we use the implementation provided by the organizers of the SIGMORPHON2016 shared task.5,acl,100
107.pdf.json,Weakly Supervised Cross-Lingual Named Entity Recognition via Effective Annotation and Representation Projection,"Named entity recognition (NER) is a fundamental information extraction task that automatically detects named entities in text and classifies them into pre-defined entity types such as PERSON, ORGANIZATION, GPE (GeoPolitical Entities), EVENT, LOCATION, DATE, etc. NER provides essential inputs for many information extraction applications, including relation extraction, entity linking, question answering and text mining. Building fast and accurate NER systems is a crucial step towards enabling large-scale automated information extraction and knowledge discovery on the huge volumes of electronic documents existing today. The state-of-the-art NER systems are statistical machine learning models including maximum entropy Markov models (MEMMs) (McCallum et al., 2000), conditional random fields (CRFs) (Lafferty et al., 2001) and neural networks (Collobert et al., 2011; Lample et al., 2016). To achieve high accuracy, an NER system needs to be trained with a large amount of human-annotated data, and is often supplied with language-specific resources (gazetteers, word clusters). Annotating NER data by human is rather expensive and time-consuming, and can be quite difficult for a new language. This places a big challenge in building NER systems of multiple languages for supporting multilingual information extraction applications. The difficulty of acquiring human-annotated multilingual NER data raises the following question: given a well-trained NER system in a source language (e.g., English), how can one go about extending it to a new language with decent performance and no human annotation in the target language? There are mainly two types of approaches for building weakly supervised cross-lingual NER systems. The first type of approaches are based on annotation projection, e.g., (Zitouni and Florian, 2008; Ehrmann et al., 2011). These approaches require parallel corpora between a source language (usually English) and a target language with alignment information. The source-la",,acl,100
108.pdf.json,A Multigraph-based Model for Overlapping Entity Recognition,"Named entity recognition (NER), or in general the task of recognizing entities in a text, has been a research topic for many years (McCallum and Li, 2003; Nadeau and Sekine, 2007; Ratinov and Roth, 2009). However, as previously noted by Finkel and Manning (2009), many previous works ignored overlapping entities, although they are quite common. For example, the location entity China appears within the organization entity Bank of China. In practice, overlapping entities have been found in many existing datasets, including ACE (Doddington et al., 2004), GENIA (Kim et al., 2003), and in a clinical text dataset (Suominen et al., 2013). Figure 1 illustrates some examples of overlapping entities adapted from existing datasets. Solving this task is non-trivial, as the typical way of modeling entity recognition as a sequence prediction problem (e.g., using linear-chain CRF which utilizes simple graphs) has difficulties handling overlapping entities (Alex et al., 2007). Finkel and Manning (2009) proposed to use a treebased constituency parsing model to handle nested entities with a time complexity that is cubic in n for its inference procedure with n being the number of words in the sentence. This complexity was later improved by Lu and Roth (2015) with a hypergraph-based model, which shows a time complexity that is linear in n. In this work, as opposed to using simple graphs or hypergraphs, we introduce a novel multigraphbased model to tackle the problem of overlapping entity extraction. We show it is possible to assign explicit semantics to different edges connecting the same pair of nodes when representing structures, leading to the novel multigraph representations that can be used to represent overlapping structures. We present the training and inference procedures over such a novel representation. To the best of our knowledge, this is the first structured prediction model utilizing multigraphs to predict overlapping structures. In this paper we make the following major c","Recognising Nested Named Entities in Biomedical Text | The Automatic Content Extraction (ACE) Program-Tasks, Data, and Evaluation | Nested Named Entity Recognition | GENIA corpus– a semantically annotated corpus for biotextmining | Introduction to the Bio-entity Recognition Task at JNLPBA | Chunking with Support Vector Machines | Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data | On the limited memory BFGS method for large scale optimization | Finding Good Sequential Model Structures using Output Transformations | Joint Mention Extraction and Classification with Mention Hypergraphs | Early results for named entity recognition with conditional random fields, feature induction and web-enhanced lexicons | Flexible text segmentation with structured multilabel classification | A survey of named entity recognition and classification | Design challenges and misconceptions in named entity recognition | Equation Parsing : Mapping Sentences to Grounded Equations | Representing Text Chunks | Voting Between Multiple Data Representations for Text Chunking | Recognizing and Encoding Disorder Concepts in Clinical Text using Machine Learning and Vector Space | Part-ofSpeech Annotation of Biology Research Abstracts | Large Margin Methods for Structured and Interdependent Output Variables | Preprocessing For GENIA, we used GENIAcorpus3.02p that comes with POS tags for each word (Tateisi and Tsujii, 2004)",acl,100
117.pdf.json,Improved Neural Relation Detection for Knowledge Base Question Answering,"Knowledge Base Question-Answering (KBQA) systems answer questions by obtaining information from KB tuples (Berant et al., 2013; Yao et al.,",Constraint-based question answering with knowledge graph | More accurate question answering on freebase | Semantic parsing on Freebase from question-answer pairs | Large-scale simple question answering with memory networks | Translating embeddings for modeling multirelational data | Cfo: Conditional focused neural question answering with largescale knowledge bases | Classifying relations by ranking with convolutional neural networks | Paraphrase-driven learning for open question answering | Character-level question answering with attention | Improved relation extraction with feature-rich compositional embedding models | Deep residual learning for image recognition | Neural symbolic machines: Learning semantic parsers on freebase with weak supervision | Distributed representations of words and phrases and their compositionality | Employing word representations and regularization for domain adaptation of relation extraction | A decomposable attention model for natural language inference | Utd: Classifying semantic relations by combining lexical and semantic resources | Semi-supervised relation extraction with large-scale word clustering | Combining recurrent and convolutional neural networks for relation classification | Relation classification via multi-level attention cnns | Question answering on freebase via relation extraction and textual evidence | S-mart: Novel tree-based structured learning algorithms applied to tweet entity linking | Freebase qa: Information extraction or semantic parsing | Information extraction over structured data: Question answering with freebase | Semantic parsing via staged query graph generation: Question answering with knowledge base | Semantic parsing for single-relation question answering | The value of semantic parse labeling for knowledge base question answering | Simple question answering by attentive convolutional neural network | Relation classification via convolutional deep neural network | Exploring various knowledge in relation extraction | Attentionbased bidirectional long short-term memory networks for relation classification,acl,100
12.pdf.json,Time Expression Analysis and Recognition Using Syntactic Types and Simple Heuristic Rules,"Time expression plays an important role in information retrieval and many applications in natural language processing (Alonso et al., 2011). Recognizing time expressions from free text has attracted considerable attention since last decade (Verhagen et al., 2007, 2010; UzZaman et al., 2013). Time expression recognition main involves two kinds of methods, rule-based method (Strotgen and Gertz, 2013; Strötgen and Gertz, 2010; Chang and Manning, 2012) and machine learning based method (Bethard, 2013; Lee et al., 2014). Rulebased time expression taggers could recognize most time expressions with carefully designed rules, while they could not recognize the time expressions that are not matched in any explicit rule. Machine learning based methods require training data for good performance, and may not recognize less frequent time expressions. In our study, we analyze the time expressions in four datasets: TimeBank (Pustejovsky et al., 2003b), Gigaword (Parker et al., 2011), WikiWars (Mazur and Dale, 2010), and Tweets. From the analysis, we make four observations. First, most time expressions are very short, with 80% of time expressions containing no more than three tokens. Second, the vocabulary used to express time information is very small, with a small group of keywords. Third, at least 93% of time expressions contain at least one time token. The last observation is that words in time expressions demonstrate similar syntactic behaviors. All the observations relate to the principle of least effort (Zipf, 1949). That is, people will act under the least effort in order to minimize the cost of energy at both individual level and collective level to language usage (Zipf, 1949). Time expression is part of language and acts as an interface of communication. Short expressions, small vocabulary, occurrence, and similar syntactic behaviors all reduce the cost of energy required to communicate. Based on the observations, we propose a typebased approach, named SynTime (‘Syn’ is f","Temporal information retrieval: Challenges and opportunities | Parsing time: Learning to interpret time expressions | Cleartk-timeml: A minimalist approach to tempeval 2013 | Sutime: A library for recognizing and normalizing time expressions | Sutime: Evaluation in tempeval-3 | Tokensregex: Defining cascaded regular expressions over tokens | Knowledge of Language: Its Nature, Origin, and Use | Adaptive subgradient methods for online learning and stochastic optimization | Mantime: Temporal expression identification and normalization in the tempeval-3 challenge | Fastus: A cascaded finite-state transducer for extracting information from natruallanguage text | Context-dependent semantic parsing for time expressions | Timen: An open temporal expression normalisation resource | Tipsem (english and spanish): Evaluating crfs and semantic roles in tempeval-2 | Foundations of Statistical Natural Language Processing | Wikiwars: A new corpus for research on temporal expressions | Engilish gigaword fifth edition | The language instinct: The new science of language and mind, volume 7529 | Timeml: Robust specification of event and temporal expressions in text | The timebank corpus | Surface Structure and Interpretation | Heideltime: High quality rule-based extraction and normalization of temporal expressions | Multilingual and cross-domain temporal tagging | Heideltime: Tuning english and developing spanish resources | A minimally supervised method for recognizing and normalizing time expressions in twitter | Trips and trios system for tempeval-2: Extracting temporal information from text | Semeval-2013 task 1: Tempeval-3: Evaluating time expressions, events, and temporal relations | Semeval-2007 task 15: Tempeval temporal relation identification | Automating temporal annotation with tarqi | Semeval-2010 task 13: Tempeval-2 | Human Behavior and the Principle of Least Effort: An Introduction to Human Ecology",acl,100
122.pdf.json,Neural Belief Tracker: Data-Driven Dialogue State Tracking,"Spoken dialogue systems (SDS) allow users to interact with computer applications through conversation. Task-based dialogue systems help users achieve goals such as finding restaurants or booking flights. The dialogue state tracking (DST) component of an SDS serves to interpret user input and update the belief state, which is the system’s internal representation of the state of the conversation (Young et al., 2010). This is a probability distribution over dialogue states used by the downstream dialogue manager component to decide which action the system should perform next. The Dialogue State Tracking Challenge (DSTC) series of shared tasks has provided a common evaluation framework accompanied by labelled datasets (Williams et al., 2016). In this framework, the dialogue system is supported by a domain ontology which describes the range of user intents the system can process. The ontology defines a collection of slots and the values each slot can take. The system must track the search constraints expressed by users (goals or informable slots) and questions the users ask about search results (requests), taking into account each user utterance (input via a speech recogniser) and the dialogue context (e.g., what the system just said). The following example shows the true state after each user utterance in a three-turn conversation: User: I’m looking for a cheaper restaurant inform(price=cheap) System: How about Thai food? User: Yes please inform(price=cheap, food=Thai) System: The House serves cheap Thai food User: Where is it? inform(price=cheap, food=Thai); request(address) System: The House is at 106 Regent Street DST models depend on identifying mentions of ontology items in user utterances, which becomes a non-trivial task when confronted with lexical variation, the dynamics of context and noisy speech recognition. Some approaches assume that a separate Spoken Language Understanding (SLU) module will solve this problem for them. However, such models require vast am","A “k hypotheses + other” belief updating model | Convolutional Neural Network Based Semantic Tagging with Entity Embeddings | Natural language processing (almost) from scratch | Robust dialog state tracking for large ontologies | PPDB: The Paraphrase Database | Understanding the difficulty of training deep feedforward neural networks | Discriminative Spoken Language Understanding Using Word Confusion Networks | The Second Dialog State Tracking Challenge | The Third Dialog State Tracking Challenge | Robust Dialog State Tracking using Delexicalised Recurrent Neural Networks and Unsupervised Adaptation | Word-Based Dialog State Tracking with Recurrent Neural Networks | Neural dialog state tracker for large ontologies by attention mechanism | A Convolutional Neural Network for Modelling Sentences | Convolutional Neural Networks for Sentence Classification | Adam: A Method for Stochastic Optimization | Dialog History Construction with Long-Short Term Memory for Robust Generative Dialog State Tracking | Attention-Based Recurrent Neural Network Models for Joint Intent Detection and Slot Filling | Joint Online Spoken Language Understanding and Language Modeling with Recurrent Neural Networks | Gated End-to-End Memory Networks | Spoken Language Understanding from Unaligned Data using Discriminative Classification Models | Using recurrent neural networks for slot filling in spoken language understanding | Counter-fitting Word Vectors to Linguistic Constraints | Multidomain Dialog State Tracking using Recurrent Neural Networks | Rectified linear units improve restricted Boltzmann machines | Recurrent Neural Networks with External Memory for Language Understanding | Glove: Global Vectors for Word Representation | Spectral decomposition method of dialog state tracking via collective matrix factorization | Dialog state tracking, a machine reading approach using Memory Network | Generative and discriminative algorithms for spoken language understanding | Reasoning about entailment with neural attention | A study of using syntactic and semantic structures for concept segmentation and labeling | Convolutional Neural Networks for Multi-topic Dialog State Tracking | The SJTU System for Dialog State Tracking Challenge | Recurrent Polynomial Network for Dialogue State Tracking | Bayesian update of dialogue state: A POMDP framework for spoken dialogue systems | Semantic Parsing Using Word Confusion Networks With Conditional Random Fields | A new corpus and imitation learning framework for contextdependent semantic parsing | Hybrid Dialog State Tracker with ASR Features | Bi-directional recurrent neural network with ranking loss for spoken language understanding | Extracting Information From Spontaneous Speech | A Simple and Generic Belief Tracking Mechanism for the Dialog State Tracking Challenge: On the believability of observed information | A networkbased end-to-end trainable task-oriented dialogue system | From paraphrase database to compositional paraphrase model and back | Web-style ranking and SLU combination for dialog state tracking | The Dialog State Tracking Challenge series: A review | The Dialogue State Tracking Challenge | Partially observable markov decision processes for spoken dialog systems | Spoken language understanding using long short-term memory neural networks | The hidden information state model: A practical framework for POMDP-based spoken dialogue management | A Joint Model of Intent Determination and Slot Filling for Spoken Language Understanding | Incremental LSTM-based dialog state tracker",acl,100
128.pdf.json,Knowledge as a Teacher: Knowledge-Guided Structural Attention Networks,"In the past decade, goal-oriented spoken dialogue systems (SDS), such as the virtual personal assistants Microsoft’s Cortana and Apple’s Siri, are being incorporated in various devices and allow users to speak to systems freely in order to finish tasks more efficiently. A key component of these conversational systems is the natural language understanding (NLU) module-it refers to the targeted understanding of human speech directed at machines (Tur and De Mori, 2011). The goal of such “targeted” understanding is to convert the recognized user speech into a task-specific semantic representation of the user’s intention, at each turn, that aligns with the back-end knowledge and action sources for task completion. The dialogue manager then interprets the semantics of the user’s request and associated back-end results, and decides the most appropriate system action, by exploiting semantic context and user specific meta-information, such as geo-location and personal preferences (McTear, 2004; Rudnicky and Xu, 1999). A typical pipeline of NLU includes: domain classification, intent determination, and slot filling (Tur and De Mori, 2011). NLU first decides the domain of user’s request given the input utterance, and based on the domain, predicts the intent and fills associated slots corresponding to a domain-specific semantic template. For example, Figure 1 shows a user utterance, “show me the flights from seattle to san francisco” and its semantic frame, find flight(origin=“seattle”, dest=“san francisco”). It is easy to see the relationship between the origin city and the destination city in this example, although these do not appear next to each other. Traditionally, domain detection and intent prediction are framed as utterance classification problems, where several classifiers such as support vector machines and maximum entropy have been employed (Haffner et al., 2003; Chelba et al., 2003; Chen et al., 2014). Then slot filling is framed as a word sequence tagging task, wh","Abstract meaning representation for sembanking | Convolutional neural network based semantic tagging with entity embeddings | Speech utterance classification | A fast and accurate dependency parser using neural networks | Deriving local relational surface forms from dependency-based entity embeddings for unsupervised spoken language understanding | Matrix factorization with knowledge graph propagation for unsupervised spoken language understanding | On the properties of neural machine translation: Encoder-decoder approaches | Empirical evaluation of gated recurrent neural networks on sequence modeling | The logical form of action sentences | Deep belief network based semantic taggers for spoken language understanding | Finding structure in time | Speech recognition with deep recurrent neural networks | Optimizing svms for complex call classification | Leveraging knowledge graphs for web-scale unsupervised semantic parsing | Long short-term memory | Learning deep structured semantic models for web search using clickthrough data | An empirical exploration of recurrent network architectures | Convolutional neural networks for sentence classification | Adam: A method for stochastic optimization | Distributed representations of sentences and documents | Finding function in form: Compositional character models for open vocabulary word representation | Toward abstractive summarization using semantic representations | Query understanding enhanced by hierarchical parsing structures | Dependency-based convolutional neural networks for sentence embedding | Knowledge graph inference for spoken dialog systems | Spoken dialogue technology: toward the conversational user interface | Using recurrent neural networks for slot filling in spoken language understanding | Distributed representations of words and phrases and their compositionality | Events in the semantics of english: A study in subatomic semantics | A speech understanding system based on statistical representation of semantics | Recurrent neural network and lstm models for lexical utterance classification | Neural semantic role labeling with dependency path embeddings | An agendabased dialog management architecture for spoken language systems | Application of deep belief networks for natural language understanding | Deep belief nets for natural language call-routing | Grounded compositional semantics for finding and describing images with sentences | End-to-end memory networks | Sequence to sequence learning with neural networks | Improved semantic representations from tree-structured long short-term memory networks | Spoken language understanding: Systems for extracting semantic information from speech | Towards deeper understanding: Deep convex networks for semantic utterance classification | What is left to be understood in atis? In Spoken Language Technology Workshop (SLT), 2010 IEEE | Spoken language understanding | Memory networks | Dynamic memory networks for visual and textual question answering | Convolutional neural network based triangular CRF for joint intent detection and slot filling | Embedding entities and relations for learning and inference in knowledge bases | Spoken language understanding using long short-term memory neural networks | Recurrent neural networks for language understanding",acl,100
130.pdf.json,Enriching Complex Networks with Word Embeddings for Detecting Mild Cognitive Impairment from Speech Transcripts,"Mild Cognitive Impairment (MCI) can affect one or multiple cognitive domains (e.g. memory, language, visuospatial skills and the executive function), and may represent a pre-clinical stage of Alzheimer’s disease (AD). The impairment that affects memory, referred to as amnestic MCI, is the most frequent, with the highest conversion rate for AD, at 15% a year versus 1 to 2% for the general population. Since dementias are chronic and progressive diseases, their early diagnosis ensures a greater chance of success to engage patients in non-pharmacological treatment strategies such as cognitive training, physical activity and socialization (Teixeira et al., 2012). Language is one of the most efficient information sources for assessing cognitive functions. Changes in language usage are frequent in patients with dementia and are normally first recognized by the patients themselves or their family members. Therefore, the automatic analysis of discourse production is promising for diagnosing MCI at early stages, which may address potentially reversible factors (Muangpaisan et al., 2012). Proposals to detect language-related impairment in dementias include machine learning (Jarrold et al., 2010; Roark et al., 2011; Fraser et al., 2014, 2015), magnetic resonance imaging (Dyrba et al., 2015), and data screening tests added to demographic information (Weakley et al., 2015). The discourse production (mainly narratives) is attractive because it allows for the analysis of linguistic microstructures, including phonetic-phonological, morphosyntactic and semantic-lexical components, as well as semanticpragmatic macrostructures. Automated discourse analysis based on Natural Language Processing (NLP) resources and tools to diagnose dementias via machine learning meth- 2 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 1","Evaluating progression of alzheimer’s disease by regression and classification methods in a narrative language test in portuguese | Authorship recognition via fluctuation analysis of network topology and word intermittency | A complex network approach to stylometry | Probing the topological properties of complex networks modeling short written texts | Probing the statistical properties of unknown texts: Application to the voynich manuscript | Extractive summarization using complex networks and syntactic dependency | Unveiling the relationship between complex networks metrics and word senses | Identification of literary movements using complex networks to represent texts | A complex network approach to text summarization | ABCD: Arizona Battery for Communication Disorders of Dementia | The natural history of alzheimer’s disease | A neural probabilistic language model | Enriching word vectors with subword information | Non-verbal semantic impairment in semantic dementia | The anatomy of a large-scale hypertextual web search engine | Natural language processing (almost) from scratch | Approaching human language with complex networks | Automatic proposition extraction from dependency trees: Helping early prediction of alzheimer’s disease from narratives | Towards automatic detection of abnormal cognitive decline and dementia through linguistic analysis | Using complex networks for text classification: Discriminating informative and imaginative documents | Support vector machines for spam categorization | Predicting prodromal alzheimer’s disease in subjects with mild cognitive impairment | Automated classification of primary progressive aphasia subtypes from narrative speech transcripts | Linguistic features identify alzheimer’s disease in narrative speech | Machine learning approaches to diagnosis and laterality effects in semantic dementia discourse | The Assessment of Aphasia and Related Disorders | Coh-metrix: Analysis of text on cohesion and language | Patterns in syntactic dependency networks | The small world of human language | Aided diagnosis of dementia type through computer-based analysis of spontaneous speech | Language analytics for assessing brain health: Cognitive impairment, depression and presymptomatic alzheimer’s disease | Text categorization with support vector machines: Learning with many relevant features | Boston naming test | A design framework for hierarchical ensemble of multiple feature extractors and multiple classifiers | Fully automated neuropsychological assessment for detecting mild cognitive impairment | Authorship attribution based on life-like network automata | The CHILDES Project: Tools for analyzing talk | Graphbased natural language processing and information retrieval | Exploiting similarities among languages for machine translation | Distributed representations of words and phrases and their compositionality | On exploration of classifier ensemble synergism in pedestrian detection | Learning predictive linguistic features for alzheimer’s disease and related dementias using verbal utterances | Inducing language networks from continuous space word representations | Mild cognitive impairment as a diagnostic entity | Alignment of spoken narratives for automated neuropsychological assessment | Spoken language derived measures for detecting mild cognitive impairment | Prose and poetry classification and boundary detection using word adjacency network analysis | The quantitative analysis of agrammatic production: Procedure and data | Automatic text processing: The transformation, analysis, and retrieval of | Word sense disambiguation via high order of learning in complex networks | Non-pharmacological interventions on cognitive functions in older people with mild cognitive impairment (mci) | Automatic detection of mild cognitive impairment from spontaneous speech using asr | Sentence segmentation in narrative transcripts from neuropsycological tests using recurrent convolutional neural networks | Detecting mild cognitive impairment by exploiting linguistic information from transcripts | Neuropsychological test selection for cognitive impairment classification: A machine learning approach | Wechsler memory scale (WMS-III) | Ensemble of feature sets and classification algorithms for sentiment classification | Ensemble methods: foundations and algorithms",acl,100
134.pdf.json,Neural End-to-End Learning for Computational Argumentation Mining,"Computational argumentation mining (AM) deals with finding argumentation structures in text. This involves several subtasks, such as: (a) separating argumentative units from non-argumentative units, also called ‘component segmentation’; (b) classifying argument components into classes such as “Premise” or “Claim”; (c) finding relations between argument components; (d) classifying relations into classes such as “Support” or “Attack” (Persing and Ng, 2016; Stab and Gurevych, 2016). Thus, AM would have to detect claims and premises (reasons) in texts such as the following, where premise P supports claim C: Since it killed many marine livesP , ::::::: tourism ::: has :::::::::: threatened :::::: natureC . Argument structures in real texts are typically much more complex, cf. Figure 1. While different research has addressed different subsets of the AM problem (see below), the ultimate goal is to solve all of them, starting from unannotated plain text. Two recent approaches to this end-to-end learning scenario are Persing and Ng (2016) and Stab and Gurevych (2016). Both solve the end-to-end task by first training independent models for each subtask and then defining an integer linear programming (ILP) model that encodes global constraints such as that each premise has a parent, etc. Besides their pipeline architecture the approaches also have in common that they heavily rely on hand-crafted features. Hand-crafted features pose a problem because AM is to some degree an “arbitrary” problem in that the notion of “argument” critically relies on the underlying argumentation theory (Reed et al., 2008; Biran and Rambow, 2011; Habernal and Gurevych, 2015; Stab and Gurevych, 2016). Accordingly, datasets typically differ with respect to their annotation of (often rather complex) argument structure. Thus, feature sets would have to be manually adapted to and designed for each new sample of data, a challenging task. The same critique applies to the designing of ILP constraints. Moreo","Neural machine translation by jointly learning to align and translate | Scheduled sampling for sequence prediction with recurrent neural networks | Identifying justifications in written dialogs | A transitionbased system for joint part-of-speech tagging and labeled non-projective dependency parsing | A fast and accurate dependency parser using neural networks | A unified architecture for natural language processing: Deep neural networks with multitask learning | Transitionbased dependency parsing with stack long shortterm memory | Argument extraction for supporting public policy formulation | Exploiting debate portals for semi-supervised argumentation mining in user-generated web discourse | Argumentation Mining in User-Generated Web Discourse | When is multitask learning effective? semantic sequence prediction under varying data conditions | Long short-term memory | Bidirectional LSTM-CRF models for sequence tagging | Simple and accurate dependency parsing using bidirectional lstm feature representations | Linking the thoughts: Analysis of argumentation structures in scientific publications | Finding the write stuff: Automatic identification of discourse structure in student essays | Context dependent claim detection | End-to-end sequence labeling via bi-directional lstm-cnns-crf | Non-projective dependency parsing using spanning tree algorithms | End-to-end relation extraction using lstms on sequences and tree structures | Automatic detection of arguments in legal texts | Efficient higher-order CRFs for morphological tagging | Argumentation mining: The detection, classification and structure of arguments in text | Joint prediction in mst-style discourse parsing for argumentation mining | An annotated corpus of argumentative microtexts | Multitask multi-domain representation learning for sequence tagging | Modeling argument strength in student essays | End-to-end argumentation mining in student essays | Here’s my point: Argumentation Mining with Pointer Networks | Language resources for studying argument | Show me your evidence - an automatic method for context dependent evidence detection | Applying kernel methods to argumentation mining | Progressive neural networks | Deep multi-task learning with low level tasks supervised at lower layers | Evaluating argumentative and narrative essays using graphs | Parsing argumentation structures in persuasive essays | Pointer networks | Multi-task cross-lingual sequence tagging from scratch | Using context to predict the purpose of argumentative writing revisions | Dependency parsing as head selection",acl,100
145.pdf.json,,"To model language, we must represent words. We can imagine representing every word with a binary one-hot vector corresponding to a dictionary position. But such a representation contains no valuable semantic information: distances between word vectors represent only differences in alphabetic ordering. Modern approaches, by contrast, learn to map words with similar meanings to nearby points in a vector space (Mikolov et al., 2013a), from large datasets such as Wikipedia. These learned word embeddings have become ubiquitous in predictive tasks. Vilnis and McCallum (2014) recently proposed an alternative view, where words are represented by a whole probability distribution instead of a deterministic point vector. Specifically, they model each word by a Gaussian distribution, and learn its mean and covariance matrix from data. This approach generalizes any deterministic point embedding, which can be fully captured by the mean vector of the Gaussian distribution. Moreover, the full distribution provides much richer information than point estimates for characterizing words, representing probability mass and uncertainty across a set of semantics. However, since a Gaussian distribution can have only one mode, the learned uncertainty in this representation can be overly diffuse for words with multiple distinct meanings (polysemys), in order for the model to assign some density to any plausible semantics (Vilnis and McCallum, 2014). Moreover, the mean of the Gaussian can be pulled in many opposing directions, leading to a biased distribution that centers its mass mostly around certain meaning while leaving the others not well represented. In this paper, we propose to represent each word with an expressive multimodal distribution, for multiple distinct meanings, entailment, heavy tailed uncertainty, and enhanced interpretability. For example, one mode of the word ‘bank’ could overlap with distributions for words such as ‘finance’ and ‘money’, and another mode could overlap wit","TensorFlow: Large-scale machine learning on heterogeneous systems | Entailment above the word level in distributional semantics | The wacky wide web: a collection of very large linguistically processed web-crawled corpora | A neural probabilistic language model | Multimodal distributional semantics | Infogan: Interpretable representation learning by information maximizing generative adversarial nets | A unified model for word sense representation and disambiguation | A unified architecture for natural language processing: deep neural networks with multitask learning | Adaptive subgradient methods for online learning and stochastic optimization | Placing search in context: the concept revisited | Large-scale learning of word relatedness with constraints | Simlex999: Evaluating semantic models with (genuine) similarity estimation | Improving word representations via global context and multiple word prototypes | Probability product kernels | Optimizing search engines using clickthrough data | Adam: A method for stochastic optimization | Autoencoding variational bayes | Efficient backprop | Neural word embedding as implicit matrix factorization | Efficient estimation of word representations in vector space | Recurrent neural network based language model | Extensions of recurrent neural network language model | Distributed representations of words and phrases and their compositionality | Contextual Correlates of Semantic Similarity | Infinite dimensional word embeddings | Glove: Global vectors for word representation | A word at a time: Computing word relatedness using temporal semantic analysis | Contextual correlates of synonymy | Bayesian probabilistic matrix factorization using markov chain monte carlo | The proof and measurement of association between two things | A probabilistic model for learning multi-prototype word embeddings | Word representations via gaussian embedding | Verb similarity on the taxonomy of wordnet | Understanding deep learning requires rethinking generalization | x;μi,Σi)N (x;μj ,Σj) dx = N (0, μi − μj ,Σi + Σj) (Vilnis and McCallum, 2014) and ξi,j is the log partial energy, given by equation",acl,100
148.pdf.json,Evaluation Metrics for Reading Comprehension: Prerequisite Skills and Readability,"A major goal of natural language processing (NLP) is to develop agents that can understand natural language. Such an ability can be tested with a reading comprehension (RC) task that requires the agent to read open-domain documents and answer questions about them. Building the RC ability is challenging because RC comprises multiple processes including parsing, understanding cohesion, and inference with linguistic and general knowledge. Clarifying what a system achieves is important to the development of RC systems. To achieve robust improvement, systems need to be measured according to various metrics, not just simple accuracy. However, a current problem is that most RC datasets are presented only with superficial categories, such as question types (e.g., what, where, and who) and answer types (e.g., numeric, location, and person). In addition, Chen et al. (2016) revealed that some questions in datasets may not have the quality to test RC systems. In these situations, it is difficult to assess systems accurately. As Norvig (1989) stated, questions easy for humans often turn out to be difficult for systems. For example, see the two RC questions in Figure 1. In the first example from SQuAD (Rajpurkar et al., 2016), although the document is taken from a Wikipedia article and is thus written for adults, the question is easy to solve simply look at one sentence and select an entity. On the other hand, in the second example from MCTest (Richardson et al., 2013), the document is written for children and is easy to read, but the question requires reading multiple sentences and a combination of several skills, such as understanding of causal relations (Sara wanted... → they went to...), coreference resolution (Sara and Her Dad = they), and complementing ellipsis (baseball team = team). These two examples show that the readability of the text does not necessarily correlate with the difficulty of the questions. Nevertheless, the accompanying categories of existing RC datasets ","Readability assessment for text simplification | Curriculum learning | Building textual entailment specialized data sets: a methodology for isolating linguistic phenomena relevant to inference | A thorough examination of the cnn/daily mail reading comprehension task | Bridging | The PASCAL recognising textual entailment challenge | Recognizing textual entailment: Models and applications | Opinosis: a graph-based approach to abstractive summarization of highly redundant opinions | Constructing inferences during narrative text comprehension | Teaching machines to read and comprehend | The goldilocks principle: Reading children’s books with explicit memory representations | Deep read: A reading comprehension system | The role of knowledge in discourse comprehension: A construction-integration model | Information accretion and reduction in text processing: Inferences | Types of common-sense knowledge needed for recognizing textual entailment | Toward a comprehensive model of comprehension | MS MARCO: A human generated machine reading comprehension dataset | Marker passing as a weak method for text inferencing | Who did what: A large-scale person-centered cloze dataset | A survey on transfer learning | The lambada dataset: Word prediction requiring a broad discourse context | Revisiting readability: A unified framework for predicting text quality | Squad: 100, 000+ questions for machine comprehension of text | A new approach to automated text readability classification based on concept indexing with integrated part-ofspeech n-gram features | MCTest: A challenge dataset for the open-domain machine comprehension of text | A neural attention model for abstractive sentence summarization | ask not what textual entailment can do for you... | An analysis of prerequisite skills for reading comprehension | Prerequisite skills for reading comprehension: Multi-perspective analysis of mctest datasets and systems | Overview of QA4MRE main task at CLEF 2013 | Newsqa: A machine comprehension dataset | On improving the accuracy of readability classification using insights from second language acquisition | Strategies of discourse comprehension | The trec-8 question answering track report | What is the Jeopardy model? a quasi-synchronous grammar for QA | Wikiqa: A challenge dataset for open-domain question answering | 2016): we randomly chose questions that satisfied the following conditions: is answer absent = 0, is question bad = 0, and validated answers do not include bad question or none",acl,100
150.pdf.json,Deep Character-Level Neural Machine Translation By Learning Morphology,"Neural machine translation (NMT) attempts to build a single large neural network that reads a sentence and outputs a translation (Sutskever et al., 2014). Most of the extant neural machine translations models belong to a family of word-level encoder-decoders (Sutskever et al., 2014; Cho et al., 2014). Recently, Bahdanau et al. (2015) proposed a model with attention mechanism which automati- cally searches the alignments and greatly improves the performance. However, the use of a large vocabulary seems necessary for the word-level neural machine translation models to improve performance (Sutskever et al., 2014; Cho et al., 2015). Chung et al. (2016b) listed three reasons behind the wide adoption of word-level modeling: (i) word is a basic unit of a language, (ii) data sparsity, (iii) vanishing gradient of character-level modeling. Consider that a language itself is an evolving system. So it is impossible to cover all words in the language. The problem of rare words that are out of vocabulary (OOV) is a critical issue which can effect the performance of neural machine translation. In particular, using larger vocabulary does improve performance (Sutskever et al., 2014; Cho et al., 2015). However, the training becomes much harder and the vocabulary is often filled with many similar words that share a lexeme but have different morphology. There are many approaches to dealing with the out-of-vocabulary issue. For example, Gulcehre et al. (2016), Luong et al. (2015) and Cho et al. (2015) proposed to obtain the alignment information of target unknown words, after which simple word dictionary lookup or identity copy can be performed to replace the unknown words in translation. However, these approaches ignore several important properties of languages such as monolinguality and crosslinguality as pointed out by Luong and Manning (2016). Thus, Luong and Manning (2016) proposed a hybrid neural machine translation model which leverages the power of both words and characters to a","Neural machine translation by jointly learning to align and translate | Theano: new features and speed improvements | Theano: a CPU and GPU math expression compiler | Learning phrase representations using rnn encoder-decoder for statistical machine translation | On using very large target vocabulary for neural machine translation | Hierarchical multiscale recurrent neural networks | A character-level decoder without explicit segmentation for neural machine translation | Empirical evaluation of gated recurrent neural networks on sequence modeling | Multi-way, multilingual neural machine translation with a shared attention mechanism | Pointing the unknown words | Long short-term memory | Character-aware neural language models | Adam: A method for stochastic optimization | Fully character-level neural machine translation without explicit segmentation | Finding function in form: Compositional character models for open vocabulary word representation | Character-based neural machine translation | Achieving open vocabulary neural machine translation with hybrid word-character models | Addressing the rare word problem in neural machine translation | Bleu: a method for automatic evaluation of machine translation | Bidirectional recurrent neural networks | Neural machine translation of rare words with subword units | Hierarchical neural network generative models for movie dialogues | Sequence to sequence learning with neural networks | Blocks and fuel: Frameworks for deep learning | Eye movements when reading transposed text: the importance of word-beginning letters",acl,100
16.pdf.json,Exploiting Argument Information to Improve Event Detection via Supervised Attention Mechanisms,"In the ACE (Automatic Context Extraction) event extraction program, an event is represented as a structure comprising an event trigger and a set of arguments. This work tackles event detection (ED) task, which is a crucial part of event extraction (EE) and focuses on identifying event triggers and categorizing them. For instance, in the sentence “He died in the hospital”, an ED system is expected to detect a Die event along with the trigger word “died”. Besides, the task of EE also includes event argument extraction (AE), which involves event argument identification and role classification. In the above sentence, the arguments of the event include “He”(Role = Person) and “hospital”(Role = Place). However, this paper does not focus on AE and only tackles the former task. According to the above definitions, event arguments seem to be not essentially necessary to ED. However, we argue that they are capable of providing significant clues for identifying and categorizing events. They are especially useful for ambiguous trigger words. For example, consider a sentence in ACE 2005 dataset: Mohamad fired Anwar, his former protege, in 1998. In this sentence, “fired” is the trigger word and the other bold words are event arguments. The correct type of the event triggered by “fired” in this case is End-Position . However, it might be easily misidentified as Attack because “fired” is a multivocal word. In this case, if we consider the phrase “former protege”, which serves as an argument (Role = Position) of the target event, we would have more confidence in predicting it as an End-Position event. Unfortunately, most exiting methods performed event detection individually, where the annotated arguments in training set are totally ignored (Ji and Grishman, 2008; Gupta and Ji, 2009; Hong et al., 2011; Chen et al., 2015; Nguyen and Grishman, 2015; Liu et al., 2016a,b; Nguyen and Grishman, 2016). Although some joint learning based methods have been proposed, which tackled event detect",Proceedings of the workshop on annotating and reasoning about time and events | A neural probabilistic language model | Event extraction via dynamic multi-pooling convolutional neural networks | Why does unsupervised pre-training help deep learning? The Journal of Machine Learning Research 11:625–660 | The berkeley framenet project | Predicting unknown time arguments based on crossevent propagation | Neural network design | Improving neural networks by preventing co-adaptation of feature detectors | Using cross-entity inference to improve event extraction | Refining event extraction through cross-document inference | Convolutional neural networks for sentence classification | Incremental joint extraction of entity mentions and relations | Constructing information networks using one single model | Joint event extraction via structured prediction with global features | Using document level cross-event inference to improve event extraction | Leveraging framenet to improve automatic event detection | A probabilistic soft logic based approach to exploiting latent and global information in event classification | Supervised attentions for neural machine translation | Efficient estimation of word representations in vector space | Joint event extraction via recurrent neural networks | Event detection and domain adaptation with convolutional neural networks | Modeling skip-grams for event detection with convolutional neural networks | A unified model of phrasal and sentential evidence for information extraction | Joint inference for knowledge extraction from biomedical literature | Relieving the computational bottleneck: Joint inference for event extraction with high-dimensional features | Adadelta: An adaptive learning rate method | Bilingual event extraction: a case study on trigger type determination,acl,100
169.pdf.json,Automatic Annotation and Evaluation of Error Types for Grammatical Error Correction,"The Conference on Natural Language Learning (CoNLL) shared task of 2014 (Ng et al., 2014) required teams to build systems that were capable of correcting all types of grammatical errors in learner text. While the submitted systems were evaluated against text that had been explicitly annotated with error type information, the teams themselves were not required to annotate their output in a similar way. This mismatch ultimately meant that a detailed error type analysis of each system was impossible and that error type performance could only be measured in terms of recall. The main aim of this paper is to rectify this situation and provide a method by which unannotated error correction data can be automatically annotated with error type information. This is important because some systems may be more effective at correcting certain error types than oth- ers, yet this information is otherwise concealed in an overall score. Although several new metrics and methodologies for Grammatical Error Correction (GEC) have been proposed since the end of the CoNLL-2014 shared task (Felice and Briscoe, 2015; Bryant and Ng, 2015; Napoles et al., 2015; Grundkiewicz et al., 2015), none of these are currently capable of producing individual error type scores. Our approach consists of two main steps. First, we automatically extract the edits between parallel original and corrected sentences by means of a linguistically-enhanced alignment algorithm (Felice et al., 2016), and second, we classify them according to a new rule-based framework specifically designed with error type evaluation in mind. This enables us to automatically annotate system hypothesis corrections with the same alignment and error type information as the reference and hence carry out a more detailed evaluation. The tool we use to do this will be released with this paper.",Human evaluation of gram | The amu system in the conll-2014 shared task: Grammatical error correction by dataintensive and feature-rich statistical machine translation | Ground truth for grammatical error correction metrics | The CoNLL-2014 shared task on grammatical error correction | Free-marginal multirater kappa: An alternative to fleiss’ fixedmarginal multirater kappa | The illinois-columbia system in the conll-2014 shared task | Grammatical error correction: Machine translation and classifiers | Reassessing the goals of grammatical error correction: Fluency instead of grammaticality | Correction detection and error type selection as an ESL educational aid | Improved correction detection in revised esl sentences | A new dataset and method for automatically grading esol texts,acl,100
173.pdf.json,Determining Gains Acquired from Word Embedding Quantitatively using Discrete Distribution Clustering,"Word embeddings, or word vectors, have been broadly adopted for document analysis (Mikolov et al., 2013b,a). A key appeal of word embedding methods is that they can be obtained from external large-scale corpus and then be easily utilized for different data. Before choosing word embeddings for data analysis, researchers must first consider how much extra gain can be brought from the “embedded” knowledge of words in comparison with that achieved by existing bag-of-words based approaches. Moreover, they must also consider how to quantify that gain. Such a preliminary evaluation is often necessary before any further decisions can be made about the data. Answering such questions is important: almost every model used in practice exploits some basic representations — bag-of-words and word embeddings — for the sake of its computational tractability. Based on word embeddings, high-level models are designed for various tasks. Examples include entity representations, similarity measures, data manifolds, hierarchical structures, language models, and neural architectures. Therefore, it is important to investigate whether the gain or loss found in practice should be credited to the extra assumptions associated with those high-level models or to the use of basic word embeddings. As our experiments demonstrate, introducing these extra assumptions will make individual methods effective only if certain constraints are met. We will address this issue from an unsupervised perspective. Our proposed clustering framework has several advantages. Instead of suppressing a document into a fixed-length vector feeding post-analysis, our framework uses the Wasserstein distance (or the Earth Mover’s Distance, EMD) as a metadistance to quantify the dissimilarity between two empirical nonparametric measures (or discrete distributions) over word embedding space (Wan, 2007; Kusner et al., 2015). Hence, it excludes any vector representation of the documents and sidesteps extra high-level assumptions, ","Barycenters in the wasserstein space | Laplacian eigenmaps and spectral techniques for embedding and clustering | Iterative bregman projections for regularized transportation problems | Latent dirichlet allocation | Document clustering using locality preserving indexing | Sinkhorn distances: Lightspeed computation of optimal transport | Fast computation of wasserstein barycenters | Indexing by latent semantic analysis | Using the triangle inequality to accelerate k-means | Locality preserving projections | Online learning for latent Dirichlet allocation | From word embeddings to document distances | Distributed representations of sentences and documents | Learning the parts of objects by non-negative matrix factorization | Real-time computerized annotation of pictures | Distributed representations of words and phrases and their compositionality | Linguistic regularities in continuous space word representations | Fast and robust earth mover’s distances | Glove: Global vectors for word representation | Inference of population structure using multilocus genotype data | Centroid-based summarization of multiple documents | Objective criteria for the evaluation of clustering methods | Vmeasure: A conditional entropy-based external cluster evaluation measure | Large-scale cross-document coreference using distributed inference and hierarchical models | A statistical interpretation of term specificity and its application in retrieval | Cluster ensembles—a knowledge reuse framework for combining multiple partitions | Topics in optimal transportation | Information theoretic measures for clusterings comparison: Variants, properties, normalization and correction for chance | A novel document similarity measure based on earth movers distance | Document update summarization using incremental hierarchical clustering | Bregman alternating direction method of multipliers | Storybase: Towards building a knowledge base for news events | Document clustering based on non-negative matrix factorization | A study of retrospective and on-line event detection | Scaling up discrete distribution clustering using admm | Fast discrete distribution clustering using wasserstein barycenter with sparse support | Clustering product features for opinion mining | A new mallows distance based metric for comparing clusterings",acl,100
178.pdf.json,"A Weakly-Supervised Method for Jointly Embedding Concepts, Phrases, and Words","Recent vector space models of semantics are primarily built on words. Word embeddings are either used directly as features in downstream modeling tasks (Chiu et al., 2016b), or are composed to produce representations of more complex linguistic units, such as phrases, sentences (Socher et al., 2011; Le and Mikolov, 2014), or even documents (Yang et al., 2016). However, there are many cases in which words are not atomic semantic units, and multi-word expressions cannot be expressed as a composition of their member words: for example, “the Big Apple” is not a fruit, and “Lou Gehrig’s disease” has little to do with baseball. Furthermore, such concepts often multiple textual forms: “the Big Apple” and “New York City” both refer to the same location, and “Lou Gehrig’s disease” and “amyotrophic lateral scle- rosis” are the same medical condition. Despite the lack of lexical overlap between these phrases, we would like a semantic model that can represent the underlying concept, regardless of the specific textual form used. Our novel approach to this task combines structured knowledge with proven techniques for learning word embeddings to train context-based representations for contexts, phrases, and words. The model requires no human annotations: we use known phrases as distant supervision in distributional similarity training over an unannotated corpus. As in the formulation of Mintz et al. (2009) in extracting textual relationships, we assume that any occurrence of a known phrase signifies an occurrence of each concept1 it can refer to, and train our concept embeddings using the contexts of their phrase forms. We experimentally validate our approach by learning embeddings for biomedical concepts and real-world entities. An evaluation on concept similarity and relatedness tasks shows that our embeddings are competitive with prior models that required human annotations for concepts. We also present a novel dataset of similarity and relatedness of real-world entities, identi",How we BLESSed distributional semantic evaluation | The Unified Medical Language System (UMLS): integrating biomedical terminology | Translating Embeddings for Modeling MultiRelational Data | Learning Structured Embeddings of Knowledge Bases | A Unified Multilingual Semantic Representation of Concepts | How to Train Good Word Embeddings for Biomedical NLP | Intrinsic Evaluation of Word Vectors Fails to Predict Extrinsic Performance | Multi-layer Representation Learning for Medical Concepts | Learning Low-Dimensional Representations of Medical Concepts Methods Background | Medical semantic similarity with a neural language model | Jointly Embedding Relations and Mentions for Knowledge Population | Retrofitting Word Vectors to Semantic Lexicons | Problems With Evaluation of Word Embeddings Using Word Similarity Tasks | WordNet | Placing Search in Context: The Concept Revisited | Knowledgebased biomedical word sense disambiguation: an evaluation and application to clinical document classification | Analogy-based Detection of Morphological and Semantic Relations With Word Embeddings: What Works and What Doesn’t | A Quantitative and Qualitative Evaluation of Sentence Boundary Detection for the Clinical Domain Department of Computer Science and Engineering | Learning Abstract Concept Embeddings from Multi-Modal Data: Since You Probably Can’t See What I Mean | SimLex-999: Evaluating Semantic Models with (Genuine) Similarity Estimation | Entity Hierarchy Embedding | Distributed Representations of Sentences and Documents | Neural Word Embedding as Implicit Matrix Factorization | Improving Distributional Similarity with Lessons Learned from Word Embeddings | Learning Entity and Relation Embeddings for Knowledge Graph Completion | Issues in evaluating semantic spaces using word analogies | YAGO3: A Knowledge Base from Multilingual Wikipedias | A SICK cure for the evaluation of compositional distributional semantic models | Medical Concept Embeddings via Labeled Background Corpora | Distributed Representations of Words and Phrases and Their Compositionality | Linguistic Regularities in Continuous Space Word Representations | Distant Supervision for Relation Extraction with an Incomplete Knowledge Base | Distant supervision for relation extraction without labeled data | Evaluating distributed word representations for capturing semantics of biomedical concepts | Embedding Senses for Efficient Graph-based Word Sense Disambiguation | Semantic Similarity and Relatedness between Clinical Terms: An Experimental Study | Corpus domain effects on distributional semantic modeling of medical terms | English Gigaword | Measures of semantic similarity and relatedness in the biomedical domain | Reasoning With Neural Tensor Networks for Knowledge Base Completion | Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions | YAGO: A Core of Semantic Knowledge Unifying WordNet and Wikipedia | Representing Text for Joint Embedding of Text and Knowledge Bases | Knowledge Graph and Text Jointly Embedding | Knowledge Graph Embedding by Translating on Hyperplanes | Embedding Entities and Relations for Learning and Inference in Knowledge Bases | Hierarchical Attention Networks for Document Classification | Retrofitting Word Vectors of MeSH Terms to Improve Semantic Similarity Measures | 2016a) found that a learning rate,acl,100
18.pdf.json,Attention-over-Attention Neural Networks for Reading Comprehension,"To read and comprehend the human languages are challenging tasks for the machines, which requires that the understanding of natural languages and the ability to do reasoning over various clues. Reading comprehension is a general problem in the real world, which aims to read and comprehend a given article or context, and answer the questions based on it. Recently, the cloze-style reading comprehension problem has become a popular task in the community. The cloze-style query (Taylor, 1953) is a problem that to fill in an appropriate word in the given sentences while taking the context information into account. To teach the machine to do cloze-style reading comprehensions, large-scale training data is nec- essary for learning relationships between the given document and query. To create large-scale training data for neural networks, Hermann et al. (2015) released the CNN/Daily Mail news dataset, where the document is formed by the news articles and the queries are extracted from the summary of the news. Hill et al. (2015) released the Children’s Book Test dataset afterwards, where the training samples are generated from consecutive 20 sentences from books, and the query is formed by 21st sentence. Following these datasets, a vast variety of neural network approaches have been proposed (Kadlec et al., 2016; Cui et al., 2016; Chen et al., 2016; Dhingra et al., 2016; Sordoni et al., 2016; Trischler et al., 2016), and most of them stem from the attention-based neural network (Bahdanau et al., 2014), which has become a stereotype in most of the NLP tasks and is wellknown by its capability of learning the “importance” distribution over the inputs. In this paper, we present a novel neural network architecture, called attention-over-attention model. As we can understand the meaning literally, our model aims to place another attention mechanism over the existing document-level attention. Unlike the previous works, that are using heuristic merging functions (Cui et al., 2016), o",Neural machine translation by jointly learning to align and translate | A thorough examination of the cnn/daily mail reading comprehension task | Batch tuning strategies for statistical machine translation | Learning phrase representations using rnn encoder–decoder for statistical machine translation | Keras | Consensus attention-based neural networks for chinese reading comprehension | Gated-attention readers for text comprehension | Teaching machines to read and comprehend | The goldilocks principle: Reading children’s books with explicit memory representations | An efficient method for determining bilingual word classes | Adam: A method for stochastic optimization | Generating and exploiting large-scale pseudo training data for zero pronoun resolution | On the difficulty of training recurrent neural networks | Exact solutions to the nonlinear dynamics of learning in deep linear neural networks | Iterative alternating neural attention for machine reading | Dropout: a simple way to prevent neural networks from overfitting | Srilm — an extensible language modeling toolkit | Cloze procedure: a new tool for measuring readability | Theano: A Python framework for fast computation of mathematical expressions | Natural language comprehension with the epireader | Pointer networks,acl,100
180.pdf.json,Identifying Products in Online Cybercrime Marketplaces: A Dataset and Fine-grained Domain Adaptation Task,"NLP can be extremely useful for enabling scientific inquiry, helping us to quickly and efficiently understand large corpora, gather evidence, and test hypotheses (Bamman et al., 2013; O’Connor et al., 2013). One domain for which automated analysis is particularly useful is Internet security: researchers obtain large amounts of text data pertinent to active threats or ongoing cybercriminal activity, for which the ability to rapidly characterize that text and draw conclusions can reap major benefits (Krebs, 2013a,b). However, conducting automatic analysis is difficult because this data is outof-domain for conventional NLP models, which harms the performance of both discrete models (McClosky et al., 2010) and deep models (Zhang et al., 2017). Not only that, we show that data from one cybercrime forum is even out of domain with respect to another cybercrime forum, making this data especially challenging. 1Available upon publication, along with all models and code from this work. In this work, we present the task of identifying products being bought and sold in the marketplace sections of these online cybercrime forums. We define a token-level annotation task where, for each post, we annotate references to the product or products being bought or sold in that post. Having the ability to automatically tag posts in this way lets us characterize the composition of a forum in terms of what products it deals with, identify trends over time, associate users with particular activity profiles, and connect to price information to better understand the marketplace. Some of these analyses only require post-level information (what is the product being bought or sold in this post?) whereas other analyses might require token-level references; we annotate at the token level to make our annotation as general as possible. Our dataset has already proven enabling for case studies on these particular forums (anon. work in press). Our task has similarities to both slot-filling information ext",Learning Latent Personas of Film Characters | A Fast and Accurate Dependency Parser using Neural Networks | Frustratingly Easy Domain Adaptation | Adaptive Subgradient Methods for Online Learning and Stochastic Optimization | Measuring nominal scale agreement among many raters | Learning a Part-of-Speech Tagger from Two Hours of Annotation | Real-World Semi-Supervised Learning of POS-Taggers for Low-Resource Languages | Foreebank: Syntactic Analysis of Customer Support Forums | Tagging and Linking Web Forum Posts | Cards Stolen in Target Breach Flood Underground Markets | An Empirical Analysis | Semi-Supervised Learning for Nat | Online) Subgradient Methods for Structured Prediction | Overview of the TAC2013 Knowledge Base Population Evaluation: English Slot Filling and Temporal Slot Filling | Overview of the English Slot Filling Track at the TAC2014 Knowledge Base Population Evaluation | Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition | Word Representations: A Simple and General Method for Semi-Supervised Learning | Predicting Thread Discourse Structure over Technical Web Forums | Learning Structural SVMs with Latent Variables | Aspect-augmented Adversarial Networks for Domain Adaptation,acl,100
182.pdf.json,Modeling Contextual Relationships Among Utterances for Multimodal Sentiment Analysis,"Emotion recognition and sentiment analysis have become a new trend in social media, helping users to automatically extract the opinions expressed in user-generated content, especially videos. Thanks to the high availability of computers and smartphones, and the rapid rise of social media, consumers tend to record their reviews and opinions about products or films and upload them on social media platforms, such as YouTube or Facebook. Such videos often contain comparisons, which can aid prospective buyers make an informed decision. The primary advantage of analyzing videos over text is the surplus of behavioral cues present in vocal and visual modalities. The vocal modulations and facial expressions in the visual data, along with textual data, provide important cues to better identify affective states of the opinion holder. Thus, a combination of text and video data helps to create a better emotion and sentiment analysis model (Poria et al., 2017). Recently, a number of approaches to multimodal sentiment analysis, producing interesting results, have been proposed (Pérez-Rosas et al., 2013; Wollmer et al., 2013; Poria et al., 2015). However, there are major issues that remain unaddressed, such as the role of speaker-dependent versus speaker-independent models, the impact of each modality across the dataset, and generalization ability of a multimodal sentiment classifier. Leaving these issues unaddressed has presented difficulties in effective comparison of different multimodal sentiment analysis methods. An utterance is a unit of speech bound by breathes or pauses. Utterance-level sentiment analysis focuses on tagging every utterance of a video with a sentiment label (instead of assigning a unique label to the whole video). In particular, utterance-level sentiment analysis is useful to understand the sentiment dynamics of different aspects of the topics covered by the speaker throughout his/her speech. The true meaning of an utterance is relative to its surrounding u","Affective computing and sentiment analysis | Multimodal human emotion/expression recognition | Semantic audio-visual data fusion for automatic emotion recognition | Facial emotion recognition using multi-modal information | Adaptive subgradient methods for online learning and stochastic optimization | Universal facial expressions of emotion | On-line emotion recognition in a 3-d activation-valence-time continuum using acoustic and linguistic cues | Opensmile: the munich versatile and fast open-source audio feature extractor | Long Short-Term Memory in Recurrent Neural Networks | 3d convolutional neural networks for human action recognition | Multimodal emotion recognition in speech-based interaction using facial expression, body gesture and acoustic analysis | Audio-visual emotion recognition using gaussian mixture models for face and voice | Efficient estimation of word representations in vector space | Thumbs up?: sentiment classification using machine learning techniques | Utterance-level multimodal sentiment analysis | A review of affective computing: From unimodal analysis to multimodal fusion | Deep convolutional neural network textual features and multiple kernel learning for utterance-level multimodal sentiment analysis | Ensemble of SVM trees for multimodal emotion recognition | Ensemble of svm trees for multimodal emotion recognition | Recognizing affect from linguistic information in 3d continuous space | Recursive deep models for semantic compositionality over a sentiment treebank | Abandoning emotion classes-towards continuous emotion recognition with modelling of long-range dependencies | Youtube movie reviews: Sentiment analysis in an audio-visual context | Emotion recognition of affective speech based on multiple classifiers using acoustic-prosodic information and semantic labels | Multimodal sentiment intensity analysis in videos: Facial gestures and verbal | Attentionbased bidirectional long short-term memory networks for relation classification",acl,100
19.pdf.json,Generating and Exploiting Large-scale Pseudo Training Data for Zero Pronoun Resolution,"Previous works on zero pronoun (ZP) resolution mainly focused on the supervised learning approaches (Han, 2006; Zhao and Ng, 2007; Iida et al., 2007; Kong and Zhou, 2010; Iida and Poesio, 2011; Chen and Ng, 2013). However, a major obstacle for training the supervised learning models for ZP resolution is the lack of annotated data. An important step is to organize the shared task on anaphora and coreference resolution, such as the ACE evaluations, SemEval-2010 shared task on Coreference Resolution in Multiple Languages (Marta Recasens, 2010) and CoNLL2012 shared task on Modeling Multilingual Unre- stricted Coreference in OntoNotes (Sameer Pradhan, 2012). Following these shared tasks, the annotated evaluation data can be released for the following researches. Despite the success and contributions of these shared tasks, it still faces the challenge of spending manpower on labeling the extended data for better training performance and domain adaptation. To address the problem above, in this paper, we propose a simple but novel approach to automatically generate large-scale pseudo training data for zero pronoun resolution. Inspired by data generation on cloze-style reading comprehension, we can treat the zero pronoun resolution task as a special case of reading comprehension problem. So we can adopt similar data generation methods of reading comprehension to the zero pronoun resolution task. For the noun or pronoun in the document, which has the frequency equal to or greater than 2, we randomly choose one position where the noun or pronoun is located on, and replace it with a specific symbol 〈blank〉. Let query Q and answer A denote the sentence that contains a 〈blank〉, and the noun or pronoun which is replaced by the 〈blank〉, respectively. Thus, a pseudo training sample can be represented as a triple: 〈D,Q,A〉 (1) For the zero pronoun resolution task, a 〈blank〉 represents a zero pronoun (ZP) in query Q, and A indicates the corresponding antecedent of the ZP. In this way, ",Neural machine translation by jointly learning to align and translate | Ltp: A chinese language technology platform | Chinese zero pronoun resolution: Some recent advances | Chinese zero pronoun resolution: An unsupervised approach combining ranking and integer linear programming | Chinese zero pronoun resolution: A joint unsupervised discourseaware model rivaling state-of-the-art resolvers | Chinese zero pronoun resolution with deep neural networks | Learning phrase representations using rnn encoder-decoder for statistical machine translation | Keras | Pronominal anaphora resolution in chinese | A computational approach to zero-pronouns in spanish | Korean zero pronouns: analysis and resolution | Teaching machines to read and comprehend | Resolving pronoun references | Exploiting syntactic patterns as clues in zero-anaphora resolution | Zero-anaphora resolution by learning rich syntactic pattern features | A cross-lingual ilp solution to zero anaphora resolution | Japanese zero pronoun resolution based on ranking rules and machine learning | Adam: A method for stochastic optimization | A tree kernelbased unified framework for chinese zero anaphora resolution | Semeval-2010 task 1: Coreference resolution in multiple languages | Glove: Global vectors for word representation | Conll-2012 shared task: Modeling multilingual unrestricted coreference in ontonotes | A discriminative approach to japanese zero anaphora resolution with large-scale lexicalized case frames | Exact solutions to the nonlinear dynamics of learning in deep linear neural networks | Theano: A Python framework for fast computation of mathematical expressions | Identification and resolution of chinese zero pronouns: A machine learning approach,acl,100
193.pdf.json,,"Universal Conceptual Cognitive Annotation (UCCA, Abend and Rappoport, 2013) is a crosslinguistically applicable semantic representation scheme, building on the established Basic Linguistic Theory typological framework (Dixon, 2010a,b, 2012), and Cognitive Linguistics literature (Croft and Cruse, 2004). It has demonstrated applicability to multiple languages, including English, French, German and Czech, support for rapid annotation, and stability under translation (Sulem et al., 2015). It has also proven useful for machine translation evaluation (Birch et al., 2016). UCCA differs from syntactic schemes in terms of content and formal structure. It exhibits reentrancy, discontinuous nodes and non-terminals, which no single existing parser supports. Lacking a parser, UCCA’s applicability has been so far limited, a gap this work addresses. We present the first UCCA parser, TUPA (Transition-based UCCA Parser), building on recent advances in discontinuous constituency and dependency graph parsing, and further introducing novel transitions and features for UCCA. Transition-based techniques are a natural starting point for UCCA parsing, given the conceptual similarity of UCCA’s distinctions, centered around predicate-argument structures, to distinctions expressed by dependency schemes, and the achievements of transition-based methods in dependency parsing (Dyer et al., 2015; Andor et al., 2016; Kiperwasser and Goldberg, 2016). We are further motivated by the strength of transition-based methods in related tasks, including dependency graph parsing (Sagae and Tsujii, 2008; Ribeyre et al., 2014; Tokgöz and Eryiğit, 2015), constituency parsing (Sagae and Lavie, 2005; Zhang and Clark, 2009; Zhu et al., 2013; Maier, 2015; Maier and Lichte, 2016), AMR parsing (Wang et al., 2015a,b, 2016; Misra and Artzi, 2016; Goodman et al., 2016; Zhou et al., 2016; Damonte et al., 2017) and CCG parsing (Zhang and Clark, 2011; Ambati et al., 2015, 2016). We evaluate TUPA on the English UCCA corp","Universal Conceptual Cognitive Annotation See Appendix E for a proof sketch for the completeness | Potsdam: Semantic dependency parsing by bidirectional graph-tree transformations and syntactic parsing | Semantic dependency graph parsing using tree approximations | Lisbon: Evaluating TurboSemanticParser on multiple languages and out-of-domain data | An incremental algorithm for transition-based CCG parsing | Shift-reduce CCG parsing using neural network models | Globally normalized transition-based neural networks | Broad-coverage CCG semantic parsing with AMR | Abstract Meaning Representation for sembanking | HUME: Human UCCA-based evaluation of machine translation | Towards wide-coverage semantic interpretation | A fast and accurate dependency parser using neural networks | Incremental parsing with the perceptron algorithm | Cognitive linguistics | An incremental parser for abstract meaning representation | Basic Linguistic Theory: Grammatical Topics, volume 2 | Basic Linguistic Theory: Methodology, volume 1 | Basic Linguistic Theory: Further Grammatical Topics, volume 3 | Peking: Building semantic dependency graphs with a hybrid parser | Transitionbased dependeny parsing with stack long shortterm memory | Parsing as reduction | A discriminative graph-based parser for the abstract meaning representation | On building a more efficient grammar by exploiting types | Learning sparser perceptron models | A dynamic oracle for arc-eager dependency parsing | Noise reduction and targeted exploration in imitation learning for Abstract Meaning Representation parsing | Multilingual joint parsing of syntactic and semantic dependencies with a latent variable model | An improved non-monotonic transition system for dependency parsing | Who did what to whom? A contrastive study of syntacto-semantic dependencies | TreeAdjoining Grammars | Adam: A method for stochastic optimization | Simple and accurate dependency parsing using bidirectional LSTM feature representations | Transforming dependencies into phrase structures | Towards a catalogue of linguistic graph banks | Toward abstractive summarization using semantic representations | Discontinuous incremental shift-reduce parsing | Discontinuous parsing with continuous trees | Efficient estimation of word representations in vector space | Neural shift-reduce CCG semantic parsing | Hybrid simplification using deep semantics and machine translation | DyNet: The dynamic neural network toolkit | An efficient algorithm for projective dependency parsing | Non-projective dependency parsing in expected linear time | MaltParser: A language-independent system for data-driven dependency parsing | SemEval 2015 task 18: Broad-coverage semantic dependency parsing | SemEval 2014 task 8: Broad-coverage semantic dependency parsing | Head Driven Phrase Structure Grammar | Aligning English strings with abstract meaning representation graphs | Parsing English into abstract meaning representation using syntax-based machine translation | Alpage: Transitionbased semantic graph parsing with syntactic features | A classifierbased parser with linear run-time complexity | Shift-reduce dependency DAG parsing | Copenhagen-Malmö: Tree approximations of semantic parsing problems | Discriminative lexical semantic segmentation with gaps: running the MWE gamut | The Syntactic Process | Conceptual annotations preserve structure across translations: A French-English case study | Greedy, joint syntactic-semantic parsing with stack LSTMs | Transitionbased dependency DAG parsing using dynamic oracles | An AMR parser for English, French, German, Spanish and Japanese and a new AMRannotated corpus | CAMR at SemEval2016 task 8: An extended transition-based amr parser | Boosting transition-based AMR parsing with refined actions and auxiliary analyzers | A transition-based algorithm for AMR parsing | OntoNotes release 5.0 LDC2013T19 | Robust subgraph generation improves abstract meaning representation parsing | Transition-based parsing of the Chinese treebank using a global discriminative model | Shift-reduce CCG parsing | AMR parsing with an incremental joint model | Fast and accurate shiftreduce constituent parsing",acl,100
201.pdf.json,Investigating Different Context Types and Representations for Learning Word Embeddings,"Recently, there is a growing research interest on word embedding models, where words are embedded into low-dimensional real vectors. Words that share similar meanings tend to have short distances in the vector space. The trained word embeddings are not only useful by themselves (e.g. used for calculating word similarities) but also effective when used as the input of the downstream models, such as part-of-speech tagging, chunking, named entity recognition (Collobert and Weston, 2008; Collobert et al., 2011) and text classification (Socher et al., 2013; Kim, 2014). For almost all word embedding models, the training objectives are based on the Distributed Hypothesis (Harris, 1954), which can be stated as: “words that occur in the same contexts tend to have similar meanings”. The “context” is usually defined as the words which precede and follow the target word within some fixed distance in most word embedding models with various architec- tures (Bengio et al., 2003; Mnih and Hinton, 2007; Mikolov et al., 2013b; Pennington et al., 2014). Among them, Global Vectors (GloVe) proposed by Pennington et al. (2014), Continuous Skip-Gram (CSG) 1 and Continuous Bag-Of-Words (CBOW) proposed by Mikolov et al. (2013a) achieve stateof-the-art results on a wide range of linguistic tasks, and scales well to corpus with billion words. Recently, Levy and Goldberg (2014b); Ling et al. (2015) 2 improve CSG and CBOW by introducing position-aware context representation, where each contextual word is associated with their relative position to the target word. Levy and Goldberg (2014a) propose DEPS, which takes the words that are connected to target word in dependency parse tree as context. Despite all these efforts, there is still no clear answer to the following questions due to the lack of systematical comparison: 1) Is dependencybased context more reasonable than traditional linear one? 2) Do the relative position or the dependency relation between contextual word and target word contrib",A study on similarity and relatedness using distributional and wordnet-based approaches | Tailoring continuous word representations for dependency parsing | A neural probabilistic language model | Intrinsic evaluation of word vectors fails to predict extrinsic performance | A unified architecture for natural language processing: Deep neural networks with multitask learning | Natural language processing (almost) from scratch | Semisupervised sequence learning | Placing search in context: The concept revisited | Distributional structure | Convolutional neural networks for sentence classification | Skip-thought vectors | How to generate a good word embedding | Dependencybased word embeddings | Linguistic regularities in sparse and explicit word representations | Neural word embedding as implicit matrix factorization | Improving distributional similarity with lessons learned from word embeddings | Two/too simple adaptations of word2vec for syntax problems | Issues in evaluating semantic spaces using word analogies | Learning word vectors for sentiment analysis | The Stanford CoreNLP natural language processing toolkit | The role of context types and dimensionality in learning word embeddings | Efficient estimation of word representations in vector space | Distributed representations of words and phrases and their compositionality | Three new graphical models for statistical language modelling | Dependency tree-based sentiment classification using crfs with hidden variables | A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts | Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales | Glove: Global vectors for word representation | Evaluation methods for unsupervised word embeddings | Recursive deep models for semantic compositionality over a sentiment treebank | A unified learning framework of skip-grams and global vectors | Is ”universal syntax” universally useful for learning distributed word representations? In ACL | Learning syntactic categories using paradigmatic representations of word context | Learning word meta-embeddings | Using wiktionary for computing semantic relatedness,acl,100
21.pdf.json,Transductive Non-linear Learning for Chinese Hypernym Prediction,"A hypernym of an entity characterizes the type or the class of the entity. For example, the word country is the hypernym of the entity Canada. The accurate prediction of hypernyms benefits a variety of NLP tasks, such as taxonomy learning (Wu et al., 2012; Fu et al., 2014), fine-grained entity categorization (Ren et al., 2016), knowledge base construction (Suchanek et al., 2007), etc. In previous work, the detection of hypernyms requires lexical, syntactic and/or semantic analysis of relations between entities and their respective hypernyms from a language-specific knowledge source. For example, Hearst (1992) is the pioneer work to extract is-a relations from a text corpus based on handcraft patterns. The followingup work mostly focuses on is-a relation extraction using automatically generated patterns (Snow et al., 2004; Ritter et al., 2009; Sang and Hof- mann, 2009; Kozareva and Hovy, 2010) and relation inference based on distributional similarity measures (Kotlerman et al., 2010; Lenci and Benotto, 2012; Shwartz et al., 2016). While these approaches have relatively high precision over English corpora, extracting hypernyms for entities is still challenging for Chinese. From the linguistic perspective, Chinese is a lower-resourced language with very flexible expressions and grammatical rules (Wang et al., 2015). For instance, there are no word spaces, explicit tenses and voices, and distinctions between singular and plural forms in Chinese. The order of words can be changed flexibly in sentences. Hence, as previous research indicates, hypernym extraction methods for English are not necessarily suitable for the Chinese language (Fu et al., 2014; Wang et al., 2015; Wang and He, 2016). Based on such conditions, several classification methods are proposed to distinguish is-a and notis-a relations based on Chinese encyclopedias (Lu et al., 2015; Li et al., 2015). Similar to Princeton WordNet, a few Chinese wordnets have also been developed (Huang et al., 2004; Xu et al.","How we blessed distributional semantic evaluation | LEDIR: an unsupervised algorithm for learning directionality of inference rules | Automatic construction of a hypernym-labeled noun hierarchy from text | Coupled semi-supervised learning for information extraction | Transductive Inference and SemiSupervised Learning | Web-scale information extraction in knowitall: (preliminary results) | Learning semantic hierarchies via word embeddings | Exploiting multiple sources for open-domain hypernym discovery | Learning by transduction | Tikhonov regularization and total least squares | Automatic acquisition of hyponyms from large text corpora | Sinica BOW (bilingual ontological wordnet): Integration of bilingual wordnet and SUMO | Directional distributional similarity for lexical inference | Learning arguments and supertypes of semantic relations using recursive patterns | Identifying hypernyms in distributional semantic spaces | A relation extraction method of chinese named entities based on location and semantic features | User generated content oriented chinese taxonomy construction | Bipartite edge prediction via transductive learning over product graphs | Taxonomy induction from chinese encyclopedias by combinatorial optimization | Characterization of a class of sigmoid functions with applications to neural networks | Efficient estimation of word representations in vector space | Wordnet: a lexical database for english | On the contribution of word embeddings to temporal relation classification | Espresso: Leveraging generic patterns for automatically harvesting semantic relations | Deriving a large-scale taxonomy from wikipedia | AFET: automatic finegrained entity typing by hierarchical partial-label embedding | What is this, anyway: Automatic hypernym discovery | Extracting hypernym pairs from the web | Lexical patterns or dependency patterns: Which is better for hypernym extraction? In Proceedings of the Thirteenth Conference on Computational Natural Language Learning | Chasing hypernyms in vector spaces with entropy | Improving hypernymy detection with an integrated path-based and distributional method | Learning syntactic patterns for automatic hypernym discovery | Yago: a core of semantic knowledge | Instance-based evaluation of entailment rule acquisition | Challenges in chinese knowledge graph construction | Chinese hypernym-hyponym extraction from user generated categories | Cbuilding the chinese open wordnet (cow): Starting from core synsets | Probase: a probabilistic taxonomy for text understanding | An integrated approach for automatic construction of bilingual chinese-english wordnet | Cross-lingual text classification via model translation with limited dictionaries",acl,100
214.pdf.json,Exploring Macro Discourse Structure with Macro-micro Unified Primary-secondary Relationship,"Discourse rarely exists isolated, so the interpretation of a discourse requires understanding of its structure and semantics. (De Beaugrande, 1981) As an instance, the discourse primary-secondary relationship is the relation between the primary content and secondary content within a discourse, or the relation between the primary and secondary aspects of a discourse and the others. Here, the primary content refers to the dominant position in the discourse, and plays a decisive role in the part, while the secondary content refers to the auxiliary position, and does not play a decisive role in the discourse. In principle, the primary-secondary relationship plays a critical role in natural language processing, since the recognition of the discourse primarysecondary relationship not only helps to understand the discourse structure and semantics, but also provides strong support for deep natural language processing applications. Despite of its potential in statistical machine translation (Meyer and Popescu-Belis, 2012; Guzmán et al., 2014; Peldszus and Stede, 2015), automatic text summarization (Atkinson and Munoz, 2013; Ferreira et al., 2014; Cohan and Goharian, 2015), question answering (Liakata et al., 2013), information extraction (Presutti et al., 2012; Zou et al., 2014), sentiment analysis (Mukherjee et al., 2012; Mittal et al., 2013; Bhatia et al., 2015) etc. recognition of the discourse primary-secondary relationship has become the bottleneck in discourse structure analysis recently, largely due to the ignorance of its critical role in discourse structure analysis by viewing it only as a dispensable component in the analysis of the discourse rhetorical structure. Generally speaking, there exist two hierarchical levels of discourse structures: micro level and macro level. While micro structure refers to the relationship between the internal structures in a sentence or two consecutive sentences, the macro structure refers to the relationship between sentences, para","Rhetoricsbased multi-document summarization | Better document-level sentiment analysis from rst discourse parsing | Scientific article summarization using citation-context and article’s discourse structure | A multi-document summarization system based on statistics and linguistic treatment | The thread of discourse, volume 207 | Attention, intentions, and the structure of discourse | Centering: A framework for modeling the local coherence of discourse | Using discourse structure improves machine translation evaluation | Linguistic function and literary style: An inquiry into the language of william golding’s the inheritors | Hilda: A discourse parser using support vector machine classification | Coherence and coreference | Intention, information, and structure in discourse: A first draft | Textual interaction: An introduction to written discourse analysis | Combining intra-and multisentential rhetorical parsing for document-level discourse analysis | Generating discourse structures for written texts | Research of Chinese discourse structure representation and resource construction | Building chinese discourse corpus with connective-driven dependency tree structure | A discourse-driven content model for summarising scientific articles evaluated in a complex question answering task | Rhetorical structure theory and text analysis | Relational propositions in discourse | Rhetorical structure theory: A theory of text organization (no | The theory and practice of discourse parsing and summarization | Working with discourse: Meaning beyond the clause | Using sense-labeled discourse connectives for statistical machine translation | Sentiment analysis of hindi review based on negation and discourse relation | Sentiment analysis in twitter with lightweight discourse analysis | Joint prediction in mst-style discourse parsing for argumentation mining | Knowledge extraction based on discourse representation theory and linguistic frames | Sentence level discourse parsing using syntactic and lexical information | Macrostructures: An interdisciplinary study of global structures in discourse, interaction, and cognition | Handbook of discourse analysis | News as discourse | Research of chinese complex sentence | A research on the collocation of the relation markers of Chinese compound sentences and some relevant explanation | Negation focus identification with contextual discourse information",acl,100
216.pdf.json,Topical Coherence in LDA-based Models through Induced Segmentation,"Since the seminal works of Hofmann (1999) and Blei et al. (2003), there have been several developments in probabilistic topic models. Many extensions have indeed been proposed for different applications, including ad-hoc information retrieval (Wei and Croft, 2006), clustering search results (Zeng et al., 2004) and driving faceted browsing (Mimno and McCallum, 2007). In most of these studies, the initial exchangeability assumptions of PLSA and LDA, stipulating that words within a document are interdependent, has led to incoherent topic assignments within semantically meaningful text units, even though the importance of having topically coherent phrases is generally admitted (Griffiths et al., 2005). More recently, (Balikas et al., 2016b) has shown that binding topics, so as to obtain more coherent topic assignments, within such text segments as noun phrases improves the performance (e.g. in terms of perplexity) of LDAbased models. The question nevertheless remains as to which segmentation one should rely on. Furthermore, text segments can refer to topics that are barely present in other parts of the document. For example, the segment “the Kurdish regional capital” in the sentence1 “A thousand protesters took to the main street in Erbil, the Kurdish regional capital, to condemn a new law requiring all public demonstrations to have government permits.” refers to geography in a document that is mainly devoted to politics. Relying on a single topic distribution, as done in most previous studies including (Balikas et al., 2016b), may prevent one from capturing those segment specific topics. In this paper, we propose a novel LDA-based model that automatically segments documents into topically coherent sequences of words. The coherence between topics is ensured through copulas (Elidan, 2013) that bind the topics associated to the words of a segment. In addition, this model relies on both document and segment specific topic distributions so as to capture fine grained differe","Streaming-lda: A copula-based approach to modeling topic dependencies in document streams | On smoothing and inference for topic models | On a topic model for sentences | Modeling topic dependencies in semantically coherent text spans with copulas | Natural Language Processing with Python | Latent dirichlet allocation | Syntactic topic models | Indexing by latent semantic analysis | A Segmented Topic Model Based on the Two-parameter Poisson-Dirichlet Process | Topic Segmentation with a Structured Topic Model | Copulas in Machine Learning, Springer Berlin Heidelberg, Berlin, Heidelberg, pages 39–60 | Finding scientific topics | Integrating topics and syntax | Nested Archimedean Copulas Meet R: The nacopula Package | Probabilistic latent semantic indexing | The sensitivity of topic coherence evaluation to topic cardinality | On collocations and topic models | Organizing the oca: Learning faceted subjects from a library of digital books | Optimizing semantic coherence in topic models | LSHTC: A Benchmark for | A hierarchical bayesian lan | Topical n-grams: Phrase and topic discovery, with an application to information retrieval | Lda-based document models for ad-hoc retrieval | Concept over time: the combination of probabilistic topic model with wikipedia knowledge | Learning to cluster web search results",acl,100
220.pdf.json,,"In everyday language, we come across many types of figurative speech. These irregular expressions are understood with little difficulty by humans but require special attention in NLP. One of these is metonymy, a type of common figurative language, which stands for the substitution of the concept, phrase or word being meant with a semantically related one. For example, in “Moscow traded gas and aluminium with Beijing.”, both location names were substituted in place of governments. Named Entity Recognition (NER) taggers have no provision for handling metonymy, meaning that this frequent linguistic phenomenon goes largely undetected within current NLP. Classi- fication decisions presently focus on the entity using features such as orthography to infer its word sense, largely ignoring the context, which provides the strongest clue about whether a word is used metonymically. A common classification approach is choosing the N words to the immediate left and right of the entity or the whole paragraph as input to the model. However, this “greedy” approach also processes input that should in practice be ignored. Metonymy is problematic for applications such as Geographical Parsing (GP) (see a survey by Monteiro et al. (2016)) and other information extraction tasks in NLP. In order to accurately identify and ground location entities, for example, we must recognise that metonymic entities constitute false positives and should not be treated the same way as regular locations. For example, in “London voted for the change.”, London refers to the concept of “people” and should not be classified as a location. There are many types of metonymy (Shutova et al., 2013), however, in this paper, we primarily address metonymic location mentions with reference to GP and NER. Contributions: 1. We investigate how to improve classification tasks by introducing a novel minimalist method called Predicate Window (PreWin), which is highly discriminating with its selection of input (achieved SOTA ","Don’t count, predict! a systematic comparison of context-counting vs | Xrce-m: A hybrid system for named entity metonymy resolution | A shortest path dependency kernel for relation extraction | Keras | Natural language processing (almost) from scratch | Metonymy and conceptual blending | Adaptive recursive neural network for target-dependent twitter sentiment classification | Gyder: maxent metonymy resolution | A synopsis of linguistic theory, 1930-1955 | Speech recognition with deep recurrent neural networks | Long short-term memory | An improved non-monotonic transition system for dependency parsing | Generalizing dependency features for opinion mining | Fuh (fernuniversität in hagen): Metonymy recognition using different kinds of context for a memory-based learner | Rcv1: A new benchmark collection for text categorization research | A dependency-based neural network for relation classification | Automatic lymphoma classification with sentence subgraph mining from pathology reports | Metonymy resolution as a classification task | Semeval2007 task 08: Metonymy resolution at semeval2007 | Data and models for metonymy resolution | context2vec: Learning generic context embedding with bidirectional lstm | Investigation of recurrent-neuralnetwork architectures and learning methods for spoken language understanding | Distributed representations of words and phrases and their compositionality | Glove: Global vectors for | Long short-term memory based recurrent neural network architectures for large vocabulary speech recognition | A computational model of logical metonymy | Word sense disambiguation | Word sense disambiguation with neural language models | Is local window essential for neural network based chinese word segmentation | Exploring metaphorical senses and word representations for identifying metonyms",acl,100
222.pdf.json,Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme,"Joint extraction of entities and relations is to detect entity mentions and recognize their semantic relations simultaneously from unstructured text, as Figure 1 shows. Different from open information extraction (Open IE) (Banko et al., 2007) whose relation words are extracted from the given sentence, in this task, relation words are extracted from a predefined relation set which may not appear in the given sentence. It is an important issue in knowledge extraction and automatic construction of knowledge base. Traditional methods handle this task in a pipelined manner, i.e., extracting the entities (Nadeau and Sekine, 2007) first and then recognizing their relations (Rink, 2010). This separated framework makes the task easy to deal with, and each component can be more flexible. But it neglects the relevance between these two sub-tasks and each subtask is an independent model. The results of entity recognition may affect the performance of relation classification and lead to erroneous delivery (Li and Ji, 2014). Different from the pipelined methods, joint learning framework is to extract entities together with relations using a single model. It can effectively integrate the information of entities and relations, and it has been shown to achieve better results in this task. However, most existing joint methods are feature-based structured systems (Li and Ji, 2014; Miwa and Sasaki, 2014; Yu and Lam, 2010; Ren et al., 2017). They need complicated feature engineering and heavily rely on the other NLP toolkits, which might also lead to error propagation. In order to reduce the manual work in feature extraction, recently, (Miwa and Bansal, 2016) presents a neural networkbased method for the end-to-end entities and relations extraction. Although the joint models can represent both entities and relations with shared parameters in a single model, they also extract the entities and relations separately and produce redundant information. For instance, the sentence in Figure 1 c","Open information extraction from the web | Named entity recognition with bidirectional lstm-cnns | Classifying relations by ranking with convolutional neural networks | Improved relation extraction with feature-rich compositional embedding models | Long short-term memory | Knowledgebased weak supervision for information extraction of overlapping relations | Bidirectional lstm-crf models for sequence tagging | Recurrent continuous translation models | Combining lexical, syntactic, and semantic features with maximum entropy models for extracting relations | Investigating lstms for joint extraction of opinion entities and relations | Conditional random fields: Probabilistic models for segmenting and labeling sequence data | Neural architectures for named entity recognition | Incremental joint extraction of entity mentions and relations | Joint entity recognition and disambiguation | Distributed representations of words and phrases and their compositionality | Distant supervision for relation extraction without labeled data | End-to-end relation extraction using lstms on sequences and tree structures | Modeling joint entity and relation extraction with table representation | A survey of named entity recognition and classification | Lexicon infused phrase embeddings for named entity resolution | Cotype: Joint extraction of typed entities and relations with knowledge bases | Utd: Classifying semantic relations by combining lexical and semantic resources | Joint inference of entities, relations, and coreference | Sequence to sequence learning with neural networks | Line: Large-scale information network embedding | Supertagging with lstms | Semantic relation classification via convolutional neural networks with simple negative sampling | Classifying relations via long short term memory networks along shortest dependency paths | Joint inference for fine-grained opinion extraction | Jointly identifying entities and extracting relations in encyclopedia text via a graphical model approach | Relation classification via convolutional deep neural network | Neural models for sequence chunking | A neural network framework for relation extraction: Learning entity semantic and relation pattern | Natural language question answering over rdf: a graph data driven approach",acl,100
226.pdf.json,,"Can you imagine a straightforward answer to the question How to automatically analyse semantics of a natural language and to represent the meaning of phrases (or even sentences) in this language in an accessible way? A few years ago most of us would probably answer I don’t know! And now, in the era of high-speed and high-performance computing, everybody seems to know it – with distributional semantics models.","Semeval-2012 task 6: A pilot on semantic textual similarity | Inter-Coder Agreement for Computational Linguistics | Nouns are vectors, adjectives are matrices: Representing adjective-noun constructions in semantic space | A neural probabilistic language model | Neural probabilistic language models | Sick through the semeval glasses | A coefficient of agreement for nominal scales | A synopsis of linguistic theory, 1930-1955 | Measuring nominal scale agreement among many raters | Experimental support for a categorical compositional distributional model of meaning | Distributional structure | Compositionality: its historic context | Content Analysis: An Introduction to Its Methodology | Content Analysis: An Introduction to Its Methodology | Semeval-2014 task 1: Evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual | Distributed representations of words and phrases and their compositionality | Composition in distributional models of semantics | Collecting image annotations using amazon’s mechanical turk | Reliability of content analysis: The case of nominal scale coding | Semantic compositionality through recursive matrix-vector spaces | Polish Dependency Parser Trained on an Automatically Induced Dependency Bank",acl,100
237.pdf.json,A New Approach for Measuring Sentiment Orientation based on Multi-Dimensional Vector Space,"Previous research in sentiment analysis or opinion mining mostly focus on supervised methods, which requires labeled training data to identify properties of unseen input, and then classify input later. Probabilistic methods in particular often calculate which class a word or phrase most likely bears and then make predictions regarding the label of a given target text, using those estimations. While such methods have widely been adopted, there are few examples which measure the likelihood of lexical items in an unsupervised or semisupervised manner. However, there still exist situations where sentiment analysis should be performed using non-labeled datasets. In such cases, discovering information regarding the sentiment orientation of vocabulary in a non-supervised fashion becomes essential. Our approach employs VSM (Vector Space Models) as its main component. VSM is deeply related to the distributional hypothesis (Turney and Pantel, 2010). The distributional hypothesis states that words in similar contexts tend to have similar meaning (Rubenstein and Goodenough, 1965; Schütze and Pederson, 1995; Deerwester et al., 1990). Traditionally, the relation of two words in a ‘similar context’ has been distinguished into two classes: syntagmatic or paradigmatic (Murphy, 2003; Sahlgren, 2006). Syntagmatic relations are concerned with whether or not two entities are in a co-occurrence relation, and paradigmatic relations are concerned with whether the two items in question are interchangeable (substitution relation). Many collocation models using N-grams and Point-wise Mutual Information (PMI) analyze the former-type of word relations. On the other hand, recent dense vector-based models (Skip-gram, Continuous Bag-of-Words) exploit the paradigmatic relation, and thus they both give a high weight to the similarity of words if they share similar neighboring entities (Mikolov et al., 2013). Our work can best be understood as an exploration to find a sentiment dimension over a multi","Don't count, predict! A systematic comparison of context-counting vs. context-predicting semantic vectors. Paper presented at the ACL | Recognizing subjectivity: a case study in manual tagging | A unified architecture for natural language processing: Deep neural networks with multitask learning | Indexing by latent semantic analysis | Conceptual spaces: The geometry of thought: MIT press | Predicting the semantic orientation of adjectives. Paper presented at the Proceedings of the eighth conference on European chapter of the Association for Computational Linguistics | Effects of adjective orientation and gradability on sentence subjectivity | Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781 | Semantic relations and the lexicon: antonymy, synonymy and other paradigms | The nature and measurement of meaning | Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales | Glove: Global Vectors for Word Representation. Paper presented at the EMNLP | Contextual correlates of synonymy | The Word-Space Model: Using distributional analysis to represent syntagmatic and paradigmatic relations between words in high-dimensional vector spaces | Word space | Categories and concepts: Harvard University | Recursive deep models for semantic compositionality over a sentiment treebank | Thumbs up or thumbs down?: semantic orientation applied to unsupervised | From frequency to meaning: Vector space models of semantics | Massively parallel parsing: A strongly interactive model of natural language interpretation | Development and use of a gold-standard data set for subjectivity classifications. Paper presented at the Proceedings of the 37th annual meeting of the Association for Computational | Automatic seed word selection for unsupervised sentiment classification of Chinese text",acl,100
239.pdf.json,How to evaluate word embeddings? On importance of data efficiency and simple supervised tasks,"Using word embeddings remains a standard practice in modern NLP systems, both in shallow and deep architectures [Goldberg, 2015]. By encoding information about words in a relatively simple algebraic structure [Arora et al., 2016] they enable fast transfer to the task of interest1. The importance of word representation learning has lead to developing multiple algorithms, but lack of principled evaluation hinders moving the field forward, which motivates developing more principled ways of evaluating word representations. Word embeddings are not only hard to evaluate, but also challenging to train. Recent practice shows that one often needs to tune algorithm, corpus and hyperparameters towards the target task [Lai et al., 2016, Sharp et al., 2016b], which challenges the promise of broad applicability of unsupervised pretraining. Evaluation methods of word embeddings can be roughly divided into two groups: extrinsic and intrinsic [Schnabel and Labutov, 2015]. In the former approach embeddings are used in a downstream task (eg. POS tagging), while in the latter embeddings are tested directly for preserving syntactic of semantic relations. The most popular intrinsic task is Word Similarity (WS) which evaluates how well dot product between two vectors reproduce score assigned by human annotators. Intrinsic evaluations always assume a very specific model for recovering given property. Despite popularity of word embeddings, there is no clear consensus what evaluation methods should be used, and both intrinsic and downstream evaluations are criticized [Tsvetkov et al., 2015a, Faruqui et al., 2016]. On top of that, different evaluation schemes usually lead to different rankings of embeddings [Schnabel and Labutov, 2015]. For instance, it has been shown [Baroni and Dinu, 2014] that neural-based word embeddings perform consistently better then count-based models and later, using WS and WA tasks, it was argued otherwise [Levy et al., 2015]. Recent research in evaluation methods f","Expanding subjective lexicons for social media mining with embedding subspaces | Linear algebraic structure of word senses, with applications to polysemy | Improving reliability of word similarity evaluation by redesigning annotation task and performance | Representation learning: A review and new perspectives | Multimodal distributional semantics | Intrinsic evaluation of word vectors fails to predict extrinsic performance | Problems With Evaluation of Word Embeddings Using Word Similarity Tasks | Nondistributional word vector representations | Non-distributional word vector representations | Wordrep: A benchmark for research on learning word representations | Domain adaptation for large-scale sentiment classification: A deep learning approach | A Primer on Neural Network Models for Natural Language | Embedding word similarity with neural machine | Simlex999: Evaluating semantic models with (genuine) similarity estimation | Convolutional neural networks for sentence classification | What’s in an embedding? analyzing word embeddings through multilingual evaluation | What’s in an embedding? analyzing word embeddings through multilingual evaluation | How to generate a good word embedding | Neural architectures for named entity recognition | Word embeddings through hellinger pca | the sum of its parts"": Joint learning of word and phrase representations with autoencoders | Large-scale linear ranksvm | Improving distributional similarity with lessons learned from word embeddings | Two/too simple adaptations of word2vec for syntax problems | Better word representations with recursive neural networks for morphology | Evaluating word embeddings using a representative suite of practical tasks | Glove: Global vectors for word representation | Association for Computational Linguistics | Word embedding calculus in meaningful ultradense subspaces. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016 | Sparsifying word representations for deep unordered sentence modeling | Labutov. Evaluation methods for unsupervised word embeddings. In EMNLP, pages 298–307 | Creating causal embeddings for question answering with minimal supervision | Creating causal embeddings for question answering with minimal supervision | Recursive deep models for semantic compositionality over a sentiment treebank | Evaluation of word vector representations by subspace alignment | Evaluation of word vector representations by subspace alignment | Character-level convolutional networks for text classification | A sensitivity analysis of (and practitioners’ guide to) convolutional neural networks for sentence classification",acl,100
251.pdf.json,,"The idea of representing words as vectors has a long history in computational linguistics and machine learning. The general idea is to find a map from words to vectors such that wordsimilarity and vector-similarity are in correspondence. Whilst vector-similarity can be readily quantified in terms of distances and angles, quantifying word-similarity is a more ambiguous task. A key insight in that regard is to posit that the meaning of a word is captured by “the company it keeps” (Firth, 1957) and, therefore, that two words that keep company with similar words are likely to be similar themselves. To break the cyclicality of this definition it is common to consider models that only attempt to capture pairwise cooccurrence statistics1. In the simplest case, one seeks vectors whose similarity approximates the co-occurrence frequencies. In more sophisticated methods cooccurrences are reweighed to suppress the effect of more frequent words (Rohde et al., 2006) and/or to emphasize pairs of words whose co-occurrence frequency maximally deviates from the independence assumption (Church and Hanks, 1990). An alternative to seeking word-embeddings that reflect co-occurrence statistics is to extract the 1Normally, if a is similar to b and b is similar to c, it should be that a is more similar to c than it is to a random word. But pairwise-similarity models do not explicitly require that, i.e., do not penalize model parameters under which a and c are not particularly similar. 2 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 vectorial representation of words from non-linear statistical language models, specifically neural networks. (Bengio","A latent variable model approach to PMI-based word embeddings | Continuous distributed representation of biological sequences for deep proteomics and genomics | A Neural Probabilistic Language Model | Word Association Norms, Mutual Information, and Lexicography | A synopsis of linguistic theory 19301955 | Sufficient Dimensionality Reduction | node2vec: Scalable Feature Learning for Networks | Linguistic Regularities in Sparse and Explicit Word Representations | Efficient Estimation of Word Representations in Vector Space | Distributed Representations of Words and Phrases and their Compositionality | Linguistic regularities in continuous space word representations | Three New Graphical Models for Statistical Language Modelling | GloVe: Global Vectors for Word Representation | Zipf’s word frequency law in natural language: A critical review and future directions | An improved model of semantic similarity based on lexical co-occurence",acl,100
256.pdf.json,Learning Discourse-level Diversity for Neural Dialog Models using Conditional Variational Autoencoders,"The dialog manager is one of the key components of dialog systems, which is responsible for modeling the decision-making process. Specifically, it typically takes a new utterance and the dialog context as input, and generates discourse-level decisions (Bohus and Rudnicky, 2003; Williams and Young, 2007). Advanced dialog managers usually have a list of potential actions that enable them to have diverse behavior during a conversation, e.g. different strategies to recover from non-understanding (Yu et al., 2016). However, the conventional approach of designing a dialog manager (Williams and Young, 2007) does not scale well to open-domain conversation models because of the vast quantity of possible decisions. Thus, there has been a growing interest in applying encoder-decoder models (Sutskever et al., 2014) for modeling open-domain conversation (Vinyals and Le, 2015; Serban et al., 2016a). The basic approach treats a conversation as a transduction task, in which the dialog history is the source sequence and the next response is the target sequence. The model is then trained end-to-end on large conversation corpora using the maximum-likelihood estimation (MLE) objective without the need for manual crafting. However recent research has found that encoder-decoder models tend to generate generic and dull responses (e.g., I don’t know), rather than meaningful and specific answers (Li et al., 2015; Serban et al., 2016b). There have been many attempts to explain and solve this limitation, and they can be broadly divided into two categories (see Section 2 for details): (1) the first category argues that the dialog history is only one of the factors that decide the next response. Other features should be extracted and provided to the models as conditionals in order to generate more specific responses (Xing et al., 2016; Li et al., 2016a); (2) the second category aims to improve the encoder-decoder model itself, including decoding with beam search and its variations (Wiseman and ",Fine-grained analysis of sentence embeddings using auxiliary prediction tasks | Natural language processing with Python | Latent dirichlet allocation | Ravenclaw: Dialog management using hierarchical task decomposition and an expectation agenda | Generating sentences from a continuous space | A systematic comparison of smoothing techniques for sentencelevel bleu | Empirical evaluation of gated recurrent neural networks on sequence modeling | Bootstrapping dialog systems with word embeddings | Switchboard-1 release 2 | Adam: A method for stochastic optimization | Autoencoding variational bayes | A diversity-promoting objective function for neural conversation models | A persona-based neural conversation model | Deep reinforcement learning for dialogue generation | A plan recognition model for subdialogues in conversations | How not to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation | Visualizing data using t-sne | Bleu: a method for automatic evaluation of machine translation | Glove: Global vectors for word representation | Towards an axiomatization of dialogue acts | Lets go public! taking a spoken dialog system to the real world | Stochastic backpropagation and approximate inference in deep generative models | The influence of context on dialogue act recognition | Termweighting approaches in automatic text retrieval | Bidirectional recurrent neural networks | Building end-to-end dialogue systems using generative hierarchical neural network models | A hierarchical latent variable encoder-decoder model for generating dialogues | Learning structured output representation using deep conditional generative models | A neural network approach to context-sensitive generation of conversational responses | Dialogue act modeling for automatic tagging and recognition | Sequence to sequence learning with neural networks | Least squares support vector machine classifiers | A neural conversational model | Partially observable markov decision processes for spoken dialog systems | Sequence-to-sequence learning as beam-search optimization | Topic augmented neural response generation with a joint attention mechanism | Attribute2image: Conditional image generation from visual attributes | Strategy and policy learning for nontask-oriented conversational systems | Recurrent neural network regularization | Towards end-to-end learning for dialog state tracking and management using deep reinforcement learning,acl,100
26.pdf.json,An End-to-End Model for Question Answering over Knowledge Base with Cross-Attention Combining Global Knowledge,"As the amount of the knowledge bases (KBs) grows, people are paying more attention to seeking effective methods for accessing these precious intellectual resources. There are several tailor-made languages designed for querying KBs, such as SPARQL (Prudhommeaux and Seaborne, 2008). However, to handle such query languages, users are required to not only be familiar with the particular language grammars, but also be aware of the architectures of the KBs. By contrast, knowledge base-based question answering (KB-QA) (Unger et al., 2014), which takes natural language as query language, is a more user-friendly solution, and has become a research focus in recent years. Given natural language questions, the goal of KB-QA is to automatically return answers from the KB. There are two mainstream research directions for this task: semantic parsing-based (SPbased) (Zettlemoyer and Collins, 2009, 2012; Kwiatkowski et al., 2013; Cai and Yates, 2013; Berant et al., 2013; Yih et al., 2015, 2016; Reddy et al., 2016) and information retrieval-based (IR-based) (Yao and Van Durme, 2014; Bordes et al., 2014a,b, 2015; Dong et al., 2015; Xu et al., 2016a,b) methods. SP-based methods usually focus on constructing a semantic parser that could convert natural language questions into structured expressions like logical forms. IR-based methods usually search answers from the KB based on the information conveyed in questions, where ranking techniques are often adopted to make correct selections from candidate answers. Recently, with the progress of deep learning, neural network-based (NN-based) methods have been introduced to the KB-QA task (Bordes et al., 2014b). They belong to IR-based methods. Different from previous methods, NN-based methods represent both of the questions and the answers as semantic vectors. Then the complex process of KB-QA could be converted into a similarity matching process between an input question and its candidate answers in a semantic space. The candidates with the h",Neural machine translation by jointly learning to align and translate | Semantic parsing on freebase from question-answer pairs | Freebase: a collaboratively created graph database for structuring human knowledge | Question answering with subgraph embeddings | Large-scale simple question answering with memory networks | Translating embeddings for modeling multirelational data | Open question answering with weakly supervised embedding models | Large-scale semantic parsing via schema matching and lexicon extension | Question answering over freebase with multicolumn convolutional neural networks | Transitionbased dependency parsing with stack long shortterm memory | Identifying relations for open information extraction | Teaching machines to read and comprehend | Long short-term memory | Scaling semantic parsers with on-the-fly ontology matching | Sparql query language for rdf | Transforming dependency structures to logical forms for semantic parsing | A neural attention model for abstractive sentence summarization | End-to-end memory networks. In Advances in neural information processing systems | Sequence to sequence learning with neural networks | An introduction to question answering over linked data | Hybrid question answering over knowledge base and free text | Question answering on freebase via relation extraction and textual evidence | Joint relational embeddings for knowledge-based question answering | Information extraction over structured data: Question answering with freebase | Semantic parsing via staged query graph generation: Question answering with knowledge base | Semantic parsing for single-relation question answering | The value of semantic parse labeling for knowledge base question answering | Simple question answering by attentive convolutional neural network | Learning context-dependent mappings from sentences to logical form | Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars,acl,100
266.pdf.json,Improving sentiment classification with task-specific data,"Sentiment analysis techniques requiring only word embeddings as features have proven to be successful (Socher et al., 2013; Tang et al., 2014; Iyyer et al., 2015). Research has also shown the importance of properly initializing the word embeddings, either through careful manipulation of the initialization of random vectors, or more commonly by pretraining the word embeddings (Kim, 2014). The content of the corpora used to train these word embeddings, however, has not been examined in depth. Most research tends toward using larger and larger datasets in order to build high-quality word embeddings, with some studies using corpora on the magnitude of several billion tokens (Mikolov et al., 2013; Pennington et al., 2014). This amount of data, however, is not available in all languages, nor is it necessarily an optimal use of available re- sources. In fact, there is evidence suggesting that tailoring a dataset for a task can achieve better results with less data (Suster et al., 2016; Barnes et al., 2016). The subjectivity or polarity content of a corpus could provide a good clue to the quality of word embeddings created for the task of sentiment analysis. Pang and Lee (2004) showed that using a pipeline technique where they first classified subjectivity before classifying polarity, they were able to achieve better results than performing classification without filtering subjective sentences. Therefore, we attempt to use subjectivity as a metric for the appropriateness of a corpus for our task. In this work we aim to: • discover if small task-specific datasets can provide better representations of words than large generic datasets for the task of sentiment analysis • quantify the amount of subjectivity in the data in order to predict the appropriateness of a dataset for the task of sentiment analysis. • discover the best way to combine this information for our task, given a large generic dataset and a smaller domain-specific dataset. • extract the subjective information a",OpeNER: Open polarity enhanced named entity recognition | Exploring distributional representations and machine translation for aspect-based cross-lingual sentiment classification | Latent dirichlet allocation | Natural language processing (almost) from scratch | Indexing by latent semantic analysis | Multiun: A multilingual corpus from united nation documents | Retrofitting word vectors to semantic lexicons | Simple task-specific bilingual word embeddings | Deep unordered composition rivals syntactic methods for text classification | Distributed word representations improve ner for e-commerce | Convolutional neural networks for sentence classification | Europarl: A parallel corpus for statistical machine translation | Neural word embedding as implicit matrix factorization | Producing highdimensional semantic spaces from lexical cooccurrence | Learning word vectors for sentiment analysis | The stanford corenlp natural language processing toolkit | Efficient estimation of word | Bilingual learning of multi-sense embeddings with discrete autoencoders | Sentiment embeddings with applications to sentiment analysis | Learning sentimentspecific word embedding for twitter sentiment classification | Opinionfinder: A system for subjectivity analysis | Rc-net: A general framework for incorporating knowledge into word representations | Improving lexical embeddings with semantic knowledge,acl,100
270.pdf.json,Enhanced LSTM for Natural Language Inference,"Reasoning and inference are central to both human and artificial intelligence. Modeling inference in human language is notoriously challenging but is a basic problem towards true natural language understanding, as pointed out by MacCartney and Manning (2008), “a necessary (if not sufficient) condition for true natural language understanding is a mastery of open-domain natural language inference.” The efforts have also included a large bulk of work on recognizing textual entailment. Specifically, natural language inference (NLI) is concerned with determining whether a naturallanguage hypothesis h can be inferred from a premise p, as depicted in the following example from MacCartney (2009), where the hypothesis is regarded to be entailed from the premise. p: Several airlines polled saw costs grow more than expected, even after adjusting for inflation. h: Some of the companies in the poll reported cost increases. The most recent years have seen advances in modeling natural language inference. An important contribution is the creation of a much larger annotated dataset, the Stanford Natural Language Inference (SNLI) dataset (Bowman et al., 2015). The corpus has 570,000 human-written English sentence pairs manually labeled by multiple human subjects. This makes it feasible to train more complex inference models. Neural network models, which often need relatively large annotated data to estimate their parameters, have shown to achieve the state of the art on SNLI (Bowman et al., 2015, 2016; Munkhdalai and Yu, 2016b; Parikh et al., 2016; Sha et al., 2016; Paria et al., 2016). While some previous top-performing models use rather complicated network architectures to achieve the state-of-the-art results (Munkhdalai and Yu, 2016b), we demonstrate in this paper that enhancing sequential inference models based on chain models can outperform all previous results, suggesting that the potential of such sequential inference approaches have not been fully exploited yet. Our model may","Neural machine translation by jointly learning to align and translate | Direct Compositionality | A large annotated corpus for learning natural language inference | A fast unified model for parsing and sentence understanding | Listen, attend and spell: A neural network for large vocabulary conversational speech recognition | Distraction-based neural networks for modeling document | Long short-term memory-networks for machine reading | On the properties of neural machine translation: Encoder-decoder approaches | Attention-based models for speech recognition | The pascal recognising textual entailment challenge | Towards syntax-aware compositional distributional semantic models | Long short-term memory | Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing, Association for Computational Linguistics, chapter Hypothesis Transformation and Semantic Variability Rules | Adam: A method for stochastic optimization | Accurate unlexicalized parsing | Compositional distributional semantics with long short term memory | Learning natural language inference using bidirectional LSTM model and inner-attention | Natural Language Inference | Modeling semantic containment and exclusion in natural language inference | Syntactic/semantic structures for textual entailment recognition | Natural language inference by tree-based convolution and heuristic matching | Neural semantic encoders | Neural tree indexers for text understanding | A neural architecture mimicking humans end-to-end for natural language inference | A decomposable attention model for natural language inference | Glove: Global vectors for word representation | Reasoning about entailment with neural attention | A neural attention model for abstractive sentence summarization | Reading and thinking: Re-read lstm unit for textual entailment recognition | Parsing natural scenes and natural language with recursive neural networks | Improved semantic representations from tree-structured long short-term memory networks | Order-embeddings of images and language | Learning natural language inference with lstm | Show, attend and tell: Neural image caption generation with visual attention | Long short-term memory over recursive structures",acl,100
276.pdf.json,Semi-supervised Multitask Learning for Sequence Labeling,"Accurate and efficient sequence labeling models have a wide range of applications, including named entity recognition (NER), part-of-speech (POS) tagging, error detection and shallow parsing. Specialised approaches to sequence labeling often include extensive feature engineering, such as integrated gazetteers, capitalisation features, morphological information and POS tags. However, recent work has shown that neural network architectures are able to achieve comparable or improved performance, while automatically discovering useful features for a specific task and only requiring a sequence of tokens as input (Collobert et al., 2011; Irsoy and Cardie, 2014; Lample et al., 2016). This feature discovery is usually driven by an objective function based on predicting the annotated labels for each word, without much incentive to learn more general language features from the available text. In many sequence labeling tasks, the relevant labels in the dataset are very sparse and most of the words contribute very little to the training process. For example, in the CoNLL 2003 NER dataset (Tjong Kim Sang and De Meulder, 2003) only 17% of the tokens represent an entity. This ratio is even lower for error detection, with only 14% of all tokens being annotated as an error in the FCE dataset (Yannakoudakis et al., 2011). The sequence labeling models are able to learn this bias in the label distribution without obtaining much additional information from words that have the majority label (O for outside of an entity; C for correct word). Therefore, we propose an additional training objective which allows the models to make more extensive use of the available data. The task of language modeling offers an easily accessible objective – learning to predict the next word in the sequence requires only plain text as input, without relying on any particular annotation. Neural language modeling architectures also have many similarities to common sequence labeling frameworks: words are first ma",Theano: A Python framework for fast computation of mathematical expressions | Multitask Learning | One Billion Word Benchmark for Measuring Progress in Statistical Language Modeling | Open-Domain Name Error Detection using a MultiTask RNN | A Unified Architecture for Natural Language Processing: Deep Neural Networks with Multitask Learning | Natural Language Processing (Almost) from Scratch | Speech recognition with deep recurrent neural networks | Long Short-term Memory | Bidirectional LSTM-CRF Models for Sequence Tagging | Opinion Mining with Deep Recurrent Neural Networks | Introduction to the Bio-entity Recognition Task at JNLPBA | CHEMDNER: The drugs and chemical names extraction challenge | Conditional random fields: Probabilistic models for segmenting and labeling sequence data | Neural Architectures for Named Entity Recognition | Building a large annotated corpus of English: The Penn Treebank | Efficient Estimation of Word Representations in Vector Space | Recurrent Neural Network based Language Model | A fast and simple algorithm for training neural probabilistic language models | Hierarchical probabilistic neural network language model | The CoNLL-2014 Shared Task on Grammatical Error Correction | The GENIA corpus: An annotated research abstract corpus in molecular biology domain | Developing a robust part,acl,100
288.pdf.json,The Effect of Different Writing Tasks on Linguistic Style: A Case Study of the ROC Story Cloze Task,"Writing style is expressed through a range of linguistic elements such as words, sentence structure, and rhetorical devices. It is influenced by personal factors such as age and gender (Schler et al., 2006), by personality traits such as agreeableness and openness (Ireland and Mehl, 2014), as well as by mental states such as sentiment (Davidov et al., 2010), sarcasm (Tsur et al., 2010), and deception (Feng et al., 2012). In this paper, we study the extent to which writing style is affected by the nature of the writing task the writer was asked to perform, since different tasks likely engage different cognitive processes (Campbell and Pennebaker, 2003; Banerjee et al., 2014). We show that similar writing tasks with different constraints on the author can lead to measurable differences in her writing style. As a case study, we present experiments based on the recently introduced ROC story cloze task (Mostafazadeh et al., 2016a). In this task, authors were asked to write five-sentence self-contained stories, henceforth original stories. Then, each original story was given to a different author, who was shown only the first four sentences as a story context, and asked to write two contrasting story endings: a right (coherent) ending, and a wrong 2 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 (incoherent) ending. Framed as a story cloze task, the goal of this dataset is to serve as a commonsense challenge for NLP and AI research. Table 1 shows an example of an original story, a coherent story, and an incoherent story. While the story cloze task was originally designed to be a story understanding challenge, its annotation proce","Gender, genre, and writing style in formal written texts | Gender identity and lexical variation in social media | Keystroke patterns as prosody in digital writings: A case study with deceptive reviews and essays | Stylometric analysis of scientific articles | Language style matching in romantic partners? conflict and support interactions | A large annotated corpus for learning natural language inference | Statistical affect detection in collaborative chat | Families on facebook | The secret life of pronouns flexibility in writing style and physical health | A thorough examination of the CNN/Daily Mail reading comprehension task | Enhanced sentiment learning using twitter hashtags and smileys | Syntactic stylometry for deception detection | Experimental disclosure and its moderators: a meta-analysis | Language style matching as a predictor of social dynamics in small groups | On lying and being lied to: A linguistic analysis of deception in computer-mediated communication | Teaching machines to read and comprehend | Long short-term memory | Language style matching, engagement, and impasse in negotiations | Natural language use as a marker of personality, Oxford University Press, USA, pages 201–237 | Language style matching predicts relationship initiation and stability | Adam: A method for stochastic optimization | Computational methods in authorship attribution | Determining an author’s native language by mining a text for errors | The writing cure: How expressive writing promotes health and emotional well-being | The winograd schema challenge | Recurrent neural network based language model | A corpus and cloze evaluation for deeper understanding of commonsense stories | 2016b. Story cloze evaluator: Vector space representation evaluation by predicting what happens next | Inference in an authorship problem | Lying words: Predicting deception from linguistic styles | how old do you think i am?” a study of language and age in twitter | Author age prediction from text using linear regression | Finding deceptive opinion spam by any stretch of the imagination | The lambada dataset: Word prediction | Scikit-learn: Machine learning in Python | Linguistic styles: language use as an individual difference | Words of wisdom: language use over the life span | Cross-cultural deception detection | Gender differences in deceivers writing style | An exploratory study on promising cues in deception detection and application of decision tree | Squad: 100,000+ questions for machine comprehension of text | Age prediction in blogs: A study of style, content, and online behavior in pre- and postsocial media generations | Enhancing the lexvec distributed word representation model using positional contexts and external memory | Effects of age and gender on blogging | Authorship attribution of micro-messages | Conceptnet 5.5: An open multilingual graph of general knowledge | A survey of modern authorship attribution methods | Linguistic analysis of workplace computer-mediated communication | Icwsm-a great catchy name: Semi-supervised recognition of sarcastic sentences in online product reviews | Using classifier features for studying the effect of native language on the choice of written second language words | Towards ai-complete question answering: A set of prerequisite toy tasks | Automatic detection of deception in child-produced speech using syntactic complexity features | Textual predictors of bill survival in congressional committees",acl,100
31.pdf.json,Event Factuality Identification via Deep Neural Networks,"Event factuality is the information expressing the commitment of relevant sources towards the factual nature of events. That is, event factuality conveys whether an event is characterized as a fact, a certain possibility, or an impossible situation, and thus is helpful for various NLP applications, e.g., opinion detection (Wiebe et al., 2005), QA (Pustejovsky et al., 2005), textual entailment (de Marneffe et al., 2006; Hickl and Bensley, 2007), rumor identification (Qazvinian et al., 2011). In principle, the value of event factuality is related to some elements, e.g., predicates, speculative and negative cues. Consider following sentences as examples1: (S1) McCulley, a famous economist, doubts that the tax rate will increase soon. (S2) He knows they are not able to go to the village due to the flood. In sentence S1, the event increase is a possibility according to the predicate doubts, while in 1In this paper, events are in bold and sources are underlined in example sentences. S2, the event go is regarded as an impossible situation due to the negation word not. From these sentences, we can learn that predicates and cues can determine the event factuality to a great degree. Such event factuality provides the way to distinguish fact events from speculative and negative ones. Traditional methods for event factuality identification usually employed either hand-crafted rules (Saurı́, 2008; Saurı́ and Pustejovsky, 2012) relying on expert knowledge, or features (Prabhakaran et al., 2010; de Marneffe et al., 2012) relying on various kinds of annotated information, such as source introducing predicates, predicate classes, speculative and negative cues. Due to the recent success of deep learning on various NLP tasks in learning useful representations from ordinary sentences (Socher et al., 2012; Zeng et al., 2014; Cheng et al., 2016) and syntactic paths (Xu et al., 2015a,b; Roth and Lapata, 2016) and the attention mechanism on capturing the focus change in sequence modeling (","Navytime: Event and time ordering from raw text | Neural sentiment classification with user and product attention | Long short-term memory-networks for machine reading | Learning to distinguish valid textual entailments | Did it happen? the pragmatic complexity of veridicality assessment | Committed belief annotation and tagging | A discourse commitment-based framework for recognizing textual entailment | Long short-term memory | Foundations of statistical natural language processing | Distributed representations of words and phrases and their compositionality | Syntactic scope resolution in uncertainty analysis | Automatic committed belief tagging | Timeml: Robust specification of event and temporal expressions in text | The timebank corpus | Temporal and event information in natural language text | Rumor has it: Identifying misinformation in microblogs | Neural semantic role labeling with dependency path embeddings | A Factuality Profiler for Eventualities in Text | Factbank: a corpus annotated with event factuality. Language Resources and Evaluation 43(3):227–268 | Are you sure that this happened? assessing the factuality degree of events in text. Computational Linguistics 38(2):1–39 | Semantic compositionality through recursive matrix-vector spaces | Speculation and negation: Rules, rankers, and the role of syntax | Relation classification via multi-level attention cnns | Annotating expressions of opinions and emotions in language | Semantic relation classification via convolutional neural networks with simple negative sampling | Classifying relations via long short term memory networks along shortest dependency paths | Relation classification via convolutional deep neural network | End-to-end learning of semantic role labeling using recurrent neural networks | Attentionbased bidirectional long short-term memory networks for relation classification",acl,100
318.pdf.json,Improved Word Representation Learning with Sememes,"Sememes are defined as minimum semantic units of word meanings, and there exists a limited close set of sememes to compose the semantic meanings of an open set of concepts (i.e. word sense). However, sememes are not explicit for each word. Hence, people manually annotate word sememes and build linguistic common-sense knowledge bases. HowNet (Dong and Dong, 2003) is one of such knowledge bases, which annotates each concepts in Chinese with one or more relevant sememes. Different from WordNet (Miller, 1995), the philosophy of HowNet emphasizes the significance of part and attribute represented by sememes. HowNet has been widely utilized in word similarity computation (Liu and Li, 2002) and sentiment analysis (Xianghua et al., 2013), and in section 3.2 we will give detailed introduction on sememes, senses and words in HowNet. In this paper, we aim to incorporate word sememes into word representation learning (WRL) and learn improved word embeddings in a lowdimensional semantic space. WRL is a fundamental and critical step in many NLP tasks such as language modeling (Bengio et al., 2003) and neural machine translation (Sutskever et al., 2014). There have been a lot of researches for learning word representations, among which word2vec (Mikolov et al., 2013) achieves a nice balance between effectiveness and efficiency. In word2vec, each word corresponds to one single embedding, ignoring the polysemy of most words. To address this issue, (Huang et al., 2012) introduces multiprototype model for WRL, conducting unsupervised word sense induction and embeddings according to context clusters. (Chen et al., 2014) further utilizes the synset information in WordNet to instruct word sense representation learning. From these previous studies we conclude that, word sense disambiguation are critical for WRL, and we believe that the sememe annotation of word senses in HowNet can provide essential semantic regularization for the both tasks. To explore its feasibility, we propose a novel",Neural machine translation by jointly learning to align and translate | An adapted lesk algorithm for word sense disambiguation using wordnet | A neural probabilistic language model | Learning structured embeddings of knowledge bases | A fast and accurate dependency parser using neural networks | A unified model for word sense representation and disambiguation | Joint learning of character and word embeddings | Hownet-a hybrid language and knowledge resource | Learning sense-specific word embeddings by exploiting bilingual resources | Improving word representations via global context and multiple word prototypes | Ontologically grounded multi-sense representation learning for semantic vector space models | Supervised word sense disambiguation with support vector machines and multiple knowledge sources | Word similarity computing based on how-net | Efficient estimation of word representations in vector space | Recurrent neural network based language model | Wordnet: a lexical database for english | Efficient nonparametric estimation of multiple embeddings per word in vector space | Glove: Global vectors for word representation | De-conflated semantic representations | Autoextend: Extending word embeddings to embeddings for synsets and lexemes | Learning representations by backpropagating errors | Sequence to sequence learning with neural networks | A probabilistic model for learning multi-prototype word embeddings | Multi-aspect sentiment analysis for chinese online social reviews based on topic modeling and hownet lexicon | Character-level convolutional networks for text classification,acl,100
323.pdf.json,A Neural Local Coherence Model,"What distinguishes a coherent text from a random sequence of sentences is that it binds the sentences together to express a meaning as a whole — the interpretation of a sentence usually depends on the meaning of its neighbors. Coherence models that can distinguish a coherent from incoherent texts have a wide range of applications in text generation, summarization, and coherence scoring. Several formal theories of coherence have been proposed (Mann and Thompson, 1988a; Grosz et al., 1995; Asher and Lascarides, 2003), and their principles have inspired development of existing coherence models (Barzilay and Lapata, 2008; Lin et al., 2011; Li and Hovy, 2014). Among these models, the entity grid (Barzilay and Lapata, 2008), which is based on Centering Theory (Grosz et al., 1995), is arguably the most popular, and has seen a number of improvements over the years. As shown in Figure 2, the entity grid model represents a text by a grid that captures how grammatical roles of different entities change from sentence to sentence. The grid is then converted into a feature vector containing probabilities of local entity transitions, which enables machine learning models to learn the degree of text coherence. Extensions of this basic grid model incorporate entity-specific features (Elsner and Charniak, 2011), multiple ranks (Feng and Hirst, 2012), and coherence relations (Feng et al., 2014). While the entity grid and its extensions have been successful in many applications, they are limited in several ways. Firstly, they use discrete representation for grammatical roles and features, which limits the model to consider sufficiently long transitions (Bengio et al., 2003). Secondly, feature vector computation in existing models is decoupled from the target task, which limits the models to learn task-specific features. In this paper, we propose a neural architecture for coherence assessment that can capture long range entity transitions along with arbitrary entityspecific features. Ou","Modeling local coherence: An entity-based approach | Modeling local coherence: An entity-based approach | A neural probabilistic language model | Using entity-based features to model coherence in student essays | Natural language processing (almost) from scratch | Coreference-inspired coherence modeling | Extending the entity grid with entity-specific features | Extending the entity-based coherence model with multiple ranks | The impact of deep hierarchical discourse structures in the evaluation of text coherence | Extending the entity-grid coherence model to semantically related entities | Understanding the difficulty of training deep feedforward neural networks | Centering: A framework for modeling the local coherence of discourse | Graph-based local coherence modeling | Optimizing search engines using clickthrough data | A convolutional neural network for modelling sentences | Convolutional neural networks for sentence classification | Adam: A method for stochastic optimization | A model of coherence based on distributed sentence representation | Recursive deep models for discourse parsing | Automatically evaluating text coherence using discourse relations | Discourse generation using utility-trained coherence models | Dropout: A simple way to prevent neural networks from overfitting | Theano: A Python framework for fast computation of mathematical expressions | RMSprop, COURSERA: Neural Networks | ADADELTA: an adaptive learning rate method",acl,100
326.pdf.json,,"Chinese word segmentation (CWS) is a preliminary and important task for Chinese natural language processing (NLP). Currently, the state-ofthe-art methods are based on statistical supervised learning algorithms (Xue, 2003; Zhao et al., 2006), and rely on a large-scale annotated corpus whose cost is extremely expensive. Although there have been great achievements in building CWS corpora, they are somewhat incompatible due to different segmentation criteria. As shown in Table 1, given a sentence “姚明进入总决赛 (YaoMing reaches the final)”, the two commonly-used corpora, PKU’s People’s Daily (PKU) (Yu et al., 2001) and Penn Chinese Treebank (CTB) (Xia, 2000), use different segmentation criteria. In a sense, it is a waste of resources if we fail to fully exploit these corpora. Recently, some efforts have been made to exploit heterogeneous annotation data for Chinese word segmentation or part-of-speech tagging Corpora Yao Ming reaches the final CTB 姚明 进入 总决赛 PKU 姚 明 进入 总 决赛 (Jiang et al., 2009; Sun and Wan, 2012; Qiu et al., 2013; Li et al., 2015). These methods adopted stacking or multi-task architectures and showed that heterogeneous corpora can help each other. However, most of these model adopt the shallow linear classifier with discrete features, which makes it difficult to design the shared feature spaces, usually resulting in a complex model. Fortunately, recent deep neural models provide a convenient way to share information among multiple tasks (Collobert and Weston, 2008; Luong et al., 2015; Chen et al., 2016). In this paper, we propose an adversarial multicriteria learning for CWS by integrating shared knowledge from multiple segmentation criteria. Specifically, we regard each segmentation criterion as a single task and propose three different shared-private models under the framework of multi-task learning (Caruana, 1997; Ben-David and Schuller, 2003), where a shared layer is used to extract the criteria-invariant features, and a private layer is used to extract the","Domain-adversarial neural networks | Exploiting task relatedness for multiple task learning | Domain separation networks | Neural word segmentation learning for chinese | Multitask learning | Exploiting heterogeneous annotations for weibo word segmentation and pos tagging | Neural network for heterogeneous annotations | Long short-term memory neural networks for chinese word segmentation | A unified architecture for natural language processing: Deep neural networks with multitask learning | Adaptive subgradient methods for online learning and stochastic optimization | The second international chinese word segmentation bakeoff | Domain-adversarial training of neural networks | Generative adversarial nets | Generating sequences with recurrent neural networks | Bidirectional lstm-crf models for sequence tagging | Automatic adaptation of annotation standards: Chinese word segmentation and POS tagging: a case study | The fourth international chinese language processing bakeoff: Chinese word segmentation, named entity recognition and chinese pos tagging | An empirical exploration of recurrent network architectures | Conditional random fields: Probabilistic models for segmenting and labeling sequence data | Coupled sequence labeling on heterogeneous annotations: Pos tagging as a case study | Multi-task sequence to sequence learning | Accurate linear-time chinese word segmentation via embedding matching | End-to-end sequence labeling via bi-directional lstm-cnns-crf | Efficient estimation of word representations in vector space | Maxmargin tensor neural network for chinese word segmentation | Joint chinese word segmentation and pos tagging on heterogeneous annotated corpora with multiple task learning | Reducing approximation and estimation errors for chinese lexical processing with heterogeneous annotations | The part-of-speech tagging guidelines for the penn Chinese treebank (3.0) | Dependency-based gated recursive neural network for chinese word segmentation | Chinese word segmentation as character tagging | Bi-directional lstm recurrent neural network for chinese word segmentation | Processing norms of modern Chinese corpus | Transition-based neural word segmentation | An improved chinese word segmentation system with conditional random field | Deep learning for chinese word segmentation and pos tagging",acl,100
33.pdf.json,Linguistically Regularized LSTM for Sentiment Classification,"Sentiment classification aims to classify text to sentiment classes such as positive or negative, or more fine-grained classes such as very positive, positive, neutral, etc. There has been a variety of approaches for this purpose such as lexicon-based classification (Turney, 2002; Taboada et al., 2011), and early machine learning based methods (Pang et al., 2002; Pang and Lee, 2005), and recently neural network models such as convolutional neural network (CNN) (Kim, 2014; Kalchbrenner et al., 2014; Lei et al., 2015), recursive autoencoders (Socher et al., 2011, 2013), Long ShortTerm Memory (LSTM) (Mikolov, 2012; Chung et al., 2014; Tai et al., 2015; Zhu et al., 2015), and many more. In spite of the great success of these neural models, there are some defects in previous studies. First, tree-structured models such as recursive autoencoders and Tree-LSTM (Tai et al., 2015; Zhu et al., 2015), depend on parsing tree structures and expensive phrase-level annotation, whose performance drops substantially when only trained with sentence-level annotation. Second, linguistic knowledge such as sentiment lexicon, negation words or negators (e.g., not, never), and intensity words or intensifiers (e.g., very, absolutely), has not been fully employed in neural models. The goal of this research is to developing simple sequence models but also attempts to fully employing linguistic resources to benefit sentiment classification. Firstly, we attempts to develop simple models that do not depend on parsing trees and do not require phrase-level annotation which is too expensive in real-world applications. Secondly, in order to obtain competitive performance, simple models can benefit from linguistic resources. Three types of resources will be addressed in this paper: sentiment lexicon, negation words, and intensity words. Sentiment lexicon offers the prior polarity of a word which can be useful in determining the sentiment polarity of longer texts such as phrases and sentences. Negators","How do negation and modality impact on opinions | Building sentiment lexicons for all major languages | Learning phrase representations using rnn encoder-decoder for statistical machine translation | Empirical evaluation of gated recurrent neural networks on sequence modeling | A statistical parsing framework for sentiment classification | Adaptive multi-compositionality for recursive neural models with applications to sentiment analysis | Neural networks for negation scope detection | Hybrid speech recognition with deep bidirectional lstm | Long short-term memory | Mining and summarizing customer reviews | Deep unordered composition rivals syntactic methods for text classification | The effect of negation on sentiment analysis and retrieval effectiveness | A convolutional neural network for modelling sentences | Sentiment classification of movie reviews using contextual valence shifters | Convolutional neural networks for sentence classification | Representing and resolving negation for sentiment analysis | Molding cnns for text: non-linear, non-consecutive convolutions | Review sentiment scoring via a parse-and-paraphrase paradigm | Distributional semantic models for affective text analysis | Statistical language models based on neural networks | Simple negation scope resolution through deep parsing: A semantic solution to a semantic problem | Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales | Opinion mining and sentiment analysis | Thumbs up?: sentiment classification using machine learning techniques | Contextual valence shifters | Learning tag embeddings and tag-specific composition functions in recursive neural network | Adjective intensity and sentiment analysis | Corpus-based discovery of semantic intensity scales | Semi-supervised recursive autoencoders for predicting sentiment distributions | Recursive deep models for semantic compositionality over a sentiment treebank | Lexicon-based methods for sentiment analysis. Computational linguistics 37(2):267–307 | Improved semantic representations from tree-structured long short-term memory networks | Context-sensitive lexicon features for neural sentiment analysis | Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of reviews | Dont count, predict! an automatic approach to learning sentiment lexicons for short text | Ecnu at semeval-2016 task 7: An enhanced supervised learning method for lexicon sentiment intensity ranking | A regression approach to affective rating of chinese words from anew | A survey on the role of negation in sentiment analysis | Recognizing contextual polarity in phraselevel sentiment analysis | An empirical study on the effect of negation words on sentiment | Long short-term memory over recursive structures | Tree kernel-based negation and speculation scope detection with structured syntactic parse features",acl,100
331.pdf.json,Connecting the dots: Summarizing and Structuring Large Document Collections Using Concept Maps,"Multi-document summarization (MDS), the transformation of a set of documents into a short text containing their most important aspects, is a longstudied problem in NLP. Generated summaries have been shown to support humans dealing with large document collections in information seeking tasks (McKeown et al., 2005; Maña-López et al., 2004; Roussinov and Chen, 2001). However, when exploring a set of documents manually, humans rarely write a fully-formulated summary for themselves. Instead, user studies (Chin et al., 2009; Kang et al., 2011) show that they note down important keywords and phrases, try to identify relationships between them and organize them accordingly. Therefore, we believe that the study of summarization with similarly structured outputs is an important extension of the traditional task. ACL 2017 long papers substantial research invites submissions of must describe Concept Relation Proposition Figure 1: Elements of a concept map. A representation more in line with observed user behavior is a concept map (Novak and Gowin, 1984). Concept maps are labeled graphs showing concepts as nodes and relationships between them as edges (Figure 1). Labels can be freely defined. A concept can be an entity, abstract idea, event or activity, designated by a unique label. Good maps should be propositionally coherent, meaning that every relation together with the two connected concepts form a meaningful proposition. Introduced in 1972 as a teaching tool (Novak and Cañas, 2007), applications in education (Edwards and Fraser, 1983; Roy, 2008), for writing assistance (Villalon, 2012) or to structure information repositories (Briggs et al., 2004; Richardson and Fox, 2005) have been reported. For summarization, concept maps allow to represent a summary concisely and clearly reveal relations. Moreover, we see a second interesting use case beyond the capabilities of textual summaries: When concepts and relations are linked to corresponding locations in the documents, the g","Open Information Extraction from the Web | Comparing Rating Scales and Preference Judgements in Language Evaluation | Bridging the gap between extractive and abstractive summaries: Creation and evaluation of coherent extracts from heterogeneous sources | Freebase | Concept Maps Applied to Mars Exploration Public Outreach | Pairwise Ranking Aggregation in a Crowdsourced Setting | Exploring the analytical processes of intelligence analysts | Overview of the TAC 2008 Update Summarization Task | Meteor Universal: Language Specific Translation Evaluation for Any Target Language | 2016. A Proposition | Concept Maps Core Ele | The Measurement of Observer Agreement for Categorical Data | Abstractive Multi-document Summarization with Semantic Information Extraction | Abstractive News Summarization based on Event Semantic Link Network | ROUGE: A Package for Automatic Evaluation of Summaries | Toward Abstractive Summarization Using Semantic Representations | Analyzing the capabilities of crowdsourcing services for text summarization | Multidocument summarization: An added value to clustering in interactive retrieval | Do summaries help? A Task-Based Evaluation of Multi-Document Summarization | Construction of Text Summarization Corpus for the Credibility of Information on the Web | Automatic Summarization | Theoretical Origins of Concept Maps, How to Construct Them, and Uses in Education | Learning How to Learn | Align, Disambiguate and Walk: A Unified Approach for Measuring Semantic Similarity | Concept map construction from text documents using affinity propagation | Knowledge discovery from texts: A Concept Frame Graph Approach | Using concept maps as a cross-language resource discovery tool for large documents in digital libraries | Information navigation on the web by clustering and summarizing query results | Using Concept Maps for Information Conceptualization and Schematization in Technical Reading and Writing Courses: A Case Study for Computer Science Majors in Japan | Corpus Annotation through Crowdsourcing: Towards Best Practice Guidelines | Cheap and Fast – But is it Good? Evaluating Non-Expert Annotations for Natural Language Tasks | Creating a Large Benchmark for Open Information Extraction | JumpStarting Concept Map Construction with Knowledge Extracted from Documents | Automated Generation of Concept Maps to Support Writing | Analysis of a Gold Standard for Concept Map Mining - How Humans Summarize Text Using Concept Maps | Crowdsourced Top-k Algorithms: An Experimental Evaluation | The Next Step for Multi-Document Summarization: A Heterogeneous Multi-Genre Corpus Built with a Novel Construction Approach | Ontologizing concept maps using graph theory | Evaluating the Generation of Domain Ontologies in the Knowledge Puzzle Project | Implementation of method for generating concept map from unstructured text in the Croatian language",acl,100
333.pdf.json,Selective Encoding for Abstractive Sentence Summarization,"Sentence summarization aims to shorten a given sentence and produce a brief summary of it. This is different from document level summarization task since it is hard to apply existing techniques in extractive methods, such as extracting sentence level features and ranking sentences. Early works propose using rule-based methods (Zajic et al., 2007), syntactic tree pruning methods (Knight and Marcu, 2002), statistical machine translation techniques (Banko et al., 2000) and so on for this task. We focus on abstractive sentence summarization task in this paper. Recently, neural network models have been applied in this task. Rush et al. (2015) use autoconstructed sentence-headline pairs to train a neural network summarization model. They use a Convolutional Neural Network (CNN) encoder and feed-forward neural network language model decoder for this task. Chopra et al. (2016) extend their work by replacing the decoder with Recurrent Neural Network (RNN). Nallapati et al. (2016) follow this line and change the encoder to RNN to make it a full RNN based sequence-tosequence model (Sutskever et al., 2014). All the above works fall into the encodingdecoding paradigm, which first encodes the input sentence to an abstract representation and then decodes the intended output sentence based on the encoded information. As an extension of the encoding-decoding framework, attentionbased approach (Bahdanau et al., 2015) has been broadly used: the encoder produces a list of vectors for all tokens in the input, and the decoder uses an attention mechanism to dynamically extract encoded information and align with the output tokens. This approach achieves huge success in tasks like neural machine translation, where alignment between all parts of the input and output are required. However, in abstractive sentence summarization, there is no explicit alignment relationship between input sentence and the summary except for the extracted common words. The 2 101 102 103 104 105 106 107 108 109 110",Neural headline generation with minimum risk training | Neural machine translation by jointly learning to align and translate | Headline generation based on statistical translation | A neural probabilistic language model | Neural summarization by extracting sentences and words | Learning phrase representations using rnn encoder–decoder for statistical machine translation | Abstractive sentence summarization with attentive recurrent neural networks | Hedge trimmer: A parse-and-trim approach to headline generation | Understanding the difficulty of training deep feedforward neural networks | Maxout networks | Incorporating copying mechanism | Pointing the unknown words | Adam: A method for stochastic optimization | Summarization beyond sentence extraction: A probabilistic approach to sentence compression | Visualizing and understanding neural models in nlp | Rouge: A package for automatic evaluation of summaries | Effective approaches to attention-based neural machine translation | Abstractive text summarization using sequence-to-sequence rnns and beyond | Annotated gigaword | Duc in context | On the difficulty of training recurrent neural networks | A neural attention model for abstractive sentence summarization | Minimum risk training for neural machine translation | Dropout: a simple way to prevent neural networks from overfitting | Sequence to sequence learning with neural networks | A dataset and evaluation metrics for abstractive compression of sentences and short paragraphs | Online segment to segment neural transduction | Multi-candidate reduction: Sentence compression as a tool for document summarization tasks | Efficient summarization with read-again and copy mechanism,acl,100
335.pdf.json,Gated Self-Matching Networks for Reading Comprehension and Question Answering,"In this paper, we focus on reading comprehension style question answering which aims to answer questions given a passage or document. We specifically focus on the Stanford Question Answering Dataset (SQuAD) (Rajpurkar et al., 2016), a largescale dataset for reading comprehension and question answering which is manually created through crowdsourcing. SQuAD constrains answers to the space of all possible spans within the reference passage, which is different from cloze-style reading comprehension datasets (Hermann et al., 1On Feb. 6, 2017 2015; Hill et al., 2016) in which answers are single words or entities. Moreover, SQuAD requires different forms of logical reasoning to infer the answer (Rajpurkar et al., 2016). Rapid progress has been made since the release of the SQuAD dataset. Wang and Jiang (2016b) build question-aware passage representation with match-LSTM (Wang and Jiang, 2016a), and predict answer boundaries in the passage with pointer networks (Vinyals et al., 2015). Seo et al. (2016) introduce bi-directional attention flow networks to model question-passage pairs at multiple levels of granularity. Xiong et al. (2016) propose dynamic co-attention networks which attend the question and passage simultaneously and iteratively refine answer predictions. Lee et al. (2016) and Yu et al. (2016) predict answers by ranking continuous text spans within passages. Inspired by Wang and Jiang (2016b), we introduce a gated self-matching network, illustrated in Figure 1, an end-to-end neural network model for reading comprehension and question answering. Our model consists of four parts: 1) the recurrent network encoder to build representation for questions and passages separately, 2) the gated matching layer to match the question and passage, 3) the self-matching layer to aggregate information from the whole passage, and 4) the pointernetwork based answer boundary prediction layer. The key contributions of this work are three-fold. First, we propose a gated attention-base","Neural machine translation by jointly learning to align and translate | Modeling biological processes for reading comprehension | A thorough examination of the cnn/daily mail reading comprehension task | Long short-term memory-networks for machine reading | Learning phrase representations using RNN encoder-decoder for statistical machine translation | Attention-overattention neural networks for reading comprehension | Gated-attention readers for text comprehension | Teaching machines to read and comprehend | The goldilocks principle: Reading children’s books with explicit memory representations | Long short-term memory | Text understanding with the attention sum reader network | Learning recurrent span representations for extractive question answering | Not all contexts are created equal: Better word representations with variable attention | The stanford corenlp natural language processing toolkit | Recurrent neural network based language model | MS MARCO: A human generated machine reading comprehension dataset | A decomposable attention model for natural language inference | Glove: Global vectors for word representation | Qatar, A meeting of SIGDAT, a Special Interest Group of the ACL | Squad: 100,000+ questions for machine comprehension of text | Mctest: A challenge dataset for the open-domain machine comprehension of text | Reasoning about entailment with neural attention | Bidirectional attention flow for machine comprehension | Reasonet: Learning to stop reading in machine comprehension | Iterative alternating neural attention for machine reading | Dropout: a simple way to prevent neural networks from overfitting | Natural language comprehension with the epireader | Pointer networks | Learning natural language inference with LSTM | Machine comprehension using match-lstm and answer pointer | Multi-perspective context matching for machine comprehension | Dynamic coattention networks for question answering | Wikiqa: A challenge dataset for open-domain question answering | Words or characters? fine-grained gating for reading comprehension | End-to-end reading comprehension with dynamic answer chunk ranking | ADADELTA: an adaptive learning rate method",acl,100
338.pdf.json,Handling Cold-Start Problem in Review Spam Detection by Jointly Embedding Texts and Behaviors,"With the rapid growth of products reviews at the web, it has become common for people to read reviews before making purchase decision. The reviews usually contain abundant consumers’ personal experiences. It has led to a significant influence on financial gains and fame for businesses. Existing studies have shown that an extra halfstar rating on Yelp causes restaurants to sell out 19% points more frequently (Anderson and Magruder, 2012), and a one-star increase in Yelp rating leads to a 5-9 % increase in revenue (Luca, 2011). This, unfortunately, gives strong incentives for imposters (called spammers) to game the system. They post fake reviews or opinions (called review spam) to promote or to discredit some targeted products and services. The news from BBC has shown that around 25% of Yelp reviews could be fake.1 Therefore, it is urgent to detect review s- 1http://www.bbc.com/news/technology-24299742 pam, to ensure that the online review continues to be trusted. Jindal and Liu (2008) make the first step to detect review spam. Most efforts are devoted to explore effective linguistic and behavioral features by subsequent work to distinguish such spam from the real reviews. However, to notice such patterns or form behavioral features, developers should take long time to observe the data, because the features are based on statistics. For instance, the feature activity window proposed by Mukherjee et al. (2013c) is to measure the activity freshness of reviewers. It usually takes several months to count the difference of timestamps between the last and first reviews for reviewers. When the features show themselves finally, some major damages might have already been done. Thus, it is important to design algorithms that can detect review spam as soon as possible, ideally, right after they are posted by the new reviewers. It is a coldstart problem which is the focus of this paper. In this paper, we assume that we must identify fake reviews immediately when a new reviewer pos","Distributional footprints of deceptive | Detecting deceptive opinion spam using human computation | The enemy in your own camp: How well can we detect statisticallygenerated fake reviews–an adversarial study | Opinion spam and analysis | Finding unusual review patterns using unexpected rules | On the temporal dynamics of opinion spamming: Case studies on yelp | Deep semantic frame-based deceptive opinion spam analysis | Learning to identify review spam | Analyzing and detecting opinion spam on a large-scale dataset via temporal and spatial patterns | Spotting fake reviews using positive-unlabeled learning | Topicspam: a topic-model based approach for spam detection | A persona-based neural conversation model | Towards a general rule for identifying deceptive opinion spam | Detecting product review spammers using rating behaviors | Sentiment Analysis: Mining Opinions, Sentiments, and Emotions | Reviews, reputation, and revenue: The case of yelp | Distributed representations of words and phrases and their compositionality | Spotting opinion spammers using behavioral footprints | Improving gender classification of blog authors | Spotting fake reviewer groups in consumer reviews | Fake review detection: Classification and analysis of real and pseudo reviews | What yelp fake review filter might be doing? In ICWSM | Lying words: Predicting deception from linguistic styles | Finding deceptive opinion spam by any stretch of the imagination | The development and psychometric properties of liwc2007 | Collective opinion spam detection: Bridging review networks and metadata | Deceptive opinion spam detection using neural network | Recursive deep models for semantic compositionality over a sentiment treebank | Review graph based online store review spammer detection | Learning to represent review with tensor decomposition for spam detection | Review spam detection via temporal pattern discovery | Using deep linguistic features for finding deceptive opinion spam",acl,100
343.pdf.json,,"There has been a recent shift of research attention in the word segmentation literature from statistical methods to deep learning (Zheng et al., 2013; Pei et al., 2014; Morita et al., 2015; Chen et al., 2015b; Cai and Zhao, 2016; Zhang et al., 2016). Neural network models have been exploited due to their strength in non-sparse representation learning and non-linear power in feature combination, which have led to advances in many NLP tasks. So far, neural word segmentors have given comparable accuracies to the best statictical models. With respect to non-sparse representation, character embeddings have been exploited as a foundation of neural word segmentors. They serve to reduce sparsity of character ngrams, allowing, for example, “猫(cat)躺(lie)在(in)墙角(corner)” to be connected with “狗(dog) 蹲(sit) 在(in) 墙 角(corner)” (Zheng et al., 2013), which is infeasible by using sparse one-hot character features. In addition to character embeddings, distributed representations of character bigrams (Mansur et al., 2013; Pei et al., 2014) and words (Morita et al., 2015; Zhang et al., 2016) have also been shown to improve segmentation accuracies. With respect to non-linear modeling power, various network structures have been exploited to represent contexts for segmentation disambiguation, including multi-layer perceptrons on fivecharacter windows (Zheng et al., 2013; Mansur et al., 2013; Pei et al., 2014; Chen et al., 2015a), as well as LSTMs on characters (Chen et al., 2015b; Xu and Sun, 2016) and words (Morita et al., 2015; Cai and Zhao, 2016; Zhang et al., 2016). For structured learning and inference, CRF has been used for character sequence labelling models (Pei et al., 2014; Chen et al., 2015b) and structural beam search has been used for word-based segmentors (Cai and Zhao, 2016; Zhang et al., 2016). Previous research has shown that segmentation accuracies can be improved by pretraining character and word embeddings over large Chinese texts, which is consistent with findings on",Globally normalized transition-based neural networks | Practical recommendations for gradient-based training of deep architectures | Neural word segmentation learning for chinese | Gated recursive neural network for chinese word segmentation | Long short-term memory neural networks for chinese word segmentation | Incremental parsing with the perceptron algorithm | Natural language processing (almost) from scratch | Adaptive subgradient methods for online learning and stochastic optimization | The second international chinese word segmentation bakeoff | Recurrent nets that time and count | Automatic adaptation of annotation standards: Chinese word segmentation and pos tagging: a case study | Punctuation as implicit annotations for chinese word segmentation | Unsupervised domain adaptation for joint segmentation and pos-tagging | Feature-based neural language model and chinese word segmentation | Morphological analysis for unsegmented languages using recurrent neural network language model | Chinese part-ofspeech tagging: One-at-a-time or all-at-once? wordbased or character-based? In EMNLP | Maxmargin tensor neural network for chinese word segmentation | Chinese segmentation and new word detection using conditional random fields | Overview of the nlpcc-iccpol 2016 shared task: Chinese word segmentation for micro-blog texts | Profiting from mark-up: Hyper-text annotations for guided parsing | A stochastic finite-state wordsegmentation algorithm for chinese | Dropout: a simple way to prevent neural networks from overfitting | Word-based and character-based word segmentation models: Comparison and combination | Exploring representations from unlabeled data with co-training for chinese word segmentation | Character-level chinese dependency parsing | Transition-based neural word segmentation | Subword-based tagging by conditional random fields for chinese word segmentation | Chinese segmentation with a word-based perceptron algorithm | Joint word segmentation and pos tagging using a single perceptron | Syntactic processing using the generalized perceptron and beam search | Effective tag set selection in chinese word segmentation via conditional random field modeling | Deep learning for chinese word segmentation and pos tagging | A neural probabilistic structuredprediction model for transition-based dependency parsing,acl,100
350.pdf.json,,"Event Extraction (EE), a challenging task in Information Extraction, aims at detecting and typing events (Event Detection), and extracting arguments with different roles (Argument Identification) from natural-language texts. For example, in the sentence shown in Figure 1, an EE system is expected to identify an Attack event triggered by threw and extract the corresponding five augments with different roles: Yesterday (Role=Time), demonstrators (Role=Attacker), stones (Role=Instrument), soldiers (Role=Target), and Israeli (Role=Place). To this end, so far most methods (Nguyen et al., 2016; Chen et al., 2015; Li et al., 2014; Hong et al., 2011; Ji and Grishman, 2008) usually adopted supervised learning paradigm which relies on elaborate human-annotated data, such as ACE 20051, to train extractors. Although this paradigm was widely studied, existing approaches still suffer from high costs for manually labeling training data and low coverage of predefined event types. In ACE 2005, all 33 event types are manually predefined and the corresponding event information (including triggers, event types, arguments and their roles) are manually annotated only in 599 English documents since the annotation process is extremely expensive. As Figure 2 shown, nearly 60% of event types in ACE 2005 have less than 100 labeled samples and there are even three event types which have less than ten labeled samples. Moreover, those predefined 33 event types are in low coverage for Natural Language Processing (NLP) applications on large-scale data. Therefore, for extracting large scale events, especially in open domain scenarios, how to automatically and efficiently generate sufficient training data is an important problem. This paper aims to automatically generate training data for EE, which involves labeling triggers, event types, arguments and their roles. Figure 1 shows an example of labeled sentence. Recent improvements of Distant Supervision (DS) have been proven to be effective to label",The stages of event extraction | The berkeley framenet project | Semantic parsing on freebase from question-answer pairs | Freebase: a collaboratively created graph database for structuring human knowledge | Template-based information extraction without the templates | Event extraction via dynamic multi-pooling convolutional neural networks | Probabilistic frame induction | Improving neural networks by preventing coadaptation of feature detectors | Knowledge-based weak supervision for information | Large-scale learning of relation | Leveraging framenet to im | Event extraction as dependency parsing | Distant supervision for relation extraction without labeled data | Event detection and domain adaptation with convolutional neural networks | Joint event extraction via recurrent neural networks | Event extraction using distant supervision | Multi-instance multi-label learning for relation extraction | Word representations: A simple and general method for semi-supervised learning | Relation classification via multi-level attention cnns | Adadelta: An adaptive learning rate method | Distant supervision for relation extraction via piecewise convolutional neural networks,acl,100
352.pdf.json,,"Multi-task learning is an effective approach to improve the performance of a single task with the help of other related tasks. Recently, neuralbased models for multi-task learning have become very popular, ranging from computer vision (Misra et al., 2016; Zhang et al., 2014) to natural language processing (Collobert and Weston, 2008; Luong et al., 2015), since they provide a convenient way of combining information frommultiple tasks. However, most existing work on multi-task learning attempts to divide the features of different tasks into private and shared spaces, merely based on whether parameters of some components should be shared. As shown in Figure 1- (a), the general shared-private model introduces two feature spaces for any task: one is used to store task-dependent features, the other is used to capture shared features. The major limitation of this framework is that the shared feature space could contain some unnecessary task-specific features, while some sharable features could also be mixed in private space, suffering from feature redundancy. Taking the following two sentences as examples, which are extracted from two different sentiment classification tasks: Movie reviews and Baby products reviews. The infantile cart is simple and easy to use. This kind of humour is infantile and boring. The word “infantile” indicates negative sentiment in Movie task while it is neutral in Baby task. However, the general shared-private model could place the task-specific word “infantile” in a shared space, leaving potential hazards for other tasks. Additionally, the capacity of shared space could also be wasted by some unnecessary features. To address this problem, in this paper we propose an adversarial multi-task framework, in which the shared and private feature spaces are inherently disjoint by introducing orthogonality constraints. Specifically, we design a generic sharedprivate learning framework to model the text se- 2 101 102 103 104 105 106 107 108 109 110 111 11","Domain-adversarial neural networks | A theory of learning from different domains | Analysis of representations for domain adaptation. Advances in neural information processing systems 19:137 | Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification | Domain separation networks | Adversarial deep averaging networks for cross-lingual sentiment classification | Empirical evaluation of gated recurrent neural networks on sequence modeling | A unified architecture for natural language processing: Deep neural networks with multitask learning | Natural language processing (almost) from scratch | Finding structure in time | Unsupervised domain adaptation by backpropagation | Domain adaptation for large-scale sentiment classification: A deep learning approach | Generative adversarial nets | Generating sequences with recurrent neural networks | Long short-term memory | Factorized latent spaces with structured sparsity | An empirical exploration of recurrent network architectures | A convolutional neural network for modelling sentences | Recurrent neural network for text classification with multi-task learning | Representation learning using multi-task deep neural networks for semantic classification and information retrieval | Multi-task sequence to sequence learning | Learning word vectors for sentiment analysis | Cross-stitch networks for multi-task learning | Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales | Image-text multi-modal representation learning by adversarial backpropagation | Glove: Global vectors for word representation | Factorized orthogonal latent spaces | Recursive deep models for semantic compositionality over a sentiment treebank | Sequence to sequence learning with neural networks | Unsupervised cross-domain image generation | Facial landmark detection by deep multi-task learning",acl,100
355.pdf.json,Neural Modeling of Multi-Predicate Interactions for Japanese Predicate Argument Structure Analysis,"Predicate argument structure (PAS) analysis is a basic semantic analysis task, in which systems are required to identify semantic units of a sentence, such as who did what to whom. In pro-drop languages such as Japanese, Chinese and Italian, arguments are often omitted in text, and such argument omission is regarded as one of the most problematic issues of PAS analysis (Iida and Poesio, 2011; Sasano and Kurohashi, 2011). As an approach to the argument omission problem, in Japanese PAS analysis, joint modeling of interactions between multiple predicates has been gaining popularity and achieved the state-of-theart result (Ouchi et al., 2015; Shibata et al., 2016). This approach is based on the linguistic intuition that the predicates in a sentence are semantically related to each other and the interaction information can be a clue for PAS analysis. However, to model such multi-predicate interactions, this ap- proach heavily relies on syntactic information predicted by parsers and suffers from the error propagation caused by the pipeline processing. To remedy this problem, we propose a neural model which automatically induces features sensitive to multi-predicate interactions from word sequence information of a sentence. This model takes as input all predicates and their argument candidates in a sentence at a time, and captures the interactions using grid-type recurrent neural networks (Grid-RNN) without syntactic information. In this paper, we firstly introduce a basic model using RNNs, which independently estimates arguments of each predicate without considering the multi-predicate interactions (Sec. 3). Then, extending this model, we propose a neural model using Grid-RNNs (Sec. 4). Performing experiments on the NAIST Text Corpus (Iida et al., 2007), we demonstrate that our neural models exceed the accuracy of the stateof-the-art Japanese PAS analyzer (Ouchi et al., 2015). In particular, the neural model using GridRNNs achieves the best result, which suggests that ou",Theano: new features and speed improvements | Introduction to the conll-2005 shared task: Semantic role labeling | Learning phrase representations using rnn encoder–decoder for statistical machine translation | Natural language processing (almost) from scratch | Hybrid speech recognition with deep bidirectional lstm | Bidirectional lstm networks for improved phoneme classification and recognition | Offline handwriting recognition with multidimensional recurrent neural networks | Japanese predicate argument structure analysis exploiting argument position and type | Deep residual learning for image recognition | Anaphora resolution by antecedent identification followed by anaphoricity determination | Annotating a japanese text corpus with predicate-argument and coreference relations | A cross-lingual ilp solution to zero anaphora resolution | Intrasentential zero anaphora resolution using subject sharing recognition | Intrasentential subject zero anaphora resolution using multi-column convolutional neural network | Discriminative approach to predicateargument structure analysis with zero-anaphora resolution | Grid long short-term memory | Adam: A method for stochastic optimization | Joint case argument identification for japanese predicate argument structure analysis | On the difficulty of training recurrent neural networks | A discriminative approach to japanese zero anaphora resolution with large-scale lexicalized case frames | Bidirectional recurrent neural networks | Neural network-based model for japanese predicate argument structure analysis | A japanese predicate argument structure analysis using decision lists | Multipredicate semantic role labeling | Jointly extracting japanese predicate-argument relation with markov logic | End-to-end learning of semantic role labeling using recurrent neural networks,acl,100
365.pdf.json,Learning attention for historical text normalization by learning to pronounce,"There is a growing interest in automated processing of historical documents, as evidenced by the growing field of digital humanities and the increasing number of digitally available collections of historical documents. A common approach to deal with the high amount of variance often found in this type of data is to perform spelling normalization (Piotrowski, 2012), which is the mapping of historical spelling variants to standardized/modernized forms (e.g. vnd→ und ‘and’). Training data for supervised learning of historical text normalization is typically scarce. On the other hand, neural networks are said to work best when trained on large amounts of data. It is therefore not clear whether neural networks are a good choice for this particular task. We explore framing the spelling normalization task as a character-based sequence-to-sequence transduction problem, and use encoder–decoder recurrent neural networks (RNNs) to induce our transduction models. This is similar to models that have been proposed for neural machine translation (e.g., Cho et al. (2014)), so essentially, our approach could also be considered a form of character-based neural machine translation. By basing our model on individual characters as input, we keep the vocabulary size small, which in turn reduces the model’s complexity and the amount of data required to train it effectively. Using an encoder–decoder architecture removes the need for an explicit character alignment between historical and modern wordforms. Furthermore, we explore using an auxiliary task for which data is more readily available, namely grapheme-tophoneme mapping (word pronunciation), to regularize the induction of the normalization models. We propose several architectures, including multi-task learning architectures taking advantage of the auxiliary data, and evaluate them across 44 small datasets from Early New High German. Contributions Our contributions are as follows: • We are, to the best of our knowledge, the first to p","Normalizing historical orthography for OCR historical documents using LSTM | The CELEX lexical database (Release 2) (CD-ROM) | VARD 2: A tool for dealing with spelling variation in historical corpora | Semi-)automatic normalization of historical texts using distance measures and the Norma tool | Automatic normalization for linguistic annotation of historical language data | Improving historical spelling normalization with bidirectional lstms and multi-task learning | Multitask learning: A knowledge-based source of inductive bias | Multitask learning | On the properties of neural machine translation: Encoder–decoder approaches | Keras | The Anselm corpus: Methods and perspectives of a parallel aligned corpus | Long short-term memory | Adam: A method for stochastic optimization | Guidelines for normalizing historical German texts | Visualizing and understanding neural models in nlp | Normalising Slovene data: historical texts vs | Visualizing data using t-SNE | An SMT approach to automatic annotation of historical text | Natural Language Processing for Historical Texts | Edit transducers for spelling variation in Old Spanish | Modernizing historical Slovene words with character-based SMT | Automatic normalisation of the Swiss German ArchiMob corpus using character-level machine translation | Sequence to sequence learning with neural networks | An open diachronic corpus of historical Spanish: annotation criteria and automatic modernisation of spelling | Evaluating the pairwise string alignment of pronunciations | Show, attend and tell: Neural image caption generation with visual attention",acl,100
367.pdf.json,,"Automatic evaluation measures, such as BLEU (Papineni et al., 2002), are used with increasing frequency to evaluate Natural Language Generation (NLG) systems: Up to 60% of NLG research published between 2012–2015 relies on automatic metrics (Gkatzia and Mahamood, 2015). Automatic evaluation is popular because it is cheaper and faster to run than human evaluation, and is needed for automatic benchmarking and tuning of algorithms. The use of such metrics is, however, only sensible if they are known to be sufficiently correlated with human preferences. This is rarely the case, as shown by various studies in NLG (Reiter and Belz, 2009; Belz and Reiter, 2006; Stent et al., 2005), as well as in related fields, such as dialogue systems (Liu et al., 2016), machine translation (MT), e.g. (Callison-Burch et al., 2006), and image captioning, e.g. (Elliott and Keller, 2014; Kilickaya et al., 2017). This paper follows on from this work and presents another evaluation study into automatic metrics with the aim to firmly establish the need for new metrics. We also suggest an alternative metric, which we call RAINBOW to reflect the diverse set of features it is based upon. In contrast to previous work, we are the first to: • Target end-to-end data-driven NLG, where we compare 3 different approaches. In contrast to NLG methods evaluated in previous work, our systems can produce ungrammatical output by (1) generating word-by-word, and (2) learning from noisy data. • Compare a large number of 21 automated metrics, including grammar-based ones. • Report results on two different domains and three different datasets, which allows us to draw more general conclusions. • Suggest an alternative automatic metric, which shows high correlation with human judgements. • Conduct a detailed error analysis, which suggests that, while metrics can be reasonable indicators at the system-level, they are not reliable at the sentence-level. •Make all associated code and data publicly available, including d","Discrete vs | Comparing automatic and human evaluation of NLG systems | Results of the WMT16 Metrics Shared Task | Re-evaluating the role of BLEU in machine translation research | Automatic evaluation of machine translation quality using n-gram cooccurrence statistics | Training a natural language generator from unaligned data | A contextaware natural language generator for dialogue systems | Sequenceto-sequence generation for spoken dialogue via deep syntax trees and strings | Comparing automatic evaluation measures for image description | How to write plain English: A book for lawyers and consumers | Recent Advances in Automatic Readability Assessment and Text Simplification, volume | deltaBLEU: A discriminative metric for generation tasks with intrinsically diverse targets | A smorgasbord of features for automatic MT evaluation | Natural language generation enhances human decision-making with uncertain information | A snapshot of NLG evaluation practices 2005–2014 | METEOR: An automatic metric for MT evaluation with high levels of correlation with human judgments | Learning to decode for future success | ROUGE: A package for automatic evaluation of summaries | How NOT to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation | Phrase-based statistical language generation using graphical models and active learning | What to talk about and how? Selective generation using LSTMs with coarse-tofine alignment | There’s no comparison: Reference-less evaluation metrics in grammatical error correction | Crowd-sourcing NLG data: Pictures elicit better data | BLEU: a method for automatic evaluation of machine translation | An investigation into the validity of some metrics for automatically evaluating natural language generation systems | Natural language generation as incremental planning under uncertainty: Adaptive information presentation for statistical dialogue systems | Natural language generation in dialogue using lexicalized and delexicalized data | A study of translation edit rate with targeted human annotation | Machine translation evaluation versus quality estimation | Evaluating evaluation methods for generation in the presence of variation | CIDEr: Consensusbased image description evaluation | Multidomain neural network language generation for spoken dialogue systems | Semantically conditioned LSTM-based natural language generation for spoken dialogue systems | Regression analysis | CASICT-DCU participation in WMT2015 Metrics Task",acl,100
369.pdf.json,Morphology Generation for Statistical Machine Translation using Deep Learning Techniques,"Machine Translation (MT) is evolving from different perspectives. One of the most popular paradigms is still Statistical Machine Translation (SMT), which consists in finding the most probable target sentence given the source sentence using probabilistic models based on co-ocurrences. Recently, deep learning techniques applied to natural language processing, speech recognition and image processing and even in MT have reached quite successful results. Early stages of deep learning applied to MT include using neural language modeling for rescoring (Schwenk et al., 2007). Later, deep learning has been integrated in MT in many different steps (Zhand and Zong, 2015). Nowadays, deep learning has allowed to develop an entire new paradigm, which within one-year of development has achieved state-of-the-art results (Jean et al., 2015) for some language pairs. In this paper, we are focusing on a challenging translation task, which is Chinese-to-Spanish. This translation task has the characteristic that we are going from an isolated language in terms of morphology (Chinese) to a fusional language (Spanish). This means that for a simple word in Chinese (e.g. 鼓励 ), the corresponding translation has many different morphology inflexions (e.g. alentar, alienta, alentamos, alientan ...), which depend on the context. It is still difficult for MT in general (no matter which paradigm) to extract information from the source context to give the correct translation. We propose to divide the problem of translation into translation and then a postprocessing of morphology generation. This has been done before, e.g. (Toutanova et al., 2008; Formiga et al., 2013), as we will review in the next section. However, the main contribution of our work is that we are using deep learning techniques in morphology generation. This gives us significant improvements in translation quality. The rest of the paper is organised as follows. Section 2 describes the related work both in morphology generation approa",Meteor: An automatic metric for mt evaluation with improved correlation with human judgments | Random forests | Evaluation Of The Bible As A Resource For Cross-language Informatio n Retrieval | Combining morpheme-based machine translation with postprocessing morpheme prediction | Natural language processing (almost) from scratch | Supportvector networks | Description of the chinese-to-spanish rule-based machine translation system developed using a hybrid combination of human annotation and statistical techniques | Evaluating indirect strategies for chinese-spanish statistical machine translation | Chinese-spanish neural machine translation enhanced with character and word bitmap fonts | Ongoing study for enhancing chinese-spanish translation with morphology strategies | Neocognitron: A selforganizing neural network model for a mechanism of pattern recognition unaffected by shift in position | Svmtool: A general pos tagger generator based on support vector machines | Long short-term memory | Montreal neural machine translation systems for wmt15 | Rich morphology generation using statistical machine translation | Statistical Phrase-Based Translation | Overview of the iwslt 2008 evaluation campaign | United Nations General Assembly Resolutions: A SixLanguage Parallel Corpus | Smooth bilingual ngram translation | Sequence to sequence learning with neural networks | Multilingual spoken language corpus development for communicatio n research | Applying morphology generation models to machine translation | Finding the k shortest loopless paths in a network | Deep neural networks in machine translation: An overview | The united nations parallel corpus v1.0,acl,100
37.pdf.json,Sequential Matching Network: A New Architecture for Multi-turn Response Selection in Retrieval-based Chatbots,"Conversational agents include task-oriented dialog systems and non-task-oriented chatbots. Dialog systems focus on helping people complete specific tasks in vertical domains (Young et al., 2010), while chatbots aim to naturally and meaningfully converse with humans on open domain topics (Ritter et al., 2011). Existing work on building chatbots includes generation based methods and retrieval based methods. Retrieval based chatbots enjoy the advantage of informative and fluent responses, because they select a proper response for the current conversation from a repository with re- sponse selection algorithms. While most existing work on retrieval based chatbots studies response selection for single-turn conversation (Wang et al., 2013) which only considers the last input message, we consider the problem in a multi-turn scenario. In a chatbot, multi-turn response selection takes a message and utterances in its previous turns as input and selects a response that is natural and relevant to the whole context. The key to response selection lies in inputresponse matching. Different from single-turn conversation, multi-turn conversation requires matching between a response and a conversation context in which one needs to consider not only the matching between the response and the input message but also the matching between the response and the utterances in previous turns. The challenges of the task include (1) how to identify important information (words, phrases, and sentences) in the context that is crucial to selecting a proper response and how to leverage the information in matching; and (2) how to model relationships among the utterances in the context. Table 1 illustrates the challenges with an example. First, “hold a drum class” and “drum” in the context are very important. Without them, one may find responses relevant to the message (i.e., the last turn of the context) but nonsense in the context (e.g., “what lessons do you want?”). Second, 2 101 102 103 104 105 106 ","Modern information retrieval, volume 463 | Empirical evaluation of gated recurrent neural networks on sequence modeling | Measuring nominal scale agreement among many raters | Towards an open-domain conversational system fully based on natural language | Convolutional neural network architectures for matching natural language sentences | An information retrieval approach to short text conversation | Improved deep learning baselines for ubuntu corpus dialogs | Adam: A method for stochastic optimization | A diversity-promoting objective function for neural conversation models | A persona-based neural conversation model | The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems | Distributed representations of words and phrases and their compositionality | Data-driven response generation in social media | Building end-to-end dialogue systems using generative hierarchical neural network models | Multiresolution recurrent neural networks: An application to dialogue response generation | A hierarchical latent variable encoder-decoder model for generating dialogues | Neural responding machine for short-text conversation | Reasoning with neural tensor networks for knowledge base completion | Lstmbased deep learning models for non-factoid answer selection | Theano: A Python framework for fast computation of mathematical expressions | A neural conversational model | The trec-8 question answering track report | Match-srnn: Modeling the recursive matching structure with spatial rnn | A dataset for research on short-text conversations | Syntax-based deep matching of short texts | Learning natural language inference with lstm | Ranking responses oriented to conversational relevance in chat-bots | Topic augmented neural network for short text conversation | Topic augmented neural response generation with a joint attention mechanism | Incorporating loose-structured knowledge into lstm with recall gate for conversation modeling | Learning to respond with deep neural networks for retrieval-based human-computer conversation system | Hierarchical attention networks for document classification | The hidden information state model: A practical framework for pomdp-based spoken dialogue management | Multiview response selection for human-computer conversation",acl,100
371.pdf.json,,"There are latent nest structures beyond sequential surface words in natural language (Chomsky, 1957). In the last two decades, researchers incorporated more and more rich structural information into conventional language model (Jelinek and Lafferty, 1991; Chelba, 1997; Chelba and Jelinek, 2000; Emami and Jelinek, 2005) and more recently on neural network-based language modeling (Dyer et al., 2016). Among the effort, one direction is to explore sub-word structures(Costa-Jussà and Fonollosa, 2016; Chung et al., 2016; Luong and Manning, 2016; Sennrich et al., 2015), such as characters, mostly to handle out-of-vocabulary word problem. A somewhat opposite direction is to explore hyper-word structure. For example, (Eriguchi et al., 2016) adopts parsing tree in encoder phase in machine translation, (Stahlberg et al., 2016) proposes to use hierarchical phrase-based (HPB) model to guide the search in decoding. Both models, however, rely heavily on human labeled data on the language structures, which is extremely expensive and limited in scale. In this paper, we propose phrasal recurrent neural networks (pRNNs; §2), a general framework of RNNs (Elman, 1990) that explicitly models task-specific nested phrases from plain text. Here we use “phrase” as its definition in phrase-based statistical machine translation (PBSMT(Zens et al., 2002; Koehn et al., 2003)), which indicates any continues sequences of words. What different here are pRNNs permit phrases with arbitrary lengths instead of limiting them for the computational issue. The phrases in pRNNs are composed and selected in a way that is jointly learned in the language modeling, therefore requiring no human-labeled data or external model such as word alignment. In previous RNN-based language modeling, the hidden state of RNN before the word to predict summarizes the history of all previous words. Similarly, in pRNNs, we use the all state of all parallel RNNs (with the same parameters) to capture the history of all subsequen",Neural Machine Translation by Jointly Learning to Align and Translate | The Mathematics of Statistical Machine Translation : Parameter Estimation | Generative Incremental Dependency Parsing with Neural Networks | A Structured Language Model | Structured language modeling | A Hierarchical PhraseBased Model for Statistical Machine Translation | Syntactic structures | A Character-level Decoder without Explicit Segmentation for Neural Machine Translation | Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling | Character-based Neural Machine Translation | Handwritten Digit Recognition with a Back-Propagation Network | Recurrent Neural Network Grammars | Finding structure in time | A Neural Syntactic Language Model | Tree-to-Sequence Attentional Neural Machine Translation | Scalable inference and training of context-rich syntactic translation models | Discriminative Training of a Neural Network Statistical Parser | Distributed representations | Improving neural networks by preventing co-adaptation of feature detectors | Statistical syntax-directed translation with extended domain of locality | Computation of the Probability of Initial Substring Generation by Stochastic Context-Free Grammars | Statistical phrase-based translation | Treeto-String Alignment Template for Statistical Machine Translation | Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models | Effective Approaches to Attentionbased Neural Machine Translation | Addressing the Rare Word Problem in Neural Machine Translation | Building a large annotated corpus of English : the Penn Treebank | Neural Transformation Machine: {A} New Architecture for Sequence-to-Sequence Learning | Forest-based Translation Rule Extraction | Forest-Based Translation | Recurrent neural network based language model | BLEU : a Method for Automatic Evaluation of Machine Translation | Neural Machine Translation of Rare Words with Subword Units | Syntactically Guided Neural Machine Translation | Sequence to Sequence Learning with Neural Networks | A Latent Variable Model for Generative Dependency Parsing | Blocks and Fuel: Frameworks for deep learning | A Novel Dependency-to-String Model for Statistical Machine Translation | Recurrent Neural Network Regularization | ADADELTA: An Adaptive Learning Rate Method | Phrase-Based Statistical Machine Translation,acl,100
375.pdf.json,CANE: Context-Aware Network Embedding for Relation Modeling,"Network embedding (NE), i.e., network representation learning (NRL), aims to map vertices of a network into a low-dimensional space according to their structural roles in the network. NE provides an efficient and effective way to represent and manage large-scale networks, alleviating the computation and sparsity issues of conventional symbol-based representations. Hence, NE is attracting many research interests in recent years (Perozzi et al., 2014; Tang et al., 2015; Grover and Leskovec, 2016), and achieves promising performance on many network analysis tasks including link prediction, vertex classification, and community detection. In real-world social networks, it is intuitive that one vertex may demonstrate various aspects when interacting with different neighbor vertices. For example, a researcher usually collaborates with different partners on diverse research topics (as illustrated in Fig. 1), a social-media user contacts with various friends sharing distinct interests, and a web page links with multiple pages for different purposes. However, most existing NE methods only arrange one single embedding vector to each vertex, and give rise to the following two invertible issues: (1) These methods cannot cope with the aspect transition of a vertex flexibly when interacting with different neighbors. (2) In these models, a vertex tends to force the embeddings of its neighbors close to each other, which may be not case all the time. For example, the left user and right user in Fig. 1, share less common interests, but are learned to be close to each other since they both link to the middle person. This will accordingly 2 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 ","A convolutional neural network for modelling sentences | Grarep: Learning graph representations with global structural information | Incorporate group information to enhance network embedding | Learning phrase representations using rnn encoder-decoder for statistical machine translation | Liblinear: A library for large linear classification | Node2vec: Scalable feature learning for networks | The meaning and use of the area under a receiver operating characteristic (roc) curve | Convolutional neural network architectures for matching natural language sentences | Effective use of word order for text categorization with convolutional neural networks | Convolutional neural networks for sentence classification | Adam: A method for stochastic optimization | Skip-thought vectors | Graphs over time: densification laws, shrinking diameters and possible explanations | Automating the construction of internet portals with machine learning | Efficient estimation of word representations in vector space | Distributed representations of words and phrases and their compositionality | Deepwalk: Online learning of social representations | Bidirectional recurrent neural networks | A general framework for content-enhanced network representation learning | Improved semantic representations from tree-structured long short-term memory networks | Line: Large-scale information network embedding | Relational learning via latent social dimensions | Max-margin deepwalk: Discriminative learning of network representation | Structural deep network embedding | Network representation learning with rich text information",acl,100
376.pdf.json,"Event-based, Recursive Neural Networks for the Extraction and Aggregation of International Alliance Relations","Information and communication technologies have provided tools and methods to make the production of information more democratic. As a result, a vast amount of content is available, which arguably creates more noise than knowledge at the end of the day. Without hierarchical organization and contextualization, users may lack perspective to understand and assimilate the multiplicity of events that they come accross every day, and to link them to related events in the past. In this context, we need tools for extracting, aggregating and visualizing knowledge in order to facilitate information analysis and access a variety of points of view. In this article, we take the example of the geopolitical alliances and their evolution; we extract relations from the texts and aggregate them in order to turn a set of very focused pieces of information into a broader knowledge and a bigger picture of a given situation. The main contributions of this paper are: • Relation extraction: we present an eventbased, recursive neural network approach for identifying alliance and opposition relations between countries, at sentence level, in English. We show that adapting the models to the eventive nature of extracted relations helps existing recursive neural models. We use a precision-oriented cost function for a better later aggregation. • Relation aggregation: we aggregate the sentence-level relations in a multi-document environment, in order to obtain a picture of the geopolitical situation and evolution on a specific subject defined by a user query (e.g., situation in Syria, nuclear proliferation, North Pole ownership). We cope with the inevitable amount of noise to produce reliable numerical data from texts.","A hierarchical O(N log N) force-calculation algorithm | Theano: new features and speed improvements | Automatic Extraction of Events from Open Source Text for Predictive Forecasting | Identifying Political Sentiment between Nation States with Social Media | Web Question Answering: Is More Always Better | Applications of Latent Variable Models in Modeling Influence and Decision Making | Learning Topics and Positions from Debatepedia | Simple Customization of Recursive Neural Networks for Semantic Relation Classification | Long short-term memory | Modeling dependencies in international relations networks | Mining and Summarizing Customer Reviews | Relational Features in Fine-Grained Opinion Analysis | A Convolutional Neural Network for Modelling Sentences | Finding Salient Dates for Building Thematic Timelines | Accurate Unlexicalized Parsing | Apache Solr 4 Cookbook | DBpedia - A Large-scale, Multilingual Knowledge Base | When Are Tree Structures Necessary for Deep Learning of Representations | Sentiment Analysis and Opinion Mining | Is It the Right Answer? Exploiting Web Redundancy for Answer Validation | AskMSR: Question Answering Using the Worldwide Web | Distributed Representations of Words and Phrases and their Compositionality | WordNet: a lexical database for English | Classifying relations by ranking with convolutional neural networks | Learning to Extract International Relations from Political Context | The CAMEO (Conflict and Mediation Event Observations) Actor Coding Framework | Automated Coding of Very Large Scale Political Event Data | Semantic Compositionality through Recursive Matrix-Vector Spaces | Grounded Compositional Semantics for Finding and Describing Images with Sentences | Semi-supervised Recursive Autoencoders for Predicting Sentiment Distributions | Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank | Thumbs Up or Thumbs Down? Semantic Orientation Applied to Unsupervised Classification of Reviews | Classifying relations via long short term memory networks along shortest dependency paths | Joint Inference for Fine-grained Opinion Extraction | Information Extraction from the Web: Techniques and Applications | Relation classification via convolutional deep neural network",acl,100
382.pdf.json,Creating Training Corpora for NLG Micro-Planning,"To train Natural Language Generation (NLG) systems, various input-text corpora have been developed which associate (numerical, formal, linguistic) input with text. As discussed in detail in Section 2, these corpora can be classified into three main types namely, (i) domain specific corpora, (ii) benchmarks constructed from “Expert” Linguistic Annotations and (iii) crowdsourced benchmarks1. 1We ignore here (Lebret et al., 2016)’s dataset which was created fully automatically from Wikipedia by associating infoboxes with text because this dataset fails to ensure an In this paper, we focus on how to create datato-text corpora which can support the learning of wide-coverage micro-planners i.e., generation systems that handles such NLG subtasks as lexicalisation (mapping data to words), aggregation (exploiting linguistic constructs such as ellipsis and coordination to avoid repetition), surface realisation (using the appropriate syntactic constructs to build sentences), sentence segmentation and referring expression generation. We start by reviewing the main existing types of NLG benchmarks and we argue for a crowdsourcing approach where data units are automatically built from an existing knowledge base and where text is crowdsourced from the data (Section 2). We then propose a generic framework for semiautomatically creating training corpora for NLG (Section 3) from existing Knowledge Bases. In Section 4, we apply this framework to DBpedia data and we compare the resulting dataset with (Wen et al., 2016)’s using various metrics to evaluate the linguistic and computational adequacy of both datasets. By applying these metrics, we show that while (Wen et al., 2016)’s dataset is more than twice larger than ours, it is less diverse both in terms of input and in terms of text. We also compare the performance of a sequence-to-sequence model (Vinyals et al., 2015) on both datasets to estimate the complexity of the learning task induced by each dataset. We show that the performan",Abstract meaning representation (AMR) 1.0 specification | The KBGen challenge | The First Surface Realisation Shared Task: Overview and Evaluation Results | Learning to sportscast: a test of grounded language acquisition | Imitation learning for language generation from unaligned data | Neural Text Generation from Structured Data with Application to the Biography Domain | Learning Semantic Correspondences with Less Supervision | The relationship of lexical richness to the quality of ESL learners’ oral narratives | DBpedia: A Multilingual Cross-domain Knowledge Base | The aNALoGuE Challenge: Non Aligned Language | BLEU: a Method for Automatic Evaluation of Machine Translation | Building RDF Content for Data-to-Text Generation | Trainable methods for surface natural language generation | Grammar as a foreign language | Multidomain Neural Network Language Generation for Spoken Dialogue Systems | Semantically conditioned lstm-based natural language generation for spoken dialogue systems,acl,100
384.pdf.json,Identifying 1950s American Jazz Composers: Fine-Grained IsA Extraction via Modifier Composition,"Substantial attention has been paid to automatically acquiring taxonomic knowledge, like that “Charles Mingus” is a “composer”, from text (Snow et al., 2006; Shwartz et al., 2016). The majority of approaches for extracting such “IsA” relations rely on lexical patterns as the primary signal of whether an instance belongs to a class: for example, observing a pattern like “X such as Y” is a strong indication that Y is an instance of class X (Hearst, 1992). Methods based on these “Hearst patterns” assume that class labels can be treated as atomic lexicalized units. This assumption has several significant weakness. First, in order to recognize an instance of a class, these patternbased methods require that the entire class label be observed verbatim in text. The requirement is reasonable for class labels containing a single word, but in practice, there are many possible fine-grained classes: not only “composers” but also “1950s American jazz composers”. The probability that a given label will appear in its entirety within one of the expected patterns is very low, even in large amounts of text. Second, when class labels are treated as though they cannot be decomposed, every class label must be modeled independently, even those containing overlapping words (“American jazz composer”, “French jazz composer”). As a result, the number of meaning representations to be learned is exponential in the length of the class label, and quickly becomes intractable. Thus, compositional models of taxonomic relations are necessary for better language understanding. We introduce a compositional approach for reasoning about fine-grained class labels. Our approach is based on the notion from formal semantics in which modifiers (“1950s”) correspond to properties which differentiate instances of a subclass (“1950s composers”) from instances of the superclass (“composers”) (Heim and Kratzer, 1998). Our method consists of two stages: interpreting each modifier relative to the head (“composers act","Structured learning for taxonomy induction with belief propagation | Nouns are vectors, adjectives are matrices: Representing adjective-noun constructions in semantic space | Scalable semantic parsing with partial ontologies | Websets: Extracting sets of entities from the Web using unsupervised information extraction | Identifying relations for open information extraction | Identifying compounds: On the role of syntax | Automatic acquisition of hyponyms from large text corpora | Semantics in generative grammar , volume 13 | SemEval-2013 task 4: Free paraphrases of noun compounds | Prototype theory and compositionality | Large-scale noun compound interpretation using bootstrapping and the Web as a corpus | Phrase clustering for | Open language learning | WordNet: a lexical database | Interpreting compound noun | Zero-shot entity extraction from web pages | Relation extraction with matrix factorization and universal schemas | Cooccurrence contexts for noun compound interpretation | Improving hypernymy detection with an integrated path-based and distributional method | Semantic taxonomy induction from heterogenous evidence | A vsm-based statistical model for the semantic relation interpretation of noun-modifier pairs | A taxonomy, dataset, and classifier for automatic noun compound interpretation | MELODI: A supervised distributional approach for free paraphrasing of noun compounds | Generalizing to unseen entities and entity pairs with row-less universal schema | Automatic set instance extraction using the Web | Compound nominals, context, and compositionality | Nut case: What does it mean?: Understanding semantic relationship between nouns in noun compounds through paraphrasing and ranking the paraphrases | Boosting open information extraction with noun-based relations | From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions",acl,100
387.pdf.json,Learning Cognitive Features from Gaze Data for Sentiment and Sarcasm Classification using Convolutional Neural Network,"Detection of sentiment and sarcasm in usergenerated short reviews is of primary importance for social media analysis, recommendation and dialog systems. Traditional sentiment analyzers and sarcasm detectors face challenges that arise at lexical, syntactic, semantic and pragmatic levels (Liu and Zhang, 2012; Mishra et al., 2016c). Featurebased systems (Akkaya et al., 2009; Sharma and Bhattacharyya, 2013; Poria et al., 2014) can aptly handle lexical and syntactic challenges (e.g. learning that the word deadly conveys a strong positive sentiment in opinions such as Shane Warne is a deadly bowler, as opposed to The high altitude Himalayan roads have deadly turns). It is, however, extremely difficult to tackle subtleties at semantic and pragmatic levels. For example, the sentence “I really love my job. I work 40 hours a week to be this poor.” requires an NLP system to be able to understand that the opinion holder has not expressed a positive sentiment towards her / his job. In the absence of explicit clues in the text, it is difficult for automatic systems to arrive at a correct classification decision, as they often lack external knowledge about various aspects of the text being classified. Mishra et al. (2016b) and Mishra et al. (2016c) show that NLP systems based on cognitive data (or simply, Cognitive NLP systems) , that of leverage eye-movement information obtained from human readers, can tackle the semantic and pragmatic challenges better. The hypothesis here is that human gaze activities are related to the cognitive processes in the brain, that combines the “external knowledge” that the a reader possesses with textual clues that she / he perceives. While incorporating behavioral information obtained from gaze-data in NLP systems is intriguing and quite plausible, especially due to the availability of low cost eye-tracking machinery (Wood and Bulling, 2014; Yamamoto et al., 2013), few methods exist for text classification and they rely on handcrafted features extra",,acl,100
388.pdf.json,,"The Universal Dependencies (UD) initiative seeks to develop cross-linguistically consistent annotation guidelines as well as a large number of uniformly annotated treebanks for many languages.1 Such resources could advance multilingual applications of parsing, improve comparability of evaluation results, enable cross-lingual learning, and more generally support natural language understanding. Seeking to exploit the benefits of UD for natural language understanding, we introduce UDEPLAMBDA, a semantic interface for UD that maps 1http://www.universaldependencies.org/. natural language to logical forms, representing underlying predicate-argument structures, in an almost language-independent manner. Our framework is based on DEPLAMBDA (Reddy et al., 2016) a recently developed method that converts English Stanford Dependencies (SD) to logical forms. The conversion process is illustrated in Figure 1 and discussed in more detail in Section 2. Whereas DEPLAMBDA works only for English, UDEPLAMBDA applies to any language for which UD annotations are available.2 In this paper, we describe the rationale behind UDEPLAMBDA and highlight important differences from DEPLAMBDA, some of which stem from the different treatment of various linguistic constructions in UD. Our experiments focus on semantic parsing as a testbed for evaluating the framework’s multilingual appeal. We address the task of learning to map natural language to machine interpretable formal meaning representations, specifically retrieving answers to questions from Freebase. To facilitate multilingual evaluation, we provide translations of the English WebQuestions (Berant et al., 2013) and GraphQuestions (Su et al., 2016) datasets to German and Spanish. We demonstrate that UDEPLAMBDA can be used to derive logical forms for these languages using a minimal amount of language-specific knowledge. Aside from developing the first multilingual semantic parsing tool for Freebase, we also experimentally show that UDEPLAMBDA o",,acl,100
395.pdf.json,DRL-Sense: Deep Reinforcement Learning for Multi-Sense Word Representations,"Recently, deep learning methodologies have dominated several research areas in natural language processing (NLP), such as machine translation, language understanding, and dialogue systems. However, most of applications usually utilize word-level embeddings to obtain semantics. Considering that natural language is highly ambiguous, the standard word embeddings may suffer from polysemy issues. Neelakantan et al. (2014) pointed out that, due to triangle inequality in vector space, if one word embedding has two different senses, the sum of the distance between the word embedding and its synonymous embedding in each sense would be larger or equal to the distance between these synonymous embed- dings1. Because this inaccurate distance measurement may degrade downstream NLP tasks, multisense word representations are proposed to address the ambiguity issue in a single word embedding scenario (Reisinger and Mooney, 2010; Huang et al., 2012) This paper proposes DRL-Sense—a novel reinforcement learning based framework for learning multi-sense representations, which is composed by two main modules: a sense selection module for inferring the most probable sense for a word given its context, and a sense representation module for representing word senses in a continuous space. Our modular design implements pure sense-level representation learning while maintaining linear time sense selection. The proposed model is optimized by reinforcement learning and incorporates a non-parametric algorithms and a sense exploration mechanism without changing the network architecture2. Our contributions are four-fold: • We are among the first to study reinforcement learning for sense embedding learning, taking account of the Markov property in sense selection given local contexts. • DRL-Sense is the first system that achieves pure sense-level representation learning with linear time complexity on sense selection. • We develop non-parametric learning and sense exploration mechanisms for a general ","Breaking sticks and ambiguities with adaptive skip-gram | Improving distributed representation of word sense via wordnet gloss composition and context clustering | A unified model for word sense representation and disambiguation | Retrofitting sense-specific word vectors using parallel text | Learning sense-specific word embeddings by exploiting bilingual resources | Improving Word Representations via Global Context and Multiple Word Prototypes | Sensembed: Learning sense embeddings for word and relational similarity | Rogets thesaurus and semantic similarity | Ontologically grounded multi-sense representation learning for semantic vector space models | Neural context embeddings for automatic discovery of word senses | A solution to plato’s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge | Molding cnns for text: non-linear, non-consecutive convolutions | Rationalizing neural predictions | Do multi-sense embeddings improve natural language understanding | Learning context-sensitive word embeddings with neural tensor skip-gram model | Topical word embeddings | Visualizing data using t-sne | The Stanford CoreNLP natural language processing toolkit | Efficient estimation of word representations in vector space | Distributed representations of words and phrases and their compositionality | Wordnet: a lexical database for english | Playing atari with deep reinforcement learning | Semeval-2007 task 07: Coarsegrained english all-words task | Efficient nonparametric estimation of multiple embeddings per word in vector space | Glove: Global vectors for word representation | Contextdependent sense embedding | Multi-prototype vector-space models of word meaning | Autoextend: Extending word embeddings to embeddings for synsets and lexemes | The westbury lab wikipedia | Sense embedding learning for word sense induction | Dropout: a simple way to prevent neural networks from overfitting | Bilingual learning of multi-sense embeddings with discrete autoencoders | Reinforcement learning: An introduction, volume 1 | Policy gradient methods for reinforcement learning with function approximation | A probabilistic model for learning multi-prototype word embeddings | Mining the web for synonyms: Pmi-ir versus lsa on toefl | K-embeddings: Learning conceptual embeddings for words using context | It makes sense: A wide-coverage word sense disambiguation system for free text",acl,100
419.pdf.json,One-Shot Neural Cross-Lingual Transfer for Paradigm Completion,"Low-resource natural language processing remains an open problem for many tasks of interest. Furthermore, for most languages in the world, high-cost linguistic annotation and resource creation are unlikely to be undertaken in the near future. In the case of morphology, out of the 7000 currently spoken (Lewis, 2009) languages, only about 200 have computer-readable annotations (Sylak-Glassman et al., 2015) – although morphology is easy to annotate compared to syntax and semantics. Transfer learning is one solution to this problem: it exploits annotations in a high-resource language to train a system for a low-resource language. In this work, we present a method for cross-lingual transfer of inflectional morphology using an encoder-decoder recurrent neural network (RNN). This allows for the development of tools for computational morphology with limited annotated data. In morphologically rich languages, individual lexical entries may be realized as distinct inflec- tions of a single lemma depending on the syntactic context. For example, the 3SgPresInd of the English verbal lemma to bring is brings. In many languages, a lemma can have hundreds of individual forms. Thus, both generation and analysis of such morphological inflections are active areas of research in NLP and morphological processing has been shown to be a boon to several other down-stream applications, e.g., machine translation (Dyer et al., 2008), speech recognition (Creutz et al., 2007), parsing (Seeker and Çetinoğlu, 2015), keyword spotting (Narasimhan et al., 2014) and word embeddings (Cotterell et al., 2016b), inter alia. In this work we focus on paradigm completion, a form of morphological generation that maps a given lemma to a target inflection, e.g., (bring, Past) 7→ brought (with Past being the target tag). RNN sequence-to-sequence models (Sutskever et al., 2014; Bahdanau et al., 2015) are the state of the art for paradigm completion (Faruqui et al., 2016; Kann and Schütze, 2016a; Cotterell et a","The Uralic Languages | Improving sequence to sequence learning for morphological inflection generation: The BIU-MIT systems for the SIGMORPHON 2016 shared task for morphological reinflection | Semi-supervised learning of morphological paradigms and lexicons | Neural machine translation by jointly learning to align and translate | Cross-lingual morphological tagging for low-resource languages | Multitask learning | On the properties of neural machine translation: Encoder-decoder approaches | An empirical comparison of simple domain adaptation methods for neural machine translation | Unsupervised structure prediction with non-parallel multilingual guidance | Natural language processing (almost) from scratch | The Slavonic Languages | The SIGMORPHON 2016 shared task— morphological reinflection | Modeling word forms using latent underlying morphs and phonology | Morphological smoothing and extrapolation of word embeddings | Analysis of morph-based speech recognition and the modeling of out-of | Multi-task learning for multiple language translation | Supervised learning of complete morphological paradigms | Generalizing word lattice translation | Morphological inflection generation using character sequence to sequence learning | Morphological inflection generation using character sequence to sequence learning | Multi-way, multilingual neural machine translation with a shared attention mechanism | The use of machine translation tools for cross-lingual text mining | Speech recognition with deep recurrent neural networks | Framewise phoneme classification with bidirectional lstm and other neural network architectures | Toward multilingual neural machine translation with universal encoder and decoder | The Romance languages | The Semitic Languages | Cross-language knowledge transfer using multilingual deep neural network with shared hidden layers | Neural morphological analysis: Encodingdecoding canonical segments | Singlemodel encoder-decoder with explicit morphological representation for reinflection | MED: The LMU system for the SIGMORPHON 2016 shared task on morphological reinflection | Very-large scale parsing and normalization of wiktionary morphological paradigms | A simple way to initialize recurrent networks of rectified linear units | Ethnologue: Languages of the World. SIL International, Dallas, Texas, 16 edition | Multi-task sequence to sequence learning | Morphological segmentation for keyword spotting | Selective sharing for multilingual dependency parsing | Inflection generation as discriminative string transduction | Cross-language text classification | Crosslinguistic projection of role-semantic information | A universal part-of-speech tagset | Semimarkov conditional random fields for information extraction | A graphbased lattice dependency parser for joint morphological segmentation and syntactic analysis | Cross language text classification by model translation and semi-supervised learning | Crosslingual propagation for morphological analysis | Unsupervised multilingual learning for morphological segmentation | Data point selection for crosslanguage adaptation of dependency parsers | Dropout: a simple way to prevent neural networks from overfitting | Sequence to sequence learning with neural networks | The composition and use of the universal morphological feature schema (unimorph schema) | A language-independent feature schema for inflectional morphology | Grammar as a foreign language | Cross-lingual projected expectation regularization for weakly supervised learning | Cross-lingual pseudo-projected expectation regularization for weakly supervised learning | Corpus-level fine-grained entity typing using contextual information | Inducing multilingual text analysis tools via robust projection across aligned corpora | ADADELTA: an adaptive learning rate method | Multi-source neural translation",acl,100
433.pdf.json,,"Languages evolve temporally and geographically, both in vocabulary as well as in syntactic structures. When major languages such as English or French are adopted in another culture as the primary language, they often mix with existing languages or dialects in that culture and evolve into a stable language called a creole. Examples of creoles include the French-based Haitian Creole, and Colloquial Singaporean English (Singlish) (MianLian and Platt, 1993), an English-based creole. While the majority of the natural language processing (NLP) research attention has been focused on the major languages, little work has been done on adapting the components to creoles. One notable body of work originated from the featured translation task of the EMNLP 2011 Workshop on Statistical Machine Translation (WMT11) to translate Haitian Creole SMS messages sent during the 2010 Haitian earthquake. This work high- lights the importance of NLP tools on creoles in crisis situations for emergency relief (Hu et al., 2011; Hewavitharana et al., 2011). Singlish is one of the major languages in Singapore, with borrowed vocabulary and grammars from a number of languages including Malay, Tamil, and Chinese dialects such as Hokkien, Cantonese and Teochew (Leimgruber, 2009, 2011), and it has been increasingly used in written forms on web media. Fluent English speakers unfamiliar with Singlish would find the creole hard to comprehend (Harada, 2009). Correspondingly, fundamental English NLP components such as POS taggers and dependency parsers perform poorly on such Singlish texts based on our observations. For example, Seah et al. (2015) adapted the Socher et al. (2013) sentiment analysis engine to the Singlish vocabulary, but failed to adapt the parser. Since dependency parsers are important for tasks such as information extraction (Miwa and Bansal, 2016) and discourse parsing (Li et al., 2015), this hinders the development of such downstream applications for Singlish in written forms and thus ma","Many languages, one parser | Globally normalized transition-based neural networks | Neural machine translation by jointly learning to align and translate | Improved transition-based parsing by modeling characters instead of words with lstms | A fast and accurate dependency parser using neural networks | Neural network for heterogeneous annotations | Shared logistic normal distributions for soft parameter tying in unsupervised grammar induction | Natural language processing (almost) from scratch | Deep biaffine attention for neural dependency parsing | Bidirectional LSTM-CRF models for sequence tagging | Bootstrapping parsers via syntactic projection across parallel texts | Simple and accurate dependency parsing using bidirectional lstm feature representations | Modelling variation in Singapore English | Singapore english | When are tree structures necessary for deep learning of representations? In Proceedings of the EMNLP 2015 | Mergers and acquisitions: on the ages and origins of singapore english particles | Multi-source transfer of delexicalized dependency parsers | Dynamics of a contact continuum: Singaporean English | End-to-end relation extraction using lstms on sequences and tree structures | Selective sharing for multilingual dependency parsing | The international computerized corpus of english | Universal dependencies v1: A multilingual | Analysing the singapore ice corpus for lexicographic evidence | Glove: Global vectors for word representation | Multilingual part-of-speech tagging with bidirectional long short-term memory models and auxiliary loss | Troll detection by domain-adapting sentiment analysis | Recursive deep models for semantic compositionality over a sentiment treebank | Cross-lingual word clusters for direct transfer of linguistic structure | Structured training for neural network transition-based parsing | Hierarchical low-rank tensors for multilingual transfer parsing | Stackpropagation: Improved representation learning for syntax | A neural probabilistic structuredprediction model for transition-based dependency parsing",acl,100
435.pdf.json,Neural Disambiguation of Causal Lexical Markers based on Context,"Causation is a psychological tool of humans to understand the world independently of language, and it is one of the principles involved in the construction of the human mental model of reality (Neeleman and van de Koot, 2012). Causal reasoning is the process of relating two events, namely cause and its effect. Following the words of Reinhart (2002), causal relations are imposed by humans on the input from the world, and the (computational) linguist’s task is to understand what is about language that enables speakers to use it to describe their causal perceptions. There are different theories concerning how natural language approximates causation. Those theories based on generative semantics argue that the causal relation is encoded in the semantics of some verbs (Lakoff, 1970; McCawley, 1976) or in the syntactic structure of a sentence (Dowty, 1979; Ramchand, 2008). For instance, Pylkkänen (2008) argues that the causing event may be associated with the subject of the causal verb in a causal predicate. This principle is true in the sentence “Pe- ter eventually killed John by hitting him with a hammer”, in which the event of Peter hitting John with a hammer caused the death of John. But, the following sentence can be used as a counterexample: “A hammer eventually killed John”. In the later sentence the subject of “killed” is the “hammer”, which does not constitute a causing event for the event “kill John”. Therefore, the syntaxgrounded construction of causality defined by those theories is far away from the human mental model of causation. Indeed, Neeleman and van de Koot (2012) showed that the later approaches cannot be proven by standard syntactic tests, because neither the causing event nor causal relation correspond to a syntactic constituent. Neeleman and van de Koot (2012) concluded that the linguistic approximation of causation by culmination of events is not exclusive of causal verbs, and it is also found in non-causative verb classes. Causation or causality ","Learning semantic links from a corpus of parallel temporal and causal relations | Minimally supervised event causality identification | Word meaning and Montague grammar: The semantics of verbs and times in generative semantics and in Montague’s PTQ | Automatic detection of causal relations for question answering | Identifying causal relations using parallel wikipedia articles | Long short-term memory | Automatic extraction of cause-effect information from newspaper text without knowledge-based inferencing | Adam: A method for stochastic optimization | Improving event causality recognition with multiple background knowledge sources using multi-column convolutional neu | Irregularity in Syntax | Grammar and Meaning | context2vec: Learning generic context embedding with bidirectional LSTM | Annotating causality in the tempeval-3 corpus | Catena: Causal and temporal relation extraction from natural language texts | The linguistic expression of causation | The proposition bank: An annotated corpus of semantic roles | Glove: Global vectors for word representation | The penn discourse treebank 2.0 | Introducing arguments, volume 49 | Verb Meaning and the Lexicon: A First Phase Syntax | The Theta System: Syntactic Realization of Verbal Concepts | Another look at causality: Discovering scenario-specific contingency relationships with no supervision | Toward a better understanding of causality between verbal events: Extraction and analysis of the causal power of verb-verb associations | In-depth exploitation of noun and verb semantics to identify causation in verb-noun pairs | ADADELTA: an adaptive learning rate method",acl,100
440.pdf.json,,"Supertagging in lexicalized grammar parsing is known as almost parsing (Bangalore and Joshi, 1999), in that each supertag is syntactically informative and most ambiguities are resolved once a correct supertag is assigned to every word. Recently this property is effectively exploited in A* Combinatory Categorial Grammar (CCG; Steedman (2000)) parsing (Lewis and Steedman, 2014; Lewis et al., 2016), in which the probability of a CCG tree y on a sentence x of length N is the product of the probabilities of supertags (categories) ci (locally factored model): P (y|x) = ∏ i∈[1,N ] Ptag(ci|x). (1) By not modeling every combinatory rule in a derivation, this formulation enables us to employ efficient A* search (see Section 2), which finds the most probable supertag sequence that can build a well-formed CCG tree. Although much ambiguity is resolved with this supertagging, some ambiguity still remains. Figure 1 shows an example, where the two CCG 1 We provide our software as a supplementary material. (a) a house in Paris in France NP (NP\NP)/NP NP (NP\NP)/NP NP > > NP\NP NP\NP < NP < NP (b) a house in Paris in France NP (NP\NP)/NP NP (NP\NP)/NP NP > NP\NP < NP > NP\NP < NP parses are derived from the same supertags. Lewis et al.’s approach to this problem is resorting to some deterministic rule. For example, Lewis et al. (2016) employ the attach low heuristics, which is motivated by the right-branching tendency of English, and always prioritizes (b) for this type of ambiguity. Though for English it empirically works well, an obvious limitation is that it does not always derive the correct parse; consider a phrase “a house in Paris with a garden”, for which the correct parse has the structure corresponding to (a) instead. In this paper, we provide a way to resolve these remaining ambiguities under the locally factored model, by explicitly modeling bilexical dependencies as shown in Figure 1. Our joint model is still locally factored so that an efficient A* search can be applied",TensorFlow: LargeScale Machine Learning on Heterogeneous Systems. Software available from tensorflow.org | Supertagging: An Approach to Almost Parsing | WideCoverage Efficient Statistical Parsing with CCG and Log-Linear Models | Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs) | Learning Character-level Representations for Part-of-Speech Tagging | Deep Biaffine Attention for Neural Dependency Parsing | TransitionBased Dependency Parsing with Stack Long ShortTerm Memory | Efficient Normal-Form Parsing for Combinatory Categorial Grammar | Normalform parsing for Combinatory Categorial Grammars with generalized composition and type-raising | Ccgbank: A corpus of ccg derivations and dependency structures extracted from the penn treebank | Simple and Accurate Dependency Parsing Using Bidirectional LSTM Feature Representations | A* Parsing: Fast Exact Viterbi Parse Selection | Japanese Dependency Analysis using Cascaded Chunking | Global Neural CCG Parsing with Optimality Guarantees | Low-Rank Tensors for Scoring Dependency Structures | LSTM CCG Parsing | A* CCG Parsing with a Supertag-factored Model | Confidential Review Copy | Jigg: A Framework for an Easy Natural Language Processing Pipeline | GloVe: Global Vectors for Word Representation | The Syntactic Process | Chainer: a Next-Generation Open Source Framework for Deep Learning | Feature-rich part-ofspeech tagging with a cyclic dependency network | Word Representations: A Simple and General Method for Semi-Supervised Learning | Japanese Dependency Structure Analysis Based on Maximum Entropy Models | Integrating Multiple Dependency Corpora for Inducing Wide-coverage Japanese CCG Resources | Supertagging With LSTMs | Structured Training for Neural Network Transition-Based Parsing,acl,100
444.pdf.json,Evaluating Creative Language Generation: The Case of Rap Lyric Ghostwriting,"Language generation tasks are often among the most difficult to evaluate. Evaluating machine translation, image captioning, summarization, and other similar tasks is typically done via comparison with existing human-generated “references”. However, human beings also use language creatively, and for the language generation tasks that seek to mimic this ability, determining how accurately the generated text represents its target is insufficient, as one also needs to evaluate creativity and style. We believe that one of the reasons such tasks receive little attention is the lack of sound evaluation methodology, without which no task is well-defined, and no progress can be made. The goal of this paper is to develop an evaluation methodology for one such task, ghostwriting, or more specifically, ghostwriting of rap lyrics. Ghostwriting is ubiquitous in politics, literature, and music. As such, it introduces a distinction between the performer/presenter of text, lyrics, etc, and the creator of text/lyrics. The goal of ghostwriting is to present something in a style that is believable enough to be credited to the performer. In the domain of rap specifically, rappers sometimes function as ghostwriters early on before embarking on their own public careers, and there are even businesses that provide written lyrics as a service1. The goal of automatic ghostwriting is therefore to create a system that can take as input a given artist’s work and generate similar yet unique lyrics. Our objective in this work is to provide a quantifiable direction and foundation for the task of rap lyric generation and similar tasks through (1) developing an evaluation methodology for such models, and (2) illustrating how such evaluation can be used to analyze system performance, including advantages and limitations of a specific language model developed for this task. As an illustration case, we use the ghostwriter model previously proposed in exploratory work by Potash et al. (2015), which uses ",Discrete vs | Natural Language Processing with Python | Generating sentences from a continuous space | A neural algorithm of artistic style | Wasp: Evaluation of different strategies for the automatic generation of spanish verse | Generating sequences with recurrent neural networks | A comparative evaluation methodology for nlg in interactive systems | Using automated rhyme detection to characterize rhyming style in rap music | Rhyme analyzer: An analysis tool for rap lyrics | Combining markov random fields and convolutional neural networks for image synthesis | Dopelearning: A computational approach to rap lyrics generation | Adapting a generic platform for poetry generation to produce spanish poems | Ghostwriter: Using an LSTM for automatic rap lyric generation | A neural network approach for knowledge-driven response generation | Learning to freestyle: Hip hop challenge-response induction via transduction rule segmentation | Evaluating improvised hip hop lyrics–challenges and observations,acl,100
447.pdf.json,,"Advances in text categorization have the potential to improve systems for analyzing sentiment, inferring authorship or author attributes, making predictions, and many more. Several past researchers have noticed that methods that reason about the relative saliency or importance of passages within a text can lead to improvements (Ko et al., 2004). Latent variables (Yessenalina et al., 2010), structured-sparse regularizers (Yogatama and Smith, 2014), and neural attention models (Yang et al., 2016) have all been explored. Discourse structure, which represents the organization of a text as a tree (for an example, see Figure 1), might provide cues for the importance of different parts of a text. Some promising results on sentiment classification tasks support this idea: Bhatia et al. (2015) and Hogenboom et al. (2015) applied hand-crafted weighting schemes to the sentences in a document, based on its discourse structure, and showed benefit to sentiment polarity classification. In this paper, we investigate the value of discourse structure for text categorization more broadly, considering five tasks, through the use of a recursive neural network built on an R Contrast Elaboration A B Explanation C Joint D Constrast E F [Although the food was amazing]A [and I was in love with the spicy pork burrito,]B [the service was really awful.]C [We watched our waiter serve himself many drinks.]D [He kept running into the bathroom]E [instead of grabbing our bill.]F automatically-derived document parse from a topperforming, open-source discourse parser, DPLP (Ji and Eisenstein, 2014). Our models learn to weight the importance of a document’s sentences, based on their positions and relations in the discourse tree. We introduce a new, unnormalized attention mechanism to this end. Experimental results show that variants of our model outperform prior work on four out of five tasks considered. Our method unsurprisingly underperforms on the fifth task, making predictions about legislative bil",Argumentative text as rhetorical structure: An application of rhetorical structure theory | Neural machine translation by jointly learning to align and translate | Learning latent personas of film characters. In Annual Meeting of the Association for Computational Linguistics (ACL) | Hyperopt: a python library for model selection and hyperparameter optimization | Better document-level sentiment analysis from rst discourse parsing | The media frames corpus: Annotations of frames across issues | Analyzing framing through the casts of characters in the news | Building a Discourse-tagged Corpus in the Framework of Rhetorical Structure Theory | Indexing by latent semantic analysis | Using rhetorical structure in sentiment analysis | Representation learning for document-level discourse parsing | One Vector is Not Enough: Entity-Augmented Distributed Semantics for Discourse Relations | Text categorization with support vector machines: Learning with many relevant features | A convolutional neural network for modelling sentences | Adam: A method for stochastic optimization | Improving text categorization using the importance of sentences | What do recurrent neural network grammars learn about syntax? In EACL | Rhetorical Structure Theory: Toward a Functional Theory of Text Organization | Discourse trees are good indicators of importance in text | Building a large annotated corpus of english: The penn treebank | Recurrent neural network based language model | Dynet: The dynamic neural network toolkit | A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts | Global Belief Recursive Neural Networks | Glove: Global vectors for word representation | Labeled lda: A supervised topic model for credit attribution in multilabeled corpora | Grounded compositional semantics for finding and describing images with sentences | Get out the vote: Determining support or opposition from congressional floor-debate transcripts | Efficient character-level document classification by combining convolution and recurrent layers | Statistical dependency analysis with support vector machines | A comparative study on feature selection in text categorization | Hierarchical attention networks for document classification | Textual predictors of bill survival in congressional committees | Multi-level structured models for document sentiment classification | Linguistic structured sparsity in text categorization | Dependency-based Discourse Parser for Single-Document Summarization | Using “annotator rationales” to improve machine learning for text categorization | Character-level convolutional networks for text classification,acl,100
462.pdf.json,Volatility Prediction using Financial Disclosures Sentiments with Word Embedding-based IR Models,"Financial volatility is an essential indicator of instability and risk of a company, sector or economy. Volatility forecasting has gained considerable attention during the last three decades. In addition to using historic stock prices, new methods in this domain use sentiment analysis to exploit various text resources, such as financial reports (Kogan et al., 2009; Wang et al., 2013; Tsai and Wang, 2014; Nopp and Hanbury, 2015), news (Kazemian et al., 2014; Ding et al., 2015), message boards (Nguyen and Shirai, 2015), and earning calls (Wang and Hua, 2014). An interesting resource of textual information are the companies’ annual disclosures, known as 10-K filing reports. They contain comprehensive information about the companies’ business as well as risk factors. Specifically, section Item 1A - Risk Factors of the reports contains information about the most significant risks for the company. These reports are however long, redundant, and written in a style that makes them complex to process. Dyer et al. (2016) notes that: “10-K reports are getting more redundant and complex [...] (it) requires a reader to have 21.6 years of formal education to fully comprehend”. Dyer et al. also analyse the topics discussed in the reports and observe a constant increase over the years in both the length of the documents as well as the number of topics. They claim that the increase in length is not the result of economic factors but is due to verboseness and redundancy in the reports. They suggest that only the risk factors topic appears to be useful and informative to investors. Their analysis motivates us to study the effectiveness of the Risk Factors section for volatility prediction. Our research builds on previous studies on volatility prediction and information analysis of 10-K reports using sentiment analysis (Kogan et al., 2009; Tsai and Wang, 2014; Wang et al., 2013; Nopp and Hanbury, 2015; Li, 2010; Campbell et al., 2014), in the sense that since the reports are long (avera","Generalized autoregressive conditional heteroskedasticity | The information content of mandatory risk factor disclosures in corporate filings | A comprehensive look at financial volatility prediction by economic variables | Deep learning for event-driven stock prediction | Support vector regression machines. Advances in neural information processing systems 9:155–161 | The ever-expanding 10-k: Why are 10-ks getting so much longer (and does it matter) | Autoregressive conditional heteroscedasticity with estimates of the variance of united kingdom inflation | Multiple kernel learning algorithms | Evaluating sentiment analysis evaluation: A case study in securities trading | Predicting risk from financial reports with regression | Learning the kernel matrix with semidefinite programming | The information content of forwardlooking statements in corporate filings–a naı̈ve bayesian machine learning approach | Financial volatility forecasting with range-based autoregressive volatility model | Estimation of monthly volatility: An empirical comparison of realized volatility, garch and acd-icv methods | When is a liability not a liability? textual analysis, dictionaries, and 10-ks | Predicting abnormal returns from news using text classification | Efficient estimation of word representations in vector space | Topic modeling based sentiment analysis on social media for stock market prediction | Support vector machine applications in computational biology | Detecting risks in the banking system by sentiment analysis | Uncertainty in neural network word embedding: Exploration of threshold for similarity | Generalizing translation models in the probabilistic relevance framework | Exploration of a threshold for similarity based on uncertainty in word embedding | Learning the kernel matrix via predictive low-rank approximations | Financial keyword expansion via continuous word vector representations | Financial sentiment analysis for risk prediction | A semiparametric gaussian copula regression model for predicting financial risks from earnings calls | Stacked generalization | Semantic Frames to Predict Stock Price Movement",acl,100
467.pdf.json,,"Multilingual word embeddings have attracted a lot of attention in recent times. In addition to having a direct application in inherently cross-lingual tasks like machine translation (Zou et al., 2013) and cross-lingual entity linking (Tsai and Roth, 2016), they provide an excellent mechanism for transfer learning, where a model trained in a resourcerich language is transferred to a less-resourced one, as shown with part-of-speech tagging (Zhang et al., 2016), parsing (Xiao and Guo, 2014) and document classification (Klementiev et al., 2012), among others. Most methods to learn these multilingual word embeddings make use of large parallel corpora (Gouws et al., 2015; Luong et al., 2015), but there have been several proposals to relax this requirement, given its scarcity in most language pairs. A possible relaxation is to use document-aligned or label-aligned comparable corpora (Søgaard et al., 2015; Vulic and Moens, 2016; Mogadala and Rettinger, 2016), but large amounts of such corpora are not always available for some language pairs. An alternative approach that we follow here is to independently train the embeddings for each language on monolingual corpora, and then learn a linear transformation to map the embeddings from one space into the other by minimizing the distances in a bilingual dictionary, usually in the range of a few thousand entries (Mikolov et al., 2013a; Artetxe et al., 2016). However, dictionaries of that size are not readily available for many language pairs, specially those involving less-resourced languages. In this work, we reduce the need of large bilingual dictionaries to much smaller seed dictionaries. Our method can work with as little as 25 word pairs, which are straightforward to obtain assuming some basic knowledge of the languages involved. The method can also work with trivially generated seed dictionaries of numerals (i.e. 1-1, 2-2, 3-3, 4-4...) making it possible to learn bilingual word embeddings without any real bilingual data. In ","Learning principled bilingual mappings of word embeddings while preserving monolingual invariance | The wacky wide web: a collection of very large linguistically processed web-crawled corpora | A framework for the construction of monolingual and cross-lingual word similarity datasets | An autoencoder approach to learning bilingual word representations | Improving zero-shot learning by mitigating the hubness problem | Unifying bayesian inference and vector space models for improved decipherment | Improving vector space word representations using multilingual correlation | Bilbowa: Fast bilingual distributed representations without word alignments | Inducing crosslingual distributed representations of words | Hubness and pollution: Delving into cross-space mapping for zero-shot learning | Deep multilingual correlation for improved word embeddings | Bilingual word representations with monolingual quality in mind | Adversarial autoencoders | The stanford corenlp natural language processing toolkit | Towards crosslingual distributed representations without parallel text trained with adversarial autoencoders | Exploiting similarities among languages for machine translation | Distributed representations of words and phrases and their compositionality | Bilingual word embeddings from parallel and nonparallel corpora for cross-language text classification | Inverted indexing for crosslingual nlp | Parallel data, tools and interfaces in opus | Cross-lingual wikification using multilingual embeddings | Cross-lingual models of word embeddings: An empirical comparison | Bilingual distributed word representations from document-aligned comparable data | Distributed word representation learning for cross-lingual dependency parsing | Normalized word embedding and orthogonal transform for bilingual word translation | Ten pairs to tag – multilingual pos tagging via coarse mapping between embeddings | Learning translation models from monolingual continuous representations | Bilingual word embeddings for phrase-based machine translation",acl,100
477.pdf.json,From Characters to Words to in Between: Do We Capture Morphology?,"Continuous representations of words learned by neural networks are central to many NLP tasks (Cho et al., 2014; Chen and Manning, 2014; Dyer et al., 2015). However, directly mapping a finite set of word types to a continuous representation has well-known limitations. First, it makes a closed vocabulary assumption, enabling only generic out-of-vocabulary handling. Second, it cannot exploit systematic functional relationships in learning. For example, cat and cats stand in the same relationship as dog and dogs. While this re- lationship might be discovered for these specific frequent words, it does not help us learn that the same relationship also holds for the much rarer words tarsier and tarsiers. These functional relationships reflect the fact that words are composed from smaller units of meaning, or morphemes. For instance, cats consists of two morphemes, cat and -s, with the latter shared by the words dogs and tarsiers. Modeling this effect is crucial for languages with rich morphology, where vocabulary sizes are larger, many more words are rare, and many more such functional relationships exist. Hence, some models produce word representations as a function of subword units obtained from morphological segmentation or analysis (Luong et al., 2013; Botha and Blunsom, 2014; Cotterell and Schütze, 2015). However, a downside of these models is that they introduce a dependence on morphological segmentation or analysis. But morphemes typically have similar orthographic representations across words. For example, the morpheme -s is realized as -es in finches, but this variation is limited, and the general relationship between morphology and orthography can be exploited by composing the representations of characters (Ling et al., 2015; Kim et al., 2016), character n-grams (Sperr et al., 2013; ?; Bojanowski et al., 2016; Botha and Blunsom, 2014), bytes (Plank et al., 2016; Gillick et al., 2016), or combinations thereof (dos Santos and Zadrozny, 2014; Qiu et al., 2014). The","TensorFlow: Large-scale machine learning on heterogeneous systems. Software available from tensorflow.org | Polyglot: Distributed word representations for multilingual nlp | Linguistic Fundamentals for Natural Language Processing: 100 Essentials from Morphology and Syntax | Enriching word vectors with subword information | Compositional Morphology for Word Representations and Language Modelling | A fast and accurate dependency parser using neural networks | Learning phrase representations using rnn encoder–decoder for statistical machine translation | Morphological word-embeddings | Learning character-level representations for part-of-speech tagging | Transitionbased dependency parsing with stack long shortterm memory | A new algorithm for data compression | Multilingual language processing from bytes | Bidirectional lstm networks for improved phoneme classification and recognition | Understanding Morphology | Long short-term memory | Character-aware neural language models | Indonesian Morphology Tool (MorphInd): Towards an Indonesian | Fully character-level neural machine translation without explicit segmentation | Finding function in form: Compositional character models for open vocabulary word representation | Better word representations with recursive neural networks for morphology | Recurrent neural network based language model | Gated word-character recurrent language model | Syntax in Functional Grammar: An Introduction to Lexicogrammar in Systemic Linguistics | Madamira: A fast, comprehensive tool for morphological analysis and disambiguation of ara | Multilingual part-of-speech tagging with bidirectional long short-term memory models and auxiliary loss | Co-learning of word representations and morpheme representations | Computational Approach to Morphology and Syntax | Neural machine translation of rare words with subword units | Morfessor 2.0: Toolkit for statistical morphological segmentation",acl,100
481.pdf.json,,"Most human language understanding is grounded in perception. There is thus growing interest in combining information from language and vision in the NLP and AI communities. So far, the primary testbeds of Language and Vision (LaVi) models have been ‘Visual Question Answering’ (VQA) (e.g. Antol et al. (2015); Malinowski and Fritz (2014); Malinowski et al. (2015); Gao et al. (2015); Ren et al. (2015)) and ‘Image Captioning’ (IC) (e.g. Hodosh et al. (2013); Fang et al. (2015); Chen and Lawrence Zitnick (2015); Donahue et al. (2015); Karpathy and Fei-Fei (2015); Vinyals et al. (2015)). Whilst some models have seemed extremely successful on those tasks, it remains unclear how the reported results should be interpreted and what those models are actually learning. There is an emerging feeling in the LaVi community that the current VQA task should be revised, especially as it has been shown that it can be handled well by ‘blind’ models which use only language input or by simple concatenation of language and vision features (Agarwal et al., 2016; Jabri et al., 2016; Zhang et al., 2016; Goyal et al., 2016). In IC too, Hodosh and Hockenmaier (2016) showed that, contrarily to what prior research had suggested, the task is far from been solved, since IC models are not able to distinguish between a correct and incorrect caption. Such results indicate that in current datasets, language provides priors that make it possible for a LaVi model to be successful without truly understanding and integrating language and vision. But problems do not stop at biasing. Johnson et al. (2016) highlight a second weakness of such datasets, pointing out that “they conflate multiple sources of error, making it hard to pinpoint model weaknesses”. The authors thus suggest the need for a diagnostic dataset. Thirdly, it has been observed that existing IC evaluation metrics are sen- 2 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 1","Analyzing the behavior of visual question answering models | Spice: Semantic propositional image caption evaluation | VQA: Visual question answering | Automatic description generation from images: A survey of models, datasets, and evaluation | Mind’s eye: A recurrent visual representation for image caption generation | Understanding image and text simultaneously: a dual vision-language machine comprehension task | Long-term recurrent convolutional networks for visual recognition and description | Comparing automatic evaluation measures for image description | From captions to visual concepts and back | Deep visualsemantic alignments for generating image descriptions | Multimodal compact bilinear pooling for visual question answering and visual grounding | Are you talking to a machine? dataset and methods for multilingual image question | Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering | Making the v in vqa matter: Elevating the role of image understanding in visual question answering | Towards transparent ai systems: Interpreting visual question answering models | Focused evaluation for image description with binary forcedchoice tasks | Framing image description as a ranking task: Data, models and evaluation metrics | Revisiting visual question answering baselines | Clevr: A diagnostic dataset for compositional language and elementary visual reasoning | Visual question answering: Datasets, algorithms, and future challenges | Deep visualsemantic alignments for generating image descriptions | Microsoft coco: Common objects in context | Deeper lstm and normalized cnn visual question answering model | Hierarchical question-image coattention for visual question answering | A multiworld approach to question answering about realworld scenes based on uncertain input | Ask your neurons: A neural-based approach to answering questions about images | Attentive explanations: Justifying decisions and pointing to the evidence | Exploring models and data for image question answering | Grad-cam: Why did you say that? visual explanations from deep networks via gradient-based localization | Show and tell: A neural image caption generator | Visual question answering: A survey of methods and datasets | From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions | Yin and yang: Balancing and answering binary visual questions | Simple baseline for visual question answering",acl,100
483.pdf.json,Here’s My Point: Argumentation Mining with Pointer Networks,"Computational approaches to argument mining/understanding have become very popular (Persing and Ng, 2016; Cano-Basave and He, 2016; Wei et al., 2016; Ghosh et al., 2016; Palau and Moens, 2009; Habernal and Gurevych, 2016). An important avenue in this work is to understand the structure in argumentative text (Persing and Ng, 2016; Peldszus and Stede, 2015; Stab and Gurevych, 2016; Nguyen and Litman, 2016). One fundamental assumption when working with argumentative text is the presence of Arguments Components (ACs). The types of ACs are generally characterized as a claim or a premise (Govier, 2013), with premises acting as support (or possibly attack) units for claims. To model more complex structures of arguments, some annotation schemes also include a major claim AC type (Stab and Gurevych, 2016, 2014b). Generally, the task of processing argument structure encapsulates four distinct subtasks: 1) Given a sequence of tokens that represents an entire argumentative text, determine the token subsequences that constitute non-intersecting ACs; 2) Given an AC, determine the type of AC (claim, premise, etc.); 3) Given a set/list of ACs, determine which ACs have directed links that encapsulate overall argument structure; 4) Given two linked ACs, determine whether the link is a supporting or attacking relation. In this work, we focus on subtasks 2 and 3. There are two key assumptions our work makes going forward. First, we assume subtask 1 has been completed, i.e. ACs have already been identified. Second, we follow previous work that assumes a tree structure for the linking of ACs (Palau and Moens, 2009; Cohen, 1987; Peldszus and Stede, 2015; Stab and Gurevych, 2016). Specifically, a given AC can only have a single outgoing link, but can have numerous incoming links. Furthermore, there is a ‘head’ component that has no outgoing link (the top of the tree). However, we note that in a broader sense, depending on the corpus (see Section 4), an argument structure can be either a si","TensorFlow: Large-scale machine learning on heterogeneous systems. Software available from tensorflow.org | Neural machine translation by jointly learning to align and translate | Back up your stance: Recognizing arguments in online discussions | Tree-structured composition in neural networks without tree-structured architectures | Recursive neural networks can learn logical semantics | Natural language arguments: A combined approach | A study of the impact of persuasive argumentation in political debates | Deep computational phenotyping | Analyzing the structure of argumentative discourse | Coarse-grained argumentation features for scoring persuasive essays | Analyzing argumentative discourse units in online interactions | A practical study of argument | Offline handwriting recognition with multidimensional recurrent neural networks | Which argument is more convincing? analyzing and predicting convincingness of web arguments using bidirectional lstm | Long short-term memory | Adam: A method for stochastic optimization | Ask me anything: Dynamic memory networks for natural language processing | Identifying and classifying subjective claims | Mining arguments from 19th century philosophical texts using topic based modelling | Contextaware argumentative relation mining | Argumentation mining: the detection, classification and structure of arguments in text | Towards segment-based recognition of argumentation structure in short texts | Joint prediction in mst-style discourse parsing for argumentation mining | Glove: Global vectors for word representation | End-to-end argumentation mining in student essays | An application of recurrent nets to phone probability estimation | Applying kernel methods to argumentation mining | Dropout: a simple way to prevent neural networks from overfitting | Annotating argument components and relations in persuasive essays | Identifying argumentative discourse structures in persuasive essays | Parsing argumentation structures in persuasive essays | Sequence to sequence learning with neural networks | Order matters: Sequence to sequence for sets | Pointer networks | Grammar as a foreign language | Is this post persuasive? ranking argumentative comments in the online forum | Towards ai-complete question answering: A set of prerequisite toy tasks | Memory networks | Mitre at semeval-2016 task 6: Transfer learning for stance detection",acl,100
484.pdf.json,,"Automatic speech recognition (ASR) is currently a mature set of technologies that have been widely deployed, resulting in great success in interface applications such as voice search. A typical ASR system is factorized into several modules including acoustic, lexicon, and language models based on a probabilistic noisy channel model (Jelinek, 1976). Over the last decade, dramatic improvements in acoustic and language models have been driven by machine learning techniques known as deep learning (Hinton et al., 2012). However, current systems lean heavily on the scaffolding of complicated legacy architectures that grew up around traditional techniques. These present the following problems that we may seek to eliminate. 1. Flat start: many module-specific processes are required to build an accurate module: for example, when we build an acoustic model from scratch, we have to first build hidden Markov model (HMM) and Gaussian mixture model (GMM) followed by deep neural networks (DNN). 2. Linguistic knowledge: to well factorize acoustic and language models, we need to have a lexicon model, which is usually based on a hand-crafted pronunciation dictionary to map word to phoneme sequence. Also, some languages do not explicitly have a word boundary and need tokenization modules (Kudo et al., 2004; Bird, 2006). 3. Conditional independence assumptions: the current ASR systems often use conditional independence assumptions (especially Markov assumptions) during the above factorization and to make use of GMM, DNN, and n-gram models. The data do not necessarily follow such assumptions leading to model mis-specification. 4. Complex decoding: inference/decoding has to be performed by integrating all modules. Although this integration is often efficiently handled by finite state transducers, the construction and implementation of welloptimized transducers is very complicated. 5. Local optimum: the above modules are optimized separately, which may result in local optima, where each m","Deep speech 2: End-to-end speech recognition in english and mandarin | Neural machine translation by jointly learning to align and translate | Endto-end attention-based large vocabulary speech recognition | NLTK: the natural language toolkit | Connectionist speech recognition: A hybrid approach | Listen, attend and spell | End-to-end continuous speech recognition using attention-based recurrent NN: First results | Towards better decoding and language model integration in sequence to sequence models | Attention-based models for speech recognition | Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks | Towards endto-end speech recognition with recurrent neural networks | Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups | Continuous speech recognition by statistical methods | Maximum a posteriori based decoding for CTC acoustic models | Joint CTC-attention based end-to-end speech recognition using multi-task learning | Applying conditional random fields to japanese morphological analysis | HKUST/MTS: A very large scale mandarin telephone speech corpus | On training the recurrent neural network encoderdecoder for large vocabulary end-to-end speech recognition | Spontaneous speech corpus of japanese | EESEN: End-to-end speech recognition using deep RNN models and WFST-based decoding | An empirical exploration of ctc acoustic models | Recurrent neural network based language model | Kaldi recipe for Japanese spontaneous speech recognition and its evaluation | On the difficulty of training recurrent neural networks | Purely sequence-trained neural networks for asr based on lattice-free MMI | Neural speech recognizer: Acoustic-to-word lstm model for large vocabulary speech recognition | Chainer: a next-generation open source framework for deep learning | Sequence-discriminative training of deep neural networks | Chinese word segmentation as character tagging | Adadelta: an adaptive learning rate method",acl,100
489.pdf.json,Combining distributional and referential information for naming objects through cross-modal mapping and direct word prediction,"Expressions referring to objects in visual scenes typically include a word naming the type of the object: E.g., “house” in Figure 1 (a), or, as a very general type, “thingy” in Figure 1 (d). Determining such a name is is a crucial step for referring expression generation (REG) systems, as many other decisions, concerning e.g. the selection of attributes, follow from it (Dale and Reiter, 1995; Krahmer and Van Deemter, 2012). For a long time, however, research on REG mostly assumed the availability of symbolic representations of referent and scene, and sidestepped questions about how speakers actually choose these names, due to the lack of models capable of capturing what a word like house refers to in the real world. Recent advances in image processing promise to fill this gap, with state-of-the-art computer vision systems being able to classify images into thousands of different categories (eg. Szegedy et al. (2015)). However, classification is not naming (Ordonez et al., 2016). Classification schemes are typically designed to be “flat”, with labels being on the same ontological level and, ideally, having disjunct extensions. In contrast, humans seem to be more flexible as to the chosen level of generality. Depending on the prototypicality of the object to name, and possibly other visual properties, a general name might be more or less appropriate. For instance, a robin can be named “bird”, but a penguin is better referred to as “penguin” (Rosch, 1978); along the same lines, the rather unusual building in Figure 1 that is not easy to otherwise 2 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 categorise was named “structure”","Don’t count, predict! a systematic comparison of context-counting vs | Computational interpretations of the gricean maxims in the generation of referring expressions | Visual dialog | ImageNet: A Large-Scale Hierarchical Image Database | What do you know about an alligator when you know the company it keeps? Semantics and Pragmatics 9(17):1–63 | Visual information in semantic representation | Devise: A deep visualsemantic embedding model | From the virtual to the real world: Referring to objects in real-world spatial scenes | The IAPR TC-12 benchmark: a new evaluation resource for visual information systems | Natural language object retrieval | Learning Image Embeddings using Convolutional Neural Networks for Improved Multi-Modal Semantics | Visual word2vec (vis-w2v): Learning visually grounded word embeddings using abstract scenes | Computational generation of referring expressions: A survey | Learning to detect unseen object classes by between-class attribute transfer | Attribute-based classification for zero-shot visual object categorization | Is this a wampimuk? Cross-modal mapping between distributional semantics and the visual world | Hubness and pollution: Delving into cross-space mapping for zero-shot learning | Combining language and vision with a multimodal skip-gram model | The time course of lexical access | Generation and comprehension of unambiguous object descriptions | Distributed representations of words and phrases and their compositionality | Zero-shot learning by convex combination of semantic embeddings | Learning to name objects | Principles of Categorization | Grounding words in perception and action: Computational insights | A trainable spoken language understanding system for visual object selection | Learning visually-grounded words and syntax for a scene description task | Resolving references to objects in photographs using the words-as-classifiers model | Learning grounded meaning representations with autoencoders | Zero-shot learning through cross-modal transfer | Going deeper with convolutions | From frequency to meaning: Vector space models of semantics | Easy things first: Installments improve referring expression generation for objects in photographs",acl,100
49.pdf.json,Chunk-based Decoder for Neural Machine Translation,"Neural machine translation (NMT) performs an end-to-end translation based on a simple encoderdecoder model (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014; Cho et al., 2014b), and now has overwhelmed the classical, complex statistical machine translation (SMT) (Sennrich et al., 2016; Luong and Manning, 2016; Cromieres et al., 2016; Neubig, 2016). In NMT, an encoder first maps a source sequence into vector representations and a decoder then maps the vectors into a target sequence (§ 2). This simple framework allows researchers to incorporate the structure of the source sentence as in SMT by leveraging various architectures as the encoder (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014; Cho et al., 2014b; Eriguchi et al., 2016b). Most of the NMT models, however, still rely on a sequential decoder based on recurrent neural network (RNN), due to the difficulty in capturing the structure of a target sentence that is unseen during translation. With the sequential decoder, however, there are two problems to be solved. First, it is difficult to model long-distance dependencies (Bahdanau et al., 2015). A hidden state ht in an RNN is only conditioned by its previous output yt−1, previous hidden state ht−1 and current input xt. This makes it difficult to capture the dependencies between an older output yt−N if they are too far from the current output. This problem can become more serious when the target sequence become longer. For example in Figure 1, when one translates the English sentence into the Japanese one, after the decoder predicts the content word “噛ま (bite)”, it has to predict five function words “れ (passive)”, “た (past)”, “そう (hearsay)”, “だ (positive)”, and “けれど (but)” and a punctuation mark “、” before predicting the next content word “君 (you)”. In such a case, the decoder is required to capture the longer dependencies in a target sentence. Another problem with the sequential decoder is that it is expected to cover possible word orders simply by mem","Parsing by chunks | Neural machine translation by jointly learning to align and translate | On the properties of neural machine translation: Encoder–decoder approaches | Learning phrase representations using RNN encoder–decoder for statistical machine translation | Kyoto university participation to WAT 2016 | Character-based decoding in treeto-sequence attention-based neural machine translation | Tree-to-sequence attentional neural machine translation | Parallel implementations of word alignment tool | Maxout networks | Kokugoho Yosetsu | Automatic evaluation of translation quality for distant language pairs | Recurrent continuous translation models | Chunk-based EBMT | Statistical phrase-based translation | A hierarchical approach for generating descriptive image paragraphs | A hierarchical neural autoencoder for paragraphs and documents | System description of bjtu nlp neural machine translation system | Hierarchical recurrent neural network for document modeling | Achieving open vocabulary neural machine translation with hybrid word-character models | Addressing the rare word problem in neural machine translation | Bunsetsu identification using category-exclusive rules | ASPEC: Asian scientific paper excerpt corpus | Lexicons and minimum risk training for neural machine translation: NAISTCMU at WAT2016 | Neural reranking improves subjective quality of machine translation: NAIST at WAT2015 | Pointwise prediction for robust, adaptable Japanese morphological analysis | A systematic comparison of various statistical alignment models | Bleu: a method for automatic evaluation of machine translation | How to construct deep recurrent neural networks | Edinburgh neural machine translation systems for WMT 16 | A hierarchical latent variable encoder-decoder model for generating dialogues | Lattice-based recurrent neural network encoders for neural machine translation | Sequence to sequence learning with neural networks | Improved semantic representations from tree-structured long short-term memory networks | Chunk-based statistical translation | A self-adaptive classifier for efficient text-stream processing | Video paragraph captioning using hierarchical recurrent neural networks | ADADELTA: An adaptive learning rate method",acl,100
494.pdf.json,Morph-fitting: Fine-Tuning Word Vector Spaces with Simple Language-Specific Rules,"Word representation learning has become a research area of central importance in natural language processing (NLP), with its usefulness demonstrated across many application areas such as parsing (Chen and Manning, 2014), machine translation (Zou et al., 2013), and many others (Turian et al., 2010; Collobert et al., 2011). Most promi- nent word representation techniques are grounded in the distributional hypothesis, relying on word co-occurrence information in large textual corpora (Curran, 2004; Turney and Pantel, 2010; Mikolov et al., 2013; Mnih and Kavukcuoglu, 2013; Levy and Goldberg, 2014; Schwartz et al., 2015, i.a.). Morphologically rich languages, in which “substantial grammatical information. . . is expressed at word level” (Tsarfaty et al., 2010), pose specific challenges for NLP. This is not always considered when techniques are evaluated on languages such as English or Chinese, which do not have rich morphology. In the case of distributional vector space models, morphological complexity brings two challenges to the fore: 1. Estimating Rare Words: A single lemma can have many different surface realisations. Naively treating each realisation as a separate word leads to sparsity problems and a failure to exploit their shared semantics. On the other hand, lemmatising the entire corpus can obfuscate the differences that exist between different word forms even though they share some aspects of meaning. 2. Embedded Semantics: Morphology can encode semantic relations such as antonymy (e.g. literate and illiterate, expensive and inexpensive) or synonymy (north, northern, northerly). In this work, we tackle the two challenges jointly by introducing a resource-light vector space finetuning procedure termed morph-fitting. The proposed method does not require curated knowledge bases or gold lexicons. Instead, it makes use of the observation that morphology implicitly encodes semantic signals pertaining to synonymy (e.g., German word inflections katalanisch, katalanisc","Polyglot: Distributed word representations for multilingual NLP | Enriching morphologically poor languages for statistical machine translation | The CELEX lexical data base on CD-ROM | Tailoring continuous word representations for dependency parsing | Don’t count, predict! A systematic comparison of contextcounting vs | Morphological priors for probabilistic neural word embeddings | Knowledge-powered deep learning for word embedding | Compositional morphology for word representations and language modelling | Multimodal distributional semantics | A joint model for word embedding and word morphology | A fast and accurate dependency parser using neural networks | Natural language processing (almost) from scratch | Morphological word-embeddings | Joint semantic synthesis and morphological analysis of the derived word | Morphological smoothing and extrapolation of word embeddings | Unsupervised models for morpheme segmentation and morphology learning | From Distributional to Semantic Similarity | Improving zero-shot learning by mitigating the hubness problem | Learning character-level representations for part-of-speech tagging | Adaptive subgradient methods for online learning and stochastic optimization | Representing multilingual data as linked data: The case of BabelNet 2.0 | Retrofitting word vectors to semantic lexicons | Improving vector space word representations using multilingual correlation | Placing search in context: The concept revisited | An Introduction to Language, 10th Edition | PPDB: The Paraphrase Database | SimVerb3500: A large-scale evaluation set of verb similarity | Understanding morphology | The Second Dialog State Tracking Challenge | The Third Dialog State Tracking Challenge | Word-based dialog state tracking with recurrent neural networks | SimLex-999: Evaluating semantic models with (genuine) similarity estimation | Ontologically grounded multi-sense representation learning for semantic vector space models | Specializing word embeddings for similarity or relatedness | Character-aware neural language models | Compositionally derived representations of morphologically complex words in distributional semantics | Recipe for building robust spoken dialog state trackers: Dialog State Tracking Challenge system description | Separated by an un-common language: Towards judgment language informed vector space modeling | Dependency-based word embeddings | Finding function in form: Compositional character models for open vocabulary word representation | Gated end-to-end memory networks | Learning semantic word embeddings based on ordinal knowledge constraints | Bilingual word representations with monolingual quality in mind | Better word representations with recursive neural networks for morphology | Context2vec: Learning generic context embedding with bidirectional LSTM | Distributed representations of words and phrases and their compositionality | Learning word embeddings efficiently with noise-contrastive estimation | Multidomain dialog state tracking using recurrent neural networks | Neural Belief Tracker: Data-driven dialogue state tracking | Counter-fitting word vectors to linguistic constraints | Rectified linear units improve restricted Boltzmann machines | BabelNet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network | Integrating distributional lexical contrast into word embeddings for antonymsynonym distinction | Encoding prior knowledge with eigenword embeddings | PPDB 2.0: Better paraphrase ranking, finegrained entailment relations, word embeddings, and style classification | Glove: Global vectors for word representation | Co-learning of word representations and morpheme representations | Knowledge-free induction of inflectional morphologies | Symmetric pattern based word embeddings for improved word similarity prediction | Symmetric patterns and coordinations: Fast and enhanced representations of verbs and adjectives | Unsupervised morphology induction using word embeddings | A languageindependent feature schema for inflectional morphology | Statistical parsing of morphologically rich languages (SPMRL) What, how and whither | Word representations: A simple and general method for semi-supervised learning | From frequency to meaning: vector space models of semantics | Character-word LSTM language models | Is ""universal syntax"" universally useful for learning distributed word representations? In Proceedings of ACL | On the role of seed lexicons in learning bilingual word embeddings | Knowledge graph embedding by translating on hyperplanes | A networkbased end-to-end trainable task-oriented dialogue system | From paraphrase database to compositional paraphrase model and back | Charagram: Embedding words and sentences via character n-grams | The Dialog State Tracking Challenge series: A review | RC-NET: A general framework for incorporating knowledge into word representations | Cognitive User Interfaces | Improving lexical embeddings with semantic knowledge | DErivBase: Inducing and evaluating a derivational morphology resource for German | Bilingual word embeddings for phrase-based machine translation",acl,100
496.pdf.json,What do Neural Machine Translation Models Learn about Morphology?,"Neural network models are quickly becoming the predominant approach to machine translation (MT). Training neural MT (NMT) models can be done in an end-to-end fashion, which is simpler and more elegant than traditional MT systems. Moreover, NMT systems have become competitive with, or better than, the previous state-of-the-art, especially since the introduction of sequence-to-sequence models and the attention mechanism (Bahdanau et al., 2014; Sutskever et al., 2014). The improved translation quality is often attributed to better handling of non-local dependencies and morphology generation (Luong and Manning, 2015; Bentivogli et al., 2016). However, little is known about what and how much these models learn about each language and its features. Recent work has started exploring the role of the NMT encoder in learning source syntax (Shi et al., 2016), but research studies are yet to answer important questions such as: (i) what do NMT models learn about word morphology? (ii) what is the effect on learning when translating into/from morphologically-rich languages? (iii) what impact do different representations (character vs. word) have on learning? and (iv) what do different modules learn about the syntactic and semantic structure of a language? Answering such questions is imperative for fully understanding the NMT architecture. In this paper, we strive towards exploring (i), (ii), and (iii) by providing quantitative, data-driven answers to the following specific questions: • Which parts of the NMT architecture capture word structure? • What is the division of labor between different components (e.g. different layers or encoder vs. decoder)? • How do different word representations help learn better morphology and modeling of infrequent words? • How does the target language affect the learning of word structure? To achieve this, we follow a simple but effective procedure with three steps: (i) train a neural MT system on a parallel corpus; (ii) use the trained model to ext","Fine-grained Analysis of Sentence Embeddings Using Auxiliary Prediction Tasks | Neural Machine Translation by Jointly Learning to Align and Translate | Neural versus PhraseBased Machine Translation Quality: a Case Study | An Arabic-Hebrew parallel corpus of TED talks | WIT3: Web Inventory of Transcribed and Translated Talks | Character-based Neural Machine Translation | Distributed representations, simple recurrent networks, and grammatical structure | From phonemes to images: levels of representation in a recurrent neural model of visually-grounded language learning | Long short-term memory | Exploring the Limits of Language Modeling | Representation of linguistic form and function in recurrent neural networks | Visualizing and Understanding Recurrent Networks | Seq2seq-attn | Character-aware Neural Language Models | Adam: A Method for Stochastic Optimization | Factored Translation Models | Empirical Methods for Compound Splitting | What’s in an Embedding? Analyzing Word Embeddings through Multilingual Evaluation | Stanford Neural Machine Translation Systems for Spoken Language Domains | Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models | A Hybrid Morpheme-Word Representation for Machine Translation of Morphologically Rich | Efficient Higher-Order CRFs for Morphological Tagging | Improving SMT quality with morpho-syntactic analysis | MADAMIRA: A Fast, Comprehensive Tool for Morphological Analysis and Disambiguation | Analyzing Linguistic Knowledge in Sequential Model of Sentence | Investigating Language Universal and Specific Properties in Word Embeddings | Maximum Entropy Models for Natural Language Ambiguity Resolution | Part-of-Speech Tagging with Neural Networks | LoPar: Design and Implementation | Neural Machine Translation | Does String-Based Neural MT Learn Source Syntax? In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing | Sequence to Sequence Learning with Neural Networks | Word Representation Models for Morphologically Rich Languages in Neural Machine Translation | Deep Recurrent Models with Fast-Forward Connections for Neural Machine Translation",acl,100
501.pdf.json,Understanding Image and Text Simultaneously: a Dual Vision-Language Machine Comprehension Task,"There has been a great deal of interest in multimodal artificial intelligence research recently, bringing together the fields of Computer Vision and Natural Language Processing. This interest has been fueled in part by the availability of many large-scale image datasets with textual annotations. Several vision+language tasks have been proposed around these datasets (Hodosh et al., 2013; Karpathy and Fei-Fei, 2015; Lin et al., 2014; Antol et al., 2015). Image Captioning (Hodosh et al., 2013; Donahue et al., 2014; Karpathy and Fei-Fei, 2015; Fang et al., 2015; Kiros et al., 2015; Vinyals et al., 2015; Mao et al., 2015; Xu et al., 2015b) and Visual Question Answering (Malinowski and Fritz, 2014; Malinowski et al., 2015; Tu et al., 2014; Antol et al., 2015; Yu et al., 2015; Wu et al., 2016b; Ren et al., 2015; Gao et al., 2015; Yang et al., 2016; Zhu et al., 2016; Lin and Parikh, 2016) have in particular attracted a lot of attention. The performances on these tasks have been steadily improving, owing much to the wide use of deep learning architectures (Bengio, 2009). A central theme underlying these efforts is the use of natural language to identify how much visual information is perceived and understood by a computer system. Presumably, a system that understands a visual scene well enough ought to be able to describe what the scene is about (thus “captioning”) or provide correct and visuallygrounded answers when queried (thus “questionanswering”). In this paper, we argue for directly measuring how well the semantic representations of the visual and linguistic modalities align (in some abstract semantic space). For instance, given an image and two captions – a correct one and an incorrect yet-cunningly-similar one – can we both qualitatively and quantitatively measure the ex- 2 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 ","TensorFlow: Large-scale machine learning on heterogeneous systems | SPICE: semantic propositional image caption evaluation | VQA: Visual question answering | Neural machine translation by jointly learning to align and translate | METEOR: An automatic metric for MT evaluation with improved correlation with human judgments | Learning deep architectures for ai | Automatic description generation from images: A survey of models, datasets, and evaluation measures | A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task | Learning phrase representations using RNN encoder-decoder for statistical machine translation | Long-term recurrent convolutional networks for visual recognition and description | From captions to visual concepts and back | Devise: A deep visual-semantic embedding model | Are you talking to a machine? dataset and methods for multilingual image question answering | Focused evaluation for image description with binary forced-choice tasks | Framing image description as a ranking task: Data, models and evaluation metrics | Deep visual-semantic alignments for generating image descriptions | Unifying visual-semantic embeddings with multimodal neural language models | Visual Genome: Connecting language and vision using crowdsourced dense image | Distributed representations of sentences and documents | Automatic evaluation of machine translation quality using longest common subsequence and skip-bigram statistics | Microsoft COCO: common objects in context | Leveraging visual question answering for image-caption ranking | A multi-world approach to question answering about real-world scenes based on uncertain input | Ask your neurons: A neural-based approach to answering questions about images | Deep captioning with multimodal recurrent neural networks (mRNN) | Bleu: A method for automatic evaluation of machine translation | Sequence level training with recurrent neural networks | Image question answering: A visual semantic embedding model and a new dataset | Sequence to sequence learning with neural networks | Rethinking the inception architecture for computer vision | Joint video and text parsing for understanding events and answering queries | Cider: Consensus-based image description evaluation | Show and tell: A neural image caption generator | Visual question answering: A survey of methods and datasets | Ask me anything: Free-form visual question answering based on knowledge from external sources | Show, attend and tell: Neural image caption generation with visual attention | Show, attend and tell: Neural image caption generation with visual attention | Stacked attention networks for image question answering | Visual madlibs: Fill-in-theblank description generation and question answering | Visual7w: Grounded question answering in images",acl,100
503.pdf.json,Probabilistic Regular Graph Languages,"NLP systems for machine translation, summarization, paraphrasing, and other problems often fail to preserve the compositional semantics of sentences and documents because they model language as bags of words, or at best syntactic trees. To preserve semantics, they must model semantics. In pursuit of this goal, several datasets have been produced which pair natural language with compositional semantic representations in the form of directed acyclic graphs (DAGs), including the Abstract Meaning Represenation Bank (AMR; Banarescu et al. 2013), the Prague Czech-English Dependency Treebank (Hajič et al., 2012), Deep- bank (Flickinger et al., 2012), and the Universal Conceptual Cognitive Annotation (Abend and Rappoport, 2013). To make use of this data, we require probabilistic models of graphs. Consider how we might use compositional semantic representations in machine translation (Figure 1). We first parse a source sentence to its semantic representation, and then generate a target sentence from this representation. Stated more formally, we first predict a graph G from a source string s, and then predict a target string t from G, giving us a conditional model P(t, G|s), which we can decompose as P(t, G|s) = P(t|G)P(G|s). Jones et al. (2012) observe that this decomposition can be modeled with a pair of probabilistic synchronous grammars over domains of strings and graphs. Given a domain of source strings Ls, a domain of source graphs LG, a domain of target graphs LG′ and a domain of target strings Lt, these grammars define relationsR ⊆ Ls×LG and R′ ⊆ LG′ ×Lt. Translation is then the solution to the following inference problem, given input s: arg max t∈Lt ∑ {G|(s,G)∈R∧(G,t)∈R′} P(t|G)P(G|s) In practical settings the sum over G is typically replaced with an arg max. Either way, we must 2 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 ","Universal conceptual cognitive annotation (ucca) | Pushdown automata in statistical machine translation | Abstract meaning representation for sembanking | On formal properties of simple phrase structure grammars | Hyperedge replacement and nonprojective dependency structures | Between a Rock and a Hard Place – Uniform Parsing for Hyperedge Replacement DAG Grammars, Springer International Publishing, Cham, pages 521–532 | Definability equals recognizability for graphs of bounded treewidth | Applying probability measures to abstract languages | On a decision method in restricted second-order arithmetic | Decision problems of weak second order arithmetic and finite | Parsing graphs with hyperedge replacement grammars | The monadic second-order logic of graphs i | The monadic second-order logic of graphs V: on closing the gap between definability and recognizability | Graph Structure and Monadic Second-Order Logic, a Language Theoretic Approach | Predictive Top-Down Parsing for Hyperedge Replacement Grammars, Springer International Publishing, Cham, pages 19–34 | Hyperedge replacement graph grammars | Weighted Automata and Weighted Logics, Springer Berlin Heidelberg, Berlin, Heidelberg, pages 513–525 | An efficient context-free parsing algorithm | The string generating power of context-free hypergraph grammars | Deepbank : a dynamically annotated treebank of the wall street journal | Confidential Review Copy. DO NOT DISTRIBUTE. Announcing prague czech-english dependency treebank 2.0 | Semanticsbased machine translation with hyperedge replacement grammars | Parallel and two-way automata on directed ordered acyclic graphs | Tree-Like Grammars and Separation Logic, Springer International Publishing, Cham, pages 90–108 | On the complexity analysis of static analyses | Speech recognition with weighted finite-state transducers | A synchronous hyperedge replacement grammar based approach for AMR parsing | Towards probabilistic acceptors and transducers for feature structures | Principles and implementation of deductive parsing | Automata, Languages and Programming: 18th International Colloquium | Finite automata and logic of monadic predicates",acl,100
516.pdf.json,Tandem Anchoring: a Multiword Anchor Approach for Interactive Topic Modeling,,"Topic significance ranking of lda generative models | Incorporating domain knowledge into topic modeling via Dirichlet forest priors | A practical algorithm for topic modeling with provable guarantees | Computing a nonnegative matrix factorization–provably | Latent dirichlet allocation | Utopian: User-driven topic modeling based on interactive nonnegative matrix factorization | Termite: Visualization techniques for assessing textual topic models | Illuminating the path: The research and development agenda for visual analytics | Tests for departure from normality. empirical results for the distributions of b2 and b1 | The topic browser: An interactive tool for browsing topic models | Online learning for latent dirichlet allocation | Stochastic variational inference | Efficient tree-based topic modeling | Interactive topic modeling | Comparing clusterings by the variation of information | Automatic evaluation of topic coherence | The author-topic model for authors and documents | Statistical topic models for multi-label document classification | A joint model of text and aspect ratings for sentiment summarization | Lda-based document models for ad-hoc retrieval | Individual comparisons by ranking methods | Details of the adjusted rand index and clustering algorithms, supplement to the paper an empirical study on principal component analysis for clustering gene expression data",acl,100
520.pdf.json,,"Deep learning methods have had a major impact on research in natural language processing and raised performance substantially in many of the standard evaluations. Moreover, multimodal tasks like image captioning (Karpathy and Li, 2015) or visual question answering (Antol et al., 2015) can now be tackled with great success. Such systems seem to solve the problems entirely on a sub-symbolic level, based only on raw image (and text) input, whereas previous approaches required a hand-crafted combination of various higher-level components. There is, however, concern about how deep neural networks learn to solve such tasks. Investigations for image recognition (Szegedy et al., 2014; Nguyen et al., 2015; Zhang et al., 2017) have shown surprising behavior very different from what would be expected of their “surpassing human-level performance” (He et al., 2015). Deep networks for language tasks may exhibit similarly odd behavior (Sproat and Jaitly, 2016; Arthur et al., 2016). Such results cast doubt on whether deep learning systems reliably acquire appropriate generalizations. However, given the recursive nature of language and the potentially enormous problem space of image captioning and similar tasks, acquiring the ability for reliable generalization will eventually be essential. A more theoretical issue is the capability of network architectures to be able, in principle, to learn certain classes of structure. For instance, it has been shown that LSTMs possess the ability to handle long-range dependencies (Hochreiter and Schmidhuber, 1997; Gers and Schmidhuber, 2001). However, the formal experiments that have been done along such lines are limited, particularly in the multimodal domain of vision and language. While recent work indicates that the information encoded in image embeddings is rich enough for good captioning results, it is an open question whether current multimodal architectures are able, in principle, to combine visual information effectively to handle the fu","VQA: Visual question answering | Incorporating discrete translation lexicons into neural machine translation | Learning long-term dependencies with gradient descent is difficult | Recursive neural networks can learn logical semantics | OpenAI Gym | Resources for building applications with Dependency Minimal Recursion Semantics | On building a more efficient grammar by exploiting types | LSTM recurrent networks learn simple context-free and context-sensitive languages | Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification | Long short-term memory | Focused evaluation for image description with binary forcedchoice tasks | The Malmo platform for artificial intelligence experimentation | Inferring algorithmic patterns with stack-augmented recurrent nets | Deep visualsemantic alignments for generating image descriptions | Virtual embodiment: A scalable long-term strategy for artificial intelligence research | Backpropagation applied to handwritten zip code recognition | A roadmap towards machine intelligence | English as a formal language | Language understanding for textbased games using deep reinforcement learning | Deep neural networks are easily fooled: High confidence predictions for unrecognizable images | The meaning of ’most’: Semantics, numerosity and psychology | Image question answering: A visual semantic embedding model and a new dataset | Look, some green circles!”: Learning to quantify from images | RNN Approaches to Text Normalization: A Challenge | MazeBase: A sandbox for learning from games | Intriguing properties of neural networks | Pointer networks | Towards AI-complete question answering: A set of prerequisite toy tasks | Learning to execute | Understanding deep learning requires rethinking generalization | Bringing semantics into focus using visual abstraction | Adopting abstract images for semantic scene understanding",acl,100
524.pdf.json,A Comparison of Robust Parsing Methods for HPSG,"Head-driven Phrase Structure Grammar (Pollard and Sag, 1994) is a constraint-based grammar formalism that combines linguistically motivated descriptive mechanisms with precise and computationally tractable logical and combinatorial properties. The design goals for computational language systems generally include the following (doubtless in addition to many others): 1. coverage — all naturally-occurring inputs can be analyzed 2. precision — only naturally-occurring inputs can be analyzed1 3. efficiency — analysis happens quickly 4. semantic competence — meaning2 is pre- served and made explicit 5. succinctness — knowledge embodied by the system is well-organized The relative priority of these goals tends to differ from one system to the next, however. Whereas many system designers will rank coverage and perhaps efficiency as the most important of these five desiderata, most HPSG grammarians would rank precision, semantic competence, and possibly succinctness higher (Flickinger, 2011). 1Or inputs that could reasonably be expected to occur in some natural context. 2By this is meant that portion of the meaning of an input which is of specific interest to the system in question. While this is not the place to expound at length on the motivation for a precision grammar, it is perhaps instructive to mention two important benefits: first, by excluding analyses of strings that the grammarian judges to be outside of the language in question, the problem of spurious ambiguity is typically greatly reduced for strings that are grammatical. Second, precision is a prerequisite to bidirectionality, enabling both parsing and generation. A system that cannot differentiate between strings that are in a language and those that are not cannot be used in this way. The relatively low priority assigned to coverage in many HPSG-based computational linguistics projects is a natural corollary of the premium placed on precision, together with the Zipfian distribution of language. However, give",Some fine points of hybrid natural language parsing | Arboretum. Using a precision grammar for grammar checking in CALL | Minimal recursion semantics: An introduction | Ubertagging: Joint segmentation and supertagging for English | On building a more efficient grammar by exploiting types. Natural Language Engineering 6(01):15–28 | Accuracy v. Robustness in grammar engineering | Robust parsing in HPSG: Bridging the coverage chasm | Constraint relaxation with weighted feature structures | Robust processing for constraint-based grammar formalisms | Computational Analysis of Present-Day | Ambiguity packing in constraint-based parsing. Practical results | LinGO Redwoods: A rich and dynamic treebank for HPSG | Head-Driven Phrase Structure Grammar. Studies in Contemporary Linguistics | Large-scale corpus-driven PCFG approximation of an HPSG,acl,100
543.pdf.json,Learning Character-level Compositionality with Visual Features,"Compositionality—the fact that the meaning of larger linguistic units is created by combining the meaning of smaller units—is a hallmark of every natural language (Szabó, 2010). Recently, neural models have provided a powerful tool for learning how to compose words together into a meaning representation of whole sentences for many downstream tasks. This is done using models of various levels of sophistication, from simpler bag-ofwords (Iyyer et al., 2015) and linear recurrent neural network (RNN) models (Sutskever et al., 2014; Kiros et al., 2015), to more sophisticated models Kalb Kälbera Do Do'(polite) Calf CalvesLaurel Whale Salmon Salmon gui jing gui gui (a) (b) (c) (d) han'da ham''ni'''da using tree-structured (Socher et al., 2013) or convolutional networks (Kalchbrenner et al., 2014). In fact, a growing body of evidence shows that it is essential to look below the word-level and consider compositionality within words themselves. For example, several works have proposed models that represent words by composing together the characters into a representation of the word itself (Ling et al., 2015; Zhang et al., 2015; Dhingra et al., 2016). Additionally, for languages with productive word formation (such as agglutination and compounding), models calculating morphologysensitive word representations have been found effective (Luong et al., 2013; Botha and Blunsom, 2014). Thesemodels help to learnmore robust representations for rare words by exploiting morphological patterns, as opposed to models that operate purely on the lexical level as the atomic units. For many languages, compositionality stops at the character-level: characters are atomic units of meaning or pronunciation in the language, and no further decomposition can be done.1 However, for other languages, character-level compositionality, where a character’s meaning or pronunciation 1In English, for example, this is largely the case. 2 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 1","Compositional morphology for word representations and language modelling | Empirical evaluation of gated recurrent neural networks on sequence modeling | Torch: A modular machine learning software | Advances in neural information processing systems | The world’s writing systems | Domain adaptation for machine translation by mining unseen words | What you get is what you see: A visual markup decompiler | Tweet2vec: Character-based distributed representations for social media | Multilingual language processing from bytes | Four techniques for online handling of out-of-vocabulary words in Arabic-English statistical machine translation | Deep unordered composition rivals syntactic methods for text classification | A convolutional neural network for modelling sentences | Large-scale video classification with convolutional neural networks | Exploiting Wikipedia as external knowledge for named entity recognition | Convolutional neural networks for sentence classification | Adam: A method for stochastic optimization | Skip-thought vectors | Finding function in form: Compositional character models for open vocabulary word representation | Achieving open vocabulary neural machine translation with hybrid word-character models | Better word representations with recursive neural networks for morphology | Distributed representations of words and phrases and their compositionality | Power laws, Pareto distributions and Zipf’s law | Design challenges and misconceptions in named entity recognition | Neural machine translation of rare words with subword units | Radical embedding: Delving deeper to chinese radicals | Early versus late fusion in semantic video analysis | Recursive deep models for semantic compositionality over a sentiment treebank | Sequence to sequence learning with neural networks | Compositionality | A proposal to automatically build and maintain gazetteers for named entity recognition by using wikipedia | Cnn-rnn: A unified framework for multi-label image classification | Show, attend and tell: Neural image caption generation with visual attention | Visualizing and understanding convolutional networks | Character-level convolutional networks for text classification | Visual7w: Grounded question answering in images",acl,100
553.pdf.json,,"Natural language is almost always used in a particular context (e.g., a particular time, location, or purpose), and thus the interpretation of a sentence, phrase, or word inherently depends on this context. Indeed, the whole subject area of pragmatics studies the ways in which context contributes meaning1. In this paper, we are interested in analyzing the variations of term meaning in different–but comparable–contexts and propose a general framework for performing cross-context lexical analysis (CCLA). We use CCLA to generally refer to any analysis of term meaning or term representation in different contexts, especially for understanding the differences and similarities in multiple contexts. Due to the generality of the notion of context, CCLA can be useful in many ways. For example, when context is defined as the time period a piece of text is written, CCLA allows us to compare the 1https://en.wikipedia.org/wiki/ Pragmatics meaning of a word in different periods and reveal how a word may have evolved over time (Hamilton et al., 2016). If context is defined as location, it would allow us to study variations in the meaning of a word over different locations, potentially revealing influences of some locations on others (Kulkarni et al., 2016). In general, we can use any associated attribute values of text data—including metadata—as context to form a partition. For example, the institution of a research article’s author can be used as a “context variable” to partition the articles based on institutions or regions in the world of their authors. Any meaningful partitioning of text data may also be regarded as implicitly defining a context value for each partition; sentiment analysis may allow us to define a sentiment context so positive and negative sentences would be regarded as belonging to different categories. We can characterize any term in a specific context by its similarity to other terms in corresponding contexts. The similarity can be computed in many ways, inc","Distributional Semantics in Technicolor | Differential Topic Models | The Corpus of Contemporary American English as the First Reliable Monitor Corpus of English | Problems With Evaluation of Word Embeddings Using Word Similarity Tasks | Diachronic Word Embeddings Reveal Statistical Laws of Semantic Change | Temporal Analysis of Language through Neural Language Models | Statistically Significant Detection of Linguistic Change | Freshman or Fresher? Quantifying the Geographic Variation of Language in Online Social Media | Neural Word Embedding as Implicit Matrix Factorization | Improving Distributional Similarity with Lessons Learned from Word Embeddings | Better Word Representations with Recursive Neural Networks for Morphology | Learning Word Vectors for Sentiment Analysis | A Probabilistic Approach to Spatiotemporal Theme Pattern Mining on Weblogs | A Mixture Model for Contextual Text Mining | Efficient Estimation of Word Representations in Vector Space | Distributed Representations of Words and Phrases and their Compositionality | Linguistic Regularities in Continuous Space Word Representations | Topic Models Conditioned on Arbitrary Features with Dirichlet-multinomial Regression | A Comparison of Domain-based Word Polarity Estimation using different Word Embeddings | GloVe: Global Vectors for Word Representation | Lexical Comparison Between Wikipedia and Twitter Corpora by Using Word Embeddings | Who, Where, when and What: Discover Spatio-temporal Topics for Twitter Users | A Cross-collection Mixture Model for Comparative Text Mining",acl,100
554.pdf.json,Scalable Bayesian Learning of Recurrent Neural Networks for Language Modeling,"Language modeling is a fundamental task, used for example to predict the next word or character in a text sequence given the context. Recently, recurrent neural networks (RNNs) have shown promising performance on this task (Mikolov et al., 2010; Sutskever et al., 2011). RNNs with Long Short-Term Memory (LSTM) units (Hochreiter and Schmidhuber, 1997) have emerged as a popular architecture, due to their representational power and effectiveness at capturing long-term dependencies. RNNs are usually trained via back-propagation through time (Werbos, 1990), using stochastic optimization methods such as stochastic gradient de- scent (SGD) (Robbins and Monro, 1951); stochastic methods of this type are particularly important for training with large data sets. However, this approach often provides a maximum a posteriori (MAP) estimate of model parameters. The MAP solution is a single point estimate, ignoring weight uncertainty (Blundell et al., 2015; HernándezLobato and Adams, 2015). Natural language often exhibits significant variability, and hence such a point estimate may make over-confident predictions on test data. To alleviate overfitting RNNs, good regularization is known as a key factor to successful applications. In the neural network literature, Bayesian learning has been proposed as a principled method to impose regularization and incorporate model uncertainty (MacKay, 1992; Neal, 1995), by imposing prior distributions on model parameters. Due to the intractability of posterior distributions in neural networks, Hamiltonian Monte Carlo (HMC) (Neal, 1995) has been used to provide sample-based approximations to the true posterior. Despite the elegant theoretical property of asymptotic convergence to the true posterior, HMC and other conventional Markov Chain Monte Carlo methods are not scalable to large training sets. This paper seeks to scale up Bayesian learning of RNNs to meet the challenge of the increasing amount of “big” sequential data in natural language proc","Meteor: An automatic metric for mt evaluation with improved correlation with human judgments | On fast dropout and its applicability to recurrent networks | Where to apply dropout in recurrent neural networks for handwriting recognition? In ICDAR | Weight uncertainty in neural networks | Large-scale machine learning with stochastic gradient descent | Bridging the gap between stochastic gradient MCMC and stochastic optimization | On the convergence of stochastic gradient MCMC algorithms with high-order integrators | Stochastic gradient Hamiltonian Monte Carlo | Microsoft coco captions: Data collection and evaluation server | Learning phrase representations using RNN encoder-decoder for statistical machine translation | Empirical evaluation of gated recurrent neural networks on sequence modeling | Bayesian sampling using stochastic gradient thermostats | Adaptive subgradient methods for online learning and stochastic optimization | Dropout as a Bayesian approximation: Representing model uncertainty in deep learning | A theoretically grounded application of dropout in recurrent neural networks | Practical variational inference for neural networks | Deep residual learning for image recognition | Probabilistic backpropagation for scalable learning of Bayesian neural networks | Improving neural networks by preventing co-adaptation of feature detectors | Long shortterm memory | Framing image description as a ranking task: Data, models and evaluation metrics | Mining and summarizing customer reviews | Visualizing and understanding recurrent networks | Adam: A method for stochastic optimization | Variational dropout and the local reparameterization trick | Skip-thought vectors | Bayesian dark knowledge | Preconditioned stochastic gradient Langevin dynamics for deep neural networks | Learning weight uncertainty with stochastic gradient MCMC for shape classification | Learning question classifiers | Rouge: A package for automatic evaluation of summaries | A practical Bayesian framework for backpropagation networks | Building a large annotated corpus of english: The penn treebank | Recurrent neural network based language model | Rnndrop: A novel dropout for rnns in asr | Bayesian learning for neural networks | Adding gradient noise improves learning for very deep networks | Regularization and nonlinearities for neural language models: when are they needed | A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts | Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales | Bleu: a method for automatic evaluation of machine translation | On the difficulty of training recurrent neural networks | Dropout improves recurrent neural networks for handwriting recognition | A stochastic approximation method | Recurrent dropout without memory loss | Dropout: A simple way to prevent neural networks from overfitting | Generating text with recurrent neural networks | Consistency and fluctuations for stochastic gradient Langevin dynamics | Theano: A Python framework for fast computation of mathematical expressions | Lecture 6.5rmsprop: Divide the gradient by a running average of its recent magnitude. Coursera: Neural Networks for Machine Learning | Visualizing data using t-SNE | Cider: Consensus-based image description evaluation | Show and tell: A neural image caption generator | Regularization of neural networks using DropConnect | Fast Dropout training | Bayesian learning via stochastic gradient Langevin dynamics | Backpropagation through time: what it does and how to do it | Annotating expressions of opinions and emotions in language | From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions | Recurrent neural network regularization",acl,100
557.pdf.json,End-to-End Neural Relation Extraction with Global Optimization,"Extracting entities (Florian et al., 2006, 2010) and relations (Zhao and Grishman, 2005; Jiang and Zhai, 2007; Sun et al., 2011; Plank and Moschitti, 2013) from unstructured texts have been two central tasks in information extraction (Grishman, 1997; Doddington et al., 2004). Traditional approaches to relation extraction take entity recognition as a predecessor step in a pipeline (Zelenko et al., 2003; Chan and Roth, 2011), predicting relations between given entities. In recent years, there has been a surge of interest in performing end-to-end relation extraction, jointly recognizing entities and relations given free text inputs (Li and Ji, 2014; Miwa and Sasaki, 2014; Miwa and Bansal, 2016; Gupta et al., 2016). End-to-end learning prevents error propagation in the pipeline approach, and allows cross-task dependencies to be modeled explicitly for entity recognition. As a result, it gives better relation extraction accuracies compared to pipelines. Miwa and Bansal (2016) were among the first to use neural networks for end-to-end relation extraction, showing highly promising results. In particular, they used a bidirectional LSTM (Graves et al., 2013) to learn hidden word representations under a sentential context, and further leveraged a tree-structured LSTMs (Tai et al., 2015) to encode syntactic information, given the output of a parser. The resulting representations are then used for making local decisions for entity and relation extraction incrementally, leading to much improved results compared with the best statistical model (Li and Ji, 2014). This demonstrates the strength of neural representation learning for endto-end relation extraction. On the other hand, Miwa and Bansal (2016)’s model is trained locally, without considering structural correspondences between incremental decisions. This is unlike existing statistical methods, which utilize well-studied structured prediction methods to address the problem (Li and Ji, 2014; Miwa and Sasaki, 2014). As has been","Globally normalized transition-based neural networks | Improved transition-based parsing by modeling characters instead of words with lstms | Scheduled sampling for sequence prediction with recurrent neural networks | A shortest path dependency kernel for relation extraction | Generative incremental dependency parsing with neural networks | Exploiting background knowledge for relation extraction | Exploiting syntactico-semantic structures for relation extraction | Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms | Incremental parsing with the perceptron algorithm | Span-based constituency parsing with a structure-label system and provably optimal dynamic oracles | Dependency tree kernels for relation extraction | The automatic content extraction (ace) program-tasks, data, and evaluation | Deep convolutional neural networks for sentiment analysis of short texts | Deep biaffine attention for neural dependency parsing | Transitionbased dependency parsing with stack long shortterm memory | A statistical model for multilingual entity detection and tracking | Factorizing complex models: A case study in mention detection | Improving mention detection robustness to noisy input | Speech recognition with deep recurrent neural networks | Information extraction: Techniques and challenges | Table filling multi-task recurrent neural network for joint entity and relation extraction | Bidirectional lstm-crf models for sequence tagging | Improving name tagging by reference resolution and relation detection | A systematic exploration of the feature space for relation extraction | Adam: A method for stochastic optimization | Simple and accurate dependency parsing using bidirectional lstm feature representations | Charner: Character-level named entity recognition | Conditional random fields: Probabilistic models for segmenting and labeling sequence data | Neural architectures for named entity recognition | When are tree structures necessary for deep learning of representations? In Proceedings of the EMNLP | Incremental joint extraction of entity mentions and relations | Neural relation extraction with selective attention over instances | Distributed training strategies for the structured perceptron | End-to-end relation extraction using lstms on sequences and tree structures | A rich feature vector for protein-protein interaction extraction from multiple corpora | Modeling joint entity and relation extraction with table representation | Embedding semantic similarity in tree kernels for domain adaptation of relation extraction | Clusteringbased stratified seed sampling for semi-supervised relation classification | Exploiting constituent dependencies for tree kernel-based semantic relation extraction | Design challenges and misconceptions in named entity recognition | A linear programming formulation for global inference in natural language tasks | Global inference for entity and relation identification via a linear programming formulation | Semi-supervised relation extraction with large-scale word clustering | Improved semantic representations from tree-structured long short-term memory networks | Context-sensitive lexicon features for neural sentiment analysis | Multilingual relation extraction using compositional universal schema | Combining recurrent and convolutional neural networks for relation classification | Graph-based dependency parsing with bidirectional lstm | Transitionbased neural constituent parsing | Sequence-to-sequence learning as beam-search optimization | Lstm shift-reduce ccg parsing | Classifying relations via long short term memory networks along shortest dependency paths | Kernel methods for relation extraction | Syntactic processing using the generalized perceptron and beam search | Extracting relations with integrated information using kernel methods | Exploring various knowledge in relation extraction | Tree kernel-based relation extraction with context-sensitive structured parse tree information | A neural probabilistic structuredprediction model for transition-based dependency parsing",acl,100
56.pdf.json,Ngram2vec: Learning Improved Word Representations from Ngram Co-occurrence Statistics,"Recently, deep learning approaches have achieved state-of-the-art results on a range of NLP tasks. One of the most fundamental work in this field is word embedding, where low-dimensional word representations are learned from unlabeled corpus. The trained word embeddings reflect semantic and syntactic information of words. They are not only useful in tasks of lexical semantics (e.g. finding similar words), but also widely used as the input of the downstream tasks, such as text classification (Kim, 2014) and tagging (Collobert et al., 2011; Pennington et al., 2014). Word2vec is one of the most popular word embedding models (Mikolov et al., 2013b,a). It is trained upon <word, context> pairs in the local window. Word2vec gains the reputation by its amazing effectiveness and efficiency. It achieves state-of-the-art results on a range of linguistic tasks with only a fraction of time compared with previous techniques. A challenger of word2vec is GloVe (Pennington et al., 2014). Instead of training on <word, context> pairs, GloVe directly uses word co-occurrence matrix. They claim that the change brings the improvement over word2vec on both accuracy and speed. Levy and Goldberg (2014b) further reveal that the attractive properties observed in word embeddings are not restricted to neural models. They use traditional bag-ofcontexts (concretely, PPMI matrix) to represent words, and achieve comparable results with the above neural embedding models. The relationships among different representation methods are intricate. A preliminary conclusion is obtained in (Levy et al., 2015), which states that none of them consistently outperform the other methods. One should not feel surprised with the conclusion, because these methods all exploit word co-occurrence statistics as the information source and no one goes beyond that. To learn improved word representations, we extend the information source from co-occurrence of ‘wordword’ type to co-occurrence of ‘ngram-ngram’ type. The idea of","A neural probabilistic language model | A convolutional neural network for modelling sentences | Natural language processing (almost) from scratch | Indexing by latent semantic analysis | Fast, easy, and cheap: Construction of statistical machine translation models with | Retrofitting word vectors to semantic lexicons | Convolutional neural network architectures for matching natural language sentences | Effective use of word order for text categorization with convolutional neural networks | Estimation of probabilities from sparse data for the language model component of a speech recognizer | Convolutional neural networks for sentence classification | Improved backing-off for m-gram language modeling | Dependencybased word embeddings | Linguistic regularities in sparse and explicit word representations | Neural word embedding as implicit matrix factorization | Improving distributional similarity with lessons learned from word embeddings | Weighted neural bag-of-n-grams model: New baselines for text classification | Word embedding revisited: A new representation learning and explicit matrix factorization perspective | Scalable language processing algorithms for the masses: A case study in computing word co-occurrence matrices with mapreduce | Efficient estimation of word representations in vector space | Distributed representations of words and phrases and their compositionality | Glove: Global vectors for word representation | Evaluation methods for unsupervised word embeddings | Learning to rank short text pairs with convolutional deep neural networks | Unsupervised morphology induction using word embeddings | Inside out: Two jointly predictive models for word representations and phrase representations | A unified learning framework of skip-grams and global vectors | Cluster-driven model for improved word and text embedding",acl,100
561.pdf.json,Semi-supervised sequence tagging with bidirectional language models,"Due to their simplicity and efficacy, pre-trained word embedding have become ubiquitous in NLP systems. Many prior studies have shown that they capture useful semantic and syntactic information (Mikolov et al., 2013; Pennington et al., 2014) and including them in NLP systems has been shown to be enormously helpful for a variety of downstream tasks (Collobert et al., 2011). However, in many NLP tasks it is essential to represent not just the meaning of a word, but also the word in context. For example, in the two phrases “A Central Bank spokesman” and “The Central African Republic”, the word ‘Central’ is used as part of both an Organization and Location. Accordingly, current state of the art sequence tagging models typically include a bidirectional re- current neural network (RNN) that encodes token sequences into a context sensitive representation before making token specific predictions (Yang et al., 2017; Ma and Hovy, 2016; Lample et al., 2016; Hashimoto et al., 2016). Although the token representation is initialized with pre-trained embeddings, the parameters of the bidirectional RNN are typically learned only on labeled data. Previous work has explored methods for jointly learning the bidirectional RNN with supplemental labeled data from other tasks (e.g., Søgaard and Goldberg, 2016; Yang et al., 2017). In this paper, we explore an alternate semisupervised approach which does not require additional labeled data. We use a neural language model (LM) pre-trained on a large, unlabeled corpus to compute an encoding of the context at each position in the sequence (hereafter an LM embedding) and use it in the supervised sequence tagging model. Since the LM embeddings are used to compute the probability of future words in a neural LM, they are likely to encode both the semantic and syntactic roles of words in context. Our main contribution is to show that the context sensitive representation captured in the LM embeddings is useful in the supervised sequence tagging sett",A highperformance semi-supervised learning method for text chunking | A neural probabilistic language model | Combining labeled and unlabeled data with co-training | One billion word benchmark for measuring progress in statistical language modeling | Named entity recognition with bidirectional lstmcnns | On the properties of neural machine translation: Encoder-decoder approaches | Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms | Natural language processing (almost) from scratch | Fast and robust neural network joint models for statistical machine translation | Bidirectional language model for handwriting recognition | A joint many-task model: Growing a neural network for multiple nlp tasks | Learning distributed representations of sentences from unlabelled data | Long short-term memory | Exploring the limits of language modeling | Recurrent continuous translation models | Visualizing and understanding recurrent networks | Adam: A method for stochastic optimization | Skip-thought vectors | Statistical machine translation | Conditional random fields: Probabilistic models for segmenting and labeling sequence data | Neural architectures for named entity recognition | Distributed representations of sentences and documents | Semi-supervised sequence modeling with syntactic topic models | Assessing the ability of lstms to learn syntaxsensitive dependencies | Joint entity recognition and disambiguation | End-to-end sequence labeling via bi-directional lstm-cnns-crf | Recurrent neural network based language model | Distributed representations of words and phrases and their compositionality | Syntax-based semi-supervised named entity tagging | Text classification from labeled and unlabeled documents using em | Glove: Global vectors for word representation | A bidirectional recurrent neural language model for machine translation | Limitations of co-training for natural language learning from large datasets | Design challenges and misconceptions in named entity recognition | Long short-term memory recurrent neural network architectures for large scale acoustic modeling | Introduction to the conll-2000 shared task chunking | Introduction to the conll-2003 shared task: Language-independent named entity recognition | Semi-supervised learning and domain adaptation in natural language processing | Deep multi-task learning with low level tasks supervised at lower layers | Semi-supervised structured output learning based on a hybrid generative and discriminative approach | Semi-supervised sequential labeling and segmentation using gigaword scale unlabeled data | Transfer learning for sequence tagging with hierarchical recurrent networks,acl,100
562.pdf.json,Zero-Shot Relation Extraction via Reading Comprehension,"Relation extraction systems populate knowledge bases with facts (relations) from an unstructured text corpus. When the type of facts (schema) are predefined, one can use crowdsourcing (Liu et al., 2016) or distant supervision (Hoffmann et al., 2011) to collect examples and train an extraction model for each relation. However, these approaches are incapable of extracting relation types that were not specified in advance and observed during training. In this paper, we propose an alternative approach for relation extraction, which can potentially extract relations of new types that were neither specified nor observed a priori. Relation Question Template educated at(x, y) Where did x graduate from? In which university did x study? What is x’s alma mater? occupation(x, y) What did x do for a living? What is x’s job? What is the profession of x? spouse(x, y) Who is x’s spouse? Who did x marry? Who is x married to? We show that it is possible to reduce relation extraction to the problem of answering simple reading comprehension questions. We map each relation R(x, y) to at least one parametrized naturallanguage question qx whose answer is y. For example, the relation educated at(x, y) can be mapped to “Where did x study?” and “Which university did x graduate from?”. Given a particular entity x (“Turing”) and a text that mentions x (“Turing obtained his PhD from Princeton”), a non-null answer to any of these questions (“Princeton”) asserts the relation and also fills the slot y. Figure 1 illustrates a few more examples. This reduction enables new ways of framing the learning problem. In particular, it allows us to perform zero-shot learning: define new relations “on the fly”, after the model has already been trained. More specifically, the zero-shot scenario assumes access to labeled data for N relations. This data is used to train a reading comprehension model through our reduction. However, at test time, we are asked about a previously unseen relation RN+1. Rather than pr","Modeling biological processes for reading comprehension | Large-scale simple question answering with memory networks | Seed-based event trigger labeling: How far can event descriptions get us | Lifted rule injection for relation embeddings | Question-answer driven semantic role labeling: Using natural language to annotate natural language | Teaching machines to read and comprehend | Wikireading: A novel large-scale language understanding task over wikipedia | The goldilocks principle: Reading children’s books with explicit memory representations | Knowledgebased weak supervision for information extraction | Learning recurrent span representations for extractive question answering | Effective crowd annotation for relation extraction | Open language learning for information extraction | Learning to answer questions from wikipedia infoboxes | Glove: Global vectors for word representation | Squad: 100,000+ questions for machine comprehension of text | Mctest: A challenge dataset for the open-domain machine comprehension of text | Relation extraction with matrix factorization and universal schemas | Injecting logical background knowledge into embeddings for relation extraction | Bidirectional attention flow for machine comprehension | Wikidata: A new platform for collaborative data collection | Multi-perspective context matching for machine comprehension | Towards ai-complete question answering: A set of prerequisite toy tasks | Dynamic coattention networks for question answering",acl,100
563.pdf.json,Exploring Vector Spaces for Semantic Relations,"1.1 Vector space semantics Vector space word representations or word embeddings, both ’count’ models (Turney and Pantel, 2010) and learned vectors (Mikolov et al., 2013a; Pennington et al., 2014), were proven useful for a variety of semantic tasks (Mikolov et al., 2013b; Baroni et al., 2014). Word vectors are used with success because they capture a notion of semantics directly extracted from corpora. Distributional representations allow to compute a functional or topical semantic similarity between two words or, more recently, bigger text units (Le and Mikolov, 2014). The closer two entities are in the vector space (quantified usually, but not necessarily in terms of cosine similarity), the more similar they are semantically. This similarity can be exploited for lexical substitution, synonym detection, subcategorization learning etc. Recent studies suggest that neural word embeddings show higher performance than count models (Baroni et al., 2014; Krebs and Paperno, 2016) for most semantic tasks, although Levy et al. (2015a) argue that this is only due to some specific hyperparameters that can be adapted to count vectors. In what follows, we will concentrate on exploring whether and how pre-trained, general-purpose word embeddings encode relational similarities. 1.2 Relational analogies as vector offsets Relation extraction and classification deal with identifying the semantic relation linking two entities or concepts based on different kinds of information, such as their respective contexts, their co-occurrences in a corpus and their position in an ontology or other kind of semantic hierarchy. Whether the vector spaces of pretrained word embeddings are appropriate for discovering or identifying relational similarities remains to be seen. Mikolov et al. (2013b) claimed that the embeddings created by a recursive neural network indeed encode a specific kind of relational similarities, i.e. analogies between pairs of words. He found that by using simple vector arithmet","Nouns are vectors, adjectives are matrices: Representing adjective-noun constructions in semantic space | The wacky wide web: A collection of very large linguistically processed web-crawled corpora | Entailment above the word level in distributional semantics | Dont count, predict! a systematic comparison of context-counting vs | Semeval2010 task 8: Multi-way classification of semantic relations between pairs of nominals | Bagpack: A general framework to represent semantic relations | Information extraction | Semeval-2012 task 2: Measuring degrees of relational similarity | The choice of features for classification of verbs in biomedical texts | When hyperparameters help: Beneficial parameter combinations in distributional semantic models | Distributed representations of sentences and documents | Linguistic regularities in sparse and explicit word representations | Improving distributional similarity with lessons learned from word embeddings | 2015b. Do supervised distributional methods really learn lexical inference relations? In ACL ’15 | Issues in evaluating semantic spaces using word analogies | Applicative structure in vector space models | Efficient estimation of word representations in vector space | Linguistic regularities in continuous space word representations | Composition in distributional models of semantics | Improving document ranking with dual word embeddings | Glove: Global vectors for word representation | Experiments with three approaches to recognizing lexical entailment | From frequency to meaning: Vector space models of semantics | Measuring semantic similarity by latent relational analysis | Similarity of semantic relations | Domain and function: A dualspace model of semantic relations and compositions | Learning to distinguish hypernyms and co-hyponyms | Hierarchical clustering algorithms for document datasets | Exploring various knowledge in relation extraction",acl,100
564.pdf.json,Lexically Constrained Decoding for Sequence Generation Using Grid Beam Search,"The output of many natural language processing models is a sequence of text. Examples include automatic summarization (Rush et al., 2015), machine translation (Koehn, 2010; Bahdanau et al., 2014), caption generation (Xu et al., 2015), and dialog generation (Serban et al., 2016), among others. In many real-world scenarios, additional information that could inform the search for the optimal output sequence may be available at inference time. Humans can provide corrections after viewing a system’s initial output, or separate classification models may be able to predict parts of the output with high confidence. When the domain of the input is known, a domain terminology may be employed to ensure specific phrases are present in a system’s predictions. Our goal in this work is to find a way to force the output of a model to contain such lexical constraints, while still taking advantage of the distribution learned from training data. For Machine Translation (MT) usecases in particular, final translations are often produced by combining automatically translated output with user inputs. Examples include Post-Editing (PE) (Koehn, 2009; Specia, 2011) and InteractivePredictive MT (Foster, 2002; Barrachina et al., 2009; Green, 2014). These interactive scenarios can be unified by considering user inputs to be lexical constraints which guide the search for the optimal output sequence. In this paper, we formalize the notion of lexical constraints, and propose a decoding algorithm which allows the specification of subsequences that are required to be present in a model’s output. Individual constraints may be single tokens or multi-word phrases, and any number of constraints may be specified simultaneously. Although we focus upon interactive applications for MT in our experiments, lexically constrained decoding is relevant to any scenario where a model is asked to generate a sequence ŷ = {y0 . . . yT } given both an input x, and a set {c0...cn}, where each ci is a sub-sequence {ci0 ","Neural machine translation by jointly learning to align and translate | PRIMT: A pickrevise framework for interactive machine translation | Hierarchical phrase-based translation | Learning phrase representations using rnn encoder–decoder for statistical machine translation | Word association norms, mutual information, and lexicography | Interactive-predictive translation based on multiple word-segments | Text Prediction for Translators | Mixed-Initiative Natural Language Translation | Globally coherent text generation with neural checklist models | A process study of computeraided translation | Statistical Machine Translation | The alignment template approach to statistical machine translation | Heuristics: Intelligent Search Strategies for Computer Problem Solving | Optimal beam search for machine translation | A neural attention model for abstractive sentence summarization | Neural machine translation of rare words with subword units | Building end-to-end dialogue systems using generative hierarchical neural network models | Dirt cheap web-scale parallel text from the common crawl | Exploiting objective annotations for measuring translation post-editing effort | The jrc-acquis: A multilingual aligned parallel corpus with 20+ languages | Sequence to sequence learning with neural networks | Neural machine translation with reconstruction | Blocks and fuel: Frameworks for deep learning | Semantically conditioned lstm-based natural language generation for spoken dialogue systems | Models and inference for prefix-constrained machine translation | Show, attend and tell: Neural image caption generation with visual attention | ADADELTA: an adaptive learning rate method | Machine Translation Infrastructure and Post-editing Performance at Autodesk",acl,100
578.pdf.json,Robust Incremental Neural Semantic Graph Parsing,"An important goal of Natural Language Understanding (NLU) is to parse sentences to structured, interpretable meaning representations that can be used for query execution, inference and reasoning. While it has recently been shown that end-to-end models outperform traditional pipeline approaches using syntactic or semantic parsers on many NLU tasks, those parses were frequently relatively shallow, e.g. restricted to projective bilexical dependencies. In this paper we focus on the robust parsing of linguistically deep semantic representations. The main representation that we use is Minimal Recursion Semantics (MRS) (Copestake et al., 1995, 2005), which serves as the semantic representation of the English Resource Grammar (ERG) (Flickinger, 2000). The only previous approach to parsing and disambiguating full MRS structures (as opposed to bilexical semantic graphs derived from, but simplifying MRS) were based on the ERG (Toutanova et al., 2005); this approach has high precision but incomplete coverage. Our main contribution is to develop a fast and robust parser for full MRS-based semantic graphs. We exploit the power of global conditioning enabled by deep learning to predict linguistically deep graphs incrementally. The model does not have access to the underlying ERG or syntactic structures from which the MRS analyses were originally derived. We develop parsers for two graph-based conversions of MRS, Elementary Dependency Structure (EDS) (Oepen and Lønning, 2006) and Dependency MRS (DMRS) (Copestake, 2009), of which the latter is inter-convertible with MRS. Abstract Meaning Representation (AMR) (Banarescu et al., 2013) is a graph-based semantic representation with similar goals to that of MRS. Apart from differences in the choice of which linguistic phenomena are annotated, MRS is a compositional representation explicitly coupled with the syntactic structure of the sentence, while AMR does not assume compositionality or alignment with the sentence structure. AMR parsin","TensorFlow: Large-scale machine learning on heterogeneous systems. Software available from tensorflow.org | Abstract meaning representation for sembanking | Riga at semeval-2016 task 8: Impact of smatch extensions and character-level neural translation on AMR parsing accuracy | Layers of interpretation: On grammar and compositionality | A fast unified model for parsing and sentence understanding | Smatch: An evaluation metric for semantic feature structures | Invited talk: Slacker semantics: Why superficiality, dependency and avoidance of commitment can be the right way to go | Resources for building applications with dependency minimal recursion semantics | Translation using minimal recursion semantics | Minimal recursion semantics: An introduction | Incremental parsing with minimal features using bi-directional lstm | Span-based constituency parsing with a structure-label system and provably optimal dynamic oracles | An incremental parser for abstract meaning representation | Language to logical form with neural attention | Parser evaluation using elementary dependency matching | Transition-based dependency parsing with stack long short-term memory | Recurrent neural network grammars | Incorporating non-local information into information extraction systems by Gibbs sampling | A discriminative graph-based parser for the abstract meaning representation | On building a more effcient grammar by exploiting types | Deepbank | A transition-based parser for 2-planar dependency structures | On different approaches to syntactic analysis into bi-lexical dependencies | Data recombination for neural semantic parsing | An empirical exploration of recurrent network architectures | Adam: A method for stochastic optimization | Simple and accurate dependency parsing using bidirectional lstm feature representations | Two/too simple adaptations of word2vec for syntax problems | The Stanford CoreNLP natural language processing toolkit | Semeval-2016 task 8: Meaning representation parsing | Algorithms for deterministic incremental dependency parsing | Lingo redwoods | Discriminant-based MRS banking | The proposition bank: An annotated corpus of semantic roles | On the difficulty of training recurrent neural networks | Uofr at semeval-2016 task 8: Learning synchronous hyperedge replacement grammar for amr parsing | Addressing the data sparsity issue in neural amr parsing | Head-driven phrase structure grammar | Online graph planarisation for synchronous parsing of semantic and syntactic dependencies | Stochastic HPSG parse disambiguation using the redwoods corpus | Pointer networks | Grammar as a foreign language | Camr at semeval2016 task 8: An extended transition-based amr parser | Robust parsing, meaning composition, and evaluation: Integrating grammar approximation, default unification, and elementary",acl,100
579.pdf.json,MinIE: Minimizing Facts in Open Information Extraction,"The goal of open information extraction (OIE) is to extract surface relations and their arguments from natural-language text in an unsupervised, domain-independent manner (Banko et al., 2007). In contrast to traditional IE systems, OIE systems do not require an upfront specification of the target schema (e.g., target relations) but instead represent extractions in the form of surface subject-relationobject triples, which are convenient for representing facts in a structured, machine-readable manner (Suchanek et al., 2007; Auer et al., 2007; Bizer et al., 2009). The extractions of OIE systems are useful for tasks such as information retrieval (Löser et al., 2012), question answering (Fader et al., 2014), knowledge-base extension (Dong et al., 2014; Riedel et al., 2013; Petroni et al., 2015) as well as text comprehension, word similarity, word analogy (Stanovsky et al., 2015). Consider for example the sentence “Superman was born on Krypton.” An OIE system aims to extract the triple (Superman, was born on, Krypton); in fact, most of the available systems will correctly produce this extraction. A key challenge in OIE is to avoid overly-specific extractions— while simultaneously producing informative and accurate results—when sentences get more complex. To see this, consider the more involved sentence “Pinocchio believes that the hero Superman was not actually born on beautiful Krypton.” Table 1 shows the corresponding extractions of various OIE systems.1 Many of the extractions are overly-specific in that the constituents contain specific modifiers or even form complete clauses. In this paper, we explore techniques to minimize OIE extractions and propose a new OIE system called MinIE. Table 1 also shows the output of (two variants of) MinIE for the example sentence. At its heart, MinIE rewrites OIE extractions by (1) identifying and removing parts that are considered overly specific and (2) removing information about polarity, modality, attribution, and quantities. To ","Kraken: Nary facts in open information extraction | Leveraging linguistic structure for open domain information extraction | Dbpedia: A nucleus for a web of open data | Open information extraction from the web | Open information extraction via contextual sentence decomposition | Nested propositions in open information extraction | Linked data-the story so far | Some issues on detecting negation from text | Finet: Context-aware fine-grained named entity typing | Clausie: clause-based open information extraction | Identifying relations for open information extraction | Open question answering over curated and extracted knowledge bases | Dependency-based open information extraction | 50-something years of work on collocations: what is or should be next | The goolap fact retrieval framework | The Stanford CoreNLP natural language processing toolkit | Demonyms and compound relational nouns in nominal open ie | Core: Context-aware open relation extraction with factorization machines | A comprehensive grammar of the English language, volume 397 | Relation extraction with matrix factorization and universal schemas | Are you sure that this happened? assessing the factuality degree of events in text. Computational Linguistics 38(2):261–299 | Open language learning for information extraction | Open ie as an intermediate structure for semantic tasks | Yago: a core of semantic knowledge | Open information extraction using wikipedia | Renoun: Fact extraction for nominal attributes",acl,100
588.pdf.json,Rare Entity Prediction: Language Understanding with External Knowledge using Hierarchical LSTMs,"One of the preeminent problems in natural language processing is the design of models that can acquire knowledge of the world through language. Such knowledge can be obtained in at least two ways: through unstructured texts such as news articles or blogs, and through structured knowledge bases such as WordNet (Miller, 1995) and Freebase (Bollacker et al., 2008). A natural setting for testing the abilities of models to acquire knowledge through natural language is reading comprehension, where models must answer questions about a given document. Many existing reading comprehension tasks, however, can be solved using basic language modelling, and re- Context [...] , who lived from 1757 to 1827, was admired by a small group of intellectuals and artists in his day, but never gained general recognition as either a poet or painter. [...] Candidate Entities Peter Ackroyd: Peter Ackroyd is an English biographer, novelist and critic with a particular interest in the history and culture of London. [...] William Blake: William Blake was an English poet, painter, and printmaker. [...] Emanuel Swedenborg: Emanuel Swedenborg was a Swedish scientist, philosopher, theologian, revelator, and mystic. [...] quire little reasoning. This is the case for the Daily Mail/ CNN dataset (Hermann et al., 2015), for example, which has been shown to have a small gap between machine and human performance (Chen et al., 2016). Existing reading comprehension tasks target reasoning about generic concepts, while accounting for syntax, lexical semantics, and/or discourse. In this work, we aim to move towards reasoning about specific instances of entities in context. This is a very difficult problem, as we have very few training samples per instance; thus, we demonstrate that we cannot simply rely on language modelling, and must leverage external sources of knowledge. Recent efforts have been made to integrate different sources of knowledge, for example com- 2 101 102 103 104 105 106 107 108 109 110 111 ","A neural knowledge language model | Modeling local coherence: An entity-based approach | Learning long-term dependencies with gradient descent is difficult | Freebase: a collaboratively created graph database for structuring human knowledge | Question answering with subgraph embeddings | Open question answering with weakly supervised embedding models | Unsupervised learning of narrative schemas and their participants | Unsupervised learning of narrative event chains | A thorough examination of the cnn/daily mail reading comprehension task | Machine learning for sequential data: A review | Machine reading | Incorporating both distributional and relational semantics in word representations | Learning precise timing with lstm recurrent networks | Centering: A framework for modeling the local coherence of discourse | Teaching machines to read and comprehend | The goldilocks principle: Reading children’s books with explicit memory representations | Learning to understand phrases by embedding the dictionary | Untersuchungen zu dynamischen neuronalen Netzen | Long short-term memory | Skip n-grams and ranking functions for predicting script events | Adam: A method for stochastic optimization | Leveraging lexical resources for learning entity embeddings in multi-relational data | The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems | Wordnet: a lexical database for english | Glove: Global vectors for word representation | Statistical script learning with multi-argument events | Learning statistical scripts with lstm recurrent neural networks | Squad: 100,000+ questions for machine comprehension of text | Named entity recognition in tweets: an experimental study | Generating factoid questions with recurrent neural networks: The 30m factoid question-answer corpus | Wikilinks: A large-scale cross-document coreference corpus labeled via links to Wikipedia | Theano: A Python framework for fast computation of mathematical expressions | Newsqa: A machine comprehension dataset | Information extraction over structured data: Question answering with freebase | Deep learning for answer sentence selection",acl,100
606.pdf.json,Neural Symbolic Machines: Learning Semantic Parsers on Freebase with Weak Supervision,"Deep neural networks have achieved impressive performance in supervised classification and structured prediction tasks such as speech recognition (Hinton et al., 2012), machine translation (Bahdanau et al., 2014; Wu et al., 2016) and more. However, training neural networks for semantic parsing (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Liang et al., 2011) or program induction, where language is mapped to a symbolic representation that is executed by a com- puter, through weak supervision remains challenging. This is because the model must interact with a computer through non-differentiable operations at training time. In semantic parsing, recent work handled this (Dong and Lapata, 2016; Jia and Liang, 2016) by training from manually annotated programs and avoiding program execution at training time. However, annotating programs is known to be expensive and scales poorly. In program induction, attempts to address this problem (Graves et al., 2014; Reed and de Freitas, 2016; Kaiser and Sutskever, 2015; Graves et al., 2016b; Andreas et al., 2016) either utilized low-level memory (Zaremba and Sutskever, 2015), or required memory to be differentiable (Neelakantan et al., 2015) so that the model can be trained with backpropagation. This makes it difficult to use the efficient discrete operations and memory of a traditional computer, and limited the application to synthetic or small knowledge bases. In this paper, we propose to utilize the mem- 2 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 ory and discrete operations of a traditional computer in a novel Manager-Programmer-Computer (MPC) framework for neural program",Learning to compose neural networks for question answering | Neural machine translation by jointly learning to align and translate | Semantic parsing on freebase from question-answer pairs | Freebase: a collaboratively created graph database for structuring human knowledge | Learning phrase representations using rnn encoder–decoder for statistical machine translation | Searchbased structured prediction | Language to logical form with neural attention | Neural turing machines | Hybrid computing using a neural network with dynamic external memory | Hybrid computing using a neural network | Deep neural networks for acoustic modeling in speech recognition: The shared | Data recombination for neural semantic parsing | Learned prioritization for trading off accuracy and speed | Neural gpus learn algorithms | Adam: A method for stochastic optimization | Learning dependency-based compositional semantics | Neural programmer: Inducing latent programs with gradient descent | Reward augmented maximum likelihood for neural structured prediction | Compositional semantic parsing on semi-structured tables | Glove: Global vectors for word representation | Neural programmer-interpreters | A reduction of imitation learning and structured prediction to noregret online learning | Prioritized experience replay | Optimal ordered problem solver | Mastering the game of go with deep neural networks and tree | Sequence to sequence learning with neural networks | Reinforcement Learning: An Introduction | Pointer networks | Building a semantic parser overnight | Memory networks | Simple statistical gradientfollowing algorithms for connectionist reinforcement learning | Sequence-to-sequence learning as beamsearch optimization | Semantic parsing via staged query graph generation: Question answering with knowledge base | The value of semantic parse labeling for knowledge base question answering | Reinforcement learning neural turing machines | Learning to parse database queries using inductive logic programming | Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars,acl,100
614.pdf.json,,"Paraphrases are alternate ways of expressing the same meaning. Natural language processing applications like machine translation (Denkowski and Lavie, 2010) and semantic representation (Yu and Dredze, 2014; Faruqui et al., 2015) benefit from large paraphrase resources that enable them to identify different words and phrases with equivalent meaning. To meet this need, there have been several efforts to automatically acquire lexical and phrasal paraphrases. The largest of these is the Paraphrase Database (PPDB) (Pavlick et al., 2015), which contains over 20M English paraphrase pairs. Since words and phrases can be polysemous, their paraphrases can be divided into subsets representing the different meanings. For example, paraphrases of the noun paper include sheet, page, notepaper, newspaper, daily, publication, press which can be grouped into two sense clusters c1: {sheet, page, notepaper} and c2: {journal, daily, publication, press}, analagous to WordNet synsets (Miller, 1995). Earlier work (Apidianaki et al., 2014; Cocos and Callison-Burch, 2016) proposed automatically clustering paraphrases by sense, rather than manually specifying sense clusters as WordNet does, in order to organize large paraphrase resources by sense. There is a clear relationship between the sense of a word or phrase in the context of some sentence, and our ability to replace it with one or more of its paraphrases. For instance, in the sentence The local papers took photographs of the footprint, the paraphrases from c2 would be good substitutes that preserve the overall meaning of the sentence, while paraphrases from c1 would be poor substitutes because they change the meaning. The task of automatically replacing a word with its meaning-equivalent paraphrases in context is called lexical substitution (lexsub). It was initially conceived as a practical alternative evaluation for Word Sense Disambiguation (WSD) systems (McCarthy and Navigli, 2007). Accordingly, many early lexsub models approached ","A comparison of extrinsic clustering evaluation metrics based on formal constraints | Vector-space models for PPDB paraphrase ranking in context | Semantic clustering of pivot paraphrases | Paraphrasing with bilingual parallel corpora | Creating a system for lexical substitutions from scratch using crowdsourcing | Clustering paraphrases by word sense | METEORNEXT and the METEOR Paraphrase Tables: Improved Evaluation Support For Five Target Languages | Measuring distributional similarity in context | A structured vector space model for word meaning in context | Retrofitting Word Vectors to Semantic Lexicons | Property of average precision | Annotated gigaword | PPDB 2.0: Better paraphrase ranking, fine-grained entailment relations, word embeddings, and style classification | Software Framework for Topic Modelling with Large Corpora | Pic a different word: A simple model for lexical substitution in context | Word meaning in context: A simple and effective vector model | Improving lexical embeddings with semantic knowledge | Ku: Word sense disambiguation by substitution",acl,100
619.pdf.json,A Corpus of Annotated Revisions for Studying Argumentative Writing,"Much of the writing-related NLP research focuses on the analysis of single drafts. Examples include document-level quality assessment (Attali and Burstein, 2006; Burstein and Chodorow, 1999), discourse-level analysis and mining (Brown and Yule, 1983; Burstein et al., 2003; Falakmasir et al., 2014; Persing and Ng, 2016), as well as fine-grained phrasal-level error detection (Leacock et al., 2010; Grammarly, 2016). Less studied is the analysis of between drafts – a comparison of revisions and the properties of the differences. Research on the topic allows a variety of applications: revision analysis (Zhang and Litman, 2015), paraphrase (Malakasiotis and Androutsopoulos, 2011) and correction detection (Swanson and Yamangil, 2012; Xue and Hwa, 2014). Although there are some corpora resources for NLP research on writing comparisons, most tend to be between individual sentences/phrases for tasks such as paraphrase comparison (Dolan and Brockett, 2005; Tan and Lee, 2014) or grammar error correction (Dahlmeier et al., 2013; Yannakoudakis et al., 2011). In terms of revision anal- ysis, the most relevant work are on Wikipedia revisions (Daxenberger and Gurevych, 2013; Bronner and Monz, 2012); however, the domain of Wikipedia is so specialized that the properties of their revisions do not correspond well with other kinds of texts. This work presents an annotated corpus to facilitate revision analysis for argumentative essays. The corpus consists of a collection of three drafts of essays written by college students; the drafts are manually aligned at the sentence level, and the purpose of each revision is manually coded, using a revision schema closely related to argument mining/discourse analysis. Within the domain of argumentative essays, the corpus may be used for research and application of argument mining techniques and argumentative revision analysis. Outside of the domain, the corpus may also be of interest to research on paraphrase comparisons, grammar error correction,","Writing in high school/writing in college: Research trends and future directions | Automated essay scoring with e-rater R | User edits classification using document revision histories | Discourse analysis | Automated essay scoring for nonnative english speakers | Towards automatic classification of discourse elements in essays | Finding the WRITE stuff: Automatic identification of discourse structure in student essays | What if the earth is flat? working with, not against, faculty concerns about grammar in student writing | Building a large annotated corpus of learner English: The NUS corpus of learner English | A corpus-based study of edit categories in featured and non-featured wikipedia articles | Automatically classifying edit categories in Wikipedia revisions | Automatically constructing a corpus of sentential paraphrases | Analyzing revision | Identifying thesis and conclusion statements in student essays to scaffold peer review | Exploring stylistic variation with age and income on twitter | Patterns of revision in online writing a study of wikipedia’s featured articles | Teaching argument: An introduction to the toulmin model | Automated grammatical error detection for language learners | Who does what: Collaboration patterns in the wikipedia and their impact on data quality | A generate and rank approach to sentence paraphrasing | The connected curriculum: Designing a vertical transfer writing curriculum | Ano (nd) difference algorithm and its variations | End-to-end argumentation mining in student essays | Cultural differences in collaborative authoring of wikipedia | Rank distance as a stylistic similarity | Correction detection and error type selection as an esl educational aid | A corpus of sentence-level revisions in academic writing: A step towards understanding statement strength in communication | Improved correction detection in revised esl sentences | A new dataset and method for automatically grading ESOL texts | Sentence-level rewriting detection | Annotation and classification of argumentative writing revisions",acl,100
627.pdf.json,Towards End-to-End Reinforcement Learning of Dialogue Agents for Information Access,"The design of intelligent assistants which interact with users in natural language ranks high on the agenda of current NLP research. With an increasing focus on the use of statistical and machine learning based approaches (Young et al., 2013), the last few years have seen some truly remarkable conversational agents appear on the market (e.g. Apple Siri, Microsoft Cortana, Google Allo). These agents can perform simple tasks, answer factual questions, and sometimes also aimlessly chit-chat with the user, but they still lag far be- hind a human assistant in terms of both the variety and complexity of tasks they can perform. In particular, they lack the ability to learn from interactions with a user in order to improve and adapt with time. Recently, Reinforcement Learning (RL) has been explored to leverage user interactions to adapt various dialogue agents designed, respectively, for task completion (Gašić et al., 2013), information access (Wen et al., 2016b), and chitchat (Li et al., 2016a). We focus on KB-InfoBots, a particular type of dialogue agent that helps users navigate a Knowledge Base (KB) in search of an entity, as illustrated by the example in Figure 1. Such agents must necessarily query databases in order to retrieve the requested information. This is usually done by performing semantic parsing on the input to construct a symbolic query representing the beliefs of the agent about the user goal (see, e.g., Wen et al. (2016b) and Williams and Zweig (2016)). We call such an operation a HardKB lookup. While natural, this approach has two drawbacks: (1) the retrieved results do not carry any information about uncertainty in semantic parsing, and (2) the retrieval operation is non differentiable, and hence the parser and dialog policy are trained separately. This makes online endto-end learning from user feedback difficult once the system is deployed. In this work, we propose a probabilistic framework for computing the posterior distribution of the user target ",A sequence-to-sequence model for user simulation in spoken dialogue systems | Learning end-to-end goal-oriented dialog | End-to-end memory networks with knowledge carryover for multiturn spoken language understanding | Learning phrase representations using rnn encoder-decoder for statistical machine translation | Human-computer dialogue simulation using hidden markov models | Online policy optimisation of bayesian spoken dialogue systems via human interaction | Likelihood ratio gradient estimation for stochastic systems | Variance reduction techniques for gradient estimates in reinforcement learning | Multi-domain joint semantic frame parsing using bi-directional RNN-LSTM | Machine learning for dialog state tracking: A review | Word-based dialog state tracking with recurrent neural networks | Lecture 6a overview of mini–batch gradient descent | Deep reinforcement learning for dialogue generation | A user simulator for task-completion dialogues | Memo: towards automatic usability evaluation of spoken dialogue services by user error | Agenda-based user simulation for bootstrapping a pomdp dialogue system | Statistical user simulation with a hidden agenda | Automatic learning of dialogue strategy using dialogue simulation and reinforcement learning | Searching the web: The public and their queries | Paradise: A framework for evaluating spoken dialogue agents | Conditional generation and snapshot learning in neural dialogue systems | A network-based end-to-end trainable task-oriented dialogue system | Semantically conditioned lstm-based natural language generation for spoken dialogue systems | Scaling up POMDPs for dialog management: The “Summary POMDP” method | Endto-end lstm-based dialog control optimized with supervised and reinforcement learning | Simple statistical gradientfollowing algorithms for connectionist reinforcement learning | A probabilistic framework for representing dialog systems and entropy-based dialog management through dynamic stochastic state evolution | Spoken language understanding using long short-term memory neural networks | Neural generative question answering | Neural enquirer: Learning to query tables | POMDP-based statistical spoken dialog systems: A review | Reinforcement learning neural Turing machines-revised | Towards end-to-end learning for dialog state tracking and management using deep reinforcement learning | Do we need entity-centric knowledge bases for entity disambiguation,acl,100
636.pdf.json,Fast and Accurate Sequence Labeling with Iterated Dilated Convolutions,"In order to democratize large-scale NLP and information extraction, we require fast, resource- efficient methods for sequence tagging tasks such as part-of-speech tagging and named entity recognition (NER). Speed is not sufficient of course: they must also be expressive enough to tolerate the tremendous lexical variation in input data. The massively parallel computation facilitated by GPU hardware has led to a surge of successful neural network architectures for sequence labeling (Ling et al., 2015; Ma and Hovy, 2016; Chiu and Nichols, 2016; Lample et al., 2016). While these models are expressive and accurate, they fail to fully exploit the parallelism opportunities of a GPU, and thus their speed is limited. Specifically, they employ either recurrent neural networks (RNNs) for feature extraction, or Viterbi inference in a structured output model, both of which require sequential computation across the length of the input. Instead, parallelized runtime independent of the length of the sequence saves time and energy costs, maximizing GPU resource usage and minimizing the amount of time it takes to train and evaluate models. Convolutional neural networks (CNNs) provide exactly this property (Kim, 2014; Kalchbrenner et al., 2014). Rather than composing representations incrementally over each token in a sequence, they apply filters in parallel across the entire sequence at once. Their computational cost grows with the number of layers, but not the input size, up to the memory and threading limitations of the hardware. This provides, for example, audio generation models that can be trained in parallel (van den Oord et al., 2016). Despite the clear computational advantages of CNNs, RNNs have become the standard method for composing deep representations of text. This is because a token encoded by a bidirectional RNN will incorporate evidence from the entire input sequence, but the CNN’s representation is limited by the receptive field of the architecture. Specifi- 2 101 102","Collective information extraction with relational markov networks | Semantic image segmentation with deep convolutional nets and fully connected crfs | Named entity recognition with bidirectional lstm-cnns | Natural language processing (almost) from scratch | Semisupervised sequence learning | Search-based structured prediction | A joint model for entity analysis: Coreference, typing and linking | Incorporating non-local information into information extraction systems by gibbs sampling | Understanding the difficulty of training deep feedforward neural networks | Deep sparse rectifier neural networks | Knowledge matters: Importance of prior information for optimization | Named entity recognition with long short-term memory | The vanishing gradient problem during learning recurrent neural nets and problem solutions | Long short-term memory | Ontonotes: the 90% solution | Bidirectional lstm-crf models for sequence tagging | Neural machine translation in linear time | A convolutional neural network for modelling sentences | Convolutional neural networks for sentence classification | Adam: A method for stochastic optimization | Conditional random fields: Probabilistic models for segmenting and labeling sequence data | Neural architectures for named entity recognition | A simple way to initialize recurrent networks of rectified linear units | Deeplysupervised nets | Molding cnns for text: non-linear, non-consecutive convolutions | Structure compilation: trading structure for features | Not all contexts are created equal: Better word representations with variable attention | Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation | Stability and generalization in structured prediction | Dropout with expectation-linear regularization | End-to-end sequence labeling via bi-directional lstm-cnns-crf | Lexicon infused phrase embeddings for named entity resolution | Towards robust linguistic analysis using ontonotes | Conll2012 shared task: Modeling multilingual unrestricted coreference in ontonotes | Text chunking using transformation-based learning | Design challenges and misconceptions in named entity recognition | Fitnets: Hints for thin deep nets | Dropout: a simple way to prevent neural networks from overfitting | Collective segmentation and labeling of distant entities in information extraction | Going deeper with convolutions | Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition | Representing text for joint embedding of text and knowledge bases | Word representations: a simple and general method for semi-supervised learning | Wavenet: A generative model for raw audio | Structured training for neural network transition-based parsing | Multi-task cross-lingual sequence tagging from scratch | Multi-scale context aggregation by dilated convolutions | Character-level convolutional networks for text classification",acl,100
649.pdf.json,Towards an Automatic Turing Test: Learning to Evaluate Dialogue Responses,"Building systems that can naturally and meaningfully converse with humans has been a central goal of artificial intelligence since the formulation of the Turing test (Turing, 1950). Research on one type of such systems, sometimes referred to as non-taskoriented dialogue systems, goes back to the mid60s with Weizenbaum’s famous program ELIZA: a rule-based system mimicking a Rogerian psychotherapist by persistently either rephrasing statements or asking questions (Weizenbaum, 1966). Recently, there has been a surge of interest in the research community towards building large-scale non-task-oriented dialogue systems using neural networks (Sordoni et al., 2015b; Shang et al., 2015; Vinyals and Le, 2015; Serban et al., 2016a; Li et al., 2015). These models are trained in an end-to-end manner to optimize a single objective, usually the likelihood of generating the responses from a fixed corpus. Such models have already had a substantial impact in industry, including Google’s Smart Reply system (Kannan et al., 2016), and Microsoft’s Xiaoice chatbot (Markoff and Mozur, 2015), which has over 20 million users. One of the challenges when developing such systems is to have a good way of measuring progress, in this case the performance of the chatbot. The Turing test provides one solution to the evaluation of dialogue systems, but there are limitations with its original formulation. The test requires live human interactions, which is expensive and difficult to scale up. Furthermore, the test requires carefully designing the instructions to the human interlocutors, in order to balance their behaviour and expectations so that different systems may be ranked accurately by performance. Although unavoidable, these instructions introduce bias into the evaluation measure. The more common approach of having humans evaluate the quality of dialogue system 2 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 1","Regression for sentence-level mt evaluation with pseudo references | Semi-formal evaluation of conversational characters | Layer normalization | Learning long-term dependencies with gradient descent is difficult | Generating sentences from a continuous space | Findings of the 2011 workshop on statistical machine translation | Recurrent batch normalization | Tweet2vec: Character-based distributed representations for social media | Censoring representations with an adversary | Hierarchical recurrent neural networks for long-term dependencies | A new algorithm for data compression | deltableu: A discriminative metric for generation tasks with intrinsically diverse targets | Reval: A simple and effective machine translation evaluation metric based on recurrent neural networks | Untersuchungen zu dynamischen neuronalen netzen | Long short-term memory | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Smart reply: Automated response suggestion for email | Adversarial evaluation of dialogue models | Adam: A method for stochastic optimization | Skip-thought vectors | A diversity-promoting objective function for neural conversation models | A persona-based neural conversation model | Learning to decode for future success | Deep reinforcement learning for dialogue generation | How not to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation | The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems | Results of the wmt14 metrics shared task | For sympathetic ear, more chinese turn to smartphone program | Memo: towards automatic usability evaluation of spoken dialogue services by user error | Bleu: a method for automatic evaluation of machine translation | Principal components analysis | Data-driven response generation in social media | Neural machine translation of rare words with subword units | Building end-to-end dialogue systems using generative hierarchical neural network models | A hierarchical latent variable encoder-decoder model for generating dialogues | Neural responding machine for short-text conversation | A hierarchical recurrent encoderdecoder for generative context-aware query suggestion | A neural network approach to context-sensitive generation of conversational responses | Results of the wmt15 metrics shared task | Computing machinery and intelligence | A neural conversational model | Paradise: A framework for evaluating spoken dialogue agents | ELIZAa computer program for the study of natural language communication between man and machine | Strategy and policy learning for nontask-oriented conversational systems",acl,100
654.pdf.json,Deep Semantic Role Labeling: What Works and What’s Next,"Semantic role labeling (SRL) systems aim to recover the predicate-argument structure of a sentence, to determine essentially “who did what to whom”, “when”, and “where.” Recently breakthroughs involving end-to-end deep models for SRL without syntactic input (Zhou and Xu, 2015; Marcheggiani et al., 2017) seem to overturn the long-held belief that syntactic parsing is a prerequisite for this task (Punyakanok et al., 2008). In this paper, we show that this result can be pushed further using deep highway bidirectional LSTMs with constrained decoding, again significantly moving the state of the art (another 2 points on CoNLL 2005). We also present careful empirical analysis to determine what works well and what might be done to progress even further. Our model combines a number of best practices in the recent deep learning literature. Following Zhou and Xu (2015), we treat SRL as a BIO tagging problem and use deep bidirectional LSTMs. However, we differ by (1) simplifying the input and output layers, (2) introducing highway connections (Srivastava et al., 2015; Zhang et al., 2016), (3) using recurrent dropout (Gal, 2015), (4) decoding with BIO-constraints, and (5) ensembling with a product of experts. Our model gives a 10% relative error reduction over previous state of the art on the test sets of CoNLL 2005 and 2012. All code and models will be publicly released. We present a set of detailed error analyses to better understand the performance gains, including (1) design choices on architecture, initialization, and regularization that have a surprisingly large impact on model performance, (2) analyses of different types of prediction errors, e.g. showing that deep models excel at predicting long-distance dependencies but still struggles with known challenges such as PP-attachment errors and adjunct-argument distinctions, (3) a careful analysis of the role of syntax, showing that there is significant room for improvement given oracle syntax but errors from existing parser","Propbank annotation guidelines | Introduction to the conll-2005 shared task: Semantic role labeling | A maximum-entropy-inspired parser | Parsing as language modeling | Natural language processing (almost) from scratch | Semantic role labeling with neural network factors | A theoretically grounded application of dropout in recurrent neural networks | Multilingual joint parsing of syntactic and semantic dependencies with a latent variable model | Training products of experts by minimizing contrastive divergence | Adding semantic annotation to the penn treebank | Parser showdown at the wall street corral: An empirical investigation of error types in parser output | A* ccg parsing with a supertag-factored model | A simple and accurate syntaxagnostic neural model for dependency-based semantic role labeling | Glove: Global vectors for word representation | Semantic role chunking combining complementary syntactic views | Towards robust linguistic analysis using ontonotes | Generalized inference with multiple semantic role labeling systems | The importance of syntactic parsing and inference in semantic role labeling | Neural semantic role labeling with dependency path embeddings | Exact solutions to the nonlinear dynamics of learning in deep linear neural networks | Training very deep networks | Greedy, joint syntacticsemantic parsing with stack lstms | Efficient inference and structured learning for semantic role labeling | A global joint model for semantic role labeling | Chinese semantic role labeling with bidirectional recurrent neural networks | Adadelta: an adaptive learning rate method | Highway long short-term memory rnns for distant speech recognition | End-to-end learning of semantic role labeling using recurrent neural networks",acl,100
657.pdf.json,Interpreting Neural Networks to Understand Written Justifications in Values-Affirmation Essays,"The difficulty of interpreting neural networks is a major barrier to their wider adoption among applied quantitative scientists. Although these models have achieved a high level of performance across a number of NLP and vision processing tasks (Sutskever et al., 2014; Bahdanau et al., 2014; Socher et al., 2011; Chen and Manning, 2014), attempts to understand why a model performs as it does have been less frequent. Some recent work in this area has been devoted to understanding long-term dependencies such as bracketing (Hermans and Schrauwen, 2013; Karpathy et al., 2015), studying learned sparse word vectors (Faruqui et al., 2015) and to generating rationalization of predictions without manual annotations (Lei et al., 2016). These efforts are important for understanding where and why a model ex- periences shortcomings. Additionally, as we address here, finding straightforward ways to interpret these models will increase their applicability across the sciences more generally. In this paper, we take a somewhat different approach to understanding properties learned by a Long-Short Term Memory (LSTM) network (Hochreiter and Schmidhuber, 1997). Rather than exploring the components of the model itself, we take a hypothesis-driven approach in which we allow the model to respond (i.e., make predictions) to stimuli we devise that is of theoretical interest to the investigators. This approach is imported directly from experimental psychology in which the objective is to mechanistically understand cognition. This is a flexible approach that allows the investigator to directly devise stimuli in an intuitive manner which address questions about what the model has learned from the information it was trained on. To demonstrate the utility of this approach, we explore a data set of essays taken from a series of field studies of a written educational intervention conducted in a North American middle school (Cohen et al., 2009, 2006; Cook et al., 2012). This intervention is designed t",,acl,100
66.pdf.json,Generating Memorable Mnemonic Encodings of Numbers,"The major system is a mnemonic device used to help memorize numbers. The system works by mapping each digit of a number to a consonant phoneme and allowing for arbitrary insertion of vowel phonemes to produce words (FauvelGouraud, 1845). For instance, the digit 1 maps to <T>, and the digit 2 maps to <N>. The number 121 can then be encoded as the word tent by replacing both 1s with <T>s, replacing the 2 with <N>, and inserting an <e>. The full major system mapping is shown in Table 1. The difficulty of generating a memorable sequence of words that encodes a number with the major system stems from the constraint that the sequence of words must encode exactly the given digits. While there are many sequences of words that correctly encode a given number, the vast majority of these sequences are incoherent and thus difficult to remember. So, this task requires the use of a language model that balances the encoding constraints with syntactic plausibility and some notion of memorability. We have developed a system that automatically produces a sequence of words to encode a se- quence of digits. Each such encoding is a sequence of sentences that balance memorability and length. We sample from a distribution of partof-speech (POS) templates to produce a syntactically plausible sentence, then use an n-gram language model to fill each POS slot in the selected template to produce an encoding. A system like ours can be used to memorize fairly short numbers, such as a numeric password, a phone number, or an account number; or to memorize arbitrarily long numbers, like digits of π. One could use our system to encode a smartphone passcode as a short sentence. Thus, our system can help improve the strength of security practices. To test the effectiveness of our system, we conducted a study on password memorability. Participants were asked to memorize an eight-digit number representing a numeric password and a phrase produced by our system to encode the same number. After seven days,","Large Language Models in Machine Translation | Phreno-mnemotechny: Or, The Art of Memory: the Series of Lectures, Explanatory of the Principles of the System, Delivered in New York and Philadelphia, in the Beginning of 1844 | Memorability of Persuasive Passwords | A Standard Corpus of Present-Day Edited American English, for use with Digital Computers | How to memorize a random 60-bit string | Phonetic Mnemonic System Keyword Search Tool | Have the cake and eat it too - Infusing usability into text-password based authentication systems | Simple Major System | Representatively Memorable: Sampling the Right Phrase Set to Get the Text Entry Experiment Right | The CMU Pronouncing Dictionary | A+ Major System | Mnemo Major System Trainer | Memorize numbers with this online mnemonic generator | Numzi | Numzi | Mnemonic Major System | Major System database | Promoting Memorability and Security of Passwords through Sentence Generation | Password Memorability and Security: Empirical Results",acl,100
660.pdf.json,Automatically Generating Rhythmic Verse with Neural Networks,"Poetry is an advanced form of linguistic communication, in which a message is conveyed that satisfies both aesthetic and semantic constraints. As poetry is one of the most expressive forms of language, the automatic creation of texts recognisable as poetry is difficult. In addition to requiring an understanding of many aspects of language including phonetic patterns such as rhyme, rhythm and alliteration, poetry composition also requires a deep understanding of the meaning of language. Poetry generation can be divided into two subtasks, namely the problem of content, which is concerned with a poem’s semantics, and the problem of form, which is concerned with the aesthetic rules that a poem follows. These rules may describe aspects of the literary devices used, and are usually highly prescriptive. Examples of different forms of poetry are limericks, ballads and sonnets. Limericks, for example, are characterised by their strict rhyme scheme (AABBA), their rhythm (two unstressed syllables followed by one stressed syllable) and their shorter third and fourth lines. Creating such poetry requires not only an understanding of the language itself, but also of how it sounds when spoken aloud. Statistical text generation usually requires the construction of a generative language model that explicitly learns the probability of any given word given previous context. Neural language models (Schwenk and Gauvain, 2005; Bengio et al., 2006) have garnered signficant research interest for their ability to learn complex syntactic and semantic representations of natural language (Mikolov et al., 2010; Sutskever et al., 2014; Cho et al., 2014; Kim et al., 2015). Poetry generation is an interesting application, since performing this task automatically requires the creation of models that not only focus on what is being written (content), but also on how it is being written (form). We experiment with two novel methodologies for solving this task. The first involves training a model to lea","Word length frequency and distribution in english: Observations, theory, and implications for the construction of verse lines | Neural probabilistic language models | Issues in building general letter to sound rules | Learning phrase representations using rnn encoder-decoder for statistical machine translation | Full face poetry generation | An exact a* method for deciphering letter-substitution ciphers | A formula for predicting readability: Instructions | Wasp: Evaluation of different strategies for the automatic generation of spanish verse | Automatic analysis of rhythmic poetry with applications to generation and translation | Long short-term memory | Character-aware neural language models | Unsupervised analysis for decipherment problems | N-gram similarity and distance | Better word representations with recursive neural networks for morphology | Towards a computational model of poetry generation | Efficient estimation of word representations in vector space | Recurrent neural network based language model | Poetry generation system with an emotional personality | Performance tradeoffs in dynamic time warping algorithms for isolated word recognition | Gaiku: Generating haiku with word associations norms | Learning phoneme mappings for transliteration without parallel data | Training neural network language models on very large corpora | Generating text with recurrent neural networks | Sequence to sequence learning with neural networks | Harnessing constraint programming for poetry composition | Freetts 1.2: A speech synthesizer written entirely in the java programming language | The carnegie mellon pronouncing dictionary [cmudict | Backpropagation through time: what it does and how to do it | Generating chinese classical poems with rnn encoderdecoder | Chinese poetry generation with recurrent neural networks",acl,100
67.pdf.json,Constructing Semantic Hierarchies via Fusion Learning Architecture,"Ontologies and semantic thesauri (Miller, 1995; Suchanek et al., 2007) are significant for many natural language processing applications. The main components of ontologies and semantic thesauri are semantic hierarchies (see in Figure 1). In the WordNet, semantic hierarchies are organized in the form of “is-a” relations. For instance, the words “dog” and “canine” have such relation, and we call “canine” is a hypernym of “dog”. Conversely, “dog” is a hyponym of “canine”. The hypernym-hyponym (“is-a”) relation is the main relationship in semantic hierarchies. However, such manual semantic hierarchies construction as WordNet (Miller, 1995) and YAGO (Suchanek et al., 2007), the primary problem is the tradeoff between coverage scope and human labor. A number of papers have proposed some approach to extract semantic hierarchies automatically. hypernym-hyponym relation discovery is the key point of semantic hierarchies construction, also the major challenge. The usage of the context is a bottleneck in improving performance of hypernym-hyponym relation discovery. Several works focus on designing or learning lexical patterns (Hearst, 1992; Snow et al., 2004) via observing context of hypernym-hyponym relation, which suffer from covering a small proportion of complex linguistic circumstances. Besides, distributional inclusion hypothesis, which states that hypernyms tend to occur in a superset of contexts in which their hyponyms are found. In other words, hypernyms are semantically broader terms than their hyponyms (Kotlerman et al., 2010; Lenci and Benotto, 2012). However, it is not always rational. To acquire more contexts of words, Fu (2013) applies a web mining method to discover the hypernyms of Chinese entities from multiple sources, assuming that the hypernyms of an entity co-occur with it frequently. The method works well for named entities. But for class names with wider range of meanings, this assumption may fail. Word embedding is a kind of low-dimensional 2 101 102 1",A neural probabilistic language model | Ltp: A chinese language technology platform | Approximation by superpositions of a sigmoidal function | Multi-view learning of word embeddings via cca | Finding structure in time | Learning semantic hierarchies via word embeddings | Exploiting multiple sources for open-domain hypernym discovery | The distributional inclusion hypotheses and lexical entailment | Automatic acquisition of hyponyms from large text corpora | Long short-term memory | Serial order: A parallel distributed processing approach | Directional distributional similarity for lexical inference | Identifying hypernyms in distributional semantic spaces | Efficient estimation of word representations in vector space | Recurrent neural network based language model | Linguistic regularities in continuous space word representations | Wordnet: a lexical database for english | A scalable hierarchical distributed language model | Principles of neurodynamics | Improving hypernymy detection with an integrated path-based and distributional method | J.(1988). nonparametric statistics for the behavioral sciences | Learning syntactic patterns for automatic hypernym discovery | Yago: a core of semantic knowledge | Adadelta: an adaptive learning rate method | Bootstrapping distributional feature vector quality,acl,100
676.pdf.json,Neural Machine Translation via Binary Code Prediction,"When handling broad or open domains, machine translation systems usually have to handle a large vocabulary as their inputs and outputs. This is particularly a problem in neural machine translation (NMT) models (Sutskever et al., 2014), such as the attention-based model (Bahdanau et al., 2014; Luong et al., 2015) shown in Figure 1. In these models, the output layer is required to generate a specific word from an internal vector, and a large vocabulary size tends to require a large amount of computation to predict each of the candidate word probabilities. Because this is a significant problem for neural language and translation models, there are a number of methods proposed to resolve this problem, which we detail in Section 2.2. However, none of these previous methods simultaneously satisfies the following desiderata, all of which, we argue, are desirable for practical use in NMT systems: Memory efficiency: The method should not require large memory to store the parameters and calculated vectors to maintain scalability in resource-constrained environments. Time efficiency: The method should be able to train the parameters efficiently, and possible to perform decoding efficiently with choosing the candidate words from the full probability distribution. In particular, the method should be performed fast on general CPUs to suppress physical costs of computational resources for actual production systems. Compatibility with parallel computation: It should be easy for the method to be minibatched and optimized to run efficiently on GPUs, which are essential for training large NMT models. In this paper, we propose a method that satisfies all of these conditions: requires significantly less memory, fast, and is easy to implement minibatched on GPUs. The method works by not pre- 2 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 15","Neural machine translation by jointly learning to align and translate | Class-based n-gram models of natural language | Strategies for training large vocabulary neural language models | Variablelength word encodings for neural translation models | Solving multiclass learning problems via errorcorrecting output codes | Multilabel classification with error-correcting codes | Multilabel classification using error-correcting codes of hard or soft bits | Learning to forget: Continual prediction with LSTM | Notes on digital coding | A method for the construction of minimum-redundancy codes | Adam: A method for stochastic optimization | On nearest-neighbor error-correcting output codes with application to all-pairs multiclass support vector machines | Multilabel classification using error correction codes | Multilabel classification by bch code and random forests | Character-based neural machine translation | Using svm and error-correcting codes for multiclass dialog act classification in meeting corpus | Effective approaches to attention-based neural machine translation | Distributed representations of words and phrases and their compositionality | A fast and simple algorithm for training neural probabilistic language models | Hierarchical probabilistic neural network language model | Aspec: Asian scientific paper excerpt corpus | Dynet: The dynamic neural network toolkit | Pointwise prediction for robust, adaptable japanese morphological analysis | Bleu: a method for automatic evaluation of machine translation | Neural machine translation of rare words with subword units | A mathematical theory of communication | Dropout: a simple way to prevent neural networks from overfitting | Sequence to sequence learning with neural networks | Building a bilingual travel conversation database for speech translation research | Error bounds for convolutional codes and an asymptotically optimum decoding algorithm | Human behavior and the principle of least effort",acl,100
68.pdf.json,A New Formula for Vietnamese Text Readability Assessment,"Text readability – as defined by Edgar Dale and Jeanne Chall (Dale and Chall, 1949) – is “the sum total (including all the interactions) of all those elements within a given piece of printed material that affect the success a group of readers has with it. The success is the extent to which they understand it, read it at an optimal speed, and find it interesting.” Text readability has a huge impact on the reading and comprehending a text. Base on the readability, readers can determine whether a text is suitable for their reading ability or not. The text author(s) can also use the readability of the draft to guide readers object or have some adjustments to make it fit the toward reader. Building a model to analyze text readability has meant a lot in the scientific and practical: help scientists writing research reports more readable; support educators drafting textbooks and curricula to suit each age of students; support publishers in shaping the audience; help governments drafting legal documents to suit the majority of citi- zens; or to assist manufacturers in preparing user guide for their products. . . In addition, text readability can effectively support in choosing appropriate curriculums when teaching language for foreigners. Researches on text readability have begun since the early of the 20th century, most of them are for English and some common languages. Most famous studies in text readability are creating linear functions to assess and grade documents like Dale-Chall formula (Dale and Chall, 1949), Flesch Reading Ease formula (Flesch, 1949), FleschKincaid formula (Kincaid et al., 1975), Gunning Fog formula (Robert, 1952), SMOG formula (Laughlin, 1969). . . In Vietnamese, there are only two studies on text readability of Liem Thanh Nguyen and Alan B. Henkin in 1982 and 1985. Both these two researches focus on examining relations between statistical characteristics at words level and at sentences level and text readability. However, these two works only eval","Readability Revisited: The New Dale-Chall Readability Formula | The concept of readability | Chữ quốc ngữ hiện nay qua các con số thống kê (Current National Vietnamese language through statistics) | Measuring nominal scale agreement among many raters | The Art of Readable Writing | Derivation of New Readability Formulas (Automated Readability Index, Fog Count and Flesch Reading Ease Formula) for Navy Enlisted Personnel | SMOG Grading-a New Readability Formula | A Second Generation Readability Formula for Vietnamese | A Readability Formula for Vietnamese | The technique of clear writing | Analytics of literature: a manual for the objective study of English prose and poetry",acl,100
684.pdf.json,,"A recent trend to measure progress towards machine reading is to test a system’s ability to answer questions about a document it has to comprehend. Towards this end, several large-scale datasets of cloze-style questions over a context document have been introduced recently, which allow the training of supervised machine learning systems (Hermann et al., 2015; Hill et al., 2015; Onishi et al., 2016). Such datasets can be easily constructed automatically and the unambiguous nature of their queries provides an objective benchmark to measure a system’s performance at text comprehension. Deep learning models have been shown to outperform traditional shallow approaches on text comprehension tasks (Hermann et al., 2015). The success of many recent models can be attributed primarily to two factors: (1) Multi-hop architectures allow a (Weston et al., 2014; Sordoni et al., 2016; Shen et al., 2016), model to scan the document and the question iteratively for multiple passes. (2) Attention mechanisms, (Chen et al., 2016; Hermann et al., 2015) borrowed from the machine translation literature (Bahdanau et al., 2014), allow the model to focus on appropriate subparts of the context document. Intuitively, the multi-hop architecture allows the reader to incrementally refine token representations, and the attention mechanism re-weights different parts in the document according to their relevance to the query. The effectiveness of multi-hop reasoning and attentions have been explored orthogonally so far in the literature. In this paper, we focus on combining both in a complementary manner, by designing a novel attention mechanism which gates the evolving token representations across hops. More specifically, unlike existing models where the query attention is applied either token-wise (Hermann et al., 2015; Kadlec et al., 2016; Chen et al., 2016; Hill et al., 2015) or sentence-wise (Weston et al., 2014; Sukhbaatar et al., 2015) to allow weighted aggregation, the Gated-Attention (GA) mod",Neural machine translation by jointly learning to align and translate | Embracing data abundance: Booktest dataset for reading comprehension | A thorough examination of the cnn/daily mail reading comprehension | Attention-over-attention neural networks for reading comprehension | Tweet2vec: Character-based distributed representations for social media | Teaching machines to read and comprehend | The goldilocks principle: Reading children’s books with explicit memory representations | Long shortterm memory | Text understanding with the attention sum reader network | Adam: A method for stochastic optimization | A multiplicative model for learning distributed text-based attribute representations | Dynamic entity representations with max-pooling improves machine reading | Dataset and neural recurrent sequence labeling model for opendomain factoid question answering | Vector-based models of semantic composition | Recurrent models of visual attention | Neural semantic encoders | Reasoning with memory augmented neural networks for language comprehension | Who did what: A largescale person-centered cloze dataset | On the difficulty of training recurrent neural networks | Glove: Global vectors for word representation | Bidirectional attention flow for machine comprehension | Reasonet: Learning to stop reading in machine comprehension | Iterative alternating neural attention for machine reading | End-to-end memory networks | Natural language comprehension with the epireader | On multiplicative integration with recurrent neural networks | Learning multi-relational semantics using neural-embedding models | Multi-task cross-lingual sequence tagging from scratch,acl,100
691.pdf.json,Using Ontology-Grounded Token Embeddings To Predict Prepositional Phrase Attachments,"Type-level word embeddings map a word type (i.e., a surface form) to a dense vector of real numbers such that similar word types have similar embeddings. When pre-trained on a large corpus of unlabeled text, they provide an effective mechanism for generalizing statistical models to words which do not appear in the labeled training data for a downstream task. In this paper, we make the following distinction between types and tokens: By word types, we mean the surface form of the word, whereas by tokens we mean the instantiation of the surface form in a context. For example, the same word type ‘pool’ occurs as two different tokens in the sentences “He sat by the pool,” and “He played a game of pool.” Most word embedding models define a single vector for each word type. However, a fundamen- tal flaw in this design is their inability to distinguish between different meanings and abstractions of the same word. In the two sentences shown above, the word ‘pool’ has different meanings, but the same representation is typically used for both of them. Similarly, the fact that ‘pool’ and ‘lake’ are both kinds of water bodies is not explicitly incorporated in most type-level embeddings. Furthermore, it has become a standard practice to tune pre-trained word embeddings as model parameters during training for an NLP task (e.g., Chen and Manning, 2014; Lample et al., 2016), potentially allowing the parameters of a frequent word in the labeled training data to drift away from related but rare words in the embedding space. Previous work partially addresses these problems by estimating concept embeddings in WordNet (e.g., Rothe and Schütze, 2015), or improving word representations using information from knowledge graphs (e.g., Faruqui et al., 2015). However, it is still not clear how to use a lexical ontology to derive context-sensitive token embeddings. In this paper, we represent a word token in a given context by estimating a context-sensitive probability distribution over relevan",Improving parsing and pp attachment performance with sense information | Neural machine translation by jointly learning to align and translate | A linear dynamical system model for text | Exploring compositional architectures and word vector representations for prepositional phrase attachment | A rule-based approach to prepositional phrase attachment disambiguation | A fast and accurate dependency parser using neural networks | A unified model for word sense representation and disambiguation | Keras | Retrofitting word vectors to semantic lexicons | Improving word representations via global context and multiple word prototypes | Ontologically grounded multi-sense representation learning for semantic vector space models | A large-scale classification of english verbs | Neural architectures for named entity recognition | Low-rank tensors for scoring dependency structures | Distributed representations of words and phrases and their compositionality | Wordnet: a lexical database for english | Efficient non-parametric estimation of multiple embeddings per word in vector space | Glove: Global vectors for word representation | A maximum entropy model for prepositional phrase attachment | Multi-prototype vector-space models of word meaning | Semantic classes and syntactic ambiguity | Autoextend: Extending word embeddings to embeddings for synsets and lexemes | Word representations via gaussian embedding | Improving lexical embeddings with semantic knowledge | Selectional preferences for semantic role classification,acl,100
699.pdf.json,,"Keyphrase or keyword is a piece of short and summative content that expresses the main semantic meaning of a long text. A typical use of keyphrase or keyword is in scientific publications, to provide the core information of a paper. We use the term “keyphrase”, interchangeable as “keyword”, in the rest of this paper, as it implies that it may contain multiple words. High-quality keyphrases can facilitate the understanding, organizing and accessing of document content. As a result, many stud- ies have devoted to studying the ways of automatic extracting keyphrases from textual content (Liu et al., 2009; Medelyan et al., 2009a; Witten et al., 1999). Due to the public accessibility, many scientific publication datasets are often used as the test beds for keyphrase extraction algorithms. Therefore, this study also focuses on extracting keyphrases from scientific publications. Automatically extracting keyphrases from a document is called Keypharase Extraction, and it has been widely exploited in many applications, such as information retrieval (Jones and Staveley, 1999), text summarization (Zhang et al., 2004), text categorization (Hulth and Megyesi, 2006), and opinion mining (Berend, 2011). Most of the existing keyphrase extraction algorithms addressed this problem through two steps (Liu et al., 2009; Tomokiyo and Hurst, 2003). The first step is to acquire a list of keyphrase candidates. Researchers have tried to use n-grams or noun phrases with certain part-of-speech patterns for identifying the potential candidates (Hulth, 2003; Le et al., 2016; Liu et al., 2010; Wang et al., 2016). The second step is to rank candidates regarding their importance to the document, either through supervised or unsupervised machine learning methods with a set of manuallydefined features (Frank et al., 1999; Liu et al., 2009, 2010; Kelleher and Luz, 2005; Matsuo and Ishizuka, 2004; Mihalcea and Tarau, 2004; Song et al., 2003; Witten et al., 1999). There are two major drawbacks for the abo",A Convolutional Attention Network for Extreme Summarization of Source Code | Neural machine translation by jointly learning to align and translate | Opinion expression mining by exploiting keyphrase extraction | Learning phrase representations using rnn encoder-decoder for statistical machine translation | Domain-specific keyphrase extraction | Lstm recurrent networks learn simple context-free and contextsensitive languages | Extracting keyphrases from research papers using citation networks | Extracting key terms from noisy and multitheme documents | Incorporating copying mechanism in sequence-to-sequence learning | Conundrums in unsupervised keyphrase extraction: making sense of the state-of-the-art | Long short-term memory | Improved automatic keyword extraction given more linguistic knowledge | A study on automatically extracted keywords in text categorization | Phrasier: a system for interactive document retrieval using keyphrases | Automatic hypertext keyphrase detection | Semeval-2010 task 5: Automatic keyphrase extraction from scientific articles | Adam: A method for stochastic optimization | Large dataset for keyphrases extraction | Unsupervised Keyphrase Extraction: Introducing New Kinds of Words to Keyphrases | Automatic keyphrase extraction by bridging vocabulary gap | Automatic keyphrase extraction via topic decomposition | Clustering to find exemplar terms for keyphrase extraction | Humb: Automatic key term extraction from scientific articles in grobid | Sequence level training with recurrent neural networks | Keyword extraction from a single document using word co-occurrence statistical information | Human-competitive tagging using automatic keyphrase extraction | Human-competitive tagging using automatic keyphrase extraction | Topic indexing with wikipedia | Textrank: Bringing order into texts | Keyphrase extraction in scientific publications | A neural attention model for abstractive sentence summarization | Building end-to-end dialogue systems using generative hierarchical neural network models | Minimum risk training for neural machine translation | Kpspotter: a flexible information gain-based keyphrase extraction system | Sequence to sequence learning with neural networks | A language model approach to keyphrase extraction | Grammar as a foreign language | Single document keyphrase extraction using neighborhood knowledge | PTR: Phrase-Based Topical Ranking for Automatic Keyphrase Extraction in Scientific Publications | Kea: Practical automatic keyphrase extraction | Efficient summarization with read-again and copy mechanism | World wide web site summarization,acl,100
706.pdf.json,Naturalizing a Programming Language via Interactive Learning,"In tasks such as analyzing and plotting data, querying databases, manipulating texts, or controlling the Internet of Things, people need computers to perform well-specified but complex actions. To accomplish this, one route is to use a programming language, but this is inaccessible to most and can be tedious even for programmers. Another route is to convert natural language into a formal language, which has been the subject of work in semantic parsing (Zettlemoyer and Collins, 2005; Artzi and Zettlemoyer, 2013; Kushman and Barzilay, 2013; Quirk et al., 2015; Pasupat and Liang, 2015). However, the expressivity of semantic Cubes: initial – select left 6 – select front 8 – black 10x10x10 frame – black 10x10x10 frame – move front 10 – red cube size 6 – move bot 2 – blue cube size 6 – green cube size 4 – (some steps are omitted) Monsters, Inc: initial – move forward – add green monster – go down 8 – go right and front – add brown floor – add girl – go back and down – add door – add black column 30 – go up 9 – finish door – (some steps for moving are omitted) Deer: initial – bird’s eye view – deer head; up; left 2; back 2; { left antler }; right 2; {right antler} – down 4; front 2; left 3; deer body; down 6; {deer leg front}; back 7; {deer leg back}; left 4; {deer leg back}; front 7; {deer leg front} – (last step censored) Figure 1: Users interactively naturalize the language in Voxelurn (http://anonymous. url). Three of the 230 structures are shown. parsers is still quite primitive compared to the power one wields with a programming language. In this paper, we propose bridging this gap with a new interactive language learning process which we call naturalization. We seed a system with a core programming language, always available to the user. As users instruct the system to per- 2 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 1",Weakly supervised learning of semantic parsers for mapping instructions to actions | Semantic parsing on Freebase from question-answer pairs | Learning to interpret natural language navigation instructions from observations | Adaptive subgradient methods for online learning and stochastic optimization | Using semantic unification to generate regular expressions from natural language | Inducing probabilistic CCG grammars from logical form with higher-order unification | Lambda dependency-based compositional semantics | Learning executable semantic parsers for natural language understanding | Environment-driven lexicon induction for high-level instructions | Compositional semantic parsing on semi-structured tables | Language to code: Learning semantic parsers for if-thisthen-that recipes | Understanding natural language commands for robotic navigation and mobile manipulation | Learning language games through interaction | Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars,acl,100
71.pdf.json,,"Information provided in languages which people can understand saves lives in crises. For example, language barrier was one of the main difficulties faced by humanitarian workers responding to the Ebola crisis in 2014. We propose to break language barriers by extracting information (e.g., entities) from a massive variety of languages and ground the information into an existing knowledge base which is accessible to a user in his/her own language (e.g., a reporter from the World Health Organization who speaks English only). ✤Wikipedia Article: Mao Zedong (d. 26 Aralık 1893 - ö. 9 Eylül 1976), Çinli devrimci ve siyasetçi. Çin Komünist Partisinin (ÇKP) ve Çin Halk Cumhuriyetinin kurucusu. ✤Wikipedia Markup: [[Mao Zedong]] (d. [[26 Aralık]] [[1893]] - ö. [[9 Eylül]] [[1976]]), Çinli devrimci ve siyasetçi. [[Çin Komünist Partisi]]nin (ÇKP) ve [[Çin Halk Cumhuriyeti]]nin kurucusu. KB Properties (e.g., DBpedia, YAGO) formationDate headquarter ideology … (Mao Zedong (December 26, 1893 - September 9, 1976) is a Chinese revolutionary and politician. The founder of the Chinese Communist Party (CCP) and the People's Republic of China.) tr/Çin_Komünist_Partisi Anchor Link en/Communist_Party_of_China Cross-lingual Link e.g., [[Çin Komünist Partisi]]nin nin Wikipedia Topic Categories Ruling Communist parties Chinese Civil War Parties of one-party systems … Affix It is probably too ambitious and challenging to perform this task for all the languages in the world due to the scarcity of resources, but perhaps we could give it a try for hundreds of them. For instance, Wikipedia is a massively multi-lingual resource that currently hosts 295 languages and contains naturally annotated markups 1 and rich informational structures through crowd-sourcing for 35 million articles in 3 billion words. Name mentions in Wikipedia are often labeled as anchor links to their corresponding referent pages. Each entry in Wikipedia is also mapped to external knowl- 1https://en.wikipedia.org/wiki/Help:Wiki ","Paradigm classification in supervised learning of morphology | Mapping arabic wikipedia into the named entities taxonomy | Automatic creation of arabic named entity annotated corpus using wikipedia | Automatic acquisition of named entity tagged corpus from world wide web | Abstract meaning representation for sembanking | Freebase: a collaboratively created graph database for structuring human knowledge | Normalized (pointwise) mutual information in collocation extraction | Exploiting background knowledge for relation extraction | Named entity recognition with bilingual constraints | Collaborative ranking: A case study on entity linking | Word association norms, mutual information, and lexicography | Tac entity linking by performing full-document entity extraction and disambiguation | Augmenting wikipedia with named entity tags | A neighborhood relevance model for entity linking | Assessing the challenge of fine-grained named entity recognition and classification | Webtlab: A cooccurence-based approach to kbp 2010 entitylinking task | Fine grained classification of named entities | Contextdependent fine-grained entity type tagging | Fine-grained classification of named entities exploiting latent semantic kernels | Morfessor flatcat: An hmmbased method for unsupervised and semi-supervised learning of morphology | Revisiting embedding features for simple semi-supervised learning | A generative entitymention model for linking entities with knowledge base | Unsupervised biographical event extraction using wikipedia traffic | Overview of tac-kbp2016 tri-lingual edl and its impact on end-to-end kbp | Exploiting wikipedia as external knowledge for named entity recognition | Multilingual named entity recognition using parallel data and metadata from wikipedia | Class label enhancement via related instances | Collective annotation of wikipedia entities in web text | Neural architectures for named entity recognition | Joint bilingual name tagging for parallel corpora | Named entity recognition for linguistic rapid response in low-resource languages: Sorani kurdish and tajik | Yago3: A knowledge base from multilingual wikipedias | Supervised morphology generation using parallel corpus | The stanford corenlp natural language processing toolkit | Crosslanguage entity linking | Learning to tag and tagging to learn: A case study on wikipedia | Distant supervision for relation extraction without labeled data | Fine-grained semantic typing of emerging entities | Transforming wikipedia into named entity training data | Learning multilingual named entity recognition from Wikipedia | A systematic comparison of various statistical alignment models | Unsupervised entity linking with abstract meaning representation | Exploiting semantic role labeling, wordnet and wikipedia for coreference resolution | Cmcrc at tac10: Document-level entity linking with graphbased re-ranking | Local and global algorithms for disambiguation to wikipedia | Clustype: Effective entity recognition and typing by relation phrase-based clustering | Classifying articles in english and german wikipedia | Arabic morphological tagging, diacritization, and lemmatization using lexeme models and feature ranking | A comparative study of minimally supervised morphological segmentation | One for all: Towards language independent named entity linking | Cross-lingual named entity recognition via wikification | Language and domain independent entity linking with quantified collective validation | Joint word alignment and bilingual named entity recognition using dual decomposition | Crosslingual projected expectation regularization for weakly supervised learning | Fine-grained entity recognition | Embedding methods for fine grained entity type classification | Hyena: Hierarchical type classification for entity names | Name tagging for low-resource incident languages based on expectation-driven learning | Bitext name tagging for annotation projection",acl,100
715.pdf.json,Reading Wikipedia to Answer Open-Domain Questions,"This paper considers the problem of answering factoid questions in an open-domain setting using Wikipedia as the unique knowledge source, as one does when looking for answers in an encyclopedia. Wikipedia is a constantly evolving source of detailed information that could facilitate intelligent machines — if they are able to leverage its power. Unlike knowledge bases (KBs) such as Freebase (Bollacker et al., 2008) or DBPedia (Auer et al., 2007), which are easier for computers to process but too sparsely populated for open-domain question answering (Miller et al., 2016), Wikipedia contains up-to-date knowledge that humans are interested in, but is designed for humans, not machines, to read. Using Wikipedia articles as the knowledge source causes the task of question answering (QA) to combine the challenges of both large-scale open-domain QA and of machine comprehension of text. In order to answer any question, one must first retrieve the few relevant articles among more than 5 millions items, and scan them carefully to identify the answer. Our work treats Wikipedia as a collection of articles and does not rely on its internal graph structure. As a result, our approach is generic and could be switched to another collection of documents. Large-scale QA systems like IBM’s DeepQA (Ferrucci et al., 2010) rely on multiple sources to answer: Wikipedia can be one of them but it is also paired with KBs, dictionaries, and even news articles, books, etc. As a result, such systems heavily rely on information redundancy among the sources to answer correctly. Having a single knowledge source forces the model to be very precise while searching for an answer as the evidence might appear only once. This challenge thus encourages research in the ability of a machine to read, a key motivation for the machine comprehension subfield and the creation of datasets such as SQuAD (Rajpurkar et al., 2016), CNN/Daily Mail (Hermann et al., 2015) and CBT (Hill et al., 2016). However, those machine","Using wikipedia at the trec qa track | Dbpedia: A nucleus for a web of open data | Neural machine translation by jointly learning to align and translate | YodaQA: a modular question answering system pipeline | Modeling of the question answering task in the YodaQA system | Semantic parsing on freebase from question-answer pairs | Freebase: a collaboratively created graph database for structuring human knowledge | Large-scale simple question answering with memory networks | An analysis of the AskMSR question-answering system | Mining knowledge from Wikipedia for the question answering task | Multitask learning | A thorough examination of the CNN/Daily Mail reading comprehension task | A unified architecture for natural language processing: deep neural networks with multitask learning | Open question answering over curated and extracted knowledge bases | Building Watson: An overview of the DeepQA project. AI magazine 31(3):59–79 | Elasticsearch: The Definitive Guide | Neural turing machines | Teaching machines to read and comprehend | Wikireading: A novel large-scale language understanding task over wikipedia | The Goldilocks Principle: Reading children’s books with explicit memory representations | What makes ImageNet good for transfer learning | A neural network for factoid question answering over paragraphs | From particular to general: A preliminary case study of transfer learning in reading comprehension | Adam: A method for stochastic optimization | Learning recurrent span representations for extractive question answering | The stanford corenlp natural language processing toolkit | Key-value memory networks for directly reading documents | Distant supervision for relation extraction without labeled data | Glove: Global vectors for word representation | SQuAD: 100,000+ questions for machine comprehension of text | Open domain question answering using Wikipedia-based knowledge model | Bidirectional attention flow for machine comprehension | Multi-perspective context matching for machine comprehension | Feature hashing for large scale multitask learning | Memory networks | Dynamic coattention networks for question answering",acl,100
723.pdf.json,MORSE: Semantic-ally Drive-n MORpheme SEgment-er,"Morpheme segmentation is a core natural language processing (NLP) task used as an integral component in systems related to fields such as information retrieval (IR) (Zieman and Bleich, 1997; Kurimo et al., 2007), automatic speech recognition (ASR) (Bilmes and Kirchhoff, 2003; Kurimo et al., 2006), and machine translation (MT) (Lee, 2004; Virpioja et al., 2007). Most previous works relied solely on orthographic features (Harris, 1970; Goldsmith, 2000; Creutz and Lagus, 2002, 2005, 2007) and neglected underlying semantic information. This has led to an oversegmentation of words because a change of the surface form pattern is a necessary but insufficient indication of a morphological change. For example, although the surface form of “freshman”, hints that it should be segmented to “freshman”, “freshman” does not describe semantically the compositional meaning of “fresh” and “man”. To compensate for this lack of semantic knowledge, previous works (Schone and Jurafsky, 2000; Baroni et al., 2002; Narasimhan et al., 2015) have incorporated semantic knowledge locally by checking the semantic relatedness of possibly morphologically related pair of words. In (Narasimhan et al., 2015), they check for semantic relatedness using cosine similarity in word representations (Mikolov et al., 2013a; Pennington et al., 2014). A limitation of such approach is due to noise in word representations, even more so in the case of rare words. Moreover, limitation to local comparison enforces modeling morphological relations via semantic relatedness, although it has been shown that difference vectors model morphological relations more accurately (Mikolov et al., 2013b). To address this issue, we introduce a new framework (MORSE), the first to bring semantics into morpheme segmentation both on a local and a vocabulary-wide level. That is, when checking for the morphological relation between two words, we not only check for the semantic relatedness of the pair at hand (local), but also check if t","The celex lexical database [cd-rom] philadelphia: University of pennsylvania | The basics of item response theory | Unsupervised discovery of morphologically related words based on orthographic and semantic similarity | Exocentric compounds | Factored language models and generalized parallel backoff | The sigmorphon 2016 shared task— morphological reinflection | A joint model of orthography and morphological segmentation | Unsupervised discovery of morphemes | Unsupervised morpheme segmentation and morphology induction from text corpora using Morfessor 1.0 | Unsupervised models for morpheme segmentation and morphology learning | Linguistica: An automatic morphological analyzer | Morfessor flatcat: An hmmbased method for unsupervised and semi-supervised learning of morphology | From phoneme to morpheme | Adaptor grammars: A framework for specifying compositional nonparametric bayesian models | Semi-supervised learning of concatenative morphology | Unsupervised morpheme analysis evaluation by ir experiments-morpho challenge 2007 | Unsupervised segmentation of words into morphemes– challenge 2005: An introduction and evaluation report | Conditional random fields: Probabilistic models for segmenting and labeling sequence data | Morphological analysis for statistical machine translation | Learning from unseen data | Efficient estimation of word representations in vector space | Linguistic regularities in continuous space word representations | An unsupervised method for uncovering morphological chains | Glove: Global vectors for word representation | Unsupervised morphological segmentation with log-linear models | Stochastic complexity in statistical inquiry, volume 15 | Supervised morphological segmentation in a low-resource learning setting using conditional random fields | Painless semi-supervised morphological segmentation using conditional random fields | Knowledge-free induction of morphology using latent semantic analysis | Minimallysupervised morphological segmentation using adaptor grammars | Unsupervised morphology induction using word embeddings | Unsupervised morphological segmentation using neural word embeddings | Empirical comparison of evaluation methods for unsupervised learning of morphology | Morphology-aware statistical machine translation based on morphs induced in an unsupervised manner | Understanding semantic change of words over centuries | Conceptual mapping of user’s queries to medical subject headings",acl,100
726.pdf.json,Learning a Neural Semantic Parser from User Feedback,"Existing semantic parsing approaches for building natural language interfaces to databases (NLIDBs) either use special-purpose intermediate meaning representations that lack the full expressivity of database query languages or require extensive feature engineering, making it difficult to deploy them in new domains. We present a robust approach to quickly and easily learn and deploy semantic parsers from scratch, whose performance improves over time based on user feedback and requires minimal intervention. To learn these semantic parsers, we (1) adapt neural sequence models to map utterances directly to SQL thereby bypassing intermediate representations and taking full advantage of SQL’s querying capabilities, (2) immediately deploy the model online to solicit questions and user feedback on results to reduce SQL annotation efforts, and (3) use crowd workers from skilled markets to provide SQL annotations that can directly be used for model improvement, in addition to being easier and cheaper to obtain than logical meaning representations. We demonstrate the effectiveness of the complete approach by successfully learning a semantic parser for an academic domain by simply deploying it online for three days. This type of interactive learning is related to a number of recent ideas in semantic parsing, including batch learning of models that directly produce programs (e.g. regular expressions (Locascio et al., 2016)), learning from paraphrases (often gathered through crowdsourcing (Wang et al., 2 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 2015)), data augmentation (e.g. based on manually engineered semantic grammars (Jia and ",Neural machine translation by jointly learning to align and translate | Semantic parsing on freebase from question-answer pairs | Sentence rewriting for semantic parsing | Scalable semantic parsing with partial ontologies | Driving semantic parsing from the world’s response | Language to logical form with neural attention | PPDB: The paraphrase database | Translating questions to SQL queries with generative parsers discriminatively reranked | Data recombination for neural semantic parsing | Globally coherent text generation with neural checklist models | Adam: A method for stochastic optimization | Weakly supervised training of semantic parsers | Learning to automatically solve algebra word problems | Using semantic unification to generate regular expressions from natural language | Lexical generalization in ccg grammar induction for semantic parsing | Learning dependency-based compositional semantics | Latent predictor networks for code generation | Neural generation of regular expressions from natural language with minimal domain knowledge | Effective approaches to attention-based neural machine translation | Distributed representations of words and phrases and their compositionality | Grounded unsupervised semantic parsing | Towards a theory of natural language interfaces to databases | Database Management Systems | Equation parsing : Mapping sentences to grounded equations | Learning language games through interaction | Building a semantic parser overnight | Generation by inverting a semantic parser that uses statistical machine translation | The value of semantic parse labeling for knowledge base question answering | Recurrent neural network regularization | Learning to parse database queries using inductive logic programming | Learning to map sentences to logical form: structured classification with probabilistic categorial grammars | Online learning of relaxed ccg grammars for parsing to logical form,acl,100
727.pdf.json,Leveraging Behavioral and Social Information for Weakly Supervised Collective Classification of Political Discourse on Twitter,"The importance of understanding political discourse on social media platforms is becoming increasingly clear. In recent U.S. presidential elections, Twitter was widely used by all candidates to promote their agenda, interact with supporters, and attack their opponents. Social interactions on such platforms allow politicians to quickly react to current events and gauge interest in and support for their actions. These dynamic settings both emphasize the importance of constructing automated tools for analyzing this content, but also the difficulty of constructing such tools as the language used to discuss new events and political agendas continuously changes. Consequently, the rich social interactions on Twitter can be leveraged to help support such analysis by providing alternatives to direct supervision. In this paper we focus on political framing, a very nuanced political discourse analysis task, on Twitter, a relatively unexplored domain for this task. Framing (Entman, 1993; Chong and Druckman, 2007) is employed by politicians to bias the discussion towards their stance by emphasizing specific aspects of the issue. For example, the debate around increasing the minimum wage can be framed as a quality of life issue or as an economic issue. While the first frame supports increasing minimum wage because it betters workers’ lives, the second frame, by conversely emphasizing the costs involved, opposes the increase. Using framing to analyze political discourse has gathered significant interest over the last few years (Tsur et al., 2015; Card et al., 2015; Baumer et al., 2015) as a way to automatically analyze political discourse in Congressional speeches and political news articles. Our dataset consists of the tweets authored by all members of the U.S. Congress from both parties, dealing with several policy issues (e.g., immigration, ACA, etc.). We annotated these tweets by adapting the annotation guidelines developed by Boydstun et al. for Twitter. More details about th",How can you say such things?!?: Recognizing disagreement in informal political argument | Identifying opinion subgroups in arabic online discussions | Hinge-loss markov random fields and probabilistic soft logic | Hinge-loss Markov random fields: Convex inference for structured prediction | Sentiment analysis of political tweets: Towards an accurate classifier | Open extraction of fine-grained political statements | Testing and comparing computational approaches for identifying the language of framing in political news | On using twitter to monitor political sentiment and predict election results | Tracking the development of media frames within and across policy issues | The media frames corpus: Annotations of frames across issues | Hedge detection as a lens on framing in the gmo debates: A position paper | Framing theory | Predicting the political alignment of twitter users | What does twitter have to say about ideology? In NLP 4 CMC | Weakly supervised tweet stance classification by relational bootstrapping | What to do about bad language on the internet | Framing: Toward clarification of a fractured paradigm | An empirical exploration of moral foundations theory in partisan news sources | How they vote: Issue-adjusted models of legislative behavior | More than words: Syntactic packaging and implicit sentiment | Why are you taking this stance? identifying and classifying reasons in ideological debates | Social group modeling with probabilistic soft logic | Political ideology detection using recursive neural networks | all i know about politics is what i read in twitter”: Weakly supervised models for extracting politicians stances from twitter | Major life event extraction from twitter based on congratulations/condolences speech acts | Weakly supervised user profile extraction from twitter | Learning for microblogs with distant supervision: Political forecasting with twitter | Tea party in the house: A hierarchical ideal point topic model and its application to republican legislators in the 112th congress | From tweets to polls: Linking text sentiment to public opinion time series | Political tendency identification in twitter using sentiment analysis techniques | Linguistic models for analyzing and detecting biased language | Unsupervised modeling of twitter conversations | Measuring ideological proportions in political speeches | Recognizing stances in online debates | Recognizing stances in ideological on-line debates | Joint models of disagreement and stance in online debate | The effect of wording on message propagation: Topicand author-controlled natural experiments on twitter | A frame of mind: Using statistical models for detection of framing and agenda setting campaigns | Predicting elections with twitter: What 140 characters reveal about political sentiment | Inferring latent user properties from texts published in social media | Inferring user political preferences from streaming communications | Stance classification using dialogic properties of persuasion | Exploiting social network structure for person-to-person sentiment analysis | Learning subjective language,acl,100
729.pdf.json,Detect Rumors in Microblog Posts Using Propagation Structure via Kernel Learning,"On November 9th, 2016, Eric Tucker, a grassroots user who had just about 40 followers on Twitter, tweeted his unverified observations about paid protesters being bused to attend anti-Trump demonstration in Austin, Texas. The tweet, which was proved false later, was shared over 16 thousand times on Twitter and 350 thousand times on Facebook within a couple of days, fueling a nation-wide conspiracy theory1. The diffusion of the story is illustrated as Figure 1 which gives the key spreading points of the story along the time line. We can see that after the initial post, the tweet 1https://www.nytimes.com/2016/11/20/ business/media/how-fake-news-spreads. html was shared or promoted by some influential online communities and users (including Trump himself), resulting in its wide spread. A widely accepted definition of rumor is “unverified and instrumentally relevant information statements in circulation” (DiFonzo and Bordia, 2007). This unverified information may eventually turn out to be true, or partly or entirely false. In today’s ever-connected world, rumors can arise and spread at lightening speed thanks to social media platforms, which could not only be wrong, but be misleading and dangerous to the public society. Therefore, it is crucial to track and debunk such rumors in timely manner. Journalists and fact-checking websites such as snopes.com have made efforts to track and detect rumors. However, such endeavor is manual, thus prone to poor coverage and low speed. Feature-based methods (Castillo et al., 2011; Yang et al., 2012; Ma et al., 2015) achieved certain success by employing large feature sets crafted from message contents, user profiles and holistic statistics of diffusion patterns (e.g., number of retweets, propagation time, etc.). But such an approach was over simplified as they ignored the dynamics of rumor propagation. Existing studies considering propagation characteristics mainly focused on the temporal features (Kwon et al., 2013, 2017) rather than ","Information credibility on twitter | Convolution kernels for natural language | Dependency tree kernels for relation extraction | Rumor, gossip and urban legends | Rumor cascades | Get back! you don’t know me like that: The social mediation of fact checking interventions in twitter conversations | Rumor detection over varying time windows | Prominent features of rumor propagation in online social media | Real-time rumor debunking on twitter | Classifying tweet level judgements of rumours in social media | Detecting rumors from microblogs with recurrent neural networks | Detect rumors using time series of social context information on microblogging websites | Tweeting is believing?: understanding microblog credibility perceptions | A study on convolution kernels for shallow semantic parsing | Efficient convolution kernels for dependency and constituent syntactic trees | An analysis of the user occupational class through twitter content | Rumor has it: Identifying misinformation in microblogs | Inside rumor: A personal journey | Exploring syntactic structural features for sub-tree alignment using bilingual tree kernels | Detecting event rumors on sina weibo automatically | On rumors: How falsehoods | False rumors detection on sina weibo by propagation structures | Automatic detection of rumor on sina weibo | Exploring syntactic structured features over parse trees for relation extraction using kernel methods | Enquiring minds: Early detection of rumors in social media from enquiry posts | Tree kernel-based relation extraction with context-sensitive structured parse tree information | Analysing how people orient to and spread rumours in social media by looking at conversational threads",acl,100
741.pdf.json,Automatic Induction of Synsets from a Graph of Synonyms,"A synset is a set of mutual synonyms, which can be represented as a clique where nodes are words and edges are synonymy relations. Synsets represent word senses and are building blocks of WordNet (Miller, 1995) and similar resources as thesauri and lexical ontologies. These resources are crucial for many natural language processing applications which require common sense reasoning, such as information retrieval (Gong et al., 2005) and question answering (Kwok et al., 2001; Zhou et al., 2013). However, for most languages no manually-constructed resource comparable to the English WordNet in terms of coverage and quality is available. For instance, Kiselev et al. (2015) presents a comparative analysis of lexical resources available for the Russian language. This lack of linguistic resources for many languages urges the development of new methods for automatic construction of WordNet-like resources. Wikipedia1, Wiktionary2, OmegaWiki3 and other collaboratively-created resources contain a large amount of lexical semantic information— yet designed to be human-readable and not formally structured. While semantic relations can be automatically extracted using such tools as DKPro JWKTL4 and Wikokit5, words in these relations are not disambiguated. For instance, the synonymy pairs (bank, streambank) and (bank, banking company) will be connected via the word “bank”, while they refer to the different senses. This problem stems from the fact that articles in Wiktionary and similar resources list undisambiguated synonyms. They are easy to disambiguate for humans while reading a dictionary article, but can be a source of errors for a language processing system. The contribution of this paper is a novel approach which resolves ambiguities of the input graph enabling fuzzy clustering. The method takes as an input synonymy relations between potentially ambiguous terms available in humanreadable dictionaries and transforms them into a disambiguated machine readable representation in t","The dictionary of Russian synonyms and semantically related expressions (Словарь русских синонимов и сходных по смыслу выражений) | Distributional Memory: A General Framework for Corpus-based Semantics | Chinese Whispers: An Efficient Graph Clustering Algorithm and Its Application to Natural Language Processing Problems | Creating a system for lexical substitutions from scratch using crowdsourcing | Text: now in 2D! A framework for lexical expansion with contextual similarity | The maximum clique problem | YARN: Spinning-inProgress | Clustering and Diversifying Web Search Results with Graph-Based Word Sense Induction | Development of lexical basis for the Universal Dictionary of UNL Concepts | Discovering Corpus-Specific Word Senses | ECO and Onto.PT: a flexible approach for creating a Portuguese wordnet automatically. Language Resources and Evaluation 48(2):373–393 | Web Query Expansion by WordNet | UBY — A Large-Scale Unified Lexical-Semantic Resource Based on LMF | Modelling Word Similarity: an Evaluation of Automatic Synonymy Extraction Algorithms | MaxMax: A GraphBased Soft Clustering Algorithm Applied to Word Sense Induction | Using WordNet to Measure Semantic Orientations of Adjectives | Current Status of Russian Electronic Thesauri: Quality, Completeness and Availability (Современное состояние электронных тезаурусов русского языка: качество, полнота и до | An approach to automated construction of a general-purpose lexical ontology based on Wiktionary | Scaling Question Answering to the Web | An Information-Theoretic Definition of Similarity | Thesauri in information retrieval tasks (Тезаурусы в задачах информационного поиска) | Distributed Representations of Words and Phrases and their Compositionality | WordNet: A Lexical Database for English | BabelNet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network | Uncovering the overlapping community structure of complex networks in nature and society | Discovering Word Senses from Text | Learning to Merge Word Senses | Graph Clustering by Flow Simulation | HyperLex: lexical cartography for information retrieval | Extracting Lexical Semantic Knowledge from Wikipedia and Wiktionary | Improving question retrieval in community question answering using world knowledge",acl,100
752.pdf.json,,"Abstract Meaning Representation (AMR) is a graph based formalism that encodes many aspects of the meaning of a natural language sentence (for example, see Figure 1). AMR has been used as an intermediate representation for machine translation (Jones et al., 2012), summarization (Liu et al., 2015), sentence compression (Takase et al., 2016), event extraction (Huang et al., 2016), and has potential applications in dialogue, or human-robotic interaction. While AMR is extremely expressive, annotation is expensive and training data is limited, making application of neural methods challenging (Misra and Artzi, 2016; Peng and Xue, 2017; Barzdins and Gosko, 2016). Obama was elected and his voters celebrated Obama elect.01 celebrate.01 voters and * op1 op2 arg0 poss arg0 person name name op1 In this work, we tackle both AMR parsing and AMR realization together, showing the first successful sequence-to-sequence (seq2seq) models for both problems. While seq2seq models have been broadly used (Wu et al., 2016; Bahdanau et al., 2014; Luong et al., 2015; Vinyals et al., 2015), application to AMR has been limited, at least in part because effective linearization (encoding graphs as linear sequences) and data sparsity were thought to pose significant challenges. We show these challenges can be easily overcome, by demonstrating that seq2seq models can be trained using any graph-isomorphic linearization and that unlabeled text can be used to significantly reduce sparsity. Our approach is two-fold. First, we carefully preprocess the AMR, anonymizing entities and dates, grouping entity categories, and encoding nesting information in concise ways, for example see Figure 2(d). Under such a representation, we show that any depth first traversal of the AMR is effective for constructing a linearization, and it is even possible to use a different random or- 2 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 ",Broad-coverage ccg semantic parsing with amr | Neural machine translation by jointly learning to align and translate | Riga at semeval-2016 task 8: Impact of smatch extensions and character-level neural translation on amr parsing accuracy | The meaning factory at semeval-2016 task 8: Producing amrs with boxer | Icl-hd at semeval-2016 task 8: Meaning representation parsing - augmenting amr parsing with a preposition semantic role labeling neural network | Smatch: an evaluation metric for semantic feature structures | Incorporating non-local information into information extraction systems by gibbs sampling | Generation from abstract meaning representation using tree transducers | A discriminative graph-based parser for the abstract meaning representation | Ucl+sheffield at semeval-2016 task 8: Imitation learning for amr parsing with an alpha-bound | Liberal event extraction and event schema induction | Semantics-Based Machine Translation with Hyperedge Replacement Grammars | Toward abstractive summarization using semantic representations | Effective approaches to attention-based neural machine translation | Neural shift-reduce ccg semantic parsing | Annotated gigaword | The Proposition Bank: An annotated corpus of semantic roles | Bleu: a method for automatic evaluation of machine translation | Addressing the data sparsity issue in neural amr parsing | Aligning english strings with abstract meaning representation graphs | Generating english from abstract meaning representations | Parsing english into abstract meaning representation using syntaxbased machine translation | M2l at semeval-2016 task 8: Amr parsing with neural networks | Improving neural machine translation models with monolingual data | Amr-to-text generation as a traveling salesman problem | Neural headline generation on abstract meaning representation | Grammar as a foreign language | Camr at semeval2016 task 8: An extended transition-based amr parser | Amr parsing with an incremental joint model,acl,100
759.pdf.json,Joint Modeling of Content and Discourse Relations in Dialogues,"Goal-oriented dialogues, such as meetings, negotiations, or customer service transcripts, play an important role in our daily life. Automatically extracting the critical points and important outcomes from dialogues would facilitate generating summaries for complicated conversations, understanding the decision-making process of meetings, or analyzing the effectiveness of collaborations. We are interested in a specific type of dialogues — spoken meetings, which is a common way for collaboration and idea sharing. Previous work (Kirschner et al., 2012) has shown that discourse structure can be used capture the main discussion points and arguments put forward during problem-solving and decision-making processes in meetings. Indeed, content of different speaker turns do not occur in isolation, and should be interpreted within the context of discourse. Meanwhile, content can also reflect the purpose of speaker turns, thus facilitate with discourse relation understanding. Take the meeting snippet from AMI corpus (Carletta et al., 2006) in Figure 1 as D: Three different types of batteries. Um can either use a hand dynamo, or the kinetic type ones, you know that they use in watches, or else uh a solar powered one. B: Um the bat uh the battery for a a watch wouldn't require a lot of power, would be my one query. Is a kinetic one going to be able to supply enough power? D: Yeah, I don't think it would. C: Yeah. D: We should probably just use conventional batteries. B: Which I suppose as well would allow us to go off the shelf again, you'd say ? D: Yeah. Uncertain Option an example. This discussion is annotated with discourse structure based on the Twente Argumentation Schema (TAS) by Rienks et al. (2005), which focuses on argumentative discourse information. As can be seen, meeting participants evaluate different options by showing doubt (UNCERTAIN), bringing up alternative solution (OPTION), or giving feedback. The discourse information helps with the identification of the key",Extractive summarization of multi-party meetings through discourse segmentation | Extracting decisions from multi-party dialogue using directed graphical models and semantic similarity | The ami meeting corpus: A pre-announcement | Learning to classify email into speech acts | Recognition of dialogue acts in multiparty meetings using a switching dbn | Identifying relevant phrases to summarize decisions in spoken meetings | A skip-chain conditional random field for ranking meeting utterances by importance | Analyzing argumentative discourse units in online interactions | A global optimization framework for meeting summarization | Towards automatic argument diagramming of multiparity meetings | HILDA: A discourse parser using support vector machine classification | The icsi meeting corpus | A latent variable recurrent neural network for discourse-driven language models | Recurrent convolutional neural networks for discourse compositionality | Improving team’s consistency of understanding in meetings | Visualizing argumentation: Software tools for collaborative and educational sensemaking | Accurate unlexicalized parsing | Automatic evaluation of summaries using n-gram co-occurrence statistics | Using spoken utterance compression for meeting summarization: A pilot study | Building a dataset for summarization and keyword extraction from emails | Using question-answer pairs in extractive summarization of email conversations | Abstractive summarization of spoken and written conversations based on phrasal queries | Sociocultural discourse analysis | Assessing group learning and shared understanding in technology-mediated interaction | Generating and validating abstracts of meeting conversations: A user study | Incorporating speaker and discourse features into speech summarization | High frequency word entrainment in spoken dialogue | Extractive summarization and dialogue act modeling on email threads: An integrated probabilistic approach | Integer linear programming for discourse parsing | Long story short - global unsupervised models for keyphrase based meeting summarization | Argument diagramming of meeting conversations | Samplerank: Training factor graphs with atomic gradients | Dependency parsing by belief propagation | Dialogue act modeling for automatic tagging and recognition | Focused Meeting Summarization via Unsupervised Relation Extraction | Domainindependent abstract generation for focused meeting summarization,acl,100
760.pdf.json,,"The last few years have seen much success of applying neural networks to many important applications in natural language processing, e.g., partof-speech tagging, chunking, named entity recognition (Collobert et al., 2011), sentiment analysis (Socher et al., 2011, 2013), document classification (Kim, 2014; Le and Mikolov, 2014; Zhang et al., 2015; Dai and Le, 2015), machine translation (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014; Bahdanau et al., 2014; Sennrich et al., 2015; Wu et al., 2016), conversational/dialogue modeling (Sordoni et al., 2015; Vinyals and Le, 2015; Shang et al., 2015), document summarization (Rush et al., 2015; Nallapati et al., 2016), parsing (Andor et al., 2016) and automatic question answering (Q&A) (Weston et al., 2015; Hermann et al., 2015; Wang and Jiang, 2016; Wang et al., 2016; Trischler et al., 2016; Lee et al., 2016; Seo et al., 2016; Xiong et al., 2016). An important trait of all these models is that they read all the text available to them. While it is essential for certain applications, such as machine translation, this trait also makes it difficult to apply these models to scenarios that have long input text, such as document classification or automatic Q&A. In this paper, we consider the problem of understanding long documents with partial reading, and propose a modification to the basic neural architectures that allows them to read input text nonsequentially. The main benefit of this approach is faster inference because it skips irrelevant information. An unexpected benefit of this approach is that it also helps the models generalize better. In our approach, the model is a recurrent network, which learns to predict the number of jumping steps after it reads one or several input tokens. Such a discrete model is therefore not fully differentiable, but it can be trained by a standard policy gradient algorithm, where the reward can be the accuracy or its proxy during training. In our experiments, we use the basic LSTM recu","Globally normalized transition-based neural networks | Multiple object recognition with visual attention | Neural machine translation by jointly learning to align and translate | Listen, attend and spell | A thorough examination of the cnn/daily mail reading comprehension task | Hierarchical question answering for long documents | Hierarchical multiscale recurrent neural networks | Natural language processing (almost) from scratch | Semisupervised sequence learning | Adaptive computation time for recurrent neural networks | Neural turing machines | Teaching machines to read and comprehend | The goldilocks principle: Reading children’s books with explicit memory representations | Gradient flow in recurrent nets: the difficulty of learning long-term dependencies | Long short-term memory | Variable computation in recurrent neural networks | Recurrent continuous translation models | Convolutional neural networks for sentence classification | Adam: A method for stochastic optimization | A clockwork rnn | Distributed representations of sentences and documents | Learning recurrent span representations for extractive question answering | Rationalizing neural predictions | Learning word vectors for sentiment analysis | Distributed representations of words and phrases and their compositionality | Recurrent models of visual attention | Abstractive text summarization using sequence-to-sequence RNNs and beyond | Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales | A neural attention model for abstractive sentence summarization | Neural machine translation of rare words with subword units | Bidirectional attention flow for machine comprehension | Attention for fine-grained categorization | Neural responding machine for short-text conversation | Reasonet: Learning to stop reading in machine comprehension | Semi-supervised recursive autoencoders for predicting sentiment distributions | Recursive deep models for semantic compositionality over a sentiment treebank | A neural network approach to context-sensitive generation of conversational responses | Sequence to sequence learning with neural networks | A parallel-hierarchical model for machine comprehension on sparse data | A neural conversational model | Machine comprehension using match-lstm and answer pointer | Multi-perspective context matching for machine comprehension | Towards ai-complete question answering: A set of prerequisite toy tasks | Memory networks | Simple statistical gradientfollowing algorithms for connectionist reinforcement learning | Dynamic coattention networks for question answering | Reinforcement learning neural turing machines-revised | Character-level convolutional networks for text classification",acl,100
768.pdf.json,Detecting Lexical Entailment in Context,"Many NLP applications require detecting relations between word meanings beyond synonymy and paraphrasing. For instance, given “Carlsen plays chess.” and the question “Which game does Carlsen play?”, successfully answering the question requires knowing that chess is a kind of game, or more generally, that chess entails game. While prior work has defined lexical entailment as a relation between word types (Turney and Mohammad, 2013), we argue entailment relations are better defined when illustrating word meaning with an example in context. Ignoring context is problematic since entailment might hold between some senses of the words, but not others. Consider the word game in two distinct contexts: 1. The championship game was played in NYC. 2. The hunters were interested in the big game. Given the sentence, Carlsen is the world chess champion, chess =⇒ game as used in the first context, while chess 6=⇒ game in the second context. In this paper, we investigate how to represent and compare the meaning of words in context for lexical entailment. Since distributional representations for word types have proved useful to detect lexical entailment out of context in supervised settings (Baroni et al., 2012; Roller et al., 2014; Turney and Mohammad, 2013), we propose to transform context-agnostic word type representations into contextualized representations that highlight salient properties of the context (Section 3), and use these contextualized representations with a range of semantic similarity features (Section 4) to successfully detect entailment. As we will see, these context representations significantly improve performance over contextagnostic baselines not only in English, but also between English and French words (Section 7) on two novel datasets (Section 5). We also show that our features are sensitive to word sense changes indicated by context, and adequately capture the direction of entailment relation (Section 8). Moreover, we establish a new state-of-the-art on an","Vector-space models for PPDB paraphrase ranking in context | Linear Algebraic Structure of Word Meanings , with Applications to Polysemy | Entailment above the word level in distributional semantics | How we BLESSed distributional semantic evaluation | A large annotated corpus for learning natural language inference | Recognizing Textual Entailment: Models and Applications | Measuring Distributional Similarity in Context | A comparison of models of word meaning in context | A structured vector space model for word meaning in context | WordNet | WordNet: An Electronic Lexical Database | Introducing and evaluating ukWaC , a very large web-derived corpus of English | PPDB : The Paraphrase Database | Knowledge processing on an extended wordnet | Multilingual Models for Compositional Distributed Semantics | Demographic Factors Improve Classification Performance | Directional Distributional Similarity for Lexical Inference | Deriving Boolean structures from distributional vectors | Do Supervised Distributional Methods Really Learn Lexical Inference Relations? In NAACL HLT 2015 | Bilingual Word Representations with Monolingual Quality in Mind | SemEval2007 Task 10: English Lexical Substitution Task | context2vec: Learning Generic Context Embedding with Bidirectional LSTM | SemEval-2010 Task 2: Cross-Lingual Lexical Substitution | Computing Lexical Contrast | Adding Semantics to Data-Driven Paraphrasing | 2015b. PPDB 2.0: Better paraphrase ranking, finegrained entailment relations, word embeddings, and style classification | GloVe: Global Vectors for Word Representation | Multi-Prototype Vector-Space Models of Word Meaning | Inclusive yet Selective: Supervised Distributional Hypernymy Detection | Adding Context to Semantic Data-Driven Paraphrasing | Learning to Exploit Structured Resources for Lexical Inference | Hypernyms under Siege: Linguistically-motivated Artillery for Hypernymy Detection | Learning SentimentSpecific Word Embedding | Contextualizing Semantic Representations Using Syntactically Enriched Vector Models | Word Meaning in Context : A Simple and Effective Vector Model | Experiments with three approaches to recognizing lexical entailment | Sparse Bilingual Word Representations for Cross-lingual Lexical Entailment | Take and Took, Gaggle and Goose, Book and Read: Evaluating the Utility of Vector Differences for Lexical Relation Learning | Bootstrapping Distributional Feature Vector Quality",acl,100
769.pdf.json,Learning Symmetric Collaborative Dialogue Agents with Dynamic Knowledge Graph Embeddings,"Current task-oriented dialogue systems (Young et al., 2013; Wen et al., 2017; Dhingra et al., 2016) require a pre-defined dialogue state (e.g., slots such as food type and price range for a restaurant searching task) and a fixed set of dialogue acts (e.g., request, inform). However, human conversation often requires richer dialogue states and more nuanced, pragmatic dialogue acts. In contrast, recent open-domain chat systems (Shang et al., 2015; Serban et al., 2015b; Sordoni et al., 2015; Li et al., 2016a) learn a mapping directly from previous utterances to the next utterance. While these models capture open-ended aspects of dialogue, the lack of structured dialogue state prevents them from being directly applied to settings that require interfacing with structured knowledge. In order to bridge the gap between the two types of systems, we focus on a symmetric collabora- tive dialogue setting, which is task-oriented but encourages open-ended dialogue acts. In our setting, two agents, each with a private list of items with attributes, must communicate to identify the unique shared item. Consider the dialogue in Figure 1, in which two people are trying to find their mutual friend. When B asks “do you have anyone who went to columbia?”, it suggests that she has some Columbia friends and they probably work at Google. Such conversational implicature is lost when interpreting it as simply requesting information about Columbia. In addition, it is hard to define a state that captures the diverse semantics in these utterances (e.g., defining “most of”, “might be”; see details in Table 1). To model both structured and open-ended context, we propose the Dynamic Knowledge Graph Network (DynoNet), in which the dialogue state is modeled as a knowledge graph with an embedding for each node (Section 3). Our model is similar 2 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 14",Developing a corpus of strategic conversation in the settlers of catan | Frames: A corpus for adding memory to goaloriented dialogue systems | Neural machine translation by jointly learning to align and translate | Learning end-to-end goal-oriented dialog | End-to-end reinforcement learning of dialogue agents for information access | Adaptive subgradient methods for online learning and stochastic optimization | Tracking the world state with recurrent entity networks | Dialogue act tagging for instant messaging chat sessions | Data recombination for neural semantic parsing | A persona-based neural conversation model | A diversity-promoting objective function for neural conversation models | Deep reinforcement learning for dialogue generation | A user simulator for taskcompletion dialogues | How NOT to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation | Goal-driven answers in the Cards dialogue corpus | A hierarchical latent variable encoder-decoder model for generating dialogues | A survey of available corpora for building data-driven dialogue systems | Building end-to-end dialogue systems using generative hierarchical neural network models | Neural responding machine for short-text conversation | A neural network approach to context-sensitive generation of conversational responses | A network-based end-to-end trainable task-oriented dialogue system | The dialog state tracking challenge series: A review | End-to-end LSTM-based dialog control optimized with supervised and reinforcement learning | POMDP-based statistical spoken dialog systems: A review,acl,100
775.pdf.json,A Geometric Contextual Model for Identifying Unseen Metaphors,"The standard approach to the computational modelling of metaphor has been grounded in theoretical work suggesting that metaphors are mappings between conceptual domains, and has accordingly dealt with the construction of representational structures that allow symbolic mappings between semantic categories. The result has been a rich literature of both symbolic and statistical approaches to metaphor identification, interpretation, and even generation. Recent approaches in the statistical vein have tended to centre on the construction of linear algebraic representations of words – words as vectors and matrices – which can be compositionally interpreted in terms of their mathematical properties. One such example for identification of metaphor is (Gutiérrez et al., 2016), who reported strong results on a new dataset using a compositional technique involving the supervised and semi-supervised learning of adjective tensors for the classification of candidate adjective-noun metaphors. Here, we also take a distributional semantic approach, but predicated on a slightly different theoretical premise: we hold that metaphors are linguistic phenomena that emerge dynamically in the course of language use, as a semantic phenomenon at the end of a fluid spectrum, related to the ad hoc, situated nature of concept formation. Our work, based on a method described by McGregor et al. (2015) for concept formation, contextually generates a new subspace for every candidate metaphor, projecting word pairs into unique geometric relationships based on an analysis of their independent word-vector representations. In addition to its contextual flexibility, the strengths of our model are its simplicity and its generality: it requires only vectors for individual words, rather than representations of the potentially metaphoric phrases themselves, and is therefore suitable for the “zero-shot” setting of identifying a novel, unseen metaphor. Analysing the subspaces produced by our model by means of ","Modeling metaphor perception with distributional semantics vector space models | Nouns are vectors, adjectives are matrices: Representing adjective-noun constructions in semantic space | Flexibility, structure, and linguistic vagary in concepts: manifestations of a compositional system of perceptual symbols | Metaphor and the literal/nonliteral distinction | Vector space models of lexical meaning | Mathematical foundations for a compositional distributed model of meaning | What metaphors mean | Indexing by latent semantic analysis | Logic and conversation | Literal and metaphorical senses in compositional distributional semantic models | Identifying metaphorical word use with tree kernels | Metaphors We Live By | Reasoning about mixed metaphors within an implemented artificial intelligence system | Literal and figurative interpretations are computed in equal time | From distributional semantics to conceptual spaces: A novel computational method for concept creation | Efficient estimation of word representations in vector space | Compostion in distributional models of semantics | Metaphor and Thought | Davidson on metaphor | The distributional hypothesis | Models of metaphor in nlp | Design and evaluation of metaphor processing systems | Literal and metaphorical sense identification through concrete and abstract context | Computational exploration of metaphor comprehension processes using a semantic space model | Round up the usual suspects: Knowledge-based metaphor generation | A fluid knowledge representation for understanding and generating creative metaphors | Making preferences more active | Meaning and Relevance | Structuremapping in metaphor comprehension",acl,100
777.pdf.json,Other Topics You May Also Agree or Disagree: Modeling Inter-Topic Preferences using Tweets and Matrix Factorization,"Social media have changed the way people shape public opinions. The latest survey by Pew Research Center reported that a majority of US adults (62%) obtain news on social media, and 18% do so often (Gottfried and Shearer, 2016). As news and opinions are shared and amplified by friend networks of individuals (Jamieson and Cappella, 2008), individuals are also isolated from informa- tion that does not fit their opinions (Pariser, 2011). Ironically, the cutting-edge technology of social media promotes ideological groups even with its potential to deliver diverse information. A great deal of studies analyze discussions, interactions, influences, and communities on social media along the political spectrum of liberal to conservative (Adamic and Glance, 2005; Zhou et al., 2011; Cohen and Ruths, 2013; Bakshy et al., 2015; Wong et al., 2016). Even though these studies provide intuitive visualizations and interpretations along the axis of liberal-conservative, political analysts argue that the axis is flawed and insufficient for representing public opinions and ideologies (Kerlinger, 1984; Maddox and Lilie, 1984). A potential solution for analyzing multiple axes of political spectrum on social media is stance detection (Thomas et al., 2006; Somasundaran and Wiebe, 2009; Murakami and Raymond, 2010; Anand et al., 2011; Walker et al., 2012; Mohammad et al., 2016; Johnson and Goldwasser, 2016), whose task is to determine whether the author of a text is for, neutral, or against towards a topic (e.g., free trade, immigration, abortion). However, stance detection across different topics is extremely difficult. Anand et al. (2011) reported that a sophisticated method with topic-dependent features greatly improved the performance of stance detection within a topic, but could not outperform a baseline method with simple n-gram features when evaluated across topics. More recently, all participants of SemEval 2016 Task 6A (with five topics) could not outperform the baseline supervised m","The political blogosphere and the 2004 u.s. election: Divided they blog | Cats rule and dogs drool!: Classifying stance in online debate | Exposure to ideologically diverse news and opinion on facebook | Open extraction of fine-grained political statements | Lessons from the netflix prize challenge | Whats in twitter, i know what parties are popular and who you are supporting now! Social Network Analysis and Mining (SNAM | A fast parallel stochastic gradient method for matrix factorization in shared memory systems | Joint extraction of entities and relations for opinion recognition | Classifying political orientation on Twitter: It’s not easy! In Proc | Predicting the political alignment of twitter users | Enhanced sentiment learning using twitter hashtags and smileys | Mpqa 3.0: An entity/event-level sentiment corpus | Minimally supervised event causality identification | The yahoo! music dataset and kdd-cup’11 | Sparse additive generative models of text | Track 4 overview: Extraction of causal network information in biological expression language (BEL) | Automatic detection of causal relations for question answering | News use across social media platforms 2016 | Excitatory or inhibitory: A new semantic orientation extracts contradiction and causality from the web | Generating event causality hypotheses through semantic relations | Echo Chamber: Rush Limbaugh and the Conservative Media Establishment | Syntactic and semantic structure for opinion expression detection | all i know about politics is what i read in twitter”: Weakly supervised models for extracting politicians’ stances from twitter | Liberalism and Conservatism: The Nature and Structure of Social Attitudes | Matrix factorization techniques for recommender systems | Beyond Liberal and Conservative: Reassessing the Political Spectrum | Predicting political preference of twitter users | Semeval-2016 task 6: Detecting stance in tweets | Support or oppose?: classifying positions in online debates from reply activities and opinion expressions | From tweets to polls: Linking text sentiment to public opinion time series | The Filter Bubble: How the New Personalized Web Is Changing What We Read and How We Think | Learning emotion indicators from tweets: Hashtags, hashtag patterns, and phrases | Learning to predict from textual data | Learning causality for news events prediction | Measuring ideological proportions in political speeches | Recognizing stances in online debates | Get out the vote: Determining support or opposition from congressional floor-debate transcripts | Predicting elections with twitter: What 140 characters reveal about political sentiment | Monday mornings are my fave :) #not exploring the automatic recognition of irony in english tweets | That is your evidence?: Classifying stance in online political debate | Annotating expressions of opinions and emotions in language | Quantifying political leaning from tweets, retweets, and retweeters | Joint inference for fine-grained opinion extraction | Classifying the political leaning of news articles and users from user votes",acl,100
779.pdf.json,A Teacher-Student Framework for Zero-Resource Neural Machine Translation,"Neural machine translation (NMT) (Kalchbrenner and Blunsom, 2013; Sutskever et al., 2014; Bahdanau et al., 2014), which directly models the translation process in an end-to-end way, has attracted intensive attention from the community. Although NMT has achieved state-of-theart translation performance on resource-rich language pairs such as English-French and GermanEnglish (Luong et al., 2015; Jean et al., 2015; Wu et al., 2016), it still suffers from the unavailability of large-scale parallel corpora for translating low resource languages. Due to the large parameter space, neural models usually learn poorly from low-count events, resulting in a poor choice for low resource language pairs. Zoph et al. (2016) indicate that NMT obtains much worse translation quality than a statistical machine translation (SMT) system on low-resource languages. As a result, a number of authors have endeavored to explore methods for translating language pairs without parallel corpora available. These methods can be roughly divided into two broad categories: multilingual and pivot-based. Firat et al. (2016b) present a multi-way, multilingual model with shared attention to achieve zeroresource translation. They fine-tune the attention part using pseudo bilingual sentences for the zeroresource language pair. Another direction is to develop a universal NMT model in multilingual scenarios (Johnson et al., 2016; Ha et al., 2016). They use parallel corpora of multiple languages to train one single model, which is then able to translate a language pair without parallel corpora available. Although these approaches prove to be effective, the combination of multiple languages in modeling and training leads to significantly increased complexity. Another direction is to achieve source-to-target NMT without parallel data via a pivot, which is either text (Cheng et al., 2016) or image (Nakayama and Nishida, 2016b). Cheng et al. (2016) propose a pivot-based method to zero-resource NMT: it first translat","Neural machine translation by jointly learning to align and translate | Phrase-based statistical machine translation with pivot languages | Neural machine translation with pivot languages | Machine translation by triangulation: Making effective use of multi-parallel corpora | Catalanenglish statistical machine translation without parallel corpus: bridging through spanish | Multi-way, multilingual neural machine translation with a shared attention mechanism | Zero-resource translation with multi-lingual neural machine translation | Toward multilingual neural machine translation with universal encoder and decoder | On using very large target vocabulary for neural machine translation | Recurrent continuous translation models | Language independent connectivity strength features for phrase pivot statistical machine translation | Sequencelevel knowledge distillation | Europarl: a parallel corpus for statistical machine translation | Addressing the rare word problem in neural machine translation | Zeroresource machine translation by multimodal encoder-decoder network with multimedia pivot | Zero-resource machine translation by multimodel encoder-decoder network with multimedia pivot | Bleu: a method for automatic evaluation of machine translation | Neural machine translation of rare words with subword units | Minimum risk training for neural machine translation | Sequence to sequence learning with neural networks | A comparison of pivot methods for phrase-based statistical machine translation | Pivot language approach for phrase-based statistical machine translation | Revisiting pivot language approach for machine translation | Semisupervised learning for neural machine translation | Using context vectors in improving a machine translation system with bridge language | Improving pivot-based statistical machine translation using random walk | Transfer learning for low-resource neural machine translation",acl,100
79.pdf.json,An Interpretable Knowledge Transfer Model for Knowledge Base Completion,"Knowledge bases (KB), such as WordNet (Fellbaum, 1998), Freebase (Bollacker et al., 2008), YAGO (Suchanek et al., 2007) and DBpedia (Lehmann et al., 2015), are useful resources for many applications such as question answering (Berant et al., 2013; Yih et al., 2015; Dai et al., 2016) and information extraction (Mintz et al., 2009). However, knowledge bases suffer from incompleteness despite their formidable sizes (Socher et al., 2013; West et al., 2014), leading to a number of studies on automatic knowledge base completion (KBC) (Nickel et al., 2015) or link prediction. The fundamental motivation behind these studies is that there exist some statistical regularities under the intertwined facts stored in the multirelational knowledge base. By discovering gener- alizable regularities in known facts, missing ones may be recovered in a faithful way. Due to its excellent generalization capability, distributed representations, a.k.a. embeddings, have been popularized to address the KBC task (Nickel et al., 2011; Bordes et al., 2011, 2014, 2013; Socher et al., 2013; Wang et al., 2014; Guu et al., 2015; Nguyen et al., 2016b). As a seminal work, Bordes et al. (2013) proposes the TransE, which models the statistical regularities with linear translations between entity embeddings operated by a relation embedding. Implicitly, TransE assumes both entity embeddings and relation embeddings dwell in the same vector space, posing an unnecessarily strong prior. To relax this requirement, a variety of models first project the entity embeddings to a relationdependent space (Bordes et al., 2014; Ji et al., 2015; Lin et al., 2015b; Nguyen et al., 2016b), and then model the translation property in the projected space. Typically, these relation-dependent spaces are characterized by the projection matrices unique to each relation. As a benefit, different aspects of the same entity can be temporarily emphasized or depressed as an effect of the projection. For instance, STransE (Nguyen et al.,","Semantic parsing on Freebase from question-answer pairs | Theano: a cpu and gpu math expression compiler | Phonologically aware neural model for named entity recognition in low resource transfer settings | Freebase: A Collaboratively Created Graph Database for Structuring Human Knowledge | A Semantic Matching Energy Function for Learning with Multi-relational Data | Translating Embeddings for Modeling Multirelational Data | Learning Structured Embeddings of Knowledge Bases | Cfo: Conditional focused neural question answering with largescale knowledge bases | Sparse overcomplete word vector representations | WordNet: An Electronic Lexical Database | Composing Relationships with Translations | Combining Two and Three-Way Embedding Models for Link Prediction in Knowledge Bases | Traversing Knowledge Graphs in Vector Space | Learning to Represent Knowledge Graphs with Gaussian Embedding | Knowledge Graph Embedding via Dynamic Mapping Matrix | DBpedia - A Large-scale, Multilingual Knowledge Base | LightRNN: Memory and Computation-Efficient Recurrent Neural Networks | Modeling Relation Paths for Representation Learning of Knowledge Bases | Learning Entity and Relation Embeddings for Knowledge Graph Completion | K-sparse autoencoders | From softmax to sparsemax: A sparse model of attention and multi-label classification | Distributed representations of words and phrases and their compositionality | Distant supervision for relation extraction without labeled data | Neighborhood mixture model for knowledge base completion | STransE: a novel embedding model of entities and relationships in knowledge bases | A Review of Relational Machine Learning for Knowledge Graphs | A Three-Way Model for Collective Learning on Multi-Relational Data | A survey on transfer learning | Outrageously large neural networks: The sparsely-gated mixture-of-experts layer | Implicit reasonet: Modeling large-scale structured relationships with shared memory | Reasoning With Neural Tensor Networks for Knowledge Base Completion | YAGO: A Core of Semantic Knowledge | Regression shrinkage and selection via the lasso | Observed Versus Latent Features for Knowledge Base and Text Inference | Representing Text for Joint Embedding of Text and Knowledge Bases | Knowledge Graph Embedding by Translating on Hyperplanes | Mining inference formulas by goal-directed random walks | Knowledge Base Completion via Searchbased Question Answering | Embedding Entities and Relations for Learning and Inference in Knowledge Bases | Semantic parsing via staged query graph generation: Question answering with knowledge base | Transfer learning for low-resource neural machine translation",acl,100
792.pdf.json,LSTMEMBED: a Lexical and SemanTic Model of Embeddings with a bidirectional LSTM,"Recurrent neural networks (RNNs) with Long Short-Term Memory (LSTMs) have recently gained considerable popularity. Introduced by Hochreiter and Schmidhuber (1997), LSTMs are a special kind of RNN capable of learning long-term dependencies on problems related with sequential data. RNNs, and particularly LSTMs have been working extremely well on a large variety of problems in NLP, such as machine translation (Cho et al., 2014), lexical substitution (Melamud et al., 2016), word sense disambiguation, (Kågebäck and Salomonsson, 2016; Yuan et al., 2016), syntactic parsing (Dyer et al., 2015), among others. Embeddings represent lexical and semantic items in a low-dimensional continuous space. The resulting vectors capture useful syntactic and semantic information, such as regularities in language, where relationships are characterized by a relation-specific vector offset. Recent approaches, such as word2vec (Mikolov et al., 2013), and GloVe (Pennington et al., 2014) are efficient for learning embeddings, but they do not take into account word ordering. Vice versa, RNNs take order into account but they are not competitive in terms of speed or quality (Mikolov et al., 2010; Mikolov and Zweig, 2012; Mesnil et al., 2013). The recently celebrated LSTMs appear to be perfect for learning sequence representations, like phrases (Hill et al., 2016) and contexts (Melamud et al., 2016). However, when dealing with large vocabularies, LSTMs involve time-intensive matrix-matrix multiplications, making them prohibitively expensive. This issue was addressed by Jean et al. (2015), who proposed an approximate training algorithm based on sampling, and Zoph et al. (2016), who introduced an adaptation for GPUs of the noise-contrastive estimation algorithm, a method that avoids repeated summations by training the model to correctly separate generated noise samples from words observed in the training data. However, both these approaches speed up the training process at the cost of lowering the ","Personalizing pagerank for word sense disambiguation | The Berkeley FrameNet Project | Learning long-term dependencies with gradient descent is difficult | Freebase: A collaboratively created graph database for structuring human knowledge | Multimodal Distributional Semantics | Learning Phrase Representations using RNN Encoder– Decoder for Statistical Machine Translation | TransitionBased Dependency Parsing with Stack Long ShortTerm Memory | Retrofitting Word Vectors to Semantic Lexicons | Community evaluation and exchange of word vectors at wordvectors.org | Placing Search in Context: The Concept Revisited | PPDB: The Paraphrase Database | SimVerb-3500: A LargeScale Evaluation Set of Verb Similarity | Framewise phoneme classification with bidirectional lstm and other neural network architectures | Learning to Understand Phrases by Embedding the Dictionary | SimLex-999: Evaluating semantic models with (genuine) similarity estimation | Untersuchungen zu dynamischen neuronalen Netzen | Long short-term memory | SensEmbed: Learning Sense Embeddings for Word and Relational Similarity | On Using Very Large Target Vocabulary for Neural Machine Translation | Semeval-2012 task 2: Measuring degrees of relational similarity | Word Sense Disambiguation using a Bidirectional LSTM | A large-scale classification of english verbs | A solution to Plato’s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge | Best-Worst Scaling: A Model for the Largest Difference Judgments | Embedding words and senses together via joint knowledgeenhanced training | context2vec: Learning generic context embedding with bidirectional LSTM | Investigation of Recurrent-neuralnetwork Architectures and Learning Methods for Spoken Language Understanding | Recurrent neural network based language model | Exploiting Similarities among Languages for Machine Translation | Context dependent recurrent neural network language model | WordNet: A Lexical Database for English | Using a Semantic Concordance for Sense Identification | Entity Linking meets Word Sense Disambiguation: a Unified Approach | BabelNet: The Automatic Construction, Evaluation and Application of a Wide-Coverage Multilingual Semantic Network | The university of south florida free association, rhyme, and word fragment norms | GloVe: Global Vectors for Word Representation | Automatic Construction and Evaluation of a Large Semantically Enriched Wikipedia | Semantic Similarity in a Taxonomy: An Information-Based Measure and its Application to Problems of Ambiguity in Natural Language | Autoextend: Extending word embeddings to embeddings for synsets and lexemes | Contextual Correlates of Synonymy | Automatic identification and disambiguation of concepts and named entities in the multilingual wikipedia | LSTM Neural Networks for Language Modeling | Generating text with recurrent neural networks | Theano: A Python framework for fast computation of mathematical expressions | Mining the web for synonyms: Pmi-ir versus lsa on toefl | Measuring Semantic Similarity in the Taxonomy of WordNet | Improving Lexical Embeddings with Semantic Knowledge | Semi-supervised word sense disambiguation with neural models | Recurrent neural network regularization | Simple, Fast Noise-Contrastive Estimation for Large RNN Vocabularies",acl,100
805.pdf.json,TextFlow: A Text Similarity Measure based on Continuous Sequences,,"The evaluation of sentence similarity measures | A large annotated corpus for learning natural language inference | The pascal recognising textual entailment challenge | Measures of the amount of ecologic association between species | Tolerating spelling errors during patient validation | Detecting text similarity over short passages: Exploring linguistic feature combinations via machine learning | Algorithms for clustering data | Advances in record-linkage methodology as applied to matching the 1985 census of tampa, florida | Sentence similarity based on semantic nets and corpus statistics. IEEE transactions on knowledge and data engineering 18(8):1138–1150 | Semeval-2014 task 1: Evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual | Bioinformatics: sequence and genome analysis | Semeval-2016 task 3: Community | Wordnet:: Similarity: measuring the relatedness of concepts | Approximate string comparison and its effect on an advanced record linkage system | A web-based kernel function for measuring the similarity of short text snippets | Time warps, string edits, and macromolecules: the theory and practice of sequence comparison | Learning to rank short text pairs with convolutional deep neural networks | Dynamic pooling and unfolding recursive autoencoders for paraphrase detection | Improving similarity measures for short segments of text | Learning discriminative projections for text similarity measures",acl,100
818.pdf.json,Verb Physics: Relative Physical Knowledge of Actions and Objects,"Reading and reasoning about natural language text often requires trivial knowledge about everyday physical actions and objects. For example, given a sentence “Martin could fit the trophy into the suitcase”, we can trivially infer that the trophy must be smaller than the suitcase, even though it’s not stated explicitly. This reasoning requires knowledge about the action “fit”, in particular, typical preconditions that need to be satisfied in order to perform the action. In addition, reasoning about Natural language clues Relative physical knowledge about objects Physical implications of actions “She barged into the stable.” HUMAN STABLE size: smaller weight: lighter speed: faster strength: n/a rigidness: less rigid x barged into y ⇒ x is smaller than y ⇒ x is lighter than y ⇒ x is faster than y ⇒ x is less rigid than y the applicability of various physical actions in a given situation often requires background knowledge about objects in the world, for example, that people are usually smaller than houses, that cars generally move faster than humans walk, or that a brick probably is heavier than a feather. In fact, the potential use of such knowledge about everyday actions and objects can go beyond language understanding and reasoning. Many open challenges in computer vision and robotics may also benefit from such knowledge, as shown 2 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 in recent work that requires visual reasoning and entailment (Izadinia et al., 2015; Zhu et al., 2014). Ideally, an AI system should acquire such knowledge through direct physical interactions with the world. However, such a physically interactive s","Philosophers are mortal: Inferring the truth of unseen facts | Naturalli: Natural logic inference for common sense reasoning | Are elephants bigger than butterflies? reasoning about sizes of objects | The berkeley framenet project | Frame semantics and the nature of language | Physical causality of action verbs in grounded language understanding | A dataset of syntactic-ngrams over time from a very large corpus of english books | Using textual patterns to learn expected event frequencies | Reporting bias and knowledge acquisition | Learning from the web: Extracting general world knowledge from noisy text | Logic and conversationin p | Segment-phrase table for semantic segmentation, visual entailment and paraphrasing | English verb classes and alternations: A preliminary investigation | Commonsense knowledge base completion | Quantitative analysis of culture using millions of digitized books. science | Wordnet: a lexical database for english | The proposition bank: An annotated corpus of semantic roles | Glove: Global vectors for word representation | How well do distributional models capture different types of semantic knowledge? In ACL (2) | Viske: Visual knowledge extraction and question answering by visual verification of relation phrases | Verbnet: A broadcoverage, comprehensive verb lexicon | Incremental acquisition of verb hypothesis space towards physical world interaction | Inverting grice’s maxims to learn rules from natural language extractions | Reasoning about object affordances in a knowledge base representation",acl,100
86.pdf.json,A Syntactic Neural Model for General-Purpose Code Generation,"Every programmer has experienced the situation where they know what they want to do, but do not have the ability to turn it into a concrete implementation. For example, a Python programmer may want to “sort my list in descending order,” but not be able to come up with the proper syntax sorted(my list, reverse=True) to realize his intention. To resolve this impasse, it is common for programmers to search the web in natural language (NL), find an answer, and modify it into the desired form (Brandt et al., 2009, 2010). However, this is time-consuming, and thus the software engineering literature is ripe with methods to directly generate code from NL descriptions, mostly with hand-engineered methods highly tailored to specific programming languages (Balzer, 1985; Little and Miller, 2009; Gvero and Kuncak, 2015). In parallel, the NLP community has developed methods for data-driven semantic parsing, which attempt to map NL to structured logical forms executable by computers. These logical forms can be general-purpose meaning representations (Clark and Curran, 2007; Banarescu et al., 2013), formalisms for querying knowledge bases (Tang and Mooney, 2001; Zettlemoyer and Collins, 2005; Berant et al., 2013) and instructions for robots or personal assistants (Artzi and Zettlemoyer, 2013; Quirk et al., 2015), among others. While these methods have the advantage of being learnable from data, compared to the programming languages (PLs) in use by programmers, the domainspecific languages targeted by these works have a schema and syntax that is relatively simple. Recently, Ling et al. (2016) have proposed a data-driven code generation method for high-level, general-purpose PLs like Python and Java. This work treats code generation as a sequence-tosequence modeling problem, and introduce methods to generate words from character-level models, and copy variable names from input descriptions. However, unlike most work in semantic parsing, it does not consider the fact that code has to ","Bimodal modelling of source code and natural language | Tree-structured decoding with doubly recurrent neural networks | Broad-coverage CCG semantic parsing with AMR | Weakly supervised learning of semantic parsers for mapping instructions to actions | Neural machine translation by jointly learning to align and translate | Deepcoder: Learning to write programs | A 15 year perspective on automatic programming | Abstract meaning representation for sembanking | Improved semantic parsers for if-then statements | Semantic parsing on freebase from question-answer pairs | Example-centric programming: integrating web search into the development environment | Two studies of opportunistic programming: interleaving web foraging, learning, and writing code | Widecoverage efficient statistical parsing with CCG and log-linear models | Driving semantic parsing from the world’s response | Language to logical form with neural attention | A theoretically grounded application of dropout in recurrent neural networks | Incorporating copying mechanism in sequence-to-sequence learning | Interactive synthesis using free-form queries | Long short-term memory | Summarizing source code using a neural attention model | Data recombination for neural semantic parsing | Semantic parsing with semi-supervised sequential autoencoders | Semantic parsing to probabilistic programs for situated question answering | Using semantic unification to generate regular expressions from natural language | Scaling semantic parsers with on-the-fly ontology matching | From natural language specifications to program input parsers | Neural symbolic machines: Learning semantic parsers on freebase with weak supervision | Learning dependency-based compositional semantics | Orange: a method for evaluating automatic evaluation metrics for machine translation | Latent predictor networks for code generation | Keyword programming in java | Addressing the rare word problem in neural machine translation | Structured generative models of natural source code | Integrating programming by example and natural language programming | Listen, attend, and walk: Neural mapping of navigational instructions to action sequences | Neural shiftreduce CCG semantic parsing | Environment-driven lexicon induction for high-level instructions | Neural programmer: Inducing latent programs with gradient descent | lamtram: A toolkit for language and translation modeling using neural networks | A statistical semantic language model for source code | Learning to generate pseudo-code from source code using statistical machine translation (T) | Neuro-symbolic program synthesis | Compositional semantic parsing on semi-structured tables | Python abstract grammar | Language to code: Learning semantic parsers for if-this-then-that recipes | SWIM: synthesizing what i mean: code search and idiomatic snippet synthesis | Compositional program synthesis from natural language and examples | Using multiple clause constructors in inductive logic programming for semantic parsing | Pointer networks | Building bing developer assistant | Sequence-based structured prediction for semantic parsing | Semantic parsing via staged query graph generation: Question answering with knowledge base | Learning to map sentences to logical form structured classification with probabilistic categorial grammars",acl,100
87.pdf.json,PositionRank: An Unsupervised Approach to Keyphrase Extraction from Scholarly Documents,"The current Scholarly Web contains many millions of scientific documents. For example, Google Scholar is estimated to have more than 100 million documents. On one hand, these rapidly-growing scholarly document collections offer benefits for knowledge discovery, and on the other hand, finding useful information has become very challenging. Keyphrases associated with a document typically provide a high-level topic description of the document and can allow for efficient information processing. In addition, keyphrases are shown to be rich sources of information in many natural language processing and information retrieval tasks such as scientific paper summarization, classification, recommendation, clustering, and search (Abu-Jbara and Radev, 2011; Qazvinian et al., 2010; Jones and Staveley, 1999; Zha, 2002; Zhang et al., 2004; Hammouda et al., 2005). Due to their importance, many approaches to keyphrase extraction have been proposed in the literature along two lines of research: supervised and unsupervised (Hasan and Ng, 2014, 2010). In the supervised line of research, keyphrase extraction is formulated as a binary classification problem, where candidate phrases are classified as either positive (i.e., keyphrases) or negative (i.e., non-keyphrases) (Frank et al., 1999; Hulth, 2003). Various feature sets and classification algorithms yield different extraction systems. For example, Frank et al. (1999) developed a system that extracts two features for each candidate phrase, i.e., the tf-idf of the phrase and its distance from the beginning of the target document, and uses them as input to Naı̈ve Bayes classifiers. Although supervised approaches typically perform better than unsupervised approaches (Kim et al., 2013), the requirement for large human-annotated corpora for each field of study has led to significant attention towards the design of unsupervised approaches. In the unsupervised line of research, keyphrase extraction is formulated as a ranking problem with graph",,acl,100
94.pdf.json,A Full Non-Monotonic Transition System for Unrestricted Non-Projective Parsing,"Greedy transition-based dependency parsers are widely used in different NLP tasks due to their speed and efficiency. They parse a sentence from left to right by greedily choosing the highestscoring transition to go from the current parser configuration or state to the next. The resulting sequence of transitions incrementally builds a parse for the input sentence. The scoring of the transitions is provided by a statistical model, previously trained to approximate an oracle, a function that selects the needed transitions to parse a gold tree. Unfortunately, the greedy nature that grants these parsers their efficiency also represents their main limitation. McDonald and Nivre (2007) show that greedy transition-based parsers lose accuracy to error propagation: a transition erroneously chosen by the greedy parser can place it in an incorrect and unknown configuration, causing more mistakes in the rest of the transition sequence. Training with a dynamic oracle (Goldberg and Nivre, 2012) improves robustness in these situations, but in a monotonic transition system, erroneous decisions made in the past are permanent, even when the availability of further information in later states might be useful to correct them. Honnibal et al. (2013) show that allowing some degree of non-monotonicity, by using a limited set of non-monotonic actions that can repair past mistakes and replace previously-built arcs, can increase the accuracy of a transition-based parser. In particular, they present a modified arc-eager transition system where the Left-Arc and Reduce transitions are non-monotonic: the former is used to repair invalid attachments made in previous states by replacing them with a leftward arc, and the latter allows the parser to link two words with a rightward arc that were previously left unattached due to an erroneous decision. Since the Right-Arc transition is still monotonic and leftward arcs can never be repaired because their dependent is removed from the stack by the arc-e",CoNLL-X shared task on multilingual dependency parsing | A fast and accurate dependency parser using neural networks | A fundamental algorithm for dependency parsing | Transitionbased dependency parsing with stack long shortterm memory | A dynamic oracle for arc-eager dependency parsing | Training deterministic parsers with non-deterministic oracles | An efficient dynamic oracle for unrestricted non-projective parsing | Divisible transition systems and multiplanar dependency parsing | A non-monotonic arc-eager transition system for dependency parsing | An improved non-monotonic transition system for dependency parsing | Finding all the elementary circuits of a directed graph | Characterizing the errors of data-driven dependency parsing models | An efficient algorithm for projective dependency parsing | Algorithms for Deterministic Incremental Dependency Parsing | The CoNLL 2007 shared task on dependency parsing | Depth-first search and linear graph algorithms | Performance-Oriented Dependency Parsing | Dependency parsing with efficient feature extraction | More accurate tests for the statistical significance of result differences,acl,100
96.pdf.json,Sarcasm SIGN: Interpreting Sarcasm with Sentiment Based Monolingual Machine Translation,"Sarcasm is a sophisticated form of communication in which speakers convey their message in an indirect way. It is defined in the MerriamWebster dictionary (Merriam-Webster, 1983) as the use of words that mean the opposite of what one would really want to say in order to insult someone, to show irritation, or to be funny. Considering this definition, it is not surprising to find frequent use of sarcastic language in opinionated 1Our dataset and code will be made publicly available. user generated content, in environments such as Twitter, Facebook, Reddit and many more. In textual communication, knowledge about the speaker’s intent is necessary in order to fully understand and interpret sarcasm. Consider, for example, the sentence ”what a wonderful day”. A literal analysis of this sentence demonstrates a positive experience, due to the use of the word wonderful. However, if we knew that the sentence was meant sarcastically, wonderful would turn into a word of a strong negative sentiment. In spoken language, sarcastic utterances are often accompanied by a certain tone of voice which points out the intent of the speaker, whereas in textual communication, sarcasm is inherently ambiguous, and its identification and interpretation may be challenging even for humans. In this paper we present the novel task of interpretation of sarcastic utterances. We define the purpose of the interpretation task as the capability to generate a non-sarcastic utterance that captures the meaning behind the original sarcastic text. Our work currently targets the Twitter domain since it is a medium in which sarcasm is prevalent, and it allows us to focus on the interpretation of tweets marked with the content tag #sarcasm. And so, for example, given the tweet ”how I love Mondays. #sarcasm” we would like our system to generate interpretations such as ”how I hate Mondays” or ”I really hate Mondays”. In order to learn such interpretations, we constructed a parallel corpus of 3000 sarcastic tweets,","Contextualized sarcasm detection on twitter | Paraphrasing with bilingual parallel corpora | Modelling sarcasm in twitter, a novel approach | Collecting highly parallel data for paraphrase evaluation | Learning phrase representations using rnn encoder-decoder for statistical machine translation | Semi-supervised recognition of sarcastic sentences in twitter and amazon | Meteor 1.3: Automatic metric for reliable optimization and evaluation of machine translation systems | Automatic evaluation of machine translation quality using ngram co-occurrence statistics | Sentiwordnet: A publicly available lexical resource for opinion mining | Irony in language and thought: A cognitive science reader | Identifying sarcasm | Moses: Open source | Rouge: A package | Challenges in developing opinion mining tools for social media | Who cares about sarcastic tweets? investigating the impact of sarcasm on sentiment analysis | Webster’s ninth new collegiate dictionary | Introduction to wordnet: An on-line lexical database | Irony and the ironic | A systematic comparison of various statistical alignment models | Opinion mining and sentiment analysis | Bleu: a method for automatic evaluation of machine translation | The mind behind the message: Advancing theory-of-mind scales for typically developing children, and those with deafness, autism, or asperger syndrome | Opine: Extracting product features and opinions from reviews | Monolingual machine translation for paraphrase generation | Sarcasm as contrast between a positive sentiment and negative situation | The neuroanatomical basis of understanding sarcasm and its relationship to social cognition | The meaning of irony | Sequence to sequence learning with neural networks | Icwsm-a great catchy name: Semisupervised recognition of sarcastic sentences in online product reviews | or# sarcasma quantitative and qualitative study based on twitter https://aclweb.org/anthology/Y/Y13/Y13-1035.pdf | Learning subjective language | Paraphrase generation as monolingual translation: Data and evaluation | Semeval-2015 task 1: Paraphrase and semantic similarity in twitter (pit) | Adadelta: an adaptive learning rate method",acl,100
97.pdf.json,,"Educational advisory body to the Japanese government has decided that writing tests will be introduced into the new national center test for university entrance examinations, as announced in a final report (MEXT, 2016) at the high school and university articulation meeting by the Ministry of Education, Culture, Sports, Science and Technology. The use of AI-based computers was proposed to stabilize the test scores efficiently. The required type of writing test is a short-answer test, where a correct answer is expected to exist. Therefore, the test is scored by judging agreement of the meaning with the correct answer. Another type of writing test is essay writing, where a correct answer does not exist. The written answers are evaluated based on the rhetoric, the connection expressions, and the content. Because short-answer scoring involves technical difficulty, the number of characters is restricted to 80 characters at most from dozens of characters. Two characters in Japanese are generally equivalent to one word in English. A short-answer test is widely considered to be more authentic and reliable for measuring ability compared with a multiple-choice test. If technical problems related to the short-answer test are solved, the potential demand for its use, as well as that for the national center test, will be enormous. Many systems for evaluating essays have been developed and offered in the United States (Shermis and Burstein, 2013). The authors’ group also developed the first and most well-known Japanese automated essay scoring system named Jess (Ishioka and Kameda, 2006), and it is in practical use now. While a short-answer scoring system has been developed because of its importance, various technical problems remain unsolved. New York University (NYU) and the Educational Testing Service (ETS) developed the first automated scoring tools in this field; they evaluated the NYU online program (Vigilante, 1999). Leacock and Chodorow (2003) reported the latest specificat","Random forests | Random forests | The Case for Case, Universals in Linguistic Theory, New York: Holt, Rinehart, and Winston, pages 1–88 | Automated japanese essay scoring system based on articles written by experts | Crater: Automated scoring of short-answer questions | Package randomforest | Publishing the final report of high school and university articulation meeting | Itefs ability which understands the meaning to be asked about | Automatic short answer marking | Handbook of Automated Essay Evaluation | Online computer scoring of constructed-response questions",acl,100
103.pdf.json,Measuring Topic Quality using Word Buckets,"Starting with the formalization of the notion of a topic as a probability distribution over words, probabilistic graphical models have been widely investigated for inferring the set of topics present in a document collection in an unsupervised manner (Blei et al., 2003). These models also infer the probability distribution over topics for documents in the collection. Since topics give a particular perspective on the structure of the document collection, topic modelling techniques have been applied on a variety of real-life document collections, such as scientific papers (Griffiths and Steyvers, 2004), (Blei, 2012) and newspapers archives (Yang et al., 2011). Topic models have also been used for im- proving many traditional text-mining tasks, such as document classification (Hingmire et al., 2013), document summarization (Wang et al., 2009), sentiment analysis (Lin and He, 2009), word sense disambiguation (Boyd-Graber et al., 2007), corpus visualization (Newman et al., 2010a) etc. Several variations on topic models are also being researched; e.g., correlated topic models (e.g., a document having a topic environment is likely to include topics such as UN and politics but not sports) (David M. Blei, 2007), dynamic topic models evolving over time (Blei and Lafferty, 2006), (Wang et al., 2008) and supervised topic models (Mcauliffe and Blei, 2008), (Ramage et al., 2009). Given this growing importance of topic modelling in text mining techniques and in practical applications, it is crucial to ensure that the inferred topics are of as high quality as possible. An attractive feature of the probabilistic topic models is that the inferred topics can be easily interpreted by humans, each topic being just a bag of probabilistically selected “prominent” words in that topic’s distribution. This has opened up a research area which explores using human expertise or designing automated techniques to measure the quality of topics and improve the topic modelling techniques by incorpor",Evaluating topic coherence using distributional semantics | Topic significance ranking of lda generative models | Dynamic topic models | Latent dirichlet allocation | Probabilistic topic models | A topic model for word sense disambiguation | Reading tea leaves: How humans interpret topic models | A correlated topic model of science | Finding scienti?c topics | Topic labeled text classification: a weakly supervised approach | Document classification by topic labeling | Machine Reading Tea Leaves: Automatically Evaluating Topic Coherence And Topic Model Quality | Joint sentiment/topic model for sentiment analysis | Supervised topic models | Efficient estimation of word representations in vector space | Optimizing semantic coherence in topic models | Improving topic evaluation using conceptual knowledge | Visualizing search results and document collections using topic maps | Automatic evaluation of topic coherence | Topics and label propagation: Best of both worlds for weakly supervised text classification | Glove: Global vectors for word representation | Labeled lda: A supervised topic model for credit attribution in multilabeled corpora | Exploring the space of topic coherence measures | Continuous time dynamic topic models | Multi-document summarization using sentence-based topic models | Topic modeling on historical newspapers,conll,001
11.pdf.json,Coreference in Wikipedia: Main Concept Resolution,"Coreference Resolution (CR) is the task of identifying all mentions of entities in a document and grouping them into equivalence classes. CR is a prerequisite for many NLP tasks. For example, in Open Information Extraction (OIE) (Yates et al., 2007), one acquires subject-predicate-object relations, many of which (e.g., <the foundation stone, was laid by, the Queen s daughter>) are useless because the subject or the object contains material coreferring to other mentions in the text being mined. Most CR systems, including state-of-the-art ones (Durrett and Klein, 2014; Martschat and Strube, 2015; Clark and Manning, 2015) are essentially adapted to news-like texts. This is basically imputable to the availability of large datasets where this text genre is dominant. This includes resources developed within the Message Understanding Conferences (e.g., (Hirshman and Chinchor, 1998)) or the Automatic Content Extraction (ACE) program (e.g., (Doddington et al., 2004)), as well as resources developed within the collaborative annotation project OntoNotes (Pradhan et al., 2007). It is now widely accepted that coreference resolution systems trained on newswire data performs poorly when tested on other text genres (Hendrickx and Hoste, 2009; Schäfer et al., 2012), including Wikipedia texts, as we shall see in our experiments. Wikipedia is a large, multilingual, highly structured, multi-domain encyclopedia, providing an increasingly large wealth of knowledge. It is known to contain well-formed, grammatical and meaningful sentences, compared to say, ordinary internet documents. It is therefore a resource of choice in many NLP systems, see (Medelyan et al., 2009) for a review of some pioneering works. While being a ubiquitous resource in the NLP community, we are not aware of much work conducted to adapt CR to this text genre. Two notable exceptions are (Nguyen et al., 2007) and (Nakayama, 2008), two studies dedicated to extract tuples from Wikipedia articles. Both studies demonstra",,conll,001
12.pdf.json,Learning when to trust distant supervision: An application to low-resource POS tagging using cross-lingual projection,"Part-of-speech tagging is a critical task for natural language processing (NLP) applications, providing lexical syntactic information. Automatic POS tagging has been wildly successful on many rich resource languages using supervised learning over large training corpora (McCallum et al., 2000; Lafferty et al., 2001; Ammar et al., 2016). However, learning POS taggers for low-resource languages from small amounts of annotated data is very challenging (Garrette and Baldridge, 2013; Duong et al., 2014a). For such problems, distant supervision via heuristic methods can provide cheap but inaccurately labelled data (Mintz et al., 2009; Takamatsu et al., 2012; Ritter et al., 2013; Plank et al., 2014). A compromise, considered here, is to use a mixture of both resources: a small collection of clean annotated data and noisy “distant” data. A popular method for distant supervision is to use parallel data between a low-resource language and a rich-resource language. Although annotated data in low-resource languages are difficult to obtain, bilingual resources are more plentiful. For example parallel translations into English are often available, in the form of news reports, novels or the Bible. Parallel data allows annotation from the high-resource language to be projected across alignments to the low-resource language, which has been shown to be effective for several language processing tasks including POS tagging (Yarowsky et al., 2001; Das and Petrov, 2011; Duong et al., 2013), named entity recognition (Wang and Manning, 2013) and dependency parsing (McDonald et al., 2013). Although cross-lingual POS projection is popular it has several problems, including noise from poor word alignments (Täckström et al., 2013; Das and Petrov, 2011) and cross-lingual syntactic divergence (Duong et al., 2013). Previous work has proposed heuristics or constraints to clean the projected tag before or during learning. In contrast, we consider compensating for these problems explicitly, by lear","Many languages, one parser | Part of speech tagging in context | Conll-x shared task on multilingual dependency parsing | Unsupervised part-of-speech tagging with bilingual graph-based projections | Simpler unsupervised pos tagging with bilingual projections | What can we get from 1000 tokens? a case study of multilingual pos tagging for resource-poor languages | What can we get from 1000 tokens? a case study of multilingual pos tagging for resource-poor languages | Learning a part-of-speech tagger from two hours of annotation | Em can find pretty good hmm pos-taggers (when given a good start) | Speech recognition with deep recurrent neural networks | Cross-lingual dependency parsing based on distributed representations | A representation learning framework for multi-source transfer parsing | A resource-light approach to russian morphology: Tagging russian using czech resources | Conditional random fields: Probabilistic models for segmenting and labeling sequence data | Wiki-ly supervised part-of-speech tagging | Maximum entropy markov models for information extraction and segmentation | Multi-source transfer of delexicalized dependency parsers | Universal dependency annotation for multilingual parsing",conll,001
124.pdf.json,Leveraging Cognitive Features for Sentiment Analysis,"This paper addresses the task of Sentiment Analysis (SA) - automatic detection of the sentiment polarity as positive versus negative - of usergenerated short texts and sentences. Several sentiment analyzers exist in literature today (Liu and Zhang, 2012). Recent works, such as Kouloumpis et al. (2011), Agarwal et al. (2011) and Barbosa and Feng (2010), attempt to conduct such analyses on user-generated content. Sentiment analysis remains a hard problem, due to the challenges it poses at the various levels, as summarized below.","Sentiment analysis of twitter data | Subjectivity word sense disambiguation | Harnessing wordnet senses for supervised sentiment classification | Modelling sarcasm in twitter, a novel approach | Robust sentiment detection on twitter from biased and noisy data | Sentiment analysis: Adjectives and adverbs are better than adjectives alone | Clues for detecting irony in user-generated contents: oh...!! it’s so easy;-) | LIBSVM: A library for support vector machines | Mining the peanut gallery: Opinion extraction and semantic classification of product reviews | Deep convolutional neural networks for sentiment analysis of short texts | The role of adverbs in sentiment analysis | Sentiwordnet: A publicly available lexical resource for opinion mining | Mining opinions in comparative sentences | Twitter sentiment classification using distant supervision | The weka data mining software: an update | Learning to shift the polarity of words for sentiment classification | The effect of negation on sentiment analysis and retrieval effectiveness | More than meets the eye: Study of human cognition in sense annotation | Measuring sentiment annotation complexity of text | Harnessing context incongruity for sarcasm detection | Derivation of new readability formulas (automated readability index, fog count and flesch reading ease formula) for navy enlisted personnel | Twitter sentiment analysis: The good the bad and the omg! ICWSM, 11:538–541 | Sentiment analysis with global topics and local dependency | The perfect solution for detecting sarcasm in tweets# not | Joint sentiment/topic model for sentiment analysis | A survey of opinion mining and sentiment analysis | Learning word vectors for sentiment analysis | Determinants of scanpath regularity in reading | Delta tfidf: An improved feature space for sentiment analysis | Who cares about sarcastic tweets? investigating the impact of sarcasm on sentiment analysis | Topic sentiment mixture: modeling facets and opinions in weblogs | Automatically predicting sentence translation difficulty | A cognitive study of subjectivity extraction in sentiment annotation | Predicting readers’ sarcasm understandability by modeling gaze behavior | Sentiment analysis using support vector machines with diverse information sources | Dependency tree-based sentiment classification using crfs with hidden variables | Examining the role of linguistic knowledge sources in the automatic identification and classification of reviews | A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts | Opinion mining and sentiment analysis | Thumbs up?: sentiment classification using machine learning techniques | Neuroergonomics: The brain at work | The haves and the have-nots: Leveraging unlabelled corpora for sentiment analysis | Sentic patterns: Dependency-based rules for concept-level sentiment analysis | Detecting turnarounds in sentiment analysis: Thwarting | Lexical complexity and fixation times in reading: Effects of word frequency, verb complexity, and lexical ambiguity | Eye movements in reading: Psycholinguistic studies | Sarcasm as contrast between a positive sentiment and negative situation | Alleviating data sparsity for twitter sentiment analysis | Detecting domain dedicated polar words | What is the scanpath signature of syntactic reanalysis | Word sense and subjectivity | Recognizing contextual polarity in phraselevel sentiment analysis",conll,001
129.pdf.json,Semi-supervised Convolutional Networks for Translation Adaptation with Tiny Amount of In-domain Data,"Statistical machine translation (SMT) systems are trained on bilingual parallel and monolingual data. The training corpora typically come from different sources, and vary across topics, genres, dialects, authors’ written styles, etc., which are usually referred as “general domain” training data. Here the word “domain” is often used to indicate some combination of all above and other possible hidden factors (Chen et al., 2013). At run time, the content to be translated may come from a different domain. Due to the mismatch in “domains”, it is possible to achieve better performance by adapting the SMT system to the test domain (in-domain). However, manually creating training data to match the test domain is not a preferred solution, because 1) sometimes the test domain is not known when training the model, and it could change from sentence to sentence; 2) even if the test domain is pre-determined, the resources required and slow turnaround in data collection process will still delay the system development process. Therefore, training data selection is widely used for domain adaptation in statistical machine translation (Zhao et al., 2004; Lü et al., 2007; Yasuda et al., 2008; Moore and Lewis, 2010; Axelrod et al., 2011; Duh et al., 2013; Axelrod et al., 2015). Data selection techniques select monolingual or bilingual data that are similar to the indomain seed data based on some criteria, which are incorporated into the training data. The most successful data selection approaches (Moore and Lewis, 2010; Axelrod et al., 2011) train n-gram language models on in-domain text to select similar sentences from the large general-domain corpora according to the cross entropy. Furthermore, (Duh et al., 2013) obtained some gains by extending these approaches from n-gram models to recurrent neural network language models (Mikolov et al., 2010). To train the in-domain language model, a reasonable size in-domain data set, which typically includes several thousands of sentences, is r","Domain adaptation via pseudo in-domain data | Data selection with fewer words | A neural probabilistic language model | Domain adaptation for statistical machine translation with monolingual resources | Non-linear text regression with a deep convolutional neural network | Vector space model for adaptation in statistical machine translation | A comparison of mixture and vector space techniques for translation model adaptation | Event extraction via dynamic multi-pooling convolutional neural networks | Domain adaptation for machine translation by mining unseen words | Question answering over freebase with multicolumn convolutional neural networks | Classifying relations by ranking with convolutional neural networks | Large scale decipherment for out-of-domain machine translation | Adaptation data selection using neural language models: Experiments in machine translation | Mixturemodel adaptation for SMT | Discriminative instance weighting for domain adaptation in statistical machine translation | Simulating discriminative training for linear mixture adaptation in statistical machine translation | Monolingual marginal matching for translation model adaptation | Effective use of word order for text categorization with convolutional neural networks | Semi-supervised convolutional neural networks for text categorization via region embedding | A convolutional neural network for modelling sentences | Convolutional neural networks for sentence classification | Statistical significance tests for machine translation evaluation | Imagenet classification with deep convolutional neural networks | Convolutional networks for images, speech, and time series | Improving Statistical Machine Translation Performance by Training Data Selection and Optimization | Discriminative corpus weight estimation for machine translation | Recurrent neural network based language model | Efficient estimation of word representations in vector space | Intelligent selection of language model training data | Event detection and domain adaptation with convolutional neural networks | BLEU: A method for automatic evaluation of Machine Translation | Glove: Global vectors for | Investigations on largescale lightly-supervised training for statistical machine translation | Perplexity minimization for translation model domain adaptation in statistical machine translation | Wordlevel confidence estimation for machine translation | Semantic clustering and convolutional neural network for short text categorization | Method of selecting training data to build a compact and ef?cient translation model | Convolutional neural network for paraphrase identification | Relation classification via convolutional deep neural network | Learning a phrase-based translation model from monolingual data with application to domain adaptation | Language model adaptation for statistical machine translation with structured query models",conll,001
13.pdf.json,Event Linking with Sentential Features from Convolutional Neural Networks,"Event extraction aims at detecting mentions of realworld events and their arguments in text documents of different domains, e.g., news articles. The subsequent task of event linking is concerned with resolving coreferences between recognized event mentions in a document, and is the focus of this paper. Several studies investigate event linking and related problems such as relation mentions spanning multiple sentences. Swampillai and Stevenson (2010) find that 28.5 % of binary relation mentions in the MUC 6 dataset are affected, as are 9.4 % of relation mentions in the ACE corpus from 2003. Ji and Grishman (2011) estimate that 15 % of slot fills in the training data for the “TAC 2010 KBP Slot Filling” task require cross-sentential inference. To confirm these numbers, we analyzed the event annotation of the ACE 2005 corpus and found that approximately 23 % of the event mentions are incomplete on the argument level, with respect to the information in other mentions of the same event instance in the respective document. These numbers suggest that event linking is an important task. Previous approaches for modeling event mentions in context of coreference resolution (Bejan and Harabagiu, 2010; Sangeetha and Arock, 2012; Liu et al., 2014) make either use of external feature sources with limited cross-domain availability like WordNet (Fellbaum, 1998) and FrameNet (Baker et al., 1998), or show low performance. At the same time, recent literature proposes a new kind of feature class for modeling events (and relations) in order to detect mentions and extract their arguments, i.e., sentential features from event-/relationmention representations that have been created by taking the full extent and surrounding sentence of a mention into account (Zeng et al., 2014; Nguyen and Grishman, 2015; Chen et al., 2015; dos Santos et al., 2015; Zeng et al., 2015). Their promising results motivate our work. We propose to use such features for event coreference resolution, hoping to thereby ",,conll,001
132.pdf.json,Mixing Dirichlet Topic Models and Word Embeddings to Make lda2vec,"Topic models are popular for their ability to organize document collections into a smaller set of prominent themes. In contrast to dense distributed representations, these document and topic representations are generally accessible to humans and more easily lend themselves to being interpreted. This interpretability provides additional options to highlight the patterns and structures within our systems of documents. For example, using Latent Dirichlet Allocation (LDA) topic models can reveal cluster of words within documents (Blei et al., 2003), highlight temporal trends (Charlin et al., 2015), and infer networks of complementary products (McAuley et al., 2015). See Blei et al. (2010) for an overview of topic modelling in do- mains as diverse as computer vision, genetic markers, survey data, and social network data. Dense vector approaches to building document representations also exist: Le and Mikolov (2014) propose paragraph vectors that are predictive of bags of words within paragraphs, Kiros et al. (2015) build vectors that reconstruct the sentence sequences before and after a given sentence, and Ghosh et al. (2016) construct contextual LSTMs that predict proceeding sentence features. Probabilistic topic models tend to form documents as a sparse mixed-membership of topics while neural network models tend to model documents as dense vectors. By virtue of both their sparsity and low-dimensionality, representations from the former are simpler to inspect and more immediately yield high level intuitions about the underlying system (although not without hazards, see Chang et al. (2009)). This paper explores hybrid approaches mixing sparse document representations with dense word and topic vectors. Unfortunately, crafting a new probabilistic topic model requires deriving a new approximation, a procedure which takes substantial expertise and must be customized to every model. As a result, prototypes are time-consuming to develop and changes to model architectures must b",Latent dirichlet allocation | Probabilistic Topic Models | Reading tea leaves: How humans interpret topic models | Dynamic Poisson Factorization | Contextual LSTM (CLSTM) models for Large scale NLP tasks | Improving neural networks by preventing coadaptation of feature detectors | An Improved Non-monotonic Transition System for Dependency Parsing | Adam: A Method for Stochastic Optimization | Skip-Thought Vectors | Distributed Representations of Sentences and Documents | DependencyBased Word Embeddings | Linguistic Regularities in Sparse and Explicit Word Representations | Neural Word Embedding as Implicit Matrix Factorization | Introduction to Information Retrieval | Inferring Networks of Substitutable and Complementary Products | Distributed Representations of Words and Phrases and their Compositionality | Scikit-learn: Machine Learning in Python | Glove: Global Vectors for Word Representation | Exploring the Space of Topic Coherence Measures,conll,001
137.pdf.json,When a Red Herring is Not a Red Herring: Using Compositional Methods to Improve the Detection of Non-Compositional Phrases,"In recent years, distributional representations of words have received a lot of interest. In many applications, the ability to cluster or find similar words in terms of their distribution in text or their hypothesised semantic similarity has a massive potential to reduce the sparse data problem. Early research in the field (Hindle, 1990; Grefenstette, 1994; Lin, 1998; Lee, 1999; Curran, 2004; Weeds and Weir, 2005; Padó and Lapata, 2007) investigated distributional representations which were built directly from corpus cooccurrence counts; such representations are now commonly referred to as count or explicit vector representations. The models considered varied in terms of the use of different association functions (Curran, 2004), the use of different similarity measures (Lee, 1999; Weeds and Weir, 2005) and whether to define context in terms of proximity or grammatical dependencies (Padó and Lapata, 2007). More recently the trend has been towards using neural models (Mikolov et al., 2013; Pennington et al., 2014) to create dense, low dimensional representations, commonly referred to as word embeddings, built by training the models to predict corpus co-occurrences. As has been noted elsewhere (Pennington et al., 2014), whilst appearing at first sight very different, both count-based methods and prediction-based methods have in common the fact that they probe the underlying co-occurrence statistics in the corpus. In fact, Levy and Goldberg (2014) demonstrated that the skip-gram model with negative sampling (SGNS) proposed by Mikolov et al. (2013) is an implicit factorisation of the positive pointwise mutual information (PPMI) matrix commonly used in count-based methods. One current focus within the field of distributional semantics is enabling systems to make inferences about phrase-level or sentence-level similarity. One approach (Turney, 2012) is to model the similarity of two phrases or sentences as a function of word-level similarities. An alternative approach (M","Distributional memory: A general framework for corpus | Nouns are vectors, adjectives are matrices: Representing adjective-noun constructions in semantic space | Semantic parsing via paraphrasing | Mathematical foundations for a compositional distributed model of meaning | From Distributional to Semantic Similarity | Contextual word similarity and estimation from sparse data | General estimation and evaluation of compositional distributional semantic models | Introducing and evaluating ukwac, a very large web-derived corpus of english | Multi-step regression learning for compositional distributional semantics | Explorations in Automatic Thesaurus Discovery | A regression model of adjective-noun compositionality in distributional semantics | Jointly learning word representations and composition functions using predicate-argument structures | An unsupervised ranking model for nounnoun compositionality | Noun classification from predicate-argument structures | Measures of distributional similarity | Neural word embedding as implicit matrix factorization | Improving distributional similarity with lessons learned from word embeddings | Automatic retrieval and clustering of similar words | Detecting a continuum of compositionality in phrasal verbs | Efficient estimation of word representations in vector space | Evaluating neural word representations in tensor-based compositional settings | Vector-based models of semantic composition | Composition in distributional models of semantics | Incrementality in deterministic dependency parsing | Dependency-based construction of semantic space models | Glove: Global vectors for word representation | An empirical study on compositionality in compound nouns | Multiword expressions: A pain in the neck for nlp | Probabilistic part-of-speech tagging using decision trees | Semantic compositionality through recursive matrix-vector spaces | From frequency to meaning: Vector space models of semantics | Domain and function: A dualspace model of semantic relations and compositions | Co-occurrence retrieval: a flexible framework for distributional similarity | Distributional composition using higher-order dependency vectors",conll,001
142.pdf.json,Exploring Prediction Uncertainty in Machine Translation Quality Estimation,"Quality Estimation (QE) (Blatz et al., 2004; Specia et al., 2009) models aim at predicting the quality of automatically translated text segments. Traditionally, these models provide point estimates and are evaluated using metrics like Mean Absolute Error (MAE), Root-Mean-Square Error (RMSE) and Pearson’s r correlation coefficient. However, in practice QE models are built for use in decision making in large workflows involving Machine Translation (MT). In these settings, relying on point estimates would mean that only very accurate prediction models can be useful in practice. A way to improve decision making based on quality predictions is to explore uncertainty estimates. Consider for example a post-editing scenario where professional translators use MT in an effort to speed-up the translation process. A QE model can be used to determine if an MT segment is good enough for post-editing or should be discarded and translated from scratch. But since QE models are not perfect they can end up allowing bad MT segments to go through for postediting because of a prediction error. In such a scenario, having an uncertainty estimate for the prediction can provide additional information for the filtering decision. For instance, in order to ensure good user experience for the human translator and maximise translation productivity, an MT segment could be forwarded for post-editing only if a QE model assigns a high quality score with low uncertainty (high confidence). Such a decision process is not possible with point estimates only. Good uncertainty estimates can be acquired from well-calibrated probability distributions over the quality predictions. In QE, arguably the most successful probabilistic models are Gaussian Processes (GPs) since they considered the state-ofthe-art for regression (Cohn and Specia, 2013; Hensman et al., 2013), especially in the low-data regimes typical for this task. We focus our analysis in this paper on GPs since other common models used in QE can onl","Query learning strategies using boosting and bagging | Reducing Annotation Effort for Quality Estimation via Active Learning | Joint Emotion Analysis via Multi-task Gaussian Processes | SHEF-Lite 2.0 : Sparse Multi-task Gaussian Processes for Translation Quality Estimation | Non-Linear Text Regression with a Deep Convolutional Neural Network | Confidence estimation for machine translation | Findings of the 2013 Workshop on Statistical Machine Translation | Real Estate Price Prediction under Asymmetric Loss | Findings of the 2012 Workshop on Statistical Machine Translation | A Framework for Evaluating Approximation Methods for Gaussian Process Regression | Optimal Prediction Under Asymmetric Loss | Modelling Annotator Bias with Multi-task Gaussian Processes: An Application to Machine Translation Quality Estimation | Improving Evaluation of Machine Translation Quality Estimation | Gaussian Processes for Big Data | Probabilistic Backpropagation for Scalable Learning of Bayesian Neural Networks | Movie Reviews and Revenues: An Experiment in Text Regression | Quantile Regression | Bayesian Warped Gaussian Processes | Lyrics, Music, and Emotions | Asymmetric Least Squares Estimation and Testing | Posterior Calibration and Exploratory Analysis for Natural Language Processing Models | Evaluating Predictive Uncertainty Challenge | Gaussian processes for machine learning, volume 1 | An Investigation on the Effectiveness of Features for Translation Quality Estimation | Warped Gaussian Processes | Estimating the sentence-level quality of machine translation systems | Multi-level Translation Quality Prediction with QUEST++ | Exploiting Objective Annotations for Measuring Translation Post-editing Effort | Learning to identify emotions in text | Bayesian Estimation and Prediction Using Asymmetric Loss Functions",conll,001
143.pdf.json,,"Vector-space representations of words are widely used in statistical models of natural language. In addition to improving the performance on standard monolingual NLP tasks, shared representation of words across languages offers intriguing possibilities (Klementiev et al., 2012). For example, in machine translation, translating a word never seen in parallel data may be overcome by seeking its vector-space neighbors, provided the embeddings are learned from both plentiful monolingual corpora and more limited parallel data. A second opportunity comes from transfer learning, in which models trained in one language can be deployed in other languages. While previous work has used hand-engineered features that are crosslinguistically stable as the basis model transfer (Zeman and Resnik, 2008; McDonald et al., 2011; Tsvetkov et al., 2014), automatically learned embeddings offer the promise of better generalization at lower cost (Klementiev et al., 2012; Hermann and Blunsom, 2014; Guo et al., 2016). We there- fore conjecture that developing estimation methods for massively multilingual word embeddings (i.e., embeddings for words in a large number of languages) will play an important role in the future of multilingual NLP. This paper builds on previous work in multilingual embeddings and makes the following contributions: • We propose two dictionary-based methods— multiCluster and multiCCA—for estimating multilingual embeddings which only require monolingual data and pairwise parallel dictionaries, and use them to train embeddings in 59 languages for which these resources are available (§2). Parallel corpora are not required but can be used when available. We show that the proposed methods work well in some settings and evaluation metrics. • We adapt QVEC (Tsvetkov et al., 2015)1 to evaluating multilingual embeddings (multiQVEC). We also develop a new evaluation method multiQVEC-CCA which addresses a theoretical shortcoming of multiQVEC (§3). Compared to other intrinsic metri","Universal dependencies 1.1. LINDAT/CLARIN digital library at Institute of Formal and Applied Linguistics, Charles University in Prague | A study on similarity and relatedness using distributional and WordNet-based approaches | Polyglot: Distributed word representations for multilingual nlp | Multimodal distributional semantics | A framework for the construction of monolingual and cross-lingual word similarity datasets | Learning phrase representations using rnn encoder-decoder for statistical machine translation | Transgram, fast cross-lingual word-embeddings | A simple, fast, and effective reparameterization of IBM Model 2 | Transitionbased dependency parsing with stack long shortterm memory | Improving vector space word representations using multilingual correlation | Translation invariant word embeddings | Bilbowa: Fast bilingual distributed representations without word alignments | Cross-lingual dependency parsing based on distributed representations | A representation learning framework for multi-source transfer parsing | Noise-contrastive estimation of unnormalized statistical models, with applications to natural image statistics | Learning bilingual lexicons from monolingual corpora | Multilingual Models for Compositional Distributional Semantics | Inducing crosslingual distributed representations of words | Learning bilingual word representations by marginalizing alignments | Judgment language matters: Towards judgment language informed vector space modeling | Better word representations with recursive neural networks for morphology | Addressing the rare word problem in neural machine translation | Bilingual word representations with monolingual quality in mind | Supersense tagging for Danish | An empirically grounded expansion of the supersense inventory | Multi-source transfer of delexicalized dependency parsers | Efficient estimation of word representations in vector space | Exploiting similarities among languages for machine translation | A semantic concordance | Building the italian syntactic-semantic | An efficient method for determining bilingual word classes | A universal part-of-speech tagset | Intriguing properties of neural networks | Cross-lingual word clusters for direct transfer of linguistic structure | Metaphor detection with cross-lingual model transfer | Evaluation of word vector representations by subspace alignment | Crosslanguage parser adaptation between related languages | Bilingual word embeddings for phrase-based machine translation",conll,001
151.pdf.json,Parsing for Universal Dependencies without training,"Grammar induction and unsupervised dependency parsing are active fields of research in natural language processing (Klein and Manning, 2004; Gelling et al., 2012). However, many data-driven approaches struggle with learning relations that match the conventions of the test data, e.g., Klein and Manning reported the tendency of their DMV parser to make determiners the heads of German nouns. Even supervised transfer approaches (McDonald et al., 2011) suffer from target adaptation problems when facing word order differences. The Universal Dependencies (UD) project (Nivre et al., 2015) offers a dependency formalism that aims at providing a consistent representation across languages, while enforcing a few hard constraints. The arrival of such treebanks, expanded and improved on a regular basis, provides a new milestone for cross-lingual dependency parsing research (McDonald et al., 2013). Furthermore, we expect that such a formalism lends itself more naturally to a simple and linguistically sound rulebased approach to cross-lingual parsing. In this paper we present such an approach. Our system is a dependency parser that requires no training, and relies solely on explicit part-ofspeech (POS) constraints that UD imposes. In par- ticular, UD prescribes that trees are single-rooted, and that function words like adpositions, auxiliaries, and determiners are always dependents of content words, while other formalisms might treat them as heads (De Marneffe et al., 2014). Contributions Our method goes beyond the existing work on rule-aided unsupervised dependency parsing by a) adapting dependency head rules to UD-compliant POS relations, b) incorporating the UD restriction of function words being leaves, c) using personalized PageRank to improve main predicate identification, and d) making it completely free of language-specific parameters by estimating adposition attachment direction directly on test data. We evaluate our system on 32 languages1 in three setups, depending on the","Universal Dependencies for Croatian (that Work for Serbian, too) | If All You Have is a Bit of the Bible: Learning POS Taggers for Truly Low-Resource Languages | TnT – A Statistical Part-ofSpeech Tagger | Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections | Universal Stanford Dependencies: A Cross-Linguistic Typology | The Pascal Challenge on Grammar Induction | Sparsity in Dependency Grammar Induction | Bootstrapping Parsers via Syntactic Projection Across Parallel Texts | Joint Part-of-Speech and Dependency Projection from Multiple Sources | Questionbank: Creating a Corpus of ParseAnnotated Questions | CorpusBased Induction of Syntactic Structure: Models of Dependency and Constituency | Unsupervised Dependency Parsing with Transferring Distribution via Parallel Guidance and Entropy Regularization | Turning on the Turbo: Fast ThirdOrder Non-Projective Turbo Parsers | Multi-Source Transfer of Delexicalized Dependency Parsers | Using Universal Linguistic Knowledge to Guide Grammar Induction | The PageRank Citation Ranking: Bringing Order to the Web | Grammar-Driven versus Data-Driven: Which Parsing System Is More Affected by Domain Shifts | Density-Driven Cross-Lingual Transfer of Dependency Parsers | Neutralizing Linguistically Problematic Annotations in Unsupervised Dependency Parsing Evaluation | From Baby Steps to Leapfrog: How Less is More in Unsupervised Dependency Parsing | Viterbi Training Improves Unsupervised Dependency Parsing | Data Point Selection for CrossLanguage Adaptation of Dependency Parsers | Two Baselines for Unsupervised Dependency Parsing | Unsupervised dependency parsing without training | Rediscovering Annotation Projection for Cross-Lingual Parser Induction | Inducing Multilingual Text Analysis Tools via Robust Projection Across Aligned Corpora",conll,001
163.pdf.json,Redefining part-of-speech classes with distributional semantic models,"Parts of speech (PoS) are useful abstractions, but still abstractions. Boundaries between them in natural languages are flexible. Sometimes, large open classes of words are situated on the verge between several parts of speech: for example, participles in English are in many respects both verbs and adjectives. In other cases, closed word classes ‘intersect’ between themselves: it is often difficult to tell a determiner from a possessive pronoun, etc. As (Houston, 1985) puts it, ‘Grammatical categories exist along a continuum which does not exhibit sharp boundaries between the categories’. When annotating natural texts for parts of speech, the choice of a PoS tag in many ways depends on the human annotators themselves, but also on the quality of linguistic conventions behind the division into different word classes. That is why there were always attempts to refine the definitions of parts of speech and to make them more ‘real’ and data-driven, produced from corpora of real texts: see, among others, the seminal work of (Biber et al., 1999). The aim of such attempts is to identify clusters of words occurring naturally and corresponding to what we usually call ‘parts of speech’. One of the main distance metrics that can be used in detecting such clusters is a distance between distributional features of words (their contexts in a reference training corpus). In this paper, we test this approach using predictive models developed in the field of distributional semantics. Recent achievements in training distributional models of language using machine learning allows for robust representations of natural language semantics created in a completely unsupervised way, using only large corpora of raw text. Relations between dense word vectors (embeddings) in the resulting vector space are of course mostly semantic. But can they be used to discover something new about grammar and syntax, particularly parts of speech? Do learned semantic vectors help here? Below we show that such mo","The handbook of English linguistics | Edward Finegan | Users Reference Guide for British National Corpus (XML Edition) | A synopsis of linguistic theory, 1930-1955 | Continuity and change in English morphology: The variable (ING) | Hui Jiang | Partof-speech tagging from 97% to 100%: is it time for some linguistics | Computational linguistics and deep learning | Distributed representations of words and phrases and their compositionality | Linguistic regularities in continuous space word representations | 2012 | and Christopher D | Christopher D Manning | Neural networks leverage corpus-wide information for part-of-speech tagging | Guillaume Lample",conll,001
165.pdf.json,Discovering Correspondences between Multiple Languages by MDL,"Systematic correspondences between languages form the basis for much linguistic work. Researchers employ them to e.g. improve teaching, analyze and quantify the similarity or relatedness of languages, or to formulate hypotheses aboutmutual intelligibility. Beyond that, they are of importance in multi-language natural language processing, notably in machine translation. Correspondence rules can be established on the basis of various linguistic features, such as the language's alphabets, their orthographies, their phonologies, or their inflectional and derivational morphologies. As an example, the Czech, Polish, Russian, andBulgarian forms of the pan-Slavic word for happiness could be analyzed to have the following ortho-phonetic correspondences: In order to find correspondences, a linguist typically collects cognates from two ormore languages and compares them manually. If the linguist observes an often-occurring pattern, or one that fits well with other known changes that occurred between the languages, then she might conclude that this pattern is systematic and use it as basis for further investigations. This technique, called the comparative method, dates back to at least the 1800s (Szemerenyi, 1970). Recently, researchers have devised various statistical approaches to identifying the regular correspondences between languages. Much of these focus on cognate identification or reconstruction (Schulz et al., 2004; Snyder et al., 2010), on discovering and quantifying etymological relationships between languages (Wettig et al., 2011), or on discovery of pseudo-morphological sub-word alignments (Snyder and Barzilay, 2008). However, most existing statistical approaches are afflicted by a number of problems: they may impose arbitrary assumptions on the distribution or shape of correspondences, may not allow for integration of linguistic knowledge, or may be limited to pairs of languages. While imposing assumptions is sometimes necessary in order to obtain any results at a","EuroComSlav Basiskurs - der panslavische Wortschatz | B | and D | A note on two problems in connexion with graphs. NUMERISCHE MATHEMATIK, 1(1):269--271 | The minimum description length principle. Adaptive computation and machine learning | A universal prior for integers and estimation by minimum description length | The neighbor-joining method: a new method for reconstructing phylogenetic trees | PercyNohama | A mathematical theory of communication | Unsupervised multilingual learning for morphological segmentation | Regina Barzilay | L | The long and the short of it: Summarising event sequences with serial episodes | and R",conll,001
166.pdf.json,Cross-Lingual Named Entity Recognition via Wikification,"Named Entity Recognition (NER) is the task of identifying and typing phrases that contain the names of persons, organizations, locations, and so on. It is an information extraction task that is important for understanding large bodies of text and is considered an essential pre-processing stage in Natural Language Processing (NLP) and Information Retrieval systems. NER is successful for languages which have a large amount of annotated data, but for languages with little to no annotated data, this task becomes very challenging. There are two common approaches to address the lack of training data problem. The first approach is to automatically generate annotated training data in the target language from Wikipedia articles or from parallel corpora. The performance of this method depends on the quality of the generated data and how well the language-specific features are explored. The second approach is to train a model on another language which has abundant training data, and then apply the model directly on test documents in the target language. This direct transfer technique relies on developing language-independent features. Note that these two approaches are orthogonal and can be used together. In this paper, we focus on the direct transfer setting. We propose a cross-lingual NER model which is trained on annotated documents in one or multiple source languages, and can be applied to all languages in Wikipedia. The model depends on a cross-lingual wikifier, which only requires multilingual Wikipedia, no sentence-aligned or wordaligned parallel text is needed. Recently, much attention has been given to cross-lingual wikification and entity linking research (Ji et al., 2015; Ji et al., 2016; Moro et al., 2014; Tsai and Roth, 2016). The key contribution of the current paper is the development of a method that makes use of cross-lingual wikification to generate language-independent features for NER, and showing how useful this can be to training NER models with no annota",,conll,001
176.pdf.json,Sentence Pair Scoring: Towards Unified Framework for Text Comprehension,"AnNLPmachine learning task often involves classifying a sequence of tokens such as a sentence or a document, i.e. approximating a function f1(s) ∈ [0, 1] (where f1 may determine a domain, sentiment, etc.). But there is a large class of problems that involve classifying a pair of sentences, f2(s0, s1) ∈ R (where s0, s1 are sequences of tokens, typically sentences). Typically, the function f2 represents some sort of semantic similarity, that is whether (or how much) the two sequences are semantically related. This formulation allows f2 to be a measure for tasks as different as topic relatedness, paraphrasing, degree of entailment, a pointwise ranking task for answer-bearing sentences or next utterance classification. In this work, we adopt the working assumption that there exist certain universal f2 type measures that may be successfuly applied to a wide variety of semantic similarity tasks — in the case of neural network models trained to represent universal semantic comprehension of sentences and adapted to the given task by just fine-tuning or adapting the output neural layer (in terms of architecture or just weights). Our argument for preferring f2 to f1 in this pursuit is the fact that the other sentence in the pair is essentially a very complex label when training the sequence model, which can therefore discern semantically rich structures and dependencies. Determining and demonstrating such universal semantic comprehension models across multiple tasks remains a few steps ahead, since the research landscape is fragmented in this regard. Model research is typically reported within the context of just a single f2-type task, each dataset requires sometimes substantial engineering work before measurements are possible, and results are reported in ways that make meaningful model comparisons problematic. Our main aims are as follows. (A) Unify research within a single framework that employs task-independent models and task-specific adaptation modules. (B) Improve the ","Semeval-2015 task 2: Semantic textual similarity, english, spanish and pi | Modeling of the question answering task in the YodaQA system | YodaQA: A Modular Question Answering System Pipeline | Semantic parsing on freebase from question-answer pairs | A large annotated corpus for learning natural language inference | Learning to rank using gradient descent | Long short-term memory-networks for machine reading | On the properties of neural machine translation: Encoder-decoder approaches | Keras | The PASCAL recognising textual entailment challenge | Automatically constructing a corpus of sentential paraphrases | Multiperspective sentence similarity modeling with convolutional neural networks | Teaching machines to read and comprehend | Deep unordered composition rivals syntactic methods for text classification | Improved deep learning baselines for ubuntu corpus dialogs | Convolutional neural networks for sentence classification | Adam: A method for stochastic optimization | Skip-thought vectors | Ask me anything: Dynamic memory networks for natural language processing | Denoising bodies to titles: Retrieving similar questions with recurrent convolutional models | The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems | Semeval-2014 task 1: Evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual | Glove: Global vectors for word representation | Mctest: A challenge dataset for the open-domain machine comprehension of text | Okapi at trec-3 | Reasoning about entailment with neural attention | Learning to rank short text pairs with convolutional deep neural networks | Improved semantic representations from tree-structured long short-term memory networks | Lstmbased deep learning models for non-factoid answer selection | What is the jeopardy model? a quasisynchronous grammar for qa | Memory networks | Towards ai-complete question answering: A set of prerequisite toy tasks | Enhancing freebase question answering using textual evidence | Wikiqa: A challenge dataset for open-domain question answering | Semantic parsing via staged query graph generation: Question answering with knowledge base | Deep learning for answer sentence selection",conll,001
18.pdf.json,Broad-Coverage Semantic Parsing: A Transition-Based Approach,"In order for a grounded semantic representation to cover the full range of semantic structures exhibited by natural language, there are three structural properties that should be supported. The first is multiple parents, representing arguments and relations (semantic units) that are shared between predicates. For instance, in the sentence “After graduation, John moved to Paris”, “John” is an argument of both “graduation” and “moved”, yielding a DAG structure (Figure 1a), rather than a tree. The second is non-terminal nodes for representing units comprising more than one word. While bi-lexical dependencies partially circumvent this requirement, by representing complex units in terms of their headwords, they fall short when representing units that have no clear head. Frequent examples of such constructions include coordination structures (e.g., “John and Mary went home”; Figure 1b), some multi-word expressions (e.g., “The Haves and the Have Nots”), and prepositional phrases. In these cases, dependency schemes often apply some convention selecting one of the sub-units as the head, but as different head selections are needed for different purposes, standardization problems arise (Ivanova et al., 2012). For example, selecting the preposition to head prepositional phrases yields better parsing results (Schwartz et al., 2012), while the head noun is more useful for information extraction. Third, semantic units may be discontinuous in the text. For instance, in “John gave everything up” (Figure 1c), the phrasal verb “gave ... up” forms a single semantic unit. Discontinuities are also pervasive with other multi-word expressions (Schneider et al., 2014). We call formal representations supporting all three properties Broadcoverage Semantic Structures (BSS). However, to our knowledge, no existing parser for a grounded semantic annotation scheme supports the combination of these criteria. The only such scheme supporting them is UCCA (Abend and Rappoport, 2013), which has no pars","Universal Conceptual Cognitive Annotation (UCCA) | An incremental algorithm for transition-based CCG parsing | Broad-coverage CCG semantic parsing with AMR | Improved transition-based parsing by modeling characters instead of words with LSTMs | Abstract Meaning Representation for sembanking | The Prague dependency treebank | Incremental parsing with the perceptron algorithm | Minimal recursion semantics: An introduction | Basic Linguistic Theory: Grammatical Topics, volume 2 | Basic Linguistic Theory: Methodology, volume 1 | Basic Linguistic Theory: Further Grammatical Topics, volume 3 | Transitionbased dependeny parsing with stack long short-term memory | Parsing as reduction | A discriminative graph-based parser for the Abstract Meaning Representation | On building a more efficient grammar by exploiting types | Learning sparser perceptron models | Who did what to whom? A contrastive study of syntacto-semantic dependencies | Semantics-based machine translation with hyperedge replacement grammars | Discourse representation theory | Transforming dependencies into phrase structures | Toward abstractive summarization using semantic representations | Characterizing discontinuity in constituent treebanks | Discontinuous incremental shift-reduce parsing | MaltParser: A language-independent system for data-driven dependency parsing | An efficient algorithm for projective dependency parsing | Non-projective dependency parsing in expected linear time | SemEval 2014 task 8: Broad-coverage semantic dependency parsing | SemEval 2015 task 18: Broad-coverage semantic dependency parsing | Aligning english strings with abstract meaning representation graphs | Parsing English into Abstract Meaning Representation using syntaxbased machine translation | Inducing Implicit Arguments from Comparable Texts: A Framework and its Applications | A classifier-based parser with linear run-time complexity | Shift-reduce dependency DAG parsing | Discriminative lexical semantic segmentation with gaps: running the MWE gamut | Learnability-based syntactic annotation design | The Meaning of the Sentence and Its Semantic and Pragmatic Aspects | Conceptual annotations preserve structure across translations: A French-English case study | Transitionbased dependency DAG parsing using dynamic oracles | An AMR parser for English, French, German, Spanish and Japanese and a new AMR-annotated corpus | A transition-based algorithm for AMR parsing | Transition-based parsing of the Chinese treebank using a global discriminative model | Fast and accurate shiftreduce constituent parsing",conll,001
25.pdf.json,Identifying Temporal Orientation of Word Senses,"There is considerable academic and commercial interest in processing time information in text, where that information is expressed either explicitly, or implicitly, or connotatively. Recognizing such information and exploiting it for Information Retrieval (IR) and Natural Language Processing (NLP) tasks are important features that can significantly improve the functionality of NLP/IR applications. Automatic identification of temporal expressions in text is usually performed either via time taggers (Strötgen and Gertz, 2013), which contain pattern files, such as uni-grams and bi-grams used to express temporal expressions in a given language (e.g. names of months) or various grammatical rules. As a rule-based system, time taggers are limited by the coverage of the rules for the different types of temporal expressions that it recognizes. To exemplify, the word ‘present’ in the sentence “Apple’s iPhone is one of the most popular smartphones at present” when labeled by SUTime1 is tagged as: <TIMEX3 tid=“t1” type=“DATE” value=“PRESENT_REF”>present</TIMEX3> It rightly tags the word ‘present’ in the above example, and refers to it as the present time when reference date is considered as same as the tagging date. However, such word based indicators can be misleading. For example, below is the tag from SUTime for the word ‘present’ in the sentence “I was in Oxford Street getting the wife her birthday present”. The tag gives us a false impression by wrongly labeling the word as a temporal one. <TIMEX3 tid=“t1” type=“DATE” value=“PRESENT_REF”>present</TIMEX3> Reasons for this misleading information are i) time taggers usually do not use contextual indicators while deciding on temporality ii) different word senses of a single word can actually be either temporal or atemporal. A typical temporallyambiguous word, i.e. a word that has at least one temporal and at least one atemporal sense, is ‘present’, as shown by the two examples above. Whereas most of the prior computational lin","Sentiment analysis: A new approach for effective use of linguistic knowledge and exploiting similarities in a set of documents to be classified | Exploratory search using timelines | Clustering and exploring search results using timeline constructions | Searching the future | Tempowordnet for sentence time tagging | Using machine learning to predict temporal orientation of search engines’ queries in the temporalia challenge | Hultech at the ntcir-11 temporalia task: Ensemble learning for temporal query intent classification | Propagation strategies for building temporal ontologies | Determining sample size | Ranking related news predictions | Uttime: Temporal relation classification using deep syntactic features | Automatic sense disambiguation using machine readable dictionaries: how to tell a pine cone from an ice cream cone | The language of time: a reader, volume 126 | Improving search relevance for implicitly temporal queries | Wordnet: a lexical database for english | Colourful language: Measuring word-colour associations | A comparison of unsupervised methods to associate colors with words | A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts | Combinatorial optimization: algorithms and complexity | Mining the web to predict future events | Multilingual and cross-domain temporal tagging | Extracting semantic orientations of words using spin model",conll,001
66.pdf.json,,"We introduce a new joint syntactic and semantic dependency parser. Our parser draws from the algorithmic insights of the incremental structure building approach of Henderson et al. (2008), with two key differences. First, it learns representations for the parser’s entire algorithmic state, not just the top items on the stack or the most recent parser states; in fact, it uses no expert-crafted features at all. Second, it uses entirely greedy inference rather than beam search. We find that it outperforms all previous joint parsing models, including Henderson et al. (2008) and variants (Gesmundo et al., 2009; Titov et al., 2009; Henderson et al., 2013) on the CoNLL 2008 and 2009 (English) shared tasks. Our multilingual results are comparable to the top systems at CoNLL 2009. Joint models like ours have frequently been proposed as a way to avoid cascading errors in NLP pipelines; varying degrees of success have been attained for a range of joint syntactic-semantic analysis tasks (Sutton and McCallum, 2005; Henderson et al., 2008; Toutanova et al., 2008; Johansson, 2009; Lluı́s et al., 2013, inter alia). One reason pipelines often dominate is that they make available the complete syntactic parse tree, and arbitrarily-scoped syntactic features—such as the “path” between predicate and argument, proposed by Gildea and Jurafsky (2002)—for semantic analysis. Such features are a mainstay of highperformance semantic role labeling (SRL) systems (Roth and Woodsend, 2014; Lei et al., 2015; FitzGerald et al., 2015; Foland and Martin, 2015), but they are expensive to extract (Johansson, 2009; He et al., 2013). This study shows how recent advances in representation learning can bypass those expensive features, discovering cheap alternatives available during a greedy parsing procedure. The specific advance we employ is the stack LSTM (Dyer et al., 2015), a neural network that continuously summarizes the contents of the stack data structures in which a transition-based parser’s state i",,conll,001
7.pdf.json,Random Positive-Only Projections: PPMI-Enabled Incremental Semantic Space Construction,"The development of data-driven methods of natural language processing starts with an educated guess, a distributional hypothesis: We assume that some properties of linguistic entities can be modelled by ‘some statistical’ observations in language data. In the second step, this statistical information (which is determined by the hypothesis) is collected and represented in a mathematical framework. In the third step, tools provided by the chosen mathematical framework are used to implement a similarity-based logic to identify linguistic structures, and/or to verify the proposed hypothesis. Harris’s distributional hypothesis is a well-known example of step one that states that meanings of words correlate with the context in which the words appear. Vector space models and η-normed-based similarity measures are renowned examples for steps two and three, respectively (i.e., word space models or word embeddings). However, as pointed out for instance by Baroni et al. (2014), the count-based models resulting from the steps two and three are not discriminative enough to achieve satisfactory results; instead, predictive models are required. To this end, an additional transformation step is often added. Turney and Pantel (2010) describe this additional step as a combination of weighting and dimensionality reduction.1 This transformation from count-based to predictive models can be implemented simply via a collection of rules of thumb (i.e., heuristics), and/or it can involve more sophisticated mathematical transformations, such as converting raw counts to probabilities and using matrix factorization techniques. Likewise, by exploiting large amounts of computational power available nowadays, this transformation can be achieved via neural word embedding techniques (Mikolov et al., 2013; Levy and Goldberg, 2014). To a large extend, the need for such transformations arises from the heavy-tailed distributions that we often find in statistical natural language models (such as the Zip",,conll,001
86.pdf.json,App2Check and Tweet2Check: machine learning-based tools for Sentiment Analysis of Apps Reviews and Tweets,"Sentiment Analysis has nowadays a crucial role in social media analysis and, more generally, in analysing user opinions about general topics or user reviews about product/services, enabling a huge number of applications. For instance, sentiment analysis can be applied to monitoring the reputation or opinion of a company or a brand with the analysis of reviews of consumer products or services (Hu and Liu, 2004), marketing campaigns in politics (Tumasjan et al., 2010), and financial applications (Oliveira et al., 2013) (Bollen et al., 2010). App stores can be seen as another, not yet well explored, field of application of sentiment analysis. Indeed, they are another social media where users can freely express their own opinion through app reviews about a product, i.e. the specific app under evaluation, or a service, to which the considered app is connecting the user (e.g., a mobile banking app connects users to mobile banking services). In addition, reading user reviews on app stores shows that people frequently talk about and evaluate also the brand associated to the app under review: thus, it is possible to extract people opinion about a brand or the sentiment about a company or the provided service quality. Twitter, on the other hand, is one of the most popular and largely used social networks which is very interesting to monitor from the perspective of sentiment analysis, and that is already considered in research challenges in this research area. In this paper, we focus on the app store as a social media platform and on the sentiment evaluation of app reviews and tweets. The former are examples of reviews related to a product, or a service or the associated brand; the latter can include more general sentences, which can be significantly different from reviews as for app reviews, and can be even more difficult to evaluate respect to sentiment analysis. On the other hand, apps reviews are also interesting because they include a score which is not available for twee","ifeel: A system that compares and combines sentiment analysis methods | An evaluation of machine translation for multilingual sentence-level sentiment analysis | Twitter mood predicts the stock market | Al and opinion mining, part 2 | Tweet sentiment: From classification to quantification | Mining and summarizing customer reviews | On the predictability of stock market behavior using stocktwits sentiment and posting volume | Sentiment strength detection in short informal text | Predicting elections with twitter: What 140 characters reveal about political sentiment | Recognizing contextual polarity: An exploration of features for phrase-level sentiment analysis",conll,001
91.pdf.json,Compression of Neural Machine Translation Models via Pruning,"Neural Machine Translation (NMT) is a simple new architecture for translating texts from one language into another (Sutskever et al., 2014; Cho et al., 2014). NMT is a single deep neural network that is trained end-to-end, holding several advantages such as the ability to capture long-range dependencies in sentences, and generalization to unseen texts. Despite being relatively new, NMT has already achieved state-of-the-art translation results for several language pairs including EnglishFrench (Luong et al., 2015b), English-German (Jean et al., 2015a; Luong et al., 2015a; Luong and Manning, 2015; Sennrich et al., 2015), English- Turkish (Sennrich et al., 2015), and English-Czech (Jean et al., 2015b; Luong and Manning, 2016). Figure 1 gives an example of an NMT system. While NMT has a significantly smaller memory footprint than traditional phrase-based approaches (which need to store gigantic phrase-tables and language models), the model size of NMT is still prohibitively large for mobile devices. For example, a recent state-of-the-art NMT system requires over 200 million parameters, resulting in a storage size of hundreds of megabytes (Luong et al., 2015a). Though the trend for bigger and deeper neural networks has brought great progress, it has also introduced over-parameterization, resulting in long running times, overfitting, and the large storage size discussed above. Thus a solution to the over-parameterization problem could potentially aid all three issues. Our contribution. In this paper we investigate the efficacy of weight pruning for NMT as a means of compression. We show that despite its simplicity, magnitude-based pruning with retraining is highly effective, and we compare three 2 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170","Pruning algorithms of neural networksa comparative study | Compressing neural networks with the hashing trick | Learning phrase representations using RNN encoder-decoder for statistical machine translation | Memory bounded deep convolutional networks | Low precision arithmetic for deep learning | Exploiting linear structure within convolutional networks for efficient evaluation | Deep learning with limited numerical precision | Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding | Learning both weights and connections for efficient neural network | Second order derivatives for network pruning: Optimal brain surgeon | Distilling the knowledge in a neural network | Long short-term memory | Squeezenet: Alexnet-level accuracy with 50x fewer parameters and < 1mb model size | Speeding up convolutional neural networks with low rank expansions | On using very large target vocabulary for neural machine translation | Montreal neural machine translation systems for WMT’15 | Recurrent continuous translation models | Optimal brain damage | Neural networks with few multiplications | Learning compact recurrent neural networks | Stanford neural machine translation systems for spoken language domain | Achieving open vocabulary neural machine translation with hybrid word-character models | Effective approaches to attentionbased neural machine translation | Addressing the rare word problem in neural machine translation | Auto-sizing neural networks: With applications to n-gram language models | On the compression of recurrent neural networks with an application to lvcsr acoustic modeling for embedded speech recognition | Improving neural machine translation models with monolingual data | Data-free parameter pruning for deep neural networks | Sequence to sequence learning with neural networks | Recurrent neural network regularization",conll,001
98.pdf.json,,"In the last two decades, many dependency treebanks for various languages have been manually annotated. They differ in word categories (POS tagset), syntactic categories (dependency relations), and structure for individual language phenomena. The CoNLL shared tasks for dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007) unified the file format, and thus the dependency parsers could easily work with 20 different treebanks. Still, the parsing outputs were not comparable between languages since the annotation styles differed even between closely related languages. In recent years, there have been a huge effort to normalize dependency annotation styles. The Stanford dependencies (de Marneffe and Manning, 2008) were adjusted to be more universal across languages (de Marneffe et al., 2014). Mc- donald et al. (2013) started to develop Google Universal Treebank, a collection of new treebanks with common annotation style using the Stanford dependencies and Universal tagset (Petrov et al., 2012) consisting of 12 part-of-speech tags. Zeman et al. (2012) produced a collection of treebanks HamleDT, in which about 30 treebanks were automatically converted to a Prague Dependency Treebank style (Hajič et al., 2006). Later, they converted all the treebanks also into the Stanford style (Rosa et al., 2014). The researchers from the previously mentioned projects joined their efforts to create one common standard: Universal Dependencies (Nivre et al., 2016). They used the Stanford dependencies (de Marneffe et al., 2014) with minor changes, extended the Google universal tagset (Petrov et al., 2012) from 12 to 17 part-of-speech tags and used the Interset morphological features (Zeman, 2008) from the HamleDT project (Zeman et al., 2014). In the current version 1.2, Universal Dependencies collection (UD) consists of 37 treebanks of 33 different languages and it is very likely that it will continue growing and become common source and standard for many researchers. Now, it is t","Unsupervised induction of tree substitution grammars for dependency parsing | CoNLL-X shared task on multilingual dependency parsing | The stanford typed dependencies representation | Universal stanford dependencies: A cross-linguistic typology | Markov chain Monte Carlo in practice | Improving unsupervised dependency parsing with richer contexts and smoothing | Corpus-based induction of syntactic structure: models of dependency and constituency | Multilingual unsupervised dependency parsing with unsupervised pos tags | Stopprobability estimates computed on a large corpus improve Unsupervised Dependency Parsing | Non-Projective Dependency Parsing using Spanning Tree Algorithms | Multi-source transfer of delexicalized dependency parsers | Using universal linguistic knowledge to guide grammar induction | The CoNLL 2007 Shared Task on Dependency Parsing | Universal dependencies v1: A multilingual | Non-projective dependency parsing in expected linear time | A universal part-of-speech tagset | Hamledt 2.0: Thirty dependency treebanks stanfordized | Multi-source cross-lingual delexicalized parser transfer: Prague or stanford? In Proceedings of the Third International Conference on Dependency Linguistics (Depling 2015), pages 281– 290, Uppsala, Sweden | Unsupervised dependency parsing without gold part-of-speech tags | Punctuation: Making a point in unsupervised dependency parsing | Three Dependency-and-Boundary Models for Grammar Induction | Crosslanguage parser adaptation between related languages | HamleDT: To Parse or Not to Parse | HamleDT: Harmonized multi-language dependency treebank",conll,001
304.pdf.json,MAKING NEURAL PROGRAMMING ARCHITECTURES GENERALIZE VIA RECURSION,"Training neural networks to synthesize robust programs from a small number of examples is a challenging task. The space of possible programs is extremely large, and composing a program that performs robustly on the infinite space of possible inputs is difficult—in part because it is impractical to obtain enough training examples to easily disambiguate amongst all possible programs. Nevertheless, we would like the model to quickly learn to represent the right semantics of the underlying program from a small number of training examples, not an exhaustive number of them. Thus far, to evaluate the efficacy of neural models on programming tasks, the only metric that has been used is generalization of expected behavior to inputs of greater complexity (Vinyals et al. (2015), Kaiser & Sutskever (2015), Reed & de Freitas (2016), Graves et al. (2016), Zaremba et al. (2016)). For example, for the addition task, the model is trained on short inputs and then tested on its ability to sum inputs with much longer numbers of digits. Empirically, existing models suffer from a common limitation—generalization becomes poor beyond a threshold level of complexity. Errors arise due to undesirable and uninterpretable dependencies and associations the architecture learns to store in some high-dimensional hidden state. This makes it difficult to reason about what the model will do when given complex inputs. One common strategy to improve generalization is to use curriculum learning, where the model is trained on inputs of gradually increasing complexity. However, models that make use of this strategy eventually fail after a certain level of complexity (e.g. the single-digit multiplication task in Zaremba et al. (2016), the bubble sort task in Reed & de Freitas (2016), and the graph tasks in Graves et al. (2016)). In this version of curriculum learning, even though the inputs are gradually becoming more complex, the semantics of the program is succinct and does not change. Although the model ",Learning efficient algorithms with hierarchical attentive memory | Neural gpus learn algorithms | Neural random access machines | Neural programmer: Inducing latent programs with gradient descent | Pointer networks. In Advances in Neural Information Processing Systems | Learning simple algorithms from examples,iclr,010
305.pdf.json,END-TO-END OPTIMIZED IMAGE COMPRESSION,"Data compression is a fundamental and well-studied problem in engineering, and is commonly formulated with the goal of designing codes for a given discrete data ensemble with minimal entropy (Shannon, 1948). The solution relies heavily on knowledge of the probabilistic structure of the data, and thus the problem is closely related to probabilistic source modeling. However, since all practical codes must have finite entropy, continuous-valued data (such as vectors of image pixel intensities) must be quantized to a finite set of discrete values, which introduces error. In this context, known as the lossy compression problem, one must trade off two competing costs: the entropy of the discretized representation (rate) and the error arising from the quantization (distortion). Different compression applications, such as data storage or transmission over limited-capacity channels, demand different rate–distortion trade-offs. Joint optimization of rate and distortion is difficult. Without further constraints, the general problem of optimal quantization in high-dimensional spaces is intractable (Gersho and Gray, 1992). For this reason, most existing image compression methods operate by linearly transforming the data vector into a suitable continuous-valued representation, quantizing its elements independently, and then encoding the resulting discrete representation using a lossless entropy code (Wintz, 1972; Netravali and Limb, 1980). This scheme is called transform coding due to the central role of the transforma- ∗JB and EPS are supported by the Howard Hughes Medical Institute. tion. For example, JPEG uses a discrete cosine transform on blocks of pixels, and JPEG 2000 uses a multi-scale orthogonal wavelet decomposition. Typically, the three components of transform coding methods – transform, quantizer, and entropy code – are separately optimized (often through manual parameter adjustment). We have developed a framework for end-to-end optimization of an image compression mo","Density Modeling of Images Using a Generalized Normalization Transformation | New Tight Frames of Curvelets and Optimal Representations of Objects with C Singularities | Normalization as a canonical neural computation | ImageNet: A Large-Scale Hierarchical Image Database | Vector Quantization and Signal Compression | Quantization | Towards Conceptual Compression | Learning Fast Approximations of Sparse Coding | Normalization of cell responses in cat striate cortex | Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariance Shift | What is the Best Multi-Stage Architecture for Object Recognition?” In: 2009 IEEE 12th International Conference on Computer Vision | Adam: A Method for Stochastic Optimization | Auto-Encoding Variational Bayes | Perceptual image quality assessment using a normalized Laplacian | Inferring sparse, overcomplete image codes | Non-linear image representation for efficient perceptual coding | Context-Based Adaptive Binary | Pixel Recurrent Neural | Universal modeling and coding | The Dual-Tree Complex | A Mathematical Theory of Communication | Shiftable Multiscale Transforms | What Is the Limit of Redundancy Reduction with Divi | A note on the evaluation | Full Resolution Image Compression with Recurrent | works”. In: arXiv e-prints",iclr,010
306.pdf.json,,"Deep learning has shown great success in a variety of tasks with large amounts of labeled data in image classification (He et al., 2015), machine translation (Wu et al., 2016), and speech modeling (Oord et al., 2016). These achievements have relied on the fact that optimization of these deep, high-capacity models requires many iterative updates across many labeled examples. This type of optimization breaks down in the small data regime where we want to learn from very few labeled examples. In this setting, rather than have one large dataset, we have a set of datasets, each with few annotated examples per class. The motivation for this task lies not only in the fact that humans, even children, can usually generalize after just one example of a given object, but also because models excelling at this task would have many useful applications. Firstly, they would help alleviate data collection as we would not require millions of labeled examples to attain reasonable performance. Furthermore, in many fields, data exhibits the characteristic of having many different classes but few examples per class. Models that are able to generalize from few examples would be able to capture this type of data effectively. There seem to be two main reasons why gradient-based optimization fails in the face of few labeled examples. Firstly, the variants of gradient-based optimization algorithms, such as momentum (Nesterov, 1983), Adagrad (Duchi et al., 2011), Adadelta (Zeiler, 2012), and ADAM (Kingma & Ba, 2014), weren’t designed specifically to perform well under the constraint of a set number of updates. Specifically when applied to non-convex optimization problems, with a reasonable choice of hyperparameters these algorithms don’t have very strong guarantees of speed of convergence, beyond that they will eventually converge to a good solution after what could be many millions of iterations. Secondly, for each separate dataset considered, the network would have to start from a random ini","Learning to learn by gradient descent by gradient descent | Optimisation d’une régle d’apprentissage pour réseaux de neurones artificiels | On the search for new learning rules for ANNs | Learning a synaptic learning | Deep learning of representations for unsupervised and transfer learning | Learning feed-forward one-shot learners | Learning many related tasks at the same time with backpropagation | Learning phrase representations using RNN encoder-decoder for statistical machine translation | Decaf: A deep convolutional activation feature for generic visual recognition | Adaptive subgradient methods for online learning and stochastic optimization | Deep residual learning for image recognition | Long short-term memory | Learning to learn using gradient descent | Batch normalization: Accelerating deep network training by reducing internal covariate | Adam: A method for stochastic optimization | Siamese neural networks for one-shot image recognition | Building machines that learn and think like people | Gradient-based hyperparameter optimization through reversible learning | A method of solving a convex programming problem with convergence rate o (1/k2) | Wavenet: A generative model for raw audio | Oneshot learning with memory-augmented neural networks | Learning to control fast-weight memories: An alternative to dynamic recurrent networks | A neural network that embeds its own meta-levels | Shifting inductive bias with success-story algorithm, adaptive levin search, and incremental self-improvement | Lifelong learning algorithms | Matching networks for one shot learning | Google’s neural machine translation system: Bridging the gap between human and machine translation | How transferable are features in deep neural networks | An empirical exploration of recurrent network architectures | ADADELTA: an adaptive learning rate method",iclr,010
307.pdf.json,,"The most useful applications of dialog systems such as digital personal assistants or bots are currently goal-oriented and transactional: the system needs to understand a user request and complete a related task with a clear goal within a limited number of dialog turns. The workhorse of traditional dialog systems is slot-filling (Lemon et al., 2006; Wang and Lemon, 2013; Young et al., 2013) which predefines the structure of a dialog state as a set of slots to be filled during the dialog. For a restaurant reservation system, such slots can be the location, price range or type of cuisine of a restaurant. Slot-filling has proven reliable but is inherently hard to scale to new domains: it is impossible to manually encode all features and slots that users might refer to in a conversation. End-to-end dialog systems, usually based on neural networks (Shang et al., 2015; Vinyals and Le, 2015; Sordoni et al., 2015; Serban et al., 2015a; Dodge et al., 2016), escape such limitations: all their components are directly trained on past dialogs, with no assumption on the domain or dialog state structure, thus making it easy to automatically scale up to new domains. They have shown promising performance in non goal-oriented chit-chat settings, where they were trained to predict the next utterance in social media and forum threads (Ritter et al., 2011; Wang et al., 2013; Lowe et al., 2015) or movie conversations (Banchs, 2012). But the performance achieved on chit-chat may not necessarily carry over to goal-oriented conversations. As illustrated in Figure 1 in a restaurant reservation scenario, conducting goal-oriented dialog requires skills that go beyond language modeling, e.g., asking questions to clearly define a user request, querying Knowledge Bases (KBs), interpreting results from queries to display options to users or completing a transaction. This makes it hard to ascertain how well end-to-end dialog models would do, especially since evaluating chit-chat performance in itse","Supervised semantic indexing | Movie-dic: a movie dialogue corpus for research and development | End-to-end memory networks with knowledge carryover for multi-turn spoken language understanding | Expanding the scope of the atis task: The atis-3 corpus | Evaluating prerequisite qualities for learning end-to-end dialog systems | Incremental on-line adaptation of pomdp-based dialogue managers to extended domains | The second dialog state tracking challenge | Word-based dialog state tracking with recurrent neural networks | Learning knowledge graphs for question answering through conversational dialog | Cobot in lambdamoo: A social statistics agent | Filter, rank, and transfer the knowledge: Learning to chat | The fourth dialog state tracking challenge | An isu dialogue system exhibiting reinforcement learning of dialogue policies: generic slot-filling in the talk in-car system | How not to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation | The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems | On the evaluation of dialogue systems with next utterance classification | Efficient estimation of word representations in vector space | A survey on metrics for the evaluation of user simulations | Data-driven response generation in social media | Building end-to-end dialogue systems using generative hierarchical neural network models | A survey of available corpora for building data-driven dialogue systems | Neural responding machine for short-text conversation | A neural network approach to context-sensitive generation of conversational responses | Learning from real users: Rating dialogue success with neural networks for reinforcement learning in spoken dialogue systems | Reward shaping with recurrent neural networks for speeding up on-line policy learning in spoken dialogue systems | End-to-end memory networks | A neural conversational model | A dataset for research on short-text conversations | A simple and generic belief tracking mechanism for the dialog state tracking challenge: On the believability of observed information | Semantically conditioned lstm-based natural language generation for spoken dialogue systems | Memory networks | Towards ai-complete question answering: a set of prerequisite toy tasks | Pomdp-based statistical spoken dialog systems: A review | 2016), we represent each utterance as a bag-of-words and in memory it is represented as a vector using the embedding matrix A, i.e. the memory is an array with entries",iclr,010
308.pdf.json,,"Generative adversarial networks (GANs)(Goodfellow et al., 2014a) have achieved great success at generating realistic and sharp looking images. However, they are widely general methods, now starting to be applied to several other important problems, such as semisupervised learning, stabilizing sequence learning methods for speech and language, and 3D modelling. (Denton et al., 2015; Radford et al., 2015; Salimans et al., 2016; Lamb et al., 2016; Wu et al., 2016) However, they still remain remarkably difficult to train, with most current papers dedicated to heuristically finding stable architectures. (Radford et al., 2015; Salimans et al., 2016) Despite their success, there is little to no theory explaining the unstable behaviour of GAN training. Furthermore, approaches to attacking this problem still rely on heuristics that are extremely sensitive to modifications. This makes it extremely hard to experiment with new variants, or to use them in new domains, which limits their applicability drastically. This paper aims to change that, by providing a solid understanding of these issues, and creating principled research directions towards adressing them. It is interesting to note that the architecture of the generator used by GANs doesn’t differ significantly from other approaches like variational autoencoders (Kingma & Welling, 2013). After all, at the core of it we first sample from a simple prior z ∼ p(z), and then output our final sample gθ(z), sometimes adding noise in the end. Always, gθ is a neural network parameterized by θ, and the main difference is how gθ is trained. Traditional approaches to generative modeling relied on maximizing likelihood, or equivalently minimizing the Kullback-Leibler (KL) divergence between our unknown data distribution Pr and our generator’s distribution Pg (that depends of course on θ). If we assume that both distributions are continuous with densities Pr and Pg , then these methods try to minimize KL(Pr‖Pg) = ∫ X Pr(x) log Pr(x) Pg(",Optimization methods for large-scale machine | Deep generative image models using a laplacian pyramid of adversarial networks | Generative adversarial nets | Explaining and harnessing adversarial examples | Approximation capabilities of multilayer feedforward networks | Auto-encoding variational bayes | Professor forcing: A new algorithm for training recurrent | Sample complexity of testing the manifold hypothesis | Unsupervised representation learning with deep convolutional generative adversarial networks | Improved techniques for training | A note on the evaluation of generative models | Optimal Transport: Old and New. Grundlehren der mathematischen Wissenschaften | Learning a probabilistic latent space of object shapes via 3d generative-adversarial,iclr,010
309.pdf.json,,,"Successor features for transfer in reinforcement learning | The arcade learning environment: An evaluation platform for general agents | Improving generalization for temporal difference learning: The successor representation | Learning to forget: Continual prediction with lstm | Vizdoom: A doom-based ai research platform for visual reinforcement learning | Skill discovery in continuous reinforcement learning domains using skill chaining | Deep successor reinforcement learning | Playing FPS games with deep reinforcement learning | Recurrent reinforcement learning: A hybrid approach | Memory approaches to reinforcement learning in non-markovian domains | Learning to navigate in complex environments | Playing atari with deep reinforcement learning | Human-level control through deep reinforcement learning | Asynchronous methods for deep reinforcement learning | Action-conditional video prediction using deep networks in atari games | Control of memory, active perception, and action in minecraft | Hippocampal place cells construct reward related sequences through unexplored | Incremental multi-step q-learning | The future of memory: remembering | Universal value function approximators | Prioritized experience replay | Formal theory of creativity, fun, and intrinsic motivation (1990–2010) | Compositional planning using optimal option models | Mastering the game of go with deep neural networks and tree | Policy gradient methods for reinforcement learning with function approximation | Between mdps and semi-mdps: A framework for temporal abstraction in reinforcement learning | Horde: A scalable real-time architecture for learning knowledge from unsupervised sensorimotor interaction | A deep hierarchical approach to lifelong learning in minecraft | Dueling Network Architectures for Deep Reinforcement Learning | Learning from delayed rewards | Modelbased reinforcement learning with parametrized physical models and optimism-driven exploration | Graying the black box: Understanding dqns",iclr,010
310.pdf.json,,"I tried to break it to him gently [...] the only way to learn an unknown language is to interact with a native speaker [...] asking questions, holding a conversation, that sort of thing [...] If you want to learn the aliens’ language, someone [...] will have to talk with an alien. Recordings alone aren’t sufficient. Ted Chiang, Story of Your Life One of the main aims of AI is to develop agents that can cooperate with others to achieve goals (Wooldridge, 2009). Such coordination requires communication. If the coordination partners are to include humans, the most obvious channel of communication is natural language. Thus, handling natural-language-based communication is a key step toward the development of AI that can thrive in a world populated by other agents. Given the success of deep learning models in related domains such as image captioning or machine translation (e.g., Sutskever et al., 2014; Xu et al., 2015), it would seem reasonable to cast the problem of training conversational agents as an instance of supervised learning (Vinyals & Le, 2015). However, training on “canned” conversations does not allow learners to experience the interactive aspects of communication. Supervised approaches, which focus on the structure of language, are an excellent way to learn general statistical associations between sequences of symbols. However, they do not capture the functional aspects of communication, i.e., that humans use words to coordinate with others and make things happen (Austin, 1962; Clark, 1996; Wittgenstein, 1953). This paper introduces the first steps of a research program based on multi-agent coordination communication games. These games place agents in simple environments where they need to develop a language to coordinate and earn payoffs. Importantly, the agents start as blank slates, but, by playing a game together, they can develop and bootstrap knowledge on top of each others, leading to the emergence of a language. ∗Work done while at Facebook AI Resea","Hierarchies of beliefs and common knowledge | Simulating the evolution of language | Domain-specific knowledge systems in the brain | Imagenet: A large-scale hierarchical image database | Learning to communicate to solve riddles with deep distributed recurrent q-networks | Recency, records and recaps: learning and nonequilibrium behavior in a simple decision problem | Generative adversarial nets | Learning to play guess who? and inventing a grounded language as a consequence | Referitgame: Referring to objects in photographs of natural scenes | Semantic feature production norms for a large set of living and nonliving things | A roadmap towards machine intelligence | The Generative Lexicon | Learning in extensive-form games: Experimental data and simple dynamic models in the intermediate term | The electronic mail game: Strategic behavior under ‘almost common knowledge | Mastering the game of Go with deep neural networks and tree | Very deep convolutional networks for large-scale image recognition | Signals: Evolution, learning, and information | Minimal requirements for the emergence of learned signaling | The grounded naming game. In Luc Steels (ed.), Experiments in Cultural Language Evolution, pp. 41–59 | Towards collaborative and adversarial learning: A case study in robotic soccer | Learning multiagent communication with backpropagation | Sequence to sequence learning with neural networks | Reinforcement Learning: An Introduction | Visualizing data using t-SNE | A neural conversational model | Progress in the simulation of emergent communication and language | Learning language games through interaction | Simple statistical gradient-following algorithms for connectionist reinforcement learning | Procedures as a representation for data in a computer program for understanding natural language | Philosophical Investigations | An introduction to multiagent systems | Show, attend and tell: Neural image caption generation with visual attention | Visualizing and understanding convolutional networks | Criterion functions for document clustering: Experiments and analysis",iclr,010
312.pdf.json,,"The last few years have seen much success of deep neural networks in many challenging applications, such as speech recognition (Hinton et al., 2012), image recognition (LeCun et al., 1998; Krizhevsky et al., 2012) and machine translation (Sutskever et al., 2014; Bahdanau et al., 2015; Wu et al., 2016). Along with this success is a paradigm shift from feature designing to architecture designing, i.e., from SIFT (Lowe, 1999), and HOG (Dalal & Triggs, 2005), to AlexNet (Krizhevsky et al., 2012), VGGNet (Simonyan & Zisserman, 2014), GoogleNet (Szegedy et al., 2015), and ResNet (He et al., 2016a). Although it has become easier, designing architectures still requires a lot of expert knowledge and takes ample time. This paper presents Neural Architecture Search, a gradient-based method for finding good architectures (see Figure 1) . Our work is based on the observation that the structure and connectivity of a ∗Work done as a member of the Google Brain Residency program (g.co/brainresidency.) neural network can be typically specified by a variable-length string. It is therefore possible to use a recurrent network – the controller – to generate such string. Training the network specified by the string – the “child network” – on the real data will result in an accuracy on a validation set. Using this accuracy as the reward signal, we can compute the policy gradient to update the controller. As a result, in the next iteration, the controller will give higher probabilities to architectures that receive high accuracies. In other words, the controller will learn to improve its search over time. Our experiments show that Neural Architecture Search can design good models from scratch, an achievement considered not possible with other methods. On image recognition with CIFAR-10, Neural Architecture Search can find a novel ConvNet model that is better than most human-invented architectures. Our CIFAR-10 model achieves a 3.65 test set error, while being 1.05x faster than the current b",Learning to compose neural networks for question answering | Learning to learn by gradient descent by gradient descent | Neural machine translation by jointly learning to align and translate | A neural probabilistic language model | Random search for hyper-parameter optimization | Algorithms for hyper-parameter optimization | Making a science of model search: Hyperparameter optimization in hundreds of dimensions for vision | The inference of regular LISP programs from examples | Language modeling with sum-product networks | Histograms of oriented gradients for human detection | Large scale distributed deep networks | Neuroevolution: from architectures to learning | A theoretically grounded application of dropout in recurrent neural networks | Deep residual learning for image recognition | Identity mappings in deep residual networks | Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups | Long short-term memory | Densely connected convolutional networks | Densely connected convolutional networks | Deep networks with stochastic depth | Tying word vectors and word classifiers: A loss framework for language modeling | Batch normalization: Accelerating deep network training by reducing internal covariate shift | What is the best multi-stage architecture for object recognition | An empirical exploration of recurrent network architectures | Character-aware neural language models | Adam: A method for stochastic optimization | Imagenet classification with deep convolutional neural networks | Human-level concept learning through probabilistic program induction | Fractalnet: Ultra-deep neural networks without residuals | Gradient-based learning applied to document recognition | Learning to optimize | Learning programs: A hierarchical Bayesian approach | Object recognition from local scale-invariant features | Towards automatically-tuned neural networks | Pointer sentinel mixture models | Context dependent recurrent neural network language model | Three new graphical models for statistical language modelling | Rectified linear units improve restricted Boltzmann machines | Neural programmer: Inducing latent programs with gradient descent | How to construct deep recurrent neural networks | Using the output embedding to improve language models | Sequence level training with recurrent neural networks | Neural programmer-interpreters | Convolutional neural fabrics | Minimum risk training for neural machine translation | Very deep convolutional networks for large-scale image recognition | Practical Bayesian optimization of machine learning algorithms | Scalable bayesian optimization using deep neural networks | Striving for simplicity: The all convolutional net | A hypercube-based encoding for evolving large-scale neural networks | A methodology for LISP program construction from examples | On the importance of initialization and momentum in deep learning | Sequence to sequence learning with neural networks | Going deeper with convolutions | Learning to learn | Modeling systems with internal state using evolino | Simple statistical gradient-following algorithms for connectionist reinforcement learning | Google’s neural machine translation system: Bridging the gap between human and machine translation | Wide residual networks | Recurrent neural network regularization | Recurrent highway networks,iclr,010
314.pdf.json,,"Machine learning problems are commonly divided into three classes: supervised, unsupervised, and reinforcement learning. In this view, supervised learning is concerned with learning input-output mappings, unsupervised learning aims to find hidden structure in data, and reinforcement learning deals with goal-directed behavior (Murphy, 2012). Reinforcement learning is compelling because it considers the natural setting of an organism acting in its environment. It is generally taken to comprise a class of problems (learning to act), the mathematical formalization of these problems (maximizing the expected discounted return), and a family of algorithmic approaches (optimizing an objective derived from the Bellman equation) (Kaelbling et al., 1996; Sutton & Barto, 2017). While reinforcement learning (RL) has achieved significant progress (Mnih et al., 2015), key challenges remain. One is sensorimotor control from raw sensory input in complex and dynamic threedimensional environments, learned directly from experience. Another is the acquisition of general skills that can be flexibly deployed to accomplish a multitude of dynamically specified goals (Lake et al., 2016). In this work, we propose an approach to sensorimotor control that aims to assist progress towards overcoming these challenges. Our approach departs from the reward-based formalization commonly used in RL. Instead of a monolithic state and a scalar reward, we consider a stream of sensory input {st} and a stream of measurements {mt}. The sensory stream is typically high-dimensional and may include the raw visual, auditory, and tactile input. The measurement stream has lower dimensionality and constitutes a set of data that pertain to the agent’s current state. In a physical system, measurements can include attitude, supply levels, and structural integrity. In a three-dimensional computer game, they can include health, ammunition levels, and the number of adversaries overcome. Our guiding observation is that th","Motor development | Recent advances in hierarchical reinforcement learning | A counterexample to temporal differences learning | Pathologies of temporal difference methods in approximate dynamic programming | Model-free episodic control | Learning parameterized skills | Multi-task policy search for robotics | Learning rates for Q-learning | Unsupervised learning for physical interaction through video prediction | Multi-criteria reinforcement learning | Delving deep into rectifiers: Surpassing humanlevel performance on ImageNet classification | Forward models: Supervised learning with a distal teacher | ViZDoom: A Doom-based AI research platform for visual reinforcement learning | Adam: A method for stochastic optimization | Reinforcement learning to adjust parametrized motor primitives to new situations | Reinforcement learning in robotics: A survey | Transfer in reinforcement learning via shared features | Hierarchical deep reinforcement learning: Integrating temporal abstraction and intrinsic motivation | Deep successor reinforcement learning | Masters of Doom: How Two Guys Created an Empire and Transformed Pop Culture | Building machines that learn and think like people | Playing FPS games with deep reinforcement learning | Off-road obstacle avoidance through end-toend learning | Guided policy search | Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection | Continuous control with deep reinforcement learning | Predictive representations of state | Deep multi-scale video prediction beyond mean square error | Human-level control through deep reinforcement learning | Asynchronous methods for deep reinforcement learning | Machine Learning: A Probabilistic Perspective | Action-conditional video prediction using deep networks in Atari games | Control of memory, active perception, and action in Minecraft | A survey of multi-objective sequential decision-making | Learning monocular reactive UAV control in cluttered natural environments | Universal value function approximators | Mastering the game of Go with deep neural networks and tree | Reinforcement learning with replacing eligibility traces | Learning predictive state representations | Learning to predict by the methods of temporal differences | Generalization in reinforcement learning: Successful examples using sparse coarse coding | Reinforcement Learning: An Introduction | Horde: a scalable real-time architecture for learning knowledge from unsupervised sensorimotor interaction | A unified analysis of value-function-based reinforcement learning algorithms | TD-gammon, a self-teaching backgammon program, achieves master-level play | On the convergence of optimistic policy iteration | WaveNet: A generative model for raw audio | Dueling network architectures for deep reinforcement learning | The large network is similar, but all layers starting from the third are wider by a factor of two. In all networks we use the leaky ReLU nonlinearity LReLU(x) = max(x, 0.2x) after each nonterminal layer",iclr,010
315.pdf.json,,"Deep Learning has emerged as one of the cornerstones of large-scale machine learning. Deep Learning models are used for achieving state-of-the-art results on a wide variety of tasks including computer vision, natural language processing and reinforcement learning; see (Bengio et al., 2016) and the references therein. The problem of training these networks is one of non-convex optimization. Mathematically, this can be represented as: min x∈Rn f(x) := 1 M M∑ i=1 fi(x), (1) where fi is a loss function for data point i ∈ {1, 2, · · · ,M} which captures the deviation of the model prediction from the data, and x is the vector of weights being optimized. The process of optimizing this function is also called training of the network. Stochastic Gradient Descent (SGD) (Bottou, 1998; Sutskever et al., 2013) and its variants are often used for training deep networks. ∗Work was performed when author was an intern at Intel Corporation These methods minimize the objective function f by iteratively taking steps of the form: xk+1 = xk − αk ( 1 |Bk| ∑ i∈Bk ∇fi(xk) ) , (2) whereBk ⊂ {1, 2, · · · ,M} is the batch sampled from the data set and αk is the step size at iteration k. These methods can be interpreted as gradient descent using noisy gradients, which and are often referred to as mini-batch gradients with batch size |Bk|. SGD and its variants are employed in a small-batch regime, where |Bk| M and typically |Bk| ∈ {32, 64, · · · , 512}. These configurations have been successfully used in practice for a large number of applications; see e.g. (Simonyan & Zisserman, 2014; Graves et al., 2013; Mnih et al., 2013). Many theoretical properties of these methods are known. These include guarantees of: (a) convergence to minimizers of strongly-convex functions and to stationary points for non-convex functions (Bottou et al., 2016), (b) saddle-point avoidance (Ge et al., 2015; Lee et al., 2016), and (c) robustness to input data (Hardt et al., 2015). Stochastic gradient methods have, howeve","Deep learning. Book in preparation for MIT Press, 2016 | Robust optimization for unconstrained simulation-based problems | Online learning and stochastic approximations | Optimization methods for large-scale machine learning | A limited memory algorithm for bound constrained optimization | Sample size selection in optimization methods for machine learning | Entropy-sgd: Biasing gradient descent into wide valleys | The loss surfaces of multilayer networks | Distributed deep learning using synchronous stochastic gradient descent | Large scale distributed deep networks | Adaptive subgradient methods for online learning and stochastic optimization | Weak sharp minima and penalty functions in mathematical programming | Hybrid deterministic-stochastic methods for data fitting | Timit acoustic-phonetic continuous speech corpus | Escaping from saddle pointsonline stochastic gradient for tensor decomposition | Explaining and harnessing adversarial examples | Qualitatively characterizing neural network optimization problems | Speech recognition with deep recurrent neural networks | Train faster, generalize better: Stability of stochastic gradient descent | Batch normalization: Accelerating deep network training by reducing internal covariate shift | adaQN: An Adaptive Quasi-Newton Algorithm for Training RNNs, pp. 1–16 | Adam: A method for stochastic optimization | Learning multiple layers of features from tiny images | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | Gradient-based learning applied to document recognition | The mnist database of handwritten digits | Efficient backprop | Gradient descent converges to minimizers | Efficient mini-batch training for stochastic optimization | A practical bayesian framework for backpropagation networks | Playing atari with deep reinforcement learning | Training recurrent neural networks by diffusion | The kaldi speech recognition toolkit. In IEEE 2011 workshop on automatic speech recognition and understanding, number EPFL-CONF-192584 | A universal prior for integers and estimation by minimum description length | Understanding adversarial training: Increasing local stability of neural nets through robust optimization | Very deep convolutional networks for large-scale image recognition | No bad local minima: Data independent training error guarantees for multilayer neural networks | Dropout: a simple way to prevent neural networks from overfitting | On the importance of initialization and momentum in deep learning | Deep learning with elastic averaging sgd",iclr,010
316.pdf.json,SEMI-SUPERVISED KNOWLEDGE TRANSFER FOR DEEP LEARNING FROM PRIVATE TRAINING DATA,"Some machine learning applications with great benefits are enabled only through the analysis of sensitive data, such as users’ personal contacts, private photographs or correspondence, or even medical records or genetic sequences (Alipanahi et al., 2015; Kannan et al., 2016; Kononenko, 2001; Sweeney, 1997). Ideally, in those cases, the learning algorithms would protect the privacy of users’ training data, e.g., by guaranteeing that the output model generalizes away from the specifics of any individual user. Unfortunately, established machine learning algorithms make no such guarantee; indeed, though state-of-the-art algorithms generalize well to the test set, they continue to overfit on specific training examples in the sense that some of these examples are implicitly memorized. Recent attacks exploiting this implicit memorization in machine learning have demonstrated that private, sensitive training data can be recovered from models. Such attacks can proceed directly, by analyzing internal model parameters, but also indirectly, by repeatedly querying opaque models to gather data for the attack’s analysis. For example, Fredrikson et al. (2015) used hill-climbing on the output probabilities of a computer-vision classifier to reveal individual faces from the training data. ∗Work done while the author was at Google. †Work done both at Google Brain and at OpenAI. Because of those demonstrations—and because privacy guarantees must apply to worst-case outliers, not only the average—any strategy for protecting the privacy of training data should prudently assume that attackers have unfettered access to internal model parameters. To protect the privacy of training data, this paper improves upon a specific, structured application of the techniques of knowledge aggregation and transfer (Breiman, 1994), previously explored by Nissim et al. (2007), Pathak et al. (2010), and particularly Hamm et al. (2016). In this strategy, first, an ensemble (Dietterich, 2000) of teacher model","Deep learning with differential privacy | On k-anonymity and the curse of dimensionality | Predicting the sequence specificities of DNA-and RNA-binding proteins by deep learning | Queries and concept learning | Differentially private empirical risk minimization: efficient algorithms and tight error bounds | Neural net algorithms that learn in polynomial time from examples and queries | Signature verification using a “Siamese” time delay neural network | Concentrated differential privacy: simplifications, extensions, and lower bounds | Privacy-preserving logistic regression | Differentially private empirical risk minimization | Ensemble methods in machine learning | A firm foundation for private data analysis | The algorithmic foundations of differential privacy | Concentrated differential privacy | Our data, ourselves: privacy via distributed noise generation | Calibrating noise to sensitivity in private data analysis | Boosting and differential privacy | RAPPOR: Randomized aggregatable privacy-preserving ordinal response | Model inversion attacks that exploit confidence information and basic countermeasures | Generative adversarial nets | Learning privately from multiparty data | Distilling the knowledge in a neural network | A semi-supervised learning approach to differential privacy | Smart reply: Automated response suggestion for email | Siamese neural networks for one-shot image recognition | Machine learning for medical diagnosis: history, state of the art and perspective | k-anonymity: A model for protecting privacy. volume 10, pp. 557–570 | Smooth sensitivity and sampling in private data analysis | Multiparty differential privacy via aggregation of locally trained classifiers | Privacy preserving probabilistic inference with hidden markov models | Missing data imputation for supervised learning | Improved techniques for training GANs | Privacy-preserving deep learning | Stochastic gradient descent with differentially private updates | Weaving technology and policy together to maintain confidentiality | Privacy aware learning | Randomized response: A survey technique for eliminating evasive answer bias",iclr,010
317.pdf.json,AMORTISED MAP INFERENCE FOR IMAGE SUPER-RESOLUTION,"Image super-resolution (SR) is the underdetermined inverse problem of estimating a high resolution (HR) image given the corresponding low resolution (LR) input. This problem has recently attracted significant research interest due to the potential of enhancing the visual experience in many applications while limiting the amount of raw pixel data that needs to be stored or transmitted. While SR has many applications in for example medical diagnostics or forensics (Nasrollahi & Moeslund, 2014, and references therein), here we are primarily motivated to improve the perceptual quality when applied to natural images. Most current single image SR methods use empirical risk minimisation, often with a pixel-wise mean squared error (MSE) loss (Dong et al., 2016; Shi et al., 2016). However, MSE, and convex loss functions in general, are known to have limitations when presented with uncertainty in multimodal and nontrivial distributions such as distributions over natural images. In SR, a large number of plausible images can explain the LR input and the Bayes-optimal behaviour for any MSE trained model is to output the mean of the plausible solutions weighted according to their posterior probability. For natural images this averaging behaviour leads to blurry and over-smoothed outputs that generally appear implausible, i.e. the produced estimates have low probability under the natural image prior. An idealised method for our applications would use a full-reference perceptual loss function that describes the sensitivity of the human visual perception system to different distortions. However the ∗Work done while CKS was an intern at Twitter shown ( ). b) Trained model outputs for x ∈ [−8, 8] and estimated gradients from a denoising function trained on pY . Note the AffGAN( ) and AffDG( ) models fit the posterior mode well whereas the MSE ( ) and MAE ( ) model outputs generally fall in low probability regions. H[qθ, pY ] `MSE(x,Ay) MAP 3.15 - MSE 9.10 1.25 · 10−2 MAE 6.30 4.04 · 1","What regularized auto-encoders learn from the data-generating distribution | Towards principled methods for training generative adversarial networks | Super-resolution with deep convolutional sufficient statistics | Image super-resolution using deep convolutional networks | Generating images with perceptual similarity metrics based on deep networks | Open source code | Generative adversarial nets | Tagger: Deep unsupervised perceptual grouping | Densely connected convolutional networks | An alternative update rule for generative adversarial networks | Auto-encoding variational bayes | Perceptual image quality assessment using a normalized laplacian pyramid | Autoencoding beyond pixels using a learned similarity metric | Photo-realistic single image super-resolution using a generative adversarial network | Combining markov random fields and convolutional neural networks for image synthesis | Optimal recovery from compressive measurements via denoising-based approximate message passing | Learning in implicit generative models | Super-resolution: a comprehensive survey | f-GAN: Training generative neural samplers using variational divergence minimization | Pixel recurrent neural networks | Unsupervised representation learning with deep convolutional generative adversarial networks | Semi-supervised learning with ladder networks | Improved techniques for training gans | Denoising source separation | Real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network | Theano: A python framework for fast computation of mathematical expressions | Generative image modeling using spatial lstms | Mixtures of conditional gaussian scale mixtures applied to multiscale image representations | Extracting and composing robust features with denoising autoencoders | Multiscale structural similarity for image quality assessment | Image quality assessment: from error visibility to structural similarity | 2016; Radford et al., 2015) via various tricks",iclr,010
318.pdf.json,LEARNING GRAPHICAL STATE TRANSITIONS,"Many different types of data can be formulated using a graph structure. One form of data that lends itself to a graphical representation is data involving relationships (edges) between entities (nodes). Abstract maps of places and paths between them also have a natural graph representation, where places are nodes and paths are edges. In addition, many data structures can be expressed in graphical form, including linked lists and binary trees. Substantial research has been done on producing output when given graph-structured input (Kashima et al., 2003; Shervashidze et al., 2011; Perozzi et al., 2014; Bruna et al., 2013; Duvenaud et al., 2015). Of particular relevance to this work are Graph Neural Networks (Gori et al., 2005; Scarselli et al., 2009), or GNNs, which extend recursive neural networks by assigning states to each node in a graph based on the states of adjacent nodes. Recently Li et al. (2016) have modified GNNs to use gated state updates and to produce output sequences. The resulting networks, called GG-NNs and GGS-NNs, are successful at solving a variety of tasks with graph-structured input. The current work further builds upon GG-NNs and GGS-NNs by allowing graph-structured intermediate representations, as well as graph-structured outputs. This is accomplished using a more flexible graph definition, along with a set of graph transformations which take a graph and other information as input and produce a modified version of the graph. This work also introduces the Gated Graph Transformer Neural Network model (GGT-NN), which combines these transformations with a recurrent input model to incrementally construct a graph given natural language input, and can either produce a final graph representing its current state, or use the graph to produce a natural language output. Extending GG-NNs in this way opens up a wide variety of applications. Since many types of data can be naturally expressed as a graph, it is possible to train a GGT-NN model to manipulate a ","Learning efficient algorithms with hierarchical attentive memory | Spectral networks and locally connected networks on graphs | Learning phrase representations using rnn encoder-decoder for statistical machine translation | Convolutional networks on graphs for learning molecular fingerprints | Learning and extracting finite state automata with second-order recurrent neural networks | A new model for learning in graph domains | Neural turing machines | Hybrid computing using a neural network with dynamic external | Dynamic neural turing machine with soft and hard addressing schemes | Tracking the world state with recurrent entity networks | Marginalized kernels between labeled graphs | Semi-supervised classification with graph convolutional networks | Gated graph sequence neural networks | Deepwalk: Online learning of social representations | The graph neural network model | Weisfeiler-lehman graph kernels | Lifted relational neural networks | End-to-end memory networks | XSEDE: accelerating scientific discovery | Order matters: Sequence to sequence for sets | Towards ai-complete question answering: A set of prerequisite toy tasks | A new kind of science, volume 5 | Dynamic memory networks for visual and textual question answering",iclr,010
319.pdf.json,,"As humans, we need to pay attention in order to be able to adequately perceive our surroundings. Attention is therefore a key aspect of our visual experience, and closely relates to perception - we need to keep attention to build a visual representation, possessing detail and coherence. As artificial neural networks became more popular in fields such as computer vision and natural language processing in the recent years, artificial attention mechanisms started to be developed as well. Artificial attention lets a system “attend” to an object to examine it with greater detail. It has also become a research tool for understanding mechanisms behind neural networks, similar to attention used in psychology. One of the popular hypothesis there is that there are non-attentional and attentional perception processes. Non-attentional processes help to observe a scene in general and gather high-level information, which, when associated with other thinking processes, helps us to control the attention processes and navigate to a certain part of the scene. This implies that different observers with different knowledge, different goals, and therefore different attentional strategies can literally see the same scene differently. This brings us to the main topic of this paper: how attention differs within artificial vision systems, and can we use attention information in order to improve the performance of convolutional neural networks ? More specifically, can a teacher network improve the performance of another student network by providing to it information about where it looks, i.e., about where it concentrates its attention into ? To study these questions, one first needs to properly specify how attention is defined w.r.t. a given convolutional neural network. To that end, here we consider attention as a set of spatial maps that essentially try to encode on which spatial areas of the input the network focuses most for taking its output decision (e.g., for classifying an image), wh","Neural machine translation by jointly learning to align and translate | Group equivariant convolutional networks | Learning where to attend with deep architectures for image tracking | Improving generalization performance using double backpropagation | Deep residual learning for image recognition | Distilling the knowledge in a neural networks | Learning to combine foveal glimpses with a third-order boltzmann machine | Do deep nets really need to be deep | Recurrent models of visual attention | Is object localization for free? weakly-supervised learning with convolutional neural networks | Deep face recognition | Recognizing indoor scenes | The dynamic representation of scenes | FitNets: Hints for thin deep nets | Grad-cam: Why did you say that? visual explanations from deep networks via gradient-based localization | Deep inside convolutional networks: Visualising image classification models and saliency maps | Striving for simplicity: The all convolutional net | The Caltech-UCSD Birds-200-2011 Dataset | Show, attend and tell: Neural image caption generation with visual attention | Stacked attention networks for image question answering | Wide residual networks | Visualizing and understanding convolutional networks | Learning deep features for discriminative localization",iclr,010
320.pdf.json,,"Visual servoing is a classic problem in robotics that requires moving a camera or robot to match a target configuration of visual features or image intensities. Many robot control tasks that combine perception and action can be posed as visual servoing, including navigation (DeSouza & Kak, 2002; Chen et al., 2006), where a robot must follow a desired path; manipulation, where the robot must servo an end-effector or a camera to a target object to grasp or manipulate it (Malis et al., 1999; Corke, 1993; Hashimoto, 1993; Hosoda & Asada, 1994; Kragic & Christensen, 2002); and various other problems, as surveyed in Hutchinson et al. (1996). Most visual servoing methods assume access to good geometric image features (Chaumette & Hutchinson, 2006; Collewet et al., 2008; Caron et al., 2013) and require knowledge of their dynamics, which are typically obtained from domain knowledge about the system. Using such hand-designed features and models prevents exploitation of statistical regularities in the world, and requires manual engineering for each new system. In this work, we study how learned visual features, learned predictive dynamics models, and reinforcement learning can be combined to learn visual servoing mechanisms. We focus on target following, with the goal of designing algorithms that can learn a visual servo using low amounts of data of the target in question, so as to be easy and quick to adapt to new targets. Successful target following requires the visual servo to tolerate moderate variation in the appearance of the target, including changes in viewpoint and lighting, as well as occlusions. Learning invariances to all such distractors typically requires a considerable amount of data. However, since a visual servo is typically specific to a particular task, it is desirable to be able to learn the servoing mechanism very quickly, using a minimum amount of data. Prior work has shown that the features learned by large convolutional neural networks on large image da","SURF: Speeded up robust features | Photometric visual servoing for omnidirectional cameras | Bootstrapping bilinear models of simple vehicles | Visual servo control. I | Homography-based visual servo tracking control of a wheeled mobile robot | Photometric visual servoing | Visual servoing set free from image processing | Visual control of robot manipulators – A review | Beyond correlation filters: Learning continuous convolution operators for visual tracking | A tutorial on the cross-entropy method | ImageNet: A large-scale hierarchical image database | Vision for mobile robot navigation: A survey | DeCAF: A deep convolutional activation feature for generic visual recognition | Tree-based batch mode reinforcement learning | A new approach to visual servoing in robotics | Regularized fitted Q-iteration for planning in continuous-space Markovian decision problems | Vision-guided servoing with feature-based trajectory generation (for robots) | Stable function approximation in dynamic programming | Versatile visual servoing without knowledge of true Jacobian | A tutorial on visual servo control | Experimental evaluation of uncalibrated visual servoing for precision manipulation | Dynamic filter networks | Caffe: Convolutional architecture for fast feature embedding | Adam: A method for stochastic optimization | Survey on visual servoing for manipulation | Acquiring visual servoing reaching and grasping skills using neural reinforcement learning | Autonomous reinforcement learning on raw visual input data in a real world application | End-to-end training of deep visuomotor policies | Continuous control with deep reinforcement learning | Deep predictive coding networks for video prediction and unsupervised learning | Distinctive image features from scale-invariant keypoints | Deep multi-scale video prediction beyond mean square error | Playing Atari with deep reinforcement | Vision-based control of a quadrotor for perching on lines | Action-conditional video prediction using deep networks in Atari games | Neural fitted Q iteration – First experiences with a data efficient neural reinforcement learning method | ORB: An efficient alternative to SIFT or SURF | Self-learning visual servoing of robot manipulator using explanation-based fuzzy neural networks and Q-learning | Trust region policy optimization | Very deep convolutional networks for large-scale image recognition | Generating videos with scene dynamics | An uncertain future: Forecasting from static images using variational autoencoders | Embed to control: A locally linear latent dynamics model for control from raw images | Dynamic sensor-based control of robots with visual feedback | Relative end-effector control using cartesian position based visual servoing | Visual dynamics: Probabilistic future frame synthesis via cross convolutional networks | Active, uncalibrated visual servoing | Multi-scale context aggregation by dilated convolutions",iclr,010
321.pdf.json,STOCHASTIC NEURAL NETWORKS FOR HIERARCHICAL REINFORCEMENT LEARNING,"In recent years, deep reinforcement learning has achieved many impressive results, including playing Atari games from raw pixel inputs (Guo et al., 2014; Mnih et al., 2015; Schulman et al., 2015), mastering the game of Go (Silver et al., 2016), and acquiring advanced manipulation and locomotion skills from raw sensory inputs (Schulman et al., 2015; Lillicrap et al., 2015; Watter et al., 2015; Schulman et al., 2016; Heess et al., 2015; Levine et al., 2016). Despite these success stories, these deep RL algorithms typically employ naive exploration strategies such as -greedy or uniform Gaussian exploration noise, which have been shown to perform poorly in tasks with sparse rewards (Duan et al., 2016; Houthooft et al., 2016; Bellemare et al., 2016). Tasks with sparse rewards are common in realistic scenarios. For example, in navigation tasks, the agent is not rewarded until it finds the target. The challenge is further complicated by long horizons, where naive exploration strategies can lead to exponentially large sample complexity (Osband et al., 2014). To tackle these challenges, two main strategies have been pursued: The first strategy is to design a hierarchy over the actions (Parr & Russell, 1998; Sutton et al., 1999; Dietterich, 2000). By composing low-level actions into high-level primitives, the search space can be reduced exponentially. However, these approaches require domain-specific knowledge and careful hand-engineering. The second strategy uses intrinsic rewards to guide exploration (Schmidhuber, 1991; 2010; Houthooft et al., 2016; Bellemare et al., 2016). The computation of these intrinsic rewards does not require domain-specific knowledge. However, when facing a collection of tasks, these methods do not provide a direct answer about how knowledge about solving one task may transfer to other tasks, and by solving each of the tasks from scratch, the overall sample complexity may still be high. 1Code available at: https://github.com/florensacc/snn4hrl 2Vide","The option-critic architecture | Unifying count-based exploration and intrinsic motivation | Infogan: Interpretable representation learning by information maximizing generative adversarial nets | Intrinsically motivated reinforcement learning | Gaussian-bernoulli deep boltzmann machine | Hierarchical relative entropy policy search | Autonomous reinforcement learning with hierarchical reps | Learning modular neural network policies for multi-task and multi-robot transfer | Hierarchical reinforcement learning with the maxq value function decomposition | Benchmarking deep reinforcement learning for continuous control | Multimodal compact bilinear pooling for visual question answering and visual grounding | Draw: A recurrent neural network for image generation | Deep learning for real-time atari game play using offline monte-carlo tree search planning | Learning continuous control policies by stochastic value gradients | Learning and transfer of modulated locomotor controllers | Training products of experts by minimizing contrastive divergence | A fast learning algorithm for deep belief nets | Variational information maximizing exploration | Categorical reparameterization with gumbel-softmax | Building portable options: Skill transfer in reinforcement learning | Autonomous skill acquisition on a mobile manipulator | Bayesian multi-task reinforcement learning | Representational power of restricted boltzmann machines and deep belief networks | End-to-end training of deep visuomotor policies | Continuous control with deep reinforcement learning | The concrete distribution: A continuous relaxation of discrete random variables | Dynamic abstraction in reinforcement learning via clustering | Human-level control through deep reinforcement learning | Strategic attentive writer for learning macro-actions | Learning stochastic feedforward networks | Connectionist learning of belief networks | Generalization and exploration via randomized value functions | Reinforcement learning with hierarchies of machines | Nonparametric bayesian reward segmentation for skill discovery using inverse reinforcement learning | Learning movement primitives | Curious model-building control systems | Formal theory of creativity, fun, and intrinsic motivation (1990–2010) | Trust region policy optimization | Highdimensional continuous control using generalized advantage estimation | Mastering the game of go with deep neural networks and tree | Identifying useful subgoals in reinforcement learning by local graph partitioning | Information processing in dynamical systems: Foundations of harmony theory | Learning options in reinforcement learning | Between mdps and semi-mdps: A framework for temporal abstraction in reinforcement learning | Learning stochastic feedforward neural networks | Transfer learning for reinforcement learning domains: A survey | A generalized iterative lqg method for locally-optimal feedback control of constrained nonlinear stochastic systems | Intrinsically motivated hierarchical skill learning in structured environments | Embed to control: A locally linear latent dynamics model for control from raw images | Multi-task reinforcement learning: a hierarchical bayesian approach | On multiplicative integration with recurrent neural networks | 2016): maximum path length of 500 and batch-size of 50k. Our SNN hierarchical approach outperforms state-of-the-art intrinsic motivation results like VIME (Houthooft et al., 2016). The baseline of having a Center of Mass speed intrinsic reward in the task happens to be stronger than expected",iclr,010
322.pdf.json,NONPARAMETRIC NEURAL NETWORKS,"Automatically choosing a neural network model for a given task without prior information is a challenging problem. Formally, let Θ be the space of all models considered. The goal of model selection is then, usually, to find the value of the hyperparameter θ ∈ Θ that minimizes a certain criterion c(θ), such as the validation error achieved by the model represented by θ when trained to convergence. Because Θ is large, structured and heterogeneous, c is complex, and gradients of c are generally not available, the most popular methods for optimizing c perform zero-order, black-box optimization and do not use any information about c except its value for certain values of θ. These methods select one or more values of θ, compute c at those values and, based on the results, select new values of θ until convergence is achieved or a time limit is reached. The most popular such methods are grid search, random search (e.g. Bergstra & Bengio (2012)) and Bayesian optimization using Gaussian processes (e.g. Snoek et al. (2012)). Others utilize random forests (Hutter et al., 2009), deep neural networks (Snoek et al., 2015) and recently Bayesian neural networks (Springenberg et al., 2016) and reinforcement learning (Zoph & Le, 2017). These black-box methods have two drawbacks. (A) To obtain each value of c, they execute a full network training run. Each run can take days on many cores or multiple GPUs. (B) They do not exploit opportunities to improve the value of c further by altering θ during each training run. In this paper, we present a framework we term nonparametric neural networks for selecting network size. We dynamically and automatically shrink and expand the network as needed to select a good network size during a single training run. Further, by altering network size during training, the network ultimately chosen can achieve a higher accuracy than networks of the same size that are trained from scratch and, in some cases, achieve a higher accuracy than is possible by blac","Learning the number of neurons in deep networks | Dynamic node creation in backpropagation networks. Institute for Cognitive Science, UCSD | Do deep nets really need to be deep | A fast iterative shrinkage-thresholding algorithm for linear inverse problems | Random search for hyper-parameter | Net2net: accelerating learning via knowledge transfer | Memory bounded deep convolutional networks | Improving deep neural networks for lvcsr using rectified linear units and dropout | Bayesian methods for neural networks | Adaptive subgradient methods for online learning and stochastic optimization | The cascade-correlation learning architecture | Learning the structure of deep convolutional networks | Perforatedcnns: Acceleration through elimination of redundant convolutions | Three constructive algorithms for network learning | Dynamic network durgery for efficient dnns | Steps toward deep kernel methods from infinite neural networks | Distilling the knowledge in a neural network | Sequential model-based optimization for general algorithm configuration (extended version) | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Adam: A method for stochastic optimization | Dsd: Dense-sparse-dense training for deep neural networks | Adaptive regularization in neural network modeling | Scalable gradient-based tuning of continuous regularization hyperparameters | Gradient-based hyperparameter optimization through reversible learning | A practical bayesian framework for backpropagation networks | Pruning convolutional neural networks for efficient inference | Learning by stretching deep networks | Fitnets: Hints for thin deep nets | Computing with infinite networks | Very deep convolutional networks for large-scale image recognition | Practical bayesian optimization of machine learning algorithms | Scalable bayesian optimization using deep neural networks | Bayesian optimization with robust bayesian neural networks | On the importance of initialization and momentum in deep learning | Regression shrinkage and selection via the lasso | Lecture 6.5 - rmsprop, coursera: Neural networks for machine learning | Learning structured sparsity in deep neural networks | Computing with infinite networks | Model selection and estimation in regression with grouped variables | Adadelta: An adaptive learning rate method | Neural architecture search with reinforcement learning",iclr,010
324.pdf.json,,"The ImageNet challenge has led to significant advancements in exploring various architectural choices in CNNs (Russakovsky et al. (2015); Krizhevsky et al. (2012); Simonyan & Zisserman (2015); Szegedy et al. (2015a); He et al. (2016)). The general trend since the past few years has been that the networks have grown deeper, with an overall increase in the number of parameters and convolution operations. These high capacity networks have significant inference costs especially when used with embedded sensors or mobile devices where computational and power resources may be limited. For these applications, in addition to accuracy, computational efficiency and small network sizes are crucial enabling factors (Szegedy et al. (2015b)). In addition, for web services that provide image search and image classification APIs that operate on a time budget often serving hundreds of thousands of images per second, benefit significantly from lower inference times. There has been a significant amount of work on reducing the storage and computation costs by model compression (Le Cun et al. (1989); Hassibi & Stork (1993); Srinivas & Babu (2015); Han et al. (2015); Mariet & Sra (2016)). Recently Han et al. (2015; 2016b) report impressive compression rates on AlexNet (Krizhevsky et al. (2012)) and VGGNet (Simonyan & Zisserman (2015)) by pruning weights with small magnitudes and then retraining without hurting the overall accuracy. However, pruning parameters does not necessarily reduce the computation time since the majority of the parameters removed are from the fully connected layers where the computation cost is low, e.g., the fully connected layers of VGG-16 occupy 90% of the total parameters but only contribute less than 1% of the overall floating point operations (FLOP). They also demonstrate that the convolutional layers can be compressed and accelerated (Iandola et al. (2016)), but additionally require sparse ∗Work done at NEC Labs †Supported in part by the NSF under Grant IIS-13","Torch7: A matlab-like environment for machine learning | Binarynet: Training deep neural networks with weights and activations constrained to+ 1 or-1 | Predicting parameters in deep learning | Learning both Weights and Connections for Efficient Neural Network | EIE: Efficient Inference Engine on Compressed Deep Neural Network | Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding | Second Order Derivatives for Network Pruning: Optimal Brain Surgeon | Convolutional Neural Networks at Constrained Time Cost | Deep Residual Learning for Image Recognition | SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and ¡ 1MB model size | Training CNNs with Low-Rank Filters for Efficient Image Classification | Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift | Speeding up convolutional neural networks with low rank expansions | Imagenet Classification with Deep Convolutional Neural Networks | Fast Algorithms for Convolutional Neural Networks | Optimal Brain Damage | Fast Convnets Using Group-wise Brain Damage | Network in Network | Sparse Convolutional Neural Networks | Fast Training of Convolutional Networks through FFTs | Channel-Level Acceleration of Deep Face Representations | XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks | Very Deep Convolutional Networks for Large-Scale Image Recognition | Data-free Parameter Pruning for Deep Neural Networks | Dropout: A Simple Way to Prevent Neural Networks from Overfitting | Going Deeper with Convolutions | Rethinking the Inception Architecture for Computer Vision | Convolutional neural networks with low-rank regularization | Learning Structured Sparsity in Deep Learning | Visualizing and Understanding Convolutional Networks | Accelerating Very Deep Convolutional Networks for Classification and Detection | Efficient and accurate approximations of nonlinear convolutional networks | Less Is More: Towards Compact CNNs",iclr,010
325.pdf.json,,"To go beyond the relatively simpler tasks of classification and regression, advancing our ability to learn good generative models of high-dimensional data appears essential. There are many scenarios where one needs to efficiently produce good high-dimensional outputs where output dimensions have unknown intricate statistical dependencies: from generating realistic images, segmentations, text, speech, keypoint or joint positions, etc..., possibly as an answer to the same, other, or multiple input modalities. These are typically cases where there is not just one right answer but a variety of equally valid ones following a non-trivial and unknown distribution. A fundamental ingredient for such scenarios is thus the ability to learn a good generative model from data, one from which we can subsequently efficiently generate varied samples of high quality. Many approaches for learning to generate high dimensional samples have been and are still actively being investigated. These approaches can be roughly classified under the following broad categories: • Ordered visible dimension sampling (van den Oord et al., 2016; Larochelle & Murray, 2011). In this type of auto-regressive approach, output dimensions (or groups of conditionally independent dimensions) are given an arbitrary fixed ordering, and each is sampled conditionally on the previous sampled ones. This strategy is often implemented using a recurrent network (LSTM or GRU). Desirable properties of this type of strategy are that the exact log likelihood can usually be computed tractably, and sampling is exact. Undesirable properties follow from the forced ordering, whose arbitrariness feels unsatisfactory especially for domains that do not have a natural ordering (e.g. images), and imposes for high-dimensional output a long sequential generation that can be slow. • Undirected graphical models with multiple layers of latent variables. These make inference, and thus learning, particularly hard and tend to be costly to sa","GSNs: generative stochastic networks. Information and Inference, 2016 | Better mixing via deep representations | Deep generative stochastic networks trainable by backprop | Quickly generating representative samples from an rbm-derived process | Nice: Non-linear independent components estimation | Deep sparse rectifier neural networks | Generative adversarial nets | The variational walkback algorithm | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Auto-encoding variational bayes | Learning multiple layers of features from tiny images | The neural autoregressive distribution estimator | The mnist database of handwritten digits | Generative moment matching networks | Deep learning face attributes in the wild | A note on the evaluation of generative models | Unsupervised representation learning with deep convolutional generative adversarial networks | Variational inference with normalizing flows | Stochastic backpropagation and approximate inference in deep generative models | A generative process for sampling contractive auto-encoders | Deep boltzmann machines | Markov chain monte carlo and variational inference: Bridging the gap | Improved techniques for training | Deep Unsupervised Learning using Nonequilibrium Thermodynamics | The toronto face database | Pixel recurrent neural networks | Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion | On the quantitative analysis of decoder-based generative models",iclr,010
328.pdf.json,MULTILAYER RECURRENT NETWORK MODELS OF PRI- MATE RETINAL GANGLION CELL RESPONSES,"Our understanding of sensory processing in the brain is most straightforwardly reflected in our ability to model the process by which stimuli presented at the sensory periphery are transformed into the spiking activity of populations of neurons. For decades, researchers have interrogated stimulus-response ∗These authors contributed equally. neural properties using simplified targeted stimuli, such as bars, spots, or gratings. While these types of stimuli uncovered many interesting aspects of visual computation, they have several limitations (Barlow & Levick, 1965). These stimuli may not fully drive important components of neural response, and modeling efforts have often assumed a quasi-linear mapping from stimulus to firing rate. Subsequent efforts to characterize cells relied on white noise stimulation and building models through reverse correlation (de Boer R & Kuyper, 1968; Marmarelis & Naka, 1972; Chichilnisky, 2001). A standard model used to relate white noise to spiking responses is the linear-nonlinear-Poisson (LN) or generalized linear model (GLM) which consists of a spatiotemporal linear filtering of the stimulus followed by a nonlinearity and probabilistic spike generation (Chichilnisky, 2001; Simoncelli et al., 2004; Schwartz et al., 2006). Although this family of models have advanced our understanding, they do not optimally capture neural responses, especially to natural scenes which can lead to more complex responses than white noise stimuli (David et al., 2004). Even in the retina, early in the visual processing stream, these commonly-used models capture retinal ganglion cell (RGC) responses to natural stimuli less accurately than to white noise (Heitman et al., 2016). Recently, deep neural networks have been used to dramatically improve performance on a diverse array of machine learning tasks (Krizhevsky et al., 2012; LeCun et al., 2015). Furthermore, these networks bear a loose resemblance to real neural networks, and provide a sufficiently rich mode","Do deep nets really need to be deep | The mechanism of directionally selective units in rabbit’s retina | A model of inductive bias learning | Functional asymmetries in on and off ganglion cells of primate retina | A simple white noise analysis of neuronal light responses | Natural stimulus statistics alter the receptive field structure of v1 neurons | Triggered correlation | Spatial properties and functional organization of small bistratified ganglion cells in primate retina | Fidelity of the ensemble code for visual motion in primate retina | Testing pseudo-linear models of responses to natural scenes in primate retina | Long short-term memory | Adam: A method for stochastic optimization | Deep neural networks: A new framework for modeling biological vision and brain information processing | Imagenet classification with deep convolutional neural networks | What does the eye tell the brain?: Development of a system for the large-scale recording of retinal output activity | White-noise analysis of a neuron chain: an application of the wiener theory | Receptive fields of optic tract axons and lateral geniculate cells: peripheral extent and barbiturate sensitivity | Deep convolutional neural network models of the retinal response to natural scenes | Effects of remote stimulation of the modulated activity of cat retina | Spatio-temporal correlations and visual signalling in a complete neuronal population | Spike-triggered neural characterization | Characterization of neural responses with stochastic stimuli, pp. 327–338 | Independent component filters of natural images compared with simple cells in primary visual cortex. Proceedings | Performance-optimized hierarchical models predict neural responses in higher visual cortex",iclr,010
329.pdf.json,IMPROVING GENERATIVE ADVERSARIAL NETWORKS WITH DENOISING FEATURE MATCHING,"Generative adversarial networks (Goodfellow et al., 2014a) (GANs) have become well known for their strength at realistic image synthesis. The objective function for the generative network is an implicit function of a learned discriminator network, estimated in parallel with the generator, which aims to tell apart real data from synthesized. Ideally, the discriminator learns to capture distinguishing features of real data, which the generator learns to imitate, and the process iterates until real data and synthesized data are indistinguishable. In practice, GANs are well known for being quite challenging to train effectively. The relative model capacities of the generator and discriminator must be carefully balanced in order for the generator to effectively learn. Compounding the problem is the lack of an unambiguous and computable convergence criterion. Nevertheless, particularly when trained on image collections from relatively narrow domains such as bedroom scenes (Yu et al., 2015) and human faces (Liu et al., 2015), GANs have been shown to produce very compelling results. For diverse image collections comprising a wider variety of the visual world, the results have generally been less impressive. For example, samples from models trained on ImageNet (Russakovsky et al., 2014) roughly match the local and global statistics of natural images but yield few recognizable objects. Recent work (Salimans et al., 2016) has sought to address this problem by training the discriminator in a semi-supervised fashion, granting the discriminator’s internal representations knowledge of the class structure of (some fraction of) the training data it is presented. This technique markedly increases sample quality, but is unsatisfying from the perspective of GANs as a tool for unsupervised learning. We propose to augment the generator’s training criterion with a second training objective which guides the generator towards samples more like those in the training set by explicitly modelin",A learning algorithm for boltzmann machines | Theano: A python framework for fast computation of mathematical expressions | What regularized auto-encoders learn from the data-generating distribution | An analysis of single-layer networks in unsupervised feature learning | Deep generative image models using a laplacian pyramid of adversarial networks | Decaf: A deep convolutional activation feature for generic visual recognition | Adversarial feature learning | Inverting visual representations with convolutional networks | Adversarially learned inference | Visualizing higher-layer features of a deep network | Generative adversarial nets | On distinguishability criteria for estimating generative models | Explaining and harnessing adversarial examples | A kernel method for the two-sample-problem | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Deep directed generative models with energy-based probability estimation | Adam: A method for stochastic optimization | Learning multiple layers of features from tiny images | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | Building high-level features using large scale unsupervised learning | Difference target propagation | Deep learning face attributes in the wild | Conditional generative adversarial nets | Deep neural networks are easily fooled: High confidence predictions for unrecognizable images | Unsupervised representation learning with deep convolutional generative adversarial networks | Generative adversarial text to image synthesis | Improved techniques for training gans | Amortised map inference for image super-resolution | Intriguing properties of neural networks | Going deeper with convolutions | A note on the evaluation of generative models | Blocks and fuel: Frameworks for deep learning | Adversarial perturbations of deep neural networks | How transferable are features in deep neural networks | Understanding neural networks through deep visualization | LSUN: construction of a largescale image dataset using deep learning with humans | Energy-based generative adversarial network,iclr,010
330.pdf.json,MENTS THROUGH CORRUPTION,"Text understanding starts with the challenge of finding machine-understandable representation that captures the semantics of texts. Bag-of-words (BoW) and its N-gram extensions are arguably the most commonly used document representations. Despite its simplicity, BoW works surprisingly well for many tasks (Wang & Manning, 2012). However, by treating words and phrases as unique and discrete symbols, BoW often fails to capture the similarity between words or phrases and also suffers from sparsity and high dimensionality. Recent works on using neural networks to learn distributed vector representations of words have gained great popularity. The well celebrated Word2Vec (Mikolov et al., 2013a), by learning to predict the target word using its neighboring words, maps words of similar meanings to nearby points in the continuous vector space. The surprisingly simple model has succeeded in generating high-quality word embeddings for tasks such as language modeling, text understanding and machine translation. Word2Vec naturally scales to large datasets thanks to its simple model architecture. It can be trained on billions of words per hour on a single machine. Paragraph Vectors (Le & Mikolov, 2014) generalize the idea to learn vector representation for documents. A target word is predicted by the word embeddings of its neighbors in together with a unique document vector learned for each document. It outperforms established document representations, such as BoW and Latent Dirichlet Allocation (Blei et al., 2003), on various text understanding tasks (Dai et al., 2015). However, two caveats come with this approach: 1) the number of parameters grows with the size of the training corpus, which can easily go to billions; and 2) it is expensive to generate vector representations for unseen documents at test time. We propose an efficient model architecture, referred to as Document Vector through Corruption (Doc2VecC), to learn vector representations for documents. It is motivated by ","Latent dirichlet allocation | Marginalized denoising autoencoders for domain adaptation | Marginalized denoising autoencoders for nonlinear representations | Language modeling for information retrieval, volume 13 | Semi-supervised sequence learning | Document embedding with paragraph vectors | Indexing by latent semantic analysis | Liblinear: A library for large linear classification | Domain adaptation for large-scale sentiment classification: A deep learning approach | Multi-step regression learning for compositional distributional semantics | Improving word representations via global context and multiple word prototypes | Character-aware neural language models | Skip-thought vectors. In Advances in neural information processing | From word embeddings to document distances | Distributed representations of sentences and documents | Learning word vectors for sentiment analysis | Visualizing data using t-sne | Semeval-2014 task 1: Evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual entailment | Ensemble of generative and discriminative techniques for sentiment analysis of movie reviews | Distributed representations of words and phrases and their compositionality | Recurrent neural network based language model | Efficient estimation of word representations in vector space | Linguistic regularities in continuous space word representations | Composition in distributional models of semantics | Term-weighting approaches in automatic text retrieval | Recursive deep models for semantic compositionality over a sentiment treebank | Grounded compositional semantics for finding and describing images with sentences | Improved semantic representations from tree-structured long short-term memory networks | Extracting and composing robust features with denoising autoencoders | Dropout training as adaptive regularization | Baselines and bigrams: Simple, good sentiment and topic classification | Compositional matrix-space models for sentiment analysis | Estimating linear models for compositional distributional semantics | Text understanding from scratch | Aligning books and movies: Towards story-like visual explanations by watching movies and reading books",iclr,010
331.pdf.json,,"People can learn large repertoires of motor skills autonomously from their own experience. However, learning is accelerated substantially when the learner is allowed to observe another person performing the same skill. In fact, human infants learn faster when they observe adults performing a task, even when the adult performs the task differently from the child, and even when the adult performs the task incorrectly (Meltzoff, 1999). Clearly, we can accelerate our own skill learning by observing a novel behavior, even when that behavior is performed by an agent with different physical capabilities or differences in morphology. Furthermore, evidence in neuroscience suggests that the parts of the brain in monkeys that respond to the pose of the hand can quickly adapt to instead respond to the pose of the end-effector of a tool held in the hand (Umilta et al., 2008). This suggests that the brain learns an invariant feature space for the task (e.g., reaching with a tool) that is independent of the morphology of the limb performing that task. Mirror neurons also fire both when the animal performs a task and when it observes another animal performing it (Rizzolatti & Craighero, 2004; Ferrari et al., 2005). Can we enable robots and other autonomous agents to transfer knowledge from other agents with different morphologies by learning such invariant representations? In robotics and reinforcement learning, prior works have considered building direct isomorphisms between state spaces, as discussed in Section 2. However, most of these methods require specific domain knowledge to determine how to form the mapping, or operate on simple, low-dimensional environments. For instance, Taylor et al. (2008) find a mapping between state spaces by searching through all possible pairings. Learning state-to-state isomorphisms involves an assumption that the two domains can be brought into correspondence, which may not be the case for morphologically ∗These authors contributed equally to thi","Reinforcement learning transfer via common subspaces | Unsupervised cross-domain transfer in policy gradient reinforcement learning via manifold alignment | Unsupervised cross-domain transfer in policy gradient reinforcement learning via manifold alignment | Exploiting task relatedness for multiple task learning | Reuse of neural modules for general video game playing | Multitask learning | Learning a similarity metric discriminatively, with application to face verification | Learning transferable policies for monocular reactive MAV control | Learning modular neural network policies for multi-task and multi-robot transfer | Mirror neurons responding to observation of actions made with tools in monkey ventral premotor cortex | Domain-adversarial training of neural networks | Random projections for manifold learning | Relations between two sets of variates | Adam: A method for stochastic optimization | A framework for transfer in reinforcement learning | Autonomous shaping: knowledge transfer in reinforcement learning | Learning neural network policies with guided policy search under unknown dynamics | End-to-end training of deep visuomotor policies | Iterative linear quadratic regulator design for nonlinear biological movement systems | Continuous control with deep reinforcement learning | Born to learn: What infants learn from watching | Dynamic time warping. Information retrieval for music and motion, pp | A survey on transfer learning | A preliminary study of transfer learning between unicycle robots | The mirror neuron system | Sim-to-real robot learning from pixels with progressive nets | Transfer learning via inter-task mappings for temporal difference learning | Transfer learning for reinforcement learning domains: A survey | Transferring instances for model-based reinforcement learning | MuJoCo: A physics engine for model-based control | Simultaneous deep transfer across domains and tasks | When pliers become fingers in the monkey motor system | Manifold alignment without correspondence | Distance metric learning, with application to clustering with side-information",iclr,010
332.pdf.json,,"The power of the human mind in inference and generalization rests on our brain’s ability to develop models of abstract knowledge of the natural world (Tenenbaum et al., 2011). When shown novel objects, both children and adults can rapidly generalize from just a few examples to classify and group them based on their perceptual similarity. Understanding the processes that give rise to perceptual similarity will provide insight into the development of abstract models in our brain. In this paper, we explored computational models for understanding the neural basis of human perceptual similarity judgment. Recent deep convolutional neural networks (DCNNs) have produced feature representations in the hidden layers that can match well with neural representations observed in the primate and human visual cortex. It was found that there is a strong correspondence between neural activities (neuronal spikes or fMRI signals) and the activities of the deep layers of deep networks (Agrawal et al., 2014; Khaligh-Razavi & Kriegeskorte, 2014; Yamins et al., 2014), suggesting that deep neural networks have in fact learned meaningful representations that are close to humans’, even though the neural networks are trained for object classification in computer vision. Cognitive neuroscientists have started to explore how the representations learned by deep networks can be used to model various aspects of human perception such as memorability of objects in images (Dubey et al., 2015), object typicality (Lake et al., 2015), and similarity judgment (Peterson et al., 2016; Kubilius et al., 2016). Certain correspondence between deep net representations and human experimental results are found. In particular, Peterson et al. (2016) found that human similarity judgment on a set of natural images might be similar to the feature representations in deep networks after some transformation. The DCNNs that neuroscientists and cognitive scientists have studied so far, such as AlexNet (Krizhevsky et al., 2","Pixels to voxels: modeling visual representation in the human brain | Understanding deep features with computer-generated imagery | Signature verification using a siamese time delay neural network | Shapenet: An information-rich 3d model repository | Learning a similarity metric discriminatively, with application to face verification | Histograms of oriented gradients for human detection | Imagenet: A large-scale hierarchical image database | Unsupervised visual representation learning by context prediction | Decaf: A deep convolutional activation feature for generic visual recognition | What makes an object memorable | Transfer of object shape knowledge across visual and haptic modalities | The amsterdam library of object images | Multi-view 3d object retrieval with deep embedding network | Dimensionality reduction by learning an invariant mapping | Caffe: Convolutional architecture for fast feature embedding | Large-scale video classification with convolutional neural networks | Deep Supervised, but Not Unsupervised, Models May Explain IT Cortical Representation | Deep neural networks as a computational model for human shape sensitivity | Human-level concept learning through probabilistic program induction | Joint embeddings of shapes and images via cnn image purification | Visualizing data using t-sne | Deep exemplar 2d-3d detection by adapting from real to rendered views | Spatial vs temporal continuity in view invariant visual object recognition learning | Adapting deep network features to capture psychological representations | Fine-grained visual categorization via multistage metric learning | Invariant visual representation by single neurons in the human brain | Single-view to multi-view: Reconstructing unseen views with a convolutional network | How to grow a mind: Statistics, structure, and abstraction | Learning fine-grained image similarity with deep ranking | Unsupervised learning of visual representations using videos | Slow Feature Analysis:nsupervised Learning of Invariances | Learning a probabilistic latent space of object shapes via 3d generative-adversarial modeling | Performanceoptimized hierarchical models predict neural responses in higher visual cortex | Multi-view self-supervised deep learning for 6d pose estimation in the amazon picking challenge | Flowweb: Joint image set alignment by weaving consistent, pixel-wise correspondences",iclr,010
333.pdf.json,WHAT DOES IT TAKE TO GENERATE NATURAL TEXTURES?,"During the last two years several different approaches towards natural image generation have been suggested, among them generative adversarial networks (Goodfellow et al., 2014; Chen et al., 2016), probabilistic generative models like the conditional PixelCNN (van den Oord et al., 2016b;a) or maximum entropy models that rely on the representations of deep neural networks (e.g. Gatys et al., 2015b; Johnson et al., 2016; Ulyanov et al., 2016). The latter approach has been particularly groundbreaking for artistic style transfer and natural texture generation (e.g. Gatys et al., 2015a;b) and has the potential to uncover the regularities that supervisedly trained deep neural networks infer from natural images. For the sake of clarity and concreteness, this paper will focus on natural texture synthesis. Parametric texture models aim to uniquely describe each texture by a set of statistical measurements that are taken over the spatial extent of the image. Each image with the same spatial summary statistics should be perceived as the same texture. Consequently, synthesizing a texture corresponds to finding a new image that reproduces the summary statistics inferred from the reference texture. Starting from Nth-order joint histograms of the pixels by Julesz (1962), many different statistical measures have been proposed (see e.g. Heeger & Bergen, 1995; Portilla & Simoncelli, 2000). The quality of the synthesized textures is usually determined by human inspection; the synthesis is successful if a human observer cannot tell the reference texture from the synthesized ones. The current state of the art in parametric texture modeling (Gatys et al., 2015a) employs the hierarchical image representation in a deep 19-layer convolutional network (Simonyan & Zisserman (2014); in the following referred to as VGG network) that was trained on object recognition in natural images(Russakovsky et al. (2015)). In this model textures are described by the raw correlations between feature activat","Reflectance modeling by neural texture synthesis | Incorporating long-range consistency in cnn-based texture generation | Audio texture synthesis with scattering moments | InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets | Texture synthesis using convolutional neural networks | A neural algorithm of artistic style | Understanding the difficulty of training deep feedforward neural networks | Generative Adversarial Networks | Pyramid-based texture analysis/synthesis | On the rationale of maximum-entropy methods | Perceptual losses for real-time style transfer and super-resolution | SciPy: Open source scientific tools for Python, 2001 | Visual pattern discrimination | Texture synthesis through convolutional neural networks and spectrum constraints | A parametric texture model based on joint statistics of complex wavelet coefficients | Efficient implementation of the k-svd algorithm using batch orthogonal matching pursuit | Very deep convolutional networks for large-scale image recognition | Texture Networks: Feedforward Synthesis of Textures and Stylized Images | Pixel Recurrent Neural Networks. ArXiv e-prints, January 2016a | Conditional Image Generation with PixelCNN Decoders | Image quality assessment: from error visibility to structural similarity | Minimax entropy principle and its application to texture modeling | Exploring texture ensembles by efficient markov chain monte carlo-toward a ’trichromacy’ theory of texture",iclr,010
334.pdf.json,EMERGENCE OF FOVEAL IMAGE SAMPLING FROM LEARNING TO ATTEND IN VISUAL SCENES,"A striking design feature of the primate retina is the manner in which images are spatially sampled by retinal ganglion cells. Sample spacing and receptive fields are smallest in the fovea and then increase linearly with eccentricity, as shown in Figure 1. Thus, we have highest spatial resolution at the center of fixation and lowest resolution in the periphery, with a gradual fall-off in resolution as one proceeds from the center to periphery. The question we attempt to address here is, why is the retina designed in this manner - i.e., how is it beneficial to vision? The commonly accepted explanation for this eccentricity dependent sampling is that it provides us with both high resolution and broad coverage of the visual field with a limited amount of neural resources. The human retina contains 1.5 million ganglion cells, whose axons form the sole output of the retina. These essentially constitute about 300,000 distinct samples of the image due to the multiplicity of cell types coding different aspects such as on vs. off channels (Van Essen & Anderson, 1995). If these were packed uniformly at highest resolution (120 samples/deg, the Nyquist-dictated sampling rate corresponding to the spatial-frequencies admitted by the lens), they would subtend an image area spanning just 5x5 deg2. Thus we would have high-resolution but essentially tunnel vision. Alternatively if they were spread out uniformly over the entire monocular visual field spanning roughly 150 deg2 we would have wide field of coverage but with very blurry vision, with each sample subtending 0.25 deg (which would make even the largest letters on a Snellen eye chart illegible). Thus, the primate solution makes intuitive sense as a way to achieve the best of both of these worlds. However we are still lacking a quantitative demonstration that such a sampling strategy emerges as the optimal design for subserving some set of visual tasks. Here, we explore what is the optimal retinal sampling lattice for an (overt","Multiple object recognition with visual attention | Neural machine translation by jointly learning to align and translate | Theano: new features and speed improvements | Topography of ganglion cells in human retina | Models of overt attention | Neural turing machines | Draw: A recurrent neural network for image generation | A saliency-based search mechanism for overt and covert shifts of visual attention | Spatial transformer networks | Adam: A method for stochastic optimization | Learning to combine foveal glimpses with a third-order boltzmann machine | The mnist database of handwritten digits | Recurrent models of visual attention | Retinal ganglion cells that project to the dorsal lateral geniculate nucleus in the macaque | Information processing strategies and pathways in the primate visual system | Show, attend and tell: Neural image caption generation with visual attention",iclr,010
335.pdf.json,NEURAL POPULATION INFOMAX,"How to discover the unknown structures in data is a key task for machine learning. Learning good representations from observed data is important because a clearer description may help reveal the underlying structures. Representation learning has drawn considerable attention in recent years (Bengio et al., 2013). One category of algorithms for unsupervised learning of representations is based on probabilistic models (Lewicki & Sejnowski, 2000; Hinton & Salakhutdinov, 2006; Lee et al., 2008), such as maximum likelihood (ML) estimation, maximum a posteriori (MAP) probability estimation, and related methods. Another category of algorithms is based on reconstruction error or generative criterion (Olshausen & Field, 1996; Aharon et al., 2006; Vincent et al., 2010; Mairal et al., 2010; Goodfellow et al., 2014), and the objective functions usually involve squared errors with additional constraints. Sometimes the reconstruction error or generative criterion may also have a probabilistic interpretation (Olshausen & Field, 1997; Vincent et al., 2010). Shannon’s information theory is a powerful tool for description of stochastic systems and could be utilized to provide a characterization for good representations (Vincent et al., 2010). However, computational difficulties associated with Shannon’s mutual information (MI) (Shannon, 1948) have hindered its wider applications. The Monte Carlo (MC) sampling (Yarrow et al., 2012) is a convergent method for estimating MI with arbitrary accuracy, but its computational inefficiency makes it unsuitable for difficult optimization problems especially in the cases of high-dimensional input stimuli and large population networks. Bell and Sejnowski (Bell & Sejnowski, 1995; 1997) have directly applied the infomax approach (Linsker, 1988) to independent component analysis (ICA) of data with independent non-Gaussian components assuming additive noise, but their method requires that the number of outputs be equal to the number of inputs. The exte","K-SVD: An algorithm for designing overcomplete dictionaries for sparse representation | Natural gradient learning for over- and under-complete bases in ica | Could information theory provide an ecological theory of sensory processing? Network: Comp | Possible principles underlying the transformation of sensory messages | An information-maximization approach to blind separation and blind deconvolution | The ”independent components” of natural scenes are edge filters | Deep learning of representations for unsupervised and transfer learning | Representation learning: A review and new perspectives | Greedy layer-wise training of deep networks | Information theory and neural coding | Structural uniformity of neocortex, revisited | An analysis of single-layer networks in unsupervised feature learning | Elements of Information, 2nd Edition | The geometry of algorithms with orthogonality constraints | Image denoising via sparse and redundant representations over learned dictionaries | Why does unsupervised pre-training help deep learning | Generative adversarial nets | A practical guide to training restricted boltzmann machines | A fast learning algorithm for deep belief nets | Reducing the dimensionality of data with neural networks | Information-theoretic bounds and approximations in neural population | Receptive fields, binocular interaction and functional architecture in the cat’s visual cortex | Fast and robust fixed-point algorithms for independent component analysis | Efficient coding of natural images with a population of noisy linear-nonlinear neurons | Statistical analysis of effective singular values in matrix rank determination | Dictionary learning algorithms for sparse representation | Gradient-based learning applied to document recognition | Efficient sparse coding algorithms. In Advances in neural information processing systems (pp. 801–808) | Sparse deep belief net model for visual area v2. In Advances in neural information processing systems (pp. 873–880) | Probabilistic framework for the adaptation and comparison of image codes | Learning overcomplete representations | Self-Organization in a perceptual network | Online dictionary learning for sparse coding | Online learning for matrix factorization and sparse coding | On the number of linear regions of deep neural networks | Rectified linear units improve restricted boltzmann machines | Emergence of simple-cell receptive field properties by learning a sparse code for natural | Sparse coding with an overcomplete basis set: A strategy employed by v1 | Information and accuracy attainable in the estimation of statistical parameters | A mathematical theory of communications | Dropout: A simple way to prevent neural networks from overfitting | presented a technique to randomly drop units from the neural network during training, which may in fact be regarded as an attempt to reduce the rank of the weight matrix because the dropout can result in a sparser weights (lower rank matrix)",iclr,010
336.pdf.json,OTHER MODIFICATIONS,"The PixelCNN, introduced by van den Oord et al. (2016b), is a generative model of images with a tractable likelihood. The model fully factorizes the probability density function on an image x over all its sub-pixels (color channels in a pixel) as p(x) = ∏ i p(xi|x<i). The conditional distributions p(xi|x<i) are parameterized by convolutional neural networks and all share parameters. The PixelCNN is a powerful model as the functional form of these conditionals is very flexible. In addition it is computationally efficient as all conditionals can be evaluated in parallel on a GPU for an observed image x. Thanks to these properties, the PixelCNN represents the current state-of-the-art in generative modeling when evaluated in terms of log-likelihood. Besides being used for modeling images, the PixelCNN model was recently extended to model audio (van den Oord et al., 2016a), video (Kalchbrenner et al., 2016b) and text (Kalchbrenner et al., 2016a). For use in our research, we developed our own internal implementation of PixelCNN and made a number of modifications to the base model to simplify its structure and improve its performance. We now release our implementation at https://github.com/openai/pixel-cnn, hoping that it will be useful to the broader community. Our modifications are discussed in Section 2, and evaluated experimentally in Section 3. State-of-the-art log-likelihood results confirm their usefulness.",Nice: Non-linear independent components estimation | Density estimation using real nvp | Who killed the directed model | Draw: A recurrent neural network for image generation | Towards conceptual compression | Neural machine translation in linear time | Video pixel networks | Auto-Encoding Variational Bayes | Improving variational inference with inverse autoregressive flow | Stochastic backpropagation and approximate inference in deep generative models | U-net: Convolutional networks for biomedical image segmentation | Deep unsupervised learning using nonequilibrium thermodynamics | Dropout: a simple way to prevent neural networks from overfitting | Generative image modeling using spatial lstms | Mixtures of conditional gaussian scale mixtures applied to multiscale image representations | Rnade: The real-valued neural autoregressive density-estimator | Locally-connected transformations for deep gmms | Wavenet: A generative model for raw audio | Pixel recurrent neural networks | Conditional image generation with pixelcnn decoders | Wide residual networks,iclr,010
338.pdf.json,UNROLLED ITERATIVE ESTIMATION,,"Multi-Residual Networks | Deep Learning Methods and Applications | Deep Learning. Book in preparation for | Deep Residual Learning for Image Recognition | Identity Mappings in Deep Residual Networks | Untersuchungen zu dynamischen neuronalen Netzen | Long short-term memory | Densely Connected Convolutional Networks. arXiv:1608.06993 [cs], August 2016a | Deep Networks with Stochastic Depth | Receptive fields, binocular interaction and functional architecture in the cat’s visual cortex | Exploring the limits of language modeling | Character-aware neural language models | Fully Character-Level Neural Machine Translation without Explicit Segmentation | Bridging the Gaps Between Residual Learning, Recurrent Neural Networks and Visual Cortex | Small-footprint Deep Neural Networks with Highway Connections for Speech Recognition | Deep learning in neural networks: An overview | Striving for Simplicity: The All Convolutional Net | Training Very Deep Networks | Highway Networks. arXiv:1505.00387 [cs], May 2015b | Inception-v4, InceptionResNet and the Impact of Residual Connections on Learning | Residual Networks are Exponential Ensembles of Relatively Shallow Networks | Visualizing and understanding convolutional networks | Recurrent Highway Networks",iclr,010
339.pdf.json,IMPROVING NEURAL LANGUAGE MODELS WITH A CONTINUOUS CACHE,"Language models, which are probability distributions over sequences of words, have many applications such as machine translation (Brown et al., 1993), speech recognition (Bahl et al., 1983) or dialogue agents (Stolcke et al., 2000). While traditional neural networks language models have obtained state-of-the-art performance in this domain (Jozefowicz et al., 2016; Mikolov et al., 2010), they lack the capacity to adapt to their recent history, limiting their application to dynamic environments (Dodge et al., 2015). A recent approach to solve this problem is to augment these networks with an external memory (Graves et al., 2014; Grefenstette et al., 2015; Joulin & Mikolov, 2015; Sukhbaatar et al., 2015). These models can potentially use their external memory to store new information and adapt to a changing environment. While these networks have obtained promising results on language modeling datasets (Sukhbaatar et al., 2015), they are quite computationally expensive. Typically, they have to learn a parametrizable mechanism to read or write to memory cells (Graves et al., 2014; Joulin & Mikolov, 2015). This may limit both the size of their usable memory as well as the quantity of data they can be trained on. In this work, we propose a very light-weight alternative that shares some of the properties of memory augmented networks, notably the capability to dynamically adapt over time. By minimizing the computation burden of the memory, we are able to use larger memory and scale to bigger datasets. We observe in practice that this allows us to surpass the perfomance of memory augmented networks on different language modeling tasks. Our model share some similarities with a model proposed by Kuhn (1988), called the cache model. A cache model stores a simple representation of the recent past, often in the form of unigrams, and uses them for prediction (Kuhn & De Mori, 1990). This contextual information is quite cheap to store and can be accessed efficiently. It also does not","Neural machine translation by jointly learning to align and translate | A maximum likelihood approach to continuous speech recognition | Exploiting latent semantic information in statistical language modeling | A neural probabilistic language model | The mathematics of statistical machine translation: Parameter estimation | A thorough examination of the cnn/daily mail reading comprehension | Empirical evaluation of gated recurrent neural networks on sequence modeling | Towards better integration of semantic predictors in statistical language modeling | Adaptive language modeling using minimum discriminant estimation | Evaluating prerequisite qualities for learning end-to-end dialog systems | Adaptive subgradient methods for online learning and stochastic optimization | Finding structure in time | A theoretically grounded application of dropout in recurrent neural networks | A bit of progress in language modeling | Efficient softmax approximation for gpus | Speech recognition with deep recurrent neural networks | Neural turing machines | Learning to transduce with unbounded memory | Pointing the unknown words | Teaching machines to read and comprehend | Long short-term memory | Modeling long distance dependence in language: Topic mixtures versus dynamic cache models | A dynamic language model for speech recognition | Inferring algorithmic patterns with stack-augmented recurrent nets | Exploring the limits of language modeling | Text understanding with the attention sum reader network | Estimation of probabilities from sparse data for the language model component of a speech recognizer | Maximum entropy techniques for exploiting syntactic, semantic and collocational dependencies in language modeling | Improved backing-off for m-gram language modeling | On the dynamic adaptation of stochastic language models | Speech recognition and the frequency of recently used words: A modified markov model for natural language | A cache-based natural language model for speech recognition | Probabilistic models of short and long distance word dependencies in running text | Trigger-based language models: A maximum entropy approach | Building a large annotated corpus of english: The penn treebank | Pointer sentinel mixture models | Context dependent recurrent neural network language model | Recurrent neural network based language model | Empirical evaluation and combination of advanced language modeling techniques | Learning longer memory in recurrent neural networks | The lambada dataset: Word prediction requiring a broad discourse context | A maximum entropy approach to adaptive statistical language modeling | Dialogue act modeling for automatic tagging and recognition of conversational speech | End-to-end memory networks | Larger-context language modelling | Backpropagation through time: what it does and how to do | An efficient gradient-based algorithm for on-line training of recurrent network trajectories | Recurrent neural network regularization | Recurrent highway networks",iclr,010
340.pdf.json,,"Humans excel in tasks that require making analogies between distinct domains, transferring elements from one domain to another, and using these capabilities in order to blend concepts that originated from multiple source domains. Our experience tells us that these remarkable capabilities are developed with very little, if any, supervision that is given in the form of explicit analogies. Recent achievements replicate some of these capabilities to some degree: Generative Adversarial Networks (GANs) are able to convincingly generate novel samples that match that of a given training set; style transfer methods are able to alter the visual style of images; domain adaptation methods are able to generalize learned functions to new domains even without labeled samples in the target domain and transfer learning is now commonly used to import existing knowledge and to make learning much more efficient. These capabilities, however, do not address the general analogy synthesis problem that we tackle in this work. Namely, given separated but otherwise unlabeled samples from domains S and T and a perceptual function f , learn a mapping G : S → T such that f(x) ∼ f(G(x)). In order to solve this problem, we make use of deep neural networks of a specific structure in which the function G is a composition of the input function f and a learned function g. A compound loss that integrates multiple terms is used. One term is a Generative Adversarial Network (GAN) term that encourages the creation of samples G(x) that are indistinguishable from the training samples of the target domain, regardless of x ∈ S or x ∈ T . The second loss term enforces that for every x in the source domain training set, ||f(x)− f(G(x))|| is small. The third loss term is a regularizer that encourages G to be the identity mapping for all x ∈ T . The type of problems we focus on in our experiments are visual, although our methods are not limited to visual or even to perceptual tasks. Typically, f would be a neural",Analysis of representations for domain adaptation | Neural photo editing with introspective adversarial networks | Marginalized denoising autoencoders for domain adaptation | Image super-resolution using deep convolutional networks | Generating images with perceptual similarity metrics based on deep | The Way We Think: Conceptual Blending and the Mind’s Hidden Complexities | Unsupervised visual domain adaptation using subspace alignment | Domain-adversarial training of neural networks | Image style transfer using convolutional neural networks | Generative adversarial nets | Perceptual losses for real-time style transfer and super-resolution | Adam: A method for stochastic optimization | State of the “art”: A taxonomy of artistic stylization techniques for images and video | URL http://yann | Understanding deep image representations by inverting them | Conditional generative adversarial nets | Reading digits in natural images with unsupervised feature learning | A data-driven approach to cleaning large face datasets | Deep face recognition | Unsupervised representation learning with deep convolutional generative adversarial networks | Generative adversarial text to image synthesis | Nonlinear total variation based noise removal algorithms | Improved techniques for training gans | Deepface: Closing the gap to human-level performance in face verification | Texture networks: Feed-forward synthesis of textures and stylized images | From facial parts responses to face detection: A deep learning approach | Inverting face embeddings with convolutional neural networks,iclr,010
341.pdf.json,THIRD-PERSON IMITATION LEARNING,"Reinforcement learning (RL) is a framework for training agents to maximize rewards in large, unknown, stochastic environments. In recent years, combining techniques from deep learning with reinforcement learning has yielded a string of successful applications in game playing and robotics Mnih et al. (2015; 2016); Schulman et al. (2015a); Levine et al. (2016). These successful applications, and the speed at which the abilities of RL algorithms have been increasing, makes it an exciting area of research with significant potential for future applications. One of the major weaknesses of RL is the need to manually specify a reward function. For each task we wish our agent to accomplish, we must provide it with a reward function whose maximizer will precisely recover the desired behavior. This weakness is addressed by the field of Inverse Reinforcement Learning (IRL). Given a set of expert trajectories, IRL algorithms produce a reward function under which these the expert trajectories enjoy the property of optimality. Recently, there has been a significant amount of work on IRL, and current algorithms can infer a reward function from a very modest number of demonstrations (e.g,. Abbeel & Ng (2004); Ratliff et al. (2006); Ziebart et al. (2008); Levine et al. (2011); Ho & Ermon (2016); Finn et al. (2016)). While IRL algorithms are appealing, they impose the somewhat unrealistic requirement that the demonstrations should be provided from the first-person point of view with respect to the agent. Human beings learn to imitate entirely from third-person demonstrations – i.e., by observing other humans achieve goals. Indeed, in many situations, first-person demonstrations are outright impossible to obtain. Meanwhile, third-person demonstrations are often relatively easy to obtain. The goal of this paper is to develop an algorithm for third-person imitation learning. Future advancements in this class of algorithms would significantly improve the state of robotics, because it will","Apprenticeship learning via inverse reinforcement learning | Autonomous helicopter aerobatics through apprenticeship learning | A survey of robot learning from demonstration | Tabula rasa: Model transfer for object category detection | Kernelized infomax clustering | Relative entropy inverse reinforcement learning | Unsupervised classifiers, mutual information and phantom targets | Signature verification using a siamese time delay neural network | Robot programming by demonstration | On learning, representing, and generalizing a task in a humanoid robot | Understanding prior intentions enables two–year–olds to imitatively learn a complex task | Infogan: Interpretable representation learning by information maximizing generative adversarial nets | Learning a similarity metric discriminatively, with application to face verification | Direct loss minimization inverse optimal control | Decaf: A deep convolutional activation feature for generic visual recognition | Learning with augmented features for heterogeneous domain adaptation | Guided cost learning: Deep inverse optimal control via policy optimization | Unsupervised domain adaptation by backpropagation | An object-based approach to map human hand synergies onto robotic hands with dissimilar kinematics | Generative adversarial nets | Learning dexterous manipulation for a soft robotic hand from human demonstration | Generative adversarial imitation learning | Efficient learning of domain-invariant image representations | Learning objective functions for manipulation | Adam: A method for stochastic optimization | Discriminative clustering by regularized information maximization | What you saw is not what you get: Domain adaptation using asymmetric kernel transforms | Nonlinear inverse reinforcement learning with gaussian processes | End-to-end training of deep visuomotor policies | Learning transferable features with deep adaptation networks | Domain adaptation: Learning bounds and algorithms | Human-level control through deep reinforcement learning | Asynchronous methods for deep reinforcement learning | Nine billion correspondence problems. Imitation and Social Learning in Robots, Humans and Animals: Behavioural, Social and Communicative Dimensions | Like me?-measures of correspondence and imitation | Algorithms for inverse reinforcement learning | Alvinn: An autonomous land vehicle in a neural network | Bayesian inverse reinforcement learning | Maximum margin planning | Boosting structured prediction for imitation learning | A reduction of imitation learning and structured prediction to no-regret online learning | Is imitation learning the route to humanoid robots | Trust region policy optimization | Highdimensional continuous control using generalized advantage estimation | Learning shared latent structure for image synthesis and robotic imitation | Deep domain confusion: Maximizing for domain invariance | Towards adapting deep visuomotor representations from simulated to real environments | Maximum entropy deep inverse reinforcement learning | Maximum entropy inverse reinforcement learning",iclr,010
342.pdf.json,VARIATIONAL RECURRENT ADVERSARIAL DEEP DOMAIN ADAPTATION,"Many real-world applications require effective machine learning algorithms that can learn invariant representations across related time-series datasets. For example, precision medicine for patients of various age groups, mobile application recommendation for users based on locations, and so on. In these examples, while the domains (i.e. age group and location) may vary, there exist common predictive patterns that can aid in inferring knowledge from one domain to another. More often than not, some domains have a significantly larger number of observations than others (e.g., respiratory failure in adults vs. children). Therefore effective domain adaption of time-series data is in great demand. The general approach to tackling domain adaptation has been explored under many facets which include reducing the domain discrepancy between the source and target domains(Ben-David et al. (2007)), instance re-weighting (Jiang & Zhai (2007)), subspace alignment (Fernando et al. (2013)), and deep learning (Tzeng et al. (2015); Ganin & Lempitsky (2014)). Many of these approaches work very well for non-sequential data but are not suitable for multivariate time-series data as they do not usually capture the temporal dependencies present in the data. For sequential data, earlier work has successfully used dynamic Bayesian Networks(Huang & Yates (2009)) and Recurrent Neural Networks (Socher et al. (2011)) to learn latent feature representations which were domaininvariant. Unfortunately, these works were not flexible enough to model non-linear dynamics or did not explicitly capture and transfer the complex latent dependencies needed to perform domain adaptation of time-series data. In this paper, we address this problem with a model that learns temporal latent dependencies (i.e. dependencies between the latent variables across timesteps) that can be transferred across domains that experience different distributions in their features. We draw inspiration from the Variational Recurrent Ne","The lifetime distribution of health care costs | Analysis of representations for domain adaptation | A theory of learning from different domains | Domain adaptation of natural language processing systems | Marginalized denoising autoencoders for domain adaptation | A Recurrent Latent Variable Model for Sequential Data | Unsupervised visual domain adaptation using subspace alignment | Discriminative instance weighting for domain adaptation in statistical machine translation | Unsupervised domain adaptation by backpropagation | Domain-adversarial training of neural networks | Geodesic flow kernel for unsupervised domain adaptation | Deep Learning | Long short-term memory | Distributional representations for handling sparsity in supervised sequence-labeling | A literature survey on domain adaptation of statistical classifiers | Instance weighting for domain adaptation in nlp | Mimic-iii, a freely accessible critical care database | Effect of tidal volume in children with acute hypoxemic respiratory failure | Adam: A method for stochastic optimization | Auto-Encoding Variational Bayes | Morphological classification of brains via high-dimensional shape transformations and machine learning methods | Learning transferable features with deep adaptation networks | The variational fair auto encoder | A Survey on Transfer Learning | Visual domain adaptation: A survey of recent advances | Adapting visual category models to new domains | A longitudinal study of the effects of age and time to death on hospital costs | Parsing natural scenes and natural language with recursive neural networks | Simultaneous deep transfer across domains and tasks",iclr,010
343.pdf.json,PROGRAM SYNTHESIS FOR CHARACTER LEVEL LANGUAGE MODELING,"Recent years have shown increased interest in learning from large datasets in order to make accurate predictions on important tasks. A significant catalyst for this movement has been the ground breaking precision improvements on a number of cognitive tasks achieved via deep neural networks. Deep neural networks have made substantial inroads in areas such as image recognition (Krizhevsky et al., 2012) and natural language processing (Józefowicz et al., 2016) thanks to large datasets, deeper networks (He et al., 2016) and substantial investments in computational power Oh & Jung (2004). While neural networks remain a practical choice for many applications, they have been less effective when used for more structured tasks such as those concerning predictions about programs (Allamanis et al., 2016; Raychev et al., 2014). Initially targeting the programming languages domain, a new method for synthesizing probabilistic models proposed by Bielik et al. (2016), without a neural network, has shown to be effective for modeling source code, and has gained traction. In this work, we investigate the applicability of this new method to tasks which have so far been addressed with recurrent neural networks and n-gram language models. The probabilistic models we propose are defined by a program from a domain-specific language (DSL). A program in this DSL describes a probabilistic model such as n-gram language models or a variant of it - e.g. trained on subsets of the training data, queried only when certain conditions are met and specialized in making specific classes of predictions. These programs can also be combined to produce one large program that queries different specialized submodels depending on the context of the query. For example, consider predicting the characters in an English text. Typically, the first character of a word is much more difficult to predict than other characters and thus we would like to predict it differently. Let f be a function that takes a predictio",A convolutional attention network for extreme summarization of source code | Syntaxguided synthesis | Neural machine translation by jointly learning to align and translate | A neural probabilistic language model | PHOG: probabilistic model for code | An empirical study of smoothing techniques for language modeling | Hierarchical multiscale recurrent neural networks | Equilibrated adaptive learning rates for nonconvex optimization | Generating sequences with recurrent neural networks | Dimensions in program synthesis | Deep residual learning for image recognition | Mimic: Computing models for opaque code | Long short-term memory | Approximation capabilities of multilayer feedforward networks | The human knowledge compression contest | Oracle-guided component-based program synthesis | Exploring the limits of language modeling | Visualizing and understanding recurrent networks | Character-aware neural language models | Improved backing-off for m-gram language modeling | Imagenet classification with deep convolutional neural networks | A cache-based natural language model for speech recognition | Visualizing and understanding neural models in NLP | Subword language modeling with neural networks | Code completion with statistical language models | Probabilistic model for code with decision trees | Learning programs from noisy data | Combinatorial sketching for finite programs | End-to-end memory networks | Generating text with recurrent neural networks | A hierarchical bayesian language model based on pitman-yor processes | The zero-frequency problem: Estimating the probabilities of novel events in adaptive text compression | On multiplicative integration with recurrent neural networks,iclr,010
344.pdf.json,,"StarCraft1 is a real-time strategy (RTS) game in which each player must build an army and control individual units to destroy the opponent’s army. As of today, StarCraft is considered one of the most difficult games for computers, and the best bots only reach the level of high amateur human players (Churchill, 2015). The main difficulty comes from the need to control a large number of units in partially observable environment, with very large state and action spaces: for example, in a typical game, there are at least 101685 possible states whereas the game of Go has about 10170 states. Because of simultaneous and durative actions, StarCraft provides an ideal environment to study the control of many agents at large scale, and an opportunity to define tasks of increasing difficulty, from micromanagement, which concerns the short-term, low-level control of fighting units during battles, to long-term strategic and hierarchical planning under uncertainty. While building a controller for the full game based on machine learning is out-of-reach with current methods, we propose, as a first step, to study reinforcement learning (RL) algorithms in micromanagement scenarios in StarCraft. Both the work on Atari games (Mnih et al., 2013) and the recent Minecraft scenarios studied by researchers (Abel et al., 2016; Oh et al., 2016) focus on the control of a single agent, with a fixed, limited set of actions. Coherently controlling multiple agents (units) is the main challenge of reinforcement learning for micromanagement tasks. This comes with two main challenges. The first one is to efficiently explore the large action space. The implementation of a coherent strategy requires the units to take actions that depend on each other, but it also implies that any small alteration of a strategy must be maintained for a sufficiently long time to properly evaluate the long-term effect of that change. In contrast to this requirement of consistency in exploration, the reinforcement learning ","Exploratory gradient boosting for reinforcement learning in complex domains | Neuronlike adaptive elements that can solve difficult learning control problems | The complexity of decentralized control of markov decision processes | A comprehensive survey of multiagent reinforcement learning | aiide starcraft ai competition report | Fast heuristic search for rts game combat scenarios | Fast and accurate deep network learning by exponential linear units (elus) | Torch7: A matlab-like environment for machine learning | A survey on policy search for robotics | Adaptive subgradient methods for online learning and stochastic optimization | Optimal rates for zero-order convex optimization: the power of two function evaluations | Exploration exploitation in go: Uct for monte-carlo go | Stochastic first-and zeroth-order methods for nonconvex stochastic programming | Hierarchical multi-agent reinforcement learning | Deep reinforcement learning in parameterized action space | Multiagent reinforcement learning: theoretical framework and an algorithm | Stochastic estimation of the maximum of a regression function | Markov games as a framework for multi-agent reinforcement learning | Evolving effective micro behaviors in rts game | Structured prediction with reinforcement learning | The cross entropy method for fast policy search | Concurrent hierarchical reinforcement learning | Playing atari with deep reinforcement learning | Human-level control through deep reinforcement learning | Problem complexity and method efficiency in optimization | Control of memory, active perception, and action in minecraft | A survey of real-time strategy game ai research and competition in starcraft | Deep exploration via bootstrapped dqn | Generalization and exploration via randomized value functions | Policy gradients with parameter-based exploration for control | Parameter-exploring policy gradients | Deterministic policy gradient algorithms | Mastering the game of go with deep neural networks and tree | A one-measurement form of simultaneous perturbation stochastic approximation | Team-partitioned, opaque-transition reinforcement learning | Learning multiagent communication with backpropagation | Learning to predict by the methods of temporal differences | Reinforcement learning: An introduction | Policy gradient methods for reinforcement learning with function approximation | A bayesian model for rts units control applied to starcraft | Torchcraft: a library for machine learning research on real-time strategy games | Learning tetris using the noisy cross-entropy method | Multi-agent reinforcement learning: Independent vs. cooperative agents | Temporal difference learning and td-gammon | Extending q-learning to general adaptive multi-agent systems | On the likelihood that one unknown probability exceeds another in view of the evidence of two samples | Lecture 6.5—RmsProp: Divide the gradient by a running average of its recent magnitude | Deep reinforcement learning with double q-learning | Applying reinforcement learning to small scale combat in the real-time strategy game starcraft: broodwar | Simple statistical gradient-following algorithms for connectionist reinforcement learning",iclr,010
345.pdf.json,NEURAL NETWORK COMPRESSION,"”Bigger is better” is the ruling maxim in deep learning land. Deep neural nets with billions of parameters are no longer an exception. Networks of such size are unfortunately not practical for mobile, on-device applications which face strong limitations with respect to memory and energy consumption. Compressing neural networks could not only improve memory and energy consumption, but also lead to less network bandwidth, faster processing and better privacy. It has been shown that large networks are heavily over-parametrized and can be compressed by approximately two orders of magnitude without significant loss of accuracy. Apparently, over-parametrization is beneficial for optimization, but not necessary for accurate prediction. This observation has opened the door for a number of highly successful compression algorithms, which either train the network from scratch (Hinton et al., 2015; Iandola et al., 2016; Courbariaux & Bengio, 2016; Courbariaux et al., 2016) or apply compression post-optimization (Han et al., 2015b;a; Guo et al., 2016; Chen et al., 2015; Wen et al., 2016). It has been long known that compression is directly related to (variational) Bayesian inference and the minimum description principle (Hinton & Van Camp, 1993). One can show that good compression can be achieved by encoding the parameters of a model using a good prior and specifying the parameters up to an uncertainty given, optimally, by the posterior distribution. An ingenious bitsback argument can then be used to get a refund for using these noisy weights. A number of papers have appeared that encode the weights of a neural network with limited precision (say 8 bits per weight), effectively cashing in on this ”bits-back” argument (Gupta et al., 2015; Courbariaux et al., 2014; Venkatesh et al., 2016). Some authors go so far of arguing that even a single bit per weight can be used without much loss of accuracy (Courbariaux et al., 2015; Courbariaux & Bengio, 2016). In this work we follow a dif","Multiresolution mixture modeling using merging of mixture components | Pattern recognition | Compressing convolutional neural networks | Binarynet: Training deep neural networks with weights and activations constrained to +1 or −1 | Training deep neural networks with low precision multiplications | Binaryconnect: Training deep neural networks with binary weights during propagations | Binarized neural networks: Training neural networks with weights and activations constrained to +1 or | Predicting parameters in deep learning | Exploiting linear structure within convolutional networks for efficient evaluation | Compressing deep convolutional networks using vector quantization | Practical variational inference for neural networks | Dynamic network surgery for efficient dnns | Deep learning with limited numerical precision | Deep compression: Compressing deep neural network with pruning, trained quantization and huffman coding | Learning both weights and connections for efficient neural networks | Deep residual learning for image recognition | Identity mappings in deep residual networks | Distilling the knowledge in a neural network | Keeping the neural networks simple by minimizing the description length of the weights | Variational learning and bits-back coding: an informationtheoretic view to bayesian learning | Squeezenet: Alexnet-level accuracy with 50x fewer parameters and¡ 1mb model size | Training cnns with low-rank filters for efficient image classification | Speeding up convolutional neural networks with low rank expansions | Adam: A method for stochastic optimization | Optimal brain damage | Gradient-based learning applied to document recognition | Fixed point quantization of deep convolutional networks | Sparse convolutional neural networks | Deep neural networks are robust to weight binarization and other non-linear distortions | Variational dropout sparsifies deep neural networks | Simplifying neural networks by soft weight-sharing | Modeling by shortest data | Stochastic complexity and modeling | A stochastic approximation method | Practical bayesian optimization of machine learning algorithms | Convolutional neural networks with low-rank regularization | Accelerating deep convolutional networks using low-precision and sparsity | Classification by minimum-message-length inference | Learning structured sparsity in deep neural networks | Arithmetic coding for data compression | Quantized convolutional neural networks for mobile devices | Wide residual networks | 2015a) propose p = 5 for fully connected layers and p = 8 for convolutional layers. An illustration of the process can is shown in Fig. 4. Furthermore, the indexes will be compressed Hoffman encoding. A.3 STORING THE WEIGHT ARRAY A In order to minimize the storage occupied by A. We quantize the values of A. Storing indexes | B CONFIGURING THE HYPER-PRIORS B.1 GAMMA DISTRIBUTION The Gamma distribution is the conjugate prior for the precision of a univariate Gaussian distribution. It is defined for positive random variables λ",iclr,010
348.pdf.json,,"Much of the recent progress in computer vision can be attributed to the availability of large labelled datasets and deep neural networks capable of absorbing large amounts of information. While many practical problems can now be solved, the requirement for big (labelled) data is a fundamentally unsatisfactory state of affairs. Human beings are able to learn new concepts with very few labels, and reproducing this ability is an important challenge for artificial intelligence research. From an applied perspective, improving the statistical efficiency of deep learning is vital because in many domains (e.g. medical image analysis), acquiring large amounts of labelled data is costly. To improve the statistical efficiency of machine learning methods, many have sought to learn invariant representations. In deep learning, however, intermediate layers should not be invariant, because the relative pose of local features must be preserved for further layers (Cohen & Welling, 2016; Hinton et al., 2011). Thus, one is led to the idea of equivariance: a network is equivariant if the representations it produces transform in a predictable way under transformations of the input. In other words, equivariant networks produce representations that are steerable. Steerability makes it possible to apply filters not just in every position (as in a standard convolution layer), but in every pose, thus allowing for increased parameter sharing. Previous work has shown that equivariant CNNs yield state of the art results on classification tasks (Cohen & Welling, 2016; Dieleman et al., 2016), even though they only enforce equivariance to small groups of transformations like rotations by multiples of 90 degrees. Learning representations that are equivariant to larger groups is likely to result in further gains, but the computational cost of current methods scales linearly with the size of the group, making this impractical. In this paper we present the general theory of steerable CNNs, which covers","Unsupervised learning of invariant representations with low sample complexity: the magic of sensory cortex or a new framework for machine learning | Strongly-Typed Recurrent Neural Networks | Learning Transformation Groups and their Invariants | Learning the Irreducible Representations of Commutative Lie Groups | Group equivariant convolutional networks | Rotation-invariant convolutional neural networks for galaxy morphology prediction | Exploiting Cyclic Symmetry in Convolutional Neural Networks | A Course in Abstract Harmonic Analysis | The design and use of steerable filters | Deep Symmetry Networks | Overcomplete Steerable Pyramid Filters and Rotation Invariance | Deep Residual Learning for Image Recognition | Identity Mappings in Deep Residual Networks | Transforming auto-encoders | Densely Connected Convolutional Networks. 2016 | Structured Receptive Fields in CNNs | Group-Theoretical Methods in Image Understanding | Locally Scale-invariant Convolutional Neural Network | Induced Representations of Locally Compact Groups | Receptive field families | A Unified Theory for Steerable and Quadrature Filters. Communications in Computer and Information Science, 4 CCIS:201–214 | Learning Multiple Layers of Features from Tiny Images | Understanding image representations by measuring their equivariance and equivalence | Group-theoretical model of feature extraction | Induced Representations of Locally Compact Groups I | Induced Representations of Locally Compact Groups II. The Frobenius Reciprocity Theorem | Induced Representations of Groups and Quantum Mechanics | Group Invariant Scattering | Learning rotation invariant convolutional filters for texture classification | Neural Networks, Types, and Functional Programming | Deep Roto-Translation Scattering for Object Classification | Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks | Semi-supervised learning with Ladder Networks | Notes on representations of finite groups, 2014 | Linear Representations of Finite Groups | Understanding and Improving Convolutional Neural Networks via Concatenated Rectified Linear Units | Rotation, Scaling and Deformation Invariant Scattering for Texture Discrimination | The steerable pyramid: a flexible architecture for multi-scale derivative computation | Spherical Tensor Algebra for Biomedical Image Analysis | Noncommutative Harmonic Analysis | Theory and Applications of Steerable Functions | Optimizing Neural Networks that Generate Images | Chainer: a Next-Generation Open Source Framework for Deep Learning | The classical groups: their invariants and representations | 2016)) are a special kind of steerable CNN. Specifically, a G-CNN is a steerable CNN with regular capsules. In a G-CNN, the feature maps (except those of the input) are thought of as functions f : G → R instead of functions on the plane f : Z → R",iclr,010
349.pdf.json,"Learning to Query, Reason, and Answer Questions On Ambiguous Texts","In recent years, deep neural networks have demonstrated impressive performance on a variety of natural language tasks such as language modeling (Mikolov et al. (2010); Sutskever et al. (2011)), image captioning (Vinyals et al. (2015); Xu et al. (2015)), and machine translation (Sutskever et al. (2014); Cho et al. (2014); Bahdanau et al. (2015)). Encouraged by these results, machine learning researchers are now tackling a variety of even more challenging tasks such as reasoning and dialog. One such recent effort is the so-called “bAbI” problems of Weston et al. (2016). In these problems, the agent is presented with a short story and a challenge question that tests its ability to reason about the events in the story. The stories require the agent to learn unstated constraints, but are otherwise self-contained, ∗The first three authors contributed equally. requiring no interaction between the agent and the environment. A very recent extension of this work (Weston (2016)) adds interaction by allowing the agent to respond in various ways to a teacher’s questions. There has also been significant recent interest in learning task-oriented dialog systems such as by Bordes & Weston (2016); Dodge et al. (2016); Williams & Zweig (2016); Henderson et al. (2014); Young et al. (2013). Here the agent is trained to help a user complete a task such as finding a suitable restaurant or movie. These tasks are typically modeled as slot-filling problems in which the agent knows about “slots”, or attributes relevant to the task, and must determine which of the required slot values have been provided, querying the user for the others. The reasoning required to decide on an action in these systems is primarily in determining which slot values the user has provided and which ones are required but still unknown to the agent. Realistic task-oriented dialog, however may require logical reasoning both to minimize irrelevant questions to the user and to focus the inquiry on questions most helpful ","Neural machine translation by jointly learning to align and translate | Learning end-to-end goal-oriented dialog | Towards understanding situated natural language | Learning phrase representations using rnn encoder–decoder for statistical machine translation | Evaluating prerequisite qualities for learning end-to-end dialog systems | Word-based dialog state tracking with recurrent neural networks | Improved deep learning baselines for ubuntu corpus dialogs | Adam: A method for stochastic optimization | Ask me anything: Dynamic memory networks for natural language processing | The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems | Recurrent neural network based language model | Language understanding for text-based games using deep reinforcement learning | Building end-to-end dialogue systems using generative hierarchical neural network models | Neural responding machine for short-text conversation | Learning from real users: Rating dialogue success with neural networks for reinforcement learning in spoken dialogue systems | Reward shaping with recurrent neural networks for speeding up on-line policy learning in spoken dialogue systems | End-to-end memory networks | Generating text with recurrent neural networks | Sequence to sequence learning with neural networks | A neural conversational model | Show and Tell: A neural image caption generator | The optimal reward baseline for gradient-based reinforcement learning | A network-based end-to-end trainable task-oriented dialogue system, 2016",iclr,010
350.pdf.json,,"Many of the most successful current deep learning architectures for vision rely on supervised learning from large sets of labeled training images. While the performance of these networks is undoubtedly impressive, reliance on such large numbers of training examples limits the utility of deep learning in many domains where such datasets are not available. Furthermore, the need for large numbers of labeled examples stands at odds with human visual learning, where one or a few views of an object is often all that is needed to enable robust recognition of that object across a wide range of different views, lightings and contexts. The development of a representation that facilitates such abilities, especially in an unsupervised way, is a largely unsolved problem. In addition, while computer vision models are typically trained using static images, in the real world, visual objects are rarely experienced as disjoint snapshots. Instead, the visual world is alive with movement, driven both by self-motion of the viewer and the movement of objects within the scene. Many have suggested that temporal experience with objects as they move and undergo transformations can serve as an important signal for learning about the structure of objects (Földiák, 1991; Softky, 1996; Wiskott & Sejnowski, 2002; George & Hawkins, 2005; Palm, 2012; O’Reilly et al., 2014; Agrawal et al., 2015; Goroshin et al., 2015a; Lotter et al., 2015; Mathieu et al., 2016; Srivastava et al., 2015; Wang & Gupta, 2015; Whitney et al., 2016). For instance, Wiskott and Sejnowski proposed “slow feature analysis” as a framework for exploiting temporal structure in video streams (Wiskott & Sejnowski, 2002). Their approach attempts to build feature representations that extract Code and video examples can be found at: https://coxlab.github.io/prednet/ slowly-varying parameters, such as object identity, from parameters that produce fast changes in the image, such as movement of the object. While approaches that rely on","Learning to see by moving | Canonical microcircuits for predictive coding | Scheduled sampling for sequence prediction with recurrent neural networks | How auto-encoders could provide credit assignment in deep networks via target propagation | End to end learning for self-driving cars | Dynamic filter networks | Deep predictive coding | Comma.ai, 2016. URL http://keras.io | Whatever next? predictive brains, situated agents, and the future of cognitive science | Pedestrian detection: A benchmark | Expectation and surprise determine neural population responses in the ventral visual stream | Unsupervised learning for physical interaction through video prediction | Learning invariance from transformation sequences | A theory of cortical responses | Vision meets robotics: The kitti dataset | A hierarchical bayesian model of invariant pattern recognition in the visual cortex | Generative adversarial nets | Unsupervised learning of spatiotemporally coherent metrics | Learning to linearize under uncertainty | Long short-term memory | Human3.6m: Large scale datasets and predictive methods for 3d human sensing in natural environments | What is the best multistage architecture for object recognition | Cerebral hierarchies : predictive processing , precision and the pulvinar | Adam: A method for stochastic optimization | Deep convolutional inverse graphics | Hierarchical bayesian inference in the visual cortex | Unsupervised learning of visual structure using predictive generative networks | Semi-supervised tuning from temporal coherence | Deep multi-scale video prediction beyond mean square error | Modeling deep temporal dependencies with recurrent ”grammar cells | Deep learning from temporal coherence in video | Actionconditional video prediction using deep networks in atari | Learning through time in the thalamocortical loops | Prediction as a candidate for learning deep hierarchical models of data | Spatio-temporal video autoencoder with differentiable memory | Deconstructing the ladder network | A high-throughput screening approach to discovering good forms of biologically inspired visual representation | Video (language) modeling: a baseline for generative models of natural videos | Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects | Predictive sequence learning in recurrent neocortical circuits | Semisupervised learning with ladder | Learning a driving simulator | On random weights and unsupervised feature learning | Convolutional LSTM network: A machine learning approach for precipitation nowcasting | Unsupervised learning of generative and discriminative weights encoding elementary image components in a predictive coding model of cortical function | Unsupervised learning of video representations using lstms | Predictive codes for forthcoming perception in the frontal cortex | Dl-sfa: Deeplylearned slow feature analysis for action recognition | A note on the evaluation of generative models | From neural pca to deep unsupervised learning | Generating videos with scene dynamics | Unsupervised learning of visual representations using videos | Image quality assessment: From error visibility to structural similarity | Understanding visual concepts with continuation learning | Learning invariance from transformation sequences | Visual dynamics: Probabilistic future frame synthesis via cross convolutional networks",iclr,010
351.pdf.json,DIET NETWORKS: THIN PARAMETERS FOR FAT GENOMICS,"Medical datasets often involve a dire imbalance between the number of training examples and the number of input features, especially when genomic information is used as input to the trained pre- ∗Equal contribution. dictor. This is problematic in the context where we want to apply deep learning (which typically involves large models) to precision medicine, i.e., making patient-specific predictions using a potentially large set of input features to better characterize the patient. This paper proposes a novel approach, called Diet Networks, to reparametrize neural networks to considerably reduce their number of free parameters when the input is very high-dimensional and orders of magnitude larger than the number of training examples. Genomics is the study of the genetic code encapsulated as DNA in all living organisms’ cells. Genomes contain the instructions to produce and regulate all the functional components needed to guide the development and adaptation of living organisms. In the last decades, advances in genomic technologies resulted in an explosion of available data, making it more interesting to apply advanced machine learning techniques such as deep learning. Learning tasks involving genomic data and already tackled by deep learning include: using Convolutional Neural Networks (CNNs) to learn the functional activity of DNA sequences (Basset package, Kelley et al. (2016), predicting effects of noncoding DNA (DeepSEA, Zhou & Troyanskaya (2015)), investigating the regulatory role of RNA binding proteins in alternative splicing (Alipanahi et al., 2015), inferring gene expression patterns (Chen et al., 2016; Singh et al., 2016) and population genetic parameters (Sheehan & Song, 2016) among others (see Leung et al. (2016) for a detailed example). Noticeably, most of these techniques are based on sequence data where convolutional or recurrent networks are appropriate. When the full DNA sequence is unavailable, such as when data is acquired through genotyping, other ","Predicting the sequence specificities of dna-and rna-binding proteins by deep learning | Learning to learn by gradient descent by gradient descent | Learning a synaptic learning rule | Learning feed-forward one-shot learners | Random projection in dimensionality reduction: Applications to image and text data | Gene expression inference with deep learning. Bioinformatics, 2016 | Predicting parameters in deep learning | Evolving modular fast-weight networks for control | Genetic ancestry inference using support vector machines, and the active emergence of a unique american population | Basset: Learning the regulatory code of the accessible genome with deep convolutional neural networks. bioRxiv, 2016 | Machine Learning in Genomic Medicine: A Review of Computational Problems and Data Sets | Distributed representations of words and phrases and their compositionality | Inferring genome-wide patterns of admixture in qataris using fifty-five ancestral populations | Principal components analysis corrects for stratification in genome-wide association studies | Learning to control fast-weight memories: An alternative to dynamic recurrent networks | Deep learning for population genetic inference | Deepchrome: deep-learning for predicting gene expression from histone modifications. Bioinformatics, 2016",iclr,010
353.pdf.json,PIXELVAE: A LATENT VARIABLE MODEL FOR NATURAL IMAGES,"Building high-quality generative models of natural images has been a long standing challenge. Although recent work has made significant progress (Kingma & Welling, 2014; van den Oord et al., 2016a;b), we are still far from generating convincing, high-resolution natural images. Many recent approaches to this problem are based on an efficient method for performing amortized, approximate inference in continuous stochastic latent variables: the variational autoencoder (VAE) (Kingma & Welling, 2014) jointly trains a top-down decoder generative neural network with a bottom-up encoder inference network. VAEs for images typically use rigid decoders that model the output pixels as conditionally independent given the latent variables. The resulting model learns a useful latent representation of the data and effectively models global structure in images, but has difficulty capturing small-scale features such as textures and sharp edges due to the conditional independence of the output pixels, which significantly hurts both log-likelihood and quality of generated samples compared to other models. PixelCNNs (van den Oord et al., 2016a;b) are another state-of-the-art image model. Unlike VAEs, PixelCNNs model image densities autoregressively, pixel-by-pixel. This allows it to capture fine details in images, as features such as edges can be precisely aligned. By leveraging carefully constructed masked convolutions (van den Oord et al., 2016b), PixelCNNs can be trained efficiently in parallel on GPUs. Nonetheless, PixelCNN models are still very computationally expensive. Unlike typical convolutional architectures they do not apply downsampling between layers, which means that each layer is computationally expensive and that the depth of a PixelCNN must grow linearly with the size of the images in order for it to capture dependencies between far-away pixels. PixelCNNs also do not explicitly learn a latent representation of the data, which can be useful for downstream tasks such as se","Generating sentences from a continuous space. 2016 | Importance weighted autoencoders | Model selection and multi-model inference, 2nd ed. A Practical information-theoretic approach | Variational Lossy Autoencoder | Density estimation using Real NVP | Adversarial feature learning | Made: Masked autoencoder for distribution estimation | Generative adversarial nets | Towards Conceptual Compression | Auto-encoding variational bayes | Improving variational inference with inverse autoregressive flow | Gradient-based learning applied to document recognition | Unsupervised representation learning with deep convolutional generative adversarial networks | Variational inference with normalizing flows | Discrete variational autoencoders | On the quantitative analysis of deep belief networks | Improved techniques for training | Ladder Variational Autoencoders | Pixel recurrent neural networks | Conditional image generation with pixelcnn decoders | Blocks and fuel: Frameworks for deep learning | LSUN: construction of a large-scale image dataset using deep learning with humans",iclr,010
354.pdf.json,,"Stochastic Gradient Descent (SGD) (Bottou, 2010) and its accelerated variants (Kingma & Ba, 2014; Duchi et al., 2011) have become the de-facto approaches for optimizing deep neural networks. The popularity of SGD can be attributed to its ability to avoid and even escape spurious saddle-points and local minima (Dauphin et al., 2014). Although avoiding these spurious solutions is generally considered positive, in this paper we argue that these local minima contain useful information that may in fact improve model performance. Although deep networks typically never converge to a global minimum, there is a notion of “good” and “bad” local minima with respect to generalization. Keskar et al. (2016) argue that local minima with flat basins tend to generalize better. SGD tends to avoid sharper local minima because gradients are computed from small mini-batches and are therefore inexact (Keskar et al., 2016). If the learningrate is sufficiently large, the intrinsic random motion across gradient steps prevents the optimizer from reaching any of the sharp basins along its optimization path. However, if the learning rate is small, the model tends to converge into the closest local minimum. These two very different behaviors of SGD are typically exploited in different phases of optimization (He et al., 2016a). Initially the learning rate is kept high to move into the general vicinity of a flat local minimum. Once this search has reached a stage in which no further progress is made, the learning rate is dropped (once or twice), triggering a descent, and ultimately convergence, to the final local minimum. It is well established (Kawaguchi, 2016) that the number of possible local minima grows exponentially with the number of parameters—of which modern neural networks can have millions. It is therefore not surprising that two identical architectures optimized with different initializations or minibatch orderings will converge to different solutions. Although different local minima ","Cristian Bucilu, Rich Caruana, and Alexandru Niculescu-Mizil | Torch7: A matlab-like environment for machine learning | Identifying and attacking the saddle point problem in high-dimensional non-convex optimization | Imagenet: A large-scale hierarchical image database | Adaptive subgradient methods for online learning and stochastic optimization | Qualitatively characterizing neural network optimization problems | Neural network ensembles | Deep residual learning for image recognition | Identity mappings in deep residual networks | Distilling the knowledge in a neural network | Densely connected convolutional networks | Deep networks with stochastic depth | Batch normalization: Accelerating deep network training by reducing internal covariate shift | On using very large target vocabulary for neural machine translation | Deep learning without poor local minima | On large-batch training for deep learning: Generalization gap and sharp minima | Adam: A method for stochastic optimization | Learning multiple layers of features from tiny images | Imagenet classification with deep convolutional neural networks | Neural network ensembles, cross validation, and active learning | Zoneout: Regularizing rnns by randomly preserving hidden activations | Temporal ensembling for semi-supervised learning | Fractalnet: Ultra-deep neural networks without residuals | Sgdr: Stochastic gradient descent with restarts | Boosted convolutional neural networks. 2016 | Reading digits in natural images with unsupervised feature learning | Fitnets: Hints for thin deep nets | Edinburgh neural machine translation systems for wmt 16 | Convolutional neural networks applied to house numbers digit classification | Swapout: Learning an ensemble of deep architectures | No more pesky learning rate guessing games | Striving for simplicity: The all convolutional net | Dropout: a simple way to prevent neural networks from overfitting | Fast committee learning: Preliminary results | Regularization of neural networks using dropconnect | Horizontal and vertical ensemble with deep representation for classification | Wide residual networks",iclr,010
355.pdf.json,,"Deep Reinforcement Learning has achieved super-human performance in fully observable environments, e.g., in Atari Games [Mnih et al. (2015)] and Computer Go [Silver et al. (2016)]. Recently, Asynchronous Advantage Actor-Critic (A3C) [Mnih et al. (2016)] model shows good performance for 3D environment exploration, e.g. labyrinth exploration. However, in general, to train an agent in a partially observable 3D environment from raw frames remains an open challenge. Direct application of A3C to competitive 3D scenarios, e.g. 3D games, is nontrivial, partly due to sparse and long-term rewards in such scenarios. Doom is a 1993 First-Person Shooter (FPS) game in which a player fights against other computercontrolled agents or human players in an adversarial 3D environment. Previous works on FPS AI [van Waveren (2001)] focused on using hand-tuned state machines and privileged information, e.g., the geometry of the map, the precise location of all players, to design playable agents. Although state-machine is conceptually simple and computationally efficient, it does not operate like human players, who only rely on visual (and possibly audio) inputs. Also, many complicated situations require manually-designed rules which could be time-consuming to tune. In this paper, we train an AI agent in Doom with a framework that based on A3C with convolutional neural networks (CNN). This model uses only the recent 4 frames and game variables from the AI side, to predict the next action of the agent and the value of the current situation. We follow the curriculum learning paradigm [Bengio et al. (2009); Jiang et al. (2015)]: start from simple tasks and then gradually try harder ones. The difficulty of the task is controlled by a variety of parameters in Doom environment, including different types of maps, strength of the opponents and the design of the reward function. We also develop adaptive curriculum training that samples from a varying distribution of tasks to train the model, which ","Tensorflow: Large-scale machine learning on heterogeneous distributed systems | Reinforcement learning through asynchronous advantage actor-critic on a gpu | Neuronlike adaptive elements that can solve difficult learning control problems | Curriculum learning | An empirical study of potential-based reward shaping and advice in complex, multi-agent systems | Learning to act by predicting the future | A survey of actor-critic reinforcement learning: Standard and natural policy gradients | Deep recurrent q-learning for partially observable mdps | Self-paced curriculum learning | Vizdoom: A doom-based ai research platform for visual reinforcement learning | Adam: A method for stochastic optimization | Playing fps games with deep reinforcement learning | Humanlevel control through deep reinforcement learning | Asynchronous methods for deep reinforcement learning | Policy invariance under reward transformations: Theory and application to reward shaping | Reinforcement learning of motor skills with policy gradients | A deep reinforcement learning doom playing agent | Mastering the game of go with deep neural networks and tree | Reinforcement learning: An introduction, volume | Temporal credit assignment in reinforcement learning | The Quake III Arena bot | Simple statistical gradient-following algorithms for connectionist reinforcement learning",iclr,010
356.pdf.json,NEURO-SYMBOLIC PROGRAM SYNTHESIS,"The act of programming, i.e., developing a procedure to accomplish a task, is a remarkable demonstration of the reasoning abilities of the human mind. Expectedly, Program Induction is considered as one of the fundamental problems in Machine Learning and Artificial Intelligence. Recent progress on deep learning has led to the proposal of a number of promising neural architectures for this problem. Many of these models are inspired from computation modules (CPU, RAM, GPU) (Graves et al., 2014; Kurach et al., 2015; Reed & de Freitas, 2015; Neelakantan et al., 2015) or common data structures used in many algorithms (stack) (Joulin & Mikolov, 2015). A common thread in this line of work is to specify the atomic operations of the network in some differentiable form, allowing efficient end-to-end training of a neural controller, or to use reinforcement learning to make hard choices about which operation to perform. While these results are impressive, these approaches have a number of important limitations: (a) they are computationally expensive and hard to train, (b) a model has to be trained for each task (program) separately, and (c) it is hard to interpret or verify the correctness of the learnt mapping (as it is defined by a neural network). While some recently proposed methods (Kurach et al., 2015; Gaunt et al., 2016; Riedel et al., 2016; Bunel et al., 2016) do learn interpretable programs, they still need to learn a separate neural network model for each individual task. Motivated by the need for model interpretability and scalability to multiple tasks, we address the problem of Program Synthesis. Program Synthesis, the problem of automatically constructing programs that are consistent with a given specification, has long been a subject of research in Computer Science (Biermann, 1978; Summers, 1977). This interest has been reinvigorated in recent years on the back of the development of methods for learning programs in various domains, ranging from low-level bit manipu",Syntax-guided synthesis | PHOG: probabilistic model for code | The inference of regular lisp programs from examples | Adaptive neural compilation | Terpret: A probabilistic programming language for program induction | Neural turing machines | Automating string processing in spreadsheets using input-output examples | Synthesis of loop-free programs | Spreadsheet data manipulation using examples | Bidirectional recursive neural networks for token-level labeling with structure | Inferring algorithmic patterns with stack-augmented recurrent nets | Adam: A method for stochastic optimization | Neural random-access machines | The inside-outside recursive neural network model for dependency parsing | Learning programs: A hierarchical Bayesian approach | Structured generative models of natural source code | A machine learning framework for programming by example | Neural programmer: Inducing latent programs with gradient descent | Global belief recursive neural networks | Learning program embeddings to propagate feedback on student code | Predicting program properties from ”big code | Programming with a differentiable forth interpreter | Stochastic superoptimization | Synthesizing data structure manipulations from storyboards | Automated feedback generation for introductory programming assignments | Program Synthesis By Sketching | Programming by sketching for bit-streaming programs | A methodology for lisp program construction from examples | TRANSIT: specifying protocols with concolic snippets,iclr,010
357.pdf.json,NATURAL VIDEO SEQUENCE PREDICTION,"Understanding videos has been one of the most important tasks in the field of computer vision. Compared to still images, the temporal component of videos provides much richer descriptions of the visual world, such as interaction between objects, human activities, and so on. Amongst the various tasks applicable on videos, the task of anticipating the future has recently received increased attention in the research community. Most prior works in this direction focus on predicting high-level semantics in a video such as action (Vondrick et al., 2015; Ryoo, 2011; Lan et al., 2014), event (Yuen and Torralba, 2010; Hoai and Torre, 2013) and motion (Pintea et al., 2014; Walker et al., 2014; Pickup et al., 2014; Walker et al., 2016). Forecasting semantics provides information about what will happen in a video, and is essential to automate decision making. However, the predicted semantics are often specific to a particular task and provide only a partial description of the future. Also, training such models often requires heavily labeled training data which leads to tremendous annotation costs especially with videos. In this work, we aim to address the problem of prediction of future frames in natural video sequences. Pixel-level predictions provide dense and direct description of the visual world, and existing video recognition models can be adopted on top of the predicted frames to infer various semantics of the future. Spatio-temporal correlations in videos provide a self-supervision for frame prediction, which enables purely unsupervised training of a model by observing raw video frames. Unfortunately, estimating frames is an extremely challenging task; not only because of the inherent uncertainty of the future, but also various factors of variation in videos leading to complicated dynamics in raw pixel values. There have been a number of recent attempts on frame prediction (Srivastava et al., 2015; Mathieu et al., 2015; Oh et al., 2015; Goroshin et al., 2015; Lotter et ",Unsupervised learning for physical interaction through video prediction | Generative adversarial nets | Actions as space-time shapes | Learning to linearize under uncertainty | Deep residual learning for image recognition | Reducing the dimensionality of data with neural networks | Max-margin early event detectors | Large-scale video classification with convolutional neural networks | A hierarchical representation for future action prediction | Unsupervised learning of visual structure using predictive generative networks | We display predicted frames (in every other frame) starting from the 5th frame. The green arrows denote the top-30 closest optical flow vectors within image patches between MCnet and ground-truth. More clear motion prediction can be seen in the project website | Deep multi-scale video prediction beyond mean square error | Action-conditional video prediction using deep networks in atari games | Spatio-temporal video autoencoder with differentiable memory | Seeing the arrow of time | Dejavu: Motion prediction in static images | Video (language) modeling: a baseline for generative models of natural videos | Human activity prediction: Early recognition of ongoing activities from streaming videos | Recognizing human actions: A local svm approach | Convolutional lstm network: A machine learning approach for precipitation nowcasting | Two-stream convolutional networks for action recognition in videos | Very deep convolutional networks for large-scale image recognition | UCF101: A dataset of 101 human actions classes from videos in the wild | Unsupervised learning of video representations using lstms | Anticipating the future by watching unlabeled video | Generating videos with scene dynamics | An uncertain future: Forecasting from static images using variational autoencoders | DeepFlow: Large displacement optical flow with deep matching | Visual dynamics: Probabilistic future frame synthesis via cross convolutional networks | A data-driven approach for event prediction | Adaptive deconvolutional networks for mid and high level feature learning,iclr,010
358.pdf.json,,"The machine learning community is well-practised at learning representations of data-points and sequences. A middle-ground between these two is representing, or summarizing, datasets - unordered collections of vectors, such as photos of a particular person, recordings of a given speaker or a document as a bag-of-words. Where these sets take the form of i.i.d samples from some distribution, such summaries are called statistics. We explore the idea of using neural networks to learn statistics and we refer to our approach as a neural statistician. The key result of our approach is a statistic network that takes as input a set of vectors and outputs a vector of summary statistics specifying a generative model of that set - a mean and variance specifying a Gaussian distribution in a latent space we term the context. The advantages of our approach are that it is: • Unsupervised: It provides principled and unsupervised way to learn summary statistics as the output of a variational encoder of a generative model. • Data efficient: If one has a large number of small but related datasets, modelling the datasets jointly enables us to gain statistical strength. • Parameter Efficient: By using summary statistics instead of say categorical labellings of each dataset, we decouple the number of parameters of the model from the number of datasets. • Capable of few-shot learning: If the datasets correspond to examples from different classes, class embeddings (summary statistics associated with examples from a class), allow us to handle new classes at test time.","TensorFlow: Large-scale machine learning | On classification with bags, groups and sets | Learning a similarity metric discriminatively, with application to face verification | Regularized multi–task learning | Kernel Bayes’ rule: Bayesian inference with positive definite kernels | Multi-instance kernels | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Learning summary statistic for approximate Bayesian computation via deep neural network | Structured vaes: Composing probabilistic graphical models and variational autoencoders | How to train deep variational autoencoders and probabilistic ladder networks | Adam: A method for stochastic optimization | Auto-encoding variational Bayes | Siamese neural networks for one-shot image recognition | Human-level concept learning through probabilistic program induction | Discriminative regularization for generative models | Learning to learn with the informative vector machine | Gradient-based learning applied to document recognition | Auxiliary deep generative models | Neural variational inference for text processing | Learning from distributions via support measure machines | A survey on transfer learning | Support distribution machines | Black box variational inference | Stochastic backpropagation and approximate inference in deep generative models | Oneshot generalization in deep generative models | One-shot learning with a hierarchical nonparametric bayesian model | Oneshot learning with memory-augmented neural networks | Exploiting tractable substructures in intractable networks | A note on the evaluation of generative models | Order matters: sequence to sequence for sets | Matching networks for one shot learning | Face recognition in unconstrained videos with matched background similarity",iclr,010
360.pdf.json,GENERALIZING SKILLS WITH SEMI-SUPERVISED REINFORCEMENT LEARNING,"Reinforcement learning (RL) provides a powerful framework for learning behavior from highlevel goals. RL has been combined with deep networks to learn policies for problems such as Atari games (Mnih et al., 2015), simple Minecraft tasks (Oh et al., 2016), and simulated locomotion (Schulman et al., 2015). To apply reinforcement learning (RL) to real-world scenarios, however, the learned policy must be able to handle the variability of the real-world and generalize to scenarios that it has not seen previously. In many such domains, such as robotics and dialog systems, the variability of the real-world poses a significant challenge. Methods for training deep, flexible models combined with massive amounts of labeled data are known to enable wide generalization for supervised learning tasks (Russakovsky et al., 2015). Lifelong learning aims to address this data challenge in the context of RL by enabling the agent to continuously learn as it collects new experiences “on the job,” directly in the real world (Thrun & Mitchell, 1995). However, this learning requires access to a reward function, to tell the agent whether it is succeeding or failing at its task. Although the reward is a high-level supervision signal that is in principle easier to provide than detailed labels, in practice it often depends on information that is extrinsic to the agent and is therefore difficult to measure in the real world. For example, in robotics, the reward may depend on the poses of all of the objects in the environment, and in dialog systems, the reward may depend on the happiness of the user. This reward supervision is practical to measure in a small set of instrumented training scenarios, in laboratory settings, or under the guidance of a human teacher, but quickly becomes impractical to provide continuously to a lifelong learning system, when the agent is deployed in varied and diverse real-world settings. Conceptually, we might imagine that this challenge should not exist, since reinfor","Apprenticeship learning via inverse reinforcement learning | Concrete problems in ai safety | Maximum entropy semisupervised inverse reinforcement learning | Transfer learning for reinforcement learning on a physical robot | The arcade learning environment: An evaluation platform for general agents | Semi-supervised reinforcement learning | Learning modular neural network policies for multi-task and multi-robot transfer | Learning from experience in manipulation planning: Setting the right goals | Inverse optimal control with linearly-solvable MDPs | Guided cost learning: Deep inverse optimal control via policy optimization | Reward mapping for transfer in long-lived agents | Model-free imitation learning with policy optimization | Optimal control as a graphical model inference problem | Semi-supervised learning with deep generative models | Autonomous shaping: Knowledge transfer in reinforcement learning | End-to-end training of deep visuomotor policies | Human-level control through deep reinforcement learning | Guided policy search as approximate mirror descent | Reset-free guided policy search: Efficient deep reinforcement learning with stochastic initial states | Combining model-based policy search with online model learning for control of physical humanoids | Algorithms for inverse reinforcement learning | Control of memory, active perception, and action in minecraft | Actor-mimic: Deep multitask and transfer reinforcement learning | Semi-supervised learning with ladder networks | Imagenet large scale visual recognition challenge | Trust region policy optimization | Knowledge transfer using local features | Information regularization with partially labeled data | Transfer learning for reinforcement learning domains: A survey | Tracking-based semi-supervised learning | Lifelong robot learning | Adapting deep visuomotor representations with weak pairwise constraints | Augmenting supervised neural networks with unsupervised objectives for large-scale image classification | Learning from labeled and unlabeled data with label propagation | Introduction to semi-supervised learning | Modeling purposeful adaptive behavior with the principle of maximum causal entropy",iclr,010
361.pdf.json,,"Deep learning has celebrated many successes, but its performance relies crucially on good hyperparameter settings. Bayesian optimization (e.g, Brochu et al. (2010); Snoek et al. (2012); Shahriari et al. (2016)) is a powerful method for optimizing the hyperparameters of deep neural networks (DNNs). However, its traditional treatment of DNN performance as a black box poses fundamental limitations for large and computationally expensive data sets, for which training a single model can take weeks. Human experts go beyond this blackbox notion in their manual tuning and exploit cheaper signals about which hyperparameter settings work well: they estimate overall performance based on runs using subsets of the data or initial short runs to weed out bad parameter settings; armed with these tricks, human experts can often outperform Bayesian optimization. Recent extensions of Bayesian optimization and multi-armed bandits therefore also drop the limiting blackbox assumption and exploit the performance of short runs (Swersky et al., 2014; Domhan et al., 2015; Li et al., 2017), performance on small subsets of the data (Klein et al., 2017), and performance on other, related data sets (Swersky et al., 2013; Feurer et al., 2015). While traditional solutions for scalable Bayesian optimization include approximate Gaussian process models (e.g., Hutter et al.; Swersky et al. (2014)) and random forests (Hutter et al., 2011), a recent trend is to exploit the flexible model class of neural networks for this purpose (Snoek et al., 2015; Springenberg et al., 2016). In this paper, we study this model class for the prediction of learning curves. Our contributions in this paper are: 1. We study how well Bayesian neural networks can fit learning curves for various architectures and hyperparameter settings, and how reliable their uncertainty estimates are. 2. Building on the parametric learning curve models of Domhan et al. (2015), we develop a specialized neural network architecture with a learn",Freeze-thaw Bayesian optimization | Initializing Bayesian hyperparameter optimization via | Algorithm runtime prediction: Methods | Gradient-based learning applied to document | Auto-encoding variational bayes,iclr,010
362.pdf.json,,"Continuous optimization algorithms are some of the most ubiquitous tools used in virtually all areas of science and engineering. Indeed, they are the workhorse of machine learning and power most learning algorithms. Consequently, optimization difficulties become learning challenges – because their causes are often not well understood, they are one of the most vexing issues that arise in practice. One solution is to design better optimization algorithms that are immune to these failure cases. This requires careful analysis of existing optimization algorithms and clever solutions to overcome their weaknesses; thus, doing so is both laborious and time-consuming. Is there a better way? If the mantra of machine learning is to learn what is traditionally manually designed, why not take it a step further and learn the optimization algorithm itself? Consider the general structure of an algorithm for unconstrained continuous optimization, which is outlined in Algorithm 1. Starting from a random location in the domain of the objective function, the algorithm iteratively updates the current iterate by a step vector ∆x computed from some functional π of the objective function, the current iterate and past iterates. Algorithm 1 General structure of unconstrained optimization algorithms Require: Objective function f x(0) ← random point in the domain of f for i = 1, 2, . . . do ∆x← π(f, {x(0), . . . , x(i−1)}) if stopping condition is met then return x(i−1) end if x(i) ← x(i−1) + ∆x end for Different optimization algorithms only differ in the choice of the update formula π. Examples of existing optimization algorithms and their corresponding update formulas are shown in Table 1. If we can learn π, we will be able to learn an optimization algorithm. Since it is difficult to model general functionals, in practice, we restrict the dependence of π on the objective function f to objective values and gradients evaluated at current and past iterates. Hence, π can be simply modelled as a ","A method for learning from hints | Learning to learn by gradient descent by gradient descent | NIPS 1995 workshop on learning to learn: Knowledge consolidation and transfer in inductive systems | Gradient-based optimization of hyperparameters | Random search for hyper-parameter optimization | Algorithms for hyper-parameter optimization | 3d hand tracking by rapid stochastic gradient descent using a skinning model | Metalearning: applications to data mining | Ranking learning algorithms: Using ibl and meta-learning on accuracy and time results | A tutorial on bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning | A representation for the adaptive generation of simple sequential programs | Learning step size controllers for robust neural network training | Generic methods for optimization-based modeling | Initializing bayesian hyperparameter optimization via meta-learning | Learning visual feature spaces for robotic manipulation with deep spatial autoencoders | Deep q-networks for accelerating the training of deep neural networks | Learning fast approximations of sparse coding | Learning compound multi-step controllers under unknown dynamics | Using deep q-learning to control optimization hyperparameters | Learning to learn using gradient descent | Sequential model-based optimization for general algorithm configuration | Learning neural network policies with guided policy search under unknown dynamics | End-to-end training of deep visuomotor policies | Learning contact-rich manipulation skills with guided policy search | Learning programs: A hierarchical Bayesian approach | Gradient-based hyperparameter optimization through reversible learning | The application of bayesian methods for seeking the extremum | Optimization on a budget: A reinforcement learning approach | Optimal ordered problem solver | Practical bayesian optimization of machine learning algorithms | Supervised sparse analysis and synthesis operators | Multi-task bayesian optimization. In Advances in neural information processing | Learning to learn | A perspective view and survey of meta-learning",iclr,010
363.pdf.json,A COMPARE-AGGREGATE MODEL FOR MATCHING TEXT SEQUENCES,"Many natural language processing problems involve matching two or more sequences to make a decision. For example, in textual entailment, one needs to determine whether a hypothesis sentence can be inferred from a premise sentence (Bowman et al., 2015). In machine comprehension, given a passage, a question needs to be matched against it in order to find the correct answer (Richardson et al., 2013; Tapaswi et al., 2016). Table 1 gives two example sequence matching problems. In the first example, a passage, a question and four candidate answers are given. We can see that to get the correct answer, we need to match the question against the passage and identify the last sentence to be the answer-bearing sentence. In the second example, given a question and a set of candidate answers, we need to find the answer that best matches the question. Because of the fundamental importance of comparing two sequences of text to judge their semantic similarity or relatedness, sequence matching has been well studied in natural language processing. With recent advances of neural network models in natural language processing, a standard practice for sequence modeling now is to encode a sequence of text as an embedding vector using models such as RNN and CNN. To match two sequences, a straightforward approach is to encode each sequence as a vector and then to combine the two vectors to make a decision (Bowman et al., 2015; Feng et al., 2015). However, it has been found that using a single vector to encode an entire sequence is not sufficient to capture all the important information from the sequence, and therefore advanced techniques such as attention mechanisms and memory networks have been applied to sequence matching problems (Hermann et al., 2015; Hill et al., 2016; Rocktäschel et al., 2015). A common trait of a number of these recent studies on sequence matching problems is the use of a “compare-aggregate” framework (Wang & Jiang, 2016b; He & Lin, 2016; Parikh et al., 2016). In suc",Neural machine translation by jointly learning to align and translate | Learning concept importance using a weighted dependence model | A large annotated corpus for learning natural language inference | Enhancing and combining sequential and tree LSTM for natural language inference | Long short-term memory-networks for machine reading | Applying deep learning to answer selection: A study and an open task | Pairwise word interaction modeling with deep neural networks for semantic similarity measurement | Teaching machines to read and comprehend | The Goldilocks principle: Reading children’s books with explicit memory representations | Convolutional neural network architectures for matching natural language sentences | Convolutional neural networks for sentence classification | Adam: A method for stochastic optimization | Effective approaches to attentionbased neural machine translation | Natural language inference by tree-based convolution and heuristic matching | A decomposable attention model for natural language inference | GloVe: Global vectors for word representation | MCTest: A challenge dataset for the open-domain machine comprehension of text | Reasoning about entailment with neural attention | Recursive deep models for semantic compositionality over a sentiment treebank | Improved semantic representations from tree-structured long short-term memory networks | Improved representation learning for question answer matching | MovieQA: Understanding stories in movies through question-answering | A parallel-hierarchical model for machine comprehension on sparse data | Match-srnn: Modeling the recursive matching structure with spatial RNN | Inner attention based recurrent neural networks for answer selection | Machine comprehension using match-LSTM and answer pointer | Learning natural language inference with LSTM | WikiQA: A challenge dataset for open-domain question answering | ABCNN: Attention-based convolutional neural network for modeling sentence pairs,iclr,010
365.pdf.json,,"Deep neural networks have achieved great success on a variety of challenging data science tasks (Krizhevsky et al., 2012; Hinton et al., 2012; Simonyan & Zisserman, 2014b; Bahdanau et al., 2014; Mnih et al., 2015; Silver et al., 2016; Sutskever et al., 2014). However, the models that have achieved this success have a very large number of parameters, a consequence of their wide and deep architectures. Although such models yield great performance benefits, the corresponding memory and computational costs are high, making such models inaccessible to lightweight architectures (e.g., portable devices, Internet-of-Things devices, etc.). In such settings, the deployment of neural networks offers tremendous potential to produce novel applications, yet the modern top-performing networks are often infeasible on these platforms. Fully-connected layers and convolutional layers are the two most commonly used neural network structures. While networks that consist of convolutional layers, are particularly good for vision tasks, the fully-connected layers, even if they are in the minority, are responsible for the majority of the parameters. For example, the VGG-16 network (Simonyan & Zisserman, 2014a) has 13 convolutional layers and 3 fully-connected layers, but the parameters for 13 convolutional layers contain only ∼ 1/9 of the parameters of the three fully-connected layers. Moreover, for general tasks, convolutional layers may be not applicable (data might be one-dimensional, or there might be no local correlation among data dimensions). Therefore, compression of fully-connected layers is critical for reducing the memory and computational cost of neural networks in general. We can use the characteristics of convolutional layers to reduce the memory and computational cost of fully-connected layers. Convolution is a special form of matrix multiplication, where the weights of the matrix are shared according to the convolution structure (low diversity), and most entries of the weigh","Do deep nets really need to be deep? In Advances in neural information processing | Neural machine translation by jointly learning to align and translate | Image recovery via total variation minimization and related problems | Mxnet: A flexible and efficient machine learning library for heterogeneous distributed systems | Compressing neural networks with the hashing | Highperformance neural networks for visual object classification | Adaptive subgradient methods for online learning and stochastic optimization | Deep compression: Compressing deep neural network with pruning, trained quantization and huffman coding | Learning both weights and connections for efficient neural network | Second order derivatives for network pruning: Optimal brain surgeon | Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | Optimal brain damage | Gradient-based learning applied to document recognition | Speaker-independent phone recognition using hidden markov models | Human-level control through deep reinforcement learning | Acoustic modeling using deep belief networks | Simplifying neural networks by soft weight-sharing | Nonlinear total variation based noise removal algorithms | Mastering the game of go with deep neural networks and tree | Very deep convolutional networks for large-scale image recognition | Very deep convolutional networks for large-scale image recognition | Sequence to sequence learning with neural networks. In Advances in neural information processing",iclr,010
366.pdf.json,AUTOENCODING VARIATIONAL INFERENCE FOR TOPIC MODELS,"Topic models (Blei, 2012) are among the most widely used models for learning unsupervised representations of text, with hundreds of different model variants in the literature, and have have found applications ranging from the exploration of the scientific literature (Blei & Lafferty, 2007) to computer vision (Fei-Fei & Perona, 2005), bioinformatics (Rogers et al., 2005), and archaeology (Mimno, 2009). A major challenge in applying topic models and developing new models is the computational cost of computing the posterior distribution. Therefore a large body of work has considered approximate inference methods, the most popular methods being variational methods, especially mean field methods, and Markov chain Monte Carlo, particularly methods based on collapsed Gibbs sampling. Both mean-field and collapsed Gibbs have the drawback that applying them to new topic models, even if there is only a small change to the modeling assumptions, requires re-deriving the inference methods, which can be mathematically arduous and time consuming, and limits the ability of practitioners to freely explore the space of different modeling assumptions. This has motivated the development of black-box inference methods (Ranganath et al., 2014; Mnih & Gregor, 2014; Kucukelbir et al., 2016; Kingma & Welling, 2014) which require only very limited and easy to compute information from the model, and hence can be applied automatically to new models given a simple declarative specification of the generative process. Autoencoding variational Bayes (AEVB) (Kingma & Welling, 2014; Rezende et al., 2014) is a particularly natural choice for topic models, because it trains an inference network (Dayan et al., 1995), a neural network that directly maps a document to an approximate posterior distribution, ∗Additional affiliation: Alan Turing Institute, British Library, 96 Euston Road, London NW1 2DB without the need to run further variational updates. This is intuitively appealing because in topic models",Probabilistic topic models | Correlated topic models | A correlated topic model of science | Latent dirichlet allocation | A generalization of principal component analysis to the exponential family | The helmholtz machine | Multiple hypergeometric functions: Probabilistic interpretations and statistical uses | Training neural Bayesian nets. http://www. iro.umontreal.ca/ ̃bengioy/cifar/NCAP2014-summerschool/slides/ Laurent_dinh_cifar_presentation.pdf | A Bayesian hierarchical model for learning natural scene categories | Finding scientific topics | Kernel topic models | Training products of experts by minimizing contrastive divergence | Replicated softmax: an undirected topic model | Online learning for latent dirichlet allocation | Probabilistic latent semantic indexing | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Adam: A method for stochastic optimization | Auto-encoding variational bayes | Automatic differentiation variational inference | A neural autoregressive topic model | Machine reading tea leaves: Automatically evaluating topic coherence and topic model quality | Choice of basis for Laplace approximation | Mallet: A machine learning for language toolkit | Neural variational inference for text processing | Reconstructing Pompeian households | Neural variational inference and learning in belief networks | Automatic evaluation of topic coherence | Black box variational inference | Stochastic backpropagation and approximate inference in deep generative models | The latent process decomposition of cdna microarray data sets | Rethinking LDA: Why priors matter | Exponential family harmoniums with an application to information retrieval | Simple statistical gradient-following algorithms for connectionist reinforcement learning,iclr,010
367.pdf.json,OPTIMAL BINARY AUTOENCODING WITH PAIRWISE CORRELATIONS,"Consider a general autoencoding scenario, in which an algorithm learns a compression scheme for independently, identically distributed (i.i.d.) V -dimensional bit vector data { x̂(1), . . . , x̂(n) } . For some encoding dimension H , the algorithm encodes each data example x̂(i) = (x̂(i)1 , . . . , x̂ (i) V ) > into an H-dimensional representation e(i), with H < V . It then decodes each e(i) back into a reconstructed example x̃(i) using some small amount of additional memory, and is evaluated on the quality of the reconstruction by the cross-entropy loss commonly used to compare bit vectors. A good autoencoder learns to compress the data into H bits so as to reconstruct it with low loss. When the loss is squared reconstruction error and the goal is to compress data in RV to RH , this is often accomplished with principal component analysis (PCA), which projects the input data on the top H eigenvectors of their covariance matrix (Bourlard & Kamp (1988); Baldi & Hornik (1989)). These eigenvectors in RV constitute V H real values of additional memory needed to decode the compressed data in RH back to the reconstructions in RV , which are linear combinations of the eigenvectors. Crucially, this total additional memory does not depend on the amount of data n, making it applicable when data are abundant. This paper considers a similar problem, except using bit-vector data and the cross-entropy reconstruction loss. Since we are compressing samples of i.i.d. V -bit data into H-bit encodings, a natural approach is to remember the pairwise statistics: the V H average correlations between pairs of bits in the encoding and decoding, constituting as much additional memory as the eigenvectors used in PCA. The decoder uses these along with the H-bit encoded data, to produce V -bit reconstructions. We show how to efficiently learn the autoencoder with the worst-case optimal loss in this scenario, without any further assumptions, parametric or otherwise. It has some striking properti","A learning algorithm for boltzmann machines | Provable bounds for learning some deep representations | Convex deep learning via normalized kernels | Breaking the curse of dimensionality with convex neural networks | Autoencoders, unsupervised learning, and deep architectures. Unsupervised and Transfer Learning Challenges in Machine Learning, Volume 7, pp | Neural networks and principal component analysis: Learning from examples without local minima | Optimally combining classifiers using unlabeled data | Scalable semi-supervised classifier aggregation | Optimal binary classifier aggregation for general losses | The fast convergence of incremental pca | The sample complexity of pattern classification with neural networks: the size of the weights is more important than the size of the network | Learning deep architectures for ai | Convex neural networks. In Advances in neural information processing systems (NIPS) | Representation learning: A review and new perspectives | Generalized denoising auto-encoders as generative models | Auto-association by multilayer perceptrons and singular value decomposition | Importance weighted autoencoders | Prediction, Learning, and Games | Identifying and attacking the saddle point problem in high-dimensional non-convex optimization. In Advances in neural information processing systems | Adaptive subgradient methods for online learning and stochastic optimization | Unsupervised learning of distributions on binary vectors using two layer networks | Generative adversarial nets | Biconvex sets and optimization with biconvex functions: a survey and extensions | Deep residual learning for image recognition | The"" wake-sleep"" algorithm for unsupervised neural networks | Beating the perils of non-convexity: Guaranteed training of neural networks using tensor methods | Why the logistic function? a tutorial discussion on probabilities and neural networks | Adam: A method for stochastic optimization | Auto-encoding variational bayes | Generative moment matching networks | On the computational efficiency of training neural networks | Semi-supervised learning with ladder networks | Parallel distributed processing, explorations in the microstructure of cognition. vol. 1: Foundations. Computational Models of Cognition and Perception | Learning representations by back-propagating | On the quantitative analysis of deep belief networks | Convergence of stochastic gradient descent for pca | Information processing in dynamical systems: foundations of harmony theory | Extracting and composing robust features with denoising autoencoders | Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion | Convexified convolutional neural networks",iclr,010
368.pdf.json,ON THE QUANTITATIVE ANALYSIS OF DECODER- BASED GENERATIVE MODELS,"In recent years, deep generative models have dramatically pushed forward the state-of-the-art in generative modelling by generating convincing samples of images (Radford et al., 2016), achieving state-of-the-art semi-supervised learning results (Salimans et al., 2016), and enabling automatic image manipulation (Zhu et al., 2016). Many of the most successful approaches are defined in terms of a process which samples latent variables from a simple fixed distribution (such as Gaussian or uniform) and then applies a learned deterministic mapping which we will refer to as a decoder network. Important examples include variational autoencoders (VAEs) (Kingma & Welling, 2014; Rezende et al., 2014), generative adversarial networks (GANs) (Goodfellow et al., 2014), generative moment matching networks (GMMNs) (Li & Swersky, 2015; Dziugaite et al., 2015), and nonlinear independent components estimation (Dinh et al., 2014). We refer to this set of models collectively as decoder-based models, also known as density networks (MacKay & Gibbs, 1998). While many decoder-based models are able to produce convincing samples (Denton et al., 2015; Radford et al., 2016), rigorous evaluation remains a challenge. Comparing models by inspecting samples is labor-intensive, and potentially misleading (Theis et al., 2016). While alternative quantitative criteria have been proposed (Bounliphone et al., 2016; Im et al., 2016; Salimans et al., 2016), log-likelihood of held-out test data remains one of the most important measures of a generative model’s performance. Unfortunately, unless the decoder is designed to be reversible (Dinh et al., 2014; 2016), log-likelihood estimation in decoder-based models is typically intractable. In the case of VAE-based models, a learned encoder network gives a tractable lower bound, but for GANs and GMMNs it is not obvious how even to compute a good lower bound. Even when lower bounds are available, their accuracy may be hard to determine. Because of the difficulty ","Theano: A python framework for fast computation of mathematical expressions, 2016 | Bounding the test log-likelihood of generative models | A test of relative similarity for model selection in generative models | Importance weighted autoencoders | Deep generative image models using a laplacian pyramid of adversarial networks | Nice: Non-linear independent components estimation | Density estimation using real nvp | Training generative neural networks via Maximum Mean Discrepancy optimization | Generative adversarial nets | Measuring the reliability of MCMC inference with bidirectional Monte Carlo | Sandwiching the marginal likelihood using bidirectional monte carlo | Generating images with recurrent adversarial networks | Random generation of combinatorial structures from a uniform distribution | Auto-encoding variational bayes | Gradient-based learning applied to document recognition | Generative moment matching networks | Annealed importance sampling | MCMC using Hamiltonian dynamics | On estimation of a probability density function and mode | Unsupervised representation learning with deep convolutional generative adversarial networks | Factored 3-way restricted Boltzmann machines for modeling natural images | Stochastic backpropagation and approximate inference in deep generative models | On the quantitative analysis of Deep Belief Networks | Improved techniques for training gans | A note on the evaluation of generative models | The variational Gaussian process | RNADE: The real-valued neural autoregressive density-estimator | Pixel recurrent neural networks | Published as a conference",iclr,010
369.pdf.json,TRAINED TERNARY QUANTIZATION,"Deep neural networks are becoming the preferred approach for many machine learning applications. However, as networks get deeper, deploying a network with a large number of parameters on a small device becomes increasingly difficult. Much work has been done to reduce the size of networks. Halfprecision networks (Amodei et al., 2015) cut sizes of neural networks in half. XNOR-Net (Rastegari et al., 2016), DoReFa-Net (Zhou et al., 2016) and network binarization (Courbariaux et al.; 2015; Lin et al., 2015) use aggressively quantized weights, activations and gradients to further reduce computation during training. While weight binarization benefits from 32× smaller model size, the extreme compression rate comes with a loss of accuracy. Hubara et al. (2016) and Li & Liu (2016) propose ternary weight networks to trade off between model size and accuracy. In this paper, we propose Trained Ternary Quantization which uses two full-precision scaling coefficients W pl , W n l for each layer l, and quantize the weights to {−Wnl , 0, +W p l } instead of traditional {-1, 0, +1} or {-E, 0, +E} where E is the mean of the absolute weight value, which is not learned. Our positive and negative weights have different absolute values W pl and W n l that are trainable parameters. We also maintain latent full-precision weights at training time, and discard them at test time. We back propagate the gradient to both W pl , W n l and to the latent full-precision weights. This makes it possible to adjust the ternary assignment (i.e. which of the three values a weight is assigned). Our quantization method, achieves higher accuracy on the CIFAR-10 and ImageNet datasets. For AlexNet on ImageNet dataset, our method outperforms previously state-of-art ternary network(Li & ∗Work done while at Stanford CVA lab. Liu, 2016) by 3.0% of Top-1 accuracy and the full-precision model by 1.6%. By converting most of the parameters to 2-bit values, we also compress the network by about 16x. Moreover, the advant","Deep speech 2: End-to-end speech recognition in english and mandarin | Binaryconnect: Training deep neural networks with binary weights during propagations | Deep compression: Compressing deep neural network with pruning, trained quantization and huffman coding | Deep residual learning for image recognition | Identity mappings in deep residual networks | Quantized neural networks: Training neural networks with low precision weights and activations | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Caffe: Convolutional architecture for fast feature embedding | Adam: A method for stochastic optimization | Learning multiple layers of features from tiny images | Imagenet classification with deep convolutional neural networks | Ternary weight networks | Neural networks with few multiplications | Xnor-net: Imagenet classification using binary convolutional neural networks | ImageNet Large Scale Visual Recognition Challenge | Dorefa-net: Training low bitwidth convolutional neural networks with low bitwidth gradients",iclr,010
370.pdf.json,DSD: DENSE-SPARSE-DENSE TRAINING FOR DEEP NEURAL NETWORKS,"Deep neural networks (DNNs) have shown significant improvements in many application domains, ranging from computer vision (He et al. (2015)) to natural language processing (Luong et al. (2015)) and speech recognition (Amodei et al. (2015)). The abundance of powerful hardware makes it easier to train complicated DNN models with large capacities. The upside of complicated models is that they are very expressive and can capture the highly non-linear relationship between features and output. The downside of such large models is that they are prone to capturing the noise, rather than the intended pattern, in the training dataset. This noise does not generalize to new datasets, leading to over-fitting and a high variance. ∗Indicates equal contribution †Also at NVIDIA ‡Now at Google Brain. eriche@google.com Dense Pruning Sparsity Constraint Sparse Increase Model Capacity Re-Dense Dense end goto Sparse Phase for iterative DSD; In contrast, simply reducing the model capacity would lead to the other extreme, causing a machine learning system to miss the relevant relationships between features and target outputs, leading to under-fitting and a high bias. Bias and variance are hard to optimize at the same time. To solve this problem, we propose a dense-sparse-dense training flow (DSD), a novel training strategy that starts from a dense model from conventional training, then regularizes the model with sparsityconstrained optimization, and finally increases the model capacity by restoring and retraining the pruned weights. At testing time, the final model produced by DSD still has the same architecture and dimension as the original dense model, and DSD training doesn’t incur any inference overhead. We experimented DSD training on 7 mainstream CNN / RNN / LSTMs and found consistent performance gains over its comparable counterpart for image classification, image captioning and speech recognition.","Deep speech 2: End-to-end speech recognition in english and mandarin | Sparsity and incoherence in compressive sampling | Identifying and attacking the saddle point problem in high-dimensional non-convex optimization | Learning both weights and connections for efficient neural network | Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding | Deep speech: Scaling up end-to-end speech recognition | Second order derivatives for network pruning: Optimal brain surgeon | Deep residual learning for image recognition | Distilling the knowledge in a neural network | Simulated annealing: theory and applications | BVLC caffe model zoo | Training skinny deep neural networks with iterative hard thresholding methods | Deep visual-semantic alignments for generating image descriptions | Sparse online learning via truncated gradient | Optimal brain damage | Effective approaches to attention-based neural machine translation | All you need is a good init | A simple weight decay can improve generalization | Very deep convolutional networks for large-scale image recognition | Dropout: A simple way to prevent neural networks from overfitting | Going deeper with convolutions | Regularization of neural networks using dropconnect | High dimensional expectation-maximization algorithm: Statistical optimization and asymptotic normality | Truncated power method for sparse eigenvalue problems",iclr,010
371.pdf.json,LEARNING PHYSICAL DYNAMICS,"Endowing an agent with a program for physical reasoning constrains the agent’s representation of the environment by establishing a prior on the environment’s physics. The agent can leverage these constraints to rapidly learn new tasks, to flexibly adapt to changes in inputs and goals, and to naturally generalize reasoning to novel scenes (Lake et al., 2016). For example, a foundational sense of intuitive physics is a prior that guides humans to decompose a scene into objects and carry expectations of object boundaries and motion across different scenarios (Spelke, 1990). Humans perceive balls on a billiard table not as meaningless patches of color but rather as impermeable objects. They expect balls moving toward each other to bounce a certain way after a collision rather than pass through each other, crumble into pieces, or disperse into smoke. Replace one billiard ball with a bowling ball and expectations for ball-to-ball interactions will differ, but the underlying sense of inertia and collisions remain. Arrange immovable wooden obstacles on the table and expectations for how a ball’s surface interacts with wood remain constant regardless of how the obstacles are arranged. The ability to plan trajectories in this space without having to relearn physics from scratch each time, regardless of whether there are three balls or eight balls, whether there are obstacles or not, whether obstacles are arranged in one way or another, whether or not the configuration of objects has been seen before, suggests that humans leverage a prior on physics to reason at a level of abstraction where objects, relations, and events are primitive. This paper explores the question of building this prior into an agent as a program. We view this program as a simulator that takes input provided by a physical scene and the past states of objects, and outputs the future states and physical properties of relevant objects (Anderson, 1990; Battaglia et al., 2013; Goodman and Tenenbaum, 2016). Our ","Structure and interpretation of computer programs | Learning to poke by poking: Experiential learning of intuitive physics | Social lstm: Human trajectory prediction in crowded spaces. 2016 | Cognitive psychology and its implications | Learning to compose neural networks for question answering | Humans predict liquid dynamics using probabilistic simulation | Interaction networks for learning about objects, relations and physics | Simulation as an engine of physical scene understanding | Physics-based visual understanding | Infogan: Interpretable representation learning by information maximizing generative adversarial nets | Torch7: A matlab-like environment for machine learning | Unsupervised learning by program synthesis | Attend, infer, repeat: Fast scene understanding with generative models | Unsupervised learning for physical interaction through video prediction | Learning visual predictive models of physics for playing billiards | Terpret: A probabilistic programming language for program induction | Noisy newtons: Unifying process and dependency accounts of causal attribution | Probabilistic models of cognition, 2016 | Neuroanimator: Fast neural network emulation and control of physics-based models | Internal physics models guide probabilistic judgments about object dynamics | Transforming auto-encoders | Long short-term memory | Structural-rnn: Deep learning on spatio-temporal graphs | Inverse graphics with probabilistic cad models | Picture: A probabilistic programming language for scene perception | Deep convolutional inverse graphics network | Human-level concept learning through probabilistic program induction | Building machines that learn and think like people | rnn: Recurrent library for torch | Learning physical intuition of block towers by example | To fall or not to fall: A visual approach to physical stability prediction | Gated graph sequence neural networks | Newtonian image understanding: Unfolding the dynamics of objects in static images | if...” learning to predict the effect of forces in images | Dynamics of target selection in multiple object tracking (mot) | The graph neural network model | Sources of uncertainty in intuitive physics | Dynamic pooling and unfolding recursive autoencoders for paraphrase detection | Program synthesis by sketching | Principles of object perception | Unsupervised learning of video representations using lstms | The recurrent temporal restricted boltzmann machine | Lecture 6.5—RmsProp: Divide the gradient by a running average of its recent magnitude | Learning physics from dynamical scenes | Understanding visual concepts with continuation learning | Galileo: Perceiving physical object properties by integrating a physics engine with deep learning | Physics 101: Learning physical object properties from unlabeled videos | 50 and used a 70-15-15 split for training, validation, and test data. All models are implemented using the neural network libraries built by Collobert et al",iclr,010
372.pdf.json,,"Machine learning systems have been successful in many domains, from computer vision (Krizhevsky et al., 2012) to speech recognition (Hinton et al., 2012) and machine translation (Sutskever et al., 2014; Bahdanau et al., 2014; Cho et al., 2014). Neural machine translation (NMT) is so successful that for some language pairs it approaches, on average, the quality of human translators (Wu et al., 2016). The words on average are crucial though. When a sentence resembles one from the abundant training data, the translation will be accurate. However, when encountering a rare word such as Dostoevsky (in German, Dostojewski), many models will fail. The correct German translation of Dostoevsky does not appear enough times in the training data for the model to sufficiently learn its translation. While more example sentences concerning the famous Russian author might eventually be added to the training data, there are many other rare words or rare events of other kinds. This illustrates a general problem with current deep learning models: it is necessary to extend the training data and re-train them to handle such rare or new events. Humans, on the other hand, learn in a life-long fashion, often from single examples. We present a life-long memory module that enables one-shot learning in a variety of neural networks. Our memory module consists of key-value pairs. Keys are activations of a chosen layer of a neural network, and values are the ground-truth targets for the given example. This way, as the network is trained, its memory increases and becomes more useful. Eventually it can give predictions that ∗First two authors contributed equally. †Work done as a member of the Google Brain Residency program (g.co/brainresidency). ‡Work done during internship at Google Brain. leverage on knowledge from past data with similar activations. Given a new example, the network writes it to memory and is able to use it afterwards, even if the example was presented just once. There are many a","Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions | Neural machine translation by jointly learning to align and translate | Large-scale simple question answering with memory | Hierarchical memory networks | Learning phrase representations using rnn encoder-decoder for statistical machine translation | One-shot learning of object categories | Dynamic neural turing machine with soft and hard addressing schemes | The goldilocks principle: Reading children’s books with explicit memory | Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups | Long short-term memory | Approximate nearest neighbors: towards removing the curse of dimensionality | Can active memory replace attention | Adam: A method for stochastic optimization | Siamese neural networks for one-shot image recognition | Imagenet classification with deep convolutional neural network | Order matters: Sequence to sequence for sets | Matching networks for one shot learning | Scaling memory-augmented neural networks with sparse reads and writes | Facenet: A unified embedding for face recognition and clustering | Weakly supervised memory | Sequence to sequence learning with neural networks | Matching networks for one shot learning | Distance metric learning for large margin nearest neighbor classification | Wsabie: Scaling up to large vocabulary image annotation | Show, attend and tell: Neural image caption generation with visual attention | Reinforcement learning neural turing machines",iclr,010
373.pdf.json,,"Sequence tagging is an important problem in natural language processing, which has wide applications including part-of-speech (POS) tagging, text chunking, and named entity recognition (NER). Given a sequence of words, sequence tagging aims to predict a linguistic tag for each word such as the POS tag. An important challenge for sequence tagging is how to transfer knowledge from one task to another, which is often referred to as transfer learning (Pan & Yang, 2010). Transfer learning can be used in several settings, notably for low-resource languages (Zirikly & Hagiwara, 2015; Wang & Manning, 2014) and low-resource domains such as biomedical corpora (Kim et al., 2003) and Twitter corpora (Ritter et al., 2011)). In these cases, transfer learning can improve performance by taking advantage of more plentiful labels from related tasks. Even on datasets with relatively abundant labels, multi-task transfer can sometimes achieve improvement over state-of-the-art results (Collobert et al., 2011). Recently, a number of approaches based on deep neural networks have addressed the problem of sequence tagging in an end-to-end manner (Collobert et al., 2011; Lample et al., 2016; Ling et al., 2015; Ma & Hovy, 2016). These neural networks consist of multiple layers of neurons organized in a hierarchy and can transform the input tokens to the output labels without explicit hand-engineered feature extraction. The aforementioned neural networks require minimal assumptions about the task at hand and thus demonstrate significant generality—one single model can be applied to multiple applications in multiple languages without changing the architecture. A natural question is whether the representation learned from one task can be useful for another task. In other words, is there a way we can exploit the generality of neural networks to improve task performance by sharing model parameters and feature representations with another task? To address the above question, we study the transfer le",Polyglot: Distributed word representations for multilingual nlp | A framework for learning predictive structures from multiple tasks and unlabeled data | A token centric part-of-speech tagger for biomedical text | Co-training for domain adaptation | Named entity recognition with bidirectional lstm-cnns | On the properties of neural machine translation: Encoder-decoder approaches | Natural language processing (almost) from scratch | Adaptive subgradient methods for online learning and stochastic optimization | Hierarchical bayesian domain adaptation | Multilingual language processing from bytes | Softmax-margin crfs: Training log-linear models with cost functions | Bidirectional lstm-crf models for sequence tagging | Genia corpusa semantically annotated corpus for bio-textmining | New transfer learning techniques for disparate label sets | Neural architectures for named entity recognition | Finding function in form: Compositional character models for open vocabulary word representation | Joint named entity recognition and disambiguation | End-to-end sequence labeling via bi-directional lstm-cnns-crf | A survey on transfer learning | Lexicon infused phrase embeddings for named entity resolution | Improving named entity recognition for chinese social media with word segmentation representation learning | Glove: Global vectors for word representation | Design challenges and misconceptions in named entity recognition | Named entity recognition in tweets: an experimental study | Flors: Fast and simple domain adaptation for part-of-speech tagging | Feature-rich part-of-speech tagging with a cyclic dependency network | Cross-lingual pseudo-projected expectation regularization for weakly supervised learning | Inducing multilingual text analysis tools via robust projection across aligned corpora | Cross-lingual transfer of named entity recognizers without parallel corpora,iclr,010
374.pdf.json,,"Finding semantically meaningful representations of the words (also called tokens) in a document is necessary for strong performance in Natural Language Processing tasks. In neural networks, tokens are mainly represented in two ways, either using word-level representations or character-level representations. Word-level representations are obtained from a lookup table, where each unique token is represented as a vector. Character-level representations are usually obtained by applying recurrent neural networks (RNNs) or convolutional neural networks (CNNs) on the character sequence of the token, and their hidden states are combined to form the representation. Word-level representations are good at memorizing the semantics of the tokens while character-level representations are more suitable for modeling sub-word morphologies (Ling et al., 2015; Yang et al., 2016a). For example, considering “cat” and “cats”, word-level representations can only learn the similarities between the two tokens by training on a large amount of training data, while character-level representations, by design, can easily capture the similarities. Character-level representations are also used to alleviate the difficulties of modeling out-of-vocabulary (OOV) tokens (Luong & Manning, 2016). Hybrid word-character models have been proposed to leverage the advantages of both word-level and character-level representations. The most commonly used method is to concatenate these two representations (Yang et al., 2016a). However, concatenating word-level and character-level representations is technically problematic. For frequent tokens, the word-level representations are usually accurately estimated during the training process, and thus introducing character-level representations can potentially bias the entire representations. For infrequent tokens, the estimation of wordlevel representations have high variance, which will have negative effects when combined with the character-level representations. To a","Neural machine translation by jointly learning to align and translate | A thorough examination of the cnn/daily mail reading comprehension | On the properties of neural machine translation: Encoder-decoder approaches | Natural language processing (almost) from scratch | Attention-over-attention neural networks for reading comprehension | Gated-attention readers for text comprehension | Tweet2vec: Character-based distributed representations for social media | Teaching machines to read and comprehend | The goldilocks principle: Reading children’s books with explicit memory representations | Long short-term memory | Text understanding with the attention sum reader network | Character-aware neural language models | Finding function in form: Compositional character models for open vocabulary word representation | Achieving open vocabulary neural machine translation with hybrid word-character models | Gated word-character recurrent language model | Neural semantic encoders | Who did what: A large-scale person-centered cloze dataset | Squad: 100,000+ questions for machine comprehension of text | Attending to characters in neural sequence labeling models | Iterative alternating neural attention for machine reading | Natural language comprehension with the epireader | Machine comprehension using match-lstm and answer pointer | On multiplicative integration with recurrent neural networks | Learning multi-relational semantics using neural-embedding models | Multi-task cross-lingual sequence tagging from scratch | Review networks for caption generation | End-to-end answer chunk extraction and ranking for reading comprehension",iclr,010
375.pdf.json,,"Word embeddings computed using diverse methods are basic building blocks for Natural Language Processing (NLP) and Information Retrieval (IR). They capture the similarities between words (e.g., (Bengio et al., 2003; Collobert & Weston, 2008; Mikolov et al., 2013a; Pennington et al., 2014)). Recent work has tried to compute embeddings that capture the semantics of word sequences (phrases, sentences, and paragraphs), with methods ranging from simple additional composition of the word vectors to sophisticated architectures such as convolutional neural networks and recurrent neural networks (e.g., (Iyyer et al., 2015; Le & Mikolov, 2014; Kiros et al., 2015; Socher et al., 2011; Blunsom et al., 2014; Tai et al., 2015; Wang et al., 2016)). Recently, (Wieting et al., 2016) learned general-purpose, paraphrastic sentence embeddings by starting with standard word embeddings and modifying them based on supervision from the Paraphrase pairs dataset (PPDB), and constructing sentence embeddings by training a simple word averaging model. This simple method leads to better performance on textual similarity tasks than a wide variety of methods and serves as a good initialization for textual classification tasks. However, supervision from the paraphrase dataset seems crucial, since they report that simple average of the initial word embeddings does not work very well. Here we give a new sentence embedding method that is embarrassingly simple: just compute the weighted average of the word vectors in the sentence and then remove the projections of the average vectors on their first principal component (“common component removal”). Here the weight of a word w is a/(a+ p(w)) with a being a parameter and p(w) the (estimated) word frequency; we call this smooth inverse frequency (SIF). This method achieves significantly better performance than the unweighted average on a variety of textual similarity tasks, and on most of these tasks even beats some sophisticated supervised methods tested ","Semeval-2012 task 6: A pilot on semantic textual similarity | Sem 2013 shared task: Semantic textual similarity. in second joint conference on lexical and computational semanOn the random order datasets, the hyperparameters are enumerated | Semeval-2014 task 10: Multilingual semantic textual similarity | Semeval-2015 task 2: Semantic textual similarity, english, spanish and pilot on interpretability | A latent variable model approach to PMI-based word embeddings | A neural probabilistic language model | A comparison of vector-based representations for semantic composition | A convolutional neural network for modelling sentences | A large annotated corpus for learning natural language inference | N-gram counts and language models from the common crawl | A unified architecture for natural language processing: Deep neural networks with multitask learning | Indexing by latent semantic analysis | Learning precise timing with lstm recurrent networks | Word embeddings as metric recovery in semantic spaces. Transactions of the Association for Computational Linguistics, 2016 | Long short-term memory | Deep unordered composition rivals syntactic methods for text classification | Skip-thought vectors | Distributed representations of sentences and documents | Neural word embedding as implicit matrix factorization | Learning word vectors for sentiment analysis | Wikipedia text preprocess script | Semeval-2014 task 1: Evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual entailment | Distributed representations of words and phrases and their compositionality | Linguistic regularities in continuous space word representations | Vector-based models of semantic composition | Composition in distributional models of semantics | Ppdb 2.0: Better paraphrase ranking, fine-grained entailment relations, word embeddings, and style classification | Glove: Global vectors for word representation | Understanding inverse document frequency: on theoretical arguments for idf | Dynamic pooling and unfolding recursive autoencoders for paraphrase detection | Recursive deep models for semantic compositionality over a sentiment treebank | Grounded compositional semantics for finding and describing images with sentences | A statistical interpretation of term specificity and its application in retrieval | Improved semantic representations from tree-structured long short-term memory networks | Baselines and bigrams: Simple, good sentiment and topic classification | Cse: Conceptual sentence embeddings based on attention model | From paraphrase database to compositional paraphrase model and back | Towards universal paraphrastic sentence embeddings | Semeval-2015 task 1: Paraphrase and semantic similarity in twitter (pit) | Predicting response to political blog posts with topic models | summary, both techniques are important for obtaining significant advantage over the unweighted average. A.2 SUPERVISED TASKS Setup of supervised tasks mostly follow (Wieting et al., 2016) to allow fair comparison: the sentence embeddings are fixed and fed into some classifier",iclr,010
376.pdf.json,,"Research and application of recurrent neural networks (RNNs) have seen explosive growth over the last few years, (Martens & Sutskever, 2011; Graves et al., 2009), and RNNs have become the central component for some very successful model classes and application domains in deep learning (speech recognition (Amodei et al., 2015), seq2seq (Sutskever et al., 2014), neural machine translation (Bahdanau et al., 2014), the DRAW model (Gregor et al., 2015), educational applications (Piech et al., 2015), and scientific discovery (Mante et al., 2013)). Despite these recent successes, it is widely acknowledged that designing and training the RNN components in complex models can be extremely tricky. Painfully acquired RNN expertise is still crucial to the success of most projects. One of the main strategies involved in the deployment of RNN models is the use of the Long Short Term Memory (LSTM) networks (Hochreiter & Schmidhuber, 1997), and more recently the Gated Recurrent Unit (GRU) proposed by Cho et al. (2014); Chung et al. (2014) (we refer to these as gated architectures). The resulting models are perceived as being more easily trained, and achieving lower error. While it is widely appreciated that RNNs are universal approximators (Doya, 1993), an unresolved question is the degree to which gated models are more computationally powerful in practice, as opposed to simply being easier to train. Here we provide evidence that the observed superiority of gated models over vanilla RNN models is almost exclusively driven by trainability. First we describe two types of capacity bottlenecks that various RNN architectures might be expected to suffer from: parameter efficiency related to learning the task, and the ability to remember input history. Next, we describe our experimental setup where we disentangle the effects of these two bottlenecks, including training with extremely thorough hyperparameter (HP) optimization. Finally, we describe our capacity experiment results ∗Work done ","Neural machine translation by jointly learning to align and translate | Number of stable points for spin-glasses and neural networks of higher orders | Nanoconnectomic upper bound on the variability of synaptic plasticity | Short-term memory capacity in networks via the restricted isometry property | Learning phrase representations using rnn encoder-decoder for statistical machine translation | Empirical evaluation of gated recurrent neural networks on sequence modeling | Geometrical and statistical properties of systems of linear inequalities with applications in pattern recognition | Parallelizing exploration-exploitation tradeoffs in gaussian process bandit optimization | Universality of fully connected recurrent neural networks | Intelligible language modeling with input switched affine networks | Memory traces in dynamical systems | The space of interactions in neural network models | Learning to forget: Continual prediction with lstm | A novel connectionist system for unconstrained handwriting recognition | Lstm: A search space odyssey | Draw: A recurrent neural network for image generation | Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding | Deep residual learning for image recognition | Long short-term memory | Harnessing nonlinearity: Predicting chaotic systems and saving energy in wireless communication | An empirical exploration of recurrent network architectures | Exploring the limits of language modeling | Visualizing and understanding recurrent networks | Adam: A method for stochastic optimization | Vapnik-chervonenkis dimension of recurrent neural networks | A simple way to initialize recurrent networks of rectified linear units | Real-time computing without stable states: A new framework for neural computation based on perturbations | Large text compression benchmark: About the test data, 2011. URL http://mattmahoney. net/dc/textdata. [Online; accessed 15-November-2016 | Context-dependent computation by recurrent dynamics in prefrontal cortex | Learning recurrent neural networks with hessian-free optimization | Deep knowledge tracing | Outrageously large neural networks: The sparsely-gated mixture-of-experts | Practical bayesian optimization of machine learning algorithms | Opening the black box: low-dimensional dynamics in high-dimensional recurrent neural networks | Sequence to sequence learning with neural networks. In Advances in neural information processing | Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude | Short-term memory in orthogonal neural networks | Deep fried convnets | Minimal gated unit for recurrent neural networks",iclr,010
377.pdf.json,DEEP REINFORCEMENT LEARNING,"Our work is inspired by empirical findings and theories in psychology indicating that infant learning and thinking is similar to that of adult scientists (Gopnik, 2012). One important view in developmental science is that babies are endowed with a small number of separable systems of core knowledge for reasoning about objects, actions, number, space, and possibly social interactions (Spelke & Kinzler, 2007). The object core system covering aspects such as cohesion, continuity, and contact, enables babies and other animals to solve object related tasks such as reasoning about oclusion and predicting how objects behave. Core knowledge research has motivated the development of methods that endow agents with physics priors and perception modules so as to infer intrinsic physical properties rapidly from data (Battaglia et al., 2013; Wu et al., 2015; 2016; Stewart & Ermon, 2016). For instance, using physics engines and mental simulation, it becomes possible to infer quantities such as mass from visual input (Hamrick et al., 2016; Wu et al., 2015). In early stages of life, infants spend a lot of time interacting with objects in a seemingly random manner (Smith & Gasser, 2005). They interact with objects in multiple ways, including throwing, pushing, pulling, breaking, and biting. It is quite possible that this process of actively engaging with objects and watching the consequences of their actions helps infants understand different physical properties of the object which cannot be observed directly using their sensory systems. It seems infants run a series of “physical” experiments to enhance their knowledge about the world (Gopnik, 2012). The act of performing an experiment is useful both for quickly adapting an agent’s policy to a new environment and for understanding object properties in a holistic manner. Despite impressive advances in artificial intelligence that have led to superhuman performance in Go, Atari and natural language processing, it is still unclear if th","Learning to see by moving | Learning to poke by poking: Experiential learning of intuitive physics | Dataefficient learning of feedback policies from image pixels using deep dynamical models | Best arm identification in multi-armed bandits | Active viewing in toddlers facilitates visual object learning: An egocentric vision approach | Simulation as an engine of physical scene understanding | Scene semantics from long-term observation of people | Unsupervised visual representation learning by context prediction | People watching: Human actions as a cue for single view geometry | Learning visual predictive models of physics for playing billiards | Generative adversarial nets | Scientific thinking in young children: Theoretical advances, empirical research, and policy implications | Inferring mass in complex scenes by mental | Deep residual learning for image recognition | Mechanical reasoning by mental simulation | Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups | Learning image representations tied to ego-motion | Look-ahead before you leap: End-to-end active recognition by forecasting the effect of motion | Auto-encoding variational bayes | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | Human-level concept learning through probabilistic program induction | Learning physical intuition of block towers by example | Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection | Asynchronous methods for deep reinforcement learning | what happens if | Action-conditional video prediction using deep networks in Atari games | Visually indicated sounds | Ambient sound provides supervision for visual learning | Supersizing self-supervision: Learning to grasp from 50k tries and 700 robot hours | The curious robot: Learning visual representations via physical interactions | Video (language) modeling: a baseline for generative models of natural videos | The development of embodied cognition: Six lessons from babies | Unsupervised learning of video representations using lstms | Label-free supervision of neural networks with physics and domain knowledge | Horde: A scalable real-time architecture for learning knowledge from unsupervised sensorimotor interaction | Pixel recurrent neural networks | Embed to control: A locally linear latent dynamics model for control from raw images | Galileo: Perceiving physical object properties by integrating a physics engine with deep learning | Physics 101: Learning physical object properties from unlabeled videos | Visual dynamics: Probabilistic future frame synthesis via cross convolutional networks | Colorful image colorization",iclr,010
378.pdf.json,EXPLORING UNDER-APPRECIATED REWARDS,"Humans can reason about symbolic objects and solve algorithmic problems. After learning to count and then manipulate numbers via simple arithmetic, people eventually learn to invent new algorithms and even reason about their correctness and efficiency. The ability to invent new algorithms is fundamental to artificial intelligence (AI). Although symbolic reasoning has a long history in AI (Russell et al., 2003), only recently have statistical machine learning and neural network approaches begun to make headway in automated algorithm discovery (Reed & de Freitas, 2016; Kaiser & Sutskever, 2016; Neelakantan et al., 2016), which would constitute an important milestone on the path to AI. Nevertheless, most of the recent successes depend on the use of strong supervision to learn a mapping from a set of training inputs to outputs by maximizing a conditional log-likelihood, very much like neural machine translation systems (Sutskever et al., 2014; Bahdanau et al., 2015). Such a dependence on strong supervision is a significant limitation that does not match the ability of people to invent new algorithmic procedures based solely on trial and error. By contrast, reinforcement learning (RL) methods (Sutton & Barto, 1998) hold the promise of searching over discrete objects such as symbolic representations of algorithms by considering much weaker feedback in the form of a simple verifier that tests the correctness of a program execution on a given problem instance. Despite the recent excitement around the use of RL to tackle Atari games (Mnih et al., 2015) and Go (Silver et al., 2016), standard RL methods are not yet able to consistently and reliably solve algorithmic tasks in all but the simplest cases (Zaremba & Sutskever, 2014). A key property of algorithmic problems that makes them challenging for RL is reward sparsity, i.e., a policy usually has to get a long action sequence exactly right to obtain a non-zero reward. ∗Work done as a member of the Google Brain Residency prog","Tensorflow: A system for largescale machine learning | Learning regular sets form queries and counterexamples | A new softmax operator for reinforcement learning | Dynamic policy programming | Neural machine translation by jointly learning to align and translate | Unifying count-based exploration and intrinsic motivation | G-learning: Taming the noise in reinforcement learning via soft updates. Uncertainty in Artifical Intelligence, 2016 | Some modified matrix eigenvalue problems | Hybrid computing using a neural network with dynamic external memory. Nature, 2016 | Long short-term memory | Learning in embedded systems | Near-optimal reinforcement learning in polynomial time | Learning and using relational theories | Adam: A method for stochastic optimization | Inductive Logic Programming: Theory and Methods | Playing atari with deep reinforcement learning | Human-level control through deep reinforcement learning | Asynchronous methods for deep reinforcement learning | Machine Learning: A Probabilistic Perspective | Neural programmer: Inducing latent programs with gradient descent | Reward augmented maximum likelihood for neural structured prediction | Deep exploration via bootstrapped DQN | Monte Carlo theory, methods and examples | Reinforcement learning by reward-weighted regression for operational space control | Artificial intelligence: a modern approach, volume 2. Prentice hall | Prioritized experience replay | Optimal artificial curiosity, creativity, music, and the fine arts | Highdimensional continuous control using generalized advantage estimation | Mastering the game of Go with deep neural networks and tree search | Incentivizing exploration in reinforcement learning with deep predictive models | Sequence to sequence learning with neural networks | Introduction to Reinforcement Learning | Efficient exploration in reinforcement learning | Adaptive ε-greedy exploration in reinforcement learning based on value differences | Deep reinforcement learning with double qlearning | Episodic reinforcement learning by logistic reward-weighted regression | Simple statistical gradient-following algorithms for connectionist reinforcement learning | Function optimization using connectionist reinforcement learning algorithms | Reinforcement learning neural turing machines | Modeling purposeful adaptive behavior with the principle of maximum causal entropy",iclr,010
379.pdf.json,DYNAMIC COMPUTATION GRAPHS,"Training deep neural networks directly on minimally pre-processed corpora has led to many recent performance breakthroughs, mainly on problems in domains such as vision (Krizhevsky et al., 2012) and natural language (Bahdanau et al., 2015) where the inputs can be cast as dense n-dimensional arrays (henceforth tensors), or sequences of tensors. These successes exploit the effectiveness of training via gradient descent on mini-batches of tens to hundreds of inputs, implemented using the parallel SIMD capabilities of modern GPUs (Oh & Jung, 2004) and multi-core CPUs (Vanhoucke et al., 2011). This, in turn has led to a proliferation of libraries making it easier to train and deploy such models, by expressing them in terms of differentiable data-flow graphs over tensors (Abadi et al., 2016; Theano Development Team, 2016; Collobert et al., 2011). However, there is also a long history of neural networks that compute over structures such as parse trees (Pollack, 1990), logical terms (Goller & Kuchler, 1996), and molecular graphs (Bianucci et al., 2000). In these models, each distinct input has a different computation graph structure; we say that they use dynamic computation graphs (DCGs). Such models continue to be developed and have recently yielded superior results on problems such as sentiment classification and semantic relatedness (Tai et al., 2015; Li et al., 2015), question-answering (Andreas et al., 2016), and screening of chemical compounds (Kearnes et al., 2016). Despite these successes, most practitioners avoid DCGs for implementation reasons. For example, Bowman et al. (2016) assert that “because TreeRNNs use a different model structure for each sentence ... efficient batching is impossible in standard implementations”. Moreover, even if efficient batching were possible in principle, current libraries such as TensorFlow (Abadi et al., 2016) assume that the data-flow graph is static (i.e. is the same for each input) and impose a significant cost to graph construc",TensorFlow: Large-scale machine learning | Learning to compose neural networks for question answering | Neural machine translation by jointly learning to align and translate | Application of cascade correlation networks for structures to chemistry | A fast unified model for parsing and sentence understanding | Torch7: A Matlab-like environment for machine learning | Learning task-dependent distributed representations by backpropagation through structure | Generalising monads to arrows | Monadic parser combinators | Molecular graph convolutions: moving beyond fingerprints | Imagenet classification with deep convolutional neural networks | When are tree structures necessary for deep learning of representations? arXiv | Neural tree indexers for text understanding | GPU implementation of neural networks | Recursive distributed representations | Feed-forward networks with attention can solve some long-term memory problems | Recurrent dropout without memory | Improved semantic representations from tree-structured long short-term memory networks | Improving the speed of neural networks on CPUs,iclr,010
380.pdf.json,CALIBRATING ENERGY-BASED GENERATIVE ADVER-,"Generative Adversarial Networks (GANs) (Goodfellow et al., 2014) represent an important milestone on the path towards more effective generative models. GANs cast generative model training as a minimax game between a generative network (generator), which maps a random vector into the data space, and a discriminative network (discriminator), whose objective is to distinguish generated samples from real samples. Multiple researchers Radford et al. (2015); Salimans et al. (2016); Zhao et al. (2016) have shown that the adversarial interaction with the discriminator can result in a generator that produces compelling samples. The empirical successes of the GAN framework were also supported by the theoretical analysis of Goodfellow et al., who showed that, under certain conditions, the distribution produced by the generator converges to the true data distribution, while the discriminator converges to a degenerate uniform solution. While GANs have excelled as compelling sample generators, their use as general purpose probabilistic generative models has been limited by the difficulty in using them to provide density estimates or even unnormalized energy values for sample evaluation. It is tempting to consider the GAN discriminator as a candidate for providing this sort of scoring function. Conceptually, it is a trainable sample evaluation mechanism that – owing to GAN training paradigm – could be closely calibrated to the distribution modeled by the generator. If the discriminator could retain fine-grained information of the relative quality of samples, measured for instance by probability density or unnormalized energy, it could be used as an evaluation metric. Such data-driven evaluators would be highly desirable for problems where it is difficult to define evaluation criteria that correlate well with human judgment. Indeed, the real-valued discriminator of the recently introduced energy-based GANs Zhao et al. (2016) might seem like an ideal candidate energy function. Unfor","Apprenticeship learning via inverse reinforcement learning | Generative adversarial nets | Generative adversarial imitation learning | Deep directed generative models with energy-based probability estimation | Algorithms for inverse reinforcement learning | f-gan: Training generative neural samplers using variational divergence minimization | Unsupervised representation learning with deep convolutional generative adversarial networks | Improved techniques for training gans | Energy-based generative adversarial network | Maximum entropy inverse reinforcement learning | 2016), the training objectives of the generator and the discriminator cannot be written",iclr,010
381.pdf.json,PRUNING CONVOLUTIONAL NEURAL NETWORKS FOR RESOURCE EFFICIENT INFERENCE,"Convolutional neural networks (CNN) are used extensively in computer vision applications, including object classification and localization, pedestrian and car detection, and video classification. Many problems like these focus on specialized domains for which there are only small amounts of carefully curated training data. In these cases, accuracy may be improved by fine-tuning an existing deep network previously trained on a much larger labeled vision dataset, such as images from ImageNet (Russakovsky et al., 2015) or videos from Sports-1M (Karpathy et al., 2014). While transfer learning of this form supports state of the art accuracy, inference is expensive due to the time, power, and memory demanded by the heavyweight architecture of the fine-tuned network. While modern deep CNNs are composed of a variety of layer types, runtime during prediction is dominated by the evaluation of convolutional layers. With the goal of speeding up inference, we prune entire feature maps so the resulting networks may be run efficiently even on embedded devices. We interleave greedy criteria-based pruning with fine-tuning by backpropagation, a computationally efficient procedure that maintains good generalization in the pruned network. Neural network pruning was pioneered in the early development of neural networks (Reed, 1993). Optimal Brain Damage (LeCun et al., 1990) and Optimal Brain Surgeon (Hassibi & Stork, 1993) leverage a second-order Taylor expansion to select parameters for deletion, using pruning as regularization to improve training and generalization. This method requires computation of the Hessian matrix partially or completely, which adds memory and computation costs to standard fine-tuning. In line with our work, Anwar et al. (2015) describe structured pruning in convolutional layers at the level of feature maps and kernels, as well as strided sparsity to prune with regularity within kernels. Pruning is accomplished by particle filtering wherein configurations are we","Learning the Number of Neurons in Deep Networks | Structured pruning of deep convolutional neural networks | An estimator for the diagonal of a matrix | Bird species categorization using pose normalized deep convolutional nets | Equilibrated adaptive learning rates for nonconvex optimization | PerforatedCNNs: Acceleration through elimination of redundant convolutions | Deep learning with limited numerical precision | Learning both weights and connections for efficient neural network | EIE: Efficient inference engine on compressed deep neural network | Second order derivatives for network pruning: Optimal brain surgeon | Network trimming: A data-driven neuron pruning approach towards efficient deep architectures | Large-scale video classification with convolutional neural networks | Compression of deep convolutional neural networks for fast and low power mobile applications | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | maxDNN: An Efficient Convolution Kernel for Deep Learning with Maxwell | Fast algorithms for convolutional neural networks | Fast convnets using group-wise brain damage | Optimal brain damage | Efficient BackProp, pp. 9–50 | Deep learning via Hessian-free optimization | Estimating the Hessian by back-propagating curvature | Online detection and classification of dynamic hand gestures with recurrent 3d convolutional neural network | Automated flower classification over a large number of classes | Fast Exact Multiplication by the Hessian | XNOR-Net: ImageNet Classification | Pruning algorithms-a survey | ImageNet Large Scale Visual Recognition Challenge | Very deep convolutional networks for large-scale image recognition | Data-free parameter pruning for deep neural networks | Learning structured sparsity in deep neural networks | Less is more: Towards compact cnns | A comparison between pruning based on regularization and our greedy scheme is illustrated in Fig. 12. We observe that our approach has higher test accuracy for the same number of remaining unpruned feature maps, when pruning 85% or more of the feature maps",iclr,010
383.pdf.json,DESIGNING NEURAL NETWORK ARCHITECTURES,"Deep convolutional neural networks (CNNs) have seen great success in the past few years on a variety of machine learning problems (LeCun et al., 2015). A typical CNN architecture consists of several convolution, pooling, and fully connected layers. While constructing a CNN, a network designer has to make numerous design choices: the number of layers of each type, the ordering of layers, and the hyperparameters for each type of layer, e.g., the receptive field size, stride, and number of receptive fields for a convolution layer. The number of possible choices makes the design space of CNN architectures extremely large and hence, infeasible for an exhaustive manual search. While there has been some work (Pinto et al., 2009; Bergstra et al., 2013; Domhan et al., 2015) on automated or computer-aided neural network design, new CNN architectures or network design elements are still primarily developed by researchers using new theoretical insights or intuition gained from experimentation. In this paper, we seek to automate the process of CNN architecture selection through a metamodeling procedure based on reinforcement learning. We construct a novel Q-learning agent whose goal is to discover CNN architectures that perform well on a given machine learning task with no human intervention. The learning agent is given the task of sequentially picking layers of a CNN model. By discretizing and limiting the layer parameters to choose from, the agent is left with a finite but large space of model architectures to search from. The agent learns through random exploration and slowly begins to exploit its findings to select higher performing models using the - greedy strategy (Mnih et al., 2015). The agent receives the validation accuracy on the given machine learning task as the reward for selecting an architecture. We expedite the learning process through repeated memory sampling using experience replay (Lin, 1993). We refer to this Q-learning based meta-modeling method as MetaQNN,","Experience replay for real-time reinforcement learning control | Making a science of model search: Hyperparameter optimization in hundreds of dimensions for vision architectures | Algorithms for hyper-parameter optimization | Convex optimization algorithms | Fast and accurate deep network learning by exponential linear units (ELUs) | Speeding up automatic hyperparameter optimization of deep neural networks by extrapolation of learning curves | Understanding the difficulty of training deep feedforward neural networks | Deep residual learning for image recognition | Identity mappings in deep residual networks | Caffe: Convolutional architecture for fast feature embedding | Reinforcement learning: A survey | Adam: A method for stochastic optimization | Generalizing pooling functions in convolutional neural networks: Mixed | End-to-end training of deep visuomotor policies | Recurrent convolutional neural network for object recognition | Continuous control with deep reinforcement learning | Self-improving reactive agents based on reinforcement learning, planning and teaching | Reinforcement learning for robots using neural networks | Human-level control through deep reinforcement learning | A high-throughput screening approach to discovering good forms of biologically inspired visual representation | Fitnets: Hints for thin deep nets | Convolutional neural fabrics | Combinations of genetic algorithms and neural networks: A survey of the state of the art | Convolutional neural networks applied to house numbers digit classification | Pedestrian detection with unsupervised multi-stage feature learning | Taking the human out of the loop: A review of bayesian optimization | Mastering the game of go with deep neural networks and tree | Very deep convolutional networks for large-scale image recognition | Practical bayesian optimization of machine learning algorithms | Striving for simplicity: The all convolutional net | Evolving neural networks through augmenting topologies | Multi-task bayesian optimization | Generative neuroevolution for deep learning | Multi-armed bandit algorithms and empirical evaluation | Regularization of neural networks using dropconnect | Learning from delayed rewards",iclr,010
384.pdf.json,,"Machine comprehension of text is one of the ultimate goals of natural language processing. While the ability of a machine to understand text can be assessed in many different ways, in recent years, several benchmark datasets have been created to focus on answering questions as a way to evaluate machine comprehension (Richardson et al., 2013; Hermann et al., 2015; Hill et al., 2016; Weston et al., 2016; Rajpurkar et al., 2016; Nguyen et al., 2016). In this setup, typically the machine is first presented with a piece of text such as a news article or a story. The machine is then expected to answer one or multiple questions related to the text. In most of the benchmark datasets, a question can be treated as a multiple choice question, whose correct answer is to be chosen from a set of provided candidate answers (Richardson et al., 2013; Hill et al., 2016). Presumably, questions with more given candidate answers are more challenging. The Stanford Question Answering Dataset (SQuAD) introduced recently by Rajpurkar et al. (2016) contains such more challenging questions whose correct answers can be any sequence of tokens from the given text. Moreover, unlike some other datasets whose questions and answers were created automatically in Cloze style (Hermann et al., 2015; Hill et al., 2016), the questions and answers in SQuAD were created by humans through crowdsourcing, which makes the dataset more realistic. Another real dataset, the Human-Generated MAchine Reading COmprehension dataset (MSMARCO) (Nguyen et al., 2016), provided a query together with several related documents collected from Bing Index. The answer to the query is generated by human and the answer words can not only come from the given text. Given these advantages of the SQuAD and MSMARCO datasets, in this paper, we focus on these new datasets to study machine comprehension of text. A sample piece of text and three of its associated questions from SQuAD are shown in Table 1. Traditional solutions to this kind ","Vqa: Visual question answering | A thorough examination of the CNN/Daily Mail reading comprehension task | Consensus attention-based neural networks for chinese reading comprehension | Multimodal compact bilinear pooling for visual question answering and visual grounding | Incorporating copying mechanism in sequence-to-sequence learning | Teaching machines to read and comprehend | WIKIREADING: A novel large-scale language understanding task over wikipedia | The Goldilocks principle: Reading children’s books with explicit memory representations | Long short-term memory | Text understanding with the attention sum reader network | Adam: A method for stochastic optimization | Ask me anything: Dynamic memory networks for natural language processing | Hierarchical question-image co-attention for visual question answering | MS MARCO: a human generated machine reading comprehension dataset | GloVe: Global vectors for word representation | SQuAD: 100,000+ questions for machine comprehension of text | MCTest: A challenge dataset for the open-domain machine comprehension of text | End-to-end memory networks | MovieQA: Understanding stories in movies through question-answering | Natural language comprehension with the EpiReader | Learning natural language inference with LSTM | Towards AI-complete question answering: A set of prerequisite toy tasks | Ask, attend and answer: Exploring question-guided spatial attention for visual question answering | End-to-end answer chunk",iclr,010
387.pdf.json,,"There are currently two dominant approaches to texture synthesis: non-parametric techniques, which synthesize a texture by extracting pixels (or patches) from a reference image that are resampled for rendering (Efros & Leung, 1999; Kwatra et al., 2003), and parametric statistical models, which optimize reconstructions to match certain statistics computed on filter responses (Heeger & Bergen, 1995; Portilla & Simoncelli, 2000). Recently, the second approach has seen a significant advancement, after Gatys et al. (2015a) showed that a CNN pre-trained on an object classification task, such as ImageNet (Russakovsky et al., 2015), can be very effective at generating textures. Gatys et al. (2015a) propose to minimize with respect to the input image a loss function, that measures how well certain high-level features of a reference image are preserved. The reference image constitutes an example of the texture to be generated. The high-level features to be preserved are pair-wise products of feature responses, averaged over the whole image, referred to as the “Gramian” in that work. In Gatys et al. (2015b), the same authors show that by adding a second term to the cost, which matches the content of another image, one can render that other image in the “style” (texture) of the first. Numerous follow-up works have since then analysed and extended this approach (Ulyanov et al., 2016; Johnson et al., 2016; Ustyuzhaninov et al., 2016). As shown in Figure 1, this method produces impressive results. However, it fails to take into account non-local structure, and consequently cannot generate results that exhibit long-range correlations in images. An example of the importance of long-range structure is the regular brick wall texture in the middle of the figure. Another example is the task of inpainting, where the goal is to fill in a missing part of an image, such that it is faithful to the non-missing pixels. Our main contribution is to introduce a way to deal with long-range structu",Image Quilting for Texture Synthesis and Transfer | Texture synthesis using convolutional neural networks | A neural algorithm of artistic | Texture features for image classification | Pyramid-based texture analysis/synthesis | Perceptual losses for real-time style transfer and super-resolution | Image features from phase congruency | Graphcut textures: Image and video synthesis using graph cuts | Quantitative evaluation on near regular texture synthesis | Analysis and synthesis of textures: A co-occurrence-based approach | Feature detection in human vision: A phase-dependent energy model | The importance of phase in signals | A parametric texture model based on joint statistics of complex wavelet coefficients | Fields of experts: A framework for learning image priors | ImageNet Large Scale Visual Recognition Challenge | Very deep convolutional networks for large-scale image recognition | Texture networks: Feed-forward synthesis of textures and stylized images | Texture synthesis using shallow convolutional networks with random filters | Local phase coherence and the perception of blur | L-bfgs-b - fortran subroutines for large-scale bound constrained optimization,iclr,010
388.pdf.json,,"Question answering (QA) is a crucial task in natural language processing that requires both natural language understanding and world knowledge. Previous QA datasets tend to be high in quality due to human annotation, but small in size (Berant et al., 2014; Richardson et al., 2013). Hence, they did not allow for training data-intensive, expressive models such as deep neural networks. To address this problem, researchers have developed large-scale datasets through semi-automated techniques (Hermann et al., 2015; Hill et al., 2016). Compared to their smaller, hand-annotated counterparts, these QA datasets allow the training of more expressive models. However, it has been shown that they differ from more natural, human annotated datasets in the types of reasoning required to answer the questions (Chen et al., 2016). Recently, Rajpurkar et al. (2016) released the Stanford Question Answering dataset (SQuAD), which is orders of magnitude larger than all previous hand-annotated datasets and has a variety of qualities that culminate in a natural QA task. SQuAD has the desirable quality that answers are spans in a reference document. This constrains answers to the space of all possible spans. However, Rajpurkar et al. (2016) show that the dataset retains a diverse set of answers and requires different forms of logical reasoning, including multi-sentence reasoning. We introduce the Dynamic Coattention Network (DCN), illustrated in Fig. 1, an end-to-end neural network for question answering. The model consists of a coattentive encoder that captures the interactions between the question and the document, as well as a dynamic pointing decoder that alternates between estimating the start and end of the answer span. Our single model obtains an F1 of 75.9% compared to the best published result of 71.0% (Yu et al., 2016). In addition, our ensemble model obtains an F1 of 80.4% compared to the second best result of 78.1% on the official SQuAD leaderboard.1 ∗Equal contribution 1As of No","Vqa: Visual question answering | Modeling biological processes for reading comprehension | On the statistical analysis of dirty pictures | A thorough examination of the cnn/daily mail reading comprehension | Attention-overattention neural networks for reading comprehension | Teaching machines to read and comprehend | The goldilocks principle: Reading children’s books with explicit memory representations | Long short-term memory | Text understanding with the attention sum reader network | Adam: A method for stochastic optimization | Hierarchical question-image co-attention for visual question answering | Effective approaches to attentionbased neural machine translation | The stanford corenlp natural language processing toolkit | Pointer sentinel mixture models | Glove: Global vectors for word representation | Squad: 100,000+ questions for machine comprehension of text | Mctest: A challenge dataset for the open-domain machine comprehension of text | Iterative alternating neural attention for machine reading | Dropout: a simple way to prevent neural networks from overfitting | Training very deep networks | Chainer: a next-generation open source framework for deep learning | Machine comprehension with syntax, frames, and semantics | Learning natural language inference with LSTM | Machine comprehension using match-LSTM and answer pointer | End-to-End Reading Comprehension with Dynamic Answer Chunk Ranking | End-to-end answer chunk extraction and ranking for reading comprehension | WHO DESIGNED THE ILLUMINATION SYSTEMS THAT TESLA ELECTRIC LIGHT & MANUFACTURING INSTALLED? ID 56e0d6cf231d4119001ac424 After leaving Edison’s company Tesla partnered with two businessmen in 1886",iclr,010
389.pdf.json,SAMPLERNN: AN UNCONDITIONAL END-TO-END NEURAL AUDIO GENERATION MODEL,"Audio generation is a challenging task at the core of many problems of interest, such as text-tospeech synthesis, music synthesis and voice conversion. The particular difficulty of audio generation is that there is often a very large discrepancy between the dimensionality of the the raw audio signal and that of the effective semantic-level signal. Consider the task of speech synthesis, where we are typically interested in generating utterances corresponding to full sentences. Even at a relatively low sample rate of 16kHz, on average we will have 6,000 samples per word generated. 1 Traditionally, the high-dimensionality of raw audio signal is dealt with by first compressing it into spectral or hand-engineered features and defining the generative model over these features. However, when the generated signal is eventually decompressed into audio waveforms, the sample quality is often degraded and requires extensive domain-expert corrective measures. This results in complicated signal processing pipelines that are to adapt to new tasks or domains. Here we propose a step in the direction of replacing these handcrafted systems. In this work, we investigate the use of recurrent neural networks (RNNs) to model the dependencies in audio data. We believe RNNs are well suited as they have been designed and are suited solutions for these tasks (see Graves (2013), Karpathy (2015), and Siegelmann (1999)). However, in practice it is a known problem of these models to not scale well at such a high temporal resolution as is found when generating acoustic signals one sample at a time, e.g., 16000 times per second. This is one of the reasons that Oord et al. (2016) profits from other neural modules such as one presented by Yu & Koltun (2015) to show extremely good performance. In this paper, an end-to-end unconditional audio synthesis model for raw waveforms is presented while keeping all the computations tractable.2 Since our model has different modules operating at different clock-r","Modeling high-dimensional discrete data with multi-layer neural networks | Random search for hyper-parameter optimization | Unsupervised learning of auditory filter banks using non-negative matrix factorisation | Empirical evaluation of gated recurrent neural networks on sequence modeling | A recurrent latent variable model for sequential data | Learning to generate chairs, tables and cars with convolutional networks. 2016 | Hierarchical recurrent neural networks for long-term dependencies | Long short-term memory in recurrent neural networks | Generating sequences with recurrent neural networks | Delving deep into rectifiers: Surpassing human-level performance on imagenet classification | Long short-term memory | Web Audio Evaluation Tool: A browser-based listening test environment | The unreasonable effectiveness of recurrent neural networks | Adam: A method for stochastic optimization | A clockwork rnn | The neural autoregressive distribution estimator | Unsupervised feature learning for audio classification using convolutional deep belief networks. In Advances in neural information processing | Wavenet: A generative model for raw audio | The blizzard challenge 2013– indian language task | Weight normalization: A simple reparameterization to accelerate training of deep neural networks | Learning complex, extended sequences using the principle of history compression | Building end-to-end dialogue systems using generative hierarchical neural network models | Computation beyond the turing limit | A hierarchical recurrent encoder-decoder for generative context-aware query suggestion | Speech synthesis based on hidden markov models | Pixel recurrent neural networks | Multi-scale context aggregation by dilated convolutions | An empirical exploration of recurrent network architectures",iclr,010
390.pdf.json,METACONTROL FOR ADAPTIVE IMAGINATION-BASED OPTIMIZATION,"While there have been significant recent advances in deep reinforcement learning (Mnih et al., 2015; Silver et al., 2016) and control (Lillicrap et al., 2015; Levine et al., 2016), most efforts train a network that performs a fixed sequence of computations. Here we introduce an alternative in which an agent uses a metacontroller to choose which, and how many, computations to perform. It “imagines” the consequences of potential actions proposed by an actor module, and refines them internally, before executing them in the world. The metacontroller adaptively decides which expert models to use to evaluate candidate actions, and when it is time to stop imagining and act. The learned experts may be state transition models, action-value functions, or any other function that is relevant to the task, and can vary in their accuracy and computational costs. Our metacontroller’s learned policy can exploit the diversity of its pool of experts by trading off between their costs and reliability, allowing it to automatically identify which expert is most worthwhile. We draw inspiration from research in cognitive science and neuroscience which has studied how people use a meta-level of reasoning in order to control the use of their internal models and allocation of their computational resources. Evidence suggests that humans rely on rich generative models of the world for planning (Gläscher et al., 2010), control (Wolpert & Kawato, 1998), and reasoning (Hegarty, 2004; Johnson-Laird, 2010; Battaglia et al., 2013), that they adapt the amount of computation they perform with their model to the demands of the task (Hamrick et al., 2015), and that they trade off between multiple strategies of varying quality (Lee et al., 2014; Lieder et al., 2014; Lieder & Griffiths, in revision; Kool et al., in press). Our imagination-based optimization approach is related to classic artificial intelligence research on bounded-rational metareasoning (Horvitz, 1988; Russell & Wefald, 1991; Hay et al., ","TensorFlow: Large-scale machine learning on heterogeneous systems | Interaction networks for learning about objects, relations and physics | Adaptive computation time for recurrent neural networks | Selecting computations: Theory and applications | Learning continuous control policies by stochastic value gradients | Adam: A method for stochastic optimization | Asynchronous methods for deep reinforcement learning | On the difficulty of training recurrent neural networks | Principles of metareasoning | Conditional image generation with PixelCNN decoders | Simple statistical gradient-following algorithms for connectionist reinforcement learning | Function optimization using connectionist reinforcement learning algorithms",iclr,010
391.pdf.json,RECURRENT NEURAL NETWORKS,"Recent advances in multiple fields such as speech recognition (Graves & Jaitly, 2014; Amodei et al., 2015), language modeling (Józefowicz et al., 2016) and machine translation (Wu et al., 2016) can be at least partially attributed to larger training datasets, larger models and more compute that allows larger models to be trained on larger datasets. For example, the deep neural network used for acoustic modeling in Hannun et al. (2014) had 11 million parameters which grew to approximately 67 million for bidirectional RNNs and further to 116 million for the latest forward only GRU models in Amodei et al. (2015). And in language modeling the size of the non-embedding parameters (mostly in the recurrent layers) have exploded even as various ways of hand engineering sparsity into the embeddings have been explored in Józefowicz et al. (2016) and Chen et al. (2015a). These large models face two significant challenges in deployment. Mobile phones and embedded devices have limited memory and storage and in some cases network bandwidth is also a concern. In addition, the evaluation of these models requires a significant amount of computation. Even in cases when the networks can be evaluated fast enough, it will still have a significant impact on battery life in mobile devices (Han et al., 2015). Inference performance of RNNs is dominated by the memory bandwidth of the hardware, since most of the work is simply reading in the parameters at every time step. Moving from a dense calculation to a sparse one comes with a penalty, but if the sparsity factor is large enough, then the smaller amount of data required by the sparse routines becomes a win. Furthermore, this suggests that if the parameter sizes can be reduced to fit in cache or other very fast memory, then large speedups could be realized, resulting in a super-linear increase in performance. The more powerful server class GPUs used in data centers can generally perform inference quickly enough to serve one user, but in ","Deep speech 2: End-to-end speech recognition in english and mandarin | Moderngpu, 2016. URL https://nvlabs.github.io/moderngpu/segreduce.html | Strategies for training large vocabulary neural language models | Compressing neural networks with the hashing trick | Learning phrase representations using rnn encoder-decoder for statistical machine translation | Predicting parameters in deep learning | Exploiting linear structure within convolutional networks for efficient evaluation | Persistent rnns: Stashing recurrent weights onchip | Compressing deep convolutional networks using vector quantization | Towards end-to-end speech recognition with recurrent neural networks | Deep compression: Compressing deep neural network with pruning, trained quantization and huffman coding | Deep speech: Scaling up end-to-end speech recognition | Advances in neural information processing systems 1. chapter Comparing Biases for Minimal Network Construction with Back-propagation, pp. 177–185 | Optimal brain surgeon and general network pruning | Speeding up convolutional neural networks with low rank expansions | Exploring the limits of language modeling | Optimal brain damage | Efficient sparse matrix-vector multiplication on x86-based many-core processors | Learning compact recurrent neural networks | Improving the speed of neural networks on cpus | Exploiting sparseness in deep neural networks for large vocabulary speech recognition",iclr,010
392.pdf.json,,"Advances in training of neural networks have helped to improve performance in a number of domains, but neural networks have yet to surpass existing codecs in lossy image compression. Promising first results have recently been achieved using autoencoders (Ballé et al., 2016; Toderici et al., 2016b) – in particular on small images (Toderici et al., 2016a; Gregor et al., 2016; van den Oord et al., 2016b) – and neural networks are already achieving state-of-the-art results in lossless image compression (Theis & Bethge, 2015; van den Oord et al., 2016a). Autoencoders have the potential to address an increasing need for flexible lossy compression algorithms. Depending on the situation, encoders and decoders of different computational complexity are required. When sending data from a server to a mobile device, it may be desirable to pair a powerful encoder with a less complex decoder, but the requirements are reversed when sending data in the other direction. The amount of computational power and bandwidth available also changes over time as new technologies become available. For the purpose of archiving, encoding and decoding times matter less than for streaming applications. Finally, existing compression algorithms may be far from optimal for new media formats such as lightfield images, 360 video or VR content. While the development of a new codec can take years, a more general compression framework based on neural networks may be able to adapt much quicker to these changing tasks and environments. Unfortunately, lossy compression is an inherently non-differentiable problem. In particular, quantization is an integral part of the compression pipeline but is not differentiable. This makes it difficult to train neural networks for this task. Existing transformations have typically been manually chosen (e.g., the DCT transformation used in JPEG) or have been optimized for a task different from lossy compression (e.g. Testa & Rossi, 2016, used denoising autoencoders for comp","Scale mixtures of normal distributions | End-to-end optimization of nonlinear transform codes for perceptual quality | Super-resolution with deep convolutional sufficient statistics | Generating images with perceptual similarity metrics based on deep networks, 2016 | Image style transfer using convolutional neural networks | Generative adversarial nets | Towards conceptual compression, 2016 | Deep residual learning for image recognition | Auto-encoding variational bayes | Adam: A Method for Stochastic Optimization | Perceptual image quality assessment using a normalized Laplacian pyramid | Gradient-based learning applied to document recognition | Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network, 2016 | Auto-encoders: reconstruction versus compression | JPEG still image data compression | Image denoising using scale mixtures of gaussians in the wavelet domain | Learning representations by back-propagating | Real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network | The JPEG 2000 still image compression standard | Mean opinion score (MOS) revisited: methods and applications, limitations and alternatives | Lightweight Lossy Compression of Biometric Patterns via Denoising Autoencoders | Generative Image Modeling Using Spatial LSTMs | A note on the evaluation of generative models | Variable rate image compression with recurrent neural networks | Full resolution image compression with recurrent neural networks, 2016b. arXiv:1608.05148v1 | The student-t mixture as a natural image patch prior with application to image compression | Pixel recurrent neural networks | Conditional Image Generation with PixelCNN Decoders, 2016b. arXiv:1606.05328v2 | scikit-image: image processing | The JPEG still picture compression standard | Image quality assessment: from error visibility to structural similarity | Multiscale structural similarity for image quality assessment | Simple statistical gradient-following algorithms for connectionist reinforcement learning",iclr,010
393.pdf.json,STRUCTURED ATTENTION NETWORKS,"Attention networks are now a standard part of the deep learning toolkit, contributing to impressive results in neural machine translation (Bahdanau et al., 2015; Luong et al., 2015), image captioning (Xu et al., 2015), speech recognition (Chorowski et al., 2015; Chan et al., 2015), question answering (Hermann et al., 2015; Sukhbaatar et al., 2015), and algorithm-learning (Graves et al., 2014; Vinyals et al., 2015), among many other applications (see Cho et al. (2015) for a comprehensive review). This approach alleviates the bottleneck of compressing a source into a fixed-dimensional vector by equipping a model with variable-length memory (Weston et al., 2014; Graves et al., 2014; 2016), thereby providing random access into the source as needed. Attention is implemented as a hidden layer which computes a categorical distribution (or hierarchy of categorical distributions) to make a soft-selection over source elements. Noting the empirical effectiveness of attention networks, we also observe that the standard attentionbased architecture does not directly model any structural dependencies that may exist among the source elements, and instead relies completely on the hidden layers of the network. While one might argue that these structural dependencies can be learned implicitly by a deep model with enough data, in practice, it may be useful to provide a structural bias. Modeling structural dependencies at the final, output layer has been shown to be important in many deep learning applications, most notably in seminal work on graph transformers (LeCun et al., 1998), key work on NLP (Collobert et al., 2011), and in many other areas (Peng et al., 2009; Do & Artiéres, 2010; Jaderberg et al., 2014; Chen et al., 2015; Durrett & Klein, 2015; Lample et al., 2016, inter alia). In this work, we consider applications which may require structural dependencies at the attention layer, and develop internal structured layers for modeling these directly. This approach generalizes cate","Globally Normalized Transition-Based Neural Networks | Neural Machine Translation by Jointly Learning to Align and Translate | Trainable Grammars for Speech Recognition. Speech Communication Papers for the 97th | Structured Prediction Energy Networks | Tree-Structured Composition in Neural Networks without Tree-Structured Architectures | A Fast Unified Model for Parsing and Sentence Understanding | Listen, Attend and Spell | Learning Deep Structured Models | Enhancing and Combining Sequential and Tree LSTM for Natural Language Inference | Describing Multimedia Content using Attention-based Encoder-Decoder Networks | Attention-Based Models for Speech Recognition | Natural Language Processing (almost) from Scratch | Parameter Learning with Truncated Message-Passing | Generic methods for optimization-based modeling | Adaptive Subgradient Methods for Online Learning and Stochastic Optimization | Neural CRF Parsing | Three New Probabilistic Models for Dependency Parsing: An Exploration | Inside-Outside and Forward-Backward Algorithms are just Backprop | Approximation-Aware Dependency Parsing by Belief Propagation | Learning to Transduce with Unbounded Memory | Teaching Machines to Read and Comprehend | Deep Structured Output Learning for Unconstrained Text Recognition | Adam: A Method for Stochastic Optimization | Simple and Accurate Dependency Parsing using Bidirectional LSTM Feature Representations | Segmental Recurrent Neural Networks | Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data | Neural Architectures for Named Entity Recognition | Gradient-based Learning Applied to Document Recognition | First- and Second-Order Expectation Semirings with Applications to Minimum-Risk Training on Translation Forests | Segmental Recurrent Neural Networks for End-to-End Speech Recognition | Effective Approaches to Attentionbased Neural Machine Translation | Gradient-based Hyperparameter Optimization through Reversible Learning | Natural language inference by tree-based convolution and heuristic matching | Neural Tree Indexers for Text Understanding | Aspec: Asian scientific paper excerpt corpus | Pointwise Prediction for Robust, Adaptable Japanese Morphological Analysis | A Decomposable Attention Model for Natural Language Inference | Conditional Neural Fields | GloVe: Global Vectors for Word Representation | Reasoning about Entailment with Neural Attention | Gradient estimation using stochastic computation graphs | Dependency Parsing as Belief Propagation | Minimum-Risk Training of Approximate CRF-based NLP Systems | Empirical Risk Minimization of Graphical Model Parameters Given Approximate Inference, Decoding, and Model Structure | End-To-End Memory Networks | Proximal Deep Structured Models | Learning Natural Language Inference with LSTM | Towards Ai-complete Question Answering: A Set of Prerequisite | Show, Attend and Tell: Neural Image Caption Generation with Visual Attention | Online Segment to Segment Neural Transduction | The Neural Noisy Channel | Textual Entailment with Structured Attentions and Composition | In particular, let x = [x1",iclr,010
394.pdf.json,ZONEOUT: REGULARIZING RNNS BY RANDOMLY PRESERVING HIDDEN ACTIVATIONS,"Regularizing neural nets can significantly improve performance, as indicated by the widespread use of early stopping, and success of regularization methods such as dropout and its recurrent variants (Hinton et al., 2012; Srivastava et al., 2014; Zaremba et al., 2014; Gal, 2015). In this paper, we address the issue of regularization in recurrent neural networks (RNNs) with a novel method called zoneout. RNNs sequentially construct fixed-length representations of arbitrary-length sequences by folding new observations into their hidden state using an input-dependent transition operator. The repeated application of the same transition operator at the different time steps of the sequence, however, can make the dynamics of an RNN sensitive to minor perturbations in the hidden state; the transition dynamics can magnify components of these perturbations exponentially. Zoneout aims to improve RNNs’ robustness to perturbations in the hidden state in order to regularize transition dynamics. Like dropout, zoneout injects noise during training. But instead of setting some units’ activations to 0 as in dropout, zoneout randomly replaces some units’ activations with their activations from the previous timestep. As in dropout, we use the expectation of the random noise at test time. This results in a simple regularization approach which can be applied through time for any RNN architecture, and can be conceptually extended to any model whose state varies over time. Compared with dropout, zoneout is appealing because it preserves information flow forwards and backwards through the network. This helps combat the vanishing gradient problem (Hochreiter, 1991; Bengio et al., 1994), as we observe experimentally. We also empirically evaluate zoneout on classification using the permuted sequential MNIST dataset, and on language modelling using the Penn Treebank and Text8 datasets, demonstrating competitive or state of the art performance across tasks. In particular, we show that zoneout per",Learning with pseudo-ensembles | On Fast Dropout and its Applicability to Recurrent Networks | Learning long-term dependencies with gradient descent is difficult | Estimating or propagating gradients through stochastic neurons for conditional computation | Hierarchical multiscale recurrent neural networks | Recurrent batch normalization | Binaryconnect: Training deep neural networks with binary weights during propagations | A Theoretically Grounded Application of Dropout in Recurrent Neural Networks | Learning to forget: Continual prediction with LSTM | Deep residual learning for image recognition | Hierarchical recurrent neural networks for long-term dependencies | Improving neural networks by preventing co-adaptation of feature detectors | Untersuchungen zu dynamischen neuronalen netzen | Long short-term memory | Deep networks with stochastic depth | Adam: A method for stochastic optimization | A clockwork rnn | Regularizing rnns by stabilizing activations | A simple way to initialize recurrent networks of rectified linear units | Building a large annotated corpus of english: The penn treebank | Rnndrop: A novel dropout for rnns in asr | Understanding the exploding gradient problem | Dropout improves Recurrent Neural Networks for Handwriting Recognition | Recurrent dropout without memory loss | Swapout: Learning an ensemble of deep architectures | Dropout: A simple way to prevent neural networks from overfitting | Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude | Fast dropout training | Recurrent neural network regularization,iclr,010
395.pdf.json,DEEP PROBABILISTIC PROGRAMMING,"The nature of deep neural networks is compositional. Users can connect layers in creative ways, without having to worry about how to perform testing (forward propagation) or inference (gradientbased optimization, with back propagation and automatic differentiation). In this paper, we design compositional representations for probabilistic programming. Probabilistic programming lets users specify generative probabilistic models as programs and then “compile” those models down into inference procedures. Probabilistic models are also compositional in nature, and much work has enabled rich probabilistic programs via compositions of random variables (Goodman et al., 2012; Ghahramani, 2015; Lake et al., 2016). Less work, however, has considered an analogous compositionality for inference. Rather, many existing probabilistic programming languages treat the inference engine as a black box, abstracted away from the model. These cannot capture probabilistic inferences that reuse the model’s representation—a key idea in recent advances in variational inference (Kingma & Welling, 2014; Rezende & Mohamed, 2015; Tran et al., 2016b), generative adversarial networks (Goodfellow et al., 2014), and also in more classic inferences (Dayan et al., 1995; Gutmann & Hyvärinen, 2010). We propose Edward1, a Turing-complete probabilistic programming language which builds on two compositional representations—one for random variables and one for inference. By treating inference as a first class citizen, on a par with modeling, we show that probabilistic programming can be as flexible and computationally efficient as traditional deep learning. For flexibility, we show how Edward makes it easy to fit the same model using a variety of composable inference methods, ranging from point estimation to variational inference to MCMC. For efficiency, we show how to integrate Edward into existing computational graph frameworks such as TensorFlow (Abadi et al., 2016). Frameworks like TensorFlow provide compu","TensorFlow: A system for largescale machine learning | The pseudo-marginal approach for efficient Monte Carlo computations | Space-efficient inference in dynamic probabilistic networks | Pattern Recognition and Machine Learning | Latent Dirichlet Allocation | Large-scale machine learning with stochastic gradient descent | Streaming Variational Bayes | Importance weighted autoencoders | Stan: A probabilistic programming language | Dataflow architectures | The Helmholtz machine | Deep generative image models using a Laplacian pyramid of adversarial networks | χ-divergence for approximate inference | On sequential Monte Carlo sampling methods for Bayesian filtering | An introduction to sequential monte carlo methods | Stochastic variational inference for hidden Markov models | Sampling-based approaches to calculating marginal densities | Probabilistic machine learning and artificial intelligence | Generative adversarial nets | Church: A language for generative models | DRAW: A recurrent neural network for image generation | Noise-contrastive estimation: A new estimation principle for unnormalized statistical models | Training products of experts by minimizing contrastive divergence | A fast learning algorithm for deep belief nets | Structured stochastic variational inference | Stochastic variational inference | Caffe: Convolutional architecture for fast feature embedding | Stochastic variational inference for Bayesian time series models | An introduction to variational methods for graphical models | Auto-encoding variational Bayes | Semi-supervised learning with deep generative models | Improving variational inference with inverse autoregressive flow | Embedded probabilistic programming | Probabilistic Graphical Models: Principles and Techniques | Building machines that learn and think like people | Variational inference with Rényi divergence | Generative moment matching networks | Venture: A higher-order probabilistic programming platform with programmable inference | The Population Posterior and Bayesian Inference on Streams | Expectation propagation for approximate Bayesian inference | The Bayes net toolbox for Matlab | MCMC using Hamiltonian dynamics | A new view of the EM algorithm that justifies incremental and other variants | Variational Bayesian inference with stochastic search | IBAL: A probabilistic rational programming language | Figaro: An object-oriented probabilistic programming language. Charles River Analytics | JAGS: A program for analysis of Bayesian graphical models using Gibbs sampling | Black box variational inference | Operator variational inference | Hierarchical variational models | Variational inference with normalizing flows | Stochastic backpropagation and approximate inference in deep generative models | Oneshot generalization in deep generative models | Deep amortized inference for probabilistic programs | Exponential family embeddings | On the quantitative analysis of deep belief networks | Probabilistic Programming in Python using PyMC | Practical probabilistic programming with monads | BUGS: Bayesian inference using Gibbs sampling, version 0.50 | Forest: A repository for generative models, 2012. URL http:// forestdb.org | Edward: A library for probabilistic modeling, inference, and criticism | The variational Gaussian process | Deep and hierarchical implicit models | Augur: Data-parallel probabilistic modeling | Truncation-free online variational inference for Bayesian nonparametric models | Bayesian learning via stochastic gradient Langevin dynamics | A new approach to probabilistic programming inference | Swift: Compiled inference for probabilistic programming languages | Composing inference algorithms as program transformations",iclr,010
396.pdf.json,,"Generative adversarial networks (GANs) (Goodfellow et al., 2014) have shown significant promise as generative models for natural images. A flurry of recent work has proposed improvements over the original GAN work for image generation (Radford et al., 2015; Denton et al., 2015; Salimans et al., 2016; Chen et al., 2016; Zhu et al., 2016; Zhao et al., 2016), multi-stage image generation including part-based models (Im et al., 2016; Kwak & Zhang, 2016), image generation conditioned on input text or attributes (Mansimov et al., 2015; Reed et al., 2016b;a), image generation based on 3D structure (Wang & Gupta, 2016), and even video generation (Vondrick et al., 2016). While the holistic ‘gist’ of images generated by these approaches is beginning to look natural, there is clearly a long way to go. For instance, the foreground objects in these images tend to be deformed, blended into the background, and not look realistic or recognizable. One fundamental limitation of these methods is that they attempt to generate images without taking into account that images are 2D projections of a 3D visual world, which has a lot of structures in it. This manifests as structure in the 2D images that capture this world. One example of this structure is that images tend to have a background, and foreground objects are placed in this background in contextually relevant ways. We develop a GAN model that explicitly encodes this structure. Our proposed model generates images in a recursive fashion: it first generates a background, and then conditioned on the background generates a foreground along with a shape (mask) and a pose (affine transformation) that together define how the background and foreground should be composed to obtain a complete image. Conditioned on this composite image, a second foreground and an associated shape and pose are generated, and so on. As a byproduct in the course of recursive image generation, our approach generates some object-shape foreground-background masks i","Infogan: Interpretable representation learning by information maximizing generative adversarial nets | Robust estimation of a multi-layered motion representation | Deep generative image models using a laplacian pyramid of adversarial networks | Attend, infer, repeat: Fast scene understanding with generative models | Generative adversarial nets | Draw: A recurrent neural network for image generation | Labeled faces in the wild: A database for studying face recognition in unconstrained environments | Efficient inference in occlusion-aware generative models of images | Generating images with recurrent adversarial networks | Scene collaging: Analysis and synthesis of natural images with semantic layers | Spatial transformer networks | Generative model for layers of appearance and deformation | Improving variational inference with inverse autoregressive flow | Learning multiple layers of features from tiny images | Generating images part by part with composite generative adversarial networks | Gradient-based learning applied to document recognition | Generating images from captions with attention | A parametric texture model based on joint statistics of complex wavelet coefficients | Unsupervised representation learning with deep convolutional generative adversarial networks | Learning what and where to draw | Generative adversarial text to image synthesis | Learning a generative model of images by factoring appearance and shape | Improved techniques for training gans | Generating videos with scene dynamics | Representing moving images with layers | Generative image modeling using style and structure adversarial networks | Caltech-UCSD Birds 200 | Attribute2image: Conditional image generation from visual attributes | Energy-based generative adversarial network | Generative visual manipulation on the natural image manifold",iclr,010
397.pdf.json,,"A key goal of representation learning is to identify and disentangle the underlying causal factors of the data, so that it becomes easier to understand the data, to classify it, or to perform other tasks (Bengio et al., 2013). For image data this often means that we are interested in uncovering the “global structure” that captures the content of an image (for example, the identity of objects present in the image) and its “style”, but that we are typically less interested in the local and high frequency sources of variation such as the specific textures or white noise patterns. A popular approach for learning representations is to fit a probabilistic latent variable model, an approach also known as analysis-by-synthesis (Yuille & Kersten, 2006; Nair et al., 2008). By learning a generative model of the data with the appropriate hierarchical structure of latent variables, it is hoped that the model will somehow uncover and untangle those causal sources of variations that we happen to be interested in. However, without further assumptions, representation learning via generative modeling is ill-posed: there are many different possible generative models with different (or no) kinds of latent variables that all encode the same probability density function on our observed data. Thus, the results we empirically get using this approach are highly dependent on the specific architectural and modeling choices that are made. Moreover, the objective that we optimize is often completely disconnected from the goal of learning a good representation: An autoregressive model of the data may achieve the same log-likelihood as a variational autoencoder (VAE) (Kingma & Welling, 2013), but the structure learned by the two models is completely different: the latter typically has a clear hierarchy of latent variables, while the autoregressive model has no stochastic latent variables at all (although it is conceivable that the deterministic hidden units of the autoregressive models will have ",Fast and accurate deep network learning by Exponential Linear Units (ELUs) | Made: Masked autoencoder for distribution estimation | Deep residual learning for image recognition | Adam: A method for stochastic optimization | Improving variational inference with inverse autoregressive flow | Rectified linear units improve restricted boltzmann machines | Acceleration of stochastic approximation by averaging | Weight normalization: A simple reparameterization to accelerate training of deep neural networks | Pixelcnn++: Improving the pixelcnn with discretized logistic mixture likelihood and other modifications | A hierarchical latent variable encoder-decoder model for generating dialogues | Pixel recurrent neural networks | Conditional image generation with pixelcnn decoders,iclr,010
398.pdf.json,A RECURRENT NEURAL NETWORK WITHOUT CHAOS,"Gated recurrent neural networks, such as the Long Short Term Memory network (LSTM) introduced by Hochreiter & Schmidhuber (1997) and the Gated Recurrent Unit (GRU) proposed by Cho et al. (2014), prove highly effective for machine learning tasks that involve sequential data. We propose an exceptionally simple variant of these gated architectures. The basic model takes the form ht = θt tanh(ht−1) + ηt tanh(Wxt), (1) where stands for the Hadamard product. The horizontal/forget gate (i.e. θt) and the vertical/input gate (i.e. ηt) take the usual form used in most gated RNN architectures. Specifically θt := σ (Uθht−1 + Vθxt + bθ) and ηt := σ (Uηht−1 + Vηxt + bη) (2) where σ(x) := (1 + e−x)−1 denotes the logistic sigmoid function. The network (1)–(2) has quite intuitive dynamics. Suppose the data xt present the model with a sequence (Wxt)(i) = { 10 if t = T 0 otherwise, (3) where (Wxt)(i) stands for the ith component of the vector Wxt. In other words we consider an input sequence xt for which the learned ith feature (Wxt)(i) remains off except at time T . When initialized from h0 = 0, the corresponding response of the network to this “impulse” in the ith feature is ht(i) ≈  0 if t < T ηT if t = T αt if t > T (4) with αt a sequence that relaxes toward zero. The forget gate θt control the rate of this relaxation. Thus ht(i) activates when presented with a strong ith feature, and then relaxes toward zero until the data present the network once again with strong ith feature. Overall this leads to a dynamically simple model, in which the activation patterns in the hidden states of the network have a clear cause and predictable subsequent behavior. Dynamics of this sort do not occur in other RNN models. Instead, the three most popular recurrent neural network architectures, namely the vanilla RNN, the LSTM and the GRU, have complex, irregular, and unpredictable dynamics. Even in the absence of input data, these networks can give rise to chaotic dynamical systems. In other words,","Real-time computation at the edge of chaos in recurrent neural networks | Learning phrase representations using rnn encoder-decoder for statistical machine translation | Learning to forget: Continual prediction with lstm | A two-dimensional mapping with a strange attractor | Long short-term memory | An empirical exploration of recurrent network architectures | Building a large annotated corpus of english: The penn treebank | Learning longer memory in recurrent neural networks | On the difficulty of training recurrent neural networks | Nonlinear dynamics and chaos: with applications to physics, biology, chemistry, and engineering | End-to-end memory networks | Opening the black box: low-dimensional dynamics in highdimensional recurrent neural networks | Recurrent neural network regularization",iclr,010
399.pdf.json,OUTRAGEOUSLY LARGE NEURAL NETWORKS: THE SPARSELY-GATED MIXTURE-OF-EXPERTS LAYER,,"Tensorflow: Large-scale machine learning on heterogeneous distributed systems | Expert gate: Lifelong learning with a network of experts | Dynamic Capacity Networks | Deep speech 2: End-to-end speech recognition in english and mandarin | Neural machine translation by jointly learning to align and translate | Conditional computation in neural networks for faster models | Estimating or propagating gradients through stochastic neurons for conditional computation | One billion word benchmark for measuring progress in statistical language modeling | Exponentially Increasing the Capacity-to-Computation Ratio for Conditional Computation in Deep Learning | A parallel mixture of SVMs for very large scale problems | Low-rank approximations for conditional feedforward computation in deep neural networks | Distributed Gaussian processes | Adaptive subgradient methods for online learning and stochastic optimization | Edinburgh’s phrase-based machine translation systems for wmt-14 | Learning factored representations in a deep mixture of experts | Ensemble learning for multi-source neural machine translation | Learning to forget: Continual prediction with lstm | Memory-efficient backpropagation through time | Deep residual learning for image recognition | Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups | Long short-term memory | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Adaptive mixtures of local experts | Google’s multilingual neural machine translation system: Enabling zero-shot translation | Hierarchical mixtures of experts and the EM algorithm | Exploring the limits of language modeling | Adam: A method for stochastic optimization | Improved backingoff for m-gram language modeling | Imagenet classification with deep convolutional neural networks | Building high-level features using large scale unsupervised learning | Deep sequential neural network | Effective approaches to attentionbased neural machine translation | Addressing the rare word problem in neural machine | Infinite mixtures of Gaussian process experts | Long short-term memory recurrent neural network architectures for large scale acoustic modeling | Japanese and Korean voice | Nonlinear models using dirichlet process mixtures | Sequence to sequence learning with neural networks | Generative image modeling using spatial LSTMs | Mixtures of Gaussian Processes | Hierarchical mixture of classification experts uncovers interactions between brain regions | Recurrent neural network regularization | Deep recurrent models with fast-forward connections for neural machine translation | ATTENTION FUNCTION The attention mechanism described in GNMT (Wu et al., 2016) involves a learned “Attention Function"" A(xi, yj) which takes a “source vector"" xi and a “target vector"" yj , and must be computed for every source time step i and target time step j",iclr,010
400.pdf.json,TREE-STRUCTURED DECODING WITH DOUBLY- RECURRENT NEURAL NETWORKS,"Recurrent neural networks have become extremely popular for modeling structured data. Key to their success is their ability to learn long-range temporal dependencies, their flexibility, and ease of customization. These architectures are naturally suited for modeling sequences since the underlying state evolution resulting from successive operations follows an inherently linear order (Williams & Zipser, 1995; Hochreiter & Schmidhuber, 1997). Indeed, they have been successfully adapted to language modeling (Zaremba et al., 2015), machine translation (Sutskever et al., 2014) and conversational agents (Vinyals & Le, 2015), among other applications. Although sequences arise frequently in practice, other structures such as trees or graphs do not naturally conform to a linear ordering. For example, natural language sentences or associated parse trees, programs, hierarchical structures in biology, or molecules are not inherently linear structures. While sentences in natural language can be modeled as if they were linear sequences, the underlying process is compositional (Frege, 1892). Models that construct sentences compositionally should derive an advantage from adopting a more appropriate inductive bias. The flexibility and success of recurrent neural networks in modeling and generating sequential data has prompted efforts to adapt them to non-sequential data too. Recent work has focused on the application of neural architectures to hierarchical structures, albeit in limited ways. Much of this work has assumed that either the full tree structure is given (Socher et al., 2012; Tai et al., 2015) or at least the nodes are (Socher & Lin, 2011; Chen & Manning, 2014; Kiperwasser & Goldberg, 2016). In the former scenario, the network aggregates the node information in a manner that is coherent with a given tree structure while, in the latter, generation is reduced to an attachment problem, i.e., sequentially deciding which pairs of nodes to join with an edge until a tree is form","Reinforcement learning for mapping instructions to actions | A Fast and Accurate Dependency Parser using Neural Networks | Language to Logical Form with Neural Attention | Learning task-dependent distributed representations by backpropagation through structure | Long short-term memory | Learning to transform natural to formal languages | Adam: A Method for Stochastic Optimization | Easy-First Dependency Parsing with Hierarchical Tree LSTMs | OpenNMT: Open-Source Toolkit for Neural Machine Translation | The Stanford CoreNLP natural language processing toolkit | GloVe: Global Vectors for Word Representation | Language to Code: Learning Semantic Parsers for If-This-Then-That | Sequence Level Training with Recurrent Neural Networks | Parsing natural scenes and natural language with recursive neural networks | Semantic Compositionality through Recursive Matrix-Vector Spaces | Recursive deep models for semantic compositionality over a sentiment treebank | Sequence to sequence learning with neural networks | Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks | Improving Multi-step Prediction of Learned Time Series Models | Gradient-based learning algorithms for recurrent networks and their computational complexity. Back-propagation Theory, Archit | Recurrent Neural Network Regularization | Top-down Tree Long Short-Term Memory Networks | IFTTT The IFTTT dataset comes with a script to generate the data by crawling and parsing the recipes. Unfortunately, by the time we ran the script many recipes",iclr,010
401.pdf.json,INTROSPECTION:ACCELERATING NEURAL NETWORK TRAINING BY LEARNING WEIGHT EVOLUTION,"Deep neural networks have been very successful in modeling high-level abstractions in data. However, training a deep neural network for any AI task is a time-consuming process. This is because a large number of parameters need to be learnt using training examples. Most of the deeper networks can take days to get trained even on GPU thus making it a major bottleneck in the large-scale application of deep networks. Reduction of training time through an efficient optimizer is essential for fast design and testing of deep neural nets. In the context of neural networks, an optimization algorithm iteratively updates the parameters (weights) of a network based on a batch of training examples, to minimize an objective function. The most widely used optimization algorithm is Stochastic Gradient Descent. Even with the advent of newer and faster optimization algorithms like Adagrad, Adadelta, RMSProp and Adam there is still a need for achieving faster convergence. In this work we apply neural network to predict weights of other in-training neural networks to accelerate their convergence. Our method has a very low memory footprint and is computationally efficient. Another aspect of this method is that we can update the weights of all the layers in parallel. ∗This work was done as part of an internship at Adobe Systems, Noida",Learning to learn by gradient descent by gradient descent | Adaptive Subgradients Method For Online Learning and Stochastic Optimization | Deep Q-Networks for Accelerating the Training of Deep Neural Networks. 2016 | Lecture 6a:Overview of mini-batch gradient descent | Decoupled Neural Interfaces using Synthetic Gradients | Learning Multiple Layers of Features from Tiny Images | ImageNet Classification with Deep Convolutional Neural Networks | Learning representations by backpropagating errors | Adadelta:An adaptive learning method,iclr,010
402.pdf.json,HYPERBAND: BANDIT-BASED CONFIGURATION EVAL-,"The task of hyperparameter optimization is becoming increasingly important as modern data analysis pipelines grow in complexity. The quality of a predictive model critically depends on its hyperparameter configuration, but it is poorly understood how these hyperparameters interact with each other to affect the quality of the resulting model. Consequently, practitioners often default to either hand-tuning or automated brute-force methods like random search and grid search. In an effort to develop more efficient search methods, the problem of hyperparameter optimization has recently been dominated by Bayesian optimization methods (Snoek et al., 2012; Hutter et al., 2011; Bergstra et al., 2011) that focus on optimizing hyperparameter configuration selection. These methods aim to identify good configurations more quickly than standard baselines like random search by selecting configurations in an adaptive manner; see Figure 1(a). Existing empirical evidence suggests that these methods outperform random search (Thornton et al., 2013; Eggensperger et al., 2013; Snoek et al., 2015). However, these methods tackle a fundamentally challenging problem of simultaneously fitting and optimizing a high-dimensional, non-convex function with unknown smoothness, and possibly noisy evaluations. To overcome these difficulties, some Bayesian optimization methods resort to heuristics, at the expense of consistency guarantees, to model the objective function or speed up resource intensive subroutines.1 Moreover, these adaptive configuration selection methods are intrinsically sequential and thus difficult to parallelize. An orthogonal approach to hyperparameter optimization focuses on speeding up configuration evaluation; see Figure 1(b). These methods are adaptive in computation, allocating more resources to promising hyperparameter configurations while quickly eliminating poor ones. Resources can take various forms, including size of training set, number of features, or number of iterat",Oracle inequalities for computationally budgeted model selection | Least squares revisited: Scalable approaches for multi-class prediction | Random search for hyper-parameter optimization | Algorithms for hyper-parameter optimization | Speeding up automatic hyperparameter optimization of deep neural networks by extrapolation of learning curves | Towards an empirical foundation for assessing bayesian optimization of hyperparameters | Efficient multi-start strategies for local search | Sequential model-based optimization for general algorithm configuration | Best-arm identification algorithms for multi-armed bandits in the fixed confidence setting | Non-stochastic best arm identification and hyperparameter optimization | Fast bayesian optimization of machine learning hyperparameters on large datasets | Learning multiple layers of features from tiny images | Fast cross-validation via sequential testing | An empirical evaluation of deep architectures on problems with many factors of variation | Hyperband: A novel banditbased approach to hyperparameter optimization | Hoeffding races: Accelerating model selection search for classification and function approximation | Reading digits in natural images with unsupervised feature learning | Random features for large-scale kernel machines | Soft margins for adaboost | Selecting near-optimal learners via incremental data allocation | Convolutional neural networks applied to house numbers digit classification | Practical bayesian optimization of machine learning algorithms | Bayesian optimization using deep neural networks | Automating model search for large scale machine learning | Multi-task bayesian optimization | Freeze-thaw bayesian optimization | Auto-weka: Combined selection and hyperparameter optimization of classification algorithms | The CVST algorithm,iclr,010
403.pdf.json,LIE-ACCESS NEURAL TURING MACHINES,"Recent work on neural Turing machines (NTMs) (Graves et al., 2014; 2016) and memory networks (MemNNs) (Weston et al., 2014) has repopularized the use of explicit external memory in neural networks and demonstrated that these networks can be effectively trained in an end-to-end fashion. These methods have been successfully applied to question answering (Weston et al., 2014; Sukhbaatar et al., 2015; Kumar et al., 2015), algorithm learning (Graves et al., 2014; Kalchbrenner et al., 2015; Kaiser & Sutskever, 2015; Kurach et al., 2015; Zaremba & Sutskever, 2015; Grefenstette et al., 2015; Joulin & Mikolov, 2015), machine translation (Kalchbrenner et al., 2015), and other tasks. This methodology has the potential to extend deep networks in a general-purpose way beyond the limitations of fixed-length encodings such as standard recurrent neural networks (RNNs). A shared theme in many of these works (and earlier exploration of neural memory) is to re-frame traditional memory access paradigms to be continuous and possibly differentiable to allow for backpropagation. In MemNNs, traditional random-access memory is replaced with a ranking approach that finds the most likely memory. In the work of Grefenstette et al. (2015), classical stack-, queue-, and deque-based memories are replaced by soft-differentiable stack, queue, and deque datastructures. In NTMs, sequential local-access memory is simulated by an explicit tape data structure. This work questions the assumption that neural memory should mimic the structure of traditional discrete memory. We argue that a neural memory should provide the following: (A) differentiability for end-to-end training and (B) robust relative indexing (perhaps in addition to random-access). Surprisingly many neural memory systems fail one of these conditions, either lacking Criterion B, discussed below, or employing extensions like REINFORCE to work around lack of differentiability (Zaremba & Sutskever, 2015). We propose instead a class of memory ","Neural Turing Machines | Hybrid computing using a neural network with dynamic external | Learning to Transduce with Unbounded Memory | Dynamic Neural Turing Machine with Soft and Hard Addressing Schemes | Long Short-Term Memory | Inferring Algorithmic Patterns with Stack-Augmented Recurrent Nets | Neural GPUs Learn Algorithms | Grid Long Short-Term Memory | Ask Me Anything: Dynamic Memory Networks for Natural Language Processing | Neural Random-Access Machines | Introduction to Smooth Manifolds | Interpolation in Lie Groups | Key-value memory networks for directly reading | Interpolation in special orthogonal groups | End-To-End Memory Networks | Sequence to Sequence Learning with Neural Networks | Backpropagation through time: what it does and how to do it | Memory Networks. arXiv:1410.3916 [cs, stat | Reinforcement Learning Neural Turing Machines - Revised",iclr,010
404.pdf.json,QUASI-RECURRENT NEURAL NETWORKS,"Recurrent neural networks (RNNs), including gated variants such as the long short-term memory (LSTM) (Hochreiter & Schmidhuber, 1997) have become the standard model architecture for deep learning approaches to sequence modeling tasks. RNNs repeatedly apply a function with trainable parameters to a hidden state. Recurrent layers can also be stacked, increasing network depth, representational power and often accuracy. RNN applications in the natural language domain range from sentence classification (Wang et al., 2015) to word- and character-level language modeling (Zaremba et al., 2014). RNNs are also commonly the basic building block for more complex models for tasks such as machine translation (Bahdanau et al., 2015; Luong et al., 2015; Bradbury & Socher, 2016) or question answering (Kumar et al., 2016; Xiong et al., 2016). Unfortunately standard RNNs, including LSTMs, are limited in their capability to handle tasks involving very long sequences, such as document classification or character-level machine translation, as the computation of features or states for different parts of the document cannot occur in parallel. Convolutional neural networks (CNNs) (Krizhevsky et al., 2012), though more popular on tasks involving image data, have also been applied to sequence encoding tasks (Zhang et al., 2015). Such models apply time-invariant filter functions in parallel to windows along the input sequence. CNNs possess several advantages over recurrent models, including increased parallelism and better scaling to long sequences such as those often seen with character-level language data. Convolutional models for sequence processing have been more successful when combined with RNN layers in a hybrid architecture (Lee et al., 2016), because traditional max- and average-pooling approaches to combining convolutional features across timesteps assume time invariance and hence cannot make full use of large-scale sequence order information. We present quasi-recurrent neural networ","Neural machine translation by jointly learning to align and translate | Strongly-typed recurrent neural networks | In Proceedings of the First Conference on Machine Translation, Berlin, Germany | A theoretically grounded application of dropout in recurrent neural networks | Long short-term memory | Densely connected convolutional networks | Effective use of word order for text categorization with convolutional neural networks | Neural machine translation in linear time | Character-aware neural language models | Adam: A method for stochastic optimization | ImageNet classification with deep convolutional neural networks | Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations | Ask me anything: Dynamic memory networks for natural language processing | Fully character-level neural machine translation without explicit segmentation | A way out of the odyssey: Analyzing and combining recent insights for LSTMs | Effective approaches to attention-based neural machine translation | Multi-dimensional sentiment analysis with learned representations | Pointer sentinel mixture models | Ensemble of generative and discriminative techniques for sentiment analysis of movie reviews | Recurrent neural network based language model | Virtual adversarial training for semi-supervised text classification | GloVe: Global vectors for word representation | Sequence level training with recurrent neural networks | Query-reduction networks for question answering | Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude | Pixel recurrent neural networks | Conditional image generation with PixelCNN decoders | Baselines and bigrams: Simple, good sentiment and topic classification | Predicting polarities of tweets by composing word embeddings with long short-term memory | Sequence-to-sequence learning as beam-search optimization | Google’s neural machine translation system: Bridging the gap between human and machine translation | Efficient character-level document classification by combining convolution and recurrent layers | Dynamic memory networks for visual and textual question answering | Recurrent neural network regularization | Character-level convolutional networks for text classification | A C-LSTM neural network for text classification",iclr,010
405.pdf.json,RECURRENT ENVIRONMENT SIMULATORS,"In order to plan and act effectively, agent-based systems require an ability to anticipate the consequences of their actions within an environment, often for an extended period into the future. Agents can be equipped with this ability by having access to models that can simulate how the environments changes in response to their actions. The need for environment simulation is widespread: in psychology, model-based predictive abilities form sensorimotor contingencies that are seen as essential for perception (O’Regan & Noë, 2001); in neuroscience, environment simulation forms part of deliberative planning systems used by the brain (Niv, 2009); and in reinforcement learning, the ability to imagine the future evolution of an environment is needed to form predictive state representations (Littman et al., 2002) and for Monte Carlo planning (Sutton & Barto, 1998). Simulating an environment requires models of temporal sequences that must possess a number of properties to be useful: the models should make predictions that are accurate, temporally and spatially coherent over long time periods; and allow for flexibility in the policies and action sequences that are used. In addition, these models should be general-purpose and scalable, and able to learn from high-dimensional perceptual inputs and from diverse and realistic environments. A model that achieves these desiderata can empower agent-based systems with a vast array of abilities, including counterfactual reasoning (Pearl, 2009), intuitive physical reasoning (McCloskey, 1983), model-based exploration, episodic control (Lengyel & Dayan, 2008), intrinsic motivation (Oudeyer et al., 2007), and hierarchical control. Deep neural networks have recently enabled significant advances in simulating complex environments, allowing for models that consider high-dimensional visual inputs across a wide variety of domains (Wahlström et al., 2015; Watter et al., 2015; Sun et al., 2015; Patraucean et al., 2015). The model of Oh et al. (2",Finite-time analysis of the multiarmed bandit problem | The Arcade Learning Environment: An evaluation platform for general agents | Generating sequences with recurrent neural networks | Long short-term memory | Intuitive physics | Human-level control through deep reinforcement learning | Asynchronous methods for deep reinforcement learning | Reinforcement learning in the brain | A sensorimotor account of vision and visual consciousness | Intrinsic motivation systems for autonomous mental development | Spatio-temporal video autoencoder with differentiable memory | Unsupervised learning of video representations using LSTMs | Learning to filter with predictive state inference machines | Reinforcement learning: An introduction | Model regularization for stable sample rollouts | From pixels to torques: Policy learning with deep dynamical models | Gradient-based learning algorithms for recurrent networks and their computational complexity | Empirical evaluation of rectified activations in convolutional network | Recurrent neural network regularization,iclr,010
406.pdf.json,EPOPT: LEARNING ROBUST NEURAL NETWORK POLICIES USING MODEL ENSEMBLES,"Reinforcement learning with powerful function approximators like deep neural networks (deep RL) has recently demonstrated remarkable success in a wide range of tasks like games (Mnih et al., 2015; Silver et al., 2016), simulated control problems (Lillicrap et al., 2015; Mordatch et al., 2015b), and graphics (Peng et al., 2016). However, high sample complexity is a major barrier for directly applying model-free deep RL methods for physical control tasks. Model-free algorithms like Q-learning, actor-critic, and policy gradients are known to suffer from long learning times (Kakade, 2003), which is compounded when used in conjunction with expressive function approximators like deep neural networks (DNNs). The challenge of gathering samples from the real world is further exacerbated by issues of safety for the agent and environment, since sampling with partially learned policies could be unstable (Garcı́a & Fernández, 2015). Thus, model-free deep RL methods often require a prohibitively large numbers of potentially dangerous samples for physical control tasks. Model-based methods, where the real-world target domain is approximated with a simulated source domain, provide an avenue to tackle the above challenges by learning policies using simulated data. The principal challenge with simulated training is the systematic discrepancy between source and target domains, and therefore, methods that compensate for systematic discrepancies (modeling errors) are needed to transfer results from simulations to real world using RL. We show that the impact of such discrepancies can be mitigated through two key ideas: (1) training on an ensemble of models in an adversarial fashion to learn policies that are robust to parametric model errors, as well as to unmodeled effects; and (2) adaptation of the source domain ensemble using data from the target domain to progressively make it a better approximation. This can be viewed either as an instance of model-based Bayesian RL (Ghavamzadeh et","Using inaccurate models in reinforcement learning | A survey of robot learning from demonstration | Learning parameterized skills | A survey on policy search for robotics | Percentile optimization for markov decision processes with parameter uncertainty | Benchmarking deep reinforcement learning for continuous control | Design for an optimal probe | Infinite-horizon model predictive control for periodic tasks with contacts | A comprehensive survey on safe reinforcement learning | Bayesian reinforcement learning: A survey | A natural policy gradient | On the Sample Complexity of Reinforcement Learning | Approximately optimal approximate reinforcement learning | Guided policy search | Continuous control with deep reinforcement learning | Reinforcement learning in robust markov decision processes | System Identification, pp. 163–173 | Human-level control through deep reinforcement learning | Ensemble-CIO: Full-body dynamic motion planning that transfers to physical humanoids | Interactive control of diverse complex characters with neural networks | Robust control of markov decision processes with uncertain transition matrices | Terrain-adaptive locomotion skills using deep reinforcement learning | Point-based value iteration for continuous pomdps | An analytic solution to discrete bayesian reinforcement learning | Bayesian reinforcement learning in continuous pomdps with application to robot navigation | Agnostic system identification for model-based reinforcement learning | Trust region policy optimization | Mastering the game of go with deep neural networks and tree | Integrating a partial model into model free reinforcement learning | Optimizing the cvar via sampling | Transfer learning for reinforcement learning domains: A survey | High-confidence off-policy evaluation | Mujoco: A physics engine for model-based control | Bayesian Reinforcement Learning, pp. 359–386 | Optimizing walking controllers for uncertain inputs and environments | Real-time reinforcement learning by sequential actor-critics and experience replay | Simple statistical gradient-following algorithms for connectionist reinforcement learning | Robust and Optimal Control. Prentice-Hall, Inc | A.7 ALTERNATE POLICY GRADIENT SUBROUTINES FOR BATCHPOLOPT As emphasized previously, EPOpt is a generic policy gradient based meta algorithm for finding robust policies. The BatchPolOpt step (line 9, Algorithm 1) calls one gradient step of a policy gradient method, the choice | function baseline parametrization for both TRPO and REINFORCE. Figure 9 depicts the learning curve when using the two policy gradient methods. We observe that performance with TRPO is significantly better. When optimizing over probability distributions, the natural gradient can navigate the warped parameter space better than the “vanilla” gradient. This observation is consistent with the findings",iclr,010
407.pdf.json,TRANSFER FROM MULTIPLE SOURCES IN THE SAME DOMAIN,"One of the goals of Artificial Intelligence (AI) is to build autonomous agents that can learn and adapt to new environments. Reinforcement Learning (RL) is a key technique for achieving such adaptability. The goal of RL algorithms is to learn an optimal policy for choosing actions that maximize some notion of long term performance. Transferring knowledge gained from tasks solved earlier to solve a new target task can help, either in terms of speeding up the learning process or in terms of achieving a better solution, among other performance measures. When applied to RL, transfer could be accomplished in many ways (see Taylor & Stone (2009; 2011) for a very good survey of the field). One could use the value function from the source task as an initial estimate in the target task to cut down exploration [Sorg & Singh (2009)]. Alternatively one could use policies from the source task(s) in the target task. This can take one of two forms - (i) the derived policies can be used as initial exploratory trajectories [Atkeson & Schaal (1997); Niekum et al. (2013)] in the target task and (ii) the derived policy could be used to define macro-actions which may then be used by the agent in solving the target task [Mannor et al. (2004); Brunskill & Li (2014)]. ∗Authors contributed equally While transfer in RL has been much explored, there are two crucial issues that have not been adequately addressed in the literature. The first is negative transfer, which occurs when the transfer results in a performance that is worse when compared to learning from scratch in the target task. This severely limits the applicability of many transfer techniques only to cases for which some measure of relatedness between source and target tasks can be guaranteed beforehand. This brings us to the second problem with transfer, which is the issue of identifying an appropriate source task from which to transfer. In some scenarios, different source tasks might be relevant and useful for different parts of ",Robot learning from demonstration | Neural machine translation by jointly learning to align and translate | General game learning using knowledge transfer | The arcade learning environment: An evaluation platform for general agents | Pac-inspired option discovery in lifelong reinforcement learning | Proto-transfer learning in markov decision processes using spectral methods | Probabilistic policy reuse in a reinforcement learning agent | Actor-critic algorithms | Transfer in reinforcement learning via shared features | Transfer from multiple mdps | Reinforcement learning for robots using neural networks | Dynamic abstraction in reinforcement learning via clustering | Playing atari with deep reinforcement learning | Recurrent models of visual attention | Human-level control through deep reinforcement learning | Asynchronous methods for deep reinforcement learning | Incremental semantically grounded learning from demonstration | Actor-mimic: Deep multitask and transfer reinforcement learning | Markov decision processes: Discrete stochastic dynamic programming | Transfer via soft homomorphisms | Introduction to Reinforcement Learning | An experts algorithm for transfer learning | Transfer learning for reinforcement learning domains: A survey | An introduction to intertask transfer for reinforcement learning | Simple statistical gradient-following algorithms for connectionist reinforcement learning,iclr,010
408.pdf.json,MULTI-VIEW RECURRENT NEURAL ACOUSTIC WORD EMBEDDINGS,"Word embeddings—continuous-valued vector representations of words—are an almost ubiquitous component of recent natural language processing (NLP) research. Word embeddings can be learned using spectral methods (Deerwester et al., 1990) or, more commonly in recent work, via neural networks (Bengio et al., 2003; Mnih & Hinton, 2007; Mikolov et al., 2013; Pennington et al., 2014). Word embeddings can also be composed to form embeddings of phrases, sentences, or documents (Socher et al., 2014; Kiros et al., 2015; Wieting et al., 2016; Iyyer et al., 2015). In typical NLP applications, such embeddings are intended to represent the semantics of the corresponding words/sequences. In contrast, embeddings that represent the way a word or sequence sounds are rarely considered. In this work we address this problem, starting with embeddings of individual words. Such embeddings could be useful for tasks like spoken term detection (Fiscus et al., 2007), spoken query-by-example search (Anguera et al., 2014), or even speech recognition using a whole-word approach (Gemmeke et al., 2011; Bengio & Heigold, 2014). In tasks that involve comparing speech segments to each other, vector embeddings can allow more efficient and more accurate distance computation than sequence-based approaches such as dynamic time warping (Levin et al., 2013, 2015; Kamper et al., 2016; Settle & Livescu, 2016; Chung et al., 2016). We consider the problem of learning vector representations of acoustic sequences and orthographic (character) sequences corresponding to single words, such that the learned embeddings represent the way the word sounds. We take a multi-view approach, where we jointly learn the embeddings for character and acoustic sequences. We consider several contrastive losses, based on learning from pairs of matched acoustic-orthographic examples and randomly drawn mismatched pairs. The losses correspond to different goals for learning such embeddings; for example, we might want the embeddings of tw","Query by example search on speech at mediaeval | End-to-end ASR-free keyword search from speech | Word embeddings for speech recognition | A neural probabilistic language model | Signature verification using a siamese time delay neural network | Rapid evaluation of speech representations for spoken term discovery | Query-by-example keyword spotting using long short-term memory networks | Learning a similarity metric discriminatively, with application to face verification | Unsupervised learning of audio segment representations using sequence-to-sequence recurrent neural networks | Indexing by latent semantic analysis | Placing search in context: The concept revisited | Results of the 2006 spoken term detection evaluation | Exemplar-based sparse representations for noise robust automatic speech recognition | Evaluation of acoustic word embeddings | SWITCHBOARD: Telephone speech corpus for research and development | Speech recognition with deep recurrent neural networks | Dimensionality reduction by learning an invariant mapping | Deep multimodal semantic embeddings for speech and images | Learning word-like units from joint audio-visual analysis | Unsupervised learning of spoken language with visual context | Multilingual distributed representations without word alignment | SimLex-999: Evaluating semantic models with (genuine) similarity estimation | Long short-term memory | Convolutional neural network architectures for matching natural language sentences | Deep unordered composition rivals syntactic methods for text classification | Unsupervised neural network based feature extraction using weak top-down constraints | Deep convolutional acoustic word embeddings using word-pair side information | ADAM: A method for stochastic optimization | Skip-thought vectors | Fixed-dimensional acoustic embeddings of variable-length segments in low-resource settings | Segmental acoustic indexing for zero resource keyword search | Word-level acoustic modeling with convolutional vector regression | Distributed representations of words and phrases and their compositionality | Three new graphical models for statistical language modelling | Multimodal deep learning | GloVe: Global vectors for word representation | Discriminative acoustic word embeddings: Recurrent neural network-based approaches | Grounded compositional semantics for finding and describing images with sentences | Improved multimodal deep learning with variation of information | Multimodal learning with deep boltzmann machines | Phonetics embedding learning with side information | Visualizing data using t-SNE | Order-embeddings of images and language | On deep multi-view representation learning | Towards universal paraphrastic sentence embeddings",iclr,010
409.pdf.json,,"Music research has benefited recently from the effectiveness of machine learning methods on a wide range of problems from music recommendation (van den Oord et al., 2013; McFee & Lanckriet, 2011) to music generation (Hadjeres & Pachet, 2016); see also the recent demos of the Google Magenta project1. As of today, there is no large publicly available labeled dataset for the simple yet challenging task of note prediction for classical music. The MIREX MultiF0 Development Set (Benetos & Dixon, 2011) and the Bach10 dataset (Duan et al., 2011) together contain less than 7 minutes of labeled music. These datasets were designed for method evaluation, not for training supervised learning methods. This situation stands in contrast to other application domains of machine learning. For instance, in computer vision large labeled datasets such as ImageNet (Russakovsky et al., 2015) are fruitfully used to train end-to-end learning architectures. Learned feature representations have outperformed traditional hand-crafted low-level visual features and lead to tremendous progress for image classification. In (Humphrey et al., 2012), Humphrey, Bello, and LeCun issued a call to action: “Deep architectures often require a large amount of labeled data for supervised training, a luxury music informatics has never really enjoyed. Given the proven success of supervised methods, MIR would likely benefit a good deal from a concentrated effort in the curation of sharable data in a sustainable manner.” This paper introduces a new large labeled dataset, MusicNet, which is publicly available2 as a resource for learning feature representations of music. MusicNet is a corpus of aligned labels on freely-licensed classical music recordings, made possible by licensing initiatives of the European Archive, the Isabella Stewart Gardner Museum, Musopen, and various individual artists. The dataset consists of 34 hours of human-verified aligned recordings, containing a total of 1, 299, 329 individual labels ",Joint multi-pitch detection using harmonic envelope estimation for polyphonic music transcription | Automatic music transcription: challenges and future directions | Unsupervised transcription of piano music | End-to-end learning for music | Multiple fundamental frequency estimation by modeling spectral peaks and non-peak regions | Multipitch estimation of piano sounds using a new probabilistic spectral smoothness principle | High resolution audio synchronization using chroma features | Metric learning for temporal sequence alignment | RWC music database: Music genre database and musical instrument sound database | Deepbach: a steerable model for bach chorales generation | Towards Automatic Extraction of Harmony Information from Music Signals | Polyphonic audio matching and alignment for music retrieval | Moving beyond feature design: Deep architectures and automatic feature learning in music informatics | Understanding features and distance functions for music sequence alignment | Learning optimal features for polyphonic audio-to-score alignment | On the potential of simple framewise approaches to piano transcription | An iterative multi range non-negative matrix factorization algorithm for polyphonic music transcription | Feature learning for chord recognition: the deep chroma extractor | A weakly-supervised discriminative model for audio-to-score alignment | Learning multi-modal similarity | The million song dataset challenge | librosa: Audio and music signal analysis in python | Alignment of monophonic and polyphonic music to a score | A discriminative model for polyphonic piano transcription | Introduction to digital speech processing | Large-scale content-based matching of MIDI and audio | mir eval: A transparent implementation of common mir | Automatic segmentation of acoustic musical signals using hidden markov models | Imagenet large scale visual recognition challenge | Improving polyphonic and poly-instrumental music to score alignment | Directly modeling voiced and unvoiced components in speech waveforms by neural networks | Ground-truth transcriptions of real music from force-aligned midi syntheses | Deep content-based music recommendation | WaveNet: A generative model for raw audio,iclr,010
410.pdf.json,,"When machine learning classifiers are employed in real-world tasks, they tend to fail when the training and test distributions differ. Worse, these classifiers often fail silently by providing highconfidence predictions while being woefully incorrect (Goodfellow et al., 2015; Amodei et al., 2016). Classifiers failing to indicate when they are likely mistaken can limit their adoption or cause serious accidents. For example, a medical diagnosis model may consistently classify with high confidence, even while it should flag difficult examples for human intervention. The resulting unflagged, erroneous diagnoses could blockade future machine learning technologies in medicine. More generally and importantly, estimating when a model is in error is of great concern to AI Safety (Amodei et al., 2016). These high-confidence predictions are frequently produced by softmaxes because softmax probabilities are computed with the fast-growing exponential function. Thus minor additions to the softmax inputs, i.e. the logits, can lead to substantial changes in the output distribution. Since the softmax function is a smooth approximation of an indicator function, it is uncommon to see a uniform distribution outputted for out-of-distribution examples. Indeed, random Gaussian noise fed into an MNIST image classifier gives a “prediction confidence” or predicted class probability of 91%, as we show later. Throughout our experiments we establish that the prediction probability from a softmax distribution has a poor direct correspondence to confidence. This is consistent with a great deal of anecdotal evidence from researchers (Nguyen & O’Connor, 2015; Yu et al., 2010; Provost et al., 1998; Nguyen et al., 2015). However, in this work we also show the prediction probability of incorrect and out-of-distribution examples tends to be lower than the prediction probability for correct examples. Therefore, capturing prediction probability statistics about correct or in-sample examples is often suff","Concrete problems in ai safety | The relationship between precision-recall and ROC curves | An introduction to ROC analysis | TIMIT Acoustic-Phonetic Continuous Speech Corpus | Part-of-Speech Tagging for Twitter: Annotation, Features, and Experiments | Deep neural networks with random gaussian weights: A universal classification strategy | Explaining and harnessing adversarial examples | Connectionist temporal classification: Labeling unsegmented sequence data with recurrent neural networks | Methods for detecting adversarial images and a colorful saliency | Bridging nonlinearities and stochastic regularizers with Gaussian error linear units. arXiv, 2016b | Adjusting for dropout variance in batch normalization and weight initialization | The Aurora experimental framework for the performance evaluation of speech recognition systems under noisy conditions | Long short-term memory | Mining and Summarizing Customer Reviews | Iii. Deep Unordered Composition Rivals Syntactic Methods for Text Classification | Bag of tricks for efficient text classification | Adam: A Method for Stochastic Optimization | Learning Multiple Layers of Features from Tiny Images | Human-level concept learning through probabilistic program induction | Newsweeder: Learning to filter netnews | Rcv1: A new benchmark collection for text categorization research | Sgdr: Stochastic gradient descent with restarts | Learning word vectors for sentiment analysis | Foundations of Statistical Natural Language Processing | Building a large annotated corpus of English: The Penn Treebank | Deep neural networks are easily fooled: High confidence predictions for unrecognizable images | Posterior calibration and exploratory analysis for natural language processing models | Improved part-of-speech tagging for online conversational text with word clusters | Thumbs up? sentiment classification using machine learning techniques | The case against accuracy estimation for comparing induction algorithms | The case against accuracy estimation for comparing induction algorithms | The precision-recall plot is more informative than the ROC plot when evaluating binary classifiers on imbalanced datasets | Investigation of deep neural networks for noise robust speech recognition | Unsupervised risk estimation using only conditional independence structure | Thchs-30 : A free chinese speech corpus | Confidence measures for hybrid hmm/ann speech recognition | Sun database: Large-scale scene recognition from abbey to zoo | Calibration of confidence measures in speech recognition | Wide residual networks | Augmenting supervised neural networks with unsupervised objectives for large-scale image classification",iclr,010
411.pdf.json,,"Considering the importance of computing to human society, it is not surprising that a very large body of research has gone into the study of the syntax and semantics of programs and programming languages. Code super-optimization is an extremely important problem in this context. Given a program or a snippet of source-code, super-optimization is the task of transforming it to a version that has the same input-output behaviour but can be executed on a target compute architecture more efficiently. Superoptimization provides a natural benchmark for evaluating representations of programs. As a task, it requires the decoupling of the semantics of the program from its superfluous properties, the exact implementation. In some sense, it is the natural analogue of the paraphrase problem in natural language processing where we want to change syntax without changing semantics. Decades of research has been done on the problem of code optimization resulting in the development of sophisticated rule-based transformation strategies that are used in compilers to allow them to perform code optimization. While modern compilers implement a large set of rewrite rules and are able to achieve impressive speed-ups, they fail to offer any guarantee of optimality, thus leaving room for further improvement. An alternative approach is to search over the space of all possible programs that are equivalent to the compiler output, and select the one that is the most efficient. If the search is carried out in a brute-force manner, we are guaranteed to achieve super-optimization. However, this approach quickly becomes computationally infeasible as the number of instructions and the length of the program grows. In order to efficiently perform super-optimization, recent approaches have started to use a stochastic search procedure, inspired by Markov Chain Monte Carlo (MCMC) sampling (Schkufza et al., 2013). Briefly, the search starts at an initial program, such as the compiler output. It iteratively su",Learning to learn by gradient descent by gradient descent | Adaptive neural compilation | Torch7: A matlab-like environment for machine learning | Hc-search: A learning framework for search-based structured prediction | Gradient estimation | Likelihood ratio gradient estimation for stochastic systems | Eliminating branches using a superoptimizer and the GNU C compiler | Synthesis of loop-free programs | The informed sampler: A discriminative approach to bayesian inference in generative computer vision models | Oracle-guided component-based program synthesis | Adam: A method for stochastic optimization | Picture: A probabilistic programming language for scene perception | Learning to optimize | Superoptimizer: A look at the smallest program | Equation of state calculations by fast computing machines | Inference networks for sequential Monte Carlo in graphical models | Scaling up superoptimization | Markov chain monte carlo and variational inference: Bridging the gap | Gradient estimation using stochastic computation graphs | Simple statistical gradient-following algorithms for connectionist reinforcement learning | Learning to discover efficient mathematical identities | Integrating bottom-up/top-down for object recognition by data driven markov chain monte carlo,iclr,010
412.pdf.json,Trusting SVM for Piecewise Linear CNNs,"The backpropagation algorithm is commonly employed to estimate the parameters of a convolutional neural network (CNN) using a supervised training data set (Rumelhart et al., 1986). Part of the appeal of backpropagation comes from the fact that it is applicable to a wide variety of networks, namely those that have (sub-)differentiable non-linearities and employ a (sub-)differentiable learning objective. However, the generality of backpropagation comes at the cost of a high sensitivity to its hyperparameters such as the learning rate and momentum. Standard line-search algorithms cannot be used on the primal objective function in this setting, as (i) there may not exist a step-size guaranteeing a monotonic decrease because of the use of sub-gradients, and (ii) even in the smooth case, each function evaluation requires a forward pass over the entire data set without any update, making the approach computationally unfeasible. Choosing the learning rate thus remains an open issue, with the state-of-the-art algorithms suggesting adaptive learning rates (Duchi et al., 2011; Zeiler, 2012; Kingma & Ba, 2015). In addition, techniques such as batch normalization (Ioffe & Szegedy, 2015) and dropout (Srivastava et al., 2014) have been introduced to respectively reduce the sensitivity to the learning rate and to prevent from overfitting. With this work, we open a different line of inquiry, namely, is it possible to design more robust optimization algorithms for special but useful classes of CNNs? To this end, we focus on the networks that are commonly used in computer vision. Specifically, we consider CNNs with convolutional and dense layers that apply a set of piecewise linear (PL) non-linear operations to obtain a discriminative representation of an input image. While this assumption may sound restrictive at first, we show that commonly used non-linear operations such as ReLU and max-pool fall under the category of PL functions. The representation obtained in this way is used to",Input convex neural networks | Greedy layer-wise training of deep networks | Theano: a CPU and GPU math expression compiler | Adaptive subgradient methods for online learning and stochastic optimization | Reliably learning the ReLU in polynomial time | Deep Learning | Improper deep kernels | A fast learning algorithm for deep belief nets | DC programming: overview | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Cutting-plane training of structural SVMs | Adam: A method for stochastic optimization | Learning multiple layers of features from tiny images | Block-coordinate Frank-Wolfe optimization for structural SVMs | Difference target propagation | Optimizing neural networks with Kronecker-factored approximate curvature | Training deep and recurrent networks with hessian-free optimization | On the expressibility of piecewise-linear continuous functions as the difference of two piecewise-linear convex functions | Partial linearization based optimization for multi-class SVM | Riemannian metrics for neural networks | Minding the gaps for block Frank-Wolfe optimization of structured SVMs | Learning representations by back-propagating errors | A multi-plane block-coordinate Frank-Wolfe algorithm for training structural SVMs with a costly max-oracle | Pegasos: Primal estimated subgradient solver for SVM | Very deep convolutional networks for large-scale image recognition | Dropout: a simple way to prevent neural networks from overfitting | Training neural networks without gradients: A scalable ADMM approach | Support vector machine learning for interdependent and structured output spaces | Learning structural SVMs with latent variables | The concave-convex procedure (CCCP) | ADADELTA: an adaptive learning rate method | Convexified convolutional neural networks,iclr,010
413.pdf.json,SIGMA-DELTA QUANTIZED NETWORKS,"For most deep-learning architectures, the amount of computation required to process a sample of input data is independent of the contents of that data. Natural data tends to contain a great deal of spatial and temporal redundancy. Researchers have taken advantage of such redundancy to design encoding schemes, like jpeg and mpeg, which introduce small compromises to image fidelity in exchange for substantial savings in the amount of memory required to store images and videos. In neuroscience, it seems clear that that some kind of sparse spatio-temporal coding is going on. Koch et al. (2006) estimate that the human retina transmits 8.75Mbps, which is about the same as compressed 1080p video at 30FPS. Thus it seems natural to think that perhaps we should be doing this in deep learning. In this paper, we propose a neural network where neurons only communicate discretized changes in their activations to one another. The computational cost of running such a network would be proportional to the amount of change in the input. Neurons send signals when the change in their input accumulates past some threshold, at which point they send a discrete “spike” notifying downstream neurons of the change. Such a system has at least two advantages over the conventional way of doing things. 1. When extracting features from temporally redundant data, it is much more efficient to communicate the changes in activation than it is to re-process each frame. 2. When receiving data asynchronously from different sources (e.g. sensors, or nodes in a distributed network) at different rates, it no longer makes sense to have a global network update. We could recompute the network with every new input, reusing the stale inputs from the other sources, but this requires doing a great deal of repeated computation for only small differences in input data. We could keep a history of all inputs and update the network periodically, but then we lose the ability to respond immediately to new inputs. Our appr","Vlsi implementation of deep neural network using integral stochastic computing | Cognitive computing building block: A versatile and efficient digital neuron model for neurosynaptic cores | Fastclassifying, high-accuracy spiking deep networks through weight and threshold balancing | Convolutional networks for fast, energy-efficient neuromorphic computing | Understanding the difficulty of training deep feedforward neural networks | Neural networks for machine learning. coursera, video lectures | computing’s energy problem (and what we can do about it) | How much the eye tells the brain | Training deep spiking neural networks using backpropagation | Deep spiking networks | Very deep convolutional networks for large-scale image recognition | Herding dynamical weights to learn | Lif and simplified srm neurons encode signals into spikes via a form of asynchronous pulse sigma-delta modulation | Fast and efficient asynchronous neural computation with adapting spiking neural networks",iclr,010
415.pdf.json,REGULARIZING CNNS WITH LOCALLY CONSTRAINED DECORRELATIONS,"Neural networks perform really well in numerous tasks even when initialized randomly and trained with Stochastic Gradient Descent (SGD) (see Krizhevsky et al. (2012)). Deeper models, like Googlenet (Szegedy et al. (2015)) and Deep Residual Networks (Szegedy et al. (2015); He et al. (2015a)) are released each year, providing impressive results and even surpassing human performances in well-known datasets such as the Imagenet (Russakovsky et al. (2015)). This would not have been possible without the help of regularization and initialization techniques which solve the overfitting and convergence problems that are usually caused by data scarcity and the growth of the architectures. From the literature, two different regularization strategies can be defined. The first ones consist in reducing the complexity of the model by (i) reducing the effective number of parameters with weight decay (Nowlan & Hinton (1992)), and (ii) randomly dropping activations with Dropout (Srivastava et al. (2014)) or dropping weights with DropConnect (Wan et al. (2013)) so as to prevent feature co-adaptation. Due to their nature, although this set of strategies have proved to be very effective, they do not leverage all the capacity of the models they regularize. The second group of regularizations is those which improve the effectiveness and generality of the trained model without reducing its capacity. In this second group, the most relevant approaches decorrelate the weights or feature maps, e.g. Bengio & Bergstra (2009) introduced a new criterion so as to learn slow decorrelated features while pre-training models. In the same line Bao et al. (2013) presented ”incoherent training”, a regularizer for reducing the decorrelation of the network activations or feature maps in the context of speech recognition. Although regularizations in the second group are promising and have already been used to reduce the overfitting in different tasks, even with the presence of Dropout (as shown by Cogswell et","Incoherent training of deep neural networks to de-correlate bottleneck features for speech recognition | Slow, decorrelated features for pretraining complex cell-like networks | Negative correlations in visual cortical networks | Fast and accurate deep network learning by exponential linear units (ELUs) | Reducing overfitting in deep networks by decorrelating representations | Understanding the difficulty of training deep feedforward neural networks | Fractional max-pooling | Deep residual learning for image recognition | Delving deep into rectifiers: Surpassing human-level performance on imagenet classification | Deep networks with stochastic depth | Batch normalization: Accelerating deep network training by reducing internal covariate shift | ImageNet Classification with Deep Convolutional Neural Networks | Gradient-based learning applied to document recognition | Multi-bias non-linear activation in deep neural networks | All you need is a good init | Reading digits in natural images with unsupervised feature learning | Simplifying neural networks by soft weight-sharing | Imagenet large scale visual recognition challenge | Exact solutions to the nonlinear dynamics of learning in deep linear neural networks | Striving for simplicity: The all convolutional net | Dropout: A simple way to prevent neural networks from overfitting | Training very deep networks | Going deeper with convolutions | Regularization of neural networks using dropconnect | Wide residual networks | Wide residual networks | Visualizing and understanding convolutional networks",iclr,010
416.pdf.json,MAXIMUM ENTROPY FLOW NETWORKS,"The maximum entropy (ME) principle (Jaynes, 1957) states that subject to some given prior knowledge, typically some given list of moment constraints, the distribution that makes minimal additional assumptions – and is therefore appropriate for a range of applications from hypothesis testing to price forecasting to texture synthesis – is that which has the largest entropy of any distribution obeying those constraints. First introduced in statistical mechanics by Jaynes (1957), and considered both celebrated and controversial, ME has been extensively applied in areas including natural language processing (Berger et al., 1996), ecology (Phillips et al., 2006), finance (Buchen & Kelly, 1996), computer vision (Zhu et al., 1998), and many more. Continuous ME modeling problems typically include certain expectation constraints, and are usually solved by introducing Lagrange multipliers, which under typical assumptions yields an exponential family distribution (also called Gibbs distribution) with natural parameters such that the expectation constraints are obeyed. Unfortunately, fitting ME distributions in even modest dimensions poses significant challenges. First, optimizing the Lagrangian for a Gibbs distribution requires evaluating the normalizing constant, which is in general computationally very costly and error prone. Secondly, in all but the rarest cases, there is no way to draw samples independently and identically from this Gibbs distribution, even if one could derive it. Third, unlike in the discrete case where a number of recent and exciting works have addressed the problem of estimating entropy from discrete-valued data (Jiao et al., 2015; Valiant & Valiant, 2013), estimating differential entropy from data samples remains inefficient and typically biased. These shortcomings are critical and costly, given the common use of ME distributions for generating reference data samples for a null distribution of a test statistic. There is thus ample need for a method that","Tensorflow: Large-scale machine learning on heterogeneous distributed systems | A maximum entropy approach to natural language processing | Efficient multivariate entropy estimation via k-nearest neighbour distances | Constrained optimization and Lagrange multiplier methods | Estimation of risk-neutral densities using positive convolution approximation | Probability distributions of assets inferred from option prices via the principle of maximum entropy | The maximum entropy distribution of an asset inferred from option prices | The loss surfaces of multilayer networks | Logistic regression, adaboost and bregman distances | Generalized iterative scaling for log-linear models | Inducing features of random fields | Density estimation using real nvp | Performance guarantees for regularized maximum entropy density estimation | Estimating the implied risk neutral density | Texture synthesis using convolutional neural networks | A kernel two-sample test | Information theory and statistical mechanics | Minimax estimation of functionals of discrete distributions | Deep learning without poor local minima | Adam: A method for stochastic optimization | Auto-encoding variational bayes | Sample estimate of the entropy of a random vector | Learning frame models using cnn filters | A comparison of algorithms for maximum entropy parameter estimation | Learning in implicit generative models | Maximum entropy modeling of species geographic distributions | Exponential expressivity in deep neural networks through transient chaos | A parametric texture model based on joint statistics of complex wavelet coefficients | On the expressive power of deep neural networks | Variational inference with normalizing flows | On the convergence of bound optimization algorithms | Texture networks: Feedforward synthesis of textures and stylized images | Improved texture networks: Maximizing quality and diversity in feed-forward stylization and texture synthesis | Estimating the unseen: improved estimators for entropy and other properties | Adadelta: an adaptive learning rate method | Filters, random fields and maximum entropy (frame): Towards a unified theory for texture modeling | 2016), but we leave such attempts for our case for future research",iclr,010
418.pdf.json,UNROLLED GENERATIVE ADVERSARIAL NETWORKS,"The use of deep neural networks as generative models for complex data has made great advances in recent years. This success has been achieved through a surprising diversity of training losses and model architectures, including denoising autoencoders (Vincent et al., 2010), variational autoencoders (Kingma & Welling, 2013; Rezende et al., 2014; Gregor et al., 2015; Kulkarni et al., 2015; Burda et al., 2015; Kingma et al., 2016), generative stochastic networks (Alain et al., 2015), diffusion probabilistic models (Sohl-Dickstein et al., 2015), autoregressive models (Theis & Bethge, 2015; van den Oord et al., 2016a;b), real non-volume preserving transformations (Dinh et al., 2014; 2016), Helmholtz machines (Dayan et al., 1995; Bornschein et al., 2015), and Generative Adversarial Networks (GANs) (Goodfellow et al., 2014).","Learning to learn by gradient descent by gradient descent | Structured prediction energy networks | Bidirectional helmholtz machines | Multiagent learning using a variable learning rate | Importance weighted autoencoders | Semantic style transfer and turning two-bit doodles into fine artworks | Mode regularized generative adversarial networks | Infogan: Interpretable representation learning by information maximizing generative adversarial nets | The theory of max-min and its application to weapons allocation problems, volume | The helmholtz machine | NICE: non-linear independent components estimation | Density estimation using real NVP | Adversarially learned inference | Understanding the difficulty of training deep feedforward neural networks | Generative adversarial nets | DRAW: A recurrent neural network for image generation | Alternating back-propagation for generator network, 2016 | Long short-term memory | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Perceptual losses for real-time style transfer and super-resolution | First order methods for nonsmooth convex large-scale optimization, i: general purpose methods | Adam: A method for stochastic optimization | Auto-encoding variational bayes | Improving variational inference with inverse autoregressive flow | Deep convolutional inverse graphics network | Photo-realistic single image super-resolution using a generative adversarial network, 2016 | Gradient-based hyperparameter optimization through reversible learning | Synthesizing the preferred inputs for neurons in neural networks via deep generator networks | f-gan: Training generative neural samplers using variational divergence minimization | Conditional image synthesis with auxiliary classifier gans | Reverse-mode ad in a functional framework: Lambda the ultimate backpropagator | Improved generator objectives for gans | Unsupervised representation learning with deep convolutional generative adversarial networks | Learning what and where to draw | Generative adversarial text-to-image synthesis | Stochastic backpropagation and variational inference in deep latent gaussian models | Improved techniques for training gans | Deep inside convolutional networks: Visualising image classification models and saliency maps | Nash convergence of gradient dynamics in general-sum games | Deep unsupervised learning using nonequilibrium thermodynamics | Amortised map inference for image super-resolution, 2016 | Generative image modeling using spatial lstms | A note on the evaluation of generative models | Lecture 6.5—RmsProp: Divide the gradient by a running average of its recent magnitude | Pixel recurrent neural networks | Conditional image generation with pixelcnn decoders | Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion | Understanding neural networks through deep visualization | Multi-agent learning with policy prediction | Energy-based generative adversarial network | Generative visual manipulation on the natural image manifold",iclr,010
419.pdf.json,TOPICRNN: A RECURRENT NEURAL NETWORK WITH LONG-RANGE SEMANTIC DEPENDENCY,"When reading a document, short or long, humans have a mechanism that somehow allows them to remember the gist of what they have read so far. Consider the following example: “The U.S.presidential race isn’t only drawing attention and controversy in the United States – it’s being closely watched across the globe. But what does the rest of the world think about a campaign that has already thrown up one surprise after another? CNN asked 10 journalists for their take on the race so far, and what their country might be hoping for in America’s next —” The missing word in the text above is easily predicted by any human to be either President or Commander in Chief or their synonyms. There have been various language models – from simple ngrams to the most recent RNN-based language models – that aim to solve this problem of predicting correctly the subsequent word in an observed sequence of words. A good language model should capture at least two important properties of natural language. The first one is correct syntax. In order to do prediction that enjoys this property, we often only need to consider a few preceding words. Therefore, correct syntax is more of a local property. Word order matters in this case. The second property is the semantic coherence of the prediction. To achieve ∗Work was done while at Microsoft Research. this, we often need to consider many preceding words to understand the global semantic meaning of the sentence or document. The ordering of the words usually matters much less in this case. Because they only consider a fixed-size context window of preceding words, traditional n-gram and neural probabilistic language models (Bengio et al., 2003) have difficulties in capturing global semantic information. To overcome this, RNN-based language models (Mikolov et al., 2010; 2011) use hidden states to “remember” the history of a word sequence. However, none of these approaches explicitly model the two main properties of language mentioned above, correct synt",Learning long-term dependencies with gradient descent is difficult | A neural probabilistic language model | Correlated topic models | Latent dirichlet allocation | Structured language modeling | One billion word benchmark for measuring progress in statistical language modeling | Learning phrase representations using rnn encoder-decoder for statistical machine translation | Semi-supervised sequence learning | Dependence language model for information retrieval | Contextual lstm (clstm) models for large scale nlp tasks | Long short-term memory | Document context language models | A latent variable recurrent neural network for discourse relation language models | An introduction to variational methods for graphical models | Exploring the limits of language modeling | Adam: A method for stochastic optimization | Auto-encoding variational bayes | Distributed representations of sentences and documents | Hierarchical recurrent neural network for document modeling | Learning word vectors for sentiment analysis | Building a large annotated corpus of english: The penn treebank | Neural variational inference for text processing | Context dependent recurrent neural network language model | Recurrent neural network based language model | Extensions of recurrent neural network language model | Learning longer memory in recurrent neural networks | Optimizing semantic coherence in topic models | Adversarial training methods for semi-supervised text classification | On the difficulty of training recurrent neural networks | Stochastic backpropagation and approximate inference in deep generative models | Dropout: a simple way to prevent neural networks from overfitting | Training recurrent neural networks | Topic modeling: beyond bag-of-words | Rethinking lda: Why priors matter. In Advances in neural information processing,iclr,010
420.pdf.json,FRUSTRATINGLY SHORT ATTENTION SPANS IN NEURAL LANGUAGE MODELING,"At the core of language models (LMs) is their ability to infer the next word given a context. This requires representing context-specific dependencies in a sequence across different time scales. On the one hand, classical N -gram language models capture relevant dependencies between words in short time distances explicitly, but suffer from data sparsity. Neural language models, on the other hand, maintain and update a dense vector representation over a sequence where time dependencies are captured implicitly (Mikolov et al., 2010). A recent extension of neural sequence models are attention mechanisms (Bahdanau et al., 2015), which can capture long-range connections more directly. However, we argue that applying such an attention mechanism directly to neural language models requires output vectors to fulfill several purposes at the same time: they need to (i) encode a distribution for predicting the next token, (ii) serve as a key to compute the attention vector, as well as (iii) encode relevant content to inform future predictions. We hypothesize that such overloaded use of output representations makes training the model difficult and propose a modification to the attention mechanism which separates these functions explicitly, inspired by Miller et al. (2016); Ba et al. (2016); Reed & de Freitas (2015); Gulcehre et al. (2016). Specifically, at every time step our neural language model outputs three vectors. The first is used to encode the next-word distribution, the second serves as key, and the third as value for an attention mechanism. We term the model key-value-predict attention and show that it outperforms existing memory-augmented neural language models on the Children’s Book Test (CBT, Hill et al., 2016) and a new corpus of 7500 Wikipedia articles. However, we observed that this model pays attention mainly to the previous five memories. We thus also experimented with a much simpler model that only uses a concatenation of output vectors from the previous time ","Using fast weights to attend to the recent past | Neural machine translation by jointly learning to align and translate | One billion word benchmark for measuring progress in statistical language modeling | Long short-term memory-networks for machine reading | Attention-based models for speech recognition | Attention-over-attention neural networks for reading comprehension | Consensus attention-based neural networks for chinese reading comprehension | Gated-attention readers for text comprehension | Neural turing machines | Dynamic neural turing machine with soft and hard addressing schemes | The goldilocks principle: Reading children’s books with explicit memory representations | Long short-term memory | Blackout: Speeding up recurrent neural network language models with very large vocabularies | Exploring the limits of language modeling | Text understanding with the attention sum reader network | Adam: A method for stochastic optimization | Recurrent neural network based language model | Empirical evaluation and combination of advanced language modeling techniques | Key-value memory networks for directly reading documents | On the difficulty of training recurrent neural networks | Reasoning about entailment with neural attention | Learning internal representations by error propagation | A neural attention model for abstractive sentence summarization | Sparse non-negative matrix language modeling for skip-grams | Higher order recurrent neural networks | Learning matrices and their applications | End-to-end memory networks | Pattern recognition by means of automatic analogue apparatus | Recurrent memory networks for language modeling | Natural language comprehension with the epireader | Separating answers from queries for neural reading comprehension | Backpropagation through time: what it does and how to do it | Scaling recurrent neural network language models | Show, attend and tell: Neural image caption generation with visual attention | Reference-aware language models",iclr,010
421.pdf.json,RECURRENT HIDDEN SEMI-MARKOV MODEL,"Segmentation and labeling of time series data is an important problem in machine learning and signal processing. Given a sequence of observations {x1, x2, . . . , xT }, we want to divide the T observations into several segments and label each segment simultaneously, where each segment consists of consecutive observations. The supervised sequence segmentation or labeling techniques have been well studied in recent decades (Sutskever et al., 2014; Kong et al., 2015; Chen et al., 2015). However, for complicated signals, like human activity sensor data, accurately annotating the segmentation boundary or the activity type would be prohibitive. Therefore, it is urgent to develop unsupervised algorithms that can jointly learn segmentation and labeling information directly from the data without supervisions. Figure 1 provides an illustration which we are focus on. The Hidden Semi-Markov Model (HSMM) (Murphy, 2002) is a powerful model for such task. It eliminates the implicit geometric duration distribution assumptions in HMM (Yu, 2010), thus allows the state to transit in a non-Markovian way. Most of the HSMM variants make strong parametric assumptions on the observation model (Rabiner, 1989; Johnson & Willsky, 2013; Yu, 2010). This makes the learning and inference simple, but ignores the nonlinear and long-range dependency within a segment. Take the human activity signals as an example. The movements a person performs at a certain time step would rely heavily on the previous movements, like the interleaving actions of left hand and right hand in swimming, or more complicated dependency like shooting after jumping in playing basketball. Some models have been proposed to tackle this problem (Ghahramani & Hinton, 2000; Fox et al., 2009; Linderman et al., 2016), but are limited in linear case. Since people have justified RNN’s ability in modeling nonlinear and complicated dependencies (Sutskever et al., 2014; Du et al., 2016), we introduce the recurrent neural emission model i",Conditional random field autoencoders for unsupervised structured prediction | Estimating or propagating gradients through stochastic neurons for conditional computation | Nonlinear Programming | Gated recursive neural network for chinese word segmentation | Explicit-duration markov switching models | Hierarchical multiscale recurrent neural networks | Provable bayesian inference via particle mirror descent | Recurrent marked temporal point processes: Embedding event history to vector | Nonparametric bayesian learning of switching linear dynamical systems | Linear dynamical neural population models through nonlinear embeddings | Variational learning for switching state-space models | Muprop: Unbiased backpropagation for stochastic neural networks | Long short-term memory | Stochastic variational inference for bayesian time series models | Bayesian nonparametric hidden semi-markov models | Structured vaes: Composing probabilistic graphical models and variational autoencoders | Leg-tracking and automated behavioural classification in drosophila | Adam: A method for stochastic optimization | Auto-encoding variational bayes | Segmental recurrent neural networks | Deep kalman filters | Recurrent switching linear dynamical systems | crfchain: Matlab code for chain-structured conditional random fields with categorical features | Neural variational inference and learning in belief networks | Variational inference for monte carlo objectives | Algorithms for the assignment and transportation problems | Hidden semi-markov models (hsmms) | Machine learning: a probabilistic perspective | A tutorial on hidden markov models and selected applications in speech recognition | Techniques for learning binary stochastic feedforward neural networks | Transition-aware human activity recognition using smartphones | Logistic regression-hsmm-based heart sound segmentation | Sequence to sequence learning with neural networks. In Advances in neural information processing | Learning stochastic feedforward neural networks | Bayesian conditionalisation and the principle of minimum information | Hidden semi-markov models | An efficient forward-backward algorithm for an explicitduration hidden markov model | Optimal Information Processing and Bayes’s Theorem,iclr,010
422.pdf.json,DEEP VARIATIONAL BAYES FILTERS: UNSUPERVISED LEARNING OF STATE SPACE MODELS FROM RAW DATA,"Estimating probabilistic models for sequential data is central to many domains, such as audio, natural language or physical plants, Graves (2013); Watter et al. (2015); Chung et al. (2015); Deisenroth & Rasmussen (2011); Ko & Fox (2011). The goal is to obtain a model p(x1:T ) that best reflects a data set of observed sequences x1:T . Recent advances in deep learning have paved the way to powerful models capable of representing high-dimensional sequences with temporal dependencies, e.g., Graves (2013); Watter et al. (2015); Chung et al. (2015); Bayer & Osendorfer (2014). Time series for dynamic systems have been studied extensively in systems theory, cf. McGoff et al. (2015) and sources therein. In particular, state space models have shown to be a powerful tool to analyze and control the dynamics. Two tasks remain a significant challenge to this day: Can we identify the governing system from data only? And can we perform inference from observables to the latent system variables? These two tasks are competing: A more powerful representation of system requires more computationally demanding inference, and efficient inference, such as the well-known Kalman filters, Kalman & Bucy (1961), can prohibit sufficiently complex system classes. Leveraging a recently proposed estimator based on variational inference, stochastic gradient variational Bayes (SGVB, Kingma & Welling (2013); Rezende et al. (2014)), approximate inference of latent variables becomes tractable. Extensions to time series have been shown in Bayer & Osendorfer (2014); Chung et al. (2015). Empirically, they showed considerable improvements in marginal data likelihood, i.e., compression, but lack full-information latent states, which prohibits, e.g., long-term sampling. Yet, in a wide range of applications, full-information latent states should be valued over compression. This is crucial if the latent spaces are used in downstream applications. Our contribution is, to our knowledge, the first model that (i) en","Learning stochastic recurrent networks | Weight uncertainty in neural networks | Large-scale machine learning with stochastic gradient descent | A recurrent latent variable model for sequential data | Pilco: A model-based and data-efficient approach to policy search | Parameter estimation for linear dynamical systems | Variational learning for switching state-space models | Generating sequences with recurrent neural networks | Keeping the neural networks simple by minimizing the description length of the weights | Approximate riemannian conjugate gradient learning for fixed-form variational bayes | Structured VAEs: Composing probabilistic graphical models and variational autoencoders | New extension of the kalman filter to nonlinear systems | New results in linear filtering and prediction theory | Auto-encoding variational bayes | Learning gp-bayesfilters via gaussian process latent variable models | Variational tempering | Statistical inference for dynamical systems: A review | Stochastic backpropagation and approximate inference in deep generative models | Variational inference with normalizing flows | Learning multilevel distributed representations for high-dimensional sequences | Model-based reinforcement learning with an approximate, learned model | A note on the evaluation of generative models | An unsupervised ensemble learning method for nonlinear dynamic state-space models | Embed to control: A locally linear latent dynamics model for control from raw images",iclr,010
423.pdf.json,GENERATIVE MULTI-ADVERSARIAL NETWORKS,"Generative adversarial networks (Goodfellow et al. (2014)) (GANs) are a framework for producing a generative model by way of a two-player minimax game. One player, the generator, attempts to generate realistic data samples by transforming noisy samples, z, drawn from a simple distribution (e.g., z ∼ N (0, 1)) using a transformation function Gθ(z) with learned weights, θ. The generator receives feedback as to how realistic its synthetic sample is from another player, the discriminator, which attempts to discern between synthetic data samples produced by the generator and samples drawn from an actual dataset using a function Dω(x) with learned weights, ω. The GAN framework is one of the more recent successes in a line of research on adversarial training in machine learning (Schmidhuber (1992); Bagnell (2005); Ajakan et al. (2014)) where games between learners are carefully crafted so that Nash equilibria coincide with some set of desired optimality criteria. Preliminary work on GANs focused on generating images (e.g., MNIST (LeCun et al. (1998)), CIFAR (Krizhevsky (2009))), however, GANs have proven useful in a variety of application domains including learning censored representations (Edwards & Storkey (2015)), imitating expert policies (Ho & Ermon (2016)), and domain transfer (Yoo et al. (2016)). Work extending GANs to semi-supervised learning (Chen et al. (2016); Mirza & Osindero (2014); Gauthier (2014); Springenberg (2015)), inference (Makhzani et al. (2015); Dumoulin et al. (2016)), feature learning (Donahue et al. (2016)), and improved image generation (Im et al. (2016); Denton et al. (2015); Radford et al. (2015)) have shown promise as well. Despite these successes, GANs are reputably difficult to train. While research is still underway to improve training techniques and heuristics (Salimans et al. (2016)), most approaches have focused on understanding and generalizing GANs theoretically with the aim of exploring more tractable formulations (Zhao et al. (2016);","Tensorflow: Large-scale machine learning on heterogeneous distributed systems | Robust supervised learning | Optimal and adaptive algorithms for online boosting | Infogan: Interpretable representation learning by information maximizing generative adversarial nets | Deep generative image models using a laplacian pyramid of adversarial networks | Adversarial feature learning | Adversarially learned inference | Censoring representations with an adversary | Conditional generative adversarial nets for convolutional face generation. Class Project for Stanford CS231N: Convolutional Neural Networks for Visual Recognition, Winter semester | Generative adversarial nets | Generative adversarial imitation learning | Generating images with recurrent adversarial networks | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Adam: A method for stochastic optimization | Learning multiple layers of features from tiny images | The mnist database of handwritten digits | Generative moment matching networks | Deep learning face attributes in the wild | Conditional generative adversarial nets | f-gan: Training generative neural samplers using variational divergence minimization | Unsupervised representation learning with deep convolutional generative adversarial networks | Enabling dark energy science with deep generative models of galaxy images | Improved techniques for training gans | Learning factorial codes by predictability minimization | Unsupervised and semi-supervised learning with categorical generative adversarial networks | A note on the evaluation of generative models | Generative adversarial nets from a density ratio estimation perspective | Pixel-level domain transfer | Deconvolutional networks | Energy-based generative adversarial network",iclr,010
424.pdf.json,,"In the last few years, deep neural networks – i.e. convolutional networks (LeCun et al., 1989), LSTMs (Hochreiter & Schmidhuber, 1997a) or GRUs (Cho et al., 2014) – set the state of the art on a range of challenging tasks (Szegedy et al., 2014; Visin et al., 2015; Hinton et al., 2012; Sutskever et al., 2014; Bahdanau et al., 2014; Mnih et al., 2013; Silver et al., 2016). However when trained with variants of SGD (Bottou, 1998) deep networks can be difficult to optimize due to their highly non-linear and non-convex nature (Choromanska et al., 2014; Dauphin et al., 2014). A number of approaches were proposed to alleviate the difficulty of optimization: addressing the problem of the internal covariate shift with Batch Normalization (Ioffe & Szegedy, 2015), learning with a curriculum (Bengio et al., 2009), recently an approach to train RNNs with diffusion process (Mobahi, 2016), and graduated optimization (Hazan et al., 2015). The impact of noise injection on the behavior of modern deep learning methods has been explored by Neelakantan et al. (2015a). Hazan et al. (2015) have shown that injecting a particular noise and scheduling it carefully, can guarantee the convergence in O(1/σ2 2) steps for -optimal and σ-nice functions. Similar to our work graduated optimization optimizes a smoothed objective function without performing expensive convolutions. Injecting noise to the activation functions and scheduling it have been recently shown to improve the performance on a wide variety of tasks (Gulcehre et al., 2016). We connect the ideas of curriculum learning and continuation methods with those arising from models with skip connections and using layers that compute near-identity transformations. Skip connections allow to train very deep residual and highway architectures (He et al., 2015; Srivastava et al., 2015) by skipping layers or block of layers. Similarly, it has been shown that stochastically changing the depth of a network during training (Huang et al., 2016b) does ",Numerical Continuation Methods | Neural machine translation by jointly learning to align and translate | Scheduled sampling for sequence prediction with recurrent neural networks | Curriculum learning | Online algorithms and stochastic approximations | Learning phrase representations using rnn encoder-decoder for statistical machine translation | The loss surface of multilayer | Identifying and attacking the saddle point problem in high-dimensional non-convex optimization | Partial differential equations | Deep sparse rectifier neural networks | Practical variational inference for neural networks | Adaptive computation time for recurrent neural networks | Knowledge matters: Importance of prior information for optimization | Learned-norm pooling for deep feedforward and recurrent neural networks | Noisy activation functions | On graduated optimization for stochastic non-convex problems | Deep residual learning for image recognition | Deep neural networks for acoustic modeling in speech recognition | Keeping neural networks simple | Long short-term memory | Deep networks with stochastic depth | Deep networks with stochastic depth | Batch normalization: Accelerating deep network training by reducing internal covariate | Neural gpus learn algorithms | Grid long short-term memory | Adam: A method for stochastic optimization | Optimization by simulated annealing | Backpropagation applied to handwritten zip code recognition | The mnist database of handwritten digits | Playing atari with deep reinforcement learning | Training recurrent neural networks by diffusion | Rectified linear units improve restricted boltzmann machines | Adding gradient noise improves learning for very deep | Adding gradient noise improves learning for very deep networks | Shaping and policy search in reinforcement learning | Policy invariance under reward transformations: Theory and application to reward shaping | Mastering the game of go with deep neural networks and tree | Gradual dropin of layers to train very deep neural networks | Training very deep networks | Sequence to sequence learning with neural networks. In Advances in neural information processing | Going deeper with convolutions | Theano Development Team. Theano: A Python framework for fast computation of mathematical expressions,iclr,010
426.pdf.json,,"Monolingual word vectors embed language in a high-dimensional vector space, such that the similarity of two words is defined by their proximity in this space (Mikolov et al., 2013b). They enable us to train sophisticated classifiers to interpret free flowing text (Kim, 2014), but they require independent models to be trained for each language. Crucially, training text obtained in one language cannot improve the performance of classifiers trained in another, unless the text is explicitly translated. Increasing interest is now focused on bilingual vectors, in which words are aligned by their meaning, irrespective of the language of origin. Such vectors may drive improvements in machine translation (Zou et al., 2013), and enable language-agnostic text classifiers (Klementiev et al., 2012). They can also be higher quality than monolingual vectors (Faruqui & Dyer, 2014). Bilingual vectors are normally trained “online”, whereby both languages are learnt together in a shared space (Chandar et al., 2014; Hermann & Blunsom, 2013). Typically these algorithms exploit two sources of monolingual text alongside a smaller bilingual corpus of aligned sentences. This bilingual signal provides a regularisation term, which penalises the embeddings if similar words in the two languages do not lie nearby in the vector space. However Mikolov et al. (2013a) showed that bilingual word vectors can also be obtained “offline”. Two sets of word vectors in different languages were first obtained independently, and then a linear matrix W was trained using a dictionary to map word vectors from the “source” language into the “target” language. Remarkably, this simple procedure was able to translate a test set of English words into Spanish with 33% precision. To develop an intuition for these two approaches, we note that the similarity of two word vectors is defined by their cosine similarity, cos(θij) = yTi xj/|yi||xj |. The vectors have no intrinsic meaning, it is only the angles between vectors ",Massively multilingual word embeddings | Learning principled bilingual mappings of word embeddings while preserving monolingual invariance | An autoencoder approach to learning bilingual word representations | Improving zero-shot learning by mitigating the hubness problem | Improving vector space word representations using multilingual correlation | Bilbowa: Fast bilingual distributed representations without word alignments | Learning bilingual lexicons from monolingual corpora | Multilingual distributed representations without word alignment | Convolutional neural networks for sentence classification | Skip-thought vectors. In Advances in neural information processing | Inducing crosslingual distributed representations of words | Europarl: A parallel corpus for statistical machine translation | Distributed representations of sentences and documents | Deep multilingual correlation for improved word embeddings | Exploiting similarities among languages for machine translation | Distributed representations of words and phrases and their compositionality | Canonical correlation clarified by singular value decomposition | A generalized solution of the orthogonal procrustes problem | Normalized word embedding and orthogonal transform for bilingual word translation | Bilingual word embeddings for phrase-based machine translation,iclr,010
427.pdf.json,VISUALIZING DEEP NEURAL NETWORK DECISIONS: PREDICTION DIFFERENCE ANALYSIS,"Over the last few years, deep neural networks (DNNs) have emerged as the method of choice for perceptual tasks such as speech recognition and image classification. In essence, a DNN is a highly complex non-linear function, which makes it hard to understand how a particular classification comes about. This lack of transparency is a significant impediment to the adoption of deep learning in areas of industry, government and healthcare where the cost of errors is high. In order to realize the societal promise of deep learning - e.g., through self-driving cars or personalized medicine - it is imperative that classifiers learn to explain their decisions, whether it is in the lab, the clinic, or the courtroom. In scientific applications, a better understanding of the complex dependencies learned by deep networks could lead to new insights and theories in poorly understood domains. In this paper, we present a new, probabilistically sound methodology for explaining classification decisions made by deep neural networks. The method can be used to produce a saliency map for each (instance, node) pair that highlights the parts (features) of the input that constitute most evidence for or against the activation of the given (internal or output) node. See figure 1 for an example. In the following two sections, we review related work and then present our approach. In section 4 we provide several demonstrations of our technique for deep convolutional neural networks (DCNNs) trained on ImageNet data, and further how the method can be applied when classifying MRI brain scans of HIV patients with neurodegenerative disease.","Non-linear optimisation. fmrib technical report tr07ja1 | On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation | Describing the brain in autism in five dimensions—magnetic resonance imaging-assisted diagnosis of autism spectrum disorder using a multiparameter classification approach | Visualizing higher-layer features of a deep network | Analytic estimation of statistical significance maps for support vector machine based multi-variate image analysis and classification | On the interpretation of weight vectors of linear models in multivariate neuroimaging | Caffe: Convolutional architecture for fast feature embedding | Automatic classification of mr scans in alzheimer’s disease | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | Classifying brain states and determining the discriminating activation patterns: Support vector machine on functional mri data | Explaining classifications for individual instances | ImageNet Large Scale Visual Recognition Challenge | A data-centric neuroscience gateway: design, implementation, and experiences | Not just a black box: Learning important features through propagating activation differences | Very deep convolutional networks for large-scale image recognition | Deep inside convolutional networks: Visualising image classification models and saliency maps | Going deeper with convolutions | Support vector machine learning-based fmri data group analysis | Understanding neural networks through deep visualization | Visualizing and understanding convolutional networks | Learning deep features for discriminative localization",iclr,010
430.pdf.json,LATENT SEQUENCE DECOMPOSITIONS,"Sequence-to-sequence (seq2seq) models (Sutskever et al., 2014; Cho et al., 2014) with attention (Bahdanau et al., 2015) have been successfully applied to many applications including machine translation (Luong et al., 2015; Jean et al., 2015), parsing (Vinyals et al., 2015a), image captioning (Vinyals et al., 2015b; Xu et al., 2015) and Automatic Speech Recognition (ASR) (Chan et al., 2016; Bahdanau et al., 2016a). Previous work has assumed a fixed deterministic decomposition for each output sequence. The output representation is usually a fixed sequence of words (Sutskever et al., 2014; Cho et al., 2014), phonemes (Chorowski et al., 2015), characters (Chan et al., 2016; Bahdanau et al., 2016a) or even a mixture of characters and words (Luong & Manning, 2016). However, in all these cases, the models are trained towards one fixed decomposition for each output sequence. We argue against using fixed deterministic decompositions of a sequence that has been defined a priori. Word segmented models (Luong et al., 2015; Jean et al., 2015) often have to deal with large softmax sizes, rare words and Out-of-Vocabulary (OOV) words. Character models (Chan et al., 2016; Bahdanau et al., 2016a) overcome the OOV problem by modelling the smallest output unit, however this typically results in long decoder lengths and computationally expensive inference. And even with mixed (but fixed) character-word models (Luong & Manning, 2016), it is unclear whether such a predefined segmentation is optimal. In all these examples, the output decomposition is only ∗Work done at Google Brain. a function of the output sequence. This may be acceptable for problems such as translations, but inappropriate for tasks such as speech recognition, where segmentation should also be informed by the characteristics of the inputs, such as audio. We want our model to have the capacity and flexibility to learn a distribution of sequence decompositions. Additionally, the decomposition should be a sequence of variab","TensorFlow: Large-scale machine learning on heterogeneous systems | Neural Machine Translation by Jointly Learning to Align and Translate | Endto-end Attention-based Large Vocabulary Speech Recognition | Task Loss Estimation for Sequence Prediction | Listen, Attend and Spell: A Neural Network for Large Vocabulary Conversational Speech Recognition | Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation | Attention-Based Models for Speech Recognition | Wav2Letter: an End-to-End ConvNetbased Speech Recognition System | Practical Variational Inference for Neural Networks | Towards End-to-End Speech Recognition with Recurrent Neural Networks | Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks | Hybrid Speech Recognition with Bidirectional LSTM | First-Pass Large Vocabulary Continuous Speech Recognition using Bi-Directional Recurrent DNNs | Hierarchical Recurrent Neural Networks for Long-Term Dependencies | Long Short-Term Memory | On Using Very Large Target Vocabulary for Neural Machine Translation | Adam: A Method for Stochastic Optimization | A Clockwork RNN | Latent Predictor Networks for Code Generation | Acoustic data-driven pronunciation lexicon for large vocabulary speech recognition | Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models | Addressing the Rare Word Problem in Neural Machine Translation | Learning Lexicons From Speech Using a Pronunciation Mixture Model | The Kaldi Speech Recognition Toolkit | Sequence Level Training with Recurrent Neural Networks | Japanese and Korean Voice Search | Bidirectional Recurrent Neural Networks | Neural Machine Translation of Rare Words with Subword Units | Automatic generation of subword units for speech recognition systems | Sequence to Sequence Learning with Neural Networks | Reinforcement Learning: An Introduction | Grammar as a foreign language | Show and Tell: A Neural Image Caption Generator | Order Matters: Sequence to sequence for sets | Show, Attend and Tell: Neural Image Caption Generation with Visual Attention | Very deep convolutional networks for end-to-end speech recognition | Advances in All-Neural Speech Recognition",iclr,010
431.pdf.json,PALEO: A PERFORMANCE MODEL FOR DEEP NEURAL NETWORKS,"Deep learning has been successfully applied in many areas including natural language processing and computer vision. The scale of modern datasets and the millions to billions of parameters in these deep networks pose new challenges when designing computational systems that leverage parallel and distributed computing. Indeed, several important open questions remain: • How fast can we train or evaluate a model on a user’s given hardware? • For a given architecture, how can a user best leverage parallel and distributed computation? • How can we design a new neural network architecture that can be trained and evaluated efficiently under common hardware setups? In response to these fundamental questions, various software packages and systemshave been painstakingly developed, e.g. DistBelief (Dean et al., 2012), TensorFlow (Abadi et al., 2015), MXNet (Chen et al., 2015), SparkNet (Moritz et al., 2015), FireCaffe (Iandola et al., 2016). Moreover, expensive benchmarking efforts, e.g., Chintala et al. (2016), have performed brute-force profiling on some of these deep learning systems on a handful network architectures. In this work we aim to tackle these questions by taking an analytical approach to model the performance of arbitrary learning systems. Our work hinges on the observation that a neural network architecture is a declarative specification of the forward and backward propagation steps required for training and deploying the network. However, given this specification, there is a rich design space of algorithms, hardware choices, and communications strategies to most efficiently execute these specifications. We build a novel performance model called PALEO1 that maps this declarative specification to arbitrary points in this design space to estimate the execution time of training and 1Open-sourced at https://github.com/TalwalkarLab/paleo. deploying deep neural networks.2 PALEO applies broadly to a wide variety of neural network architectures and for arbitrary learnin","Tensorflow: Large-scale machine learning on heterogeneous systems, 2015 | The effects of hyperparameters on sgd training of neural networks | Mxnet: A flexible and efficient machine learning library for heterogeneous distributed systems | cudnn: Efficient primitives for deep learning | convnet-benchmarks, 2016. URL https://github.com/soumith/ convnet-benchmarks | Deep learning with cots hpc systems | An algorithm for the machine calculation of complex fourier series | Large scale distributed deep networks | Firecaffe: near-linear acceleration of deep neural network training on compute clusters | cuda-convnet2, 2014a. URL https://github.com/akrizhevsky/ cuda-convnet2 | One weird trick for parallelizing convolutional neural networks | Fast algorithms for convolutional neural networks | Sparknet: Training deep networks in spark | Announcing tensorflow 0.8 now with distributed computing support!, 2016 | Unsupervised representation learning with deep convolutional generative adversarial networks | Very deep convolutional networks for large-scale image recognition | Going deeper with convolutions | Rethinking the inception architecture for computer vision | Fast convolutional nets with fbfft: A gpu performance evaluation | Minimizing development and maintenance costs in supporting persistently optimized BLAS | Butterfly mixing: Accelerating incremental-update algorithms on clusters",iclr,010
432.pdf.json,,"In reinforcement learning an agent explores an environment and through the use of a reward signal learns to optimize its behavior to maximize the expected long-term return. Reinforcement learning has seen success in several areas including robotics (Lin, 1993; Levine et al., 2015), computer games (Mnih et al., 2013; 2015), online advertising (Pednault et al., 2002), board games (Tesauro, 1995; Silver et al., 2016), and many others. For an introduction to reinforcement learning we refer to the classic text by Sutton & Barto (1998). In this paper we consider model-free reinforcement learning, where the state-transition function is not known or learned. There are many different algorithms for model-free reinforcement learning, but most fall into one of two families: action-value fitting and policy gradient techniques. Action-value techniques involve fitting a function, called the Q-values, that captures the expected return for taking a particular action at a particular state, and then following a particular policy thereafter. Two alternatives we discuss in this paper are SARSA (Rummery & Niranjan, 1994) and Q-learning (Watkins, 1989), although there are many others. SARSA is an on-policy algorithm whereby the action-value function is fit to the current policy, which is then refined by being mostly greedy with respect to those action-values. On the other hand, Q-learning attempts to find the Qvalues associated with the optimal policy directly and does not fit to the policy that was used to generate the data. Q-learning is an off-policy algorithm that can use data generated by another agent or from a replay buffer of old experience. Under certain conditions both SARSA and Q-learning can be shown to converge to the optimal Q-values, from which we can derive the optimal policy (Sutton, 1988; Bertsekas & Tsitsiklis, 1996). In policy gradient techniques the policy is represented explicitly and we improve the policy by updating the parameters in the direction of the gradient ","Natural gradient works efficiently in learning | Dynamic policy programming | Covariant policy search | Advantage updating | The arcade learning environment: An evaluation platform for general agents | Dynamic programming | Dynamic programming and optimal control, volume 1 | Off-policy actor-critic | Taming the noise in reinforcement learning via soft updates | On-policy vs. off-policy updates for deep reinforcement learning. Deep Reinforcement Learning: Frontiers and Challenges | Actor-critic reinforcement learning with energybased policies | A natural policy gradient | On actor-critic algorithms | Policy gradient methods for off-policy control | Guided policy search | End-to-end training of deep visuomotor policies | Continuous control with deep reinforcement learning | Reinforcement learning for robots using neural networks | Playing atari with deep reinforcement learning | Human-level control through deep reinforcement learning | Asynchronous methods for deep reinforcement learning | Reward augmented maximum likelihood for neural structured prediction | Revisiting natural gradient for deep networks | Sequential cost-sensitive decision making with reinforcement learning | Incremental multi-step Q-learning | Relative entropy policy search | Neural fitted Q iteration–first experiences with a data efficient neural reinforcement learning method | On-line Q-learning using connectionist systems | Reinforcement learning with factored states and actions | Prioritized experience replay | Trust region policy optimization | Deterministic policy gradient algorithms | Mastering the game of go with deep neural networks and tree | Reinforcement Learning: an Introduction | Learning to predict by the methods of temporal differences | Policy gradient methods for reinforcement learning with function approximation | Temporal difference learning and TD-Gammon | Bias in natural actor-critic algorithms | Deep reinforcement learning with double Qlearning | A theoretical and empirical analysis of expected sarsa | Backward q-learning: The combination of sarsa algorithm and q-learning | Dueling network architectures for deep reinforcement learning | Learning from delayed rewards | Simple statistical gradient-following algorithms for connectionist reinforcement learning | Function optimization using connectionist reinforcement learning algorithms",iclr,010
433.pdf.json,,"The domain of representation learning has undergone tremendous advances due to improved supervised learning techniques. However, unsupervised learning has the potential to leverage large pools of unlabeled data, and extend these advances to modalities that are otherwise impractical or impossible. One principled approach to unsupervised learning is generative probabilistic modeling. Not only do generative probabilistic models have the ability to create novel content, they also have a wide range of reconstruction related applications including inpainting [61, 46, 59], denoising [3], colorization [71], and super-resolution [9]. As data of interest are generally high-dimensional and highly structured, the challenge in this domain is building models that are powerful enough to capture its complexity yet still trainable. We address this challenge by introducing real-valued non-volume preserving (real NVP) transformations, a tractable yet expressive approach to modeling high-dimensional data. This model can perform efficient and exact inference, sampling and log-density estimation of data points. Moreover, the architecture presented in this paper enables exact and efficient reconstruction of input images from the hierarchical features extracted by this model.","Jozefowicz and George Dahl for their input on a draft of the paper | Understanding symmetries in deep networks | Density modeling of images using a generalized normalization transformation | An information-maximization approach to blind separation and blind deconvolution | Artificial neural networks and their application to sequence recognition | Modeling high-dimensional discrete data with multi-layer neural networks | Stochastic gradient estimate variance in contrastive divergence and persistent contrastive divergence | Generating sentences from a continuous space | Super-resolution with deep convolutional sufficient statistics | Importance weighted autoencoders | A Gopinath. Gaussianization | A recurrent latent variable model for sequential data | The helmholtz machine | Higher order statistical decorrelation without information loss | Deep generative image models using a laplacian pyramid of adversarial networks. In Advances in Neural Information Processing Systems 28: 10 Published as a conference paper at ICLR | Sample-based non-uniform random variate generation | Nice: non-linear independent components estimation | Graphical models for machine learning and digital communication | Texture synthesis using convolutional neural networks. In Advances in Neural Information Processing Systems | MADE: masked autoencoder for distribution estimation | Generative adversarial nets | Towards conceptual compression | Continuous deep q-learning with model-based acceleration | Deep residual learning for image recognition | Identity mappings in deep residual networks | Long short-term memory | Stochastic variational inference | Independent component analysis, volume 46 | Nonlinear independent component analysis: Existence and uniqueness results | Generating images with recurrent adversarial networks | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Exploring the limits of language modeling | Adam: A method for stochastic optimization | Improving variational inference with inverse autoregressive flow | Auto-encoding variational bayes | Learning multiple layers of features from tiny | The neural autoregressive distribution estimator | Autoencoding beyond pixels using a learned similarity | Efficient backprop | Deep learning face attributes in the wild | Auxiliary deep generative models | Neural variational inference and learning in belief networks | Human-level control through deep reinforcement learning | A view of the em algorithm that justifies incremental, sparse, and other variants. In Learning in graphical models, pages 355–368 | Pixel recurrent neural networks | Unsupervised representation learning with deep convolutional generative adversarial networks | Variational inference with normalizing flows | Stochastic backpropagation and approximate inference in deep generative models | High-dimensional probability estimation with deep density models | Learning representations by backpropagating errors | Imagenet large scale visual recognition challenge | Deep boltzmann machines | Weight normalization: A simple reparameterization to accelerate training of deep neural networks | Markov chain monte carlo and variational inference: Bridging the gap | Mean field theory for sigmoid belief networks | Very deep convolutional networks for large-scale image recognition | Information processing in dynamical systems: Foundations of harmony theory | Deep unsupervised learning using nonequilibrium thermodynamics | Resnet in resnet | Generative image modeling using spatial lstms | A note on the evaluation of generative models | Variational gaussian process | Rnade: The real-valued neural autoregressive densityestimator | Learning functions across many orders of magnitudes | Order matters: Sequence to sequence for sets | Embed to control: A locally linear latent dynamics model for control from raw images | Simple statistical gradient-following algorithms for connectionist reinforcement learning | Multi-scale context aggregation by dilated convolutions | Construction of a large-scale image dataset using deep learning with humans in the loop",iclr,010
434.pdf.json,RECURRENT BATCH NORMALIZATION,"Recurrent neural network architectures such as LSTM (Hochreiter & Schmidhuber, 1997) and GRU (Cho et al., 2014) have recently exhibited state-of-the-art performance on a wide range of complex sequential problems including speech recognition Amodei et al. (2015), machine translation (Bahdanau et al., 2015) and image and video captioning (Xu et al., 2015; Yao et al., 2015). Top-performing models, however, are based on very high-capacity networks that are computationally intensive and costly to train. Effective optimization of recurrent neural networks is thus an active area of study (Pascanu et al., 2012; Martens & Sutskever, 2011; Ollivier, 2013). It is well-known that for deep feed-forward neural networks, covariate shift (Shimodaira, 2000; Ioffe & Szegedy, 2015) degrades the efficiency of training. Covariate shift is a change in the distribution of the inputs to a model. This occurs continuously during training of feed-forward neural networks, where changing the parameters of a layer affects the distribution of the inputs to all layers above it. As a result, the upper layers are continually adapting to the shifting input distribution and unable to learn effectively. This internal covariate shift (Ioffe & Szegedy, 2015) may play an especially important role in recurrent neural networks, which resemble very deep feed-forward networks. Batch normalization (Ioffe & Szegedy, 2015) is a recently proposed technique for controlling the distributions of feed-forward neural network activations, thereby reducing internal covariate shift. It involves standardizing the activations going into each layer, enforcing their means and variances to be invariant to changes in the parameters of the underlying layers. This effectively decouples each layer’s parameters from those of other layers, leading to a better-conditioned optimization problem. Indeed, deep neural networks trained with batch normalization converge significantly faster and generalize better. Although batch normalizati","Deep speech 2: End-to-end speech recognition in english and mandarin | Unitary evolution recurrent neural networks | Neural machine translation by jointly learning to align and translate | Learning long-term dependencies with gradient descent is difficult | Learning phrase representations using rnn encoder-decoder for statistical machine translation | Hierarchical multiscale recurrent neural networks | Generating sequences with recurrent neural networks | Teaching machines to read and comprehend | Untersuchungen zu dynamischen neuronalen netzen | Long short-term memory | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Adam: A method for stochastic optimization | Regularizing rnns by stabilizing activations | Zoneout: Regularizing rnns by randomly preserving hidden activations | Batch normalized recurrent neural networks | A simple way to initialize recurrent networks of rectified linear units | Bridging the gaps between residual learning, recurrent neural networks and visual cortex | Large text compression benchmark | Building a large annotated corpus of english: The penn treebank | Learning recurrent neural networks with hessian-free optimization | Subword language modeling with neural networks | Persistent contextual neural networks for learning symbolic data sequences | Regularization and nonlinearities for neural language models: when are they needed | On the difficulty of training recurrent neural networks | Improving predictive inference under covariate shift by weighting the log-likelihood function | Development Team et al. Theano: A Python framework for fast computation of mathematical expressions | Lecture 6.5—RmsProp: Divide the gradient by a running average of its recent magnitude | Blocks and fuel: Frameworks for deep learning | Show, attend and tell: Neural image caption generation with visual attention | Describing videos by exploiting temporal structure | Architectural complexity measures of recurrent neural networks | During training, we randomly sample the examples with replacement and shuffle the order of the placeholders in each text inside the minibatch. We use a vocabulary of 65829 words. We deviate from Hermann et al. (2015) in order to save computation: we use only the 4 most relevant sentences",iclr,010
435.pdf.json,,"Deep neural networks (DNNs) are currently the best-performing method for many classification problems, such as object recognition from images (Krizhevsky et al., 2012a; Donahue et al., 2014) or speech recognition from audio data (Deng et al., 2013). Their training on large datasets (where DNNs perform particularly well) is the main computational bottleneck: it often requires several days, even on high-performance GPUs, and any speedups would be of substantial value. The training of a DNN with n free parameters can be formulated as the problem of minimizing a function f : IRn → IR. The commonly used procedure to optimize f is to iteratively adjust xt ∈ IRn (the parameter vector at time step t) using gradient information ∇ft(xt) obtained on a relatively small t-th batch of b datapoints. The Stochastic Gradient Descent (SGD) procedure then becomes an extension of the Gradient Descent (GD) to stochastic optimization of f as follows: xt+1 = xt − ηt∇ft(xt), (1) where ηt is a learning rate. One would like to consider second-order information xt+1 = xt − ηtH−1t ∇ft(xt), (2) but this is often infeasible since the computation and storage of the inverse Hessian H−1t is intractable for large n. The usual way to deal with this problem by using limited-memory quasiNewton methods such as L-BFGS (Liu & Nocedal, 1989) is not currently in favor in deep learning, not the least due to (i) the stochasticity of ∇ft(xt), (ii) ill-conditioning of f and (iii) the presence of saddle points as a result of the hierarchical geometric structure of the parameter space (Fukumizu & Amari, 2000). Despite some recent progress in understanding and addressing the latter problems (Bordes et al., 2009; Dauphin et al., 2014; Choromanska et al., 2014; Dauphin et al., 2015), state-ofthe-art optimization techniques attempt to approximate the inverse Hessian in a reduced way, e.g., by considering only its diagonal to achieve adaptive learning rates. AdaDelta (Zeiler, 2012) and Adam (Kingma & Ba, 2014) are not","Sgd-qn: Careful quasi-newton stochastic gradient descent | The loss surface of multilayer networks | Identifying and attacking the saddle point problem in high-dimensional non-convex optimization | Rmsprop and equilibrated adaptive learning rates for non-convex optimization | New types of deep neural network learning for speech recognition and related applications: An overview | Decaf: A deep convolutional activation feature for generic visual recognition | Function minimization by conjugate gradients | Local minima and plateaus in hierarchical structures of multilayer perceptrons | Deep pyramidal residual networks | Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding | Benchmarking a BI-population CMA-ES on the BBOB-2009 function testbed | Evaluating the cma evolution strategy on multimodal test functions | Deep residual learning for image recognition | Identity mappings in deep residual networks | Snapshot ensembles: Train 1, get m for free | Densely connected convolutional networks | Deep networks with stochastic depth | Adam: A method for stochastic optimization | Imagenet classification with deep convolutional neural networks | Learning multiple layers of features from tiny images | Imagenet classification with deep convolutional neural networks | On the limited memory bfgs method for large scale optimization | SGDR: Stochastic Gradient Descent with Restarts | Alternative restart strategies for CMA-ES | A method of solving a convex programming problem with convergence rate o (1/k2) | Introductory lectures on convex optimization: A basic course, volume 87 | Adaptive restart for accelerated gradient schemes | Tiny imagenet visual recognition challenge | Restart procedures for the conjugate gradient method | Niching the CMA-ES via nearest-better clustering | Niching methods and multimodal optimization performance | Benchmarking the bfgs algorithm on the bbob-2009 function testbed | No more pesky learning rate guessing games | Cyclical learning rates for training neural networks | Stochastic subgradient methods with linear convergence for polyhedral convex optimization | Wide residual networks | Adadelta: An adaptive learning rate method | Residual Networks of Residual Networks: Multilevel Residual Networks",iclr,010
436.pdf.json,,"Databases are a pervasive way to store and access knowledge. However, it is not straightforward for users to interact with databases since it often requires programming skills and knowledge about database schemas. Overcoming this difficulty by allowing users to communicate with databases via natural language is an active research area. The common approach to this task is by semantic parsing, which is the process of mapping natural language to symbolic representations of meaning. In this context, semantic parsing yields logical forms or programs that provide the desired response when executed on the databases (Zelle & Mooney, 1996). Semantic parsing is a challenging problem that involves deep language understanding and reasoning with discrete operations such as counting and row selection (Liang, 2016). The first learning methods for semantic parsing require expensive annotation of question-program pairs (Zelle & Mooney, 1996; Zettlemoyer & Collins, 2005). This annotation process is no longer necessary in the current state-of-the-art semantic parsers that are trained using only question-answer pairs (Liang et al., 2011; Kwiatkowski et al., 2013; Krishnamurthy & Kollar, 2013; Pasupat & Liang, 2015). However, the performance of these methods still heavily depends on domain-specific grammar or pruning strategies to ease program search. For example, in a recent work on building semantic parsers for various domains, the authors hand-engineer a separate grammar for each domain (Wang et al., 2015). Recently, many neural network models have been developed for program induction (Andreas et al., 2016; Jia & Liang, 2016; Reed & Freitas, 2016; Zaremba et al., 2016; Yin et al., 2015), despite ∗Work done at Google Brain. the notorious difficulty of handling discrete operations in neural networks (Joulin & Mikolov, 2015; Kaiser & Sutskever, 2016). Most of these approaches rely on complete programs as supervision (Jia & Liang, 2016; Reed & Freitas, 2016) while others (Zaremba et al.,","Tensorflow: Large-scale machine learning on heterogeneous distributed systems | Learning to compose neural networks for question answering | Neural machine translation by jointly learning to align and translate | Question answering with subgraph embeddings | Semi-supervised sequence learning | A theoretically grounded application of dropout in recurrent neural networks | Teaching machines to read and comprehend | Long short-term memory | A neural network for factoid question answering over paragraphs | Deep unordered composition rivals syntactic methods for text classification | Data recombination for neural semantic parsing | Inferring algorithmic patterns with stack-augmented recurrent nets | Adam: A method for stochastic optimization | Semantic parsing with semi-supervised sequential autoencoders | Jointly learning to parse and perceive: Connecting natural language to the physical world | Ask me anything: Dynamic memory networks for natural language processing | Scaling semantic parsers with on-the-fly ontology matching | Neural symbolic machines: Learning semantic parsers on freebase with weak supervision | Learning executable semantic parsers for natural language understanding | Learning dependency-based compositional semantics | Efficient estimation of word representations in vector space | Neural programmer: Neural programmer: Inducing latent programs with gradient descent | Compositional semantic parsing on semi-structured tables | Towards neural network-based reasoning | Squad: 100, 000+ questions for machine comprehension of text | Dropout: A simple way to prevent neural networks from overfitting | End-to-end memory networks | Sequence to sequence learning with neural networks | Machine comprehension using match-lstm and answer pointer | Building a semantic parser overnight | Backpropagation through time: what does it do and how to do it | Simple statistical gradient-following algorithms for connectionist reinforcement learning | Neural enquirer: Learning to query tables with natural language | Learning simple algorithms from examples | Learning to parse database queries using inductive logic programming | Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars",iclr,010
437.pdf.json,,"In the past, the need for task-specific, or even hand-crafted, features limited the application of Reinforcement Learning (RL) in real world problems (Sutton & Barto, 1998). However, the introduction of Deep Q-Learning Networks (DQN) (Mnih et al., 2015) revived the use of Deep Neural Networks (DNNs) as function approximators for value and policy functions, unleashing a rapid series of advancements. Remarkable results include learning to play video games from raw pixels (Bellemare et al., 2016; Lample & Singh Chaplot, 2016) and demonstrating super-human performance on the ancient board game Go (Silver et al., 2016). Research has yielded a variety of effective training formulations and DNN architectures (van Hasselt et al., 2015; Wang et al., 2015), as well as methods to increase parallelism while decreasing the computational cost and memory footprint (Nair et al., 2015; Mnih et al., 2016). In particular, Mnih et al. (2016) achieve state-of-the-art results on many gaming tasks through a novel lightweight, parallel method called Asynchronous Advantage ActorCritic (A3C). When the proper learning rate is used, A3C learns to play an Atari game (Brockman et al., 2016) from raw screen inputs more quickly and efficiently than previous methods: on a 16- core CPU, A3C achieves higher scores than previously published methods run for the same amount of time on a GPU. Our study sets aside many of the learning aspects of recent work and instead delves into the computational issues of deep RL. Computational complexities are numerous, largely centering on a common factor: RL has an inherently sequential aspect, since the training data are generated while learning. The DNN model is constantly queried to guide the actions of agents whose gameplay in turn feeds DNN training. Training batches are commonly small and must be efficiently shepherded from the agents and simulator to the DNN trainer. When using a GPU, the mix of small DNN architectures, small training batch sizes, and content",TensorFlow: Large-scale machine learning on heterogeneous systems | Unifying CountBased Exploration and Intrinsic Motivation | Playing FPS Games with Deep Reinforcement Learning | Continuous control with deep reinforcement learning | Asynchronous Methods for Deep Reinforcement Learning | Human-level control through deep reinforcement learning | Massively parallel methods for deep reinforcement learning | Prioritized experience replay | Mastering the game of go with deep neural networks and tree | Introduction to Reinforcement Learning | Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude | Deep reinforcement learning with double qlearning | Dueling network architectures for deep reinforcement learning | Simple statistical gradient-following algorithms for connectionist reinforcement learning,iclr,010
438.pdf.json,,"The ability to navigate efficiently within an environment is fundamental to intelligent behavior. Whilst conventional robotics methods, such as Simultaneous Localisation and Mapping (SLAM), tackle navigation through an explicit focus on position inference and mapping (Dissanayake et al., 2001), here we follow recent work in deep reinforcement learning (Mnih et al., 2015; 2016) and propose that navigational abilities could emerge as the by-product of an agent learning a policy that maximizes reward. One advantage of an intrinsic, end-to-end approach is that actions are not divorced from representation, but rather learnt together, thus ensuring that task-relevant features are present in the representation. Learning to navigate from reinforcement learning in partially observable environments, however, poses several challenges. First, rewards are often sparsely distributed in the environment, where there may be only one goal location. Second, environments often comprise dynamic elements, requiring the agent to use memory at different timescales: rapid one-shot memory for the goal location, together with short term memory subserving temporal integration of velocity signals and visual observations, and longer term memory for constant aspects of the environment (e.g. boundaries, cues). To improve statistical efficiency we bootstrap the reinforcement learning procedure by augmenting our loss with auxiliary tasks that provide denser training signals that support navigation-relevant representation learning. We consider two additional losses: the first one involves reconstruction of a low-dimensional depth map at each time step by predicting one input modality (the depth channel) from others (the colour channels). This auxiliary task concerns the 3D geometry of the environment, and is aimed to encourage the learning of representations that aid obstacle avoidance and short-term trajectory planning. The second task directly invokes loop closure from SLAM: the agent is trained to","Deep reinforcement learning in a 3-d blockworld environment | URL https://arxiv.org/ abs/1612.03801 | A solution to the simultaneous localization and map building (slam) problem | Depth map prediction from a single image using a multi-scale deep network | Speech recognition with deep recurrent neural networks | Hybrid computing using a neural network with dynamic external memory | Deep recurrent q-learning for partially observable mdps | Reinforcement learning with unsupervised auxiliary tasks | Evolving large-scale neural networks for vision-based reinforcement learning | Deep successor reinforcement learning | Playing FPS games with deep reinforcement learning. CoRR, 2016 | Recurrent reinforcement learning: A hybrid approach | Visualizing data using t-sne | Dynamic auto-encoders for semantic indexing | Human-level control through deep reinforcement learning | Asynchronous methods for deep reinforcement learning | Massively parallel methods for deep reinforcement learning | Language understanding for text-based games using deep reinforcement learning | Control of memory, active perception, and action in minecraft | Hippocampus, space, and memory | How to construct deep recurrent neural networks | Semi-supervised learning with ladder networks | Rule-injection hints as a means of improving network performance and learning time | Between mdps and semi-mdps: A framework for temporal abstraction in reinforcement learning | Towards cognitive exploration through deep reinforcement learning for mobile robots | A deep hierarchical approach to lifelong learning in minecraft | rmsprop: Divide the gradient by a running average of its recent magnitude | Augmenting supervised neural networks with unsupervised objectives for large-scale image classification | Stacked what-where auto-encoders | Target-driven visual navigation in indoor scenes using deep reinforcement learning",iclr,010
439.pdf.json,DEEPCODER: LEARNING TO WRITE PROGRAMS,"A dream of artificial intelligence is to build systems that can write computer programs. Recently, there has been much interest in program-like neural network models (Graves et al., 2014; Weston et al., 2015; Kurach et al., 2015; Joulin & Mikolov, 2015; Grefenstette et al., 2015; Sukhbaatar et al., 2015; Neelakantan et al., 2016; Kaiser & Sutskever, 2016; Reed & de Freitas, 2016; Zaremba et al., 2016; Graves et al., 2016), but none of these can write programs; that is, they do not generate human-readable source code. Only very recently, Riedel et al. (2016); Bunel et al. (2016); Gaunt et al. (2016) explored the use of gradient descent to induce source code from input-output examples via differentiable interpreters, and Ling et al. (2016) explored the generation of source code from unstructured text descriptions. However, Gaunt et al. (2016) showed that differentiable interpreterbased program induction is inferior to discrete search-based techniques used by the programming languages community. We are then left with the question of how to make progress on program induction using machine learning techniques. In this work, we propose two main ideas: (1) learn to induce programs; that is, use a corpus of program induction problems to learn strategies that generalize across problems, and (2) integrate neural network architectures with search-based techniques rather than replace them. In more detail, we can contrast our approach to existing work on differentiable interpreters. In differentiable interpreters, the idea is to define a differentiable mapping from source code and inputs to outputs. After observing inputs and outputs, gradient descent can be used to search for a program that matches the input-output examples. This approach leverages gradient-based optimization, which has proven powerful for training neural networks, but each synthesis problem is still solved independently—solving many synthesis problems does not help to solve the next problem. We argue that mach","DeepMath deep sequence models for premise selection | Adaptive neural compilation | The Helmholtz machine | On label dependence and loss minimization in multi-label classification | Hllermeier. Bayes optimal multilabel classification via probabilistic classifier chains | Synthesizing data structure transformations from input-output examples | Terpret: A probabilistic programming language for program induction | Hybrid computing using a neural network with dynamic external memory | Learning to transduce with unbounded memory | Programming by examples: Applications, algorithms, and ambiguity resolution | Synthesis of loop-free programs | Learning to pass expectation propagation messages | The informed sampler: A discriminative approach to Bayesian inference in generative computer vision models | Inferring algorithmic patterns with stack-augmented recurrent nets | Neural GPUs learn algorithms | Stochastic gradient VB and the variational auto-encoder | Neural random-access machines | Gated graph sequence neural networks | Latent predictor networks for code generation | Deep network guided proof search | A machine learning framework for programming by example | Neural programmer: Inducing latent programs with gradient descent | Learning program embeddings to propagate feedback on student code | FlashMeta: a framework for inductive program synthesis | Neural programmer-interpreters | Programming with a differentiable forth interpreter | Stochastic program optimization | Real-time human pose recognition in parts from single depth images | Predicting a correct program in programming by example | Program Synthesis By Sketching | Learning stochastic inverses | End-to-end memory networks | Learning simple algorithms from examples",iclr,010
440.pdf.json,,"In model-based reinforcement learning, an agent uses its experience to first learn a model of the environment and then uses that model to reason about what action to take next. We consider the case in which the agent observes the current state st, takes some action a, and then observes the next state st+1. The problem of learning the model corresponds then to learning a stochastic transition function p(st+1|st,a) specifying the conditional distribution of st+1 given st and a. Most classic control theory texts, e.g. Bertsekas (2002), will start with the most general model of dynamical systems: st+1 = f(st,a, z,W) where f is some deterministic function parameterized by weightsW that takes as input the current state st, the control signal a, and some stochastic disturbance z. However, to date, we have not been able to robustly learn dynamical system models to such a level of generality. Popular modes for transition functions include Gaussian processes (Rasmussen et al., 2003; Ko et al., 2007; Deisenroth & Rasmussen, 2011), fixed bases such as Laguerre functions (Wahlberg, 1991), and adaptive basis functions or neural networks (Draeger et al., 1995). All of these methods assume deterministic transition functions, perhaps with some addition of Gaussian observation noise. Thus, they are severely limited in the kinds of stochasticity—or transition noise—they can express. In many real-world scenarios stochasticity may often arise due to some unobserved environmental feature that can affect the dynamics in complex ways (such as unmeasured gusts of wind on a boat). In this work we use Bayesian neural networks (BNNs) in conjunction with a random input noise source z to express stochastic dynamics. We take advantage of a very recent inference advance based on α-divergence minimization (Hernández-Lobato et al., 2016), with α = 0.5, to learn with high accuracy BNN transition functions that are both scalable and expressive in terms of stochastic patterns. Previous work achieved on","Dynamic Programming and Optimal Control. Athena Scientific optimization and computation series | Weight uncertainty in neural networks | Deep Gaussian processes for regression using approximate expectation propagation | PILCO: A model-based and data-efficient approach to policy search | A survey on policy search for robotics | Model predictive control using neural networks | Improving PILCO with Bayesian neural networks dynamics models | Continuous deep q-learning with model-based acceleration | Efficient uncertainty propagation for reinforcement learning with limited data | Reinforcement learning with particle swarm optimization policy (PSO-P) in continuous state and action | Introduction to the"" industrial benchmark | Predictive entropy search for efficient global optimization of black-box functions | Black-box α-divergence minimization | VIME: Variational information maximizing exploration | Variational dropout and the local reparameterization trick | Gaussian processes and reinforcement learning for identification and control of an autonomous blimp | Divergence measures and message passing | Policy gradient methods for robotics | Reinforcement learning of motor skills with policy gradients | Gaussian processes in reinforcement learning | The recurrent control neural network | Sparse Gaussian processes using pseudo-inputs | The wet game of chicken | System identification using Laguerre models | Graphical models, exponential families, and variational inference | Model-based policy gradient reinforcement learning | Embed to control: A locally linear latent dynamics model for control from raw images",iclr,010
441.pdf.json,,"The class of Recurrent Neural Network models (RNNs) is particularly well suited to dealing with sequential data, and has been successfully applied to a diverse array of tasks, such as language modeling and speech recognition (Mikolov, 2012), machine translation (Mikolov, 2012; Cho et al., 2014a), or acoustic modeling (Robinson et al., 1993; Graves & Jaitly, 2014) among others. Two factors have been instrumental in allowing this paradigm to be so widely adopted and give rise to the aforementioned successes. On the one hand, recent advances in both hardware and software have had a significant role in bringing the training of recurrent models to tractable time periods. On the other hand, novel units and architectures have allowed recurrent networks to model certain features of sequential data better than Elman’s simple RNN architecture (Elman, 1990). These include such developments as the LSTM (Hochreiter & Schmidhuber, 1997) and GRU (Cho et al., 2014a) units, which can more easily learn to model long range interactions (Chung et al., 2014), or attention mechanisms that allow the model to focus on a specific part of its history when making a prediction (Bahdanau et al., 2014). In this work, we focus on another feature of recurrent networks: the ability to efficiently model processes happening at different and possibly varying time scales. Most existing recurrent models take one of two approaches regarding the amount of computation they require. Either the computational load is constant over time, or it follows a fixed (or deterministic) schedule (Koutnı́k et al., 2014), (Mikolov et al., 2014). The latter approach has proven especially useful when dealing with sequences which reflect processes taking place at different lev- ∗Work done at Facebook AI Research els (and time scales) (Bojanowski et al., 2015). However, we believe that taking a more flexible approach could prove useful. Consider sequential data such as video feeds, audio signal, or language. In video data, t","Neural machine translation by jointly learning to align and translate | Alternative structures for character-level rnns | On the properties of neural machine translation: Encoder-decoder approaches | Learning phrase representations using RNN encoder-decoder for statistical machine translation | Empirical evaluation of gated recurrent neural networks on sequence modeling | Hierarchical multiscale recurrent neural networks | Finding structure in time | The hierarchical hidden markov model: Analysis and applications | The infinite factorial hidden markov model | Variational learning for switching state-space models | Factorial hidden markov models | Adaptive computation time for recurrent neural networks | Towards end-to-end speech recognition with recurrent neural networks | Long short-term memory | Exploring the limits of language modeling | A clockwork RNN | Statistical language models based on neural networks | Learning longer memory in recurrent neural networks | Induction of multiscale temporal structure | Linear-time inference in hierarchical hmms | A neural network based, speaker independent, large vocabulary, continuous speech recognition system: the WERNICKE project | Neural sequence chunkers | Learning complex, extended sequences using the principle of history compression | Architectural complexity measures of recurrent neural networks",iclr,010
442.pdf.json,,"We adopt an information theoretic view of deep networks. We regard the internal representation of some intermediate layer as a stochastic encoding Z of the input source X , defined by a parametric encoder p(z|x;θ).1 Our goal is to learn an encoding that is maximally informative about our target Y , measured by the mutual information between our encoding and the target I(Z, Y ;θ), where I(Z, Y ;θ) = ∫ dx dy p(z, y|θ) log p(z, y|θ) p(z|θ)p(y|θ) . 2 (1) Given the data processing inequality, and the invariance of the mutual information to reparameterizations, if this was our only objective we could always ensure a maximally informative representation by taking the identity encoding of our data (Z = X), but this is not a useful representation of our data. Instead we would like to find the best representation we can obtain subject to a constraint on its complexity. A natural and useful constraint to apply is on the mutual information between our encoding and the original data, I(X,Z) ≤ Ic, where Ic is the information constraint. This suggests the objective: max θ I(Z, Y ;θ) s.t. I(X,Z;θ) ≤ Ic . (2) Equivalently, with the introduction of a Lagrange multiplier β, we can maximize the objective function RIB(θ) = I(Z, Y ;θ)− βI(Z,X;θ). (3) Here our goal is to learn an encoding Z that is maximally expressive about Y while being maximally compressive about X , where β ≥ 0 controls the tradeoff.3 This approach is known as the information bottleneck (IB), and was first proposed in Tishby et al. (1999). Intuitively, the first term in RIB encourages Z to be predictive of Y ; the second term encourages Z to “forget” X . Essentially it forces Z to act like a minimal sufficient statistic of X for predicting Y . The IB principle is appealing, since it defines what we mean by a good representation, in terms of the fundamental tradeoff between having a concise representation and one with good predictive power (Tishby & Zaslavsky, 2015a). The main drawback of the IB principle is that compu","Tensorflow: Large-scale machine learning on heterogeneous distributed systems | The IM algorithm: a variational approach to information maximization | The virtues of peer pressure: A simple method for discovering high-value mistakes | Towards open world recognition | Predictability, complexity, and learning | Weight uncertainty in neural networks | Multivariate sharp quadratic bounds via Σ-strong convexity and the fenchel connection | Towards evaluating the robustness of neural networks | Relevant sparse codes with variational information bottleneck | Information bottleneck for gaussian variables | Differential privacy as a mutual information constraint | Imagenet: A large-scale hierarchical image database | Robustness of classifiers: from adversarial to random noise | Understanding the difficulty of training deep feedforward neural networks | Explaining and harnessing adversarial examples | beta-VAE: Learning basic visual concepts with a constrained variational framework | Learning with a strong adversary | Adam: A method for stochastic optimization | Auto-encoding variational Bayes | Adversarial examples in the physical world | The variational fair autoencoder | Information theory, inference and learning algorithms | Variational information maximisation for intrinsically motivated reinforcement learning | Universal adversarial perturbations | Deepfool: a simple and accurate method to fool deep neural networks | Deep neural networks are easily fooled: High confidence predictions for unrecognizable images | Predictive information in a sensory population | The limitations of deep learning in adversarial settings | Regularizing neural networks by penalizing confident output predictions | Acceleration of stochastic approximation by averaging | Confusing deep convolution networks by relabelling | Adversarial manipulation of deep representations | Intriguing properties of neural networks | Inception-v4, inceptionresnet and the impact of residual connections on learning | Deep learning and the information bottleneck principle | The information bottleneck method | Deep learning and the information bottleneck principle | On the relation between identifiability, differential privacy and Mutual-Information privacy | Deep variational canonical correlation analysis | Here the aim is to take our dataX and maximize the mutual information contained in some encoding Z, while restricting how much information we allow our representation to contain about the identity of each data element in our sample (i)",iclr,010
443.pdf.json,THE NEURAL NOISY CHANNEL,"Recurrent neural network sequence to sequence models (Kalchbrenner & Blunsom, 2013; Sutskever et al., 2014; Bahdanau et al., 2015) are excellent models of p(output sequence y | input sequence x), provided sufficient input–output (x,y) pairs are available for estimating their parameters. However, in many domains, vastly more unpaired output examples are available than input–output pairs (e.g., transcribed speech is relatively rare although non-spoken texts are abundant; Swahili–English translations are rare although English texts are abundant; etc.). A classic strategy for exploiting both kinds of data is to use Bayes’ rule to rewrite p(y | x) as p(x | y)p(y)/p(x), a factorisation which is called a noisy channel model (Shannon, 1948). A noisy channel model thus consists of two component models: the conditional channel model, p(x | y), which characterizes the reverse transduction problem and whose parameters are estimated from the paired (x,y) samples, and the unconditional source model, p(y), whose parameters are estimated from both the paired and (usually much more numerous) unpaired samples.1 Beyond their data omnivorousness, noisy channel models have other benefits. First, the two component models mean that two different aspects of the transduction problem can be addressed independently. For example, in many applications, source models are language models and innovations in these can be leveraged to obtain improvements in any system that uses them as a component. Second, the component models can have complementary strengths, since inference is carried out in the product space; this simplifies design because a single model does not have to get everything perfectly right. Third, the noisy channel operates by selecting outputs that both are a priori likely and that explain the input well. This addresses a failure mode that can occur in conditional models in which inputs are “explained away” by highly predictive output prefixes, resulting in poor training (Klein & Man",Alignment-based neural machine translation | Neural machine translation by jointly learning to align and translate | An improved error model for noisy channel spelling correction | The mathematics of statistical machine translation: Parameter estimation | Semisupervised learning for neural machine translation | Abstractive sentence summarization with attentive recurrent neural networks | Supervised learning of complete morphological paradigms | A noisy-channel approach to question answering | Finding structure in time | Morphological inflection generation using character sequence to sequence learning | Sequence transduction with recurrent neural networks | Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks | Don’t until the final verb wait: Reinforcement learning for simultaneous machine translation | Learning to translate in real-time with neural machine | On using monolingual corpora in neural machine | Long short-term memory | Character-level incremental speech recognition with recurrent neural networks | A neural transducer | Statistical Methods for Speech Recognition | Recurrent continuous translation models | Adam: A method for stochastic optimization | Conditional structure versus conditional estimation in nlp models | Segmental recurrent neural networks | Agreement on target-bidirectional neural machine translation | Language as a latent variable: Discrete generative models for sentence compression | Annotated gigaword | Inflection generation as discriminative string transduction | A neural attention model for abstractive sentence summarization | Incremental decoding for phrase-based statistical machine translation | Improving neural machine translation models with monolingual data | A mathematical theory of communication | Computational complexity of probabilistic disambiguation by means of treegrammars | Sequence to sequence learning with neural networks | A DP-based search using monotone alignments in statistical translation | Neural machine translation with reconstruction | Online segment to segment neural transduction,iclr,010
444.pdf.json,,"Neural network language models, especially recurrent neural networks (RNN), are now standard tools for natural language processing. Amongst other things, they are used for translation Sutskever et al. (2014), language modelling Jozefowicz et al. (2016), and question answering Hewlett et al. (2016). In particular, the Long Short Term Memory (LSTM) Hochreiter & Schmidhuber (1997) architecture has become a basic building block of neural NLP. Although LSTM’s are regularly used in state of the art systems, their operation is not well understood. Besides the basic desire from a scientific viewpoint to clarify their workings, it is often the case that it is important to understand why a machine learning algorithm made a particular choice. Moreover, LSTM’s are computationally intensive compared to discrete models with lookup tables and pattern matching. In this work, we describe a novel method for visualizing the importance of specific inputs for determining the output of an LSTM. We then demonstrate that, by searching for phrases which are consistently important, the importance scores can be used to extract simple phrase patterns consisting of one to five words from a trained LSTM. The phrase extraction is first done in a general document classification framework on two different sentiment analysis datasets. We then demonstrate that it can also be specialized to more complex models by applying it to WikiMovies, a recently introduced question answer dataset. To concretely validate the extracted patterns, we use them as input to a rules-based classifier which approximates the performance of the original LSTM.","Automatic text scoring using neural networks | Ask the gru: Multi-task learning for deep text recommendations | Large-scale simple question answering with memory networks | Extraction of salient sentences from labelled documents | Visual analysis of hidden state dynamics in recurrent neural networks | Wikireading: A novel large-scale language understanding task over wikipedia | Long short-term memory | Exploring the limits of language modeling | Visualizing and understanding recurrent neural networks | Convolutional neural networks for sentence classification | Adam: A method for stochastic optimization | Dataset and neural recurrent sequence labeling model for open-domain factoid question answering | Key-value memory networks for directly reading documents | Squad: 100,000+ questions for machine comprehension of text | Recursive deep models for semantic compositionality over a sentiment treebank | Sequence to sequence learning with neural networks | Character-level convolutional networks for text classification",iclr,010
445.pdf.json,DIALOGUE LEARNING WITH HUMAN-IN-THE-LOOP,"A good conversational agent (which we sometimes refer to as a learner or bot1) should have the ability to learn from the online feedback from a teacher: adapting its model when making mistakes and reinforcing the model when the teacher’s feedback is positive. This is particularly important in the situation where the bot is initially trained in a supervised way on a fixed synthetic, domainspecific or pre-built dataset before release, but will be exposed to a different environment after release (e.g., more diverse natural language utterance usage when talking with real humans, different distributions, special cases, etc.). Most recent research has focused on training a bot from fixed training sets of labeled data but seldom on how the bot can improve through online interaction with humans. Human (rather than machine) language learning happens during communication (Bassiri, 2011; Werts et al., 1995), and not from labeled datasets, hence making this an important subject to study. In this work, we explore this direction by training a bot through interaction with teachers in an online fashion. The task is formalized under the general framework of reinforcement learning via the teacher’s (dialogue partner’s) feedback to the dialogue actions from the bot. The dialogue takes place in the context of question-answering tasks and the bot has to, given either a short story or a set of facts, answer a set of questions from the teacher. We consider two types of feedback: explicit numerical rewards as in conventional reinforcement learning, and textual feedback which is more natural in human dialogue, following (Weston, 2016). We consider two online training scenarios: (i) where the task is built with a dialogue simulator allowing for easy analysis and repeatability of experiments; and (ii) where the teachers are real humans using Amazon Mechanical Turk. We explore important issues involved in online learning such as how a bot can be most efficiently trained using a minimal amount ","Interactional feedback and the impact of attitude and motivation on noticing l2 form | Large-scale simple question answering with memory networks | Counterfactual reasoning and learning systems: The example of computational advertising | Evaluating prerequisite qualities for learning end-to-end dialog systems | Pomdp-based dialogue manager adaptation to extended domains | Incremental on-line adaptation of pomdp-based dialogue managers to extended domains | Teaching machines to read and comprehend | Learning dialogue strategies within the markov decision process framework | A stochastic model of human-machine interaction for learning dialog strategies | Key-value memory networks for directly reading documents | Playing atari with deep reinforcement learning | Are we there yet? research in commercial spoken dialog systems | Squad: 100,000+ questions for machine comprehension of text | Sequence level training with recurrent neural networks | A survey of statistical user simulation techniques for reinforcement-learning of dialogue management strategies | Empirical evaluation of a reinforcement learning spoken dialogue system | Optimizing dialogue management with reinforcement learning: Experiments with the njfun system | Continuously learning neural dialogue management | End-to-end memory networks | An application of reinforcement learning to dialogue strategy selection in a spoken dialogue system for email | A trainable generator for recommendations in multimodal dialog | Instructive feedback: Review of parameters and effects | Dialog-based language learning | Towards ai-complete question answering: A set of prerequisite toy tasks | Simple statistical gradient-following algorithms for connectionist reinforcement learning | The hidden information state model: A practical framework for pomdp-based spoken dialogue management",iclr,010
446.pdf.json,ADVERSARIALLY LEARNED INFERENCE,"Deep directed generative model has emerged as a powerful framework for modeling complex highdimensional datasets. These models permit fast ancestral sampling, but are often challenging to learn due to the complexities of inference. Recently, three classes of algorithms have emerged as effective for learning deep directed generative models: 1) techniques based on the Variational Autoencoder (VAE) that aim to improve the quality and efficiency of inference by learning an inference machine (Kingma & Welling, 2013; Rezende et al., 2014), 2) techniques based on Generative Adversarial Networks (GANs) that bypass inference altogether (Goodfellow et al., 2014) and 3) autoregressive approaches (van den Oord et al., 2016b;c;a) that forego latent representations and instead model the relationship between input variables directly. While all techniques are provably consistent given infinite capacity and data, in practice they learn very different kinds of generative models on typical datasets. VAE-based techniques learn an approximate inference mechanism that allows reuse for various auxiliary tasks, such as semi-supervised learning or inpainting. They do however suffer from a wellrecognized issue of the maximum likelihood training paradigm when combined with a conditional independence assumption on the output given the latent variables: they tend to distribute probability mass diffusely over the data space (Theis et al., 2015). The direct consequence of this is that image samples from VAE-trained models tend to be blurry (Goodfellow et al., 2014; Larsen et al., 2015). Autoregressive models produce outstanding samples but do so at the cost of slow sampling speed and foregoing the learning of an abstract representation of the data. GAN-based approaches represent a good compromise: they learn a generative model that produces higher-quality samples than the best VAE techniques (Radford et al., 2015; Larsen et al., 2015) without sacrificing sampling speed and also make use of a late",Theano: new features and speed improvements | Estimating or propagating gradients through stochastic neurons for conditional computation | Deep generative stochastic networks trainable by backprop | Theano: a cpu and gpu math expression compiler | Neural photo editing with introspective adversarial networks | Infogan: Interpretable representation learning by information maximizing generative adversarial nets | Adversarial feature learning | Generating images with perceptual similarity metrics based on deep networks | A guide to convolution arithmetic for deep learning | Generative adversarial nets | Adam: A method for stochastic optimization | Fast gradient-based inference with continuous latent variable models in auxiliary form | Auto-encoding variational bayes | Semi-supervised learning with deep generative models | Improving variational inference with inverse autoregressive flow | Learning multiple layers of features from tiny | Discriminative regularization for generative models | Autoencoding beyond pixels using a learned similarity metric | Divergence measures based on the shannon entropy | Deep learning face attributes in the wild | Auxiliary deep generative models | Reading digits in natural images with unsupervised feature learning | Deconvolution and checkerboard artifacts | Unsupervised representation learning with deep convolutional generative adversarial networks | Semi-supervised learning with ladder network | Stochastic backpropagation and approximate inference in deep generative models | Imagenet large scale visual recognition challenge | Improved techniques for training gans | Is the deconvolution layer the same as a convolutional layer | Unsupervised and semi-supervised learning with categorical generative adversarial networks | A note on the evaluation of generative models | Wavenet: A generative model for raw audio | Pixel recurrent neural networks | Conditional image generation with pixelcnn decoders | Blocks and fuel: Frameworks for deep learning | Stacked what-where auto-encoders,iclr,010
447.pdf.json,,"When a student is asked a question by a teacher, but is not confident about the answer, they may ask for clarification or hints. A good conversational agent (a learner/bot/student) should have this ability to interact with a dialogue partner (the teacher/user). However, recent efforts have mostly focused on learning through fixed answers provided in the training set, rather than through interactions. In that case, when a learner encounters a confusing situation such as an unknown surface form (phrase or structure), a semantically complicated sentence or an unknown word, the agent will either make a (usually poor) guess or will redirect the user to other resources (e.g., a search engine, as in Siri). Humans, in contrast, can adapt to many situations by asking questions. We identify three categories of mistakes a learner can make during dialogue1: (1) the learner has problems understanding the surface form of the text of the dialogue partner, e.g., the phrasing of a question; (2) the learner has a problem with reasoning, e.g. they fail to retrieve and connect the relevant knowledge to the question at hand; (3) the learner lacks the knowledge necessary to answer the question in the first place – that is, the knowledge sources the student has access to do not contain the needed information. All the situations above can be potentially addressed through interaction with the dialogue partner. Such interactions can be used to learn to perform better in future dialogues. If a human student has problems understanding a teacher’s question, they might ask the teacher to clarify the question. If the student doesn’t know where to start, they might ask the teacher to point out which known facts are most relevant. If the student doesn’t know the information needed at all, they might ask the teacher to tell them the knowledge they’re missing, writing it down for future use. In this work, we try to bridge the gap between how a human and an end-to-end machine learning dialogue agent d",Interactional feedback and the impact of attitude and motivation on noticing l2 form | Learning end-to-end goal-oriented dialog | Large-scale simple question answering with memory networks | Evaluating prerequisite qualities for learning end-to-end dialog systems | The conscientious consumer: Reconsidering the role of assessment feedback in student learning | Learning through feedback | A diversity-promoting objective function for neural conversation models | Key-value memory networks for directly reading documents | Sequence level training with recurrent neural networks | A neural network approach to context-sensitive generation of conversational responses | Continuously learning neural dialogue management | End-to-end memory networks | A neural conversational model | Learning language games through interaction | A network-based end-to-end trainable task-oriented dialogue system | Instructive feedback: Review of parameters and effects | Dialog-based language learning | Towards ai-complete question answering: A set of prerequisite toy tasks | Simple statistical gradient-following algorithms for connectionist reinforcement learning | Understanding natural language | Philosophical investigations | Reinforcement learning neural turing machines,iclr,010
448.pdf.json,DEEP INFORMATION PROPAGATION,"Deep neural network architectures have become ubiquitous in machine learning. The success of deep networks is due to the fact that they are highly expressive (Montufar et al., 2014) while simultaneously being relatively easy to optimize (Choromanska et al., 2015; Goodfellow et al., 2014) with strong generalization properties (Recht et al., 2015). Consequently, developments in machine learning often accompany improvements in our ability to train increasingly deep networks. Despite this, designing novel network architectures is frequently equal parts art and science. This is, in part, because a general theory for neural networks that might inform design decisions has lagged behind the feverish pace of design. A pair of recent papers (Poole et al., 2016; Raghu et al., 2016) demonstrated that random neural networks are exponentially expressive in their depth. Central to their approach was the consideration of networks after random initialization, whose weights and biases were i.i.d. Gaussian distributed. In particular the paper by Poole et al. (2016) developed a “mean field” formalism for treating wide, untrained, neural networks. They showed that these mean field networks exhibit an order-to-chaos transition as a function of the weight and bias variances. Notably the mean field formalism is not closely tied to a specific choice of activation function or loss. In this paper, we demonstrate the existence of several characteristic “depth” scales that emerge naturally and control signal propagation in these random networks. We then show that one of these depth scales, ξc, diverges at the boundary between order and chaos. This result is insensitive to many architectural decisions (such as choice of activation function) and will generically be true at any order-to-chaos transition. We then extend these results to include dropout and we show that even small amounts of dropout destroys the order-to-chaos critical point and consequently removes the divergence in ξc. Together th","The problem of learning long-term dependencies in recurrent networks | At the edge of chaos: Real-time computations and self-organized criticality in recurrent neural networks | The loss surfaces of multilayer networks | Toward Deeper Understanding of Neural Networks: The Power of Initialization and a Dual View on Expressivity | Understanding the difficulty of training deep feedforward neural networks | Qualitatively characterizing neural network optimization problems | Deep Residual Learning for Image Recognition | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Random feedback weights support learning in deep neural networks | On the number of linear regions of deep neural networks | Bayesian learning for neural networks, volume 118 | Exponential expressivity in deep neural networks through transient chaos | On the expressive power of deep neural networks | Train faster, generalize better: Stability of stochastic gradient descent | Exact solutions to the nonlinear dynamics of learning in deep linear neural networks | Random walks: Training very deep nonlinear feed-forward networks with smart initialization",iclr,010
449.pdf.json,FRACTALNET: ULTRA-DEEP NEURAL NETWORKS WITHOUT RESIDUALS,"Residual networks (He et al., 2016a), or ResNets, lead a recent and dramatic increase in both depth and accuracy of convolutional neural networks, facilitated by constraining the network to learn residuals. ResNet variants (He et al., 2016a;b; Huang et al., 2016b) and related architectures (Srivastava et al., 2015) employ the common technique of initializing and anchoring, via a pass-through channel, a network to the identity function. Training now differs in two respects. First, the objective changes to learning residual outputs, rather than unreferenced absolute mappings. Second, these networks exhibit a type of deep supervision (Lee et al., 2014), as near-identity layers effectively reduce distance to the loss. He et al. (2016a) speculate that the former, the residual formulation itself, is crucial. We show otherwise, by constructing a competitive extremely deep architecture that does not rely on residuals. Our design principle is pure enough to communicate in a single word, fractal, and a simple diagram (Figure 1). Yet, fractal networks implicitly recapitulate many properties hard-wired into previous successful architectures. Deep supervision not only arises automatically, but also drives a type of student-teacher learning (Ba & Caruana, 2014; Urban et al., 2017) internal to the network. Modular building blocks of other designs (Szegedy et al., 2015; Liao & Carneiro, 2015) resemble special cases of a fractal network’s nested substructure. For fractal networks, simplicity of training mirrors simplicity of design. A single loss, attached to the final layer, suffices to drive internal behavior mimicking deep supervision. Parameters are randomly initialized. As they contain subnetworks of many depths, fractal networks are robust to choice of overall depth; make them deep enough and training will carve out a useful assembly of subnetworks. The entirety of emergent behavior resulting from a fractal design may erode the need for recent engineering tricks intended to ac","Do deep nets really need to be deep | Fast and accurate deep network learning by exponential linear units (ELUs) | ImageNet: A large-scale hierarchical image database | Understanding the difficulty of training deep feedforward neural networks | Highway and residual networks learn unrolled iterative estimation | Hypercolumns for object segmentation and fine-grained localization | Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification | Deep residual learning for image recognition | Identity mappings in deep residual networks. ECCV, 2016b | Improving neural networks by preventing co-adaptation of feature detectors | Densely connected convolutional networks | Deep networks with stochastic depth | SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and ă1MB model size | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Caffe: Convolutional architecture for fast feature embedding | Learning multiple layers of features from tiny images | ImageNet classification with deep convolutional neural networks | A simple way to initialize recurrent networks of rectified linear units | Generalizing pooling functions in convolutional neural networks: Mixed | Recurrent convolutional neural network for object recognition | Reconstructive sparse code transfer for contour detection and semantic labeling | All you need is a good init | Rectified linear units improve restricted boltzmann machines | Reading digits in natural images with unsupervised feature learning | Path-SGD: Path-normalized optimization in deep neural networks | Fitnets: Hints for thin deep | Very deep convolutional networks for large-scale image recognition | Scalable bayesian optimization using deep neural networks | Striving for simplicity: The all convolutional net | Resnet in resnet: Generalizing residual architectures | Do deep convolutional nets really need to be deep and convolutional? ICLR, 2017 | Residual networks behave like ensembles of relatively shallow networks | Regularization of neural networks using dropconnect",iclr,010
450.pdf.json,REVISITING CLASSIFIER TWO-SAMPLE TESTS,"One of the most fundamental problems in statistics is to assess whether two samples, SP ∼ Pn and SQ ∼ Qm, are drawn from the same probability distribution. To this end, two-sample tests (Lehmann & Romano, 2006) summarize the differences between the two samples into a real-valued test statistic, and then use the value of such statistic to accept1 or reject the null hypothesis “P = Q”. The development of powerful two-sample tests is instrumental in a myriad of applications, including the evaluation and comparison of generative models. Over the last century, statisticians have nurtured a wide variety of two-sample tests. However, most of these tests are only applicable to one-dimensional examples, require the prescription of a fixed representation of the data, return test statistics in units that are difficult to interpret, or do not explain how the two samples under comparison differ. Intriguingly, there exists a relatively unexplored strategy to build two-sample tests that overcome the aforementioned issues: training a binary classifier to distinguish between the examples in SP and the examples in SQ. Intuitively, if P = Q, the test accuracy of such binary classifier should remain near chance-level. Otherwise, if P 6= Q and the binary classifier is able to unveil some of the distributional differences between SP and SQ, its test accuracy should depart from chance-level. As we will show, such Classifier Two-Sample Tests (C2ST) learn a suitable representation of the data on the fly, return test statistics in interpretable units, have simple asymptotic distributions, and their learned features and predictive uncertainty provide interpretation on how P and Q differ. In such a way, this work brings together the communities of statistical testing and representation learning. The goal of this paper is to establish the theoretical properties and evaluate the practical uses of C2ST. To this end, our contributions are: • We review the basics of two-sample tests in Section 2, a","Effect of high dimension: by an example of a two sample problem | Bounding the test log-likelihood of generative models | A test of relative similarity for model selection in generative models | Sampling and bayes’ inference in scientific modelling and robustness | Fast two-sample testing with analytic representations of probability measures | Training generative neural networks via Maximum Mean Discrepancy | Binomial approximation to the poisson binomial distribution | The elements of statistical learning | On multivariate goodness of fit and two sample testing | Kernel choice and classifiability for rkhs embeddings of probability distributions | Generative adversarial nets | Measuring statistical dependence with hilbert-schmidt norms | A kernel two-sample test | Optimal kernel choice for large-scale two-sample tests | Training and investigating residual nets, 2016 | Noise-contrastive estimation of unnormalized statistical models, with applications to natural image statistics | Deep residual learning for image recognition | Labeled faces in the wild: A database for studying face recognition in unconstrained environments | Interpretable Distribution Features with Maximum Testing | Perceptual Losses for Real-Time Style Transfer and SuperResolution | f-divergence estimation and two-sample homogeneity test under semiparametric density-ratio models | Adam: A method for stochastic optimization | Sulla determinazione empirica di una legge di distribuzione | Tests concerning random points on a circle | Gradient-based learning applied to document recognition | Statistical model criticism using kernel two sample tests | Towards a learning theory of cause-effect inference | On a test of whether one of two random variables is stochastically larger than the other | Linking losses for density ratio and class-probability estimation | Distributed representations of words and phrases and their compositionality | Conditional generative adversarial nets | Learning in Implicit Generative Models. arXiv, 2016 | Distinguishing cause from effect using observational data: methods and benchmarks | f-GAN: Training generative neural samplers using variational divergence minimization | Deconvolution and checkerboard artifacts | Induction in neuroscience with classification: issues and solutions | Machine learning classifiers and fMRI: a tutorial overview | Estimation of information theoretic measures for continuous random variables | Unsupervised representation learning with deep convolutional generative adversarial networks | Adaptivity and ComputationStatistics Tradeoffs for Kernel and Distance based High Dimensional | Classification accuracy as a proxy for two sample testing | On the high dimensional power of a linear-time two sample test under mean-shift | Information, divergence and risk for binary experiments | ImageNet large scale visual recognition challenge | Improved techniques for training GANs | On the estimation of the discrepancy between empirical curves of distribution for two independent samples | Generative Models and Model Criticism via Optimized Maximum Mean Discrepancy | A note on the evaluation of generative models | Statistical learning theory | Individual comparisons by ranking methods | Two-sample homogeneity tests based on divergence measures | LSUN: Construction of a Large-scale Image Dataset using Deep Learning with Humans",iclr,010
451.pdf.json,,"Optimization is a critical component in deep learning, governing its success in different areas of computer vision, speech processing and natural language processing. The prevalent optimization strategy is Stochastic Gradient Descent, invented by Robbins and Munro in the 50s. The empirical performance of SGD on these models is better than one could expect in generic, arbitrary non-convex loss surfaces, often aided by modifications yielding significant speedups Duchi et al. (2011); Hinton et al. (2012); Ioffe & Szegedy (2015); Kingma & Ba (2014). This raises a number of theoretical questions as to why neural network optimization does not suffer in practice from poor local minima. The loss surface of deep neural networks has recently attracted interest in the optimization and machine learning communities as a paradigmatic example of a hard, high-dimensional, non-convex problem. Recent work has explored models from statistical physics such as spin glasses Choromanska et al. (2015), in order to understand the macroscopic properties of the system, but at the expense of strongly simplifying the nonlinear nature of the model. Other authors have advocated that the real danger in high-dimensional setups are saddle points rather than poor local minima Dauphin et al. (2014), although recent results rigorously establish that gradient descent does not get stuck on saddle points Lee et al. (2016) but merely slowed down. Other notable recent contributions are Kawaguchi (2016), which further develops the spin-glass connection from Choromanska et al. (2015) and resolves the linear case by showing that no poor local minima exist; Sagun et al. (2014) which also ∗Currently on leave from UC Berkeley. discusses the impact of stochastic vs plain gradient, Soudry & Carmon (2016), that studies Empirical Risk Minimization for piecewise multilayer neural networks under overparametrization (which needs to grow with the amount of available data), and Goodfellow et al. (2014), which provided ins",Convex relaxations of structured matrix factorizations | The loss surfaces of multilayer networks | Identifying and attacking the saddle point problem in high-dimensional non-convex optimization | Compressed sensing | Adaptive subgradient methods for online learning and stochastic optimization | Recovery of sparse translationinvariant signals with continuous basis pursuit | Qualitatively characterizing neural network optimization problems | Lecture 6a overview of mini–batch gradient descent | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Deep learning without poor local minima | Adam: A method for stochastic optimization | Gradient descent converges to minimizers | On the quality of the initial basin in overspecified neural networks | Explorations on high dimensional landscapes | Exact solutions to the nonlinear dynamics of learning in deep linear neural networks | Distribution-specific hardness of learning neural networks | No bad local minima: Data independent training error guarantees for multilayer neural networks | Local minima in training of neural networks,iclr,010
452.pdf.json,DEEP REINFORCEMENT LEARNING,"Reinforcement learning (RL) is used to solve goal-directed sequential decision making problems wherein explicit supervision in the form of correct decisions is not provided to the agent, but only evaluative feedback in the form of the rewards sampled from the environment. RL algorithms model goal-directed sequential decision making problems as Markov Decision Processes (MDP) [Sutton & Barto (1998)]. However, for problems with an exponential or continuous state space, tabular RL algorithms that maintain value or policy estimates for every state become infeasible. Therefore, there is a need to be able to generalize decision making to unseen states. Recent advances in representation learning through deep neural networks provide an efficient mechanism for such generalization [LeCun et al. (2015)]. Such a combination of representation learning through deep neural networks with reinforcement learning objectives has shown promising results in many sequential decision making domains such as the Atari 2600 domain [Bellemare et al. (2013); Mnih et al. (2015); Schaul et al. (2015); Mnih et al. (2016)], Mujoco simulated physics tasks domain [Todorov et al. (2012); Lillicrap et al. (2015)], the Robosoccer domain [Hausknecht et al. (2016)] and the TORCS domain [Wymann et al. (2000); Mnih et al. (2016)]. Often, MDP settings consist of an agent interacting with the environment at discrete time steps. A common feature shared by all the Deep Reinforcement Learning (DRL) algorithms above is that they repeatedly execute a chosen action for a fixed number of time steps k. If at represents the action taken at time step t, then for the said algorithms, a1 = a2 = · · · = ak, ak+1 = ak+2 = · · · = a2k and in general aik+1 = aik+2 = · · · = a(i+1)k, i ≥ 0. Action repetition allows these algorithms to compute the action once every k time steps and hence operate at higher speeds, thus achieving real-time performance. This also offers other advantages such as smooth action policies. More import","The arcade learning environment: An evaluation platform for general agents | Transition point dynamic programming | Hierarchical reinforcement learning with the maxq value function decomposition | Reinforcement learning methods for continuous-time markov decision problems | Deep reinforcement learning with macro-actions | Learning to translate in real-time with neural machine translation | Deep reinforcement learning in parametrized action space | Half field offense: An environment for multiagent learning and ad hoc teamwork | Delving deep into rectifiers: Surpassing human-level performance on imagenet classification | Dynamic action repetition for deep reinforcement learning | Deterministic policy gradient algorithms | Continuous control with deep reinforcement learning | Self-improving factory simulation using continuous-time average-reward reinforcement learning | Human-level control through deep reinforcement learning | Asynchronous methods for deep reinforcement learning | Simultaneous machine translation using deep reinforcement learning | Prioritized experience replay | Trust region policy optimization | Introduction to reinforcement learning | Mujoco: A physics engine for model-based control | Strategic attentive writer for learning macro-actions | Torcs, the open racing car simulator. Software available at http://torcs | The initial learning rate used was 10−3 and it was linearly annealed to 0 over 100 million steps. The n used in n-step returns was 20. Entropy regularization was used to encourage exploration, similar to | 2015), except that the pre-LSTM hidden layer had size | Similar to Mnih et al. (2016) the Actor and Critic share all but one | 2015), we did not find it useful to use batch normalization and hence it was not used. However, a replay memory was used of size 10000. Target networks were also used with soft updates being applied with τ = 0.001. Sine DDPG is an off-policy actor-critic method, we need to ensure that sufficient exploration takes place. Use of an Ornstein-Uhlenbeck process",iclr,010
453.pdf.json,,"Recently, deep neural networks have achieved state-of-the-art performance in various tasks such as speech recognition, visual object recognition, and image classification (LeCun et al., 2015). Though powerful, the large number of network weights leads to space and time inefficiencies in both training and storage. For instance, the popular AlexNet, VGG-16 and Resnet-18 all require hundred of megabytes to store, and billions of high-precision operations on classification. This limits its use in embedded systems, smart phones and other portable devices that are now everywhere. To alleviate this problem, a number of approaches have been recently proposed. One attempt first trains a neural network and then compresses it (Han et al., 2016; Kim et al., 2016). Instead of this two-step approach, it is more desirable to train and compress the network simultaneously. Example approaches include tensorizing (Novikov et al., 2015), parameter quantization (Gong et al., 2014), and binarization (Courbariaux et al., 2015; Hubara et al., 2016; Rastegari et al., 2016). In particular, binarization only requires one bit for each weight value. This can significantly reduce storage, and also eliminates most multiplications during the forward pass. Courbariaux et al. (2015) pioneered neural network binarization with the BinaryConnect algorithm, which achieves state-of-the-art results on many classification tasks. Besides binarizing the weights, Hubara et al. (2016) further binarized the activations. Rastegari et al. (2016) also learned to scale the binarized weights, and obtained better results. Besides, they proposed the XNOR-network with both weights and activations binarized as in (Hubara et al., 2016). Instead of binarization, ternary-connect quantizes each weight to {−1, 0, 1} (Lin et al., 2016). Similarly, the ternary weight network (Li & Liu, 2016) and DoReFa-net (Zhou et al., 2016) quantize weights to three levels or more. However, though using more bits allows more accurate weight ","BinaryConnect: Training deep neural networks with binary weights during propagations | Equilibrated adaptive learning rates for non-convex optimization | RMSprop and equilibrated adaptive learning rates for non-convex optimization | Adaptive subgradient methods for online learning and stochastic optimization | Understanding the difficulty of training deep feedforward neural networks | Compressing deep convolutional networks using vector quantization | Pylearn2: a machine learning research | Deep compression: Compressing deep neural network with pruning, trained quantization and Huffman coding | Long short-term memory | Visualizing and understanding recurrent networks | Compression of deep convolutional neural networks for fast and low power mobile applications | Adam: A method for stochastic optimization | Proximal Newton-type methods for minimizing composite functions | Ternary weight networks | Neural networks with few multiplications | Training deep and recurrent networks with Hessian-free optimization | Tensorizing neural networks | Revisiting natural gradient for deep networks | On the difficulty of training recurrent neural networks | DC proximal Newton for nonconvex optimization problems | XNOR-Net: ImageNet classification using binary convolutional neural networks | Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude | The concave-convex procedure (CCCP) | ADADELTA: An adaptive learning rate method | DoReFa-Net: Training low bitwidth convolutional neural networks with low bitwidth gradients",iclr,010
455.pdf.json,,,"On contrastive divergence learning | Deep generative image models using a laplacian pyramid of adversarial networks | Generative adversarial nets | Generating images with recurrent adversarial networks | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Learning convolutional feature hierarchies for visual recognition | Deep directed generative models with energy-based probability estimation | Adam: A method for stochastic optimization | Deep learning face attributes in the wild | Efficient learning of sparse representations with an energy-based model | Deep multi-scale video prediction beyond mean square error | Deconstructing the ladder network architecture | Unsupervised representation learning with deep convolutional generative adversarial networks | A unified energy-based framework for unsupervised learning | Semi-supervised learning with ladder networks | Contractive auto-encoders: Explicit invariance during feature extraction | Improved techniques for training gans | Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion | Matching networks for one shot learning | Lsun: Construction of a large-scale image dataset using deep learning with humans in the loop | Stacked what-where auto-encoders | ExKL(p(y)||p(y|x)), where x denotes a generated sample and y is the label predicted by a MNIST classifier that is trained off-line using the entire MNIST training set. Two main changes were made upon its original form: (i)-we swap the order of the distribution pair; (ii)-we omit the e(·) operation. The modified score condenses the histogram in figure 2 and figure 3",iclr,010
456.pdf.json,DOMAIN-INVARIANT REPRESENTATION LEARNING,"The collection and preprocessing of large amounts of data for new domains is often time consuming and expensive. This in turn limits the application of state-of-the-art methods like deep neural network architectures, that require large amounts of data. However, often data from related domains can be used to improve the prediction model in the new domain. This paper addresses the particularly important and challenging domain-invariant representation learning task of unsupervised domain adaptation (Glorot et al., 2011; Li et al., 2014; Pan et al., 2011; Ganin et al., 2016). In unsupervised domain adaptation, the training data consists of labeled data from the source domain(s) and unlabeled data from the target domain. In practice, this setting is quite common, as in many applications ∗http://www.flll.jku.at †http://www.scch.at 1https://github.com/wzell/cmd the collection of input data is cheap, but the collection of labels is expensive. Typical examples include image analysis tasks and sentiment analysis, where labels have to be collected manually. Recent research shows that domain adaptation approaches work particularly well with (deep) neural networks, which produce outstanding results on some domain adaptation data sets (Ganin et al., 2016; Sun & Saenko, 2016; Li et al., 2016; Aljundi et al., 2015; Long et al., 2015; Li et al., 2015; Zhuang et al., 2015; Louizos et al., 2016). The most successful methods have in common that they encourage similarity between the latent network representations w. r. t. the different domains. This similarity is often enforced by minimizing a certain distance between the networks’ domainspecific hidden activations. Three outstanding approaches for the choice of the distance function are the Proxy A-distance (Ben-David et al., 2010), the Kullback-Leibler (KL) divergence Kullback & Leibler (1951), applied to the mean of the activations (Zhuang et al., 2015), and the Maximum Mean Discrepancy (Gretton et al., 2006, MMD). Two of them, the M",Landmarks-based kernelized subspace alignment for unsupervised domain adaptation | A theory of learning from different domains | Probability and measure | Convergence of probability measures | Marginalized denoising autoencoders for domain adaptation | Keras: Deep learning library for theano and tensorflow | Dlid: Deep learning for domain adaptation by interpolating between domains | Adaptive subgradient methods for online learning and stochastic optimization | The smallest upper bound for the pth absolute central moment of a class of random variables | Domain-adversarial training of neural networks | Domain adaptation for large-scale sentiment classification: A deep learning approach | A kernel method for the two-sample-problem | A kernel two-sample test | A practical guide to support vector classification | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | On information and sufficiency | Revisiting batch normalization for practical domain adaptation | Unsupervised domain adaptation by domain invariant projection | Generative moment matching networks | Learning transferable features with deep adaptation networks | The variational fair auto encoder | Domain adaptation via transfer component analysis | Adapting visual category models to new domains | Very deep convolutional networks for large-scale image recognition | Kernel choice and classifiability for rkhs embeddings of probability distributions | Deep coral: Correlation alignment for deep domain adaptation | Return of frustratingly easy domain adaptation | Generative models and model criticism via optimized maximum mean discrepancy | Deep domain confusion: Maximizing for domain invariance | Adadelta: an adaptive learning rate method | Fastmmd: Ensemble of circular discrepancy for efficient two-sample test | Cross validation framework to choose amongst models and datasets for transfer learning | Supervised representation learning: Transfer learning with deep autoencoders,iclr,010
457.pdf.json,INCREMENTAL NETWORK QUANTIZATION: TOWARDS LOSSLESS CNNS WITH LOW-PRECISION WEIGHTS,"Deep convolutional neural networks (CNNs) have demonstrated record breaking results on a variety of computer vision tasks such as image classification (Krizhevsky et al., 2012; Simonyan & Zisserman, 2015), face recognition (Taigman et al., 2014; Sun et al., 2014), semantic segmentation (Long et al., 2015; Chen et al., 2015a) and object detection (Girshick, 2015; Ren et al., 2015). Regardless of the availability of significantly improved training resources such as abundant annotated data, powerful computational platforms and diverse training frameworks, the promising results of deep CNNs are mainly attributed to the large number of learnable parameters, ranging from tens of millions to even hundreds of millions. Recent progress further shows clear evidence that CNNs could easily enjoy the accuracy gain from the increased network depth and width (He et al., 2016; Szegedy et al., 2015; 2016). However, this in turn lays heavy burdens on the memory and other ∗This work was done when Aojun Zhou was an intern at Intel Labs China, supervised by Anbang Yao who proposed the original idea and is responsible for correspondence. The first three authors contributed equally to the writing of the paper. 1This notation applies to our method throughout the paper. computational resources. For instance, ResNet-152, a specific instance of the latest residual network architecture wining ImageNet classification challenge in 2015, has a model size of about 230 MB and needs to perform about 11.3 billion FLOPs to classify a 224× 224 image crop. Therefore, it is very challenging to deploy deep CNNs on the devices with limited computation and power budgets. Substantial efforts have been made to the speed-up and compression on CNNs during training, feedforward test or both of them. Among existing methods, the category of network quantization methods attracts great attention from researches and developers. Some network quantization works try to compress pre-trained full-precision CNN models dire","Semantic image segmentation with deep convolutional nets and fully connected crfs | Compressing neural networks with the hashing trick | Binaryconnect: Training deep neural networks with binary weights during propagations | Binarized neural networks: Training deep neural networks with weights and activations constrained to +1 or -1 | Fast r-cnn | Compressing deep concolutional networks using vector quantization | Dynamic network surgery for efficient dnns | Deep learning with limited numerical precision | Learning both weights and connections for efficient neural networks | Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding | Deep residual learning for image recognition | Quantized neural networks: Training neural networks with low precision weights and activations | Imagenet classification with deep convolutional neural networks | Gradient-based learning applied to documentrecognition | Ternary weight networks | Fully convolutional networks for semantic segmentation | Xnor-net: Imagenet classification using binary convolutional neural networks | Faster r-cnn: Towards real-time object detection with region proposal networks | Very deep convolutional networks for large-scale image recognition | Expectation backpropagation: Parameter-free training of multilayer neural networks with continuous or discrete weights | Deep learning face representation from predicting 10,000 classes | Going deeper with convolutions | Inception-v4, inception-resnet and the impact of residual connections on learning | Deepface: Closing the gap to human-level performance in face verification | Improving the speed of neural networks on cpus | Dorefa-net: Training low bitwidth convolutional neural networks with low bitwidth gradients",iclr,010
458.pdf.json,ENTROPY-SGD: BIASING GRADIENT DESCENT INTO WIDE VALLEYS,"This paper presents a new optimization tool for deep learning designed to exploit the local geometric properties of the objective function. Consider the histogram we obtained in Fig. 1 showing the spectrum of the Hessian at an extremum discovered by Adam (Kingma & Ba, 2014) for a convolutional neural network on MNIST (LeCun et al., 1998) (≈ 47,000 weights, cf. Sec. 5.1). It is evident that: (i) a large number of directions (≈ 94%) have near-zero eigenvalues (magnitude less than 10−4), (ii) positive eigenvalues (right inset) have a long tail with the largest one being almost 40, (iii) negative eigenvalues (left inset), which are directions of descent that the optimizer missed, have a much faster decay (the largest negative eigenvalue is only −0.46). Interestingly, this trend is not unique to this particular network. Rather, its qualitative properties are shared across a variety of network architectures, network sizes, datasets or optimization algorithms (refer to Sec. 5 for more experiments). Local minima that generalize well and are discovered by gradient descent lie in “wide valleys” of the energy landscape, rather than in sharp, isolated minima. For an intuitive understanding of this phenomenon, imagine a Bayesian prior concentrated at the minimizer of the expected loss, the marginal likelihood of wide valleys under this prior is much higher than narrow, sharp valleys even if the latter are close to the global minimum in training loss. Almost-flat regions of the energy landscape are robust to data perturbations, noise in the activations, as well as perturbations of the parameters, all of which are widely-used techniques to achieve good generalization. This suggests that wide valleys should result in better generalization and, indeed, standard optimization algorithms in deep learning seem to discover exactly that — without being explicitly tailored to do so. For another recent analysis of the Hessian, see the parallel work of Sagun et al. (2016). Based on this unde","Numerical continuation methods: an introduction, volume | Bayesian dark knowledge | Unreasonable effectiveness of learning neural networks: From accessible states and robust ensembles to basic algorithmic schemes. PNAS, 113(48):E7655–E7662, 2016a | Learning may need only a few bits of synaptic precision | Local entropy as a measure for sampling solutions in constraint satisfaction problems | Subdominant dense clusters allow for simple learning and high computational performance in neural networks with discrete synapses | Neural networks and principal component analysis: Learning from examples without local minima | Variational inference: A review for statisticians | Stochastic gradient descent tricks | Stability and generalization | Metastability: A potential theoretic approach | The statistics of critical points of Gaussian fields on large-dimensional spaces | On the energy landscape of deep networks | Bridging the gap between stochastic gradient MCMC and stochastic optimization | Stochastic Gradient Hamiltonian Monte Carlo | The loss surfaces of multilayer networks | Open problem: The landscape of the loss surfaces of multilayer networks | Fast and accurate deep network learning by exponential linear units (ELUs) | Analytical and numerical study of internal representations in multilayer neural networks with binary weights | Recurrent batch normalization | Identifying and attacking the saddle point problem in high-dimensional non-convex optimization | Bayesian sampling using stochastic gradient thermostats | Adaptive subgradient methods for online learning and stochastic optimization | Replica symmetry breaking condition exposed by random matrix calculation of landscape complexity | Scalable Bayesian Learning of Recurrent Neural Networks for Language Modeling | Escaping from saddle points — online stochastic gradient for tensor decomposition | Qualitatively characterizing neural network optimization problems | Global optimality in tensor factorization, deep learning, and beyond | Train faster, generalize better: Stability of stochastic gradient descent | Mutual information, metric entropy and cumulative relative entropy risk | On graduated optimization for stochastic non-convex problems | Long short-term memory | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Beating the Perils of Non-Convexity: Guaranteed Training of Neural Networks using Tensor Methods | Visualizing and understanding recurrent networks | Deep learning without poor local minima | Adam: A method for stochastic optimization | Learning multiple layers of features from tiny images | Gradient-based learning applied to document recognition | A complete recipe for stochastic gradient MCMC | A variational analysis of stochastic gradient algorithms | Building a large annotated corpus of English: The Penn Treebank | Training Recurrent Neural Networks by Diffusion | On the link between Gaussian homotopy continuation and convex envelopes | Weight space structure and internal representations: A direct approach to learning and generalization in multilayer neural networks | MCMC using Hamiltonian dynamics | Fast exact multiplication by the hessian | Acceleration of stochastic approximation by averaging | Langevin diffusions and Metropolis-Hastings algorithms | Weight normalization: A simple reparameterization to accelerate training of deep neural networks | Exact solutions to the nonlinear dynamics of learning in deep linear neural networks | No bad local minima: Data independent training error guarantees for multilayer neural networks | Striving for simplicity: The all convolutional net | Dropout: a simple way to prevent neural networks from overfitting | On the importance of initialization and momentum in deep learning | Lecture 6.5: RmsProp, Coursera: Neural networks for machine learning | All of statistics: A concise course in statistical inference | Bayesian learning via stochastic gradient Langevin dynamics | Recurrent neural network regularization | Understanding deep learning requires rethinking generalization | Deep learning with elastic averaging SGD | 2015) and set the learning rate schedule to be η/(1+ t)b where the initial",iclr,010
459.pdf.json,DEEP MULTI-TASK REPRESENTATION LEARNING: A TENSOR FACTORISATION APPROACH,"The paradigm of multi-task learning is to learn multiple related tasks simultaneously so that knowledge obtained from each task can be re-used by the others. Early work in this area focused on neural network models (Caruana, 1997), while more recent methods have shifted focus to kernel methods, sparsity and low-dimensional task representations of linear models (Evgeniou & Pontil, 2004; Argyriou et al., 2008; Kumar & Daumé III, 2012). Nevertheless given the impressive practical efficacy of contemporary deep neural networks (DNN)s in many important applications, we are motivated to revisit MTL from a deep learning perspective. While the machine learning community has focused on MTL for shallow linear models recently, applications have continued to exploit neural network MTL (Zhang et al., 2014; Liu et al., 2015). The typical design pattern dates back at least 20 years (Caruana, 1997): define a DNN with shared lower representation layers, which then forks into separate layers and losses for each task. The sharing structure is defined manually: full-sharing up to the fork, and full separation after the fork. However this complicates DNN architecture design because the user must specify the sharing structure: How many task specific layers? How many task independent layers? How to structure sharing if there are many tasks of varying relatedness? In this paper we present a method for end-to-end multi-task learning in DNNs. This contribution can be seen as generalising shallow MTL methods (Evgeniou & Pontil, 2004; Argyriou et al., 2008; Kumar & Daumé III, 2012) to learning how to share at every layer of a deep network; or as learning the sharing structure for deep MTL (Caruana, 1997; Zhang et al., 2014; Spieckermann et al., 2014; Liu et al., 2015) which currently must be defined manually on a problem-by-problem basis. Before proceeding it is worth explicitly distinguishing some different problem settings, which have all been loosely referred to as MTL in the literature. H",TensorFlow: Large-scale machine learning on heterogeneous systems | Convex multi-task feature learning | Multi-task gaussian process prediction | Multitask learning | Frustratingly easy domain adaptation | Age and gender estimation of unfiltered faces | Regularized multi–task learning | The indian buffet process: An introduction and review | Cross-language knowledge transfer using multilingual deep neural network with shared hidden layers | Clustered multi-task learning: A convex formulation | Learning with whom to share in multi-task feature learning | Tensor decompositions and applications | Learning task grouping and overlap in multi-task learning | Human-level concept learning through probabilistic program induction | A multilinear singular value decomposition | Speeding-up convolutional neural networks using fine-tuned cp-decomposition | Gradient-based learning applied to document recognition | Age and gender classification using convolutional neural networks | Representation learning using multi-task deep neural networks for semantic classification and information | Tensorizing neural networks | Tensor-train decomposition | Flexible modeling of latent task structures in multitask learning | Multilinear multitask learning | To transfer or not to transfer | Data-effiicient temporal regression with multitask recurrent neural networks | Cluster adaptive training for deep neural network based acoustic model | Some mathematical notes on three-mode factor analysis | Multitask learning meets tensor factorization: task imputation via convex optimization | Multi-task learning for classification with dirichlet process priors | A unified perspective on multi-domain and multi-task learning | Facial landmark detection by deep multi-task learning,iclr,010
460.pdf.json,,"Realistic simulated environments, where agents can be trained to learn a large repertoire of cognitive skills, are at the core of recent breakthroughs in AI (Bellemare et al., 2013; Mnih et al., 2015; Schulman et al., 2015a; Narasimhan et al., 2015; Mnih et al., 2016; Brockman et al., 2016; Oh et al., 2016). With richer realistic environments, the capabilities of our agents have increased and improved. Unfortunately, these advances have been accompanied by a substantial increase in the cost of simulation. In particular, every time an agent acts upon the environment, an expensive simulation step is conducted. Thus to reduce the cost of simulation, we need to reduce the number of simulation steps (i.e. samples of the environment). This need for sample efficiency is even more compelling when agents are deployed in the real world. Experience replay (Lin, 1992) has gained popularity in deep Q-learning (Mnih et al., 2015; Schaul et al., 2016; Wang et al., 2016; Narasimhan et al., 2015), where it is often motivated as a technique for reducing sample correlation. Replay is actually a valuable tool for improving sample efficiency and, as we will see in our experiments, state-of-the-art deep Q-learning methods (Schaul et al., 2016; Wang et al., 2016) have been up to this point the most sample efficient techniques on Atari by a significant margin. However, we need to do better than deep Q-learning, because it has two important limitations. First, the deterministic nature of the optimal policy limits its use in adversarial domains. Second, finding the greedy action with respect to the Q function is costly for large action spaces. Policy gradient methods have been at the heart of significant advances in AI and robotics (Silver et al., 2014; Lillicrap et al., 2015; Silver et al., 2016; Levine et al., 2015; Mnih et al., 2016; Schulman et al., 2015a; Heess et al., 2015). Many of these methods are restricted to continuous domains or to very specific tasks such as playing Go. The exi","The arcade learning environment: An evaluation platform for general agents | Off-policy actor-critic | Learning continuous control policies by stochastic value gradients | On a connection between importance sampling and the likelihood ratio policy gradient | Guided policy search | End-to-end training of deep visuomotor policies | Continuous control with deep reinforcement learning | Self-improving reactive agents based on reinforcement learning, planning and teaching | Off-policy policy search | Human-level control through deep reinforcement learning | Asynchronous methods for deep reinforcement learning | Safe and efficient off-policy reinforcement learning | Language understanding for text-based games using deep reinforcement learning | Control of memory, active perception, and action in Minecraft | Eligibility traces for off-policy policy evaluation | Prioritized experience replay | Trust region policy optimization | High-dimensional continuous control using generalized advantage estimation | Deterministic policy gradient algorithms | Mastering the game of Go with deep neural networks and tree | Policy gradient methods for reinforcement learning with function approximation | MuJoCo: A physics engine for model-based control | Dueling network architectures for deep reinforcement learning | Real-time reinforcement learning by sequential actor–critics and experience replay | velocity of all joints as well as the displacement between target and the end effector of the arm. The 3-dimensional action are the torques applied to the joints. Cheetah The Half-Cheetah (Wawrzyński",iclr,010
461.pdf.json,TEMPORAL ENSEMBLING FOR SEMI-SUPERVISED LEARNING,"It has long been known that an ensemble of multiple neural networks generally yields better predictions than a single network in the ensemble. This effect has also been indirectly exploited when training a single network through dropout (Srivastava et al., 2014), dropconnect (Wan et al., 2013), or stochastic depth (Huang et al., 2016) regularization methods, and in swapout networks (Singh et al., 2016), where training always focuses on a particular subset of the network, and thus the complete network can be seen as an implicit ensemble of such trained sub-networks. We extend this idea by forming ensemble predictions during training, using the outputs of a single network on different training epochs and under different regularization and input augmentation conditions. Our training still operates on a single network, but the predictions made on different epochs correspond to an ensemble prediction of a large number of individual sub-networks because of dropout regularization. This ensemble prediction can be exploited for semi-supervised learning where only a small portion of training data is labeled. If we compare the ensemble prediction to the current output of the network being trained, the ensemble prediction is likely to be closer to the correct, unknown labels of the unlabeled inputs. Therefore the labels inferred this way can be used as training targets for the unlabeled inputs. Our method relies heavily on dropout regularization and versatile input augmentation. Indeed, without neither, there would be much less reason to place confidence in whatever labels are inferred for the unlabeled training data. We describe two ways to implement self-ensembling, Π-model and temporal ensembling. Both approaches surpass prior state-of-the-art results in semi-supervised learning by a considerable margin. We furthermore observe that self-ensembling improves the classification accuracy in fully labeled cases as well, and provides tolerance against incorrect labels. The recentl","Learning with pseudo-ensembles | Dropout as a bayesian approximation: Representing model uncertainty in deep learning | Fractional max-pooling | Delving deep into rectifiers: Surpassing human-level performance on imagenet classification | Distilling the knowledge in a neural network | Deep networks with stochastic depth | Snapshot Ensembles: Train 1, get M for free | Adam: A method for stochastic optimization | Semi-supervised learning with deep generative models | Generalizing pooling functions in convolutional neural networks: Mixed | Rectifier nonlinearities improve neural network acoustic models | All you need is a good init | Distributional smoothing with virtual adversarial training | Semi-supervised learning with generative adversarial networks. Data Efficient Machine Learning workshop at ICML | Making neural networks robust to label noise: a loss correction approach | Semisupervised learning with ladder networks | Training deep neural networks on noisy labels with bootstrapping | Mutual exclusivity loss for semi-supervised deep learning | Regularization with stochastic transformations and perturbations for deep semi-supervised learning | Weight normalization: A simple reparameterization to accelerate training of deep neural networks | Improved techniques for training | Transformation Invariance in Pattern Recognition  | Swapout: Learning an ensemble of deep architectures | Unsupervised and semi-supervised learning with categorical generative adversarial networks | Striving for simplicity: The all convolutional net | 80 million tiny images: A large data set for nonpara | Regularization of neural | Bootstrapping via graph propagation | A NETWORK ARCHITECTURE, TEST SETUP, AND TRAINING PARAMETERS Table 5 details the network architecture used in all of our tests. It is heavily inspired by ConvPoolCNN-C (Springenberg et al., 2014) and the improvements made by Salimans | confirmed from the authors). This kind of stratification might further improve the convergence of our methods as well. Tiny Images, extra data from restricted categories The restricted extra data in Section 3.3 was extracted from Tiny Images by picking all images with labels corresponding to the 100 categories used in CIFAR-100. As the Tiny Images dataset does not contain CIFAR-100 categories aquar",iclr,010
462.pdf.json,ON DETECTING ADVERSARIAL PERTURBATIONS,"In the last years, machine learning and in particular deep learning methods have led to impressive performance on various challenging perceptual tasks, such as image classification (Russakovsky et al., 2015; He et al., 2016) and speech recognition (Amodei et al., 2016). Despite these advances, perceptual systems of humans and machines still differ significantly. As Szegedy et al. (2014) have shown, small but carefully directed perturbations of images can lead to incorrect classification with high confidence on artificial systems. Yet, for humans these perturbations are often visually imperceptible and do not stir any doubt about the correct classification. In fact, so called adversarial examples are crucially characterized by requiring minimal perturbations that are quasi-imperceptible to a human observer. For computer vision tasks, multiple techniques to create such adversarial examples have been developed recently. Perhaps most strikingly, adversarial examples have been shown to transfer between different network architectures, and networks trained on disjoint subsets of data (Szegedy et al., 2014). Adversarial examples have also been shown to translate to the real world (Kurakin et al., 2016), e.g., adversarial images can remain adversarial even after being printed and recaptured with a cell phone camera. Moreover, Papernot et al. (2016a) have shown that a potential attacker can construct adversarial examples for a network of unknown architecture by training an auxiliary network on similar data and exploiting the transferability of adversarial inputs. The vulnerability to adversarial inputs can be problematic and even prevent the application of deep learning methods in safety- and security-critical applications. The problem is particularly severe when human safety is involved, for example in the case of perceptual tasks for autonomous driving. Methods to increase robustness against adversarial attacks have been proposed and range from augmenting the training data",Deep Speech 2: End-to-End Speech Recognition in English and Mandarin | Towards Evaluating the Robustness of Neural Networks | A study of the effect of JPG compression on adversarial images | Explaining and Harnessing Adversarial Examples | Deep Residual Learning for Image Recognition | Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift | Adam: A Method for Stochastic Optimization | Learning Multiple Layers of Features from Tiny Images | Adversarial examples in the physical world | Universal adversarial perturbations | DeepFool: A simple and accurate method to fool deep neural networks | Practical Black-Box Attacks against Deep Learning Systems using Adversarial Examples | Distillation as a Defense to Adversarial Perturbations against Deep Neural Networks | Are accuracy and robustness correlated | ImageNet Large Scale Visual Recognition Challenge | Very Deep Convolutional Networks for Large-Scale Image Recognition | Intriguing properties of neural networks | A Boundary Tilting | Development Team. Theano: A Python framework for fast computation of mathematical expressions | Improving the Robustness of Deep Neural Networks via Stability Training,iclr,010
463.pdf.json,TRAINING DEEP NEURAL-NETWORKS USING A NOISE ADAPTATION LAYER,"The presence of class label noise inherent to training samples has been reported to deteriorate the performance of even the best classifiers in a broad range of classification problems (Nettleton et al. (2010), Pechenizkiy et al. (2006), Zhu & Wu (2004)). Noisy labels also tend to be more harmful than noisy attributes (Zhu & Wu (2004)). Noisy data are usually related to the data collection process. Typically, the labels used to train a classifier are assumed to be unambiguous and accurate. However, this assumption often does not hold since labels that are provided by human judgments are subjective. Many of the largest image datasets have been extracted from social networks. These images are labeled by non-expert users and building a consistent model based on a precisely labeled training set is very tedious. Mislabeling examples have been reported even in critical applications such as biomedical datasets where the available data are restricted (Alon et al. (1999)). A very common approach to noisy datasets is to remove the suspect samples in a preprocessing stage or have them relabeled by a data expert (Brodley & Friedl (1999)). However, these methods are not scalable and may run the risk of removing crucial examples that can impact small datasets considerably. Variants that are noise robust have been proposed for the most common classifiers such as logisticregression and SVM (Frénay & Verleysen (2014), Jakramate & Kabán (2012), Beigman & Klebanov (2009)). However, classifiers based on label-noise robust algorithms are still affected by label noise. From a theoretical point of view, Bartlett et al. (2006) showed that most loss functions are not completely robust to label noise. Natarajan et al. (2013) proposed a generic unbiased estimator for binary classification with noisy labels. They developed a surrogate cost function that can be expressed by a weighted sum of the original cost functions, and provided asymptotic bounds for performance. Grandvalet & Bengio (2005","Broad patterns of gene expression revealed by clustering analysis of tumor and normal colon tissues probed by oligonucleotide arrays | Convexity, classification, and risk bounds | Learning with annotation noise | Training deep neural-networks based on unreliable labels | Identifying mislabeled training data | A comprehensive introduction to label noise | Classification in the presence of label noise: a survey | Semi-supervised learning by entropy minimization | Distilling the knowledge in a neural network | Label-noise robust logistic regression and its applications | Adam: A method for stochastic optimization | Learning multiple layers of features from tiny images | Design of robust neural network classifiers | Learning to label aerial images from noisy data | Hierarchical probabilistic neural network language model | Learning with noisy labels | A study of the effect of different types of noise on the precision of supervised learning techniques | Class noise and supervised learning in medical domains: The effect of feature extraction | Training deep neural networks on noisy labels with bootstrapping | Learning from noisy labels with deep neural networks | Class noise vs. attribute noise: A quantitative study",iclr,010
464.pdf.json,,"Languages encode meaning in terms of hierarchical, nested structures on sequences of words (Chomsky, 1957). However, the degree to which neural network architectures that compute representations of the meaning of sentences for practical applications should explicitly reflect such structures is a matter for debate. In this work, we use reinforcement learning to learn to construct trees for computing sentence representations, guided by feedback from downstream tasks that depend on these representations. The space of structures that are considered by the learner includes both fully sequential structures (corresponding to traditional recurrent neural network “encoders”), as well as all projective binary trees. Thus, although we take seriously the notion that good compositional architectures might be tree-structured, we specify neither the form of the tree nor whether a tree is necessary at all, and instead leave those decisions up to the learner (and the data). To place this work in context, there are three predominant approaches for constructing vector representations of sentences from a sequence of words. The first composes words sequentially using a recurrent neural network, treating the RNN’s final hidden state as the representation of the sentence (Cho et al., 2014; Sutskever et al., 2014; Kiros et al., 2015). In such models, there is no explicit hierarchical organization imposed on the words, and the RNN’s dynamics must learn to simulate it. The second approach uses tree-structured networks to recursively compose representations of words and phrases to form representations of larger phrases and, finally, the complete sentence. In contrast to sequential models, these models’ architectures are organized according to each sentence’s syntactic structure, that is, the hierarchical organization of words into nested phrases that characterizes human intuitions about how words combine to form grammatical sentences. Prior work on tree-structured models has assumed that tree","The meaning factory: Formal semantics for recognizing textual entailment and determining semantic similarity | Unsupervised induction of tree substitution grammars for dependency parsing | A large annotated corpus for learning natural language inference | A fast unified model for parsing and sentence understanding | Hierarchical phrase-based translation | Learning phrase representations using RNN encoder-decoder for statistical machine translation | A compositional distributional model of meaning | Jointly modeling aspects, ratings and sentiments for movie recommendation (JMARS) | Recurrent neural network grammars | Experimental support for a categorical compositional distributional model of meaning | Long short-term memory | UNAL-NLP: Combining soft cardinality features for semantic textual similarity, relatedness and entailment | A convolutional neural network for modelling sentences | Convolutional neural networks for sentence classification | Skip-thought vectors | Accurate unlexicalized parsing | Corpus-based induction of syntactic structure: Models of dependency and constituency | Illinois-lh: A denotational and distributional approach to semantics | Dependency-based convolutional neural networks for sentence embedding | Evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual entailment | Natural language inference by tree-based convolution and heuristic matching | Neural semantic encoders | Neural tree indexers for text understanding | Improving nlp through marginalization of hidden syntactic structure | Glove: Global vectors for word representation | Language Learnability and Language Development | Semantic compositionality through recursive matrix-vector spaces | Recursive deep models for semantic compositionality over a sentiment treebank | Grounded compositional semantics for finding and describing images with sentences | Unsupervised dependency parsing without gold part-of-speech tags | Sequence to sequence learning with neural networks | Improved semantic representations from tree-structured long short-term memory networks | Order-embeddings of images and language | Simple statistical gradient-following algorithms for connectionist reinforcement learning | Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars | Long short-term memory over recursive structures",iclr,010
465.pdf.json,,"Recent research has demonstrated that for a deep architecture, it is easy to generate adversarial examples, which are close to the original ones but are misclassified by the deep architecture (Szegedy et al. (2013); Goodfellow et al. (2014)). The existence of such adversarial examples may have severe consequences, which hinders vision-understanding-based applications, such as autonomous driving. Most of these studies require explicit knowledge of the underlying models. It remains an open question how to efficiently find adversarial examples for a black-box model. Several works have demonstrated that some adversarial examples generated for one model may also be misclassified by another model. Such a property is referred to as transferability, which can be leveraged to perform black-box attacks. This property has been exploited by constructing a substitute of the black-box model, and generating adversarial instances against the substitute to attack the black-box system (Papernot et al. (2016a;b)). However, so far, transferability is mostly examined over small datasets, such as MNIST (LeCun et al. (1998)) and CIFAR-10 (Krizhevsky & Hinton (2009)). It has yet to be better understood transferability over large scale datasets, such as ImageNet (Russakovsky et al. (2015)). In this work, we are the first to conduct an extensive study of the transferability of different adversarial instance generation strategies applied to different state-of-the-art models trained over a large scale dataset. In particular, we study two types of adversarial examples: (1) non-targeted adversarial examples, which can be misclassified by a network, regardless of what the misclassified labels may be; and (2) targeted adversarial examples, which can be classified by a network as a target label. We examine several existing approaches searching for adversarial examples based on a single model. While non-targeted adversarial examples are more likely to transfer, we observe few targeted adversarial ex",Towards evaluating the robustness of neural networks | Robustness of classifiers: from adversarial to random noise | Explaining and harnessing adversarial examples | Deep residual learning for image recognition | Adam: A method for stochastic optimization | Learning multiple layers of features from tiny images | Gradient-based learning applied to document recognition | Delving into transferable adversarial examples and black-box attacks | Universal adversarial perturbations | Transferability in machine learning: from phenomena to black-box attacks using adversarial samples | Practical black-box attacks against deep learning systems using adversarial examples | Very deep convolutional networks for large-scale image recognition | Man vs. computer: Benchmarking machine learning algorithms for traffic sign recognition | Intriguing properties of neural networks,iclr,010
466.pdf.json,,"Traditional convolutional neural networks for image classification, such as AlexNet (Krizhevsky et al. (2012)), are parameterized in such a way that when all trainable weights are 0, a convolutional layer represents the 0-mapping. Moreover, the weights are initialized symmetrically around 0. This standard parameterization makes it non-trivial for a convolutional layer trained with stochastic gradient methods to preserve features that were already good. Put differently, such convolutional layers cannot easily converge to the identity transformation at training time. This shortcoming was observed and partially addressed by Ioffe & Szegedy (2015) through batch normalization, i.e., layer-wise whitening of the input with a learned mean and covariance. But the idea remained somewhat implicit until residual networks (He et al. (2015); He et al. (2016)) explicitly introduced a reparameterization of the convolutional layers such that when all trainable weights are 0, the layer represents the identity function. Formally, for an input x, each residual layer has the form x + h(x), rather than h(x). This simple reparameterization allows for much deeper architectures largely avoiding the problem of vanishing (or exploding) gradients. Residual networks, and subsequent architectures that use the same parameterization, have since then consistently achieved state-of-the-art results on various computer vision benchmarks such as CIFAR10 and ImageNet.","Random matrices and complexity of spin glasses | Neural networks and principal component analysis: Learning from examples without local minima | The loss surfaces of multilayer networks | Identifying and attacking the saddle point problem in high-dimensional non-convex optimization | Qualitatively characterizing neural network optimization problems | Deep residual learning for image recognition | Identity mappings in deep residual networks | Densely connected convolutional networks | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Extensions of lipschitz mappings into a hilbert space | Linear Convergence of Gradient and Proximal-Gradient Methods Under the Polyak-\L{}ojasiewicz Condition | Deep Learning without Poor Local Minima | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | No bad local minima: Data independent training error guarantees for multilayer neural networks | Striving for Simplicity: The All Convolutional Net | Normal matrix, from mathworld–a wolfram web resource., 2016",iclr,010
467.pdf.json,ADVERSARIAL FEATURE LEARNING,"Deep convolutional networks (convnets) have become a staple of the modern computer vision pipeline. After training these models on a massive database of image-label pairs like ImageNet (Russakovsky et al., 2015), the network easily adapts to a variety of similar visual tasks, achieving impressive results on image classification (Donahue et al., 2014; Zeiler & Fergus, 2014; Razavian et al., 2014) or localization (Girshick et al., 2014; Long et al., 2015) tasks. In other perceptual domains such as natural language processing or speech recognition, deep networks have proven highly effective as well (Bahdanau et al., 2015; Sutskever et al., 2014; Vinyals et al., 2015; Graves et al., 2013). However, all of these recent results rely on a supervisory signal from large-scale databases of hand-labeled data, ignoring much of the useful information present in the structure of the data itself. Meanwhile, Generative Adversarial Networks (GANs) (Goodfellow et al., 2014) have emerged as a powerful framework for learning generative models of arbitrarily complex data distributions. The GAN framework learns a generator mapping samples from an arbitrary latent distribution to data, as well as an adversarial discriminator which tries to distinguish between real and generated samples as accurately as possible. The generator’s goal is to “fool” the discriminator by producing samples which are as close to real data as possible. When trained on databases of natural images, GANs produce impressive results (Radford et al., 2016; Denton et al., 2015). Interpolations in the latent space of the generator produce smooth and plausible semantic variations, and certain directions in this space correspond to particular semantic attributes along which the data distribution varies. For example, Radford et al. (2016) showed that a GAN trained on a database of human faces learns to associate particular latent directions with gender and the presence of eyeglasses. A natural question arises from this oste","Learning to see by moving | Neural machine translation by jointly learning to align and translate | Deep generative image models using a Laplacian pyramid of adversarial networks | Unsupervised visual representation learning by context prediction | DeCAF: A deep convolutional activation feature for generic visual recognition | The PASCAL Visual Object Classes challenge: A retrospective | Fast R-CNN | Rich feature hierarchies for accurate object detection and semantic segmentation | Generative adversarial nets | Speech recognition with deep recurrent neural networks | Reducing the dimensionality of data with neural networks | A fast learning algorithm for deep belief nets | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Caffe: Convolutional architecture for fast feature embedding | Adam: A method for stochastic optimization | Data-dependent initializations of convolutional neural networks | ImageNet classification with deep convolutional neural networks | Gradient-based learning applied to document recognition | Fully convolutional networks for semantic segmentation | Rectifier nonlinearities improve neural network acoustic models | Unsupervised learning of visual representations by solving jigsaw puzzles | Context encoders: Feature learning by inpainting | Unsupervised representation learning with deep convolutional generative adversarial networks | CNN features off-the-shelf: an astounding baseline for recognition | ImageNet large scale visual recognition challenge | Deep Boltzmann machines | Sequence to sequence learning with neural networks | Grammar as a foreign language | Unsupervised learning of visual representations using videos | Visualizing and understanding convolutional networks | non-linearity with a “leak” of 0.2 is used; in G, a standard ReLU non-linearity is used. All models are trained for 400 epochs. C.2 IMAGENET In all ImageNet experiments (Section 4.3), the encoder E architecture follows AlexNet (Krizhevsky et al., 2012) through the fifth and last convolution layer (conv5), with local response normalization | 2016) (left), nearest neighbors (by minimum cosine distance) from the ImageNet LSVRC (Russakovsky et al., 2015) training set in the fc6 feature space of the ImageNet-trained BiGAN encoder E. (The fc6 weights are set randomly; this space is a random projection of the learned conv5 feature space",iclr,010
468.pdf.json,,"Deep neural networks have emerged to be the state-of-the-art in the field of machine learning for image classification, object detection, speech recognition, natural language processing, and machine translation (LeCun et al., 2015). The substantial progress of neural networks however comes with high cost of computations and hardware resources resulting from a large number of parameters. For example, Krizhevsky et al. (2012) came up with a deep convolutional neural network consisting of 61 million parameters and won the ImageNet competition in 2012. It is followed by deeper neural networks with even larger numbers of parameters, e.g., Simonyan & Zisserman (2014). The large sizes of deep neural networks make it difficult to deploy them on resource-limited devices, e.g., mobile or portable devices, and network compression is of great interest in recent years to reduce computational cost and memory requirements for deep neural networks. Our interest in this paper is mainly on curtailing the size of the storage (memory) for network parameters (weights and biases). In particular, we focus on the network size compression by reducing the number of distinct network parameters by quantization. Besides network quantization, network pruning has been studied for network compression to remove redundant parameters permanently from neural networks (Mozer & Smolensky, 1989; LeCun et al., 1989; Hassibi & Stork, 1993; Han et al., 2015b; Lebedev & Lempitsky, 2016; Wen et al., 2016). Matrix/tensor factorization and low-rank approximation have been investigated as well to find more efficient representations of neural networks with a smaller number of parameters and consequently to save computations (Sainath et al., 2013; Xue et al., 2013; Jaderberg et al., 2014; Lebedev et al., 2014; Yang et al., 2015; Liu et al., 2015; Kim et al., 2015; Tai et al., 2015; Novikov et al., 2015). Moreover, similar to network quantization, low-precision network implementation has been examined in Vanhoucke ","Improving the convergence of back-propagation learning with second order methods | Entropy-constrained vector quantization | Training deep neural networks with low precision multiplications | Binaryconnect: Training deep neural networks with binary weights during propagations | Elements of information theory | Adaptive subgradient methods for online learning and stochastic optimization | Asymptotically efficient quantizing | Compressing deep convolutional networks using vector quantization | Deep learning with limited numerical precision | Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding | Learning both weights and connections for efficient neural network | Second order derivatives for network pruning: Optimal brain surgeon | Deep residual learning for image recognition | Speeding up convolutional neural networks with low rank expansions | Compression of deep convolutional neural networks for fast and low power mobile applications | Adam: A method for stochastic optimization | Learning multiple layers of features from tiny images | Imagenet classification with deep convolutional neural networks | Modèles connexionnistes de l’apprentissage | Fast convnets using group-wise brain damage | Speeding-up convolutional neural networks using fine-tuned CP-decomposition | Optimal brain damage | Gradient-based learning applied to document recognition | Fixed point quantization of deep convolutional networks | Neural networks with few multiplications | Sparse convolutional neural networks | Skeletonization: A technique for trimming the fat from a network via relevance assessment | Tensorizing neural networks | XNOR-Net: Imagenet classification using binary convolutional neural networks | Imagenet large scale visual recognition challenge | Lowrank matrix factorization for deep neural network training with high-dimensional output targets | Very deep convolutional networks for large-scale image recognition | Going deeper with convolutions | Rethinking the inception architecture for computer vision | Convolutional neural networks with low-rank regularization | Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude | Improving the speed of neural networks on CPUs | Learning structured sparsity in deep neural networks | Restructuring of deep neural network acoustic models with singular value decomposition | Deep fried convnets | Adadelta: an adaptive learning rate method",iclr,010
469.pdf.json,,"Due to the success of deep neural networks in a broad set of practical and even critical artificial intelligence tasks, they are now widely deployed in a spectrum of platforms: smart phones, autonomous cars, data center servers, and even supercomputers. While suitably designed and trained CNNs can be powerful, they are often large – requiring many parameters (e.g., the celebrated AlexNet (Krizhevsky et al., 2012) has 60 millions). That large neural network models incur cost in terms of memory, energy, and inference speed is easy to see. This motivated a line of research (Han et al. (2015; 2016b); Guo et al. (2016); Denton et al. (2014), to name a few) that tries to prune the parameters after a CNN design is trained and proved useful. A common thread is to post-process a trained CNN. Post-processing may consist of retraining with sparsity inducing regularization or of approximating tensors of parameters via tensor factorization. These methods reduce the size of CNNs significantly while preserving inference accuracy. Nevertheless, the inference speed gains in pruned networks is not nearly as impressive as the size reduction. In this sense, the benefits of CNN pruning seem not fully realized. While seemingly unintuitive, that the significantly pruned CNNs run not nearly as significantly faster can be easily explained. First, fully connected (fc) layers usually contain the bulk of the parameters while convolutional (conv) layers consume the bulk of computation time. This property shows that reducing the size of just the fc layers will readily lead to meaningful reduction in size as in Han et al. (2016b); Guo et al. (2016); but little speed improvement. The crux of speed improvement thus lie in actual fast convolution of sparse kernels with feature maps (not just floating-point operations reduction), which is a challenging problem. It is well known in the field of numerical linear algebra that the performance of sparse matrix operations is typically memory bandwidth boun","Parallel Sparse Matrix-Vector and Matrix-Transpose-Vector Multiplication Using Compressed Sparse Blocks | convnet-benchmarks: Layer-wise Benchmarking | ImageNet: A Large-Scale Hierarchical Image Database | Predicting Parameters in Deep Learning | Exploiting Linear Structure Within Convolutional Networks for Efficient Evaluation | Dynamic Network Surgery for Efficient DNNs | Caffe con Troll: Shallow Ideas to Speed Up Deep Learning | Learning both Weights and Connections for Efficient Neural Networks | EIE: efficient inference engine on compressed deep neural network. CoRR, 2016a | Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding | Deep Residual Learning for Image Recognition | Training CNNs with Low-Rank Filters for Efficient Image Classification | Speeding up Convolutional Neural Networks with Low Rank Expansions | Caffe: Convolutional Architecture for Fast Feature Embedding | Compression of Deep Convolutional Neural Networks for Fast and Low Power Mobile Applications | Tensor decompositions and applications | ImageNet Classification with Deep Convolutional Neural Networks | Fast Algorithms for Convolutional Neural Networks | Fast ConvNets Using Group-wise Brain Damage | Speedingup Convolutional Neural Networks Using Fine-tuned CP-Decomposition | Sparse Convolutional Neural Networks | Holistic SparseCNN: Forging the Trident of Accuracy, Speed, and Size | Going Deeper with Convolutions | Convolutional neural networks with low-rank regularization | Fast Convolutional Nets with fbfft: A GPU Performance Evaluation | Learning Structured Sparsity in Deep Neural Networks | Roofline: An Insightful Visual Performance Model for Multicore Architectures | Accelerating Very Deep Convolutional Networks for Classification and Detection",iclr,010
470.pdf.json,STICK-BREAKING VARIATIONAL AUTOENCODERS,"Deep generative models trained via Stochastic Gradient Variational Bayes (SGVB) (Kingma & Welling, 2014a; Rezende et al., 2014) efficiently couple the expressiveness of deep neural networks with the robustness to uncertainty of probabilistic latent variables. This combination has lead to their success in tasks ranging from image generation (Gregor et al., 2015; Rezende et al., 2016) to semi-supervised learning (Kingma et al., 2014; Maaløe et al., 2016) to language modeling (Bowman et al., 2016). Various extensions to SGVB have been proposed (Burda et al., 2016; Maaløe et al., 2016; Salimans et al., 2015), but one conspicuous absence is an extension to Bayesian nonparametric processes. Using SGVB to perform inference for nonparametric distributions is quite attractive. For instance, SGVB allows for a broad class of non-conjugate approximate posteriors and thus has the potential to expand Bayesian nonparametric models beyond the exponential family distributions to which they are usually confined. Moreover, coupling nonparametric processes with neural network inference models equips the networks with automatic model selection properties such as a selfdetermined width, which we explore in this paper. We make progress on this problem by first describing how to use SGVB for posterior inference for the weights of Stick-Breaking processes (Ishwaran & James, 2001). This is not a straightforward task as the Beta distribution, the natural choice for an approximate posterior, does not have the differentiable non-centered parametrization that SGVB requires. We bypass this obstacle by using the little-known Kumaraswamy distribution (Kumaraswamy, 1980). Using the Kumaraswamy as an approximate posterior, we then reformulate two popular deep generative models—the Variational Autoencoder (Kingma & Welling, 2014a) and its semi-supervised variant (model M2 proposed by Kingma et al. (2014))—into their nonparametric analogs. These models perform automatic model selection via an infinite ",Variational inference for Dirichlet process mixtures | Generating sentences from a continuous space | Importance weighted autoencoders | An infinite restricted Boltzmann machine | Deep unsupervised clustering with gaussian mixture variational autoencoders | A Bayesian analysis of some nonparametric problems | Infinite latent feature models and the Indian buffet process | Adaptive computation time for recurrent neural networks | Draw: A recurrent neural network for image generation | Reducing the dimensionality of data with neural networks | Reliable and scalable variational inference for the hierarchical Dirichlet process | Gibbs sampling methods for stick-breaking priors | An introduction to variational methods for graphical models | Adam: A method for stochastic optimization | Auto-encoding variational bayes | Efficient gradient-based inference through transformations between Bayes nets and neural nets | Semi-supervised learning with deep generative models | Stochastic gradient variational bayes for gamma approximating distributions | A generalized probability density function for double-bounded random processes | Variational inference with renyi divergence | Auxiliary deep generative models | Density networks. Statistics and neural networks: advances at the interface | Approximate inference for deep latent gaussian mixtures | Combinatorial stochastic processes | Variational inference with normalizing flows | Stochastic backpropagation and approximate inference in deep generative models | Oneshot generalization in deep generative models | Learning ordered representations with nested dropout | Nonparametric bayesian models through probit stick-breaking processes | The generalized reparameterization gradient | Fixed-form variational posterior approximation through stochastic linear regression | Markov chain monte carlo and variational inference: Bridging the gap | A constructive definition of Dirichlet priors | Variational Gaussian process,iclr,010
471.pdf.json,IMPROVING NEURAL CONVERSATION MODELS,"Chatbots are one of the classical applications of artificial intelligence and are now ubiquitous in technology, business and everyday life. Many corporate entities are now increasingly using chatbots to either replace or assist humans in customer service contexts. For example, Microsoft is currently actively building a chat bot to optimise and streamline its technical support service. In these scenarios, there is usually an abundance of historical data since past conversations between customers and human customer service agents are usually recorded by organisations. An apparently straightforward solution would be to train chatbots to reproduce the responses by human agents using standard techniques such as maximum likelihood. While this seems natural, it is far from desirable for several reasons. It has been observed that such procedures have a tendency to produce very generic responses (Sordoni et al., 2015). For instance, when we trained chatbots via maximum likelihood on a restaurant recommendations dataset, they repeatedly output responses to the effect of How large is your group?, What is your budget? etc. Further, they also produce responses such as Let me look that up. or Give me a second. which, although permissible for a human agent to say, are not appropriate for a chatbot. Although there are ways to increase the diversity of responses (Li et al., 2015), our focus is on encouraging the bot to meaningfully advance the conversation. One way to address this problem is to provide some form of weak supervision for responses generated by a chatbot. For example, a human labeller, such as a quality assurance agent, could score each response generated by a chatbot in a conversation with a customer. This brings us to the reinforcement learning (RL) paradigm where these rewards (scores) are to be used to train a good chatbot. In this paper we will use the terms score, label, and reward interchangeably. Labelled data will mean conversations which have been assigned a ","Natural gradient works efficiently in learning | Neural machine translation by jointly learning to align and translate | An actor-critic algorithm for sequence prediction | Dynamic programming and Lagrange multipliers | Stochastic approximation with two time scales | Learning phrase representations using rnn encoder-decoder for statistical machine translation | Off-policy actor-critic | Building watson: An overview of the deepqa project | Deep reinforcement learning with a natural language action space | Teaching machines to read and comprehend | Long short-term memory | Recurrent continuous translation models | Deep visual-semantic alignments for generating image descriptions | Europarl: A parallel corpus for statistical machine translation | A diversity-promoting objective function for neural conversation models | Deep reinforcement learning for dialogue generation | Gradient temporal-difference learning algorithms | Recurrent neural network based language model | Playing atari with deep reinforcement learning | Language understanding for text-based games using deep reinforcement learning | Sequence level training with recurrent neural networks | Science question answering using instructional materials | A neural network approach to context-sensitive generation of conversational responses | Sequence to sequence learning with neural networks. In Advances in neural information processing | Learning to predict by the methods of temporal differences | Reinforcement learning: An introduction, volume 1 | Policy gradient methods for reinforcement learning with function approximation | Temporal credit assignment in reinforcement learning | Counterfactual risk minimization: Learning from logged bandit feedback | Algorithms for reinforcement learning | Chainer: a next-generation open source framework for deep learning | End-to-end lstm-based dialog control optimized with supervised and reinforcement learning | Simple statistical gradient-following algorithms for connectionist reinforcement learning",iclr,010
472.pdf.json,,"The aim of sparse coding is to represent an input vector by a linear combination of a few atoms of a learned dictionary which is usually over-complete, and the coefficients for the atoms are called sparse code. Sparse coding is widely applied in machine learning and signal processing, and sparse code is extensively used as a discriminative and robust feature representation with convincing performance for classification and clustering (Yang et al., 2009; Cheng et al., 2013; Zhang et al., 2013). Suppose the data X = [x1,x2, . . . ,xn] ∈ IRd×n lie in the d-dimensional Euclidean space IRd, and the dictionary matrix is D = [D1,D2, . . . ,Dp] ∈ IRd×p with each Dk ∈ IRd (k = 1, . . . , p) being an atom of the dictionary, sparse coding method seeks for the linear sparse representation with respect to the dictionary D for each vector x ∈X by solving the following convex optimization problem: min D,Z n∑ i=1 1 2 ‖xi −DZi‖22 + λ‖Zi‖1 s.t. ‖Dk‖2 ≤ c0, k = 1, . . . , p where λ is a weighting parameter for the `1-norm of z, and c0 is a positive constant that bounds the `2-norm of each dictionary atom. In (Gregor & LeCun, 2010), a feed-forward neural network named Learned Iterative Shrinkage and Thresholding Algorithm (LISTA) is proposed to produce the approximation for sparse coding (1). The architecture of LISTA is illustrated in Figure 1. The LISTA network involves an finite number of stages wherein each stage performs the following operation on the intermediate sparse code: z(k+1) = hθ(Wx + Sz (k)), z(0) = 0 (1) This material is based upon work supported by the National Science Foundation under Grant No. 1318971. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation. where hθ is an element-wise shrinkage function defined as [hθ(u)]k = sign(uk)(|uk| − θ)+, k = 1, . . . , p (2) and (·)+ = max{·, 0} is the positive part of a number. Let f indicate ","Tensorflow: Large-scale machine learning on heterogeneous distributed systems | A fast iterative shrinkage-thresholding algorithm for linear inverse problems | Laplacian eigenmaps for dimensionality reduction and data representation | Manifold regularization: A geometric framework for learning from labeled and unlabeled examples | Proximal alternating linearized minimization for nonconvex and nonsmooth problems | Parallel coordinate descent for l1regularized loss minimization | The restricted isometry property and its implications for compressed sensing | Return of the devil in the details: Delving deep into convolutional nets | Sparse representation and learning in visual recognition: Theory and applications | Spectral Graph Theory | An iterative thresholding algorithm for linear inverse problems with a sparsity constraint | Sparse manifold clustering and embedding | Laplacian sparse coding, hypergraph laplacian sparse coding, and applications | Learning fast approximations of sparse coding | Laplacian regularized gaussian mixture model for data clustering | Locally linear hashing for extracting non-linear manifolds | Manifold-based similarity adaptation for label propagation | Efficient sparse coding algorithms | Robust single image super-resolution via deep networks with sparse prior | Gaussian mixture model with local consistency | Online dictionary learning for sparse coding | Parallel coordinate descent methods for big data optimization | Nonlinear dimensionality reduction by locally linear embedding | Learning A deep L∞ encoder for hashing | Collaborative linear coding for robust image classification | Linear spatial pyramid matching using sparse coding for image classification | Low-rank sparse coding for image classification | Graph regularized sparse coding for image representation | Locality preserving clustering for image database | Semi-supervised learning using gaussian fields and harmonic functions",iclr,010
473.pdf.json,,"Neural network models have recently made tremendous progress in a variety of NLP applications such as speech recognition (Irie et al., 2016), sentiment analysis (Socher et al., 2013), text summarization (Rush et al., 2015; Nallapati et al., 2016), and machine translation (Firat et al., 2016). Despite the overwhelming success achieved by recurrent neural networks in modeling long range dependencies between words, current recurrent neural network language models (RNNLM) are based on the conventional classification framework, which has two major drawbacks: First, there is no assumed metric on the output classes, whereas there is evidence suggesting that learning is improved when one can define a natural metric on the output space (Frogner et al., 2015). In language modeling, there is a well established metric space for the outputs (words in the language) based on word embeddings, with meaningful distances between words (Mikolov et al., 2013; Pennington et al., 2014). Second, in the classical framework, inputs and outputs are considered as isolated entities with no semantic link between them. This is clearly not the case for language modeling, where inputs and outputs in fact live in identical spaces. Therefore, even for models with moderately sized vocabularies, the classical framework could be a vast source of inefficiency in terms of the number of variables in the model, and in terms of utilizing the information gathered by different parts of the model (e.g. inputs and outputs). In this work, we introduce a novel loss framework for language modeling to remedy the above two problems. Our framework is comprised of two closely linked improvements. First, we augment the classical cross-entropy loss with an additional term which minimizes the KL-divergence between the model’s prediction and an estimated target distribution based on the word embeddings space. This estimated distribution uses knowledge of word vector similarity. We then theoretically analyze this loss, and ","A neural probabilistic language model | Numerical methods for computing angles between linear subspaces | Language modeling with sum-product networks | On the properties of neural machine translation: Encoder-decoder approaches | Multi-way, multilingual neural machine translation with a shared attention mechanism | Learning with a wasserstein loss | A theoretically grounded application of dropout in recurrent neural networks | Distilling the knowledge in a neural network | Long short-term memory | Improved learning through augmenting the loss. Stanford CS 224D: Deep Learning for Natural Language | Lstm, gru, highway and a bit of attention: an empirical overview for language modeling in speech recognition | Character-aware neural language models | Building a large annotated corpus of english: The penn treebank | Pointer sentinel mixture models | Recurrent neural network based language model | Distributed representations of words and phrases and their compositionality | Three new graphical models for statistical language modelling | Abstractive text summarization using sequence-to-sequence rnns and beyond | How to construct deep recurrent neural networks | On the difficulty of training recurrent neural networks | Glove: Global vectors for word representation | Using the output embedding to improve language models | A neural attention model for abstractive sentence summarization | Recursive deep models for semantic compositionality over a sentiment treebank | Recurrent neural network regularization | Recurrent highway networks",iclr,010
474.pdf.json,,"Forming hierarchical concepts from low-level observations is key to knowledge discovery. In the field of artificial neural networks, deep architectures are employed for machine learning tasks, with the awareness that hierarchical representations are important (Bengio et al., 2013). Rapid progress in deep learning has shown that mapping and representing topical domains through increasingly abstract layers of feature representation is extremely effective. Unfortunately, this layered representation is difficult to interpret or use for teaching people. Consequently, deep learning models are widely used as algorithmic task performers (e.g. AlphaGo), but few act as theorists or pedagogues. In contrast, our goal is to achieve a deeper-level interpretability that explains not just what has been learned (the end results), but also what is being learned at every single stage (the process). On the other hand, music theory studies underlying patterns beneath the music surface. It objectively reveals higher-level invariances that are hidden from the low-level variations. In practice, the development of music theory is an empirical process. Through manual inspection of large corpora of music works, theorists have summarized compositional rules and guidelines (e.g. J. J. Fux, author of Gradus ad Parnassum, the most influential book on Renaissance polyphony), and have devised multi-level analytical methods (e.g. H. Schenker, inventor of Schenkerian analysis) to emphasize the hierarchical structure of music, both of which have become the standard materials taught in today’s music theory classes. The objective and empirical nature of music theory suggests the possibility of an automatic theorist — statistical techniques that perform hierarchical concept learning — while its pedagogical purpose requires human interpretability throughout the entire learning process. The book title Gradus ad Parnassum, means “the path towards Mount Parnassus,” the home of poetry, music, and learning. Th","Representation learning: A review and new perspectives | GenJam: A genetic algorithm for generating jazz solos | InfoGAN: Interpretable representation learning by information maximizing generative adversarial nets | An expert system for computer-assisted composition | Experiments in Musical Intelligence, volume 12 | Deep generative image models using a Laplacian pyramid of adversarial networks | Disentangling factors of variation via generative entangling | Universal prediction applied to stylistic music generation | Generative adversarial nets | A fast learning algorithm for deep belief nets | How to train your generative models and why does adversarial training work so well | An information theoretic approach to chord categorization and functional harmony | The Complete Musician: an Integrated Approach to Tonal Theory, Analysis, and Listening | Human-level concept learning through probabilistic program induction | Adversarial autoencoders | Complexity measures and concept learning | Unsupervised representation learning with deep convolutional generative adversarial networks | Semisupervised learning with ladder networks | Statistical properties of tonal harmony in Bach’s chorales | MySong: Automatic accompaniment generation for vocal melodies | Automatic tonal analysis: Toward the implementation of a music theory workbench | To surprise and inform | Extracting and composing robust features with denoising autoencoders | MUS-ROVER: A self-learning system for musical compositional rules | Learning interpretable musical compositional rules and traces",iclr,010
475.pdf.json,DISCRETE VARIATIONAL AUTOENCODERS,"Unsupervised learning of probabilistic models is a powerful technique, facilitating tasks such as denoising and inpainting, and regularizing supervised tasks such as classification (Hinton et al., 2006; Salakhutdinov & Hinton, 2009; Rasmus et al., 2015). Many datasets of practical interest are projections of underlying distributions over real-world objects into an observation space; the pixels of an image, for example. When the real-world objects are of discrete types subject to continuous transformations, these datasets comprise multiple disconnected smooth manifolds. For instance, natural images change smoothly with respect to the position and pose of objects, as well as scene lighting. At the same time, it is extremely difficult to directly transform the image of a person to one of a car while remaining on the manifold of natural images. It would be natural to represent the space within each disconnected component with continuous variables, and the selection amongst these components with discrete variables. In contrast, most stateof-the-art probabilistic models use exclusively discrete variables — as do DBMs (Salakhutdinov & Hinton, 2009), NADEs (Larochelle & Murray, 2011), sigmoid belief networks (Spiegelhalter & Lauritzen, 1990; Bornschein et al., 2016), and DARNs (Gregor et al., 2014) — or exclusively continuous variables — as do VAEs (Kingma & Welling, 2014; Rezende et al., 2014) and GANs (Goodfellow et al., 2014).1 Moreover, it would be desirable to apply the efficient variational autoencoder framework to models with discrete values, but this has proven difficult, since backpropagation through discrete variables is generally not possible (Bengio et al., 2013; Raiko et al., 2015). We introduce a novel class of probabilistic models, comprising an undirected graphical model defined over binary latent variables, followed by multiple directed layers of continuous latent variables. This class of models captures both the discrete class of the object in an image, an","Adaptive dropout for training deep neural networks | Estimating or propagating gradients through stochastic neurons for conditional computation | Efficient estimation of free energy differences from Monte Carlo data | Reweighted wake-sleep | Bidirectional Helmholtz machines | Generating sentences from a continuous space | Accurate and conservative estimates of MRF log-likelihood using reverse annealing | Importance weighted autoencoders | Differentiation under the integral sign with weak derivatives | Enhanced gradient for training restricted Boltzmann machines | A recurrent latent variable model for sequential data | Unsupervised models of images by spike-and-slab rbms | Approximating probabilistic inference in Bayesian belief networks is NP-hard | Learning deep generative models with doubly stochastic MCMC | Generative adversarial nets | Stochastic backpropagation through mixture density distributions | Deep autoregressive networks | DRAW: A recurrent neural network for image generation | A fast learning algorithm for deep belief nets | Autoencoders, minimum description length, and Helmholtz free energy | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Composing graphical models with neural networks for structured representations and fast inference | An introduction to variational methods for graphical models | Adam: A method for stochastic optimization | Semi-supervised learning with deep generative models | Auto-encoding variational bayes | One-shot learning by inverting a compositional causal process | The neural autoregressive distribution estimator | Gradient-based learning applied to document recognition | Variational inference with Rényi divergence | Restricted Boltzmann machines are hard to approximately evaluate or simulate | Inductive principles for restricted Boltzmann machine learning | Neural variational inference and learning in belief networks | Variational inference for Monte Carlo objectives | Evaluating probabilities under high-dimensional latent variable models | Connectionist learning of belief networks | Emergence of simple-cell receptive field properties by learning a sparse code for natural images | Variational Baysian inference with stochastic search | Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference | Building blocks for variational Bayesian learning of latent variable models | Techniques for learning binary stochastic feedforward neural networks | Semisupervised learning with ladder networks | Variational inference with normalizing flows | Stochastic backpropagation and approximate inference in deep generative models | Deep Boltzmann machines | On the quantitative analysis of deep belief networks | A structured variational auto-encoder for learning deep hierarchies of sparse features | Markov chain Monte Carlo and variational inference: Bridging the gap | Statistically optimal analysis of samples from multiple equilibrium states | Information processing in dynamical systems: Foundations of harmony theory | Ladder variational autoencoders | Sequential updating of conditional probabilities on directed graphical structures | Dropout: A simple way to prevent neural networks from overfitting | Replica Monte Carlo simulation of spin-glasses | Training restricted Boltzmann machines using approximations to the likelihood gradient | The variational Gaussian process | Simple statistical gradient-following algorithms for connectionist reinforcement learning | 2015); and the variational Gaussian process (Tran et al., 2016). On Omniglot, we compare to the importance-weighted autoencoder (IWAE; Burda et al., 2016); ladder variational autoencoder (Ladder VAE; Sønderby et al., 2016); and the restricted Boltzmann machine (RBM; Smolensky, 1986) and deep belief network (DBN | Silhouettes, we compare to the importance-weighted autoencoder (IWAE; Burda et al., 2016), reporting the results of Li & Turner (2016); reweighted wake-sleep with a deep sigmoid belief network (RWS SBN; Bornschein & Bengio, 2015); the restricted Boltzmann machine (RBM; Smolensky, 1986), reporting the results",iclr,010
476.pdf.json,,"Cybenko (1989) proved that a network with a large enough single hidden layer of sigmoid units can approximate any decision boundary. Empirical work, however, suggests that it can be difficult to train shallow nets to be as accurate as deep nets. Dauphin and Bengio (2013) trained shallow nets on SIFT features to classify a large-scale ImageNet dataset and found that it was difficult to train large, high-accuracy, shallow nets. A study of deep convolutional nets suggests that for vision tasks deeper models are preferred under a parameter budget (e.g. Eigen et al. (2014); He et al. (2015); Simonyan and Zisserman (2014); Srivastava et al. (2015)). Similarly, Seide et al. (2011) and Geras et al. (2015) show that deeper models are more accurate than shallow models in speech acoustic modeling. More recently, Romero et al. (2015) showed that it is possible to gain increases in accuracy in models with few parameters by training deeper, thinner nets (FitNets) to mimic much wider nets. Cohen and Shashua (2016); Liang and Srikant (2016) suggest that the representational efficiency of deep networks scales exponentially with depth, but it is unclear if this applies only to pathological problems, or is encountered in practice on data sets such as TIMIT and CIFAR. Ba and Caruana (2014), however, demonstrated that shallow nets sometimes can learn the functions learned by deep nets, even when restricted to the same number of parameters as the deep nets. They did this by first training state-of-the-art deep models, and then training shallow models to mimic the deep models. Surprisingly, and for reasons that are not well understood, the shallow models learned more accurate functions when trained to mimic the deep models than when trained on the original data used to train the deep models. In some cases shallow models trained this way were as accurate as state-of-the-art deep models. But this demonstration was made on the TIMIT speech recognition benchmark. Although their deep teacher m",Do deep nets really need to be deep | Theano: new features and speed improvements | Theano: a CPU and GPU math expression compiler | Transferring knowledge from a RNN to a DNN | Convolutional rectifier networks as generalized tensor decompositions | Approximation by superpositions of a sigmoidal function | Big neural networks waste capacity | Understanding deep architectures using a recursive convolutional network | Scheduled denoising autoencoders | Understanding the difficulty of training deep feedforward neural networks | Deep residual learning for image recognition | Distilling the knowledge in a neural network | Learning multiple layers of features from tiny images | Fastfood-computing hilbert space expansions in loglinear time | Learning small-size dnn with output-distribution-based criteria | Why deep neural networks | How far can we go without convolution | Zero-bias autoencoders and the benefits of co-adapting features | Actor-mimic: Deep multitask and transfer reinforcement learning | Regularizing neural networks by penalizing output distributions | FitNets: Hints for thin deep | Policy distillation | Conversational speech transcription using context-dependent deep neural networks | Very deep convolutional networks for large-scale image recognition | Practical bayesian optimization of machine learning | Scalable bayesian optimization using deep neural networks | Training very deep networks | 80 million tiny images: A large data set for nonparametric object and scene recognition | Understanding deep learning requires rethinking generalization,iclr,010
478.pdf.json,LEARNING INVARIANT REPRESENTATIONS OF PLANAR CURVES,"The discussion on invariance is a strong component of the solutions to many classical problems in numerical differential geometry. A typical example is that of planar shape analysis where one desires to have a local function of the contour which is invariant to rotations, translations and reflections like the Euclidean curvature. This representation can be used to obtain correspondence between the shapes and also to compare and classify them. However, the numerical construction of such functions from discrete sampled data is non-trivial and requires robust numerical techniques for their stable and efficient computation. Convolutional neural networks have been very successful in recent years in solving problems in image processing, recognition and classification. Efficient architectures have been studied and developed to extract semantic features from images invariant to a certain class or category of transformations. Coupled with efficient optimization routines and more importantly, a large amount of data, a convolutional neural network can be trained to construct invariant representations and semantically significant features of images as well as other types of data such as speech and language. It is widely acknowledged that such networks have superior representational power compared to more principled methods with more handcrafted features such as wavelets, Fourier methods, kernels etc. which are not optimal for more semantic data processing tasks. In this paper we connect two seemingly different fields: convolutional neural network based metric learning methods and numerical differential geometry. The results we present are the outcome of investigating the question: ”Can metric learning methods be used to construct invariant geometric quantities?” By training with a Siamese configuration involving only positive and negative examples of Euclidean transformations, we show that the network is able to train for an invariant geometric function of the curve which can b","Signature verification using a siamese time delay neural network | Numerical geometry of non-rigid shapes | On differential invariants of planar curves and recognizing partially occluded planar shapes | Recognizing objects using scale space local invariants | Differential and numerically invariant signature curves applied to object recognition | Learning visual feature descriptors for dynamic lighting conditions | Geometry of Riemannian Spaces: Lie Groups; History, Frontiers and Applications Series, volume 13 | Learning a similarity metric discriminatively, with application to face verification | Torch: a modular machine learning software library | Adaptive subgradient methods for online learning and stochastic optimization | Identifiability and reconstruction of shapes from integral invariants | The heat equation shrinking convex plane curves | The heat equation shrinks embedded plane curves to round points | Dimensionality reduction by learning an invariant mapping | Shape matching using multiscale integral invariants | Discriminative deep metric learning for face verification in the wild | Numerical geometry of images: Theory, algorithms, and applications | Shape descriptors for non-rigid shapes with a single closed contour | Integral invariant signatures | Geodesic convolutional neural networks on riemannian manifolds | A theory of multiscale, curvature-based shape representation for planar curves | Matching of 3-d curves using semi-differential invariants | Integral invariants for robust geometry processing | Area and length preserving geometric invariant scalespaces | Deep learning face representation from predicting 10,000 classes | Deepface: Closing the gap to human-level performance in face verification | Noise-resistant invariants of curves | Deepshape: Deep learned shape descriptor for 3d shape matching and retrieval",iclr,010
479.pdf.json,,"Formulating new hypotheses and testing them is a cognitive process that supports human reasoning and intelligence. This hypothesis testing process involves selective attention, working memory and cognitive control (Just and Carpenter, 1992; Polk and Seifert, 2002). Attention and working memory are engaged in order to maintain, manipulate, and update new hypotheses. Cognitive control is required to inspect and ignore incorrect hypotheses. Inspired by the hypothesis testing process in the human brain and to support dynamic reasoning of machines, in this work, we introduce a reasoning approach that is based on memory augmented neural networks (MANN). A new hypothesis is formed by regressing the original statement (i.e. query in context of QA). Then the hypothesis is tested against reality (i.e. data or document story). If the model is satisfied with the current test response or the hypothesis is true, the reasoning process is halted and the answer is found. Otherwise, another hypothesis is formulated by refining the previous one and the process is repeated until the answer is found. While the idea of modeling hypothesis testing with MANN remains a generic reasoning framework and is applicable to several AI tasks, we apply this approach to cloze-type QA by using Neural Semantic Encoders (NSE). NSE is a flexible MANN architecture and have shown a notable success on several language understanding tasks ranging from sentence classification to language inference and machine translation (Munkhdalai and Yu, 2016). NSE has read, compose and write modules to manipulate external memories and it has introduced a concept of shared and multiple memory accesses, which has shown to be effective for sequence transduction problems. Cloze-type question answering (QA) is a clever way to assess the ability of human and machine to comprehend natural language. This type of tasks are attractive for the natural language processing (NLP) community because the test sets or datasets can be gener",A capacity theory of comprehension: individual differences in working memory | Cognitive modeling | Neural semantic encoders | Teaching machines to read and comprehend | The goldilocks principle: Reading children’s books with explicit memory representations | Who did what: A large-scale person-centered cloze dataset | Natural language comprehension with the epireader | Iterative alternating neural attention for machine reading | A thorough examination of the cnn/daily mail reading comprehension | Text understanding with the attention sum reader network | End-to-end memory networks | Gated-attention readers for text comprehension | Attention-overattention neural networks for reading comprehension | Reasonet: Learning to stop reading in machine comprehension | Glove: Global vectors for word representation | Simple statistical gradient-following algorithms for connectionist reinforcement learning,iclr,010
480.pdf.json,HIERARCHICAL BEHAVIOR MODELING,"Behavioral scientists strive to decode the functional relationship between sensory input and motor output of the brain (Tinbergen, 1963; Moore, 2002). In particular, ethologists study the natural behavior of animals while neuroscientists and psychologists study behavior in a controlled environment, manipulating neural activations and environmental stimuli. These studies require quantitative measurements of behavior to discover correlations or causal relationships between behaviors over time or between behavior and stimuli; automating this process allows for more objective and precise measurements, and significantly increased throughput (Dell et al., 2014; Anderson & Perona, 2014). Many industries are also concerned with automatic measurement and prediction of human behavior, for applications such as surveillance, assisted living, sports analytics, and self driving vehicles. Behavior is complex and may be perceived at different time-scales of resolution: position, trajectory, action, activity. While position and trajectory are geometrical notions, action and activity are semantic in nature. The analysis of behavior may therefore be divided into two steps: (a) detection and tracking, where the pose of the body over time is estimated, and (b) action/activity detection and classification, where motion is segmented into meaningful intervals, each one of which is associated with a goal or a purpose. Our work focuses on going from (a) to (b), that is to detect and classify actions from motion trajectories. We use data for which tracking and pose estimation is relatively simple, which lets us focus on modeling the temporal dynamics of pose trajectories without worrying about errors stemming from low level feature extraction. Supervised learning is a powerful tool for learning action classifiers from expert-labeled examples (Jhuang et al., 2010; Burgos-Artizzu et al., 2012; Kabra et al., 2013; Eyjolfsdottir et al., 2014). However, it has two drawbacks. First, it requires a l","TensorFlow: Large-scale machine learning on heterogeneous systems | Toward a science of computational ethology | Autoencoders, unsupervised learning, and deep architectures | Mapping the stereotyped behaviour of freely moving fruit flies | Vehicles Experiments in Synthetic Psychology | Social behavior recognition in continuous video | Learning phrase representations using rnn encoder-decoder for statistical machine translation | A recurrent latent variable model for sequential data | Automated image-based tracking and its application in ecology | Detecting social actions of fruit flies | Speech recognition with deep recurrent neural networks | Generating sequences with recurrent neural networks | Long short-term memory | Automated home-cage behavioural phenotyping of mice | Jaaba: interactive machine learning for automatic annotation of animal | Iam-ondb-an on-line english sentence database acquired from handwritten text on a whiteboard | Visualizing data using t-sne | Human-level control through deep reinforcement learning | Some thoughts on the relation between behavior analysis and behavioral neuroscience | Dynamic bayesian networks: representation, inference and learning | Semisupervised learning with ladder networks | A stochastic neuronal model predicts random search behaviors at multiple spatial scales in c | Learning internal representation by error propagation, parallel distributed processing | Mastering the game of go with deep neural networks and tree | The sciences of the artificial | Fruitless, doublesex and the genetics of social behavior in drosophila melanogaster | On aims and methods of ethology | From neural pca to deep unsupervised learning | Mapping sub-second structure in mouse",iclr,010
481.pdf.json,,"It has been shown that machine learning models are often vulnerable to adversarial manipulation of their input intended to cause incorrect classification (Dalvi et al., 2004). In particular, neural networks and many other categories of machine learning models are highly vulnerable to attacks based on small modifications of the input to the model at test time (Biggio et al., 2013; Szegedy et al., 2014; Goodfellow et al., 2014; Papernot et al., 2016b). The problem can be summarized as follows. Let’s say there is a machine learning system M and input sample C which we call a clean example. Let’s assume that sample C is correctly classified by the machine learning system, i.e. M(C) = ytrue. It’s possible to construct an adversarial example A which is perceptually indistinguishable from C but is classified incorrectly, i.e. M(A) 6= ytrue. These adversarial examples are misclassified far more often than examples that have been perturbed by noise, even if the magnitude of the noise is much larger than the magnitude of the adversarial perturbation (Szegedy et al., 2014). Adversarial examples pose potential security threats for practical machine learning applications. In particular, Szegedy et al. (2014) showed that an adversarial example that was designed to be misclassified by a model M1 is often also misclassified by a model M2. This adversarial example transferability property means that it is possible to generate adversarial examples and perform a misclassification attack on a machine learning system without access to the underlying model. Papernot et al. (2016a) and Papernot et al. (2016b) demonstrated such attacks in realistic scenarios. It has been shown (Goodfellow et al., 2014; Huang et al., 2015) that injecting adversarial examples into the training set (also called adversarial training) could increase robustness of neural networks to adversarial examples. Another existing approach is to use defensive distillation to train the network (Papernot et al., 2015). Howe","Evasion attacks against machine learning at test time | Fast and accurate deep network learning by exponential linear units (elus) | Adversarial classification | Explaining and harnessing adversarial examples | Learning with a strong adversary | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Adversarial examples in the physical world | Virtual adversarial training for semi-supervised text classification | Distributional smoothing with virtual adversarial training | Transferability in Machine Learning: from Phenomena to Black-Box Attacks using Adversarial Samples | Distillation as a defense to adversarial perturbations against deep neural networks | Practical black-box attacks against deep learning systems using adversarial examples | Are accuracy and robustness correlated | Imagenet large scale visual recognition challenge | Intriguing properties of neural networks | Rethinking the inception architecture for computer | Inception-v4, inception-resnet and the impact of residual connections on learning | Fast grad. L∞” is similar to “fast grad. L2” but uses L∞ norm for normalization",iclr,010
482.pdf.json,,"The idea of exploiting the large amounts of data captured in electronic medical records for both clinical care and secondary research holds great promise, but its potential is weakened by errors and omissions in those records (Safran et al., 2007; de Lusignan & van Weel, 2006). Among many other problems, accurately capturing the list of medications currently taken by a given patient is extremely challenging (Velo & Minuz, 2009). In one study, over 50% of electronic medication lists contained omissions (Caglar et al., 2011), and in another, 25% of all medications taken by patients were not recorded (Kaboli et al., 2004). Even medication lists provided by the patients themselves contain multiple errors and omissions (Green et al., 2010) . Many efforts have been made to ensure the correctness of medication lists, most of them involving improved communication between patients and providers (Keogh et al., 2016), but these efforts have not yet been successful, and incorrect or incomplete medication documentation continues to be a source of error in computational medical research. In this work we attempt to identify likely errors and omissions in the record, predicting the set of active medications from the sequence of most recent disease-based billing codes in the record. Predictions from such a model could be used either in manual medication reconciliation (a common process undertaken to correct the medication record) or to provide a prior to other models, such as an NLP model attempting to extract medication use from the narrative clinical text. Given the sequential nature of clinical data, we suspected that recurrent neural networks would be a good architecture for making these predictions. In this work we investigate this potential, comparing the performance of recurrent networks to that of similarly-configured feed forward networks. The input for each case is a sequence of ICD-9 billing codes (Section 2.1), for which the model produces a single, multi-label predictio","The use of ICD-9 codes in genetic association studies | Random search for hyper-parameter optimization | Emergency department medication lists are not accurate | Learning phrase representations using RNN encoder-decoder for statistical machine | Doctor ai: Predicting clinical events via recurrent neural networks | Using recurrent neural network models for early detection of heart failure onset | Empirical evaluation of gated recurrent neural networks on sequence modeling | The use of routinely collected computer data for research in primary care: opportunities and challenges | Phewas: demonstrating the feasibility of a phenome-wide scan to discover gene–disease | Do we need hundreds of classifiers to solve real world classification problems | Supervised Sequence Labelling with Recurrent Neural Networks | Speech recognition with deep recurrent neural networks | A study of the use of medicine lists in medicines reconciliation: please remember this, a list is just a list | Long short-term memory | An empirical exploration of recurrent network architectures | Assessing the accuracy of computerized medication histories | Ambulatory medication reconciliation: Using a collaborative approach to process improvement at an academic medical center | Efficient inference of Gaussian process modulated renewal processes with application to medical event data | Learning to diagnose with LSTM recurrent neural networks | Distributed representations of words and phrases and their compositionality | Measuring diagnoses: ICD code accuracy | Scikit-learn: Machine learning in Python | Development of a large-scale de-identified dna biobank to enable personalized medicine | Learning internal representations by error propagation | Toward a national framework for the secondary use of health data: an american medical informatics association white paper | On the stratification of multilabel data | Sequence to sequence learning with neural networks | Mining multi-label data | Medication errors: prescribing faults and prescription errors | Show and tell: A neural image caption generator | Achieving human parity in conversational speech recognition, 2016 | Medex: a medication information extraction system for clinical narratives",iclr,010
483.pdf.json,RECURRENT MIXTURE DENSITY NETWORK FOR SPATIOTEMPORAL VISUAL ATTENTION,"Attentional modeling and saliency prediction in images has been an active research topic in computer vision over the last decade. Interest in attentional models is primarily motivated by their ability to eliminate or down-weight pixels that are not important for the task at hand, as for example shown in prior work using visual attention for image recognition and caption generation (Sermanet et al., 2014; Xu et al., 2015; Mnih et al., 2014). Integrating visual attention in an image analysis model can potentially lead to improved overall accuracy, as the system can focus on the most salient regions in the photo without being disturbed by irrelevant information. Recently, we have witnessed a shift of trend from image saliency prediction (Borji & Itti, 2013) to the modeling of saliency in videos (Rudoy et al., 2013). Since human fixation patterns are strongly correlated over time (Coull, 2004), it appears critical to model the relations between saliency maps of consecutive frames. In this scenario, attention can be defined as a spatiotemporal volume, where each saliency map (one for each frame) depends on the frames at the previous times. The saliency map can be interpreted as a probability distribution over pixels and the actual fixation patterns can be generated by sampling from the the map. ∗This work was done when Loris Bazzani was at Dartmouth College. †Hugo Larochelle is now at Google Brain. Going from images to videos is not straightforward, since videos bring up many challenges. First of all, videos have an additional dimension (time), compared to images. This causes a dramatic growth in the number of pixels to be processed and poses a significantly higher computational cost for analysis. At the same time, there are strong redundancies present in such data, which implies that visual attention may be particularly beneficial for the video setting. For example, typically the objects or people in a video do not change significantly in appearance over time. Yet, for ","Multiple object recognition with visual attention | Learning attentional policies for object tracking and recognition in video with deep networks | Mixture density networks | State-of-the-art in visual attention modeling | Quantitative analysis of human-model agreement in visual saliency modeling: A comparative study | A deeper look at saliency: Feature contrast, semantics, and beyond | Transfer learning with deep networks for saliency prediction in natural video | Deep learning for saliency prediction in natural video | fmri studies of temporal attention: allocating attention within, or towards, time | Learning where to attend with deep architectures for image tracking | Semiautomatic visual-attention modeling and its application to video compression | Generating sequences with recurrent neural networks | Draw: A recurrent neural network for image generation | Spatio-temporal saliency detection using phase spectrum of quaternion fourier transform | Graph-based visual saliency | Long short-term memory | How many bits does it take for a stimulus to be salient | Salicon: Reducing the semantic gap in saliency prediction by adapting deep neural networks | End-to-end saliency mapping via probability distribution prediction | Saliency in crowd | Learning to predict where humans look | A benchmark of computational models of saliency to predict human fixations | Eye tracking assisted extraction of attentionally important objects from videos | Deep gaze I: boosting saliency prediction with feature maps trained on imagenet | Learning to combine foveal glimpses with a third-order Boltzmann machine | Visual saliency based on multiscale deep features | Predicting eye fixations using convolutional neural networks | Salient deconvolutional networks | Actions in context | Actions in the eye: Dynamic gaze datasets and learnt saliency models for visual recognition | Encoding based saliency detection for videos and images | Recurrent models of visual attention | Modeling the shape of the scene: A holistic representation of the spatial envelope | End-to-end convolutional network for saliency prediction | Learning video saliency from human gaze using candidate selection | Learning discriminative space–time action parts from weakly labelled videos | Attention for fine-grained categorization | Action recognition using visual attention | Deep inside convolutional networks: Visualising image classification models and saliency maps | Two-stream convolutional networks for action recognition in videos | Beyond frame-level cnn: Saliency-aware 3d cnn with lstm for video action recognition | Ucf101: A dataset of 101 human actions classes from videos in the wild | Unsupervised learning of video representations using lstms | Action from still image dataset and inverse optimal control to learn task specific visual scanpaths | Learning spatiotemporal features with 3d convolutional networks | Space-variant descriptor sampling for action recognition based on saliency and eye movements | Action recognition with improved trajectories | Show, attend and tell: Neural image caption generation with visual attention | Describing Videos by Exploiting Temporal Structure | Attentionnet: Aggregating weak directions for accurate object detection | An object-based visual attention model for robotic applications | Beyond short snippets: Deep networks for video classification | Visual attention detection in video sequences using spatiotemporal cues | Fixation bank: Learning to reweight fixation candidates | A Neural Autoregressive Approach to Attentionbased Recognition",iclr,010
484.pdf.json,,"A central factor in the application of machine learning to a given task is the inductive bias, i.e. the choice of hypotheses space from which learned functions are taken. The restriction posed by the inductive bias is necessary for practical learning, and reflects prior knowledge regarding the task at hand. Perhaps the most successful exemplar of inductive bias to date manifests itself in the use of convolutional networks (LeCun and Bengio (1995)) for computer vision tasks. These hypotheses spaces are delivering unprecedented visual recognition results (e.g. Krizhevsky et al. (2012); Szegedy et al. (2015); Simonyan and Zisserman (2014); He et al. (2015)), largely responsible for the resurgence of deep learning (LeCun et al. (2015)). Unfortunately, our formal understanding of the inductive bias behind convolutional networks is limited – the assumptions encoded into these models, which seem to form an excellent prior knowledge for imagery data, are for the most part a mystery. Existing works studying the inductive bias of deep networks (not necessarily convolutional) do so in the context of depth efficiency, essentially arguing that for a given amount of resources, more layers result in higher expressiveness. More precisely, depth efficiency refers to a situation where a function realized by a deep network of polynomial size, requires super-polynomial size in order to be realized (or approximated) by a shallower network. In recent years, a large body of research was devoted to proving existence of depth efficiency under different types of architectures (see for example Delalleau and Bengio (2011); Pascanu et al. (2013); Montufar et al. (2014); Telgarsky (2015); Eldan and Shamir (2015); Poggio et al. (2015); Mhaskar et al. (2016)). Nonetheless, despite the wide attention it is receiving, depth efficiency does not convey the complete story behind the inductive bias of deep networks. While it does suggest that depth brings forth functions that are otherwise unattainable,","Introduction to matrix analysis, volume 960 | Numerical operator calculus in higher dimensions | Multivariate regression and machine learning with sums of separable functions | The zero set of a polynomial | Simnets: A generalization of convolutional networks | Convolutional rectifier networks as generalized tensor decompositions | Deep simnets | On the expressive power of deep learning: A tensor analysis | Elements of information theory | Shallow vs. deep sum-product networks | The approximation of one matrix by another of lower rank | The power of depth for feedforward neural networks | Matrix Computations. Johns Hopkins Studies in the Mathematical Sciences | On the efficient evaluation of coalescence integrals in population balance models | Tensor Spaces and Numerical Tensor Calculus, volume 42 of Springer Series in Computational Mathematics | Image analysis using mathematical morphology | Multiresolution quantum chemistry in multiwavelet bases | Deep residual learning for image recognition | Caffe: Convolutional architecture for fast feature embedding | Adam: A method for stochastic optimization | Tensor Decompositions and Applications | ImageNet Classification with Deep Convolutional Neural Networks | Convolutional networks for images, speech, and time series | Learning real and boolean functions: When is deep better than shallow | On the number of linear regions of deep neural networks | Rectified linear units improve restricted boltzmann machines | On the number of inference regions of deep feed forward networks with piece-wise linear activations | I-theory on depth vs width: hierarchical function composition | Functional analysis. international series in pure and applied mathematics | Tensorial mixture models | Very deep convolutional networks for large-scale image recognition | Dropout: a simple way to prevent neural networks from overfitting | Going Deeper with Convolutions | Representation benefits of deep feedforward networks | It is not difficult to see that any pixel active in the original image is necessarily active in its closure. Moreover, pixels that are originally inactive yet are surrounded by active ones will also be turned on in the closure, hence the effect of “gap filling”. Finally, we note that the particular sequence of steps described above represents the most basic form of morphological closure",iclr,010
485.pdf.json,,"Deep neural networks have achieved state-of-the-art results in a variety of tasks. One possible reason for this remarkable success is that their hierarchical, layered structure may allow them to capture the geometric regularities of commonplace data. We support this hypothesis by exploring ways that networks can handle input data that lie on or near a low-dimenisonal manifold. In many problems, for example face recognition, data lie on or near manifolds that are of much lower dimension than the input space (Turk & Pentland, 1991; Basri & Jacobs, 2003; Lee et al., 2003), and that represent the intrinsic degrees of variation in the data. We study the ability of deep networks to represent manifold data. We show that the initial layers of networks can approximate data that lies on high-dimensional manifolds using piecewise linear functions, and economically output their coordinates embedded in a low-dimensional Euclidean space. In fact, each new linear segment approximating the manifold can be represented by a single additional hidden unit, leading to a representation of manifold data that in some cases is nearly optimal in the number of parameters of the system. Subsequent layers of a deep network could build upon these early layers, operating in lower dimensional spaces that more naturally represent the input data. We further show empirical results that suggest that training with stochastic gradient descent can find efficient representations akin to the one suggested in this paper. We first show how this embedding can be done efficiently for manifolds consisting of monotonic chains of linear segments. We then show how these primitives can be combined to form linear approximations for more complex manifolds. This process is illustrated in Figure 1. We further show that when the data lies sufficiently close to their linear approximation, the error in the embedding will be small. Our constructions will use a feed-forward network with rectified linear unit (RELU) activati","Do deep nets really need to be deep | On the complexity of neural network classifiers: A comparison between shallow and deep architectures | Why deep learning works: A manifold disentanglement perspective | Learning a similarity metric discriminatively, with application to face verification | Deep nets for local manifold learning | On the expressive power of deep learning: A tensor analysis | Approximation by superpositions of a sigmoidal function | Shallow vs. deep sum-product networks | Pattern classification | The power of depth for feedforward neural networks | Deep neural networks with random gaussian weights: A universal classification strategy | Nonlinear metric learning with deep convolutional neural network for face verification | Video-based face recognition using probabilistic appearance manifolds | Deep learning from temporal coherence in video | On the number of linear regions of deep neural networks | Diffusion maps, spectral clustering and eigenfunctions of fokker-planck operators | Dimensionality reduction by learning an invariant mapping | The manifold tangent classifier | Nonlinear dimensionality reduction by locally linear embedding | Learning a nonlinear embedding by preserving class neighbourhood structure | Provable approximation properties for deep neural networks | Representation benefits of deep feedforward networks | A global geometric framework for nonlinear dimensionality reduction | Eigenfaces for recognition | Deep learning via semi-supervised embedding | Deep metric learning for person re-identification | Principal manifolds and nonlinear dimensionality reduction via tangent space alignment",iclr,010
486.pdf.json,,"We consider the problem of classifying nodes (such as documents) in a graph (such as a citation network), where labels are only available for a small subset of nodes. This problem can be framed as graph-based semi-supervised learning, where label information is smoothed over the graph via some form of explicit graph-based regularization (Zhu et al., 2003; Zhou et al., 2004; Belkin et al., 2006; Weston et al., 2012), e.g. by using a graph Laplacian regularization term in the loss function: L = L0 + λLreg , with Lreg = ∑ i,j Aij‖f(Xi)− f(Xj)‖2 = f(X)>∆f(X) . (1) Here, L0 denotes the supervised loss w.r.t. the labeled part of the graph, f(·) can be a neural networklike differentiable function, λ is a weighing factor and X is a matrix of node feature vectors Xi. ∆ = D − A denotes the unnormalized graph Laplacian of an undirected graph G = (V, E) with N nodes vi ∈ V , edges (vi, vj) ∈ E , an adjacency matrix A ∈ RN×N (binary or weighted) and a degree matrix Dii = ∑ j Aij . The formulation of Eq. 1 relies on the assumption that connected nodes in the graph are likely to share the same label. This assumption, however, might restrict modeling capacity, as graph edges need not necessarily encode node similarity, but could contain additional information. In this work, we encode the graph structure directly using a neural network model f(X,A) and train on a supervised target L0 for all nodes with labels, thereby avoiding explicit graph-based regularization in the loss function. Conditioning f(·) on the adjacency matrix of the graph will allow the model to distribute gradient information from the supervised loss L0 and will enable it to learn representations of nodes both with and without labels. Our contributions are two-fold. Firstly, we introduce a simple and well-behaved layer-wise propagation rule for neural network models which operate directly on graphs and show how it can be motivated from a first-order approximation of spectral graph convolutions (Hammond et al., 2011)","TensorFlow: Large-scale machine learning on heterogeneous systems | Diffusion-convolutional neural networks. In Advances in neural information processing systems (NIPS), 2016 | Manifold regularization: A geometric framework for learning from labeled and unlabeled examples | On modularity clustering | Spectral networks and locally connected networks on graphs | Toward an architecture for never-ending language learning | Convolutional neural networks on graphs with fast localized spectral filtering. In Advances in neural information processing systems (NIPS), 2016 | The Weisfeiler-Lehman method and graph isomorphism testing | Convolutional networks on graphs for learning molecular fingerprints. In Advances in neural information processing systems | Understanding the difficulty of training deep feedforward neural networks | A new model for learning in graph domains | node2vec: Scalable feature learning for networks | Wavelets on graphs via spectral graph theory | Deep residual learning for image recognition | Transductive inference for text classification using support vector machines | Adam: A method for stochastic optimization | Gated graph sequence neural networks | Link-based classification | Visualizing data using t-sne | Distributed representations of words and phrases and their compositionality | Learning convolutional neural networks for graphs | Deepwalk: Online learning of social representations | The graph neural network model | Collective classification in network data | Dropout: a simple way to prevent neural networks from overfitting | Line: Large-scale information network embedding | A reduction of a graph to a canonical form and an algebra arising during this reduction | Deep learning via semisupervised embedding | Revisiting semi-supervised learning with graph embeddings | An information flow model for conflict and fission in small groups | Learning with local and global consistency | Semi-supervised learning using gaussian fields and harmonic functions",iclr,010
487.pdf.json,,"Deep neural networks (DNNs) have shown remarkable performance in extracting and representing high-level abstractions in complex data (Lecun et al. (2015)). DNNs rely on multiple layers of interconnected neurons and parameters to solve complex tasks, such as image recognition and classification (Krizhevsky et al. (2012)). While they have been proven very effective in said tasks, their hardware implementations still suffer from high memory and power consumption, due to the complexity and size of their models. Therefore, research efforts have been conducted towards more efficient implementations of DNNs (Han et al. (2016)). In the past few years, the parallel nature of DNNs has led to the use of graphical processing units (GPUs) to execute neural networks tasks (Han et al. (2015)). However, their large latency and power consumption have pushed researchers towards application-specific integrated circuits (ASICs) for hardware implementations (Cavigelli et al. (2015)). For instance, in (Han et al. (2016)), it was shown that a DNN implemented with customized hardware can accelerate the classification task by 189× and 13×, while saving 24,000× and 3,400× energy compared to CPU (Intel i7-5930k) and GPU (GeForce TITAN X), respectively. Convolutional layers in DNNs are used to extract high level abstractions and features of data. In such layers, the connectivity between neurons follows a pattern inspired by the organization of the animal visual cortex. It was shown that the computation in the visual cortex can mathematically be described by a convolution operation (LeCun et al. (1989)). Therefore, each neuron is only connected to a few neurons based on a pattern and a set of weights is shared among all neurons. In contrast, in a fully-connected layer, each neuron is connected to every neuron in the previous and next layers and each connection is associated with a weight. These layers are usually used to learn non-linear combinations of given data. Fig. 1 shows a two-layer full","Structured pruning of deep convolutional neural networks | VLSI implementation of deep neural network using integral stochastic computing | Subdominant dense clusters allow for simple learning and high computational performance in neural networks with discrete synapses | Origami: a convolutional network accelerator | Eyeriss: a spatial architecture for energy-efficient dataflow for convolutional neural networks | Eyeriss: An Energy-Efficient Reconfigurable Accelerator for Deep Convolutional Neural Networks | Training binary multilayer neural networks for image classification using expectation backpropagation | BinaryNet: Training deep neural networks with weights and activations constrained to +1 or -1 | BinaryConnect: Training deep neural networks with binary weights during propagations | Stochastic Computing Systems, pp. 37–172 | EIE: Efficient inference engine on compressed deep neural network | Deep compression: compressing deep neural network with pruning, trained quantization and huffman | computing’s energy problem (and what we can do about it) | Fixed-point feedforward deep neural network design using weights -1, 0, and 1 | Batch normalization: accelerating deep network training by reducing internal covariate | Learning multiple layers of features from tiny images | Imagenet classification with deep convolutional neural networks | Backpropagation applied to handwritten zip code recognition | URL http://yann | Gradient-based learning applied to document recognition | Generalizing pooling functions in convolutional neural networks: mixed | Neural networks with few multiplications | Fpga implementation of an image recognition system based on tiny neural networks and on-line reconfiguration | Rectified linear units improve restricted boltzmann machines | Reading digits in natural images with unsupervised feature learning | Parallel distributed processing: Explorations in the microstructure of cognition, vol. 1. chapter Learning Internal Representations by Error Propagation, pp. 318–362 | ISAAC: a convolutional neural network accelerator with in-situ analog arithmetic in crossbars | StochasticNet: forming deep neural networks via stochastic connectivity | Very deep convolutional networks for large-scale image recognition | Stochastic computing can improve upon digital spiking neural networks | Going deeper with convolutions | Deep learning using support vector machines | Learning structured sparsity in deep neural networks. CoRR, abs/1608.03665, 2016 | Visualizing and understanding convolutional networks",iclr,010
488.pdf.json,,"Adversarial examples are examples that are created by making small perturbations to the input designed to significantly increase the loss incurred by a machine learning model (Szegedy et al., 2014; Goodfellow et al., 2015). Several models, including state of the art convolutional neural networks, lack the ability to classify adversarial examples correctly, sometimes even when the adversarial perturbation is constrained to be so small that a human observer cannot perceive it. Adversarial training is the process of training a model to correctly classify both unmodified examples and adversarial examples. It improves not only robustness to adversarial examples, but also generalization performance for original examples. Adversarial training requires the use of labels when training models that use a supervised cost, because the label appears in the cost function that the adversarial perturbation is designed to maximize. Virtual adversarial training (Miyato et al., 2016) extends the idea of adversarial training to the semi-supervised regime and unlabeled examples. This is done by regularizing the model so that given an example, the model will produce the same output distribution as it produces on an adversarial perturbation of that example. Virtual adversarial training achieves good generalization performance for both supervised and semi-supervised learning tasks. Previous work has primarily applied adversarial and virtual adversarial training to image classification tasks. In this work, we extend these techniques to text classification tasks and sequence models. Adversarial perturbations typically consist of making small modifications to very many real-valued inputs. For text classification, the input is discrete, and usually represented as a series of highdimensional one-hot vectors. Because the set of high-dimensional one-hot vectors does not admit infinitesimal perturbation, we define the perturbation on continuous word embeddings instead of discrete word inputs. Tradi","Tensorflow: Large-scale machine learning on heterogeneous distributed systems | Manifold regularization: A geometric framework for learning from labeled and unlabeled examples | Neural probabilistic language models | Semi-supervised classification by low density separation | Large scale transductive svms | Semi-supervised sequence learning | Deep sparse rectifier neural networks | Explaining and harnessing adversarial examples | Framewise phoneme classification with bidirectional lstm and other neural network architectures | A fast learning algorithm for deep belief nets | What is the best multi-stage architecture for object recognition | Transductive inference for text classification using support vector machines | Effective use of word order for text categorization with convolutional neural networks | Semi-supervised convolutional neural networks for text categorization via region embedding | Convolutional neural networks for text categorization: Shallow word-level vs. deep character-level | Supervised and semi-supervised text categorization using LSTM for region embeddings | Convolutional neural networks for sentence classification | Adam: A method for stochastic optimization | Distributed representations of sentences and documents | Dbpedia–a large-scale, multilingual knowledge base extracted from wikipedia | Rcv1: A new benchmark collection for text categorization research | Auxiliary deep generative models | Learning word vectors for sentiment analysis | Hidden factors and hidden topics: understanding rating dimensions with review text | Recurrent neural network based language model | Distributed representations of words and phrases and their compositionality | Distributional smoothing with virtual adversarial training | Rectified linear units improve restricted boltzmann machines | Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales | Analyzing noise in autoencoders and deep networks | Creating artificial neural networks that generalize | Dropout: A simple way to prevent neural networks from overfitting | Sequence to sequence learning with neural networks | Intriguing properties of neural networks | Baselines and bigrams: Simple, good sentiment and topic classification | Adversarial perturbations of deep neural networks | Character-level convolutional networks for text classification | Self-adaptive hierarchical sentence model",iclr,010
489.pdf.json,FINE-GRAINED ANALYSIS OF SENTENCE EMBEDDINGS USING AUXILIARY PREDICTION TASKS,"While sentence embeddings or sentence representations play a central role in recent deep learning approaches to NLP, little is known about the information that is captured by different sentence embedding learning mechanisms. We propose a methodology facilitating fine-grained measurement of some of the information encoded in sentence embeddings, as well as performing fine-grained comparison of different sentence embedding methods. In sentence embeddings, sentences, which are variable-length sequences of discrete symbols, are encoded into fixed length continuous vectors that are then used for further prediction tasks. A simple and common approach is producing word-level vectors using, e.g., word2vec (Mikolov et al., 2013a;b), and summing or averaging the vectors of the words participating in the sentence. This continuous-bag-of-words (CBOW) approach disregards the word order in the sentence.1 Another approach is the encoder-decoder architecture, producing models also known as sequenceto-sequence models (Sutskever et al., 2014; Cho et al., 2014; Bahdanau et al., 2014, inter alia). In this architecture, an encoder network (e.g. an LSTM) is used to produce a vector representation of the sentence, which is then fed as input into a decoder network that uses it to perform some prediction task (e.g. recreate the sentence, or produce a translation of it). The encoder and decoder networks are trained jointly in order to perform the final task. 1We use the term CBOW to refer to a sentence representation that is composed of an average of the vectors of the words in the sentence, not to be confused with the training method by the same name which is used in the word2vec algorithm. Some systems (for example in machine translation) train the system end-to-end, and use the trained system for prediction (Bahdanau et al., 2014). Such systems do not generally care about the encoded vectors, which are used merely as intermediate values. However, another common case is to train an encoder","Neural machine translation by jointly learning to align and translate | Don’t count, predict! A systematic comparison of context-counting vs. context-predicting semantic vectors. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) | NLTK: the natural language toolkit | Learning phrase representations using rnn encoder-decoder for statistical machine translation | Torch7: A matlab-like environment for machine learning | Semi-supervised sequence learning | Adaptive subgradient methods for online learning and stochastic optimization | Distributed representations, simple recurrent networks, and grammatical structure | Deep sparse rectifier neural networks | Speech recognition with deep recurrent neural networks | Learning Distributed Representations of Sentences from Unlabelled Data | Improving neural networks by preventing co-adaptation of feature detectors | Long short-term memory | Representation of linguistic form and function in recurrent neural networks | Visualizing and understanding recurrent networks | Adam: A method for stochastic optimization | Skip-thought vectors | rnn: Recurrent library for torch | Linguistic regularities in sparse and explicit word representations | Improving distributional similarity with lessons learned from word embeddings | A hierarchical neural autoencoder for paragraphs and documents | Efficient estimation of word representations in vector space | Distributed representations of words and phrases and their compositionality | Rectified linear units improve restricted boltzmann machines | Bleu: a method for automatic evaluation of machine translation | Matching to remove bias in observational studies | Word ordering without syntax | Generating text with recurrent neural networks | Sequence to sequence learning with neural networks. In Advances in neural information processing | Lecture 6.5-rmsprop. COURSERA: Neural networks for machine | Adadelta: an adaptive learning rate method | 2015) in reversing the input sentences and clipping gradients. Word vectors are initialized to random values. We evaluate the encoder-decoder models using BLEU scores (Papineni et al., 2002), a popular machine translation evaluation metric that is also used to evaluate auto-encoder models (Li et al., 2015). BLEU score measures how well the original sentence is recreated, and can be thought of as a proxy",iclr,010
490.pdf.json,POINTER SENTINEL MIXTURE MODELS,"A major difficulty in language modeling is learning when to predict specific words from the immediate context. For instance, imagine a new person is introduced and two paragraphs later the context would allow one to very accurately predict this person’s name as the next word. For standard neural sequence models to predict this name, they would have to encode the name, store it for many time steps in their hidden state, and then decode it when appropriate. As the hidden state is limited in capacity and the optimization of such models suffer from the vanishing gradient problem, this is a lossy operation when performed over many timesteps. This is especially true for rare words. Models with soft attention or memory components have been proposed to help deal with this challenge, aiming to allow for the retrieval and use of relevant previous hidden states, in effect increasing hidden state capacity and providing a path for gradients not tied to timesteps. Even with attention, the standard softmax classifier that is being used in these models often struggles to correctly predict rare or previously unknown words. Pointer networks (Vinyals et al., 2015) provide one potential solution for rare and out of vocabulary (OoV) words as a pointer network uses attention to select an element from the input as output. This allows it to produce previously unseen input tokens. While pointer networks improve performance on rare words and long-term dependencies they are unable to select words that do not exist in the input. We introduce a mixture model, illustrated in Fig. 1, that combines the advantages of standard softmax classifiers with those of a pointer component for effective and efficient language modeling. Rather than relying on the RNN hidden state to decide when to use the pointer, as in the recent work of Gülçehre et al. (2016), we allow the pointer component itself to decide when to use the softmax vocabulary through a sentinel. The model improves the state of the art perpl",Fine-grained Analysis of Sentence Embeddings Using Auxiliary Prediction Tasks | Neural Machine Translation by Jointly Learning to Align and Translate | One Billion Word Benchmark for Measuring Progress in Statistical Language Modeling | Long Short-Term Memory-Networks for Machine | Language Modeling with Sum-Product Networks | A Theoretically Grounded Application of Dropout in Recurrent Neural Networks | Incorporating Copying Mechanism in Sequence-to-Sequence Learning | Long Short-Term Memory | Text Understanding with the Attention Sum Reader Network | Character-aware neural language models | Open Source Toolkit for Statistical Machine Translation | Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations | Ask me anything: Dynamic memory networks for natural language processing | Latent Predictor Networks for Code Generation | Building a Large Annotated Corpus of English: The Penn Treebank | Context dependent recurrent neural network language model | Recurrent neural network based language model | On the difficulty of training recurrent neural networks | A Maximum Entropy Approach to Adaptive Statistical Language Modeling | End-To-End Memory Networks | Dynamic Memory Networks for Visual and Textual Question Answering | Recurrent neural network regularization | Recurrent Highway Networks,iclr,010
493.pdf.json,TIGHTER BOUNDS LEAD TO IMPROVED CLASSIFIERS,"Classification aims at mapping inputs X ∈ X to one or several classes y ∈ Y . For instance, in object categorization, X will be the set of images depicting an object, usually represented by the RGB values of each of their pixels, and Y will be a set of object classes, such as “car” or “dog”. We shall assume we are given a training set comprised of N independent and identically distributed labeled pairs (Xi, yi). The standard approach to solve the problem is to define a parameterized class of functions p(y|X, θ) indexed by θ and to find the parameter θ∗ which minimizes the log-loss, i.e. θ∗ = arg min θ − 1 N ∑ i log p(yi|Xi, θ) (1.1) = arg min θ Llog(θ) , with Llog(θ) = − 1 N ∑ i log p(yi|Xi, θ) . (1.2) One justification for minimizing Llog(θ) is that θ∗ is the maximum likelihood estimator, i.e. the parameter which maximizes θ∗ = arg max θ p(D|θ) = arg max θ ∏ i p(yi|Xi, θ) . There is another reason to use Eq. 1.1. Indeed, the goal we are interested in is minimizing the classification error. If we assume that our classifiers are stochastic and outputs a class according to p(yi|Xi, θ), then the expected classification error is the probability of choosing the incorrect classa. This translates to L(θ) = 1 N ∑ i (1− p(yi|Xi, θ)) = 1− 1 N ∑ i p(yi|Xi, θ) . (1.3) aIn practice, we choose the class deterministically and output argmaxy p(y|Xi, θ). This is a highly nonconvex function of θ, which makes its minimization difficult. However, we have L(θ) = 1− 1 N ∑ i p(yi|Xi, θ) ≤ 1− 1 N ∑ i 1 K (1 + log p(yi|Xi, θ) + logK) = (K − 1− logK) K + Llog(θ) K , where K = |Y| is the number of classes (assumed finite), using the fact that, for every nonnegative t, we have t ≥ 1 + log t. Thus, minimizing Llog(θ) is equivalent to minimizing an upper bound of L(θ). Further, this bound is tight when p(yi|Xi, θ) = 1K for all yi. As a model with randomly initialized parameters will assign probabilities close to 1/K to each class, it makes sense to minimize Llog(θ) rather than L(θ) early on in t",Considering cost asymmetry in learning classifiers | Two high stakes challenges in machine learning. http://videolectures | Counterfactual reasoning and learning systems: The example of computational advertising | A parallel mixture of svms for very large scale problems | Trading convexity for scalability | Nonconvex online support vector machines | Batch and online learning algorithms for nonconvex neyman-pearson classification | A stochastic gradient method with an exponential convergence rate for finite training sets | Prodding the roc curve: Constrained optimization of classifier performance | Optimizing f-measures by cost-sensitive classification | Robust support vector machine training via convex outlier ablation | The concave-convex procedure,iclr,010
494.pdf.json,HOLSTEP: A MACHINE LEARNING DATASET FOR HIGHER-ORDER LOGIC THEOREM PROVING,"As the usability of interactive theorem proving (ITP) systems (Harrison et al., 2014) grows, its use becomes a more common way of establishing the correctness of software as well as mathematical proofs. Today, ITPs are used for software certification projects ranging from compilers (Leroy, 2009) and operating system components (Chen et al., 2016; Klein et al., 2014), to establishing the absolute correctness of large proofs in mathematics such as the Kepler conjecture (Hales et al., 2015) and the Feit-Thomson Theorem (Gonthier et al., 2013). For results of such significance to be possible, the theorem libraries of these ITPs must contain all necessary basic mathematical properties, accompanied with formal proofs. This means that the size of many ITP libraries can be measured in dozens of thousands of theorems (Grabowski et al., 2010; Blanchette et al., 2015) and billions of individual proof steps. While the general direction of the proofs is specified by humans (by providing the goal to prove, specifying intermediate steps, or applying certain automated tactics), the majority of such proof steps are actually found by automated reasoning-based proof search (Kaliszyk & Urban, 2015b), with very little application of machine learning techniques so far. At the same time, fast progress has been unfolding in machine learning applied to tasks that involve logical inference, such as natural language question answering (Sukhbaatar et al., 2015), knowledge base completion (Socher et al., 2013a), automated translation (Wu et al., 2016), and premise selection in the context of theorem proving (Alemi et al., 2016). Deep learning in particular has proven to be a powerful tool for embedding semantic meaning and logical relationships into geometric spaces, specifically via models such as convolutional neural networks, recurrent neural networks, and tree-recursive neural networks. These advances strongly suggest that deep learning may have become mature enough to yield significant adv","TensorFlow: Large-scale machine learning on heterogeneous systems | Premise selection for mathematics by corpus analysis and kernel methods | DeepMath – Deep sequence models for premise selection | What’s in a theorem name | Term rewriting and all that | Hammering towards QED | Mining the Archive of Formal Proofs | Machine learning for first-order theorem proving - learning to select a good heuristic | Using crash Hoare logic for certifying the FSCQ file system | A formulation of the simple theory of types | ImageNet: A Large-Scale Hierarchical Image Database | The Use of Data-Mining for the Automatic Formation of Tactics | Internal guidance for Satallax | A machine-checked proof of the odd order theorem | Edinburgh LCF, volume | Mizar in a nutshell | A revision of the proof of the Kepler Conjecture | A formal proof of the Kepler conjecture | HOL Light: An overview | The HOL Light theory of Euclidean space | History of interactive theorem proving | The principal type-scheme of an object in combinatory logic | Long short-term memory | Sine qua non for large theory reasoning. In Nikolaj Bjørner and Viorica Sofronie-Stokkermans (eds.), CADE-23, volume 6803 | First-order proof tactics in higher-order logic theorem provers | The OpenTheory standard theory library | Scalable LCF-style proof translation | Learning-assisted automated reasoning with Flyspeck | FEMaLeCoP: Fairly efficient machine learning connection prover | Learning-assisted theorem proving with millions of lemmas | Learning to parse on aligned corpora | Comprehensive formal verification of an OS microkernel | First-order theorem proving and Vampire | MaLeS: A framework for automatic tuning of automated theorem provers | Formal verification of a realistic compiler | Importing HOL into Isabelle/HOL | A generic tableau prover and its integration with Isabelle | Mastering the game of go with deep neural networks and tree | Reasoning with neural tensor networks for knowledge base completion | Recursive deep models for semantic compositionality over a sentiment treebank | End-to-end memory networks | The CADE ATP system competition - CASC | MaLeCoP: Machine learning connection prover",iclr,010
495.pdf.json,,"Neural networks have drawn significant interest from the machine learning community, especially due to their recent empirical successes (see the surveys (Bengio, 2009)). Neural networks are used to build state-of-art systems in various applications such as image recognition, speech recognition, natural language process and others (see, Krizhevsky et al. 2012; Goodfellow et al. 2013; Wan et al. 2013, for example). The result that neural networks are universal approximators is one of the theoretical results most frequently cited to justify the use of neural networks in these applications. Numerous results have shown the universal approximation property of neural networks in approximations of different function classes, (see, e.g., Cybenko 1989; Hornik et al. 1989; Funahashi 1989; Hornik 1991; Chui & Li 1992; Barron 1993; Poggio et al. 2015). All these results and many others provide upper bounds on the network size and assert that small approximation error can be achieved if the network size is sufficiently large. More recently, there has been much interest in understanding the approximation capabilities of deep versus shallow networks. Delalleau & Bengio (2011) have shown that there exist deep sum-product networks which cannot be approximated by shallow sum-product networks unless they use an exponentially larger amount of units or neurons. Montufar et al. (2014) have shown that the number of linear region increases exponentially with the number of layers in the neural network. Telgarsky (2016) has established such a result for neural networks, which is the subject of this paper. Eldan & Shamir (2015) have shown that, to approximate a specific function, a two-layer network requires an exponential number of neurons in the input dimension, while a three-layer network requires a polynomial number of neurons. These recent papers demonstrate the power of deep networks by showing that depth can lead to an exponential reduction in the number of neurons required, for specifi","Learning polynomials with neural networks | Universal approximation bounds for superpositions of a sigmoidal function | Learning deep architectures for ai | Approximation by ridge functions and neural networks with one hidden layer | Approximation by superpositions of a sigmoidal function | The power of approximating: a comparison of activation functions | Shallow vs. deep sum-product networks | The power of depth for feedforward neural networks | On the approximate realization of continuous mappings by neural networks | Numerical methods for special functions | Approximation capabilities of multilayer feedforward networks | Multilayer feedforward networks are universal approximators | Imagenet classification with deep convolutional neural networks | On the number of linear regions of deep neural networks | Notes on hierarchical splines, dclns and i-theory | Benefits of depth in neural networks | Regularization of neural networks using dropconnect | Error bounds for approximations with deep ReLU networks",iclr,010
496.pdf.json,HIERARCHICAL MULTISCALE RECURRENT NEURAL NETWORKS,"One of the key principles of learning in deep neural networks as well as in the human brain is to obtain a hierarchical representation with increasing levels of abstraction (Bengio, 2009; LeCun et al., 2015; Schmidhuber, 2015). A stack of representation layers, learned from the data in a way to optimize the target task, make deep neural networks entertain advantages such as generalization to unseen examples (Hoffman et al., 2013), sharing learned knowledge among multiple tasks, and discovering disentangling factors of variation (Kingma & Welling, 2013). The remarkable recent successes of the deep convolutional neural networks are particularly based on this ability to learn hierarchical representation for spatial data (Krizhevsky et al., 2012). For modelling temporal data, the recent resurgence of recurrent neural networks (RNN) has led to remarkable advances (Mikolov et al., 2010; Graves, 2013; Cho et al., 2014; Sutskever et al., 2014; Vinyals et al., 2015). However, unlike the spatial data, learning both hierarchical and temporal representation has been among the long-standing challenges of RNNs in spite of the fact that hierarchical multiscale structures naturally exist in many temporal data (Schmidhuber, 1991; Mozer, 1993; El Hihi & Bengio, 1995; Lin et al., 1996; Koutník et al., 2014). A promising approach to model such hierarchical and temporal representation is the multiscale RNNs (Schmidhuber, 1992; El Hihi & Bengio, 1995; Koutník et al., 2014). Based on the observation that high-level abstraction changes slowly with temporal coherency while low-level abstraction has quickly changing features sensitive to the precise local timing (El Hihi & Bengio, 1995), the multiscale RNNs group hidden units into multiple modules of different timescales. In addition to the fact that the architecture fits naturally to the latent hierarchical structures in many temporal data, the multiscale approach provides the following advantages that resolve some inherent problems of stan","End-to-end attention-based large vocabulary speech recognition | Estimating or propagating gradients through stochastic neurons for conditional computation | Listen, attend and spell: A neural network for large vocabulary conversational speech recognition | Learning phrase representations using RNN encoder-decoder for statistical machine translation | Gated feedback recurrent neural networks | A character-level decoder without explicit segmentation for neural machine translation. Association for Computational Linguistics (ACL), 2016 | Recurrent batch normalization | Binarized neural networks: Training deep neural networks with weights and activations constrained to+ 1 or-1 | Hierarchical recurrent neural networks for long-term dependencies | Sequence labelling in structured domains with hierarchical recurrent neural networks | Generating sequences with recurrent neural networks | Neural networks for machine learning | Long short-term memory | One-shot adaptation of supervised deep convolutional models | Deep networks with stochastic depth | The human knowledge compression contest | Grid long short-term memory | Convolutional neural networks for sentence classification | Character-aware neural language models | Adam: A method for stochastic optimization | Auto-encoding variational bayes | Segmental recurrent neural networks | A clockwork rnn | Imagenet classification with deep convolutional neural networks | Regularizing rnns by stabilizing activations | Zoneout: Regularizing rnns by randomly preserving hidden activations | Learning long-term dependencies in narx recurrent neural networks | Character-based neural machine translation | Iam-ondb-an on-line english sentence database acquired from handwritten text on a whiteboard | Adaptive weighing of context models for lossless data compression | Large text compression benchmark | Building a large annotated corpus of english: The penn treebank | Recurrent neural network based language model | Subword language modeling with neural networks | Neural variational inference and learning in belief networks | Induction of multiscale temporal structure | Rectified linear units improve restricted boltzmann machines | Regularization and nonlinearities for neural language models: when are they needed | On the difficulty of training recurrent neural networks | Recurrent memory array structures | Surprisal-driven feedback in recurrent networks | Neural sequence chunkers | Learning complex, extended sequences using the principle of history compression | Deep learning in neural networks: An overview | A hierarchical recurrent encoder-decoder for generative context-aware query suggestion | Dropout: a simple way to prevent neural networks from overfitting | Generating text with recurrent neural networks | Sequence to sequence learning with neural networks | Theano: A python framework for fast computation of mathematical expressions | Strategic attentive writer for learning macro-actions | Show and tell: A neural image caption generator | Simple statistical gradient-following algorithms for connectionist reinforcement learning | On multiplicative integration with recurrent neural networks | Architectural complexity measures of recurrent neural networks | Recurrent highway networks",iclr,010
498.pdf.json,DROPOUT WITH EXPECTATION-LINEAR REGULARIZATION,"Deep neural networks (DNNs, e.g., LeCun et al., 2015; Schmidhuber, 2015), if trained properly, have been demonstrated to significantly improve the benchmark performances in a wide range of application domains. As neural networks go deeper and deeper, naturally, its model complexity also increases quickly, hence the pressing need to reduce overfitting in training DNNs. A number of techniques have emerged over the years to address this challenge, among which dropout (Hinton et al., 2012; Srivastava, 2013) has stood out for its simplicity and effectiveness. In a nutshell, dropout randomly “drops” neural units during training as a means to prevent feature co-adaptation—a sign of overfitting (Hinton et al., 2012). Simple as it appears to be, dropout has led to several record-breaking performances (Hinton et al., 2012; Ma & Hovy, 2016), and thus spawned a lot of recent interests in analyzing and justifying dropout from the theoretical perspective, and also in further improving dropout from the algorithmic and practical perspective. In their pioneering work, Hinton et al. (2012) and Srivastava et al. (2014) interpreted dropout as an extreme form of model combination (aka. model ensemble) with extensive parameter/weight sharing, and they proposed to learn the combination through minimizing an appropriate expected loss. Interestingly, they also pointed out that for a single logistic neural unit, the output of dropout is in fact the geometric mean of the outputs of the model ensemble with shared parameters. Subsequently, many theoretical justifications of dropout have been explored, and we can only mention a few here due to space limits. Building on the weight sharing perspective, Baldi & Sadowski (2013; 2014) analyzed the ensemble averaging property of dropout in deep non-linear logistic networks, and supported the view that dropout is equivalent to applying stochastic gradient descent on some regularized loss function. Wager et al. (2013) treated dropout as an adaptive regu","On the accuracy of selfnormalized log-linear models | The dropout learning algorithm | Understanding dropout | Differential sparse coding | Dropout distillation | Dropout training for support vector machines | Dropout as a bayesian approximation: Insights and applications | A theoretically grounded application of dropout in recurrent neural networks | Dropout rademacher complexity of deep neural networks | On the inductive bias of dropout | Fundamental differences between dropout and weight decay in deep networks | A practical guide to training restricted boltzmann machines. Momentum | Distilling the knowledge in a neural network | Improving neural networks by preventing co-adaptation of feature detectors | To drop or not to drop: Robustness, consistency and differential privacy properties of dropout | Variational dropout and the local reparameterization trick | Learning multiple layers of features from tiny images | Gradient-based learning applied to document recognition | End-to-end sequence labeling via bi-directional LSTM-CNNs-CRF | Deep learning in neural networks: An overview | Striving for simplicity: The all convolutional net | Maximum-margin matrix factorization | Improving neural networks with dropout | Dropout: A simple way to prevent neural networks from overfitting | Regression shrinkage and selection via the lasso | On the stability of inverse problems | Dropout training as adaptive regularization | Altitude training: Strong bounds for single-layer dropout | Fast dropout training | We guess one of the possible reasons is that we used different library for implementation.) | EFFECT OF EXPECTATION-LINEARIZATION RATE λ Table 4 illustrates the detailed results of the experiments on the effect of λ. For MNIST, it lists the error rates under different λ values for six different network architectures. For two datasets of CIFAR",iclr,010
499.pdf.json,,"In this work, we consider an approach of using a small network (called a “hypernetwork"") to generate the weights for a larger network (called a main network). The behavior of the main network is the same as with any usual neural network: it learns to map some raw inputs to their desired targets; whereas the hypernetwork takes a set of inputs that contain information about the structure of the weights and generates the weights for that layer. The focus of this work is to use hypernetworks to generate weights for recurrent networks (RNN). In this case, the weights Wt for the main RNN at step t is a function of the input to the hidden state of the main RNN at the previous step ht−1 and the input at the current time step xt. This weight-generation scheme allows approximate weight-sharing across layers of the main RNN. We perform experiments to investigate the behaviors of hypernetworks in a range of contexts and find that hypernetworks mix well with other techniques such as batch normalization and layer normalization. Our main result is that hypernetworks can generate non-shared weights for LSTM that work better than the standard version of LSTM (Hochreiter & Schmidhuber, 1997). On language modelling tasks with character Penn Treebank, Hutter Prize Wikipedia datasets, hypernetworks for LSTM achieve near state-of-the-art results. On a handwriting generation task with IAM handwriting dataset, hypernetworks for LSTM achieves good quantitative and qualitative results. On machine translation, hypernetworks for LSTM also obtain state-of-the-art performance on the WMT’14 en→fr benchmark.",Learning to learn by gradient descent by gradient descent | Learning feed-forward one-shot learners | Mixture density networks | Gated feedback recurrent neural networks | Hierarchical multiscale recurrent neural networks | Dynamic filter networks | Predicting Parameters in Deep Learning | Convolution by evolution: Differentiable pattern producing networks | Evolving modular fast-weight networks for control | First-order versus second-order single-layer recurrent neural networks | Generating sequences with recurrent neural networks | Orthogonal RNNs and long-memory tasks | Long short-term memory | URL http://prize | Decoupled Neural Interfaces using Synthetic Gradients | Grid long short-term memory | Adam: A method for stochastic optimization | Evolving neural networks in compressed weight space | Multiplicative LSTM for sequence modelling | Zoneout: Regularizing RNNs by randomly preserving hidden activations | IAM-OnDB - an on-line English sentence database acquired from handwritten text on a whiteboard | Building a large annotated corpus of english: The penn treebank | Subword language modeling with neural networks | ACDC: A Structured Efficient Linear Layer | Regularizing recurrent networks-on injected noise and normbased methods | Recurrent memory array structures | Surprisal-driven feedback in recurrent networks | Learning to control fast-weight memories: An alternative to dynamic recurrent networks | A ‘self-referential’ weight matrix | Recurrent dropout without memory loss | A hypercube-based encoding for evolving large-scale neural networks | Generating text with recurrent neural networks | On multiplicative integration with recurrent neural networks | Deep Fried Convnets | Deep recurrent models with fastforward connections for neural machine translation | Recurrent highway networks,iclr,010
502.pdf.json,,"Learning to communicate with humans is a crucial ability for intelligent agents. Among the primary forms of communication between humans is natural language dialogue. As such, building systems that can naturally and meaningfully converse with humans has been a central goal of artificial intelligence since the formulation of the Turing test (Turing, 1950). Research on one type of such systems, sometimes referred to as non-task-oriented dialogue systems, goes back to the mid-60s with Weizenbaum’s famous program ELIZA: a rule-based system mimicking a Rogerian psychotherapist by persistently either rephrasing statements or asking questions (Weizenbaum, 1966). Recently, there has been a surge of interest in the research community towards building large-scale non-task-oriented dialogue systems using neural networks (Sordoni et al., 2015b; Shang et al., 2015; Vinyals & Le, 2015; Serban et al., 2016a; Li et al., 2015). These models are trained in an end-to-end manner to optimize a single objective, usually the likelihood of generating the responses from a fixed corpus. Such models have already had a substantial impact in industry, including Google’s Smart Reply system (Kannan et al., 2016), and Microsoft’s Xiaoice chatbot (Markoff & Mozur, 2015), which has over 20 million users. More recently, Amazon has announced the Alexa Prize Challenge: a research competition with the goal of developing a natural and engaging chatbot system (Farber, 2016). One of the challenges when developing such systems is to have a good way of measuring progress, in this case the performance of the chatbot. The Turing test provides one solution to the evaluation of dialogue systems, but there are limitations with its original formulation. The test requires live human interactions, which is expensive and difficult to scale up. Furthermore, the test requires carefully designing the instructions to the human interlocutors, in order to balance their behaviour and expectations so that different systems m","Semi-formal evaluation of conversational characters | Meteor: An automatic metric for mt evaluation with improved correlation with human judgments. In Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation | Learning long-term dependencies with gradient descent is difficult | Generating sentences from a continuous space | Findings of the 2011 workshop on statistical machine translation | A systematic comparison of smoothing techniques for sentence-level bleu | Weighted kappa: Nominal scale agreement provision for scaled disagreement or partial credit | Recurrent batch normalization | Tweet2vec: Character-based distributed representations for social media | Censoring representations with an adversary | Hierarchical recurrent neural networks for long-term dependencies | Amazon’s ’Alexa Prize | A new algorithm for data compression | deltableu: A discriminative metric for generation tasks with intrinsically diverse targets | Reval: A simple and effective machine translation evaluation metric based on recurrent neural networks | Untersuchungen zu dynamischen neuronalen netzen | Long short-term memory | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Smart reply: Automated response suggestion for email | Adam: A method for stochastic optimization | Skip-thought vectors | A diversity-promoting objective function for neural conversation models | A persona-based neural conversation model | Deep reinforcement learning for dialogue generation | Rouge: A package for automatic evaluation of summaries. In Text summarization branches out | How not to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation | The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems | Results of the wmt14 metrics shared task | Mozur. For sympathetic ear, more chinese turn to smartphone program | Memo: towards automatic usability evaluation of spoken dialogue services by user error simulations | Bleu: a method for automatic evaluation of machine translation | Principal components analysis | Data-driven response generation in social media | Neural machine translation of rare words with subword units | Building end-to-end dialogue systems using generative hierarchical neural network models | A hierarchical latent variable encoder-decoder model for generating dialogues | Neural responding machine for short-text conversation | A hierarchical recurrent encoder-decoder for generative context-aware query suggestion | A neural network approach to context-sensitive generation of conversational responses | Results of the wmt15 metrics shared task | Theano: A python framework for fast computation of mathematical expressions | Computing machinery and intelligence | A neural conversational model | Paradise: A framework for evaluating spoken dialogue agents | ELIZAa computer program for the study of natural language communication between man and machine | Strategy and policy learning for non-task-oriented conversational systems | r̂)) βn is a weighting that is usually uniform, and b(·) is the brevity penalty. The most commonly used version of BLEU assigns N = 4. Modern versions of BLEU also use sentence-level smoothing, as the geometric mean often results in scores of 0 if there is no 4-gram overlap | 2016) data In order to ensure that the correlations between word-overlap metrics and human judgements were comparable across datasets, we standardized the processing of the evaluation dataset from Liu et al | <first speaker>’, ‘<second speaker>’, or ‘<third speaker>’) at the beginning of each utterance. This is an artifact left-over by the processing used as input to the hierarchical recurrent encoder-decoder (HRED) model (Serban et al., 2016a)",iclr,010
503.pdf.json,,"Representation learning methods have received a lot of attention by researchers and practitioners because of its successful application to complex problems in areas such as computer vision, speech recognition and text processing (LeCun et al., 2015). Most of these efforts have concentrated on data involving one type of information (images, text, speech, etc.), despite data being naturally multimodal. Multimodality refers to the fact that the same real-world concept can be described by different views or data types. Collaborative encyclopedias (such as Wikipedia) describe a famous person through a mixture of text, images and, in some cases, audio. Users from social networks comment events like concerts or sport games with small phrases and multimedia attachments (images/videos/audios). Medical records are represented by a collection of images, sound, text and signals, among others. The increasing availability of multimodal databases from different sources has motivated the development of automatic analysis techniques to exploit the potential of these data as a source of knowledge in the form of patterns and structures that reveal complex relationships (Bhatt & Kankanhalli, 2011; Atrey et al., 2010). In recent years, multimodal tasks have acquired attention by the representation learning community. Strategies for visual question answering (Antol et al., 2015), or image captioning (Vinyals et al., 2015; Xu et al., 2015; Johnson et al., 2015) have developed interesting ways of combining different representation learning architectures. Most of these models are focused on mapping from one modality to another or solving an auxiliary task to create a common representation with the information of all modalities. In this work, we design a novel module that combines multiple sources of information, which is optimized with respect to the end goal objective function. Our proposed module is based on the idea of gates for selecting which parts of the input are more likely to contr","Zero-Shot Learning with Structured Embeddings | Evaluating folksonomy information sources for genre prediction | Vqa: Visual question answering | Multimodal fusion for multimedia analysis: a survey | A neural probabilistic language model | Random search for hyper-parameter optimization | Multimedia data mining: state of the art and challenges | The importance of encoding versus training with sparse coding and vector quantization | A tutorial survey of architectures, algorithms, and applications for deep learning | Constructing hierarchical image-tags bimodal representations for word tags alternative choice | Multimodal PLSA for Movie Genre Classification | Improving word representations via global context and multiple word prototypes | A Film Classifier Based on Low-level Visual Features | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Movie posters classification into genres based on low-level features | Automatic Movie Posters Classification into Genres | Adaptive mixtures of local experts | Densecap: Fully convolutional localization networks for dense captioning | Learning to recognize webpage genres | Deep learning to hash with multiple representations | Learning Image Embeddings using Convolutional Neural Networks for Improved Multi-Modal Semantics | Adam: A method for stochastic optimization | Multimodal neural language models | Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models | Deep Learning: Methods and Applications | Learning multimodal neural network with ranking examples | An extensive experimental comparison of methods for multi-label learning | A movie genre prediction based on Multivariate Bernoulli model and genre correlations | Lenskiy. A multinomial probabilistic model for movie genre predictions | Explain images with multimodal recurrent neural networks | Efficient estimation of word representations in vector space | Distributed representations of words and phrases and their compositionality | Multimodal Deep Learning | Animated movie genre detection using symbolic fusion of text and image descriptors | Unsupervised multimodal feature learning for semantic image segmentation | Movie Classification Using k-Means and Hierarchical Clustering | Very deep convolutional networks for large-scale image recognition | Zero-Shot Learning Through Cross-Modal Transfer | Grounded Compositional Semantics for Finding and Describing Images with Sentences | Multimodal Learning with Deep Boltzmann Machines | Deep learning-based feature representation for AD/MCI classification | Challenge Huawei challenge: Fusing multimodal features with deep neural networks for Mobile Video Annotation | Blocks and fuel: Frameworks for deep learning | Show and tell: A neural image caption generator | Online multimodal deep similarity learning with application to image retrieval | Show, attend and tell: Neural image caption generation with visual attention | Twenty years of mixture of experts | Topic Modeling of Multimodal Data: an Autoregressive Approach",iclr,010
504.pdf.json,,"Social learning, such as imitation, plays a critical role in allowing humans and animals to quickly acquire complex skills in the real world. Humans can use this weak form of supervision to acquire behaviors from very small numbers of demonstrations, in sharp contrast to deep reinforcement learning (RL) methods, which typically require extensive training data. In this work, we make use of two ideas to develop a scaleable and efficient imitation learning method: first, imitation makes use of extensive prior knowledge to quickly glean the “gist” of a new task from even a small number of demonstrations; second, imitation involves both observation and trial-and-error learning (RL). Building on these ideas, we propose a reward learning method for understanding the intent of a user demonstration through the use of pre-trained visual features, which provide the “prior knowledge” for efficient imitation. Our algorithm aims to discover not only the high-level goal of a task, but also the implicit sub-goals and steps that comprise more complex behaviors. Extracting such sub-goals can allow the agent to make maximal use of the information contained in the demonstration. Once the reward function has been extracted, the agent can use its own experience at the task to determine the physical structure of the behavior, even when the reward is provided by an agent with a substantially different embodiment (e.g. a human providing a demonstration for a robot). ∗Work done as part of the Google Brain Residency program (g.co/brainresidency). To our knowledge, our method is the first reward learning technique that learns generalizable visionbased reward functions for complex robotic manipulation skills from only a few demonstrations provided directly by a human. Although prior methods have demonstrated reward learning with vision for real-world robotic tasks, they have either required kinesthetic demonstrations with robot state for reward learning (Finn et al., 2015), or else required low","Apprenticeship learning via inverse reinforcement learning | Relative entropy inverse reinforcement learning | Path integral guided policy search | ImageNet: A Large-Scale Hierarchical Image Database | Perceptual reward functions | Deep spatial autoencoders for visuomotor learning | A connection between generative adversarial networks, inverse reinforcement learning, and energy-based models | Guided cost learning: Deep inverse optimal control via policy optimization | Efficient image and video co-localization with frank-wolfe algorithm | Inverse reinforcement learning with pi | Autonomous reinforcement learning on raw visual input data in a real world application | Algorithms for inverse reinforcement learning | Relative entropy policy search | Bayesian inverse reinforcement | Maximum margin planning | Rethinking the inception architecture for computer | A generalized path integral control approach to reinforcement learning | Embed to control: A locally linear latent dynamics model for control from raw images | Watch This: Scalable Cost-Function Learning for Path Planning in Urban Environments | A formal study of shot boundary detection | Maximum entropy inverse reinforcement learning | DKL(π(ut|xt)‖π̄(ut|xt)) ≤ for a step size epsilon. Further details and a complete derivation are provided in prior work Theodorou et al",iclr,010
507.pdf.json,,"High quality datasets for evaluating word and phrase representations are essential for building better models that can advance natural language understanding. Various researchers have developed and shared datasets for syntactic and semantic intrinsic evaluation. The majority of these datasets are based on word similarity (e.g., Finkelstein et al. (2001); Bruni et al. (2012); Hill et al. (2016)) and analogy tasks (e.g., Mikolov et al. (2013a;b)). While there has been a significant amount of work in this area which has resulted in a large number of publicly available datasets, many researchers have recently identified problems with existing datasets and called for further research on better evaluation methods (Faruqui et al., 2016; Gladkova et al., 2016; Hill et al., 2016; Avraham & Goldberg, 2016; Linzen, 2016; Batchkarov et al., 2016). A significant problem with word similarity tasks is that human bias and subjectivity result in low inter-annotator agreement and, consequently, human performance that is lower than automatic methods (Hill et al., 2016). Another issue is low or no correlation between intrinsic and extrinsic evaluation metrics (Chiu et al., 2016; Schnabel et al., 2015). Recently, Camacho-Collados & Navigli (2016) proposed the outlier detection task as an intrinsic evaluation method that improved upon some of the shortcomings of word similarity tasks. The task builds upon the “word intrusion” task initially described in Chang et al. (2009): given a set of words, the goal is to identify the word that does not belong in the set. However, like the vast majority of existing datasets, this dataset requires manual annotations that suffer from human subjectivity and bias, and it is not multilingual. Inspired by Camacho-Collados & Navigli (2016), we have created a new outlier detection dataset that can be used for intrinsic evaluation of semantic models. The main advantage of our approach is that it is fully automated using Wikidata and Wikipedia, and it is also",Improving reliability of word similarity evaluation by redesigning annotation task and performance measure | A critique of word similarity as a method for evaluating distributional semantic models | Distributional semantics in technicolor | Find the word that does not belong: A framework for an intrinsic evaluation of word vector representations | Reading tea leaves: How humans interpret topic models | Intrinsic evaluation of word vectors fails to predict extrinsic performance | Problems with evaluation of word embeddings using word similarity tasks | Placing search in context: The concept revisited | Intrinsic evaluations of word embeddings: What can we do better | Simlex-999: Evaluating semantic models with (genuine) similarity estimation | Europarl: A parallel corpus for statistical machine translation | Issues in evaluating semantic spaces using word analogies | Efficient estimation of word representations in vector space | Linguistic regularities in continuous space word representations | Glove: Global vectors for word representation | Corpus portal for search in monolingual corpora | Evaluation methods for unsupervised word embeddings | A cross-lingual dictionary for english wikipedia,iclr,010
508.pdf.json,SHIFT AGGREGATE EXTRACT NETWORKS,"Many different problems in various fields of science require the classification of structured data, i.e. collections of objects bond together by some kind of relation. A natural way to represent such structures is through graphs, which are able to encode both the individual objects composing the collection (as vertices) and the relationships between them (as edges). A number of approaches to the graph classification problem has been studied in graph kernel and neural network literature. Graph kernels decompose input graphs in substructures such as shortest paths (Borgwardt & Kriegel, 2005), graphlets (Shervashidze et al., 2009) or neighborhood subgraph pairs (Costa & De Grave, 2010). The similarity between two graphs is then computed by comparing the respective sets of parts. Methods based on recursive neural networks unfold a neural network over input graphs and learn vector representations of their nodes employing backpropagation though structure (Goller & Kuchler, 1996). Recursive neural networks have been successfully applied to domains such as natural language (Socher et al., 2011) and biology (Vullo & Frasconi, 2004; Baldi & Pollastri, 2003). An advantage of recursive neural networks over graph kernels, is that the vector representations of the input graphs are learnt rather than handcrafted. Learning on social network data can be considerably hard due to their peculiar structure: as opposed to chemical compounds and parse trees, the structure of social network graphs is highly irregular. Indeed in social networks it is common to have nodes in the same graph whose degree differs by orders of magnitude. This poses a significant challenge for the substructure matching approach used by some graph kernels as the variability in connectivity generates a large number of unique patterns leading to diagonally dominant kernel matrices. We propose Shift Aggregate Extract Networks (SAEN), a neural network architecture for learning representations of input graphs. SAEN dec",The principled design of large-scale recursive neural network architectures– dag-rnns and the protein structure prediction problem | Shortest-path kernels on graphs | Fast neighborhood subgraph pairwise distance kernel | Learning task-dependent distributed representations by backpropagation through structure | Convolution kernels on discrete structures | Marginalized kernels between labeled graphs | Lifted linear programming | Learning convolutional neural networks for graphs | Expressivity versus efficiency of graph kernels | Efficient graphlet kernels for large graph comparison | Weisfeilerlehman graph kernels | Parsing natural scenes and natural language with recursive neural networks | Supervised neural networks for the classification of structures | Disulfide connectivity prediction using recursive neural networks and evolutionary information | Deep graph kernels,iclr,010
509.pdf.json,,"A central goal of Artificial Intelligence is the creation of machines that learn as effectively from human instruction as they do from data. A recent and important step towards this goal is the invention of neural architectures that can learn to perform algorithms akin to traditional computers, using primitives such as memory access and stack manipulation (Graves et al., 2014; Joulin & Mikolov, 2015; Grefenstette et al., 2015; Kaiser & Sutskever, 2015; Kurach et al., 2015; Graves et al., 2016). These architectures can be trained through standard gradient descent methods, and enable machines to learn complex behavior from input-output pairs or program traces. In this context the role of the human programmer is often limited to providing training data. However, for many tasks training data is scarce. In these cases the programmer may have partial procedural background knowledge: one may know the rough structure of the program, or how to implement several sub-routines that are likely necessary to solve the task. For example, in visual programming, a user often knows a rough sketch of what they want to do, but need to fill in the specific components. In programming by demonstration (Lau et al., 2001) and programming with query languages (Neelakantan et al., 2015a) a user conforms to a larger set of conditions on the data, and needs to settle details. In all these scenarios, the question then becomes how to exploit this type of prior knowledge when learning algorithms. To address the above question we present an approach that enables programmers to inject their procedural background knowledge into a neural network. In this approach the programmer specifies a program sketch (Solar-Lezama et al., 2005) in a traditional programming language. This sketch defines one part of the neural network behaviour. The other part is learned using training data. The core insight that enables this approach is the fact that most programming languages can be formulated in terms of an abstra","Recursive program synthesis | Neural module networks | Adaptive neural compilation | Terpret: A probabilistic programming language for program induction | Church: a language for generative models | Neural turing machines | Hybrid computing using a neural network with dynamic external | Learning to transduce with unbounded memory | Ratajszczak, and Gilles Wiber | Inferring algorithmic patterns with stack-augmented recurrent nets | Neural gpus learn algorithms | Symbolic Execution and Program Testing | Adam: A method for stochastic optimization | Inductive pProgramming: A sSurvey of pProgram sSynthesis tTechniques | Genetic programming: on the programming of computers by means of natural selection, volume 1 | Neural random-access machines | Your wish is my command. chapter Learning Repetitive Text-editing Procedures with SMARTedit, pp. 209–226 | Gradient-based hyperparameter optimization through reversible learning | Toward automatic program synthesis | Neural programmer: Inducing latent programs with gradient descent | Adding gradient noise improves learning for very deep networks | Evolutionary program induction of binary machine code and its applications | Neural programming language | Ebcioğlu. Programming by Sketching for Bit-streaming Programs | Combinatorial sketching for finite programs | Training very deep networks | Sequence to sequence learning with neural networks",iclr,010
511.pdf.json,,"Artificial neural networks are remarkable function approximators used in a myriad of applications ranging from complex controllers for robotic actuation (Levine et al., 2016) (Schulman et al., 2015) to simple image classifiers for digit recognition (LeCun et al., 1989) . They even find uses in physics to find approximations to solutions of PDEs and systems of coupled ordinary differential equations (ODEs) (Lagaris et al., 1998). Their success is in part achieved by their property of being universal function approximators (Hornik et al., 1989). In order to train a neural network one usually defines a cost function which captures the ”goodness” of the choice of parameters in our model, and uses gradient descent/ascent algorithms to improve them. In supervised learning, for example, input output data pairs are used to define a cost function such as the mean squared error or the mean absolute error; unfortunately, in many cases the function we want to approximate is unkown. For instance, in many reinforcement learning settings one wants to find the optimal policy, a function from state variables to actions1, which maximizes the expected sum of discounted rewards of an agent in some environment. This function is usually unkown a priori, so this problem can’t readily be framed as a regression problem using input-output pairs. This assertion becomes blurred, however, when looking at the work of Mnih et al. (2013), where a deep Q-network learns by generating targets and minimizing a cost of the form Li(θi) = Es,a∼ρ[(yi −Q(s, a; θi))2]. (1) Here, the targets yi are generated from the same Q-network that is being used to approximate the Q-function, hence the neural network has two purposes: approximation and data generation. In this work, we show that this same idea can be extended to the domain of approximating solutions to partial differential equations, and in particular the solution to the Hamiton-Jacobi-Isaacs PDE. 1or states to probabilities over actions","End-to-End Training of Deep Visuomotor Policies | Trust Region Policy Optimization | Backpropagation Applied to Handwritten | Artificial neural networks for solving ordinary and partial differential equations | Multilayer feedforward networks are universal approximators | Playing Atari with Deep Reinforcement Learning | A toolbox of level set methods | Neural approximation of PDE solutions: An application to reachability computations | The number of points sampled was chosen to be N = 2000, uniformly picked",iclr,010
512.pdf.json,NONPARAMETRICALLY LEARNING ACTIVATION FUNCTIONS IN DEEP NEURAL NETS,"Deep learning techniques have proven particularly useful in the classification setting, recently surpassing even human performance on some image-classification tasks. We seek to advance the state of the art by learning not only weights between neurons in the network but also part of the network structure itself – the activation functions. Current deep learning literature largely focuses on improving architectures and adding regularization to the training process. By contrast, the realm of learning the network structure itself is relatively unexplored. Current best practice often treats network size, shape and choice of activation function as a hyper-parameter to be chosen empirically. Instead, we propose to learn the activation functions through nonparametric estimation. We introduce a class of nonparametric models for activation functions. Importantly, we ensure that our technique can be incorporated into the back-propagation framework. This is crucial because it means our method can be easily added to current practice. To this end, we propose learning functions via basis expansion. In particular, we find that using a Fourier basis works well in practice and offers improved performance over the baseline on several benchmark datasets. We see relative improvements in test error rates of up to 15%. Nonparametric activation functions in dropout nets are especially successful. We also introduce a two-stage training process. First, a network without nonparametric activation functions is trained. Then, the learned network is used as an initialization for an identical network with nonparametric activation functions. This method of initializing the network yields considerable improvements in performance for convolution neural networks on image classification tasks. Lastly, we consider the algorithmic stability approach to accessing generalization bounds. We use this to demonstrate that feed-forward networks with our method of nonparametrically estimating activation function","Learning activation functions to improve deep neural networks | Non-asymptotic analysis of stochastic approximation algorithms for machine learning | Neural Network Learning: Theoretical Foundations | Theano: a CPU and GPU math expression compiler | Stability and generalization | cudnn: Efficient primitives for deep learning | Train faster, generalize better: Stability of stochastic gradient descent | Scalable parallel programming with cuda | Learning multiple layers of features from tiny images | Efficient backprop | The MNIST database of handwritten digits | Gradient-based hyperparameter optimization through reversible learning | Dropout: A simple way to prevent neural networks from overfitting | cos((L− T )iπ/L) + bi sin((L− T )iπ/L) x > L− T k grows with sample size n and is given by k = dne. We need to control the norm of the weight matrices W and biases b in the affine transformations. In addition, we also need to control the magnitude of the coefficients in the basis expansion",iclr,010
513.pdf.json,,"Humans learn a tremendous amount of knowledge about the world with almost no supervision and can construct a predictive model of the world. We use this model of the world to interact with our environment. As also argued by Lake et al. (2016) one of the core ingredients of human intelligence is intuitive physics. Children can learn and predict some of the common physical behaviors of our world just by observing and interacting without any direct supervision. And they form a sophisticated predictive model of the physical environment and expect the world to behave based on their mental model and have a reasonable expectation about unseen situations Téglás et al. (2011). Despite impressive progress in the last few years in the training of the supervised models, we have not yet quite been able to achieve similar results in unsupervised learning, and it remains one of the challenging research areas in the field. The full potential of the application of unsupervised learning is yet to be realized. In this work, we leverage unsupervised learning to train a predictive model over sequences. We use the imagined and predicted future sequence data to help a physical environment prediction model generalize better to unseen settings. More specifically we focus on the task of predicting if a tower of square bricks will fall or not, as introduced by Lerer et al. (2016). They showed that a deep convolution neural network could predict the fall of the towers with super-human accuracy. But despite the strengths of convolution neural networks, Zhang et al. (2016) shows how deep neural networks have a hard time generalizing to novel situations in the same way as humans or simulation-based models can do. In this work, we show that deep neural networks are capable of generalizing to novel situations through a form of unsupervised learning. The core idea is to observe the world without any supervision and build a future predictive model of it, and in a later stage leverage and utilize the",Greedy layer-wise training of deep networks | Adversarially learned inference | Deep visual foresight for planning robot motion | Unsupervised learning for physical interaction through video prediction | Learning visual predictive models of physics for playing billiards | Understanding the difficulty of training deep feedforward neural networks | Deep residual learning for image recognition | Identity mappings in deep residual networks | Reducing the dimensionality of data with neural networks | A fast learning algorithm for deep belief nets | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Adam: A method for stochastic optimization | Semi-supervised learning with deep generative models | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | Building machines that learn and think like people | Learning physical intuition of block towers by example | Deep predictive coding networks for video prediction and unsupervised learning | Deep multi-scale video prediction beyond mean square error | Statistical language models based on neural networks. Presentation at Google | Rectified linear units improve restricted boltzmann machines | Action-conditional video prediction using deep networks in atari games | Improved techniques for training gans | Amortised map inference for image super-resolution | Dropout: a simple way to prevent neural networks from overfitting | Unsupervised learning of video representations using lstms | Pure reasoning in 12-month-old infants as probabilistic inference | A comparative evaluation of approximate probabilistic simulation and deep neural networks as accounts of human physical scene understanding,iclr,010
514.pdf.json,,"Recent progress in deep learning (LeCun et al., 2015) has witnessed its application to structured settings, including graphs (Bruna et al., 2013; Duvenaud et al., 2015) groups (Gens & Domingos, 2014; Christopher, 2014; Cohen & Welling, 2016), sequences and hierarchies (Irsoy & Cardie, 2014; Socher et al., 2013). Here, we introduce a simple permutation-equivariant layer for deep learning with set structure, where the primary dataset is a collection of sets, possibly of different sizes. Note that each instance may have a structure of its own, such as graph, image, or another set. In typical machine-learning applications, iid assumption implies that the entire data-set itself has a set structure. Therefore, our special treatment of the set structure is only necessary due to multiplicity of distinct yet homogeneous (data)sets. Here, we show that a simple parameter-sharing scheme enables a general treatment of sets within supervised and semi-supervised settings. In the following, after introducing the set layer in Section 2, we explore several novel applications. Section 3 studies supervised learning with sets that requires “invariance” to permutation of inputs. Section 3.1 considers the task of summing multiple MNIST digits, and Section 3.2 studies an important application of sets in representing low-dimensional point-clouds. Here, we show that deep networks can successfully classify objects using their point-cloud representation. Section 4 presents numerical study in semi-supervised setting where the output of the multi-layer network is “equivariant” to the permutation of inputs. We use permutation-equivariant layer to perform outlier detection on CelebA face dataset in Section 4.1 and improve galaxy red-shift estimates using its clustering information in Section 5.",Tensorflow: Large-scale machine learning on heterogeneous distributed systems | Galactic astronomy | Generative and discriminative voxel modeling with convolutional neural networks | Spectral networks and locally connected networks on graphs | Shapenet: An information-rich 3d model repository | Unsupervised deep haar scattering on graphs | Groups and group convolutions | Fast and accurate deep network learning by exponential linear units (elus) | Group equivariant convolutional networks | Slicing through multicolor space: Galaxy redshifts from broadband photometry | Symmetric Functions and Allied Tables | Convolutional networks on graphs for learning molecular fingerprints | Deep symmetry networks | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Deep recursive neural networks for compositionality in language | Adam: A method for stochastic optimization | Gradient-based learning applied to document recognition | A mesh reconstruction algorithm driven by an intrinsic property of a point cloud | Deep learning face attributes in the wild | Voxnet: A 3d convolutional neural network for real-time object recognition | Estimating cosmological parameters from the dark matter distribution | Multi-instance learning | Rykoff. redmapper ii: X-ray and sz performance benchmarks for the sdss catalog | 3D is here: Point Cloud Library (PCL) | Deeppano: Deep panoramic representation for 3-d shape recognition | Recursive deep models for semantic compositionality over a sentiment treebank | Dropout: a simple way to prevent neural networks from overfitting | Multi-view convolutional neural networks for 3d shape recognition | Learning theory for distribution regression | Learning a probabilistic latent space of object shapes via 3d generative-adversarial modeling | 3d shapenets: A deep representation for volumetric shapes | Multi-instance learning by treating instances as non-iid samples,iclr,010
515.pdf.json,,"Machine learning problems with categorical data require modeling interactions between the features to solve them. As an example, consider a sentiment analysis problem – detecting whether a review is positive or negative – and the following dataset: ‘I liked it’, ‘I did not like it’, ‘I’m not sure’. Judging by the presence of the word ‘like’ or the word ‘not’ alone, it is hard to understand the tone of the review. But the presence of the pair of words ‘not’ and ‘like’ strongly indicates a negative opinion. If the dictionary has d words, modeling pairwise interactions requires O(d2) parameters and will probably overfit to the data. Taking into account all interactions (all pairs, triplets, etc. of words) requires impractical 2d parameters. In this paper, we show a scalable way to account for all interactions. Our contributions are: • We propose a predictor that models all 2d interactions of d-dimensional data by representing the exponentially large tensor of parameters in a compact multilinear format – Tensor Train (TT-format) (Sec. 3). Factorizing the parameters into the TT-format leads to a better generalization, a linear with respect to d number of underlying parameters and inference time (Sec. 5). The TT-format lets you control the number of underlying parameters through the TT-rank – a generalization of the matrix rank to tensors. • We develop a stochastic Riemannian optimization learning algorithm (Sec. 6.1). In our experiments, it outperformed the stochastic gradient descent baseline (Sec. 8.2) that is often used for models parametrized by a tensor decomposition (see related works, Sec. 9). • We show that the linear model (e.g. logistic regression) is a special case of our model with the TT-rank equal 2 (Sec. 8.3). • We extend the model to handle interactions between functions of the features, not just between the features themselves (Sec. 7).",TensorFlow: Large-scale machine learning on heterogeneous systems | Fastfm: a library for factorization machines | Learning long-term dependencies with gradient descent is difficult | Higher-order factorization machines. 2016a | Polynomial networks and factorization machines: New insights and efficient training algorithms | Fast kernel classifiers with online and active learning | A training algorithm for optimal margin classifiers | Analysis of individual differences in multidimensional scaling via n-way generalization of Eckart-Young | The movielens datasets: History and context | Foundations of the PARAFAC procedure: models and conditions for an explanatory multimodal factor analysis | On manifolds of tensors of fixed TT-rank | Adam: A method for stochastic optimization | Speeding-up convolutional neural networks using fine-tuned CP-decomposition | On the computational efficiency of training neural networks | Time integration of tensor trains | Regression on fixed-rank positive semidefinite matrices: a Riemannian approach | Tensorizing neural networks | Tensor-Train decomposition | Scikit-learn: Machine learning in Python | Factorization machines | The density-matrix renormalization group in the age of matrix product states | Supervised learning with tensor networks | Riemannian pursuit for big matrix recovery | Learning multidimensional fourier series with tensor trains | Stochastic variance reduced riemannian eigensolver | Tensor machines for learning target-specific polynomial features | Fast stochastic optimization on riemannian manifolds | MovieLens 100K. MovieLens 100K is a recommender system dataset with 943 users and 1682 movies,iclr,010
517.pdf.json,LEARNING TO DISCOVER SPARSE GRAPHICAL MODELS,"Probabilistic graphical models provide a powerful framework for describing the dependencies between a set of variables. Many applications infer the structure of a probabilistic graphical model from data to elucidate the relationships between variables. These relationships are often represented by an undirected graphical model also known as a Markov Random Field (MRF). We focus on a common MRF model, Gaussian graphical models (GGMs). GGMs are used in structure-discovery settings for rich data such as neuroimaging, genetics, or finance (Friedman et al., 2008; Ryali et al, 2012; Mohan et al., 2012; Belilovsky et al., 2016). Although multivariate Gaussian distributions are well-behaved, determining likely structures from few examples is a complex task when the data is high dimensional. It requires strong priors, typically a sparsity assumption, or other restrictions on the structure of the graph, which now make the distribution difficult to express analytically and use. A standard approach to estimating structure with GGMs in high dimensions is based on the classic result that the zeros of a precision matrix correspond to zero partial correlation, a necessary and sufficient condition for conditional independence (Lauritzen, 1996). Assuming only a few conditional dependencies corresponds to a sparsity constraint on the entries of the precision matrix, leading to a combinatorial problem. Many popular approaches to learning GGMs can be seen as leveraging the `1-norm to create convex surrogates to this problem. Meinshausen & Bühlmann (2006) use nodewise `1 penalized regressions. Other estimators penalize the precision matrix directly (Cai et al., 2011; Friedman et al., 2008; Ravikumar et al., 2011). The most popular being the graphical lasso fglasso(Σ̂) = arg min Θ 0 − log |Θ|+ Tr (Σ̂Θ) + λ‖Θ‖1, (1) which can be seen as a penalized maximum-likelihood estimator. Here Θ and Σ̂ are the precision and sample covariance matrices, respectively. A large variety of alternative regul","Learning polynomials with neural networks | Bayesian dark knowledge | On estimation of the diagonal elements of a sparse precision matrix | Hypothesis testing for differences in Gaussian graphical models: Applications to brain connectivity | Under review as a conference paper at ICLR | The joint graphical lasso for inverse covariance estimation | intrinsic brain architecture in autism | On the statistical efficiency of `1,p multi-task learning | Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization | Understanding the effective receptive field in deep | Accelerating Bayesian structural | Maximal sparsity with deep networks | We take the network trained on 500 nodes in the synthetic experiments section. We use the same experimental setup as in the gene experiments",iclr,010
518.pdf.json,,"Modern machine learning increasingly relies on highly complex probabilistic models to reason about uncertainty. A key computational challenge is to develop efficient inference techniques to approximate, or draw samples from complex distributions. Currently, most inference methods, including MCMC and variational inference, are hand-designed by researchers or domain experts. This makes it difficult to fully optimize the choice of different methods and their parameters, and exploit the structures in the problems of interest in an automatic way. The hand-designed algorithm can also be inefficient when it requires to make fast inference repeatedly on a large number of different distributions with similar structures. This happens, for example, when we need to reason about a number of observed datasets in settings like online learning, or need fast inference as inner loops for other algorithms such as maximum likelihood training. Therefore, it is highly desirable to develop more intelligent probabilistic inference systems that can adaptively improve its own performance to fully the optimize computational efficiency, and generalize to new tasks with similar structures. Specifically, denote by p(x) a probability density of interest specified up to the normalization constant, which we want to draw sample from, or marginalize to estimate its normalization constant. We want to study the following problem: Problem 1. Given a distribution with density p(x) and a function f(η; ξ) with parameter η and random input ξ, for which we only have assess to draws of the random input ξ (without knowing its true distribution q0), and the output values of f(η; ξ) and its derivative ∂ηf(η; ξ) given η and ξ. We want to find an optimal parameter η so that the density of the random output variable x = f(η; ξ) with ξ ∼ q0 closely matches the target density p(x). Because we have no assumption on the structure of f(η; ξ) and the distribution of random input, we can not directly calculate the actual ","Learning to learn by gradient descent by gradient descent | An introduction to Stein’s method, volume 4 | Probabilistic integration: A role for statisticians in numerical analysis | A kernel test of goodness of fit | Learning step size controllers for robust neural network training | Integral approximation by kernel smoothing | Training generative neural networks via maximum mean discrepancy optimization | Amortized inference in probabilistic reasoning | Markov chain Monte Carlo maximum likelihood | Generative adversarial nets | Measuring sample quality with Stein’s method | Importance sampling via the estimated sampler | Training products of experts by minimizing contrastive divergence | Deep directed generative models with energy-based probability estimation | Adam: A method for stochastic optimization | Auto-encoding variational Bayes | Learning to optimize | Generative moment matching networks | Stein variational gradient descent: A general purpose bayesian inference algorithm | A kernelized Stein discrepancy for goodness-of-fit tests | Deep learning face attributes in the wild | Learning deep energy models | f-gan: Training generative neural samplers using variational divergence minimization | Control functionals for Monte Carlo integration | Monte Carlo is fundamentally unsound | Bayes–hermite quadrature | Inference networks for sequential monte carlo in graphical models | Unsupervised representation learning with deep convolutional generative adversarial networks | Operator variational inference | Black box variational inference | Hierarchical variational models | Variational inference with normalizing flows | Variational inference with normalizing flows | Improved techniques for training gans | A bound for the error in the normal approximation to the distribution of a sum of dependent random variables | Training restricted boltzmann machines using approximations to the likelihood gradient | Variational gaussian process | A theory of generative convnet | Lsun: Construction of a large-scale image dataset using deep learning with humans in the loop | Energy-based generative adversarial network",iclr,010
519.pdf.json,RECURRENT NORMALIZATION PROPAGATION,"Recurrent neural network have shown remarkably good performances for sequential modelling tasks including machine translation (Bahdanau et al., 2015), visual captioning (Xu et al., 2015; Yao et al., 2015) or question answering (Hermann et al., 2015). However, such models remain notoriously hard to train with gradient backpropagation. As the number of time steps in the input sequence increases, the contractive or expanding effects associated with the state-to-state transformation at each time step can shrink or grow exponentially, leading respectively to vanishing or exploding gradients (Hochreiter, 1991; Bengio et al., 1994; Pascanu et al., 2012). In particular, with gradient vanishing, states at a given time are not influenced by changes happening much earlier in the sequence, preventing the model from learning long-term dependencies. While the long-term dependencies problem is unsolvable in absolute (Hochreiter, 1991; Bengio et al., 1994), different RNN parameterizations, such as LSTM or GRU (Hochreiter & Schmidhuber, 1997; Cho et al., 2014) can help mitigate it. Furthermore, the LSTM parametrization has been recently extended to include layer-wise normalization (Cooijmans et al., 2016; Ba et al., 2016), building upon Batch Normalization (BN) (Ioffe & Szegedy, 2015). By normalizing the hidden state distributions to a fix scale and shift through the different time steps, normalized LSTMs have been shown to ease training, resulting in a parametrization that converges faster than a standard LSTM. However, normalized LSTM introduces extra-computations as it involves standardizing the hidden states, enforcing their means and variances at each time step. By contrast, we propose an LSTM reparametrization that allows by construction to cheaply preserve the normalization of the hidden states through time. Our approach can be seen as the recurrent counterpart to the recent normalization propagation applied in feed-forward network (Arpit et al., 2016). It results in faster t","Normalization propagation: A parametric technique for removing internal covariate shift in deep networks | Neural machine translation by jointly learning to align and translate | Learning long-term dependencies with gradient descent is difficult | Learning phrase representations using rnn encoder-decoder for statistical machine translation | Recurrent batch normalization | Understanding the difficulty of training deep feedforward neural networks | Draw: A recurrent neural network for image generation | Teaching machines to read and comprehend | Untersuchungen zu dynamischen neuronalen netzen | Long short-term memory | Batch normalization: Accelerating deep network training by reducing internal covariate | Adam: A method for stochastic optimization | Zoneout: Regularizing rnns by randomly preserving hidden activations | The neural autoregressive distribution estimator | Building a large annotated corpus of english: The penn treebank | Subword language modeling with neural networks | On the difficulty of training recurrent neural networks | Weight normalization: A simple reparameterization to accelerate training of deep neural networks | Recurrent dropout without memory | Improving predictive inference under covariate shift by weighting the log-likelihood function | Accelerating the convergence of the back-propagation method | Show, attend and tell: Neural image caption generation with visual attention | Describing videos by exploiting temporal structure",iclr,010
520.pdf.json,,"a man wearing snow gear poses for a photo while standing on skis A person on snow skis with a backpack skiing down a mountain. A white body and head with a bright orange bill along with black coverts and rectrices. A young girl is wearing a black ballerina outfit and pink tights dancing. person person person Figure 1: Examples of interpretable and controllable image synthesis. Left: MS-COCO, middle: CUB, right: MHP. Bottom row shows segmentation and keypoint conditioning information. Image generation has improved dramatically over the last few years. The state-of-the-art images generated by neural networks in 2010, e.g. (Ranzato et al., 2010) were noted for their global structure and sharp boundaries, but were still easily distinguishable from natural images. Although we are far from generating photo-realistic images, the recently proposed image generation models using modern deep networks (van den Oord et al., 2016c; Reed et al., 2016a; Wang & Gupta, 2016; Dinh et al., 2016; Nguyen et al., 2016) can produce higher-quality samples, at times mistakable for real. Three image generation approaches are dominating the field: generative adversarial networks (Goodfellow et al., 2014; Radford et al., 2015; Chen et al., 2016), variational autoencoders (Kingma & Welling, 2014; Rezende et al., 2014; Gregor et al., 2015) and autoregressive models (Larochelle & Murray, 2011; Theis & Bethge, 2015; van den Oord et al., 2016b;c). Each of these approaches have significant pros and cons, and each remains an important research frontier. Realistic high-resolution image generation will impact media and communication profoundly. It will also likely lead to new insights and advances in artificial intelligence. Understanding how to control the process of composing new images is at the core of this endeavour. Researchers have shown that it is possible to control and improve image generation by conditioning on image properties, such as pose, zoom, hue, saturation, brightness and shape (Dosov",2d human pose estimation: New benchmark and state of the art analysis | InfoGAN: Interpretable representation learning by information maximizing generative adversarial nets | Deep generative image models using a Laplacian pyramid of adversarial networks | Density estimation using Real NVP | Learning to generate chairs with convolutional neural networks | Generative adversarial nets | DRAW: A recurrent neural network for image generation | Identity mappings in deep residual networks | Auto-encoding variational Bayes | Deep convolutional inverse graphics network | The neural autoregressive distribution estimator | Microsoft COCO: Common objects in context | Generating images from captions with attention | Conditional generative adversarial nets | Synthesizing the preferred inputs for neurons in neural networks via deep generator networks | Context encoders: Feature learning by inpainting | Unsupervised representation learning with deep convolutional generative adversarial networks | Generating more realistic images using gated MRF’s | Learning what and where to draw | Generative adversarial text-to-image synthesis | Stochastic backpropagation and approximate inference in deep generative models | Generative image modeling using spatial lstms | WaveNet: A generative model for raw audio | Pixel recurrent neural networks | Conditional image generation with PixelCNN decoders | Generative image modeling using style and structure adversarial networks | Attribute2Image: Conditional image generation from visual attributes | Generative visual manipulation on the natural image manifold,iclr,010
521.pdf.json,,"Representation of bioacoustic sequences started with ’Human’ speech in the 70’. Speech automatic processing yields to the efficient Mel Filter Cepstral Coefficients (MFCC) representation. Today new bioacoustic representation paradigms arise from environmental monitoring and species classification at weak Signal to Noise Ratio (SNR) and with small amount of data per species. Several neurobiological evidences suggest that auditory cortex is tuned to complex time varying acoustic features, and consists of several fields that decompose sounds in parallel (Kowalski et al., 1996; Mercado et al., 2000). Therefore it is more than reasonable to investigate the Chirplet timefrequency representation from acoustic and neurophysiological points of view. Chirps, or transient amplitude and frequency modulated waveforms, are ubiquitous in nature systems (Flandrin (2001)), ranging from bird songs and music, to animal vocalization (frogs, whales) and Speech. Moreover the sinusoidal models are a typical attempt to represent audio signals as a superposition of chirp-like components. Chirp signals are also commonly observed in biosonar systems. The Chirplet transform subsumes both Fourier analysis and wavelet analysis, providing a broad framework for mapping one-dimensional sound waveforms into a n-dimensional auditory parameter space. It offers the processing described in different auditory fields, i.e. cortical regions with systematically related response sensitivities. Moreover, Chirplet spaces are highly over-complete because there is an infinite number of ways to segment a time-frequency plane, the dictionary is redundant: this corresponds well with the overlapping, parallel signal processing pathways of auditory cortex. Then we suggest that low level CNN layers shall be pretrained by Chirplet kernels. Thus, we define and code a Fast Chirplet Transform (FCT). We conduct validation on real recordings of whale and birds, and on Speech (vowels subset of TIMIT). We demonstrate that CNN","Dynamic fuzzy wavelet neural network model for structural system identification | Deep scattering spectrum | Invariant scattering convolution networks | Wavelet analysis and signal processing | Signal processing and compression with wavelet packets | Time frequency and chirps | Timit acoustic-phonetic continuous speech corpus | Analysis of dynamic spectra in ferret primary auditory cortex. ii. prediction of unit responses to arbitrary dynamic spectra | Convolutional networks for images, speech, and time series | A wavelet tour of signal processing | The chirplet transform: A generalization of gabor’s logon transform | Adaptive chirplet transform: an adaptive generalization of the wavelet transform | Modeling auditory cortical processing as an adaptive chirplet | Wavelets-algorithms and applications. Wavelets-Algorithms and applications Society for Industrial and Applied Mathematics Translation | Estimating phoneme class conditional probabilities from raw speech signal using convolutional neural networks | Investigating sparse deep neural networks for speech recognition | Numerical recipes 3rd edition: The art of scientific computing | A tonotopic artificial neural network architecture for phoneme probability estimation",iclr,010
522.pdf.json,,"Deep learning has made substantial progress in many applications, including Computer Vision [He et al. (2016); Simonyan & Zisserman (2015); Szegedy et al. (2015); Krizhevsky et al. (2012)], Natural Language Processing [Sutskever et al. (2014)] and Speech Recognition [Hinton et al. (2012)]. However, till now, how and why it works remains elusive due to a lack of theoretical understanding. First, how simple approaches like gradient descent can solve a very complicated non-convex optimization effectively. Second, how the deep models, especially deep convolutional models, achieve generalization power despite massive parameters. In this paper, we focus on the first problem and use dynamical system to analyze the nonlinear gradient descent dynamics of certain two-layered nonlinear network in the following form: g(x;w) = K∑ j=1 σ(wᵀj x) (1) where σ(x) = max(x, 0) is the ReLU nonlinearity. We consider the following setting: a student network learns the parameters that minimize the l2 distance between its prediction and the supervision provided by the teacher network of the same size with a fixed set of parameters w∗. We assume all inputs x to follow Gaussian distribution and thus the network is bias-free. Eqn. 1 is highly nonconvex and could contain exponential number of symmetrically equivalent solutions. To analyze this, we first derive novel and concise gradient update rules for multilayer ReLU networks (See Lemma 2.1) in the teacher-student setting under l2 loss. Then for K = 1, we prove that the nonlinear gradient dynamics of Eqn. 1 has a close form and converges to w∗ with at least (1 − )/2 probability, if initialized randomly with standard derivation on the order of 1/ √ d, verifying commonly used initialization techniques [Glorot & Bengio (2010); He et al. (2015); LeCun et al. (2012)],. When K ≥ 2, we prove that when the teacher parameters {wj}Kj=1 form orthonormal bases, (1) a symmetric initialization of a student network gets stuck at a saddle point and (2) under ",The loss surfaces of multilayer networks | Open problem: The landscape of the loss surfaces of multilayer networks | Local minima and plateaus in hierarchical structures of multilayer perceptrons | Understanding the difficulty of training deep feedforward neural networks | Delving deep into rectifiers: Surpassing human-level performance on imagenet classification | Deep residual learning for image recognition | Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups | Beating the perils of non-convexity: Guaranteed training of neural networks using tensor methods | Deep learning without poor local minima | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | Efficient backprop | The landscape of empirical risk for non-convex losses | Dynamics of on-line gradient descent learning for multilayer neural networks | Exact solutions to the nonlinear dynamics of learning in deep linear neural networks | Very deep convolutional networks for large-scale image recognition | No bad local minima: Data independent training error guarantees for multilayer neural networks | Sequence to sequence learning with neural networks. In Advances in neural information processing | Going deeper with convolutions,iclr,010
523.pdf.json,,"This paper considers strategies to learn parametric models for language modeling with very large vocabularies. This problem is key to natural language processing, with applications in machine translation (Schwenk et al., 2012; Sutskever et al., 2014; Vaswani et al., 2013) or automatic speech recognition (Graves et al., 2013; Hinton et al., 2012). In particular, Neural Network Language Models (NNLMs) have received a renewed interest in recent years, by achieving state of the art performance on standard benchmarks (Jozefowicz et al., 2016; Mikolov et al., 2010). These approaches are more costly but generalize better than traditional non-parametric models (Bahl et al., 1983; Kneser & Ney, 1995). Statistical language models assign a probability to words given their history (Bahl et al., 1983). They are evaluated by objective criteria such as perplexity (ppl), which directly measures the ability of the system to determine proper probabilities for all the words. This potentially makes parametric models prohibitively slow to train on corpara with very large vocabulary. For instance, the vocabulary of the One Billion Word benchmark (Chelba et al., 2013) contains around 800K words. In standard NNLMs, such as feedforward networks (Bengio et al., 2003a) or recurrent networks (Mikolov et al., 2010), computing this probability over the whole vocabulary is the bottleneck. Many solutions have been proposed to reduce the complexity of this expensive step (Bengio et al., 2003b; Goodman, 2001a; Gutmann & Hyvärinen, 2010). We distinguish (i) the methods that consider the original distribution and aim at providing approximations of the probabilities, or of a subset of them (Bengio et al., 2003b; Ji et al., 2015), from (ii) the approaches that compute exact probabilities for an approximate model yielding a lower computational cost, such as the popular hierarchical softmax (Goodman, 2001a; Mnih & Hinton, 2009; Morin & Bengio, 2005). Our approach, called adaptive softmax, belongs to the s","When and why are log-linear models self-normalizing | A maximum likelihood approach to continuous speech recognition | Adaptive importance sampling to accelerate training of a neural probabilistic language model | A neural probabilistic language model | Quick training of probabilistic neural nets by importance sampling | Class-based n-gram models of natural language | One billion word benchmark for measuring progress in statistical language modeling | Strategies for training large vocabulary neural language models | Empirical evaluation of gated recurrent neural networks on sequence modeling | Fast and robust neural network joint models for statistical machine translation | Adaptive subgradient methods for online learning and stochastic optimization | Finding structure in time | Classes for fast maximum entropy training | A bit of progress in language modeling | Speech recognition with deep recurrent neural networks | Noise-contrastive estimation: A new estimation principle for unnormalized statistical models | Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups | Long short-term memory | On using very large target vocabulary for neural machine translation | Blackout: Speeding up recurrent neural network language models with very large vocabularies | Learning visual features from large weakly supervised data | Exploring the limits of language modeling | Estimation of probabilities from sparse data for the language model component of a speech recognizer | Improved backing-off for m-gram language modeling | Europarl: A parallel corpus for statistical machine translation | A cache-based natural language model for speech recognition | Structured output layer neural network language model | A simple way to initialize recurrent networks of rectified linear units | Context dependent recurrent neural network language model | Recurrent neural network based language model | Empirical evaluation and combination of advanced language modeling techniques | Strategies for training large scale neural network language models | Extensions of recurrent neural network language model | Efficient estimation of word representations in vector space | Learning longer memory in recurrent neural networks | A scalable hierarchical distributed language model | A fast and simple algorithm for training neural probabilistic language models | Hierarchical probabilistic neural network language model | Continuous space language models | Large, pruned or continuous space language models on a gpu for statistical machine translation | Sparse non-negative matrix language modeling for skip-grams | Sequence to sequence learning with neural networks | Decoding with large-scale neural language models improves translation | Efficient exact gradient update for training deep networks with very large sparse targets | Backpropagation through time: what it does and how to do | An efficient gradient-based algorithm for on-line training of recurrent network trajectories | Human behavior and the principle of least effort | Speed regularization and optimality in word classing",iclr,010
524.pdf.json,,"One of the major catalysts for the resurgence of neural networks as “deep learning” was the influx of the availability of data. Labeled data is crucial for any supervised machine learning algorithm to work, even moreso for deep architectures which are easily susceptible to overfitting. Deep learning has flourished in a few domains (e.g. images, speech, text) where labeled data has been relatively simple to acquire. Unfortunately most of the data that is readily available is unstructured and unlabeled and this has prevented recent successes from propagating to other domains. In order to leverage the power of supervised learning, data must be manually labeled, a process which requires investment of human effort. An alternative to labeling unlabeled data is to generate new data with known labels. One variant of this approach is to create synthetic data from a simulation such as a computer graphics engine (Shotton et al., 2013; Richter et al., 2016), however, this may not work if the simulation is not a good representation of the real world domain. Another option is dataset augmentation, wherein the existing data is transformed in some way to create new data that appears to come from the same (conditional) data generating distribution (Bengio et al., 2011). The main challenge with such an approach is that domain expertise is required to ensure that the newly generated data respects valid transformations (i.e. those that would occur naturally in that domain). In this work, we consider augmentation not by a domain-specific transformation, but by perturbing, interpolating, or extrapolating between existing examples. However, we choose to operate not in input space, but in a learned feature space. Bengio et al. (2013) and Ozair & Bengio (2014) claimed that higher level representations expand the relative volume of plausible data points within the feature space, conversely shrinking the space allocated for unlikely data points. As such, when traversing along the manifold it ","GSNs: generative stochastic networks | End-to-end attentionbased large vocabulary speech recognition | Hidden Markov model on a unit hypersphere space for gesture trajectory recognition | Listen, attend and spell: A neural network for large vocabulary conversational speech recognition | Smote: synthetic minority over-sampling technique | Learning phrase representations using rnn encoder–decoder for statistical machine translation | Semi-supervised sequence learning | Exploring the trade-off between accuracy and observational latency in action recognition | Generative adversarial nets | Spoken Arabic digits recognition using MFCC based on GMM | On using very large target vocabulary for neural machine translation | Temporal classification: Extending the classification paradigm to multivariate time series | Adam: A method for stochastic optimization | Auto-encoding variational bayes | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | Gradient-based learning applied to document recognition | Constructing long short-term memory based deep recurrent neural networks for large vocabulary speech recognition | The UJIpenchars database: a pen-based database of isolated handwritten characters | Addressing the rare word problem in neural machine translation | Deep directed generative autoencoders | Playing for data: Ground truth from computer games | Support vector machines of intervalbased features for time series classification | Exploring data augmentation for improved singing voice detection with neural networks | Real-time human pose recognition in parts from single depth images | Unsupervised learning of video representations using lstms | Sequence to sequence learning with neural networks. In Advances in neural information processing | Sequence to sequence-video to text | A neural conversational model | Grammar as a foreign language | Show and tell: A neural image caption generator | Under review as a conference paper at ICLR",iclr,010
525.pdf.json,,"Sum-product networks (SPNs) were first introduced by Poon & Domingos (2011) as a new type of deep representation. They distinguish themselves from other types of neural networks by several desirable properties: 1. The quantities computed by each node can be clearly interpreted as (un-normalized) probabilities. 2. SPNs are equivalent to Bayesian and Markov networks (Zhao et al., 2015) while ensuring that exact inference has linear complexity with respect to the size of the network. 3. They represent generative models that naturally handle arbitrary queries with missing data while changing which variables are treated as inputs and outputs. There is a catch: these nice properties arise only when the structure of the network satisfies certain conditions (i.e., decomposability and completeness) (Poon & Domingos, 2011). Hence, it is not easy to specify sum-product networks by hand. In particular, fully connected networks typically violate those conditions. Similarly, most sparse structures that are handcrafted by practitioners to compute specific types of features or embeddings also violate those conditions. While this may seem like a major drawback, the benefit is that researchers have been forced to develop structure learning techniques to obtain valid SPNs that satisfy those conditions (Dennis & Ventura, 2012; Gens & Domingos, 2013; Peharz et al., 2013; Lee et al., 2013; Rooshenas & Lowd, 2014; Adel et al., 2015; Vergari et al., 2015; Rahman & Gogate, 2016; Mazen Melibari, 2016). At the moment, the search for good network structures in other types of neural networks is typically done by hand based on intuitions as well as trial and error. However the expectation is that automated structure learning techniques will eventually dominate. For this to happen, we need structure learning techniques that can scale easily to large amounts of data. To that effect, we propose the first online structure learning technique for SPNs with Gaussian leaves. The approach starts with a n","Learning the structure of sum-product networks via an svd-based algorithm | On-line expectation–maximization algorithm for latent data models | Learning the architecture of sum-product networks using clustering on variables | Discriminative learning of sum-product networks | Learning the structure of sum-product networks | Online algorithms for sum-product networks with continuous variables | Online incremental structure learning of sum–product networks | Generative moment matching networks | Dynamic sum-product networks for tractable inference on sequence data | Foundations of Sum-Product Networks for Probabilistic Modeling | Greedy part-wise learning of sum-product networks | Sum-product networks: A new deep architecture | Merging strategies for sum-product networks: From trees to graphs | Online and Distributed Bayesian Moment Matching for Sum-Product Networks | Learning sum-product networks with direct and indirect variable interactions | On the hardness of approximate reasoning | Deep boltzmann machines | A note on the evaluation of generative models | Simplifying, regularizing and strengthening sum-product network structure learning | A unified approach for learning the parameters of sum-product networks | On the relationship between sum-product networks and Bayesian networks | Collapsed variational inference for sum-product networks",iclr,010
526.pdf.json,,"Deep learning has achieved impressive performance on a range of tasks (LeCun et al., 2015). The workhorse underlying deep learning is gradient descent or backprop. Gradient descent has convergence guarantees in settings that are smooth, convex or both. However, modern convnets are neither smooth nor convex. Every winner of the ImageNet classification challenge since 2012 has used rectifiers which are not smooth (Krizhevsky et al., 2012; Zeiler & Fergus, 2014; Simonyan & Zisserman, 2015; Szegedy et al., 2015; He et al., 2015). Even in convex settings, convergence for nonsmooth functions is lower-bounded by 1/ √ N (Bubeck, 2015). The paper’s main contribution is the first convergence result for modern convnets, Theorem 2. It applies to any neural net with a loss convex in the output of the net. The idea is simple: backprop constructs linear snapshots (gradients) of a neural net’s landscape; section 2 introduces neural Taylor approximations which are used to construct Taylor losses as convex snapshots closely related to backprop. The online convex optimization framework (Zinkevich, 2003) then gives 1/ √ N convergence to the Taylor optimum, matching the lower bound in (Bubeck, 2015). Section 2.3 investigates the Taylor optimum and regret terms empirically. We observe that convergence to the Taylor optimum occurs at 1/ √ N in practice. The nonsmoothness of rectifier nets is perhaps underappreciated. Fig. 1 shows a piecewise-linear (PL) function and its gradient. The gradient is discontinuous or shattered. Shattering is problematic for accelerated and Hessian-based methods which speed up convergence by exploiting the relationship between gradients at nearby points (Sutskever et al., 2013). The success of these methods on rectifier networks requires explanation since gradients at (nearby) points on different sides of a kink are not related. Further, the number of kinks grows exponentially with network depth (Pascanu et al., 2014; Telgarsky, 2016). Section 3 addresses the s","Convex Deep Learning via Normalized Kernels | Breaking the Curse of Dimensionality with Convex Neural Networks | Deep Online Convex Optimization with Gated Games | Convex Neural Networks | Convex Optimization: Algorithms and Complexity | Identifying and attacking the saddle point problem in high-dimensional non-convex optimization | Equilibrated adaptive learning rates for non-convex optimization | Adaptive Subgradient Methods for Online Learning and Stochastic Optimization | Estimation, optimization, and parallelism when data is sparse | Noisy Activation Functions | Delving Deep into Rectifiers: Surpassing HumanLevel Performance on ImageNet Classification | Lecture 6a: Overview of minibatch gradient descent | Adam: A method for stochastic optimization | Imagenet classification with deep convolutional neural networks | Scalable adaptive stochastic optimization using random projections | Estimating the Hessian by Backpropagating Curvature | Explaining NonLinear Classification Decisions with Deep Taylor Decomposition | Adding Gradient Noise Improves Learning for Very Deep Networks | On the number of inference regions of deep feed forward networks with piece-wise linear activations | A direct adaptive method for faster backpropagation learning: The RPROP algorithm | Understanding and Improving Convolutional Neural Networks via Concatenated Rectified Linear Units | Very Deep Convolutional Networks for Large-Scale Image Recognition | Dropout: A Simple Way to Prevent Neural Networks from Overfitting | On the importance of initialization and momentum in deep learning | Going Deeper With Convolutions | Benefits of depth in neural networks | Regularization of Neural Networks using DropConnect | Visualizing and Understanding Convolutional Networks | Convexified Convolutional Neural Networks | Online Convex Programming and Generalized Infinitesimal Gradient Ascent",iclr,010
527.pdf.json,MULTIPLICATIVE LSTM FOR SEQUENCE MODELLING,"Recurrent neural networks (RNNs) are powerful sequence density estimators that can use long contexts to make predictions. They have achieved tremendous success in (conditional) sequence modelling tasks such as language modelling, machine translation and speech recognition. Generative models of sequences can apply factorization via the product rule to perform density estimation of the sequence x1:T = {x1, . . . , xT }, P (x1, . . . , xT ) = P (x1)P (x2|x1)P (x3|x2, x1) · · ·P (xT |x1 . . . xT−1). (1) RNNs can model sequences with the above factorization by using a hidden state to summarize past inputs. The hidden state vector ht is updated recursively using the previous hidden state vector ht−1 and the current input xt as ht = F(ht−1, xt), (2) where F is a differentiable function with learnable parameters. In a vanilla RNN, F multiplies its inputs by a matrix and squashes the result with a non-linear function such as a hyperbolic tangent (tanh). The updated hidden state vector is then used to predict a probability distribution over the next sequence element, using function G. In the case where x1:T consists of mutually exclusive discrete outcomes, G may apply a matrix multiplication followed by a softmax function: P (xt+1) = G(ht). (3) Generative RNNs can evaluate log-likelihoods of sequences exactly, and are differentiable with respect to these log-likelihoods. RNNs can be difficult to train due to the vanishing gradient problem (Bengio et al., 1994), but advances such as the long short-term memory architecture (LSTM) (Hochreiter & Schmidhuber, 1997) have allowed RNNs to be successful. Despite their success, generative RNNs (as well as other conditional generative models) are known to have problems with recovering from mistakes (Graves, 2013). Each time the recursive function of the RNN is applied and the hidden state is updated, the RNN must decide which information from the previous hidden state to store, due to its limited capacity. If the RNN’s hidden representa",Using fast weights to attend to the recent past | Learning long-term dependencies with gradient descent is difficult | Gated feedback recurrent neural networks | Hierarchical multiscale recurrent neural networks | Recurrent batch normalization | Generating sequences with recurrent neural networks | Long short-term memory | The human knowledge compression contest | Grid long short-term memory | Neural machine translation in linear time | Europarl: A parallel corpus for statistical machine translation | Zoneout: Regularizing RNNs by randomly preserving hidden activations | Building a large annotated corpus of English: The Penn Treebank | Subword language modeling with neural networks. preprint (http://www.fit.vutbr.cz/ imikolov/rnnlm/char.pdf) | Regularization and nonlinearities for neural language models: when are they needed | Recurrent memory array structures | Surprisal-driven feedback in recurrent networks | Generating text with recurrent neural networks | Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude | On multiplicative integration with recurrent neural networks | Architectural complexity measures of recurrent neural networks | Recurrent highway networks,iclr,010
528.pdf.json,NEURAL FUNCTIONAL PROGRAMMING,"Inductive Program Synthesis (IPS), i.e., the task of learning a program from input/output examples, is a fundamental problem in computer science. It is at the core of empowering non-experts to use computers for repeated tasks, and recent advances such as the FlashFill extension of Microsoft Excel (Gulwani, 2011) have started to deliver on this promise. A related line of research is the extension of neural network architectures with components that correspond to hardware primitives (Giles et al., 1989; Graves et al., 2014; Weston et al., 2015; Joulin & Mikolov, 2015; Grefenstette et al., 2015; Kurach et al., 2016; Kaiser & Sutskever, 2016; Reed & de Freitas, 2016; Andrychowicz & Kurach, 2016; Zaremba et al., 2016; Graves et al., 2016), enabling them to learn program-like behavior. However, these models are usually tightly coupled to the idea of a differentiable interpretation of computer hardware, as names such as Neural Turing Machine (Graves et al., 2014), Neural Random-Access Machine (Kurach et al., 2016), and Neural GPU (Kaiser & Sutskever, 2016) indicate. We observe that while such architectures form the basis modern computing, they are usually not the models that are used to program computers. Instead, decades of programming languages research have lead to ever higher programming languages that aim to make programming simpler and less error-prone. Indeed, as recent comparisons show (Gaunt et al., 2016b), program synthesis methods from the programming languages community that actively exploit such constructs, e.g. by leveraging known semantics of loops, are currently achieving considerably better results than comparable neural architectures. Still, neural IPS techniques are clearly at an advantage when extending the problem setting from simple integer input/output examples to more complex cases, such as IPS problems with perceptual data (Gaunt et al., 2016a), imprecise examples, or leveraging additional cues such as a natural language description of the desired ",TensorFlow: Large-scale machine learning on heterogeneous systems | Recursive Program Synthesis | Learning efficient algorithms with hierarchical attentive memory | Adaptive neural compilation | Letters to the Editor: Go to Statement Considered Harmful | Synthesizing data structure transformations from input-output examples | Example-directed Synthesis: A Type-theoretic Interpretation | Lifelong perceptual programming by example. 2016a. Under submission to ICLR 2017 | Terpret: A probabilistic programming language for program induction | Higher order recurrent networks and grammatical inference | Hybrid computing using a neural network with dynamic external memory | Learning to transduce with unbounded memory | Automating string processing in spreadsheets using input-output examples | Inferring algorithmic patterns with stack-augmented recurrent nets | Neural GPUs learn algorithms | Neural random-access machines | Neural programmer: Inducing latent programs with gradient descent | Adding gradient noise improves learning for very deep networks | Type-and-example-directed Program Synthesis | Neural programmer-interpreters | Programming with a differentiable forth interpreter | Learning simple algorithms from examples,iclr,010
529.pdf.json,,"Generative modeling of music with deep neural networks is typically accomplished by training a RNN such as a Long Short-Term Memory (LSTM) network to predict the next note in a musical sequence (e.g. Eck & Schmidhuber (2002)). Similar to a Character RNN (Mikolov et al., 2010), these Note RNNs can be used to generate novel melodies by initializing them with a short sequence of notes, then repeatedly sampling from the model’s output distribution generated to obtain the next note. While melodies and text generated in this way have recently garnered attention1, this type of model tends to suffer from common failure modes, such as excessively repeating tokens, or producing sequences that lack a consistent theme or structure. Such sequences can appear wandering and random (see Graves (2013) for a text example). Music compositions adhere to relatively well-defined structural rules, making music an interesting sequence generation challenge. For example, music theory tells that groups of notes belong to keys, chords follow progressions, and songs have consistent structures made up of musical phrases. Our research question is therefore whether such music-theory-based constraints can be learned by an RNN, while still allowing it to maintain note probabilities learned from data. To approach this problem we propose RL Tuner, a novel sequence learning approach in which RL is used to impose structure on an RNN trained on data. The reward function in our framework combines task-related rewards with the probability of a given action originally learned by the pre-trained RNN. Thus, our model directly preserves inforamtion about the original probability distributions learned from data, while allowing us to explicitly control the trade-off between the influence of data 1http://www.theverge.com/2016/6/1/11829678/google-magenta-melody-art-generative-artificialintelligence and heuristic rewards. This is an important novel direction of research, because in many tasks the available reward f",Planning by probabilistic inference | An actor-critic algorithm for sequence prediction | Modeling temporal dependencies in highdimensional sequences: Application to polyphonic music generation and transcription | Semantics derived automatically from language corpora necessarily contain human biases | A recurrent latent variable model for sequential data | Wavenet: A generative model for raw audio | Finding temporal structure in music: Blues improvisation with LSTM recurrent networks | Learning to forget: Continual prediction with LSTM | Generative adversarial nets | Framewise phoneme classification with bidirectional LSTM and other neural network architectures | Neural adaptive sequential monte carlo | Continuous Deep Q-Learning with model-based acceleration | Deep reinforcement learning with double Q-learning | Optimal control as a graphical model inference problem | Adam: A method for stochastic optimization | Deep reinforcement learning for dialogue generation | Continuous control with deep reinforcement learning | Emotional response to musical repetition | Recurrent neural network based language model | Playing atari with deep reinforcement learning | Reward augmented maximum likelihood for neural structured prediction | Relative entropy policy search | Sequence level training with recurrent neural networks | On stochastic optimal control and reinforcement learning by approximate inference | Trust region policy optimization | Stochastic optimal control | Music transcription modelling and composition using deep learning | Policy gradient methods for reinforcement learning with function approximation | Robot trajectory optimization using approximate inference | Probabilistic inference for solving discrete and continuous state markov decision processes | SeqGAN: Sequence generative adversarial nets with policy gradient,iclr,010
530.pdf.json,DISCOVERING OBJECTS AND THEIR RELATIONS FROM ENTANGLED SCENE REPRESENTATIONS,"The ability to reason about objects and relations is important for solving a wide variety of tasks (Spelke et al., 1992; Lake et al., 2016). For example, object relations enable the transfer of learned knowledge across superficial (dis)similarities (Tenenbaum et al., 2011): the predator-prey relationship between a lion and a zebra is knowledge that is similarly useful when applied to a bear and a salmon, even though many features of these animals are very different. In this work, we introduce a neural network architecture for learning to reason about – or model – objects and their relations, which we call relation networks (RNs). RNs accomplish their goal by adhering to a few fundamental design principles. Firstly, RNs are designed to be invariant to permutations of object descriptions in their input. For example, RN representations of the object set {table, chair, book} will be identical for arbitrary re-orderings of the elements of the set. Secondly, RNs are designed to learn relations across multiple objects rather than within a single object – a basic defining property of object relations. This design principle manifests itself in the use of shared computations across groups of objects. In designing the RN architecture, we took inspiration from the recently developed Interaction Network (IN) (Battaglia et al., 2016) which is more generally concerned with modelling temporal interactions. In principle, a deep network with a sufficiently large number of parameters and a large enough training set should be capable of matching the performance of a RN. However, such networks would have to learn both the permutation invariance of objects and the relational structure of the objects in the execution of a desired computation. This quickly becomes unfeasible as the number of objects and relations increase. ∗Denotes equal contribution. To test the ability of RNs to discover relations between objects, we turned to the classification of scenes, wherein classification boundari","Interaction networks for learning about objects, relations and physics | Hico: A benchmark for recognizing human-object interactions in images | Long short-term memory | Learning to learn using gradient descent | Adam: A method for stochastic optimization | Auto-encoding variational bayes | Visual genome: Connecting language and vision using crowdsourced dense image annotations | Human-level concept learning through probabilistic program induction | Building machines that learn and think like people | The effects of contextual scenes on the identification of objects | Metalearning with memory-augmented neural networks | Origins of knowledge | How to grow a mind: Statistics, structure, and abstraction | Matching networks for one shot learning | The one-shot learning task | 2016); the network must learn to bind useful scene representations with arbitrary, episode-specific labels, and use this bound information to infer class membership for subsequent samples in the episode. This task poses a particular challenge for RNs; they must have the capacity to quickly extract useful representations of scene classes to enable rapid, within-episode comparisons",iclr,010
531.pdf.json,PERCEPTION UPDATING NETWORKS: ON ARCHITEC- TURAL CONSTRAINTS FOR INTERPRETABLE VIDEO GENERATIVE MODELS,"The current computer graphics pipelines are the result of efficient implementations required by limited hardware and high frequency output requirements. These requirements were also achieved with the use of explicit physics and optic constraints and modeling with constantly improving data structures (Shirley et al., 2015). In machine learning on the other hand, for a long time image (Olshausen et al., 1996) and video (Hurri & Hyvärinen, 2003) generative models had been investigated with statistical approaches that model images down to the pixel level (Simoncelli & Olshausen, 2001), sometimes assuming neighborhood statistical dependencies (Osindero & Hinton, 2008). In video prediction, the current state of the art uses variations of deep convolutional recurrent neural networks (Kalchbrenner et al., 2016) (Lotter et al., 2016) (Finn et al., 2016). As a parallel to the classic machine learning approach to image and video interpretation and prediction is a growing trend in the deep learning literature for modeling vision as inverse graphics (Kulkarni et al., 2015)(Rezende et al., 2016)(Eslami et al., 2016). These approaches can be interpreted into two groups: supervised and unsupervised vision as inverse graphics. The supervised approach assumes that during training an image is provided with extra information about its rotation, translation, illumination, etc. The goal of the supervised model is to learn an auto-encoder that explicitly factors out the content of the image and its physical properties. The supervised approach is illustrated by Kulkarni et al. (2015). The unsupervised approach requires extra architectural constraints, similar to those assumed in computer graphics. For example, Reed et al. (2016) modeled the content of a scene with a Generative Adversarial Network (Goodfellow et al., 2014) and its location with Spatial Transformer Networks (Jaderberg et al., 2015). The full model is adapted end-to-end to generate images whose appearance can be changed by i","Neural machine translation by jointly learning to align and translate | Attend, infer, repeat: Fast scene understanding with generative models | Unsupervised learning for physical interaction through video prediction | Unsupervised monocular depth estimation with left-right consistency | Generative adversarial nets | Neural turing machines | Simple-cell-like receptive fields maximize temporal coherence in natural video | Spatial transformer networks | Video pixel networks | Auto-encoding variational bayes | Deep convolutional inverse graphics network | Deep predictive coding networks for video prediction and unsupervised learning | Geometry-based next frame prediction from monocular video | Emergence of simple-cell receptive field properties by learning a sparse code for natural images | Modeling image patches with a directed hierarchy of markov random fields | Learning what and where to draw | Unsupervised learning of 3d structure from images | Fundamentals of computer graphics | Natural image statistics and neural representation | Unsupervised learning of video representations using lstms | Generating videos with scene dynamics",iclr,010
532.pdf.json,,"With large amount of training data as its fuel, deep neural networks (DNN) have achieved stateof-art performances in multiple tasks. Examples include deep convolutional neural network (CNN) for image understanding (Krizhevsky et al., 2012; Ioffe & Szegedy, 2015; He et al., 2015; Ren et al., 2015) and recurrent neural networks (RNN) for natural language processing (Cho et al., 2014; Kiros et al., 2015; Dai & Le, 2015; Shang et al., 2015). To effectively train DNN with large scale of data, typically mini-batch based Stochastic Gradient Descent (SGD) (and its variants such as Adagrad (Duchi et al., 2011), Adadelta (Zeiler, 2012) and Adam (Kingma & Ba, 2014)) is used. The mini-batch based SGD training is a sequential process, in which mini-batches of data D = {D1, · · ·Dt, . . . , DT } arrive sequentially in a random order. Here Dt = (d1, · · · , dM ) is the mini-batch of data arriving at the t-th time step and consisting of M training instances. After receivingDt at t-th step, the loss and gradient w.r.t. current model parametersWt are Lt = 1M l(dm) and gt = ∂Lt∂Wt , based on which the neural network model gets updated: Wt+1 =Wt − ηtgt. (1) Here l(·) is the loss function specified by the neural network and ηt is the learning rate at t-th step. With the sequential execution of SGD training, the neural network evolves constantly from a raw state to a fairly mature state, rendering different views even for the same training data. For example, as imposed by the spirit of Curriculum Learning (CL) (Bengio et al., 2009) and Self-Paced Learning (SPL) (Kumar et al., 2010), at the baby stage of the neural network, easy examples play important roles whereas hard examples are comparatively negligible. In contrast, at the adult age, the neural ∗Works done when Yang Fan is an intern at Microsoft Research Asia. network tends to favor harder training examples, since easy ones bring minor changes. It remains an important question that, how to optimally and dynamically allocate training","Learning to learn by gradient descent by gradient descent | Curriculum learning | Learning phrase representations using rnn encoder-decoder for statistical machine translation | Semi-supervised sequence learning | Adaptive subgradient methods for online learning and stochastic optimization | Deep residual learning for image recognition | Long short-term memory | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Easy samples first: Selfpaced reranking for zero-example multimedia search | Self-paced learning with diversity | Adam: A method for stochastic optimization | Skip-thought vectors. In Advances in neural information processing | Actor-critic algorithms | Learning multiple layers of features from tiny images | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | Self-paced learning for latent variable models | Continuous control with deep reinforcement learning | Continuous control with deep reinforcement learning | Online batch selection for faster training of neural networks | Learning word vectors for sentiment analysis | Playing atari with deep reinforcement learning | Asynchronous methods for deep reinforcement learning | Faster r-cnn: Towards real-time object detection with region proposal networks. In Advances in neural information processing | Easy questions first? a case study on curriculum learning for question answering. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) | Neural responding machine for short-text conversation | Mastering the game of go with deep neural networks and tree | From baby steps to leapfrog: How less is more in unsupervised dependency parsing | Dropout: a simple way to prevent neural networks from overfitting | Self-paced learning for long-term tracking | On the importance of initialization and momentum in deep learning | Reinforcement learning: An introduction, volume 1 | Learning the curriculum with bayesian optimization for task-specific word representation learning. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) | Simple statistical gradient-following algorithms for connectionist reinforcement learning | Adadelta: an adaptive learning rate method",iclr,010
533.pdf.json,SURPRISE-BASED INTRINSIC MOTIVATION FOR DEEP REINFORCEMENT LEARNING,"A reinforcement learning agent uses experiences obtained from interacting with an unknown environment to learn behavior that maximizes a reward signal. The optimality of the learned behavior is strongly dependent on how the agent approaches the exploration/exploitation trade-off in that environment. If it explores poorly or too little, it may never find rewards from which to learn, and its behavior will always remain suboptimal; if it does find rewards but exploits them too intensely, it may wind up prematurely converging to suboptimal behaviors, and fail to discover more rewarding opportunities. Although substantial theoretical work has been done on optimal exploration strategies for environments with finite state and action spaces, we are here concerned with problems that have continuous state and/or action spaces, where algorithms with theoretical guarantees admit no obvious generalization or are prohibitively impractical to implement. Simple heuristic methods of exploring such as -greedy action selection and Gaussian control noise have been successful on a wide range of tasks, but are inadequate when rewards are especially sparse. For example, the Deep Q-Network approach of Mnih et al. [13] used -greedy exploration in training deep neural networks to play Atari games directly from raw pixels. On many games, the algorithm resulted in superhuman play; however, on games like Montezuma’s Revenge, where rewards are extremely sparse, DQN (and its variants [25], [26], [15], [12]) with -greedy exploration failed to achieve scores even at the level of a novice human. Similarly, in benchmarking deep reinforcement learning for continuous control, Duan et al.[5] found that policy optimization algorithms that explored by acting according to the current stochastic policy, including REINFORCE and Trust Region Policy Optimization (TRPO), could succeed across a diverse slate of simulated robotics control tasks with well-defined, non-sparse reward signals (like rewards proportion",Novelty or Surprise | Unifying Count-Based Exploration and Intrinsic Motivation | R-max – A General Polynomial Time Algorithm for Near-Optimal Reinforcement Learning | Benchmarking Deep Reinforcement Learning for Continuous Control | VIME Open-Source Code | Variational Information Maximizing Exploration | Bayesian surprise attracts human attention | Near-optimal Regret Bounds for Reinforcement Learning | Near Optimal Reinforcement Learning in Polynomial Time | Exploration in model-based reinforcement learning by empirically estimating learning progress | Asynchronous Methods for Deep Reinforcement Learning | Human-level control through deep reinforcement learning | Variational Information Maximisation for Intrinsically Motivated Reinforcement Learning | Massively Parallel Methods for Deep Reinforcement Learning | Action- Conditional Video Prediction using Deep Networks in Atari Games | How can we define intrinsic motivation | PAC Optimal Exploration in Continuous Space Markov Decision Processes | Curious Model-Building Control Systems | Trust Region Policy Optimization | High- Dimensional Continuous Control Using Generalized Advantage Estimation | Incentivizing Exploration In Reinforcement Learning | Reinforcement driven information acquisition in non-deterministic environments | Planning to be surprised: Optimal Bayesian exploration in dynamic environments | Deep Reinforcement Learning with Double Q-learning,iclr,010
534.pdf.json,,,"A general class of coefficients of divergence of one distribution from another | Multi-task learning for HIV therapy screening | Loss functions for binary class probability estimation and classification: Structure and applications | Fast two-sample testing with analytic representations of probability measures | An overview of bilevel optimization | Introduction to derivative-free optimization, volume | Approximating likelihood ratios with calibrated discriminative classifiers | Task specific adversarial cost function | Information-type measures of difference of probability distributions and indirect observations | Non-uniform random variate generation | Monte Carlo methods of inference for implicit statistical models | Training generative neural networks via maximum mean discrepancy optimization | Asymptotic properties of approximate Bayesian computation | Learning with a Wasserstein loss | Stochastic gradient estimation | The estimation of the gradient of a density function, with applications in pattern recognition | Monte Carlo methods in financial engineering, volume 53 | Strictly proper scoring rules, prediction, and estimation | Generative adversarial nets | Bayesian optimization for likelihood-free inference of simulatorbased statistical models | Noise-contrastive estimation of unnormalized statistical models, with applications to natural image statistics | Statistical inference of intractable generative models via classification | Generalized method of moments | The elements of statistical learning. Springer, pp 495–497 | How (not) to train your generative model: Scheduled sampling, likelihood, adversary | Bayes factors | Generative moment matching networks | divergences: Sufficiency, deficiency and testing of hypotheses | Revisiting classifier two-sample tests for GAN evaluation and causal discovery | Unifying non-maximum likelihood learning objectives with minimum KL contraction | Approximate Bayesian computational methods | Markov chain Monte Carlo without likelihoods | Linking losses for density ratio and class-probability estimation | Divergence measures and message passing | Computing likelihood functions for high-energy physics experiments when distributions are defined by simulators with nuisance parameters | GAN: Training generative neural samplers using variational divergence minimization | Empirical likelihood ratio confidence intervals for a single functional | Inferences for case-control and semiparametric two-sample density ratio models | Unsupervised representation learning with deep convolutional generative adversarial networks | Information, divergence and risk for binary experiments | Improved techniques for training GANs | Amortised MAP inference for image super-resolution | On integral probability metrics, φ-divergences and binary classification | Density-ratio matching under the Bregman divergence: a unified framework of density-ratio estimation | Density ratio estimation in machine learning | Density-difference estimation | Generative adversarial nets from a density ratio estimation perspective | Energy-based generative adversarial network",iclr,010
535.pdf.json,,"Accurately understanding the fast-growing number of videos poses a significant challenge for computer vision and machine learning. An important component of video analyasis involves generating natural-language video descriptions, i.e., video captioning. Inspired by the successful deployment of the encoder-decoder framework used in machine translation (Cho et al., 2014) and image caption generation (Vinyals et al., 2015; Pu et al., 2016; Gan et al., 2017), most recent work on video captioning (Venugopalan et al., 2015; Yu et al., 2016) employs a 2-dimentional (2D) or 3-dimentional (3D) Convolutional Neural Network (CNN) as an encoder, mapping an input video to a compact feature vector representation; a Recurrent Neural Network (RNN) is typically employed as a decoder, unrolling this feature vector to generate a sequence of words of arbitrary length. Despite achieving encouraging successes in video captioning, previous models suffer from important limitations. First, the rich contents in an input video is often compressed to a single compact feature vector for caption generation; this approach is prone to miss detailed spatiotemporal information. Secondly, the video feature representations are typically extracted from the output of a CNN at a manually-selected fixed layer, which is incapable of modeling rich context-aware semantics that requires focusing on different abstraction levels of features. As investigated in Zeiler & Fergus (2014); Simonyan et al. (2014), the features from layers at or near the top of a CNN tends to focus on global semantic discriminative visual percepts, while low-layer feature provides more local, fine-grained information. It is desirable to select/weight features from different CNN layers ∗Most of this work was done when the author was an intern at NEC Labs America. adaptively when decoding a caption, selecting different levels of feature abstraction by sequentially emphasizing features from different CNN layers. In addition to focusing on","Meteor: An automatic metric for mt evaluation with improved correlation with human judgments | Collecting highly parallel data for paraphrase evaluation | Learning phrase representations using rnn encoder-decoder for statistical machine translation | Semantic compositional networks for visual captioning | Long short-term memory | Large-scale video classification with convolutional neural networks | Recurrent models of visual attention | Bleu: a method for automatic evaluation of machine translation | Variational autoencoder for deep learning of images, labels and captions | Deep inside convolutional networks: Visualising image classification models and saliency maps | Learning spatiotemporal features with 3d convolutional networks | Cider: Consensus-based image description evaluation | Sequence to sequence-video to text | Show and tell: A neural image caption generator | Show, attend and tell: Neural image caption generation with visual attention | Video paragraph captioning using hierarchical recurrent neural networks | Visualizing and understanding convolutional networks",iclr,010
536.pdf.json,ON ROBUST CONCEPTS AND SMALL NEURAL NETS,"The universal approximation theorem of Hornik et al. (1989) and Cybenko (1992) provides a foundation to the mathematical theory of artificial neural networks. It states that any continuous function on a compact subset of the Euclidean space can be approximated arbitrarily well by a feed-forward artificial neural network with only one hidden layer containing finitely many neurons, under mild assumptions on the activation function. In such neural networks, each node applies an activation function to a weighted linear combination of its inputs, and the above theorem holds true for many different choices of activation functions as shown by Hornik (1991). However, the universal approximation theorem and its quantitative improvements by Barron (1993) and others have certain limitations, namely, they do not provide reasonable, practical bounds or efficient learning algorithms for the parameters of these neural networks, that is, the number of neurons in the hidden layer and the size of weights used in the linear combinations. For a detailed survey of these results in approximation theory, we point the reader to Pinkus (1999). In practice, we notice that even moderate-sized neural networks can be trained to learn various natural concepts in computer vision tasks, and the typical rules of thumb followed for their model and size selection are usually guided by the domain knowledge, the learning algorithm, and the available computational resources more than any theoretical bounds; see Simard et al. (2003). The known theoretical bounds are either based on the Network Information Criterion (NIC) by Amari (1998), which is a generalization of Akaike Information Criterion (AIC) by Akaike (1974) used in statistical inference, or based on the Vapnik-Chervonenkis dimension; see Baum & Haussler (1989), Bartlett (1993), Maass (1995), Karpinski & Macintyre (1997). These bounds do not adequately explain the observed efficiency of learning many natural concepts in practice. ∗This work was ","A new look at the statistical model identification | How to refute a random CSP | The handbook of brain theory and neural networks. chapter Learning and Statistical Inference, pp. 522–526 | Learning polynomials with neural networks | Provable bounds for learning some deep representations | An algorithmic theory of learning: Robust concepts and random projection | Universal approximation bounds for superpositions of a sigmoidal function | Vapnik-chervonenkis dimension bounds for two- and three-layer networks | Hardness results for neural network approximation problems | What size net gives valid generalization | Random search for hyper-parameter optimization | Cryptographic primitives based on hard learning problems | On the distribution of the fourier spectrum of Boolean functions | Approximation by superpositions of a sigmoidal function | A PTAS for agnostically learning halfspaces | Complexity theoretic limitations on learning halfspaces | From average case complexity to improper learning | Nearly optimal solutions for the chow parameters problem and low-weight approximation of halfspaces | Backpropagation neural nets with one and two hidden layers | Noise Stable Halfspaces are Close to Very Small Juntas | Optimal bounds on approximation of submodular and xos functions by juntas | Simulating threshold circuits by majority circuits | Majority gates vs. general weighted threshold | Hardness of learning halfspaces with noise | Hardness of learning halfspaces with noise | Kernel methods in machine learning | Computing and Combinatorics | Approximation capabilities of multilayer feedforward networks | Multilayer feedforward networks are universal approximators | Noise-resistant boolean functions are juntas | Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm | Vapnik-chervonenkis dimension of neural nets | Perceptrons - an introduction to computational geometry | Noise Stability and Correlation with Half Spaces | The chow parameters problem | Noise stability of weighted majority | Approximation theory of the mlp model in neural networks | Best practices for convolutional neural networks applied to visual document analysis | Discrete Neural Computation: A Theoretical Foundation. Prentice-Hall, Inc | Finding correlations in subquadratic time, with applications to learning parities and the closest pair problem | A neuroidal architecture for cognitive computation",iclr,010
537.pdf.json,RENDERGAN: GENERATING REALISTIC LABELED DATA,"When an image is taken from a real world scene, many factors determine the final appearance: background, lighting, object shape, position and orientation of the object, the noise of the camera sensor, and more. In computer vision, high-level information such as class, shape, or pose is reconstructed from raw image data. Most real-world applications require the reconstruction to be invariant to noise, background, and lighting changes. In recent years, deep convolutional neural networks (DCNNs) advanced to the state of the art in many computer vision tasks (Krizhevsky et al., 2012; He et al., 2015; Razavian et al., 2014). More training data usually increases the performance of DCNNs. While image data is mostly abundant, labels for supervised training must often be created manually – a time-consuming and tedious activity. For complex annotations such as human joint angles, camera viewpoint or image segmentation, the costs of labeling can be prohibitive. In this paper, we propose a method to drastically reduce the costs of labeling such that we can train a model to predict even complex sets of labels. We present a generative model that can sample from the joint distribution of labels and data. The training procedure of our model does not require any manual labeling. We show that the generated data is of high quality and can be used to train a model in a supervised setting, i.e. a model that maps from real samples to labels, without using any manually labeled samples. We propose two modifications to the recently introduced GAN framework (Goodfellow et al., 2014). First, a simple 3D model is embedded into the generator network to produce samples from corresponding input labels. Second, the generator learns to add missing image characteristics to the model output using a number of parameterized augmentation functions. In the adversarial training we leverage large amounts of unlabeled image data to learn the particular form of blur, lighting, background and image detail. By","The laplacian pyramid as a compact image code | Infogan: Interpretable representation learning by information maximizing generative adversarial nets | Imagenet: A large-scale hierarchical image database | Deep generative image models using a laplacian pyramid of adversarial networks | Learning to generate chairs with convolutional neural networks | Rich feature hierarchies for accurate object detection and semantic segmentation | Generative adversarial nets | Deep learning. Book in preparation for MIT Press, 2016 | Deep residual learning for image recognition | Adam: A method for stochastic optimization | Learning Multiple Layers of Features | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | Fully Convolutional Networks for Semantic Segmentation | Deep exemplar 2d-3d detection by adapting from real to rendered views | Learning Deep Object Detectors from 3D Models | Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks | Cnn features offthe-shelf: an astounding baseline for recognition | Playing for data: Ground truth from computer games | The synthia dataset: A large collection of synthetic images for semantic segmentation of urban scenes | Unsupervised and semi-supervised learning with categorical generative adversarial networks | Render for cnn: Viewpoint estimation in images using cnns trained with rendered 3d model views | Generative image modeling using style and structure adversarial networks | Automatic methods for long-term tracking and the detection and decoding of communication dances in honeybees | Beyond pascal: A benchmark for 3d object detection in the wild | How transferable are features in deep neural networks",iclr,010
538.pdf.json,,"Representing and learning knowledge about the world requires not only learning declarative knowledge about facts but also procedural knowledge, knowledge about how to do things, which can be complex yet difficult to articulate explicitly. The goal of building systems that learn procedural knowledge has motivated many recent architectures for learning representations of algorithms (Graves et al., 2014; Reed & de Freitas, 2016; Kaiser & Sutskever, 2016). These methods generally learn from execution traces of programs (Reed & de Freitas, 2016) or input-output pairs generated from a program (Graves et al., 2014; Kurach et al., 2015; Riedel et al., 2016; Grefenstette et al., 2015; Neelakantan et al., 2015). However, the recursive abstraction that is central to procedural knowledge is perhaps most naturally represented not by abstract models of computation, as in that work, but by symbolic representations that have syntactic structure, such as logical expressions and source code. One type of evidence for this claim is the simple fact that people communicate algorithms using mathematical formulae and pseudocode rather than Turing machines. Yet, apart from some notable exceptions (Alemi et al., 2016; Piech et al., 2015; Allamanis et al., 2016; Zaremba & Sutskever, 2014), symbolic representations of procedures have received relatively little attention within the machine learning literature as a source of information for representing procedural knowledge. In this paper, we address the problem of learning continuous semantic representations (SEMVECs) of symbolic expressions. The goal is to assign continuous vectors to symbolic expressions in such a way that semantically equivalent, but syntactically diverse expressions are assigned to identical (or highly similar) continuous vectors, when given access to a training set of pairs for which semantic equivalence is known. This is an important but hard problem; learning composable SEMVECs of symbolic expressions requires that we le","DeepMath– deep sequence models for premise selection | A convolutional attention network for extreme summarization of source code | Neural machine translation by jointly learning to align and translate | Learning a similarity metric discriminatively, with application to face verification | Transition-based dependency parsing with stack long short-term memory | Learning to transduce with unbounded memory | Ratajszczak, and Gilles Wiber | Inferring algorithmic patterns with stack-augmented recurrent nets | Neural GPUs learn algorithms | Neural random-access machines | Convolutional neural networks over tree structures for programming language processing | Neural programmer: Inducing latent programs with gradient descent | Symbolic processing in neural networks | Learning program embeddings to propagate feedback on student code | Programming with a differentiable forth interpreter | Neural programming language | Practical Bayesian optimization of machine learning algorithms | Semi-supervised recursive autoencoders for predicting sentiment distributions | Semantic compositionality through recursive matrix-vector spaces | Recursive deep models for semantic compositionality over a sentiment treebank | Learning to execute",iclr,010
540.pdf.json,,"Deep convolutional neural networks have continuously demonstrated their excellent performances on diverse computer vision problems. In image classification, the milestones of such networks can be roughly represented by LeNet (LeCun et al., 1989), AlexNet (Krizhevsky et al., 2012), VGG net (Simonyan & Zisserman, 2014), GoogLeNet (Szegedy et al., 2014), and ResNet (He et al., 2015), with networks becoming deeper and deeper. However, the architectures of these network are significantly altered and hence are not backward-compatible. Considering a life-long learning system, it is highly desired that the system is able to update itself from the original version established initially, and then evolve into a more powerful one, rather than re-learning a brand new one from scratch. Network morphism (Wei et al., 2016) is an effective way towards such an ambitious goal. It can morph a well-trained network to a new one with the knowledge entirely inherited, and hence is able to update the original system to a compatible and more powerful one based on further training. Network morphism is also a performance booster and architecture explorer for convolutional neural networks, allowing us to quickly investigate new models with significantly less computational and human resources. However, the network morphism operations proposed in (Wei et al., 2016), including depth, width, and kernel size changes, are quite primitive and have been limited to the level of layer in a network. For practical applications where neural networks usually consist of dozens or even hundreds of layers, the morphing space would be too large for researchers to practically design the architectures of target morphed networks, when based on these primitive morphing operations only. Different from previous work, we investigate in this research the network morphism from a higher level of viewpoint, and systematically study the central problem of network morphism on the module level, i.e., whether and how a convolu",Do deep nets really need to be deep | Net2net: Accelerating learning via knowledge transfer | Deep residual learning for image recognition | Identity mappings in deep residual networks | Distilling the knowledge in a neural network | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Learning multiple layers of features from tiny | Imagenet classification with deep convolutional neural networks | Backpropagation applied to handwritten zip code recognition | Gradient-based learning applied to document recognition | Fitnets: Hints for thin deep nets | Imagenet large scale visual recognition challenge | Very deep convolutional networks for large-scale image recognition | Going deeper with convolutions | Rethinking the inception architecture for computer vision,iclr,010
542.pdf.json,,,"Programmable reinforcement learning agents | State abstraction for programmable reinforcement learning agents | Alignment-based compositional semantics for instruction following | Learning to compose neural networks for question answering | Weakly supervised learning of semantic parsers for mapping instructions to actions. Transactions of the Association for Computational Linguistics | The option-critic architecture | Hierarchical reinforcement learning based on subgoal discovery and subpolicy specialization | Reinforcement learning for mapping instructions to actions | Learning to interpret natural language navigation instructions from observations | Hierarchical relative entropy policy search | Learning modular neural network policies for multi-task and multi-robot transfer | Variance reduction techniques for gradient estimates in reinforcement learning | Using motion primitives in probabilistic sample-based planning for humanoid robots | Discovering hierarchy in reinforcement learning with HEXQ | A neural network for factoid question answering over paragraphs | Near-optimal reinforcement learning in polynomial time | Building portable options: Skill transfer in reinforcement learning | Robot learning from demonstration by constructing skill trees | Hierarchical deep reinforcement learning: Integrating temporal abstraction and intrinsic motivation | Concurrent hierarchical reinforcement learning | Listen, attend, and walk: Neural mapping of navigational instructions to action sequences | Q-cutdynamic discovery of sub-goals in reinforcement learning | Neural programmer: Inducing latent programs with gradient descent | Reinforcement learning with hierarchies of machines | Temporal abstraction in reinforcement learning | Neural programmer-interpreters | Highdimensional continuous control using generalized advantage estimation | Semantic compositionality through recursive matrix-vector spaces | Learning options in reinforcement learning | Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning | Understanding natural language commands for robotic navigation and mobile manipulation | Strategic attentive writer for learning macro-actions | Learning to follow navigational directions | Simple statistical gradient-following algorithms for connectionist reinforcement learning",iclr,010
543.pdf.json,ING PLATFORM AND APPLICATION TO DISTRIBUTED TRAINING,"Recently, machine learning, which uses big data derived from user activity on websites, images and videos is increasingly getting attention. Deep learning is at the center of that attention. Conventional machine learning techniques have required hand-crafted features specialized to a particular domain such as image or voice. In contrast, deep learning has a hugely important benefit that can illustrate data flow from raw data to an objective value in a single neural network and can train thoroughly using those data. In the computer vision domain, a team of Hinton (Krizhevsky et al., 2012) achieved outstanding classification accuracy using deep learning in an object classification competition ILSVRC2012 (Russakovsky et al., 2015). In the subsequent years’ competitions, deep-learningbased methods evolved continually and exhibited superior performance (Simonyan & Zisserman, 2014a; Szegedy et al., 2014; He et al., 2016). Convolutional neural networks (CNNs) trained for ILSVRC object classification are helpful for improving classification accuracy for scene recognition and video recognition by functioning as a feature extractor or being fine-tuned (Zhou et al., 2014; Simonyan & Zisserman, 2014b). Moreover, application is beginning to emerge in other areas such as medical imaging (Tajbakhsh et al., 2016). Software platforms for deep learning are expected to play an important role in accelerating a wide range of research efforts and applications. Although deep learning achieved significant recognition accuracy that cannot be achieved using conventional methods, the number of parameters that can be trained is greater, resulting in requests for huge amounts of training data. This shortcoming not only increases data collection costs but also increases computational costs of training larger parameters with larger data. Moreover, trialand-error must be undertaken to ascertain a good neural network structure; thereby higher costs become necessary. What resolved this computational","SETI@home: an experiment in public-resource computing | Large scale distributed deep networks | 8-Bit Approximations for Parallelism in Deep Learning | Deep Residual Learning for Image Recognition | Caffe: Convolutional Architecture for Fast Feature Embedding | Unwitting Distributed Genetic Programming via Asynchronous JavaScript and XML | Learning Multiple Layers of Features from Tiny Images | ImageNet Classification with Deep Convolutional Neural Networks | maxDNN: An Efficient Convolution Kernel for Deep Learning with Maxwell GPUs | Gradient-based learning applied to document recognition | The mnist database of handwritten digits, 1998b. http://yann.lecun.com/exdb/mnist | Asynchronous distributed genetic algorithms with javascript and json | Implementation of a practical distributed calculation system with browsers and javascript, and application to distributed deep learning | MILJS : Brand new javascript libraries for matrix calculation and machine learning | ImageNet Large Scale Visual Recognition Challenge | Very Deep Convolutional Networks for Large-Scale Image Recognition | Two-stream convolutional networks for action recognition in videos | Convolutional Neural Networks for Medical Image Analysis: Full Training or Fine Tuning | Learning Deep Features for Scene Recognition using Places Database",iclr,010
544.pdf.json,A DIFFERENTIABLE PHYSICS ENGINE,"To solve tasks efficiently, robots require an optimization of their control system. This optimization process can be done in automated testbeds (Degrave et al., 2015), but typically these controllers are optimized in simulation. Standard methods to optimize these controllers include particle swarms, reinforcement learning, genetic algorithms and evolutionary strategies. These are all derivative-free methods. A recently popular alternative approach is to use deep Q-learning, a reinforcement learning algorithm. This method requires a lot of evaluations in order to train the many parameters (Levine et al., 2016). However, deep learning experience has taught us that optimizing with a gradient is often faster and more efficient. This fact is especially true when there are a lot of parameters, as is common in deep learning. However, in the optimization processes for control systems, the robot is almost exclusively treated as a non-differentiable black box. The reason for this is that the robot in hardware is not differentiable, nor are current physics engines able to provide the gradient of the robot models. The resulting need for derivative-free optimization approaches limits both the optimization speed and the number of parameters in the controllers. Recent physics engines, such as mujoco (Todorov et al., 2012), can derive gradients through the model of a robot but rely on a finite difference method to approximate the gradient. Evaluating finite difference approximations, however, requires the same number of model evaluations as the number of states with respect to which is differentiated. Additionally, the gradient is an estimation. In this paper, we suggest an alternative approach, by introducing a differentiable physics engine with analytical gradients. This idea is not novel. It has been done before with spring-damper models in 2D and 3D (Hermans et al., 2014). This technique is also similar to adjoint optimization, a method widely used in various applications such ","TensorFlow: Large-scale machine learning on | Theano: A Python framework for fast computation of mathematical expressions | Modeling and solving constraints | Constraints derivation for rigid body simulation in 3D | Evolved electrophysiological soft robots | Transfer from simulation to real world through learning deep inverse dynamics model | Transfer learning of gaits on a quadrupedal robot | Comparing trotting and turning strategies on the quadrupedal oncilla robot | Spatial chirp-Z transformer networks | A learned representation for artistic style. CoRR, abs/1610.07629 | Simulation tools for model-based robotics: Comparison of bullet, havok, mujoco, ode and physx | Generative adversarial nets | The cma evolution strategy: a comparing review | Automated design of complex dynamic systems | Long short-term memory | Approximating polyhedra with spheres for time-critical collision detection | An aerodynamic optimization method based on the inverse problem adjoint equations | Spatial transformer networks | A general optimization method using adjoint equation for solving multidimensional inverse heat conduction | Caffe: Convolutional architecture for fast feature embedding | Perceptual losses for real-time style transfer and super-resolution | A gauss-seidel like algorithm to solve frictional contact problems. Computer methods in applied mechanics and engineering, 155(1):31–47 | Adam: A method for stochastic optimization | Variational policy search via trajectory optimization | Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection | V-clip: Fast and robust polyhedral collision detection | Combining the benefits of function approximation and trajectory optimization | How the body shapes the way we think: a new view of intelligence | Direction cosine matrix IMU: Theory | Evolving 3d morphology and behavior by competition | Nonlinear black-box modeling in system identification: a unified overview | Towards dynamically running quadruped robots: performance, scaling, and comparison | An implicit time-stepping scheme for rigid body dynamics with coulomb friction | Training recurrent neural networks | Mujoco: A physics engine for model-based control | Digital control: a state-space approach, volume 196",iclr,010
545.pdf.json,,"The depth of state-of-the-art convnets is a double-edged sword: it yields both nonlinearity for sophisticated discrimination and nonconvexity for frustrating optimization. The established training procedure for ILSVRC classification cycles through the million-image training set more than fifty times, requiring substantial stochasticity, data augmentation, and hand-tuned learning rates. On today’s consumer hardware, the process takes several days. However, performance depends heavily on hyperparameters, which include the number and connections of neurons as well as optimization details. Unfortunately, the space of hyperparameters is unbounded, and each configuration of hyperparameters requires the aforementioned training procedure. It is no surprise that large organizations with enough computational power to conduct this search dominate this task. Yet mastery of object recognition on a static dataset is not enough to propel robotics and internetscale applications with ever-growing instances and categories. Each time the training set is modified, the convnet must be retrained (“fine-tuned”) for optimum performance. If the training set grows linearly with time, the total training computation grows quadratically. We propose the Compositional Kernel Machine (CKM), a kernel-based visual classifier that has the symmetry and compositionality of convnets but with the training benefits of instance-based learning (IBL). CKMs branch from the original instance-based methods with virtual instances, an exponential set of plausible compositions of training instances. The first steps in this direction are promising compared to IBL and deep methods, and future work will benefit from over fifty years of research into nearest neighbor algorithms, kernel methods, and neural networks. In this paper we first define CKMs, explore their formal and computational properties, and compare them to existing kernel methods. We then propose a key contribution of this work: a sum-product function (S","TensorFlow: Large-scale machine learning on heterogeneous systems | Scaling learning algorithms towards AI | In defense of nearest-neighbor based image classification | Choosing multiple parameters for support vector machines | On the algorithmic implementation of multiclass kernel-based vector machines | Pattern Classification | The sum-product theorem: A foundation for learning tractable models | Syntactic Methods in Pattern Recognition, volume 112 | Spherical hashing | The Cerebellum: Brain for an Implicit Self | Learning methods for generic object recognition with invariance to pose and lighting | Efficient algorithms for minimizing cross validation error | On estimation of characters obtained in statistical procedure of recognition | Fast approximate nearest neighbors with automatic algorithm configuration | Scikit-learn: Machine learning in Python | A neural network classifier for the I1000 | ORB: An efficient alternative to SIFT or SURF | Deep Boltzmann machines | Incorporating invariances in support vector learning machines | Efficient pattern recognition using a new transformation distance | Rethinking the inception architecture for computer vision | Small codes and large image databases for recognition",iclr,010
546.pdf.json,EXTRAPOLATION AND LEARNING EQUATIONS,"The quality of a model is typically measured by its ability to generalize from a training set to previously unseen data from the same distribution. In regression tasks generalization essentially boils down to interpolation if the training data is sufficiently dense. As long as models are selected correctly, i. e. in a way to not overfit the data, the regression problem is well understood and can – at least conceptually – be considered solved. However, when working with data from real-world devices, e. g. controlling a robotic arm, interpolation might not be sufficient. It could happen that future data lies outside of the training domain, e. g. when the arm is temporarily operated outside of its specifications. For the sake of robustness and safety it is desirable in such a case to have a regression model that continues to make good predictions, or at least does not fail catastrophically. This setting, which we call extrapolation generalization, is the topic of the present paper. We are particularly interested in regression tasks for systems that can be described by real-valued analytic expression, e. g. mechanical systems such as a pendulum or a robotic arm. These are typically governed by a highly nonlinear function but it is nevertheless possible, in principle, to infer their behavior on an extrapolation domain from their behavior elsewhere. We make two main contributions: 1) a new type of network that can learn analytical expressions and is able to extrapolate to unseen domains and 2) a model selection strategy tailored to the extrapolation setting. The following section describes the setting of regression and extrapolation. Afterwards we introduce our method and discuss the architecture, its training, and its relation to prior art. We present our results in the Section Experimental evaluation and close with conclusions.","Support vector regression | A theory of learning from different domains | Learning deep architectures for AI | Representation learning: A review and new perspectives | Neural networks for pattern recognition | Radial basis functions, multi-variable functional interpolation and adaptive networks | X-ray transition energies: new approach to a comprehensive evaluation | Product units: A computationally powerful and biologically plausible extension to backpropagation networks | Nonparametric curve estimation from time series, volume 60 | Adam: A method for stochastic optimization | Predicting time series with support vector machines | Causal discovery with continuous additive noise models | Dataset shift in machine learning | Distilling free-form natural laws from experimental data | The pi-sigma network : An efficient higher-order neural network for pattern classification and function approximation | A tutorial on support vector regression | A general regression neural network | Regression shrinkage and selection via the lasso | Extrapolation, interpolation, and smoothing of stationary time series, volume 2",iclr,010
548.pdf.json,CHARGED POINT NORMALIZATION AN EFFICIENT SOLUTION TO THE SADDLE POINT PROBLEM,"Recently more and more attention has focused on the problem of saddle points in very high dimensional non-convex optimization. Saddle points represent points in the optimization problem where the first order gradients are all zero, but the stationary point is neither a maxima or a minima. The saddle point of a function can be confirmed by using the eigenvalues of Hessian matrix. If the set of eigenvalues contains at least one negative eigenvalue and at least one positive eigenvalue the point is said to be a saddle point. One way to analyze the prevalence of saddle point is to assign a joint probability density to the eigenvalues of the Hessian matrix at a critical point. • If the eigenvalues are all negative, then the critical point is a local maximum • If the eigenvalues are all positive, then the critical point is a local minimum. • If the eigenvalues contain at least one positive and at least one negative eigenvalue then the point is a saddle point. If p(λ1, λ2, ..., λn) is the joint probability density function then the probability that the Hessian matrix resembles a saddle point is, given that the Hessian is not singular is: 1− ∫ ∞ 0 ∫ ∞ 0 ... ∫ ∞ 0 p(λ1, λ2, ..., λn)dλ1dλ2...dλn − ∫ 0 −∞ ∫ 0 −∞ ... ∫ 0 −∞ p(λ1, λ2, ..., λn)dλ1dλ2...dλn (1) Another way to interpret the expression above is to realize that each of the two n-integrals represents the joint density summation of the two hyper-cubes, one in the direction of all the positive axis, and the other in all the negative axis. Each respectively representing minimas and maximas. Theorem 1 The space of eigenvalues of a non-singular Hessian matrix that represent minimas and maximas in comparison to the total space, decreases by 2n asymptotically. The amount of unique hypercubes starting from the origin and spanning along the axis is 2n. The amount of hypercubes representing minimas and maximas is two. Therefore the fraction of the space that contains the eigenvalues that would indicate either a minima or a maxim",Theano: new features and speed improvements | Empirical evaluation of gated recurrent neural networks on sequence modeling | Identifying and attacking the saddle point problem in high-dimensional non-convex optimization | Adaptive subgradient methods for online learning and stochastic optimization | Delving deep into rectifiers: Surpassing human-level performance on imagenet classification | Improving neural networks by preventing co-adaptation of feature detectors | Long short-term memory | Matplotlib: A 2d graphics environment | Adam: A method for stochastic optimization | A method of solving a convex programming problem with convergence rate O(1/sqr(k)) | Dynamics of on-line gradient descent learning for multilayer neural networks | Bandwidth Selection in Kernel Density Estimation: A Review | ADADELTA: an adaptive learning rate method,iclr,010
549.pdf.json,ENERGY-BASED SPHERICAL SPARSE CODING,"Sparse coding has been widely studied as a representation for images, audio and other vectorial data. This has been a highly successful method that has found its way into many applications, from signal compression and denoising (Donoho, 2006; Elad & Aharon, 2006) to image classification (Wright et al., 2009), to modeling neuronal receptive fields in visual cortex (Olshausen & Field, 1997). Since its introduction, subsequent works have brought sparse coding into the supervised learning setting by introducing classification loss terms to the original formulation to encourage features that are not only able to reconstruct the original signal but are also discriminative (Jiang et al., 2011; Yang et al., 2010; Zeiler et al., 2010; Ji et al., 2011; Zhou et al., 2012; Zhang et al., 2013). While supervised sparse coding methods have been shown to find more discriminative features leading to improved classification performance over their unsupervised counterparts, they have received much less attention in recent years and have been eclipsed by simpler feed-forward architectures. This is in part because sparse coding is computationally expensive. Convex formulations of sparse coding typically consist of a minimization problem over an objective that includes a least-squares (LSQ) reconstruction error term plus a sparsity inducing regularizer. Because there is no closed-form solution to this formulation, various iterative optimization techniques are generally used to find a solution (Zeiler et al., 2010; Bristow et al., 2013; Yang et al., 2013; Heide et al., 2015). In applications where an approximate solution suffices, there is work that learns non-linear predictors to estimate sparse codes rather than solve the objective more directly (Gregor & LeCun, 2010). The computational overhead for iterative schemes becomes quite significant when training discriminative models due to the demand of processing many training examples necessary for good performance, and so sparse coding ha",Fast convolutional sparse coding | Look and think twice: Capturing top-down visual attention with feedback convolutional neural networks | Compressed sensing | Image denoising via sparse and redundant representations over learned dictionaries | Learning fast approximations of sparse coding | Fast and flexible convolutional sparse coding | Hierarchical discriminative sparse coding via bidirectional connections | Learning a discriminative dictionary for sparse coding via label consistent K-SVD | Learning convolutional feature hierarchies for visual recognition | Adam: A method for stochastic optimization | Learning multiple layers of features from tiny images | Classification using discriminative restricted boltzmann machines | A tutorial on energy-based learning | Bi-directional representation learning for multi-label classification | Sparse coding with an overcomplete basis set: A strategy employed by v1 | Histograms of sparse codes for object detection | Sparse coding via thresholding and local competition in neural circuits | Understanding and improving convolutional neural networks via concatenated rectified linear units | Striving for simplicity: The all convolutional net | Convolutional networks and learning invariant to homogeneous multiplicative scalings | Matconvnet – convolutional neural networks for matlab | Robust face recognition via sparse representation | Fastminimization algorithms for robust face recognition | Supervised translation-invariant sparse coding | Discriminative tensor sparse coding for image classification | Learning inter-related visual dictionary for object recognition,iclr,010
550.pdf.json,,"Auto-encoders (AE)s are unsupervised learning algorithms that capture structure in data by finding an representation of the inputs (encoding) from which they can be recovered at least approximately. By learning a transformation G (encoding) from the input x ∈ X to z = G(x) ∈ Z , the autoencoder tries to capture the structure of the input. To guarantee the transformation G preserves the information about x, a decoder G̃−1 (an approximate inverse map) is also learned such that a measure of fidelity E[D(X, X̃)] between the input and its reconstruction is optimized. Learning non-linear encoding and decoding mappings has proved to be a non-trivial problem. For example, there is no consensus on what the dimensionality of the encoding space should be. On one side of the spectrum, AE architectures such as bottle-neck networks, map input data x ∈ X ⊆ Rd to a lower dimensional space Z ⊆ Rp, and then map it back to input space X through dimensionality expansion. The intuition behind bottleneck networks is that the lower dimensional space forces the encoder to capture meaningful relations between the variables in the input space. While this is clear when one is restricted to linear mappings, the problem becomes less well-understood if nonlinear mappings are allowed. The idea of using a low dimensional latent space has been recently employed in the context of modern generative models such as variational auto-encoders (VAE)s Kingma & Welling (2013) and generative adversarial networks (GAN)s Goodfellow et al. (2014). On the other hand, AE architectures can contain over-complete representations where inputs are mapped to a high dimensional encoding spaces; much higher than the dimensionality of the input space (dim(X ) < dim(Z)). Over-complete representations have proved very useful in supervised learning. However, effective learning of this high dimensional mappings relies on specialized mechanisms that attempt to avoid trivial solutions or on the large amount of constraint impose",Generative adversarial nets | Auto-encoding variational bayes | Winner-take-all autoencoders. In Advances in Neural Information Processing Systems | Efficient learning of sparse representations with an energy-based model | Higher order contractive auto-encoder | Contractive autoencoders: Explicit invariance during feature extraction | Extracting and composing robust features with denoising autoencoders,iclr,010
551.pdf.json,,,Lasagne: First release | V-REP: a Versatile and Scalable Robot Simulation Framework | Neural Turing Machines | Backprop KF: Learning Discriminative Deterministic State Estimators | Deep Residual Learning for Image Recognition | Long short-term memory | Learning state representations with robotic priors | Towards Combining Robotic Algorithms and Machine Learning: End-To-End Learnable Histogram Filters. In Workshop on Machine Learning Methods for High-Level Cognitive Capabilities in Robotics 2016 | Guided Policy Search | Rectified linear units improve restricted boltzmann machines | Model learning for robot control: a survey | Neural Programmer-Interpreters | A Physics-Based Model Prior for Object-Oriented MDPs | Mastering the game of Go with deep neural networks and tree search | Value Iteration Networks | Probabilistic Robotics | Backpropagation through time: what it does and how to do it | Multi-view Self-supervised Deep Learning for 6d Pose Estimation in the Amazon Picking Challenge,iclr,010
552.pdf.json,ROTATION PLANE DOUBLY ORTHOGONAL RECUR-,"Deep Neural Networks have shown increasingly impressive performance on a wide variety of practical tasks. Recurrent Neural Networks (RNNs) are powerful sequence modeling tools that have found successful applications in speech recognition, natural language processing, image captioning, and many more (Sutskever et al., 2014; Bahdanau et al., 2014; Wu et al., 2016; Donahue et al., 2015; Karpathy & Li, 2015; Luong et al., 2014). One fundamental problem with RNNs is the so called vanishing and exploding gradients problem (Hochreiter, 1991; Bengio, 1994; Hochreiter et al., 2001). These problems occur when training RNNs using gradient descent to model long sequences where the gradient magnitude either goes towards zero or infinity, respectively, as the length of the sequence increases. Several heuristics have been proposed to alleviate these problems. The Long Short Term Memory (LSTM) in Hochreiter et al. (1997) and Gated Recurrent Units (GRU) in Cho et al. (2014) have been incredibly successful recurrent transition architectures to model complicated dependencies for sequences up to several hundred timesteps long and are the main RNN architectures in use today. The IRNN model modifies the standard RNN transition to initialize at the identity, which increases the timestep length modeling capability (Le et al., 2015). Stabilizing the forward hidden state norm can have a positive effect on hidden state gradient norm preservation (Krueger & Memisevic, 2015; Ba et al., 2016; Cooijmans et al., 2016). A simple gradient norm clipping during hidden state backpropagation can also help to alleviate the exploding gradient problem for these architectures (Graves, 2013). Recently, there has been a surge of interest in orthogonal and unitary transition architectures. Orthogonal and unitary transitions exactly preserve forward and gradient norms passed through them. Theory developed for the linear neural networks suggests that training time can be vastly shorter when the weight matrices a","Unitary evolution recurrent neural networks | Neural machine translation by jointly learning to align and translate | Learning long-term dependencies with gradient descent is difficult | On the Properties of Neural Machine Translation: EncoderDecoder Approaches | Recurrent batch normalization | Long-term Recurrent Convolutional Networks for Visual Recognition and Description | Geometric Algebra for Computer Science (Revised Edition): An Object-Oriented Approach to Geometry | Generating sequences with recurrent neural networks | Orthogonal RNNs and Long-Memory Tasks, 2016 | Untersuchungen zu dynamischen neuronalen netzen | Long short-term memory | Gradient flow in recurrent nets: the difficulty of learning | Learning Unitary Operators with Help From u(n). jul 2016 | Deep visual-semantic alignments for generating image descriptions | Regularizing RNNs by Stabilizing Activations | A Simple Way to Initialize Recurrent Networks of Rectified Linear Units | End-to-End Training of Deep Visuomotor Policies | Addressing the Rare Word Problem in Neural Machine Translation | Exact solutions to the nonlinear dynamics of learning in deep linear neural networks | Sequence to sequence learning with neural networks",iclr,010
553.pdf.json,,"Recent successes in deep learning can be accredited to the availability of big data that has made the training of large deep neural networks possible. In the conventional memory hierarchy, the training data stored at the low level (e.g., hard disks) need to be moved upward all the way to the CPU registers. As larger and larger data are being used for training large-scale models such as deep networks (LeCun et al., 2015), the overhead incurred by the data movement in the hierarchy becomes more salient, critically affecting the overall computational efficiency and power consumption. ∗To whom correspondence should be addressed. The idea of near-data processing (NDP) (Balasubramonian et al., 2014) is to equip the memory or storage with intelligence (i.e., processors) and let it process the data stored therein firsthand. A successful NDP implementation would reduce the data transfers and power consumption, not to mention offloading the computational burden of CPUs. The types of NDP realizations include processing in memory (PIM) (Gokhale et al., 1995) and in-storage processing (ISP) (Acharya et al., 1998; Kim et al., 2016c; Lee et al., 2016; Choi & Kee, 2015). Despite the potential of NDP, it has not been considered significantly for commercial systems. For PIM, there has been a wide performance gap between the separate processes to manufacture logic and memory chips. For ISP, commercial hard disk drives (HDDs), the mainstream storage devices for a long time, normally have limited processing capabilities due to tight selling prices. Recently, we have seen a resurrection of NDP with renewed interest, which has been triggered by two major factors, one in the application side and the other in the technology side: First, computingand data-intensive deep learning is rapidly becoming the method of choice for various machine learning tasks. To train deep neural networks, a large volume of data is typically needed to ensure performance. Although GPUs and multicore CPUs often pro","Active disks: Programming model, algorithms and evaluation | Near-data processing: Insights from a micro-46 workshop | Energy efficient scale-in clusters with in-storage processing for big-data analytics | Large scale distributed deep networks | Adaptive subgradient methods for online learning and stochastic optimization | Processing in memory: The terasys massively parallel pim array | Deep learning. Book in preparation for MIT Press, 2016 | DFTL: a flash translation layer employing demand-based selective caching of page-level address mappings, volume | Bluedbm: an appliance for big data analytics | Architecture exploration of high-performance pcs with a solid-state disk | A space-efficient flash translation layer for compactflash systems | Nand flash memory with multiple page sizes for high-performance storage devices | An effective pre-store/pre-load method exploiting intra-request idle time of nand flashbased storage | Instorage processing of database scans and joins | The mnist database of handwritten digits | Activesort: Efficient external sorting using active ssds in the mapreduce framework | Machine learning: a probabilistic perspective | Hogwild: A lock-free approach to parallelizing stochastic gradient descent | Best practices for convolutional neural networks applied to visual document analysis | Adadelta: an adaptive learning rate method | Deep learning with elastic averaging sgd | Parallelized stochastic gradient descent",iclr,010
554.pdf.json,,"Deep reinforcement learning has had many practical successes in game playing (Mnih et al. (2015),Silver et al. (2016)) and robotics (Levine & Abbeel (2014)). Our interest is in further exploring these algorithms in the context of environments with sparse rewards and partial observability. To this end, we investigate the use of two methods that are known to mitigate these problems: recurrent networks, which provide a form of memory summarizing past experiences, and eligibility traces, which allow information to propagate over multiple time steps. Eligibility traces have been shown empirically to provide faster learning (Sutton & Barto (2017), in preparation) but their use with deep RL has been limited so far (van Seijen & Sutton (2014), Hausknecht & Stone (2015)). We provide experiments in the Atari domain showing that eligibility traces boost the performance of Deep RL. We also demonstrate a surprisingly strong effect of the optimization method on the performance of the recurrent networks. The paper is structured as follows. In Sec. 2 we provide background and notation needed for the paper. Sec. 3 describes the algorithms we use. In sec. 4 we present and discuss our experimental results. In Sec. 5 we conclude and present avenues for future work.","The arcade learning environment: An evaluation platform for general agents | Generating sequences with recurrent neural networks | Deep recurrent q-learning for partially observable mdps | Long short-term memory | Adam: A method for stochastic optimization | Playing fps games with deep reinforcement learning | Learning neural network policies with guided policy search under unknown dynamics | Human-level control through deep reinforcement learning | Asynchronous methods for deep reinforcement learning | Safe and efficient offpolicy reinforcement learning | Prioritized experience replay | Mastering the game of go with deep neural networks and tree | Reinforcement learning: An introduction, volume 1 | Reinforcement learning: An introduction, In Preparation | Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude | True online td (lambda) | Dueling network architectures for deep reinforcement learning",iclr,010
555.pdf.json,,"Recent advances in deep neural networks (DNNs) have led to breakthroughs in fields such as image classification (He et al., 2015; Krizhevsky et al., 2012) and speech recognition (Yu et al., 2010; Dahl et al., 2012). One reason for the effectiveness of DNNs is their ability to integrate low, mid and highlevel features in a natural way (Zeiler & Fergus, 2014). While recent work such as (Simonyan & Zisserman, 2014) suggests that in many cases the depth of the architecture is crucial, the emergence of more complex architectures (He et al., 2015; Szegedy et al., 2015) demonstrates that depth alone often does not suffice. While DNNs have been highly effective in several domains, their application in additional fields is yet to become widespread. We argue that this is the case due to two challenges. The first is the difficulty of designing effective architectures for domains in which there is little or no previous knowledge on the application of deep learning. Moreover, since designing DNN architectures is not intuitive for most people, this task is likely to fall to experts whose time is in high demand. The second challenge, which is strongly coupled with the first, is the large amounts of computing power and time required to evaluate multiple DNNs. These traits constrain the number of DNN architectures that can be evaluated, thus further limiting one’s ability to explore new architectures or respond to changing circumstances. In this study we explore the possibility of applying architectures that are effective for one domain to another. We do so by generating a large number of architectures and evaluate their performance on multiple tabular datasets in order to determine whether the architectures are transferable. We also explore the feasibility of architectures with parallel layers and compare their effectiveness to that of their “linear” counterparts. Our results show that while architectures do not perform well across multiple datasets, parallel architectures are surp",Learning to learn by gradient descent by gradient descent | Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition | Early stopping as nonparametric variational inference | The weka data mining software: an update | Deep residual learning for image recognition | Non-stochastic best arm identification and hyperparameter optimization | What is the best multi-stage architecture for object recognition | Optimizing recurrent neural networks architectures under time constraints | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | Efficient hyperparameter optimization and infinitely many armed bandits | Gradient-based hyperparameter optimization through reversible learning | No more pesky learning rates | Understanding and improving convolutional neural networks via concatenated rectified linear units | Very deep convolutional networks for large-scale image recognition | Going deeper with convolutions | A perspective view and survey of meta-learning | Roles of pre-training and fine-tuning in context-dependent,iclr,010
556.pdf.json,AN EMPIRICAL ANALYSIS OF DEEP NETWORK LOSS SURFACES,"Deep neural networks are trained by optimizing an extremely high-dimensional loss function with respect to the weights of the network’s linear layers. The objective function minimized is some measure of the error of the network’s predictions based on these weights compared to training data. This loss function is non-convex and has many local minima. These loss functions are usually minimized using first-order gradient descent (Robbins & Monro, 1951; Polyak, 1964) algorithms such as stochastic gradient descent (SGD) (Bottou, 1991). The success of deep learning critically depends on how well we can minimize this loss function, both in terms of the quality of the local minima found and the time to find them. Understanding the geometry of this loss function and how well optimization algorithms can find good local minima is thus of vital importance. Several works have theoretically analyzed and characterized the geometry of deep network loss functions. However, to make these analyses tractible, they have relied on simplifications of the network structures, including that the networks are linear (Saxe et al., 2014), or assuming the path and variable independence of the neural networks (Choromanska et al., 2015). Orthogonally, the performance of various gradient descent algorithms has been theoretically characterized (Nesterov, 1983). Again, these analyses make simplifying assumptions, in particular that the loss function is strictly convex, i.e. there is only a single local minimum. In this work, we empirically investigated the geometry of the real loss functions for state-of-the-art networks and data sets. In addition, we investigated how popular optimization algorithms interact with these real loss surfaces. To do this, we plotted low-dimensional projections of the loss function in subspaces chosen to investigate properties of the local minima selected by different algorithms. We chose these subspaces to address the following questions: • What types of changes to the op","Linear learning: Landscapes and algorithms | Neural networks and principal component analysis: Learning from examples without local minima | Complex-valued autoencoders | Stochastic gradient learning in neural networks | The statistics of critical points of gaussian fields on largedimensional spaces | The convergence of a class of double-rank minimization algorithms 1. general considerations | Coefficients for the study of runge-kutta integration processes | The loss surfaces of multilayer networks | Identifying and attacking the saddle point problem in high-dimensional non-convex optimization | Convergence rates of sub-sampled newton methods | Replica symmetry breaking condition exposed by random matrix calculation of landscape complexity | Understanding the difficulty of training deep feedforward neural networks | Qualitatively characterizing neural network optimization problems | Solving Ordinary Differential Equations I Nonstiff | Delving deep into rectifiers: Surpassing human-level performance on imagenet classification | Long short-term memory | Deep learning without poor local minima | Adam: A method for stochastic optimization | Learning multiple layers of features from tiny images | Network in network | Deep learning via hessian-free optimization | A method of solving a convex programming problem with convergence rate o(1/sqr(k)) | Probabilistic line searches for stochastic optimization | Some methods of speeding up the convergence of iteration methods | A stochastic approximation method | Imagenet large scale visual recognition challenge | Exact solutions to the nonlinear dynamics of learning in deep linear neural networks | Very deep convolutional networks for large-scale image recognition | No bad local minima: Data independent training error guarantees for multilayer neural networks | On the importance of momentum and initialization in deep learning | Local minima in training of deep networks | Rmsprop gradient optimization. In Neural Networks for Machine Learning slide: http://www.cs.toronto.edu/t̃ijmen/csc321/slides/lecture slides lec6.pdf | Adaptive deconvolutional networks for mid and high level feature learning | 2015) introduced the idea of visualizing 1D subspace of the loss surface between the parameters. Here, we propose to visualize loss surface in 3D space through interpolating over three and four vertices | Instead, we trained NIN with exotic intializations such as initial parameters drawn from N (−10.0, 0.01) or N (−1.0, 1.0) and observe the loss surface behaviours. The results are shown in Figure 11. We can see that NIN without BN does not train at all with any of these initializations",iclr,010
558.pdf.json,#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning,"Reinforcement learning (RL) studies an agent acting in an initially unknown environment, learning through trial and error to maximize rewards. It is impossible for the agent to act near-optimally until it has sufficiently explored the environment and identified all of the opportunities for high reward, in all scenarios. A core challenge in RL is how to balance exploration—actively seeking out novel states and actions that might yield high rewards and lead to long-term gains; and exploitation—maximizing short-term rewards using the agent’s current knowledge. While there are exploration techniques for finite MDPs that enjoy theoretical guarantees, there are no fully satisfying techniques for highdimensional state spaces; therefore, developing more general and robust exploration techniques is an active area of research. Most of the recent state-of-the-art RL results have been obtained using simple exploration strategies such as uniform sampling (Mnih et al., 2015) and i.i.d./correlated Gaussian noise (Schulman et al., 2015; Lillicrap et al., 2015). Although these heuristics are sufficient in tasks with well-shaped rewards, the sample complexity can grow exponentially (with state space size) in tasks with sparse rewards (Osband et al., 2016b). Recently developed exploration strategies for deep RL have led to significantly improved performance on environments with sparse rewards. Bootstrapped DQN ∗These authors contributed equally. (Osband et al., 2016a) led to faster learning in a range of Atari 2600 games by training an ensemble of Q-functions. Intrinsic motivation methods using pseudo-counts achieve state-of-the-art performance on Montezuma’s Revenge, an extremely challenging Atari 2600 game (Bellemare et al., 2016). Variational Information Maximizing Exploration (VIME, Houthooft et al. (2016)) encourages the agent to explore by acquiring information about environment dynamics, and performs well on various robotic locomotion problems with sparse rewards. However, we h","Exploratory gradient boosting for reinforcement learning in complex domains | Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions | The arcade learning environment: An evaluation platform for general agents | Unifying count-based exploration and intrinsic motivation | Space/time trade-offs in hash coding with allowable errors | R-max-a general polynomial time algorithm for near-optimal reinforcement learning | Similarity estimation techniques from rounding algorithms | An improved data stream summary: the count-min sketch and its applications | Histograms of oriented gradients for human detection | Benchmarking deep reinforcement learning for continous control | Summary cache: a scalable wide-area web cache sharing protocol | Bayesian reinforcement learning: A survey | Towards conceptual compression | Bayes-adaptive simulation-based search with value function approximation | Deep residual learning for image recognition | VIME: Variational information maximizing exploration | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Near-optimal regret bounds for reinforcement learning | Near-optimal reinforcement learning in polynomial time.Machine Learning | Adam: A method for stochastic optimization | Near-bayesian exploration in polynomial time | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | Asymptotically efficient adaptive allocation rules | Continuous control with deep reinforcement learning | Object recognition from local scale-invariant features | Human-level control through deep reinforcement learning | Asynchronous methods for deep reinforcement learning | Massively parallel methods for deep reinforcement learning | Deep exploration via bootstrapped DQN | Generalization and exploration via randomized value functions | What is intrinsic motivation? A typology of computational approaches | PAC optimal exploration in continuous space Markov decision processes | Formal theory of creativity, fun, and intrinsic motivation (1990–2010) | Trust region policy optimization | Very deep convolutional networks for large-scale image recognition | Incentivizing exploration in reinforcement learning with deep predictive models | A theoretical analysis of model-based interval estimation | An analysis of model-based interval estimation for Markov decision processes | Planning to be surprised: Optimal Bayesian exploration in dynamic environments | Daisy: An efficient dense descriptor applied to wide-baseline stereo | Pixel recurrent neural networks | Learning functions across many orders of magnitudes | Deep reinforcement learning with double Q-learning | Strategic attentive writer for learning macro-actions | Dueling network architectures for deep reinforcement learning | 2016), following the sparse reward adaptation",iclr,010
559.pdf.json,,"One-shot classification (Miller et al., 2000; Lake et al., 2011; Koch, 2015) (and more generally, fewshot classification) is a problem in which a classifier must be adapted to accommodate new classes not seen in training, given only a single (n) example(s) of these classes. A classical approach, such as retraining the model on the new data, would severely overfit. While the problem is quite difficult, it has been demonstrated that people have the ability to successfully perform one-shot classification (Lake et al., 2011). Nonparametric models such as nearest neighbors are useful in one-shot classification because they naturally adapt to new data, however this comes at the cost of storing the entire set of examples per class, the “support set”. To overcome this, much progress has been made recently in applying metric learning (Goldberger et al., 2004; Kulis, 2012; Bellet et al., 2013) to one-shot tasks. Most recently, (Vinyals et al., 2016) proposed a metric learning approach that they call matching networks. This approach uses an attention mechanism over a learned embedding of the support set in order to predict class labels for the points to be classified, a.k.a the “query set”. It optionally allows the embeddings to be conditioned on other points in the support set (“full context embeddings”) or for the embeddings to be fine-tuned at test time. A particularly interesting feature of the matching networks model is that it utilizes sampled mini-batches called “episodes” during training, where each episode is designed to mimic the one-shot task. This makes the training problem more faithful to the test environment. Matching networks however optionally utilize additional components such as an attention-based LSTM to change the embedding based on the support set. This complexity makes implementation more difficult in addition to the aforementioned poor scaling characteristics due to computing attention over the entire support set. In this paper, we propose a few-shot le",Label-embedding for attribute-based classification | Evaluation of output embeddings for fine-grained image classification | A survey on metric learning for feature vectors and structured data | Imagenet: A large-scale hierarchical image database | Towards a neural statistician | Neighbourhood components analysis | Neural turing machines | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Adam: A method for stochastic optimization | Auto-encoding variational bayes | Siamese neural networks for one-shot image recognition | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | Metric learning: A survey | One shot learning of simple visual concepts | Learning deep parsimonious representations | Visualizing data using t-sne | Distance-based image classification: Generalizing to new classes at near-zero cost | Learning from one example through shared densities on transforms | Learning deep representations of finegrained visual descriptions | Metric learning with adaptive density discrimination | Imagenet large scale visual recognition challenge | Learning a nonlinear embedding by preserving class neighbourhood structure | Metalearning with memory-augmented neural networks | Going deeper with convolutions | Matching networks for one shot learning | Caltech-UCSD Birds 200,iclr,010
560.pdf.json,ON ORTHOGONALITY AND LEARNING RECURRENT NETWORKS WITH LONG TERM DEPENDENCIES,"The depth of deep neural networks confers representational power, but also makes model optimization more challenging. Training deep networks with gradient descent based methods is known to be difficult as a consequence of the vanishing and exploding gradient problem (Hochreiter & Schmidhuber, 1997). Typically, exploding gradients are avoided by clipping large gradients (Pascanu et al., 2013) or introducing an L2 or L1 weight norm penalty. The latter has the effect of bounding the spectral radius of the linear transformations, thus limiting the maximal gain across the transformation. Krueger & Memisevic (2015) attempt to stabilize the norm of propagating signals directly by penalizing differences in successive norm pairs in the forward pass and Pascanu et al. (2013) propose to penalize successive gradient norm pairs in the backward pass. These regularizers affect the network parameterization with respect to the data instead of penalizing weights directly. Both expansivity and contractivity of linear transformations can also be limited by more tightly bounding their spectra. By limiting the transformations to be orthogonal, their singular spectra are limited to unitary gain causing the transformations to be norm-preserving. Le et al. (2015) and Henaff et al. (2016) have respectively shown that identity initialization and orthogonal initialization can be beneficial. Arjovsky et al. (2015) have gone beyond initialization, building unitary recurrent neural network (RNN) models with transformations that are unitary by construction which they achieved by composing multiple basic unitary transformations. The resulting transformations, for some n-dimensional input, cover only some subset of possible n × n unitary matrices but appear to perform well on simple tasks and have the benefit of having low complexity in memory and computation. The entire set of possible unitary or orthogonal parameterizations forms the Stiefel manifold. At a much higher computational cost, gradient ",Unitary evolution recurrent neural networks | Norm-preserving orthogonal permutation linear unit activation functions (oplu) | Understanding the difficulty of training deep feedforward neural networks | Delving deep into rectifiers: Surpassing human-level performance on imagenet classification | Orthogonal rnns and long-memory tasks | Long short-term memory | Regularizing rnns by stabilizing activations | A simple way to initialize recurrent networks of rectified linear units | Gradient-based learning applied to document recognition | Building a large annotated corpus of english: The penn treebank | Rectified linear units improve restricted boltzmann machines | A note on riemannian optimization methods on the stiefel and the grassmann manifolds | On the difficulty of training recurrent neural networks | Exact solutions to the nonlinear dynamics of learning in deep linear neural networks | Notes on optimization on stiefel manifolds | Lecture 6.5—RmsProp: Divide the gradient by a running average of its recent magnitude | Full-capacity unitary recurrent neural networks,iclr,010
561.pdf.json,,"Deep learning transforms the data into compact intermediate representations akin to principal components, and derives layered structures by removing the redundancy in representations (Li Deng, 2014). In recent years, deep learning has demonstrated great success with significant improvement in various artificial intelligence applications, including speech recognition (Sak et al., 2015), image recognition (Ciresan et al., 2012; Cir; Krizhevsky et al., 2012), and natural language processing (Vinyals et al., 2015; Socher et al., 2013). Convolutional Neural Networks (CNNs) are mainly designed for image and video recognition. Typical CNN architecture alternates convolutional layers and pooling layers, followed by several fully connected or sparsely connected layers with a final softmax as the classification layer. Milestones include the 16-layer AlexNet (Krizhevsky et al., 2012), the 19-layer VGG (Simonyan & Zisserman, 2014), and the 22-layer GoogleNet (Szegedy et al., 2015). By adding identity function as a short cut, He et al. (2015) are able to build a substantially deeper ResNet with 152 layers, which received the first place on the ILSVRC 2015 image classification task (Russakovsky et al., 2015). Other very deep networks include the highway network with depths up to 100 layers (Srivastava et al., 2015). Eldan & Shamir (2016) provide a theoretical justification that reveals the utility of having deeper networks rather than wider networks, implying that future progress will lead to the development of even deeper networks. Understanding the deep representations of neural networks has become increasingly difficult as the state-of-the-art models have more layers. This problem is important because it will help us understand the intrinsic mechanism of deep neural networks and explore possible novel applications based on the understanding. Ballester & de Araújo (2016) show how CNNs, trained to identify objects primarily in photos, could be used for abstract sketch recogniti",On the performance of googlenet and alexnet applied to sketches | Prokaryotic evolution and the tree of life are two different things | Modern multidimensional scaling: Theory and applications | Deep autoencoder neural networks for gene ontology annotation predictions | Mitosis detection in breast cancer histology images using deep neural networks | Multi-column deep neural network for traffic sign classification | Multi-task neural networks for QSAR predictions | Pattern pluralism and the tree of life hypothesis | Is a new and general theory of molecular systematics | The power of depth for feedforward neural networks | A neural algorithm of artistic style | Texture synthesis using convolutional neural networks | Deep residual learning for image recognition | A new view of the tree of life : Nature microbiology | Imagenet classification with deep convolutional neural networks | Deep learning: Methods and applications | Wordnet: a lexical database for english | Massively multitask networks for drug | Google voice search: faster and more accurate | Very deep convolutional networks for large-scale image recognition | Parsing with compositional vector grammars | Training very deep networks | Going deeper with convolutions | Show and tell: A neural image caption generator | Atomnet: A deep convolutional neural network for bioactivity prediction in structure-based drug,iclr,010
562.pdf.json,GENERATIVE ADVERSARIAL PARALLELIZATION,"The growing popularity Generative Adversarial Networks (GAN) and their variants stems from their success in producing realistic samples (Denton et al., 2015; Radford et al., 2015; Im et al., 2016; Salimans et al., 2016; Dumoulin et al., 2016) as well as the intuitive nature of the adversarial training framework (Goodfellow et al., 2014). Compared to other unsupervised learning paradigms, GANs have several merits: • The objective function is not restricted to distances in input (e.g. pixel) space, for example, reconstruction error. Moreover, there is no restriction to certain type of functional forms such as having a Bernoulli or Gaussian output distribution. • Compared to undirected probabilistic graphical models (Hinton et al., 2006; Salakhutdinov & Hinton, 2009), samples are generated in a single pass rather than iteratively. Moreover, the time to generate a sample is much less than recurrent models like PixelRNN (Oord et al., 2016). • Unlike inverse transformation sampling models, the latent variable size is not restricted (Hyvarinen & Pajunen, 1999; Dinh et al., 2014). In contrast, GANs are known to be difficult to train, especially as the data generating distribution becomes more complex. There have been some attempts to address this issue. For example, Salimans et al. (2016) propose several tricks such as feature matching and minibatch discrimination. In this work, we attempt to address training difficulty in a different way: extending two player generative adversarial games into a multi-player game. This amounts to training many GAN-like variants in parallel, periodically swapping their discriminators such that generator-discriminator coupling is reduced. Figure 1 provides a graphical depiction of our method. Besides the training dilemma, from the point of view of density estimation, GANs possess very different characteristics compared to other probabilistic generative models. Most probabilistic models distribute the probability mass over the entire domain, w",Theano: a cpu and gpu math expression compiler | Deep learning with COTS HPC systems | Deep generative image models using a laplacian pyramid of adversarial networks | Nice: non-linear independent components estimation | Adversarially learned inference | Generative adversarial nets | A fast learning algorithm for deep belief nets | Nonlinear independent component analysis: Existence and uniqueness results | Generating images with recurrent adversarial networks | Theano-MPI: a Theano-based distributed training framework | Annealed importance sampling | Pixel recurrent neural networks | On the difficulty of training recurrent neural networks | Connecting generative adversarial networks and Actor-Critic methods | Unsupervised representation learning with deep convolutional generative adversarial networks | Deep boltzmann machines | Improved techniques for training gans | A note on the evaluation of generative models | On the quantitative analysis of decoderbased generative models,iclr,010
563.pdf.json,,"There have been many recent studies about deep generative models. Generative adversarial networks (GAN) (Goodfellow et al., 2014) is the variant of these models that has attracted the most attention. It has been demonstrated that generating vivid, realistic images from a uniform distribution is possible (Radford et al., 2015; Denton et al., 2015). GANs are formulated as a two-player minimax game. However, the objective function derived in the original motivation is modified to obtain stronger gradients when learning the generator. GANs have been applied in various studies; however, few studies have attempted to reveal their mechanism (Goodfellow, 2014; Huszar, 2015). Recently, f-GAN, which minimizes the variational estimate of f-divergence, has been proposed (Nowozin et al., 2016). The original GAN is a special case of f-GAN. In this study, we propose a novel algorithm inspired by GANs from the perspective of density ratio estimation based on the Bregman divergence, which we refer to as b-GAN. The proposed algorithm iterates density ratio estimation and f-divergence minimization based on the obtained density ratio. This study make the following two primary contributions: 1. We derive a novel unified algorithm that employs well-studied results regarding density ratio estimation (Kanamori et al., 2012; Sugiyama et al., 2012; Menon & Ong, 2016). 2. In the original GANs, the value function derived from the two-player minimax game does not match the objective function that is actually used for learning the generative model. In our algorithm, the objective function derived from the original motivation is not changed for learning the generative model. The remainder of this study is organized as follows. Section 2 describes related work. Section 3 introduces and analyzes the proposed algorithm in detail. Section 4 explains the proposed algorithm for specific cases. Section 5 reports experimental results. Section 6 summarizes our findings and discusses future work.","TensorFlow: Large-scale machine learning on heterogeneous systems, 2015. URL http://tensorflow.org/. Software available from tensorflow.org | A general class of coefficients of divergence of one distribution from another | Information geometry of divergence functions | Convexity, classification and risk bounds | Robust and efficient estimation by minimising a density power divergence | Learning bounds for importance weighing | Theory and applications of proper scoring | Minimum scoring rule inference | Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks | Training generative neural networks via maximum mean discrepancy optimization | Dimensionality reduction for supervised learning with reproducing kernel hilbert spaces | Generative adversarial nets | On distinguishability criteria for estimating generative models | A kernel two-sample test | Noisecontrastive estimation: A new estimation principle for unnormalized statistical models | Bregman divergence as general framework to estimate unnormalized statistical models | Robust statistics | How (not) to Train your Generative Model: Scheduled Sampling, Likelihood | Divergence estimation and two-sample homogeneity test under semiparametric density-ratio models | Divergence estimation and two-sample homogeneity test under semiparametric density-ratio models | Adam: A Method for Stochastic Optimization | Learning multiple layers of features from tiny images | Generative moment matching networks | Deep learning face attributes in the wild | Linking losses for density ratio and class-probability estimation | Learning in Implicit Generative Models | Foundation of Machine Learning | Direct density ratio estimation with convolutional neural networks with application in outlier detection | Estimating divergence functionals and the likelihood ratio by convex risk minimization | f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization | A family of computationally efficient and simple estimators for unnormalized statistical models | Inferences for case-control and semiparametric two-sample density ratio models | Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks | Composite binary losses | Information, divergence and risk for binary experiments | Improved Techniques for Training GANs | Batch normalization: Accelerating deep network training by reducing internal covariate shift | On the influence of the kernel on the consistency of support vector machines | Density ratio matching under the bregman divergence: a unified framework of density ratio estimation | Learning under non-stationarity:covariate shift and class-balance change | Relative density-ratio estimation for robust distribution comparison | Energy-based Generative Adversarial Network | EXPLANATION OF HEURISTICS USING RADEMACHER COMPLEXITY Here, we justify three points using Rademacher complexity. All techniques used are described in the literature | 2012), we expand the explanation of density ratio estimation. As noted in Section 3, the objective function of density ratio estimation | analyze robust proper loss from the perspective of influence function. They proposed a concept of B-robustness from the perspective of influence function. It is stated that using KL divergence and reversed KL divergence is not robust because the second derivative of f is not bounded at 0. That is a similar conclusion to our analysis in Appendix D",iclr,010
564.pdf.json,HIGHER ORDER RECURRENT NEURAL NETWORKS,"In the recent resurgence of neural networks in deep learning, deep neural networks have achieved successes in various real-world applications, such as speech recognition, computer vision and natural language processing. Deep neural networks (DNNs) with a deep architecture of multiple nonlinear layers are an expressive model that can learn complex features and patterns in data. Each layer of DNNs learns a representation and transfers them to the next layer and the next layer may continue to extract more complicated features, and finally the last layer generates the desirable output. From early theoretical work, it is well known that neural networks may be used as the universal approximators to map from any fixed-size input to another fixed-size output. Recently, more and more empirical results have demonstrated that the deep structure in DNNs is not just powerful in theory but also can be reliably learned in practice from a large amount of training data. Sequential modeling is a challenging problem in machine learning, which has been extensively studied in the past. Recently, many deep neural network based models have been successful in this area, as shown in various tasks such as language modeling Mikolov (2012), sequence generation Graves (2013); Sutskever et al. (2011), machine translation Sutskever et al. (2014) and speech recognition Graves et al. (2013). Among various neural network models, recurrent neural networks (RNNs) are appealing for modeling sequential data because they can capture long term dependency in sequential data using a simple mechanism of recurrent feedback. RNNs can learn to model sequential data over an extended period of time, then carry out rather complicated transformations on the sequential data. RNNs have been theoretically proved to be a turing complete machine Siegelmann & Sontag (1995). RNNs in principle can learn to map from one variable-length sequence to another. When unfolded in time, RNNs are equivalent to very deep neural netwo","Improving continuous space language models using auxiliary features | Neural machine translation by jointly learning to align and translate | Learning long-term dependencies with gradient descent is difficult | A neural probabilistic language model | Learning phrase representations using RNN encoder-decoder for statistical machine translation | Gated feedback recurrent neural networks | Generating sequences with recurrent neural networks | Speech recognition with deep recurrent neural | Deep residual learning for image recognition | Hierarchical recurrent neural networks for long-term dependencies | Long short-term memory | Character-aware neural language models | A clockwork rnn | Deeply supervised nets | Neural networks for handwriting recognition, Book Chapter, Computational intelligence paradigms in advanced pattern classification | Statistical Language Models based on Neural Networks | Extensions of recurrent neural network language model | Learning longer memory in recurrent neural networks | Gated word-character recurrent language model | Regularization and nonlinearities for neural language models: when are they needed | How to construct deep recurrent neural networks | On the computational power of neural nets | End-to-end memory networks | LSTM neural networks for language modeling | Generating text with recurrent neural networks | Sequence to sequence learning with neural networks | gen cnn: A convolutional architecture for word sequence prediction | Backpropagation through time: what it does and how to do it | A hybrid and connectionist architecture for a scanning understanding | Recurrent neural network regularization | The fixed-size ordinally-forgetting encoding method for neural network language models",iclr,010
566.pdf.json,,"A daunting challenge in many contexts is to gather annotated data. This can be a long and tedious process, which often slows down the development of a framework and may jeopardize its economic prospects. We refer to active learning Cohn (1994) as the field of machine learning which targets building iteratively the annotated training set with the help of an oracle. In this setting and in a context of pool-based active learning1, a model is trained on a small amount of data (i.e. the initial training set) and a scoring function discriminates samples which should be labeled by the oracle from the ones which do not hold new information for the model. The queried samples are then submitted to an oracle (which can be another decision algorithm for instance in co-training context, or a human expert in interactive learning context) to be labeled. They are then added to the current training set. Finally the model is retrained from scratch. This process is repeated recursively to grow the training set. Although active learning and deep learning represent two important pillars of machine learning, they have mainly coexisted into independent stream of works owing to the complexity of combining them. The main issues are the scalability and the adaptability of common active learning schemes when considering architectures with a huge number of parameters such as deep networks. Another issue lies in the overall number of training iterations since training a deep architecture remains a computationally expensive process despite all the optimizations through GPU processing. This specificity has prevented deep learning from being prevalent within active learning. Indeed seminal active learning frameworks Cohn (1994) have mainly focused on adding one sample at-a-time. When it comes to selecting a batch of queries, the most intuitive solution is to select top scoring samples. 1Other settings exist but are not considered here for the sake of clarity, we refer the reader to Settles (2012) ","The loss surfaces of multilayer networks | Neural network exploration using optimal experiment design | Near-optimal bayesian active learning with noisy observations | Explaining and Harnessing Adversarial Examples | Practical variational inference for neural networks | A kronecker-factored approximate fisher matrix for convolution layers | Batch mode active learning and its application to medical image classification | Optimizing neural networks with kronecker-factored approximate curvature | Active Learning, volume 6 of Synthesis Lectures on Artificial Intelligence and Machine Learning | Intriguing properties of neural networks | Matrix Approximation for Large-scale Learning | Submodularity in data subset selection and active learning | The value of unlabeled data for classification problems | Active deep networks for semi-supervised sentiment classification",iclr,010
567.pdf.json,,"Finding dependent subspaces across views (subspaces where some property of data is statistically related or similar across views) is a common data analysis need, where Canonical Correlation Analysis (CCA) (Hotelling, 1936) is a standard unsupervised tool. Preprocessing to find dependent subspaces is useful both for prediction and for analysis: in predictive tasks, such subspaces help if non-dependent parts of each view may arise from noise and distortions. In some data analysis tasks, finding the dependent subspaces may itself be the main goal; for example in bioinformatics domains dependency seeking projections have been used to identify relationships between different views of cell activity (Tripathi et al., 2008; Klami et al., 2013); in signal processing a similar task could be identifying optimal filters for dependent signals of different nature, e.g., speech and the corresponding tongue movements of the speakers as in Westbury (1994). Methods like CCA maximize simple correlations between data point coordinate features across the projected subspaces. However, in many data domains the coordinates may not be of main interest but rather the data relationships that they reveal. It is then of great interest to develop dependency seeking methods that directly focus on the data relationships. For example, consider a database of scientists, defined in one view by their level of interest in various research topics, and in another view by their level of interest in various hobbies. In a database like this, finding relationships of people is the common interest, e.g. to find nearest colleagues for a scientist, having the most similar (neighboring) research interests; or to find hobby partners having the most similar (neighboring) hobby interests; the question is then, can we predict the research colleagues from hobby partners or vice versa? Research topics and hobbies are very dissimilar views, and not all of their variation will be related, but we can try to find subspace","Deep canonical correlation analysis | Kernel independent component analysis | Euclidean embedding of co-occurrence data | Framing image description as a ranking task: Data, models and evaluation metrics | Relations between two sets of variates | Bayesian canonical correlation analysis | Kernel and nonlinear canonical correlation analysis | Canonical divergence analysis | Visualization by linear projections as information retrieval | The eyes have it: A task by data type taxonomy for information visualizations | Comprehensive identification of cell cycle-regulated genes of the yeast saccharomyces cerevisiae by microarray hybridization | Locality preserving cca with applications to data visualization and pose estimation | Simple integrative preprocessing preserves what is shared in data sources | Accelerating t-sne using tree-based algorithms | Visualizing data using t-SNE | Information retrieval perspective to nonlinear dimensionality reduction for data visualization | Non-linear cca and pca by alignment of local models | Linear-time training of nonlinear low-dimensional embeddings | On deep multi-view representation learning | Local cca alignment and its applications | X-ray Microbeam Speech Production Database User’s Handbook | Scalable optimization of neighbor embedding for visualization",iclr,010
568.pdf.json,,"For text classification, a popular feature representation method is bag-of-word. However, this representation has an intrinsic disadvantage that two separate features will be generated for two words with the same root or of different tenses. Lemmatization and stemming could be applied to partially address this problem, but may not always leads to correct results. For example, “meaningful” and “meaningless” would both be considered as “meaning” after applying lemmatization or stemming algorithms, while they are of opposite meanings. Thus, word morphology could also provide useful information in document understanding, particular in short text where the information redundancy is low. For short text, an important issue is data sparsity, particularly when utilizing feature representation method like bag-of-word, regardless the weighting scheme. Therefore, various distributed word representation like Word2Vec (Mikolov et al., 2013) and document representation Doc2Vec (Le & Mikolov, 2014) have been proposed to address the problem. However, this kind of method miss the word morphology information and word combination information. To deal with these issues, we propose a model which could capture various kinds of features that could benefit classification task. In this paper, we look deep into characters. We learn character representation and combine both character-level (Zhang et al., 2015) and word-level embedding to represent a word. Thus both morphology and semantic properties of the word are captured. As we know, not all the words in a sentence contribute the same when predicting the sentence’s label. Therefore, highlight the relatively pertinent information would give better chance of correct prediction. Attention mechanism (Mnih et al., 2014; Bahdanau et al., 2016) which focuses on specific part of input could help achieve this goal. The applications of attention mechanism are mostly on sequential model, while we employ ∗The two authors contribute the same for the wor","Neural machine translation by jointly learning to align and translate | Endto-end attention-based large vocabulary speech recognition | Learning mid-level features for recognition | Semantic segmentation with modified deep residual networks | Natural language processing (almost) from scratch | Deep convolutional neural networks for sentiment analysis of short texts | Learning character-level representations for partof-speech tagging | Deep residual learning for image recognition | Identity mappings in deep residual networks | Text understanding with the attention sum reader network | Convolutional neural networks for sentence classification | Character-aware neural language models | Imagenet classification with deep convolutional neural networks | Distributed representations of sentences and documents | Handwritten digit recognition with a back-propagation network | Distributed representations of words and phrases and their compositionality | Recurrent models of visual attention | Rectified linear units improve restricted boltzmann machines | Feed-forward networks with attention can solve some long-term memory problems | Pruning subsequence search with attention-based embedding | Reasoning about entailment with neural attention | Overfeat: Integrated recognition, localization and detection using convolutional networks | A latent semantic model with convolutional-pooling structure for information retrieval | Character-level convolutional networks for text classification",iclr,010
569.pdf.json,ATTENTIVE RECURRENT COMPARATORS,"Advancing Deep Learning systems to solve Artificial Intelligence tasks requires that models be capable of performing continual meta-learning[ (Lake et al., 2016), (Schaul & Schmidhuber, 2010)]. But top-down hierarchical designs of models (Santoro et al., 2016) to perform such tasks are not very successful on real world data and there are many reasons for this. First, most datasets are generally not designed with such higher order tasks in mind, thus researchers either work with synthetic data or fabricate higher level tasks based on traditional datasets - both of which constrain their utility. Second, hierarchical or meta models suffer from reduced supervision during training due to their inherent design. Third, with our experiments we found that the foundational architectures like Memory Augmented Neural Networks are still in their infancy and not ripe enough to be utilized in complex hierarchical systems. Therefore, in this paper, we present an alternative way of bridging this gap by building models in a bottom-up fashion. Comparing two or more inputs and estimating their similarity is a primal task using which more sophisticated models can be designed - an idea that has been well exploited in traditional Machine Learning for long (Bellet et al., 2013). Using the modern developments of attention mechanisms and by combining it with recurrent neural networks, we first built better comparators called Attentive Recurrent Comparators (ARCs) 1. Using ARCs as a foundational element, we were then able to build more complex models and achieve qualitatively better results on tasks like one-shot learning. Thus, this work is proof of concept for the bottom-up design approach that can be applied to almost any dataset. When a person is asked to compare two objects and estimate their similarity, the person does so by repeatedly looking back and forth between the two objects. With each glimpse of an object, a specific observation is made. These observations made in both objects a","Multiple object recognition with visual attention | A survey on metric learning for feature vectors and structured data | Fullyconvolutional siamese networks for object tracking | Signature verification using a ?siamese? time delay neural network | Learning a similarity metric discriminatively, with application to face verification | Learning where to attend with deep architectures for image tracking | Neural mechanisms of selective visual attention | A bayesian approach to unsupervised one-shot learning of object categories | Learning to forget: Continual prediction with lstm | Generating sequences with recurrent neural networks | Draw: A recurrent neural network for image generation | Long short-term memory | Deep metric learning using triplet network | Convolutional neural network architectures for matching natural language sentences | Human-level concept learning through probabilistic program induction | Building machines that learn and think like people | Learning to combine foveal glimpses with a third-order boltzmann machine | A deep architecture for matching short texts | Recurrent models of visual attention | Oneshot learning with memory-augmented neural networks | Learning to generate artificial fovea trajectories for target detection | Deep learning in neural networks: An overview | Deepface: Closing the gap to human-level performance in face verification | Matching networks for one shot learning | Learning to compare image patches via convolutional neural networks",iclr,010
570.pdf.json,CAN AI GENERATE LOVE ADVICE?: TOWARD NEURAL ANSWER GENERATION FOR NON-FACTOID QUESTIONS,"Recently, dialog-based natural language understanding systems such as Apple’s Siri, IBM’s Watson, Amazon’s Echo, and Wolfram Alpha have spread through the market. In those systems, Question Answering (QA) modules are particularly important since people want to know many things in their daily lives. Technically, there are two types of questions in QA systems: factoid questions and non-factoid ones. The former are asking, for instance, for the name of a person or a location such that “What/Who is X?”. The latter are more diverse questions which cannot be answered by a short fact. They range from advice on making long distance relationships work well, to requests for opinions on some public issues. Significant progress has been made at answering factoid questions (Wang et al. (2007); Yu et al. (2014)), however, retrieving answers for non-factoid questions from the Web remains a critical challenge in improving QA modules. The QA community sites such as Yahoo! Answers and Quora can be sources of training data for the non-factoid questions where the goal is to automatically select the best of the stored candidate answers. Recent deep learning methods have been applied to this non-factoid answer selection task using datasets stored in the QA sites resulting in state-of-the-art performance (Yu et al. (2014); Tan et al. (2015); Qiu & Huang (2015); Feng et al. (2015); Wang & Nyberg (2015); Tan et al. (2016)). They usually compute closeness between questions and answers by the individual embeddings obtained using a convolutional model. For example, Tan et al. (2016) builds the embeddings of questions and those of answers based on bidirectional long short-term memory (biLSTM) models, and measures their closeness by cosine similarity. It also utilizes an efficient attention mechanism to generate the answer representation following the question context. Their results show that their model can achieve much more accurate results than the strong baseline (Feng et al. (2015)). The cu",Parameterized concept weighting in verbose queries | Joint word representation learning using a corpus and a semantic lexicon | What is an opinion about? exploring political standpoints using opinion scoring model | Learning hybrid representations to retrieve semantically equivalent questions | Retrofitting word vectors to semantic lexicons | Applying deep learning to answer selection: A study and an open | Convolutional neural network architectures for matching natural language sentences | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Embedding a semantic network in a word space | Distributed representations of sentences and documents | Opinion summarization with integer linear programming formulation for sentence extraction and ordering | Convolutional neural tensor network architecture for communitybased question answering | A survey of automated web service composition methods | Neurocomputing: Foundations of research. chapter Learning Representations by Back-propagating Errors | Domain-independent sentence type classification: Examining the scenarios of scientific abstracts and scrum protocols | Hierarchical neural network generative models for movie dialogues | Lstm-based deep learning models for non-factoid answer selection | Improved representation learning for question answer matching | A neural conversational model | A long short-term memory model for answer sentence selection in question answering | What is the jeopardy model? a quasisynchronous grammar for qa | RCNET: A general framework for incorporating knowledge into word representations | Deep learning for answer sentence selection | Sentence type based reordering model for statistical machine translation,iclr,010
571.pdf.json,BOOSTED GENERATIVE MODELS,"Many of the recent successful applications of machine learning in computer vision, speech recognition, and natural language processing are based on discriminative models. Learning generative models has proven to be much more difficult. Deep architectures, including latent variable models such as Boltzmann machines (Smolensky, 1986), variational autoencoders (Kingma & Welling, 2014), and generative adversarial networks (Goodfellow et al., 2014), have recently shown great success. Despite significant progress, existing generative models cannot fit complex distributions with a sufficiently high degree of accuracy. In this paper, we propose a technique for ensembling (imperfect) generative models to improve their overall performance. Our meta-algorithm is inspired by boosting, a powerful technique used in supervised learning to construct ensembles of weak classifiers (e.g., decision stumps or trees), which individually might not perform well on a given classification task. The boosting algorithm will attempt to learn a classifier to correct for the mistakes made and repeat this procedure recursively. Under some conditions on the weak classifiers’ effectiveness, the boosting meta-algorithm can drive the (training) error to zero (Freund et al., 1999). Boosting can also be thought as a feature learning algorithm, where at each round a new feature is learned by training a classifier on a re-weighted version of the original dataset. In practice, algorithms based on boosting (such as boosted trees) perform extremely well in machine learning competitions (Caruana & Niculescu-Mizil, 2006). We show that a similar procedure can be applied to generative models. Given an initial generative model that provides an imperfect fit to the data distribution, we construct a second model to correct for the error, and repeat recursively. The second model is also a generative one, which is trained on a re-weighted version of the original training set. Our meta algorithm is general and can con","Quickly generating representative samples from an rbm-derived process | An empirical comparison of supervised learning algorithms | A short introduction to boosting | The elements of statistical learning, volume 1. Springer series in statistics | Stochastic gradient boosting | Generative adversarial nets | On distinguishability criteria for estimating generative models | Eigenboosting: Combining discriminative and generative information | Noise-contrastive estimation: A new estimation principle for unnormalized statistical models | Training products of experts by minimizing contrastive divergence | Transductive inference for text classification using support vector machines | Cryptographic limitations on learning boolean formulae and finite automata | Adam: A method for stochastic optimization | Auto-encoding variational bayes | Imagenet classification with deep convolutional neural networks | Boosting and maximum likelihood for exponential models | Convolutional networks for images, speech, and time series | Mnist handwritten digit database | Learning in implicit generative models | Annealed importance sampling | A cascade of boosted generative and discriminative classifiers for vehicle detection | Pixel recurrent neural networks | Semisupervised learning with ladder networks | Data programming: Creating large training sets, quickly | The strength of weak learnability | Boosting: Foundations and algorithms | Information processing in dynamical systems: Foundations of harmony theory | A note on the evaluation of generative models | Adaboost. mrf: Boosted markov random forests and application to multilevel activity recognition | Learning generative models via discriminative approaches",iclr,010
572.pdf.json,,"Adversarial examples have been shown to exist for a variety of deep learning architectures.1 They are small perturbations of the original inputs, often barely visible to a human observer, but carefully crafted to misguide the network into producing incorrect outputs. Seminal work by Szegedy et al. (2013) and Goodfellow et al. (2014), as well as much recent work, has shown that adversarial examples are abundant and finding them is easy. Most previous work focuses on the application of adversarial examples to the task of classification, where the deep network assigns classes to input images. The attack adds small adversarial perturbations to the original input image. These perturbations cause the network to change its classification of the input, from the correct class to some other incorrect class (possibly chosen by the attacker). Critically, the perturbed input must still be recognizable to a human observer as belonging to the original input class.2 Deep generative models, such as Kingma & Welling (2013), learn to generate a variety of outputs, ranging from handwritten digits to faces (Kulkarni et al., 2015), realistic scenes (Oord et al., 2016), videos (Kalchbrenner et al., 2016), 3D objects (Dosovitskiy et al., 2016), and audio (van den Oord et al., 2016). These models learn an approximation of the input data distribution in different ways, and then sample from this distribution to generate previously unseen but plausible outputs. To the best of our knowledge, no prior work has explored using adversarial inputs to attack generative models. There are two main requirements for such work: describing a plausible scenario in which an attacker might want to attack a generative model; and designing and demonstrating an attack that succeeds against generative models. We address both of these requirements in this work. One of the most basic applications of generative models is input reconstruction. Given an input image, the model first encodes it into a lower-dimensional ","TensorFlow: Large-scale machine learning on heterogeneous systems, 2015. URL http://tensorflow.org/. Software available from tensorflow.org | Towards evaluating the robustness of neural networks | Learning to generate chairs, tables and cars with convolutional networks | Generative Adversarial Networks | Explaining and harnessing adversarial examples | Learning with a strong adversary | Video pixel networks | Adam: A method for stochastic optimization | Auto-encoding variational bayes | Semi-supervised learning with deep generative models | Deep convolutional inverse graphics network | Adversarial examples in the physical world | Autoencoding beyond pixels using a learned similarity metric | Gradient-based learning applied to document recognition | Deep learning face attributes in the wild | Deepfool: a simple and accurate method to fool deep neural networks. 2016 | Reading digits in natural images with unsupervised feature learning | Deep neural networks are easily fooled: High confidence predictions for unrecognizable | Conditional image generation with pixelcnn decoders | The limitations of deep learning in adversarial settings | Practical black-box attacks against deep learning systems using adversarial examples | Adversarial manipulation of deep representations | Intriguing properties of neural networks | Adversarial Images for Variational Autoencoders | Variable rate image compression with recurrent neural networks | Full resolution image compression with recurrent neural networks | Wavenet: A generative model for raw audio",iclr,010
573.pdf.json,TOWARDS INFORMATION-SEEKING AGENTS,"Humans possess an innate desire to know and to understand. We seek information actively through behaviors both simple (glancing at a billboard) and elaborate (conducting scientific experiments) (Gottlieb et al., 2013). These qualities equip us to deal with a complex, ever-changing environment. Artificial agents could benefit greatly from similar capacities. Discussion of information seeking behavior in artificial agents dates back at least 25 years (Schmidhuber, 1991). We contribute to this discussion by reformulating and implementing some of the associated ideas, aided by 10-20 years worth of algorithmic and computational advances. To that end, we present a general problem setting for examining the ability of models to seek information efficiently, and show that our models can apply generic information seeking behavior to improve performance in goal-oriented tasks. Consider the game 20 Questions. The objective is to guess the identity of some arbitrary item by asking no more than twenty yes-or-no questions (that is, collecting no more than 20 bits of information). At each turn, the questioner seeks to split the set of all viable items along some dimension, thereby shrinking the set. The “optimal” question changes from turn to turn, depending heavily on the questions asked previously. The rules of this game demand efficient seeking. Almost all “guessing games”, from 20 Questions to Battleship to Hangman, seem expressly designed to train efficient information seeking, or at least to exploit our intrinsic joy in exercising this skill. With this in mind, we develop a collection of tasks that can be solved only through efficient acquisition of information. Our tasks vary in difficulty and complexity, but all involve searching an environment iteratively for salient fragments of information (clues) towards the fulfilment of some goal. To necessitate efficient search we impose restrictions on the information that can be acquired at each turn and on the total number of turn","Neural machine translation by jointly learning to align and translate | Intrinsically motivated reinforcement learning | Information-seeking, curiosity, and attention: computational and neural mechanisms | Draw: A recurrent neural network for image generation | Predictive entropy search for efficient global optimization of black-box functions | Long short-term memory | Variational information maximizing exploration | Auto-encoding variational bayes | Learning to combine foveal glimpses with a third-order boltzmann machine | Deep learning face attributes in the wild | Recurrent models of visual attention | Variational information maximisation for intrinsically motivated reinforcement learning | Unsupervised representation learning with deep convolutional generative adversarial networks | Neural mechanisms for detecting and remembering novel events | On learning where to look | The dynamic representation of scenes | Stochastic backpropagation and approximate inference in deep generative models | A possibility for implementing curiosity and boredom in model-building neural controllers | Self-motivated development through rewards for predictor errors / improvements | Formal theory of creativity, fun, and intrinsic motivation (1990-2010) | Highdimensional continuous control using generalized advantage estimation | Deterministic policy gradient algorithms | Iterative alternating neural attention for machine reading | An information-theoretic approach to curiosity-driven reinforcement learning | Reinforcement driven information acquisition in non-deterministic environments | Reinforcement Learning: an Introduction, volume 1 | Character-level convolutional networks for text classification",iclr,010
574.pdf.json,,"Online commerce has been a great impact on our life over the past decade. We focus on an online market for fashion related items1. Finding similar fashion-product images for a given image query is a classical problem in an application to computer vision, however, still challenging due to the absence of an absolute definition of the similarity between arbitrary fashion items. Deep learning technology has given great success in computer vision tasks such as efficient feature representation (Razavian et al., 2014; Babenko et al., 2014), classification (He et al., 2016a; Szegedy et al., 2016b), detection (Ren et al., 2015; Zhang et al., 2016), and segmentation (Long et al., 2015). Furthermore, image to caption generation (Vinyals et al., 2015; Xu et al., 2015) and visual question answering (VQA) (Antol et al., 2015) are emerging research fields combining vision, language (Mikolov et al., 2010), sequence to sequence (Sutskever et al., 2014), long-term memory (Xiong et al., 2016) based modelling technologies. These computer vision researches mainly concern about general object recognition. However, in our fashion-product search domain, we need to build a very specialised model which can mimic human's perception of fashion-product similarity. To this end, we start by brainstorming about what makes two fashion items are similar or dissimilar. Fashion-specialist and merchandisers are also involved. We then compose fashion-attribute dataset for our fashion-product images. Table 1 explains a part of our fashion-attributes. Conventionally, each of the columns in Table 1 can be modelled as a multi-class classification. Therefore, our fashion-attributes naturally is modelled as a multi-label classification. ∗This work was done by the author at SK Planet. 1In our e-commerce platform, 11st (http://english.11st.co.kr/html/en/main.html), al- most a half of user-queries are related to the fashion styles, and clothes. Multi-label classification has a long history in the machine learnin","Vqa: Visual question answering | Neural codes for image retrieval | Microsoft COCO captions: Data collection and evaluation | On the properties of neural machine translation: Encoder-decoder approaches | Learning tree structure of label dependency for multi-label learning | A tutorial on multilabel learning | Generating sequences with recurrent neural networks | Towards end-to-end speech recognition with recurrent neural networks | Speech recognition with deep recurrent neural networks | Deep residual learning for image recognition | Identity mappings in deep residual networks | Word-based Dialog State Tracking with Recurrent Neural Networks | Long short-term memory | Hamming embedding and weak geometric consistency for large scale image search | Visual search at pinterest | Fully convolutional networks for semantic segmentation | Recurrent neural network based language model | Dependency recurrent neural language models for sentence completion | Scalable recognition with a vocabulary tree | Cnn features offthe-shelf: An astounding baseline for recognition | Classifier chains for multi-label classification | Faster r-cnn: Towards real-time object detection with region proposal networks | ImageNet Large Scale Visual Recognition Challenge | Building end-to-end dialogue systems using generative hierarchical neural network models | Very deep convolutional networks for large-scale image recognition | Sequence to sequence learning with neural networks | Going deeper with convolutions | Inception-v4, inception-resnet and the impact of residual connections on learning | Rethinking the inception architecture for computer vision | Cider: Consensus-based image description evaluation | Show and tell: A neural image caption generator | CNN-RNN: A unified framework for multi-label image classification | Dynamic memory networks for visual and textual question answering | Show, attend and tell: Neural image caption generation with visual attention | Recurrent neural network regularization | Is faster R-CNN doing well for pedestrian detection | Multi-label learning by exploiting label dependency",iclr,010
575.pdf.json,DIFFERENTIABLE CANONICAL CORRELATION ANALYSIS,"Deep Canonical Correlation Analysis (DCCA) (Andrew et al., 2013) is a non-linear extension of classic Canonical Correlation Analysis (CCA) (Hotelling, 1936) that learns highly correlated latent representations on top of two different neural networks. The central idea of our work is to extend this formulation and cast CCA as a fully differentiable neural network layer which allows for parameter optimization via back-propagation through the CCA projection matrices. This is in contrast to DCCA, where correlation analysis is the topmost part of the network and only used as an optimization target for maximizing the correlation between the respective views. DCCA in general gained a lot of attention recently. It inspired related methods such as Deep Linear Discriminant Analysis (Dorfer et al., 2015) as well as a discriminative re-formulation of DCCA (Elmadany et al., 2016) applied to improve speech-based emotion recognition. Wang et al. (2015a) show that joint optimization of correlation and reconstruction error in auto-encoder configurations is successfully used for representation learning on a multi-modal speech production dataset. We take this as a motivation to evolve and extend the applicability of DCCA. In our experiments, we employ the proposed differentiable CCA layer in a cross-modality retrieval setup. Cross-modality retrieval is the task of retrieving relevant data of another type when a sample of a different modality is given as a search query. A recent survey by Wang et al. (2016) categorizes the task into binary and real-valued representation learning. In the case of real-valued representation learning, End-to-End DCCA (Yan & Mikolajczyk, 2015) achieves state of the art retrieval results in combination with retrieval by cosine distance computation. With differentiable CCA, it becomes possible to train the networks to directly minimize the objective which will be used for retrieval (e.g., the cosine distance), while still benefitting from the optimally-correla","Deep canonical correlation analysis | Return of the devil in the details: Delving deep into convolutional nets | Fast and accurate deep network learning by exponential linear units (elus) | Deep linear discriminant analysis | Multiview learning via deep discriminative canonical correlation analysis | The iapr tc-12 benchmark: A new evaluation resource for visual information systems | Relations between two sets of variates | Batch normalization: Accelerating deep network training by reducing internal covariate | Deep fragment embeddings for bidirectional image sentence mapping | Adam: A method for stochastic optimization | Unifying visual-semantic embeddings with multimodal neural language models | On differentiating eigenvalues and eigenvectors | Explain images with multimodal recurrent neural networks | Multivariate analysis. Probability and mathematical statistics | Estimating the Jacobian of the Singular Value Decomposition: Theory and Applications | The matrix cookbook, nov | Grounded compositional semantics for finding and describing images with sentences | A comprehensive survey on crossmodal retrieval | On deep multi-view representation learning | Unsupervised learning of acoustic features via deep canonical correlation analysis | Deep correlation for matching images and text | From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions",iclr,010
577.pdf.json,UNDERSTANDING INTERMEDIATE LAYERS USING LINEAR CLASSIFIER PROBES,"The recent history of deep neural networks features an impressive number of new methods and technological improvements to allow the training of deeper and more powerful networks. Despite this, models still have a reputation for being black boxes. Neural networks are criticized for their lack of interpretability, which is a tradeoff that we accept because of their amazing performance on many tasks. Efforts have been made to identify the role played by each layer, but it can be hard to find a meaning to individual layers. There are good arguments to support the claim that the first layers of a convolution network for image recognition contain filters that are relatively “general”, in the sense that they would work great even if we switched to an entirely different dataset of images. The last layers are specific to the dataset being used, and have to be retrained when using a different dataset. In Yosinski et al. (2014) the authors try to pinpoint the layer at which this transition occurs, but they show that the exact transition is spread across multiple layers. In this paper, we introduce the concept of linear classifier probe, referred to as a “probe” for short when the context is clear. We start from the concept of Shannon entropy, which is the classic way to describe the information contents of a random variable. We then seek to apply that concept to understand the roles of the intermediate layers of a neural network, to measure how much information is gained at every layer (answer : technically, none). We argue that it fails to apply, and so we propose an alternative framework to ask the same question again. This time around, we ask what would be the performance of an optimal linear classifier if it was trained on the inputs of a given layer from our model. We demonstrate how this powerful concept can be very useful to understand the dynamics involved in a deep neural network during training and after.","What is the best multi-stage architecture | Information Theory, Inference and Learning Algorithms | How transferable are features in deep",iclr,010
578.pdf.json,ERTIES OF CONVOLUTIONAL NEURAL NETWORKS,"The overwhelming success of Convolutional Neural Networks (CNNs) is generally attributed to their ability to learn task-specific representations from large quantities of data. This has led to many state of the art results in areas such as image classification (He et al., 2015), semantic segmentation (Liu et al., 2015), and game-playing Go agents (Silver et al., 2016). However, our current understanding of CNN representations is limited, though there is a growing body of literature on visualization techniques for interpreting internal representations (Mahendran & Vedaldi, 2016; Dosovitskiy & Brox, 2015; Nguyen et al., 2016). In this work, we aim to understand the effect that the training data has on three key properties of representations: invariance, equivariance, and equivalence (Lenc & Vedaldi, 2015). Invariance, with respect to a particular transformation (e.g. rotation by θ = 5), is achieved when the feature vectors for input images at a particular layer do not change when the inputs are transformed. This can be seen as a measure of the robustness of the representation. Equivariance is a generalization of invariance and allows the representation to change in predictable ways in response to input transformations. Equivariance is a rough measure of the structure of the representation space because we can reason about input space transformations in the more abstract representation space. Likewise, measuring equivalence among network representations trained on either the same or different data distributions gives insight into how the training data shapes the representation. Data augmentation has been considered essential for top CNN performance since the seminal work of Krizhevsky et al. (2012). When input images are stochastically perturbed, less overfitting is observed because all inputs are unique. Since then, others have experimented with various data augmentation strategies with great success (Howard, 2013; Wu et al., 2015; He et al., 2014). While others have n",Analyzing the performance of multilayer neural networks for object recognition | Understanding deep features with computer-generated imagery | Digging deep into the layers of cnns: In search of how cnns achieve view invariance | Inverting visual representations with convolutional networks | Manitest: Are classifiers really invariant | Evaluation of deep convolutional nets for document image classification and retrieval | Spatial pyramid pooling in deep convolutional networks for visual recognition | Deep residual learning for image recognition | Some improvements on deep convolutional neural network based image classification | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | Understanding image representations by measuring their equivariance and equivalence | Convergent learning: Do different neural networks learn the same representations | Semantic image segmentation via deep parsing network | Visualizing data using t-sne | Visualizing deep convolutional neural networks using natural pre-images | Multifaceted feature visualization: Uncovering the different types of features learned by each neuron in deep neural networks | Exploring invariances in deep convolutional neural networks using synthetic images | Mastering the game of go with deep neural networks and tree | Best practices for convolutional neural networks applied to visual document analysis | Deep image: Scaling up image recognition,iclr,010
579.pdf.json,,"Time series, which is a sequence of data points in time order, is being generated in a wide spectrum of domains, such as daily fluctuation of the stock market, power consumption records of households, performance monitoring data of clusters in data centres, and so on. In many applications, users are interested in understanding the evolving trend in time series and forecasting the trend, since the conventional prediction on specific data points could deliver very little information about the semantics and dynamics of the underlying process generating the time series. For instance, time series in Figure 1 are from the household power consumption dataset1. Figure 1(a) shows some raw data points of time series. Though pointA andB have approximately the same value, the underlying system is likely to be in two different states when it outputs A and B, because A is in an upward trend whileB is in a downward trend (Wang et al., 2011; Matsubara et al., 2014). On the other hand, even when two points with the similar value are both in the upward trend, e.g, point A and C, the different slopes and durations of the trends where point A and C locate, could also indicate different states of the underlying process. Particularly, in this paper we are interested in the local trend of time series which measures the intermediate local behaviour, i.e., upward or downward pattern of time series that characterized by the slope and duration (Wang et al., 2011). For instance, in Figure 1(b) the linear segments over raw data points of time series represent the local trends extracted from a real household power consumption time series. For the ease of presentation, we will use the term trend and local trend interchangeably in the rest of the paper. Learning and forecasting local trends are quite useful in a wide range of applications. For instance, in the stock market, due to its high volatility and noisy environment, in reality predicting stock price trends is preferred over the prediction o","Forecasting stock market short-term trends using a neuro-fuzzy based methodology | Delving deeper into convolutional networks for learning video representations | Learning representations from eeg with deep recurrent-convolutional neural networks | Reinforced two-step-ahead weight adjustment technique for online training of recurrent neural networks | A novel model by evolving partially connected neural network for stock price trend forecasting | Anomaly detection in ecg time signals via deep long shortterm memory networks | Empirical evaluation of gated recurrent neural networks on sequence modeling | Long-term recurrent convolutional networks for visual recognition and description | Supervised Sequence Labelling with Recurrent Neural Networks | Framewise phoneme classification with bidirectional lstm and other neural network architectures | Deep, convolutional, and recurrent models for human activity recognition using wearables | Long short-term memory | A review of online learning in supervised neural networks | Large-scale video classification with convolutional neural networks | An online algorithm for segmenting time series | Adam: A method for stochastic optimization | Temporal convolutional networks: A unified approach to action segmentation | Protein secondary structure prediction using cascaded convolutional and recurrent neural networks | Learning to diagnose with lstm recurrent neural networks | Temporal embedding in convolutional neural networks for robust learning of abstract snippets | Revisit long short-term memory: An optimization perspective | Long short term memory networks for anomaly detection in time series | Deep captioning with multimodal recurrent neural networks (m-rnn) | Autoplait: Automatic mining of coevolving time sequences | On the importance of initialization and momentum in deep learning | Sequence to sequence learning with neural networks. In Advances in neural information processing | Show and tell: A neural image caption generator | Cnn-rnn: A unified framework for multi-label image classification | Morphological segmentation with window lstm neural networks | Finding semantics in time series | Empirical evaluation of rectified activations in convolutional network | Deep convolutional neural networks on multichannel time series for human activity recognition | Unsupervised machine condition monitoring using segmental hidden markov models | A review on the prediction of building energy consumption",iclr,010
580.pdf.json,INTELLIGIBLE LANGUAGE MODELING WITH INPUT SWITCHED AFFINE NETWORKS,"Neural networks and the general field of deep learning have made remarkable progress over the last few years in fields such as object recognition (Krizhevsky et al., 2012), language translation (Sutskever et al., 2014), and speech recognition (Graves et al., 2013). For all of the success of the deep learning approach however, there are certain application domains in which intelligibility of the system is an essential design requirement. One commonly used example is the necessity to understand the decisions that a self-driving vehicle makes when avoiding various obstacles in its path. Another example is the application of neural network methodologies to scientific discovery (Mante et al., 2013). Even where intelligibility is not an overt design requirement, it is fair to say that most users of neural networks would like to better understand the models they deploy. There are at least two approaches to creating intelligible network models. One approach is to build networks as normal, and then apply analysis techniques after training. Often this approach yields systems that perform extremely well, and whose intelligibility is limited. A second approach is to build a neural network where intelligibility is an explicit design constraint. In this case, the typical result is a system that can be understood reasonably well, but may underperform. In this work we follow this second approach and build intelligibility into our network model, yet without sacrificing performance for the task we studied. Designing intelligibility into neural networks for all application domains is a worthy, but daunting goal. Here we contribute to that larger goal by focusing on a commonly studied task, that of character based ∗This work was performed as an intern at Google Brain. †Work done as a member of the Google Brain Residency program (g.co/brainresidency) ‡Work performed when author was a visiting faculty at Google Brain. language modeling. We develop and analyze a model trained on a one-ste","Understanding intermediate layers using linear classifier probes | A linear dynamical system model for text | Learning phrase representations using rnn encoder-decoder for statistical machine translation | Capacity and trainability in recurrent neural networks | Speech recognition with deep recurrent neural networks | Lstm: A search space odyssey | Long short-term memory | Observable operator models for discrete stochastic time series | Visualizing and understanding recurrent networks | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | Building high-level features using large scale unsupervised learning | A simple way to initialize recurrent networks of rectified linear units | Recurrent switching linear dynamical systems | Visualizing data using t-sne | Large text compression benchmark: About the test data, 2011. URL http://mattmahoney. net/dc/textdata. [Online; accessed 15-November-2016 | Context-dependent computation by recurrent dynamics in prefrontal cortex | Learning recurrent neural networks with hessian-free optimization | Opening the black box: low-dimensional dynamics in high-dimensional recurrent neural networks | Generating text with recurrent neural networks | Sequence to sequence learning with neural networks. In Advances in neural information processing",iclr,010
581.pdf.json,SEQUENCE GENERATION WITH A PHYSIOLOGICALLY PLAUSIBLE MODEL OF HANDWRITING AND RECURRENT MIXTURE DENSITY NETWORKS,"Recent results (Graves, 2013) have demonstrated that, given a sufficiently large training data-set, Long Short-Term Memory (LSTM) (Hochreiter & Schmidhuber, 1997) Recurrent Mixture Density Networks (RMDNs) (Schuster, 1999) are capable of learning and generating convincing synthetic handwriting sequences. In this study we explore a similar network architecture combined with an intermediate feature representation, given by the parameters of a physiologically plausible model of handwriting: the Sigma Lognormal model (Plamondon, 1995; Plamondon et al., 2014). In the work by Graves (2013) and subsequent derivations, the RMDN operates on raw sequences of points recorded with a digitizing device. In our approach we preprocess the training data using an intermediate representation that describes a form of “motor program” coupled with a sequence of dynamic parameters that describe the evolution of the pen tip. By doing so, we use a representation that is more concise (i.e. lower in dimensionality), meaningful (i.e. every data point is a high level segment descriptor of the trajectory), and is resolution independent. This project stems from the observation that human handwriting results from the orchestration of a large number of motor and neural subsystems, and is ultimately produced with the execution of complex and skillful motions. As such we seek a representation that abstracts the complex task of trajectory formation from the neural network, which is then rather focused on a higher level task of movement planning. Note that for the scope of this study, we do not implement text-to-handwriting synthesis (Graves, 2013), but rather focus on the task of generating sequences that possess the statistical and dynamic qualities of handwriting, which can be expanded to calligraphy, asemic handwriting, drawings and graffiti (Berio & Leymarie, 2015; Berio et al., 2016)). In particular, we focus on two distinct tasks: (1) learning and generating motor plans and (2) given a motor pla","TensorFlow: Large-scale machine learning on heterogeneous systems, 2015. URL http://tensorflow.org/. Software available from tensorflow.org | Random Search for Hyper-Parameter Optimization | Learning dynamic graffiti strokes with a compliant robot | Computational Models for the Analysis and Synthesis of Graffiti Tag Strokes | Generation and analysis of handwriting script with the beta-elliptic model | Mixture density networks | Segmenting handwritten signatures at their perceptually important points | A neural network model for cursive script production | A tutorial on task-parameterized movement learning and retrieval | Perceptual saliency of points along the contour of everyday objects: A large-scale study | Maximum likelihood from incomplete data via the EM algorithm | An interactive system for the automatic generation of huge handwriting databases from a few specimens | A new methodology to improve myoelectric signal processing using handwriting | A model of handwriting | Information along contours and object boundaries | Neuromuscular representation and synthetic generation of handwritten whiteboard notes | Affine differential geometry analysis of human arm movements | Motion, emotion and empathy in esthetic experience | Learning to forget: Continual prediction with LSTM | Supervised Sequence Labelling with Recurrent Neural Networks | Generating sequences with recurrent neural networks | Generative Handwriting Demo using TensorFlow | Long short-term memory | Graphonomics: Contemporary research in handwriting | Adam: A method for stochastic optimization | The law relating the kinematic and figural aspects of drawing movements | The beta-velocity model for simulating handwritten korean scripts. In Electronic Publishing, Artistic Imaging, and Digital Typography | Effects of inertial load and velocity on the braking process of voluntary limb movements | Segmentation and reconstruction of on-line handwritten scripts | Why does deep and cheap learning work so well | A neuro-beta-elliptic model for handwriting generation movements | The iam-database: an english sentence database for offline handwriting recognition | Trajectory formation and handwriting: a computational model | Asymmetric velocity and acceleration profiles of human arm movements | Inferring motor programs from images of handwritten digits | Automatic extraction of sigma-lognormal parameters on signatures | On the difficulty of training recurrent neural networks | Dropout Improves Recurrent Neural Networks for Handwriting Recognition | A kinematic theory of rapid human movement | Recent developments in the study of rapid human movements with the kinematic theory | A Kinematic Theory of Rapid Human Movements | A multi-level representation paradigm for handwriting stroke generation | A neural model for generating and learning a rapid movement sequence | Recent Developments in the Study of Rapid Human Movements with the Kinematic Theory | The Lognormal Handwriter: Learning, Performing and Declining | Avoiding spurious submovement decompositions II | Planning reaches by evaluating stored postures | A neural oscillator-network model of temporal pattern generation | Better Generative Models for Sequential Data Problems: Bidirectional Recurrent Mixture Density Networks | Many regression algorithms, one unified model: A review | Training Recurrent neural Networks | Template-based Synthetic Handwriting Generation for the Training of Recognition Systems | Trajectory determines movement | A developmental study of the relationship between geometry and kinematics in drawing movements | A neural network model for arm trajectory formation using forward and inverse dynamics models | Drawing and Recognizing Chinese Characters with Recurrent Neural Network | 2008): first we measure the turning angle at each position of the input p[k] and then compute a smooth version of the signal by convolving it with a Hanning window. We assume that the turning angles have Figure 13: Input key-point estimation. Left, the (smoothed) turning angle surprisal signal and the key-points estimated with peak detection. Right, the corresponding key-points along the input trajectory",iclr,010
582.pdf.json,FOR THE TASK OF PRODUCT RECOMMENDATION,"Online product recommendation is now a key driver of demand, not only in E-commerce businesses that recommend physical products, such as Amazon (Marshall, 2006), TaoBao (Xiang, 2013) and Ebay (Academy, 2013), but also in online websites that recommend digital content such as news (Yahoo! - Agarwal et al. (2013), Google - Liu et al. (2010)), movies (Netflix - Bell & Koren (2007)), music (Spotify - Johnson (2015)), videos (YouTube - Covington et al. (2016)) and games (Xbox - Koenigstein et al. (2012)). Two of the most challenging aspects of recommendation in general and of product recommendation in particular, are scalability and freshness. The first one addresses the problem of making fast recommendations in parallel, the second addresses the problem of updating recommendations based on real-time user interaction. One of the most encountered architecture solutions for recommendation at scale divides the recommendation process in two stages: a candidate generation stage that prunes the number of recommendable items from billions to a couple of hundreds, followed by a second item selection stage that decides the final set of items to be displayed to the user, as shown in Figure 1 (see Mazare (2016), Cheng et al. (2016), Covington et al. (2016)). The first stage generally implies the pre-generation of an inverted index over the set of recommendable products, paired with a real-time retrieval module, similarly to a search engine architecture. In our current paper we focus on the cases where the system supports vectorial product queries. The sources of the vectorial representations range from the set of co-occurring products, like in the case of neighborhood-based collaborative filtering, to a low-dimensional representation produced via matrix factorization or to an embedded representation produced via a deep neural network. The second stage takes the candidate set and decides the final list of recommendations, usually by optimizing a ranking metric. This stage has in gen",Wide & deep learning for recommender systems | Deep neural networks for youtube recommendations | E-commerce in your inbox: Product recommendations at scale | node2vec: Scalable feature learning for networks. 2016 | Dimensionality reduction by learning an invariant mapping | Identity matters in deep learning | Deep residual learning for image recognition | Vbpr: visual bayesian personalized ranking from implicit feedback | Learning deep structured semantic models for web search using clickthrough data | Convolutional neural networks for sentence classification | The xbox recommender system | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | Personalized news recommendation based on click behavior | Venture beat article. http://venturebeat.com/2006/12/10/ aggregate-knowledge-raises-5m-from-kleiner-on-a-roll | Product recommendation at criteo | Image-based recommendations on styles and substitutes | Metric learning to rank | Efficient estimation of word representations in vector space | Distributed representations of words and phrases and their compositionality | Content-based recommendation systems | Glove: Global Vectors for Word Representation | Deep crossing: Webscale modeling without manually crafted combinatorial features | Swivel: Improving embeddings by noticing what’s missing | Learning semantic representations using convolutional neural networks for web search | Rethinking the inception architecture for computer vision | Deep content-based music recommendation | Meta-prod2vec-product embeddings using side-information for recommendation | Learning visual clothing style with heterogeneous dyadic co-occurrences | Structural deep network embedding | How transferable are features in deep neural networks | Logistic similarity metric learning for face verification,iclr,010
583.pdf.json,,"Recent advances in machine learning have renewed interest in artificial creativity. Studies such as deep dream (Mordvintsev et al., 2015) and style transfer (Gatys et al., 2015) have aroused both general public interest and have given strong impetus to use deep learning models in computational creativity research (ICC, 2016). Although creativity has been a topic of interest on and off throughout the years in machine learning (Schmidhuber, 2009), it has been slowly becoming a legitimate sub-domain with the appearance of dedicated research groups such as Google’s Magenta and research work on the topic (Nguyen et al., 2015; Lake et al., 2015). There is a large body of work studying creativity by computational methods. A large variety of techniques, from rule-based systems to evolutionary computation has been used for a myriad of research questions. Compared to these methods, machine learning methods provide an important advantage: they enable the study of creativity in relation with knowledge (i.e., knowledge-driven creativity; Kazakçı et al. (2016)). Nevertheless, to better highlight the points of interest in computational creativity research for the machine learning community and to allow machine learning researchers to provide systematic and rigorous answers to computational creativity problems, it is important to precisely answer three questions: 1. What is meant by the generation of novelty? 2. How can novelty be generated? 3. How can a model generating novelty be evaluated? Within the scope of machine learning, it would be tempting to seek answers to these questions in the sub-field on generative modeling. Mainstream generative modeling assumes that there is a phenomena generating the observed data and strive to build a model of that phenomena, which would, for instance, allow generating further observations. Traditional generative modeling considers only in-distribution generation where the goal is to generate objects from the category or categories of already ","Smart decisions by small adjust-ments: Iterating denoising autoencoders | Greedy layer-wise training of deep networks | Generalized denoising auto-encoders as generative models | Unlearning for better mixing | Boltzmann machines and denoising autoencoders for image denoising | Deep generative image models using a laplacian pyramid of adversarial networks | Image super-resolution using deep convolutional networks | Learning to generate chairs, tables and cars with convolutional networks. 2016 | Example-based super-resolution | A neural algorithm of artistic style | Generative adversarial nets | Ck design theory: an advanced formulation | A fast learning algorithm for deep belief nets | Conceptive artificial intelligence: Insights from design theory | Digits that are not: Generating new types through deep neural nets | Semi-supervised learning with deep generative models | Human-level concept learning through probabilistic program induction | Photo-realistic single image super-resolution using a generative adversarial network | Auxiliary deep generative models | Winner-take-all autoencoders | Inceptionism: Going deeper into neural networks | Innovation engines: Automated creativity and improved stochastic optimization via deep learning | Unsupervised representation learning with deep convolutional generative adversarial networks | Semisupervised learning with ladder networks | Oneshot generalization in deep generative models | Contractive autoencoders: Explicit invariance during feature extraction | The standard definition of creativity | Improved techniques for training GANs | Driven by Compression Progress: A Simple Principle Explains Essential Aspects of Subjective Beauty, Novelty, Surprise, Interestingness, Attention, Curiosity, Creativity, Art, Science, Music, Jokes, pp. 48–76 | A note on the evaluation of generative models | Image denoising and inpainting with deep neural networks | Semantic image inpainting with perceptual and contextual losses | Adadelta: an adaptive learning rate method",iclr,010
584.pdf.json,A JOINT MANY-TASK MODEL: GROWING A NEURAL NETWORK FOR MULTIPLE NLP TASKS,"The potential for leveraging multiple levels of representation has been demonstrated in a variety of ways in the field of Natural Language Processing (NLP). For example, Part-Of-Speech (POS) tags are used to train syntactic parsers. The parsers are used to improve higher-level tasks, such as natural language inference (Chen et al., 2016), relation classification (Socher et al., 2012), sentiment analysis (Socher et al., 2013; Tai et al., 2015), or machine translation (Eriguchi et al., 2016). However, higher level tasks are not usually able to improve lower level tasks, often because systems are pipelines and not trained end-to-end. In deep learning, unsupervised word vectors are useful representations and often used to initialize recurrent neural networks for subsequent tasks (Pennington et al., 2014). However, not being jointly trained, deep NLP models have yet shown benefits from predicting many (> 4) increasingly complex linguistic tasks each at a successively deeper layer. Instead, existing models are often designed to predict different tasks either entirely separately or at the same depth (Collobert et al., 2011), ignoring linguistic hierarchies. We introduce a Joint Many-Task (JMT) model, outlined in Fig. 1, which predicts increasingly complex NLP tasks at successively deeper layers. Unlike traditional NLP pipeline systems, our single JMT model can be trained end-to-end for POS tagging, chunking, dependency parsing, semantic relatedness, and textual entailment. We propose an adaptive training and regularization strategy to grow this model in its depth. With the help of this strategy we avoid catastrophic interference between tasks, and instead show that both lower and higher level tasks benefit from the joint training. Our model is influenced by the observation of Søgaard & Goldberg (2016) who showed that predicting two different tasks is more accurate when performed in different layers than in the same layer (Collobert et al., 2011). ∗Work was done while the f",Improved Transition-Based Parsing and Tagging with Neural Networks | Globally Normalized Transition-Based Neural Networks | Chunking and Dependency Parsing | Top Accuracy and Fast Dependency Parsing is not a Contradiction | Enhancing and Combining Sequential and Tree LSTM for Natural Language Inference | Parsing as Language Modeling | Natural Language Processing (Almost) from Scratch | TransitionBased Dependency Parsing with Stack Long Short-Term Memory | Tree-to-Sequence Attentional Neural Machine Translation | Maxout Networks | Framewise Phoneme Classification with Bidirectional LSTM and Other Neural Network Architectures | Improving neural networks by preventing co-adaptation of feature detectors | Long short-term memory | Easy-First Dependency Parsing with Hierarchical Tree LSTMs | Chunking with Support Vector Machines | Ask Me Anything: Dynamic Memory Networks for Natural Language Processing | Illinois-LH: A Denotational and Distributional Approach to Semantics | Learning without Forgetting | Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation | Multi-task Sequence to Sequence Learning | End-to-end Sequence Labeling via Bi-directional LSTM-CNNsCRF | SemEval-2014 Task 1: Evaluation of Compositional Distributional Semantic Models on Full Sentences through Semantic Relatedness and Textual Entailment | Distributed Representations of Words and Phrases and their Compositionality | Cross-stitch Networks for Multi-task Learning | Gated Word-Character Recurrent Language Model | Word Embedding-based Antonym Detection using Thesauri and Distributional Information | Glove: Global Vectors for Word Representation | Dropout improves Recurrent Neural Networks for Handwriting Recognition | Semantic Compositionality through Recursive Matrix-Vector Spaces | Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank | Semi-supervised condensed nearest neighbor for part-of-speech tagging | Deep multi-task learning with low level tasks supervised at lower layers | Sequence to Sequence Learning with Neural Networks | Semi-Supervised Sequential Labeling and Segmentation Using Giga-Word Scale Unlabeled Data | Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks | Feature-Rich Partof-Speech Tagging with a Cyclic Dependency Network | Learning with Lookahead: Can HistoryBased Models Rival Globally Optimized Models | Structured Training for Neural Network Transition-Based Parsing | CHARAGRAM: Embedding Words and Sentences via Character n-grams | ABCNN: Attention-Based Convolutional Neural Network for Modeling Sentence Pairs | Modelling Sentence Pairs with Tree-structured Attentive Encoder,iclr,010
586.pdf.json,,"Deep Neural Networks (DNNs) are extremely useful for solving difficult pattern recognition tasks for two reasons: first, because they can compactly represent good solutions to difficult pattern recognition tasks; and second, because these good solutions can be found with stochastic gradient descent. It is not immediately obvious that a DNN should have the ability to represent solutions to such problems compactly. This is the case because the depth and width of DNNs allows them to simulate any parallel computer that runs for a modest number of steps, making it possible for the DNN to match the performance of any parallelizeable statistical ML model by simply simulating it. This is one of the reasons DNNs are successful relative to other ML models. DNNs are especially useful in the supervised learning setting, where the goal is achieve low test error over a given data distribution. Statistical learning theory (Vapnik, 2013) guarantees that this can be done by minimizing training error, as long as the training data is drawn from the same data distribution and when there is more training cases than parameters. While the ability to achieve low test error on a specific data distribution is extremely useful in practice and has already enabled a wide range of practical applications, there is evidence that this ability does not fully capture the intuitive notion of pattern recognition. For example, the existence of adversarial examples, which are data cases that are nearly indistinguishable from real data cases that confuse all existing discriminative classifiers, suggests that supervised DNNs are substantially less robust than human pattern recognition. And indeed, we would expect a system that has fully “understood” the relevant visual (say) concepts to not be fooled by adversarial examples. Understanding and fixing this problem is an active area of research. 1Work done while at OpenAI. Another domain where a mere low error on a specific data distribution seems unsatisfyin","Tensorflow: Large-scale machine learning on heterogeneous systems, 2015 | Learning efficient algorithms with hierarchical attentive memory | Neural machine translation by jointly learning to align and translate | Curriculum learning | Genetic Algorithms in Search, Optimization and Machine Learning | Accelerated neural evolution through cooperatively coevolved synapses | Adaptive computation time for recurrent neural networks | Neural turing machines | Learning to transduce with unbounded memory | Memoryefficient backpropagation through time | Adaptation in Natural and Artificial Systems: An Introductory Analysis with Applications to Biology, Control and Artificial Intelligence | Inferring algorithmic patterns with stack-augmented recurrent nets | Neural gpus learn algorithms | Grid long short-term memory | Neural random-access machines | Learning dependency-based compositional semantics | Training deep and recurrent networks with hessian-free optimization | Evolutionary program induction of binary machine code and its applications | Overfeat: Integrated recognition, localization and detection using convolutional networks | A formal theory of inductive inference | Dropout: a simple way to prevent neural networks from overfitting | Weakly supervised memory networks | The nature of statistical learning theory | A representation scheme to perform program induction in a canonical genetic algorithm. In Parallel Problem Solving from NaturePPSN | Cellular automata as models of complexity | Learning to execute | Reinforcement learning neural turing machines | Learning simple algorithms from examples",iclr,010
587.pdf.json,,"Recent years have witnessed the breakthrough of deep learning techniques for image classification and object recognition. Mobile device becomes more and more popular due to its convenient mobiles services provided for end users. More and more mobile applications require deep learning techniques to provide accurate, intelligent and effective services. However, the execution speed of the deep learning model on mobile devices becomes a bottleneck for many applications due to the large model size, deep network structure and complicated model parameters, which hinders the real-time deployment. However, if deep learning service is only provided at cloud side, transmis- sion of images though internet may compromise image owners’ privacy and is also limited by the availability of the Internet. Running deep learning models efficiently on mobile CPUs is a highly intriguing feature due to many reasons: (1) CPU is available for all mobile devices, even phones released many years ago; (2) powerful CUDA-enabled GPUs are generally not available on (compact) mobile devices; (3) though a large majority of mobile devices are equipped with mobile GPUs, the speed-up achieved on the mobile GPUs is quite limited when compared to CPU sh1r0 et al. (2015), not to mention the complexity caused by different mobile GPU architectures; (4) major deep learning frameworks such as Caffe Jia et al. (2014) and Tensorflow Abadi et al. (2015) only support CPU implementation on mobile devices currently, and therefore an efficient CPU-friendly model is highly desirable. However, most of current mobile CPUs cannot meet the needs of deep learning model deployment because it takes much longer time and higher energy cost to process an image using pre-trained deep learning models. For example, it takes more than 651ms to recognize an image using GoogleNet on Samsung S5 (Table 4) with 984mJ energy costs (Table 5). Therefore a question that naturally follows is: can we develop an efficient deep learning acceler","Provable bounds for learning some deep representations | Stochastic Gradient Tricks | Compressing neural networks with the hashing | Exploiting linear structure within convolutional networks for efficient evaluation | Understanding the difficulty of training deep feedforward neural networks | Compressing deep convolutional networks using vector quantization | Eie: Efficient inference engine on compressed deep neural network | Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding | Deep residual learning for image recognition | Squeezenet: Alexnet-level accuracy with 50x fewer parameters and <1mb model size | Caffe: Convolutional architecture for fast feature embedding | Quantized convolutional neural networks for mobile devices | Compression of deep convolutional neural networks for fast and low power mobile applications | Imagenet classification with deep convolutional neural networks | Xnor-net: Imagenet classification using binary convolutional neural networks | CNN features off-the-shelf: an astounding baseline for recognition | Striving for simplicity: The all convolutional net | Improving the speed of neural networks on cpus | How transferable are features in deep neural networks | Accurate online power estimation and automatic battery behavior based power model generation for smartphones",iclr,010
588.pdf.json,SEMI-SUPERVISED DETECTION OF EXTREME WEATHER EVENTS IN LARGE CLIMATE DATASETS,"Climate change is one of the most important challenges facing humanity in the 21st century and climate simulations are one of the only viable mechanisms for understanding the future impact of various carbon emission scenarios and intervention strategies. Large climate simulations produce massive datasets: a single 30-year run from a 25-km resolution model produces on the order of 10TB of multi-variate data. This scale of data makes post-processing such datasets to make quantitative assessments challenging and as a result, climate analysts and policy makers typically take global and annual averages of temperature or sea-level rise. These quantities are very coarse measurements and while they are perfect for public and media consumption, they ignore spatially (and temporally) resolved extreme weather events such as extra-tropical cyclones and tropical cyclones (hurricanes). Because the general public and policy makers are concerned about the local impacts of climate change, it is critical that we be able to analyze trends in extreme weather events which can have dramatic and tragic impacts on local and national populations and economies. The task of finding extreme weather events in climate data has some similarities to the task of detecting objects and activities in video streams - a popular application area for deep learning techniques. An important difference is that in the case of climate data the ’video’ has 16 or more ’channels’ of information (such as water vapour, pressure and temperature), while conventional video only has 3 (RGB). In addition, these climate simulations do not share the same statistics as natural images. As a result, we cannot build off of some of the computer vision communities’ efforts, such as pretrained weights from VGG or AlexNet with ImageNet. Deep neural networks, especially deep convolutional neural networks, have enjoyed breakthrough success in recent recent years, achieving state-of-the-art results on many benchmark datasets (Krizhe","Delving deeper into convolutional networks for learning video representations | Deepdriving: Learning affordance for direct perception in autonomous driving | Atmospheric rivers, floods and the water resources of california | Long-term recurrent convolutional networks for visual recognition and description | Generative adversarial nets | Delving deep into rectifiers: Surpassing human-level performance on imagenet classification | Alzheimer’s disease diagnostics by a deeply supervised adaptable 3d convolutional network. 2016 | 3d convolutional neural networks for human action recognition | Large-scale video classification with convolutional neural networks | Adam: A method for stochastic optimization | Auto-encoding variational bayes | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | The detection of atmospheric rivers in atmospheric reanalyses and their links to british winter floods and the large-scale climatic circulation | Ssd: Single shot multibox detector | Application of deep convolutional neural networks for detecting extreme weather in climate | Imilast: A community effort to intercompare extratropical cyclone detection and tracking algorithms | Deep face recognition | Teca: A parallel toolkit for extreme climate analysis | Teca: Petascale pattern recognition for climate science | You only look once: Unified, real-time object detection | Faster r-cnn: Towards real-time object detection with region proposal | Imagenet large scale visual recognition challenge | Overfeat: Integrated recognition, localization and detection using convolutional networks | Unsupervised learning of video representations using lstms | Going deeper with convolutions | Theano: A python framework for fast computation of mathematical expressions | Learning spatiotemporal features with 3d convolutional networks | Resolution dependence of future tropical cyclone projections of cam5.1 in the u.s. clivar hurricane working group idealized configurations | Understanding visual concepts with continuation learning | Synthesizing dynamic textures and sounds by spatial-temporal generative convnet | Convolutional lstm network: A machine learning approach for precipitation nowcasting | Describing videos by exploiting temporal structure | Augmenting supervised neural networks with unsupervised objectives for large-scale image classification | Stacked what-where auto-encoders",iclr,010
589.pdf.json,GRAPH CONVOLUTIONAL RECURRENT NETWORKS,"Many real-world data can be cast as structured sequences, with spatio-temporal sequences being a special case. A well-studied example of spatio-temporal data are videos, where succeeding frames share temporal and spatial structures. Many works, such as Donahue et al. (2015); Karpathy & FeiFei (2015); Vinyals et al. (2015), leveraged a combination of CNN and RNN to exploit such spatial and temporal regularities. Their models are able to process possibly time-varying visual inputs for variable-length prediction. These neural network architectures consist of combining a CNN for visual feature extraction followed by a RNN for sequence learning. Such architectures have been successfully used for video activity recognition, image captioning and video description. More recently, interest has grown in properly fusing the CNN and RNN models for spatio-temporal sequence modeling. Inspired by language modeling, Ranzato et al. (2014) proposed a model to represent complex deformations and motion patterns by discovering both spatial and temporal correlations. They showed that prediction of the next video frame and interpolation of intermediate frames can be achieved by building a RNN-based language model on the visual words obtained by quantizing the image patches. Their highest-performing model, recursive CNN (rCNN), uses convolutions for both inputs and states. Shi et al. (2015) then proposed the convolutional LSTM network (convLSTM), a recurrent model for spatio-temporal sequence modeling which uses 2D-grid convolution to leverage the spatial correlations in input data. They successfully applied their model to the prediction of the evolution of radar echo maps for precipitation nowcasting. The spatial structure of many important problems may however not be as simple as regular grids. For instance, the data measured from meteorological stations lie on a irregular grid, i.e. a network of heterogeneous spatial distribution of stations. More challenging, the spatial structure of d",Long-term recurrent convolutional networks for visual recognition and description | Recurrent nets that time and count | Generating sequences with recurrent neural networks | Long short-term memory | Structural-RNN: Deep Learning on SpatioTemporal Graphs | Deep visual-semantic alignments for generating image descriptions | Semi-Supervised Classification with Graph | Gated graph sequence neural networks | Semantic object parsing with graph lstm | Geodesic convolutional neural networks on riemannian manifolds | Estimation of Word Representations in Vector Space | Learning Convolutional Neural Networks for Graphs | Video (language) modeling: a baseline for generative models of natural videos | The graph neural network model | Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting | The Emerging Field of Signal Processing on Graphs: Extending High-Dimensional Data Analysis to Networks and other Irregular Domains | Unsupervised learning of video representations using lstms | Sequence to sequence learning with neural networks. In Advances in neural information processing systems | Improved semantic representations from treestructured long short-term memory networks | Show and tell: A neural image caption generator | Recurrent neural network regularization,iclr,010
590.pdf.json,,"Reading comprehension-based question answering (RCQA) is the task of answering a question with a chunk of text taken from related document(s). A variety of neural models have been proposed recently either for extracting a single entity or a single token as an answer from a given text (Hermann et al., 2015; Kadlec et al., 2016; Trischler et al., 2016b; Dhingra et al., 2016; Chen et al., 2016; Sordoni et al., 2016; Cui et al., 2016a); or for selecting the correct answer by ranking a small set of human-provided candidates (Yin et al., 2016; Trischler et al., 2016a). In both cases, an answer boundary is either easy to determine or already given. Different from the above two assumptions for RCQA, in the real-world QA scenario, people may ask questions about both entities (factoid) and non-entities such as explanations and reasons (nonfactoid) (see Table 1 for examples). In this regard, RCQA has the potential to complement other QA approaches that leverage structured data (e.g., knowledge bases) for both the above question types. This is because RCQA can exploit the textual evidences to ensure increased answer coverage, which is particularly helpful for nonfactoid answers. However, it is also challenging for RCQA to identify answer in arbitrary position in the passage with arbitrary length, especially for non-factoid answers which might be clauses or sentences. As a result, apart from a few exceptions (Rajpurkar et al., 2016; Wang & Jiang, 2016), this research direction has not been fully explored yet. Compared to the relatively easier RC task of predicting single tokens/entities1, predicting answers of arbitrary lengths and positions significantly increase the search space complexity: the number of possible candidates to consider is in the order of O(n2), where n is the number of passage words. In contrast, for previous works in which answers are single tokens/entities or from candidate lists, the complexity is in O(n) or the size of candidate lists l (usually l ≤5), res","Neural machine translation by jointly learning to align and translate | Curriculum learning | Learning to rank: from pairwise approach to listwise approach | Hierarchical memory networks | A thorough examination of the cnn/daily mail reading comprehension | Learning phrase representations using rnn encoder-decoder for statistical machine translation | Attention-overattention neural networks for reading comprehension | Consensus attention-based neural networks for chinese reading comprehension | Gated-attention readers for text comprehension | Bagging gradient-boosted trees for high precision, low variance ranking models | Neural turing machines | Learning to transduce with unbounded memory | Dynamic neural turing machine with soft and hard addressing schemes | Teaching machines to read and comprehend | The goldilocks principle: Reading children’s books with explicit memory representations | Text understanding with the attention sum reader network | Adam: A method for stochastic optimization | Dynamic entity representations with max-pooling improves machine reading | The Stanford CoreNLP natural language processing toolkit | Who did What: A large-scale person-centered cloze dataset | Glove: Global vectors for word representation | Squad: 100,000+ questions for machine comprehension of text | Mctest: A challenge dataset for the open-domain machine comprehension of text | Reasoning about entailment with neural attention | Iterative alternating neural attention for machine reading | Movieqa: Understanding stories in movies through question-answering | A parallel-hierarchical model for machine comprehension on sparse data | Natural language comprehension with the epireader | Learning natural language inference with lstm | Machine comprehension using match-lstm and answer pointer | Separating answers from queries for neural reading comprehension | Attention-based convolutional neural network for machine comprehension | Empirical study on deep learning models for question answering | Reinforcement learning neural turing machines | Structured memory for neural turing machines",iclr,010
591.pdf.json,SAMPLE IMPORTANCE IN TRAINING DEEP NEURAL NETWORKS,"Sample importance is the sample’s contribution to the parameter change during training. In statistics, the concept “leverage” of a point is used (St Laurent & Cook (1992)) to measure the impact of a sample on the training of a model. In the context of SVM, the most important samples are the support vectors as they define the separating hyperplane. Understanding the importance of the samples can help us interpret trained models and structure training to speed up convergence and improve prediction accuracy. For example, Curriculum learning (CL) from Bengio et al. (2009) shows that training with easy samples first, then gradually transitioning to difficult samples can improve the learning. In CL, the “easiness” of a sample is predefined either manually or using an evaluation model. Self-paced learning (SPL) (Kumar et al. (2010)) shows that it is possible to learn from samples in order of easiness. In this framework, easiness is related to the prediction error and can be estimated from the model. However, easiness of a sample may not be sufficient to decide when it should be introduced to a learner. Maintaining diversity among the training samples can have a substantial effect on the training (Jiang et al. (2014)). In this work, we explore the sample importance in deep neural networks. Deep learning methods have been successfully applied in many tasks and routinely achieve better generalization error than classical shallow methods (LeCun et al. (2015)). One of the key characteristics of a deep network is its capacity to construct progressively more complex features throughout its layers (Lee et al. (2011)). An intuitive question arises: which samples contribute the most to the training of the different layer’s parameters? From literature Saxe et al. (2011), we know that even randomly generated filters can compute features that lead to good performance – presumably on easy samples. However, to learn hard samples correctly, the model may need to construct complex features",Theano: new features and speed improvements | Curriculum learning | Theano: a CPU and GPU math expression compiler | Understanding the difficulty of training deep feedforward neural networks | Self-paced learning with diversity | Learning multiple layers of features from tiny | Self-paced learning for latent variable models | Unsupervised learning of hierarchical representations with convolutional deep belief networks | On random weights and unsupervised feature learning | Leverage and superleverage in nonlinear regression,iclr,010
592.pdf.json,EPITOMIC VARIATIONAL AUTOENCODER,"Unsupervised learning holds the promise of learning the inherent structure in data so as to enable many future tasks including generation, prediction and visualization. Generative modeling is an approach to unsupervised learning wherein an explicit stochastic generative model of data is defined, such that independent draws from this model are likely to produce the original data distribution, while the learned latent structure itself is useful in prediction, classification and visualization tasks. The recently proposed variational autoencoder (VAE) (Kingma & Welling, 2014) is an example of one such generative model. VAE pairs a top down generative model with a bottom up recognition network for amortized probabilistic inference. Both networks are jointly trained to maximize a variational lower bound on the data likelihood. A number of recent works use VAE as a modeling framework, including iterative conditional generation of images (Gregor et al., 2015) and conditional future frame prediction (Xue et al., 2016). A commonly known problem with the VAE lower bound is that it is known to self-prune or under utilize the model’s capacity (Mackay, 2001). This can lead to poor generalization. A common approach to alleviate this problem is to resort to optimization schedules and regularization techniques (Bowman et al., 2015; Kaae Sonderby et al., 2016) that trade-off two competing terms, latent cost and data reconstruction, in the bound. Fig. 1 provides a quick insight into this problem of over-pruning and how commonly used regularization techniques may not be sufficient. Detailed discussion is provided in § 2.1. In this paper, we take a model-based approach to directly address this problem. We present an extension of variational autoencoders called epitomic variational autoencoder (Epitomic VAE, or eVAE, for short) that automatically learns to utilize its model capacity more effectively, leading to better generalization. Consider the task of learning a D-dimensional represen","Generating sentences from a continuous space | Importance weighted autoencoders | Attend, infer, repeat: Fast scene understanding with generative models | Structured sparse coding via lateral inhibition | Draw: A recurrent neural network for image generation | Proximal methods for hierarchical sparse coding | Epitomic analysis of appearance and shape | How to train deep variational autoencoders and probabilistic ladder networks | Adam: A method for stochastic optimization | Improving variational inference with inverse autoregressive flow | Auto-encoding variational bayes | Deep convolutional inverse graphics | The mnist database of handwritten digits | Local minima, symmetry-breaking, and model pruning in variational free energy minimization | Variational inference with normalizing flows | A generative process for sampling contractive auto-encoders | Markov chain monte carlo and variational inference: Bridging the gap | The toronto face database | Visual dynamics: Probabilistic future frame synthesis via cross convolutional networks | Attribute2image: Conditional image generation from visual attributes",iclr,010
593.pdf.json,IN DEEP GENERATIVE MODELS,"Reasoning in complex perceptual domains such as vision often requires the ability to effectively learn flexible representations of high-dimensional data, interpret the representations in some form, and understand how the representations can be used to reconstruct the data. The ability to learn representations is a measure of how well one can capture relevant information in the data. Being able to interpret the learned representations is a measure of extracting consistent meaning in an effort to make sense of them. Having the ability to reliably reconstruct the data, a tool for predictive synthesis, can aid in model diagnosis, enable successful transfer learning, and improve generality. Such tasks are typically best addressed by generative models, as they exhibit the flexibility required to satisfy all three facets. Discriminative models primarily attend to the first two, learning flexible representations and conforming to some interpretable space (e.g. classification domain) but don’t perform the predictive synthesis task. Probabilistic graphical models (Koller & Friedman, 2009; Murphy, 2012) are a framework for generative modelling that enables specifying a joint probability distribution on a richly semantic representation space. As good a fit as they are for specification and representation, the learning process for both the analysis and synthesis tasks typically suffers in complex perceptual domains such as vision. This is because constructing a generative model requires explicitly specifying the conditional distribution of the observed data given latent variables of interest. In practice, designing such likelihood functions by hand is incredibly challenging, and applying generative models to vision data often requires extensive and significant feature engineering to be successful. One approach to alleviate some of this hardship involves the development of deep generative models: generative models that employ neural networks to learn, automatically from data, the","Neural module networks | Estimating or propagating gradients through stochastic neurons for conditional computation | Infogan: Interpretable representation learning by information maximizing generative adversarial nets | Torch7: A matlab-like environment for machine learning | Attend, infer, repeat: Fast scene understanding with generative models | Generative adversarial nets | A language for generative models | Spatial transformer networks | Consensus message passing for layered graphical models | Composing graphical models with neural networks for structured representations and fast inference | Adam: A method for stochastic optimization | Auto-encoding variational bayes | Semi-supervised learning with deep generative models | Probabilistic graphical models: principles and techniques | Picture: A probabilistic programming language for scene perception | Deep convolutional inverse graphics network | Inference compilation and universal probabilistic programming | Neural variational inference and learning in belief networks | Machine learning: a probabilistic perspective | Hierarchical variational models | Stochastic backpropagation and approximate inference in deep generative models | Deep amortized inference for probabilistic programs | Gradient estimation using stochastic computation graphs | Learning structured output representation using deep conditional generative models | Simple statistical gradient-following algorithms for connectionist reinforcement learning | Lightweight implementations of probabilistic programming languages via transformational compilation | A new approach to probabilistic programming inference",iclr,010
594.pdf.json,LOW-RANK PASSTHROUGH NEURAL NETWORKS,,Unitary evolution recurrent neural networks | Neural machine translation by jointly learning to align and translate | Learning long-term dependencies with gradient descent is difficult | On the properties of neural machine translation: Encoder-decoder approaches | Learning phrase representations using rnn encoder-decoder for statistical machine translation | A character-level decoder without explicit segmentation for neural machine translation | Associative Long Short-Term Memory | A theoretically grounded application of dropout in recurrent neural networks | Deep sparse rectifier neural networks | Generating sequences with recurrent neural networks | Framewise phoneme classification with bidirectional lstm and other neural network architectures | Speech recognition with deep recurrent neural networks | Neural turing machines | Deep residual learning for image recognition | Orthogonal RNNs and Long-Memory Tasks | Untersuchungen zu dynamischen neuronalen netzen | Long short-term memory | Batch normalization: Accelerating deep network training by reducing internal covariate shift | A neural network for factoid question answering over paragraphs | Exploring the limits of language modeling | Neural gpus learn algorithms | Adam: A method for stochastic optimization | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | A simple way to initialize recurrent networks of rectified linear units | Learning methods for generic object recognition with invariance to pose and lighting | Fully character-level neural machine translation without explicit segmentation | Character-based neural machine translation | Long short-term memory recurrent neural network architectures for large scale acoustic modeling | Weight normalization: A simple reparameterization to accelerate training of deep neural networks | Neural machine translation of rare words with subword units | Dropout: A simple way to prevent neural networks from overfitting | Temporal localization of fine-grained actions in videos by domain transfer from web images | Deep learning using linear support vector machines | Grammar as a foreign language | Recurrent neural network regularization | Architectural complexity measures of recurrent neural networks,iclr,010
595.pdf.json,INFERENCE & INTROSPECTION IN DEEP GENERATIVE MODELS OF SPARSE DATA,"Deep latent Gaussian models (DLGMs, a.k.a. variational autoencoders; Rezende et al., 2014; Kingma et al., 2014) have led a resurgence in the use of deep generative models for density estimation. DLGMs assume that observed vectors x are generated by applying a nonlinear transformation (defined by a neural network with parameters θ) to a vector of Gaussian random variables z. Learning in DLGMs proceeds by approximately maximizing the average marginal likelihood p(x) ≡∫ z p(z)p(x|z)dz of the observations x. Computing the true marginal likelihood is intractable, so we resort to variational expectation-maximization (Bishop, 2006), an approximation to maximumlikelihood estimation. To learn the parameters θ of the generative model, the procedure needs to find a distribution q(z|x) that approximates the posterior distribution p(z|x) of the latent vector z given the observations x. In the past, such q distributions were fit using iterative optimization procedures (e.g., Hoffman et al., 2013). But Rezende et al. (2014) and Kingma et al. (2014) showed that q(z|x) can be parameterized by a feedforward “inference network” with parameters φ, speeding up learning. This inference network is trained jointly with the generative model; as training proceeds, the inference network learns to approximate posterior inference on the generative model, and the generative model improves itself using the output of the inference network. Embedded within this procedure, however, lies a potential problem: both the inference network and the generative model are initialized randomly. Early on in learning, the inference network’s q(z|x) distributions will be poor approximations to the true posterior p(z|x), and the gradients used to update the parameters of the generative model will therefore be poor approximations to the gradients of the true log-likelihood log p(x). Previous stochastic variational inference methods (Hoffman et al., 2013) were slower, but suffered less from this problem since for ev","Modern information retrieval, volume 463 | A neural probabilistic language model | Pattern Recognition and Machine Learning | Statistical modeling: The two cultures | Importance weighted autoencoders | Learning low-dimensional representations of medical concepts | A unified architecture for natural language processing: Deep neural networks with multitask learning | Medical semantic similarity with a neural language model | Visualizing higher-layer features of a deep | Placing search in context: The concept revisited | Building the graph of medicine from millions of clinical narratives | Understanding the difficulty of training deep feedforward neural networks | Replicated softmax: an undirected topic model | The” wake-sleep” algorithm for unsupervised neural networks | Iterative refinement of approximate posterior for training directed belief networks | Stochastic variational inference | Improving Word Representations via Global Context and Multiple Word Prototypes | Exploiting generative models in discriminative classifiers | Adam: A method for stochastic optimization | Auto-encoding variational bayes | Semi-supervised learning with deep generative models | An introduction to latent semantic analysis | The 20 newsgroups data | Exploring strategies for training deep neural networks | RCV1: A new benchmark collection for text categorization research | Generative topic embedding: a continuous representation of documents | Neural variational inference for text processing | Distributed representations of words and phrases and their compositionality | Neural variational inference and learning in belief networks | Glove: Global vectors for word representation | Stochastic backpropagation and approximate inference in deep generative models | Exponential family embeddings | Efficient learning of deep boltzmann machines | intelligence,” objectively determined and measured | A tutorial on spectral clustering | Analysis of deep neural networks with the extended data jacobian matrix | NETFLIX: EMBEDDINGS FOR MOVIES The Netflix dataset Netflix (2009) comprises movie ratings of 500, 000 users. We treat each user’s ratings as a document and model the numbers ascribed to each movie (from 1− 5) as counts drawn from the multinomial distribution parameterized as in Eq",iclr,010
596.pdf.json,IMPLICIT REASONET: MODELING LARGE-SCALE STRUCTURED RELATIONSHIPS WITH SHARED MEM- ORY,"Knowledge bases such as WordNet (Fellbaum, 1998), Freebase (Bollacker et al., 2008), or Yago (Suchanek et al., 2007) contain many real-world facts expressed as triples, e.g., (Bill Gates, FounderOf, Microsoft). These knowledge bases are useful for many downstream applications such as question answering (Berant et al., 2013; Yih et al., 2015) and information extraction (Mintz et al., 2009). However, despite the formidable size of knowledge bases, many important facts are still missing. For example, West et al. (2014) showed that 21% of the 100K most frequent PERSON entities have no recorded nationality in a recent version of Freebase. We seek to infer unknown relations based on the observed triples. Thus, the knowledge base completion (KBC) task has emerged an important open research problem (Nickel et al., 2011). Neural-network based methods have been very popular for solving the KBC task. Following Bordes et al. (2013), one of the most popular approaches for KBC is to learn vector-space representations of entities and relations during training, and then apply linear or bi-linear operations to infer the missing relations at test time. However, several recent papers demonstrate limitations of prior approaches relying upon vector-space models alone. By themselves, there is no straightforward way to capture the structured relationships between multiple triples adequately (Guu et al., 2015; Toutanova et al., 2016; Lin et al., 2015a). For example, assume that we want to fill in the missing relation for the triple (Obama, NATIONALITY, ?), a multi-step search procedure might be needed to discover the evidence in the observed triples such as (Obama, BORNIN, Hawaii) and (Hawaii, PARTOF, U.S.A). To address this issue, Guu et al. (2015); Toutanova et al. (2016); Lin et al. (2015a) propose different approaches of injecting structured information by directly operating on the observed triplets. Unfortunately, due to the size of knowledge bases, these newly proposed approaches suf","Semantic parsing on Freebase from questionanswer pairs | Freebase: A collaboratively created graph database for structuring human knowledge | Learning structured embeddings of knowledge bases | Translating embeddings for modeling multi-relational data | A semantic matching energy function for learning with multi-relational data | Learning phrase representations using rnn encoder-decoder for statistical machine translation | WordNet: An Electronic Lexical Database | Composing relationships with translations | Combining two and three-way embeddings models for link prediction in knowledge | Neural turing machines | Hybrid computing using a neural network with dynamic external memory | Traversing knowledge graphs in vector space | Learning to represent knowledge graphs with gaussian embedding | Knowledge graph embedding via dynamic mapping matrix | Planning and acting in partially observable stochastic domains | Modeling relation paths for representation learning of knowledge bases | Learning entity and relation embeddings for knowledge graph completion | Distant supervision for relation extraction without labeled data | STransE: a novel embedding model of entities and relationships in knowledge bases | A three-way model for collective learning on multi-relational data | why should i trust you?"": Explaining the predictions of any classifier | Relation extraction with matrix factorization and universal schemas | Reasonet: Learning to stop reading in machine comprehension | Reasoning With Neural Tensor Networks For Knowledge Base Completion | A neural network approach to context-sensitive generation of conversational responses | Yago: A Core of Semantic Knowledge | End-to-end memory networks | Sequence to sequence learning with neural networks | Observed versus latent features for knowledge base and text inference | Representing text for joint embedding of text and knowledge bases | Compositional learning of embeddings for relation paths in knowledge bases and text | Knowledge graph embedding by translating on hyperplanes | Mining inference formulas by goal-directed random walks | Knowledge base completion via search-based question answering | Simple statistical gradient-following algorithms for connectionist reinforcement learning | Embedding entities and relations for learning and inference in knowledge | Semantic parsing via staged query graph generation: Question answering with knowledge base",iclr,010
597.pdf.json,,"Combinatorial optimization is a fundamental problem in computer science. A canonical example is the traveling salesman problem (TSP), where given a graph, one needs to search the space of permutations to find an optimal sequence of nodes with minimal total edge weights (tour length). The TSP and its variants have myriad applications in planning, manufacturing, genetics, etc. (see (Applegate et al., 2011) for an overview). Finding the optimal TSP solution is NP-hard, even in the two-dimensional Euclidean case (Papadimitriou, 1977), where the nodes are 2D points and edge weights are Euclidean distances between pairs of points. In practice, TSP solvers rely on handcrafted heuristics that guide their search procedures to find competitive (and in many cases optimal) tours efficiently. Even though these heuristics work well on TSP, once the problem statement changes slightly, they need to be revised. In contrast, machine learning methods have the potential to be applicable across many optimization tasks by automatically discovering their own heuristics based on the training data, thus requiring less handengineering than solvers that are optimized for one task only. While most successful machine learning techniques fall into the family of supervised learning, where a mapping from training inputs to outputs is learned, supervised learning is not applicable to most combinatorial optimization problems because one does not have access to optimal labels. However, one can compare the quality of a set of solutions using a verifier, and provide some reward feedbacks to a learning algorithm. Hence, we follow the reinforcement learning (RL) paradigm to tackle combinatorial optimization. We empirically demonstrate that, even when using optimal solutions as labeled data to optimize a supervised mapping, the generalization is rather poor compared to an RL agent that explores different tours and observes their corresponding rewards. We propose Neural Combinatorial Optimization, a framew",Tensorflow: A system for largescale machine learning | A theoretical investigation into the performance of the Hopfield model | Self-organizing feature maps and the Travelling Salesman Problem | Implementing the dantzigfulkerson-johnson algorithm for large traveling salesman problems | The traveling salesman problem: a computational study | Neural machine translation by jointly learning to align and translate | An approximate dynamic programming approach to multidimensional knapsack problems | Hyperheuristics: An emerging direction in modern search technology | Hyper-heuristics: a survey of the state of the art | Neural methods for the Traveling Salesman Problem: insights from operations research | Noisy parallel approximate decoding for conditional recurrent language model | Worst-case analysis of a new heuristic for the Travelling Salesman Problem | Solution of a large-scale traveling-salesman problem | An analogue approach to the Travelling Salesman | A study of the application of Kohonen-type neural networks to the travelling salesman problem | Solving a combinatorial problem via self-organizing process: an application of the Kohonen algorithm to the traveling salesman problem | Problem solving with optimization networks | An effective implementation of the Lin-Kernighan traveling salesman | URL http://akira.ruc.dk/ ̃keld/research/LKH | Neural” computation of decisions in optimization problems | Local search and the traveling salesman problem | Adam: A method for stochastic optimization | Optimization by simulated annealing | The self-organizing map | Comparison of neural networks for solving the Travelling Salesman Problem | An effective heuristic algorithm for the traveling-salesman problem | Asynchronous methods for deep reinforcement learning | A branch-and-cut algorithm for the resolution of largescale symmetric traveling salesman problems | The Euclidean Travelling Salesman Problem is NP-complete | An expanding-core algorithm for the exact 0-1 knapsack problem european journal of operational research | A minimal algorithm for the 0-1 knapsack problem | Critical analysis of Hopfield’s neural network model for TSP and its comparison with heuristic algorithm for shortest path computation | Neural networks for combinatorial optimization: a review of more than a decade of research | Sequence to sequence learning with neural networks | A hierarchical strategy for solving traveling salesman problems using elastic nets | Order matters: Sequence to sequence for sets | Guided local search and its application to the traveling salesman problem | Simple statistical gradient following algorithms for connectionnist reinforcement learning | On the stability of the travelling salesman problem algorithm of hopfield and tank | No free lunch theorems for optimization | Learning to learn for global optimization of black box functions | Neural architecture search with reinforcement learning,iclr,010
598.pdf.json,SPEECH RECOGNITION SYSTEM,"We present an end-to-end system to speech recognition, going from the speech signal (e.g. MelFrequency Cepstral Coefficients (MFCC), power spectrum, or raw waveform) to the transcription. The acoustic model is trained using letters (graphemes) directly, which take out the need for an intermediate (human or automatic) phonetic transcription. Indeed, the classical pipeline to build state of the art systems for speech recognition consists in first training an HMM/GMM model to force align the units on which the final acoustic model operates (most often context-dependent phone states). This approach takes its roots in HMM/GMM training (Woodland & Young, 1993). The improvements brought by deep neural networks (DNNs) (Mohamed et al., 2012; Hinton et al., 2012) and convolutional neural networks (CNNs) (Sercu et al., 2015; Soltau et al., 2014) for acoustic modeling only extend this training pipeline. The current state of the art on Librispeech (the dataset that we used for our evaluations) uses this approach too (Panayotov et al., 2015; Peddinti et al., 2015b), with an additional step of speaker adaptation (Saon et al., 2013; Peddinti et al., 2015a). Recently, Senior et al. (2014) proposed GMMfree training, but the approach still requires to generate a force alignment. An approach that cut ties with the HMM/GMM pipeline (and with force alignment) was to train with a recurrent neural network (RNN) (Graves et al., 2013) for phoneme transcription. There are now competitive end-to-end approaches of acoustic models toppled with RNNs layers as in (Hannun et al., 2014; Miao et al., 2015; Saon et al., 2015; Amodei et al., 2015), trained with a sequence criterion (Graves et al., 2006). However these models are computationally expensive, and thus take a long time to train. Compared to classical approaches that need phonetic annotation (often derived from a phonetic dictionary, rules, and generative training), we propose to train the model end-to-end, using graphemes directly. Compared","Deep speech 2: End-to-end speech recognition in english and mandarin | Maximum mutual information estimation of hidden markov model parameters for speech recognition | Une approche theorique de l’apprentissage connexionniste et applications a la reconnaissance de la parole | Global training of document processing systems using graph transformer networks | Hypothesis spaces for minimum bayes risk training in large vocabulary speech recognition | Speech recognition with deep recurrent neural networks | Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks | Deep speech: Scaling up end-to-end speech recognition | Scalable modified kneser-ney language model estimation | Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups | Conditional random fields: Probabilistic models for segmenting and labeling sequence data | Convolutional networks for images, speech, and time series | Eesen: End-to-end speech recognition using deep rnn models and wfst-based decoding | Acoustic modeling using deep belief networks. Audio, Speech, and Language Processing | Estimating phoneme class conditional probabilities from raw speech signal using convolutional neural networks | Joint phoneme segmentation inference and classification using crfs | Analysis of cnn-based speech recognition system using raw speech as input | Librispeech: an asr corpus based on public domain audio books | Jhu aspire system: Robust lvcsr with tdnns, i-vector adaptation, and rnn-lms | A time delay neural network architecture for efficient modeling of long temporal contexts | Learning the speech front-end with raw waveform cldnns | Speaker adaptation of neural network acoustic models using i-vectors | The ibm 2015 english conversational telephone speech recognition system | Gmm-free dnn training | Very deep multilingual convolutional neural networks for lvcsr | Joint training of convolutional and non-convolutional neural networks | Improvements in beam search | The htk tied-state continuous speech recogniser",iclr,010
599.pdf.json,,"Multivariate time series data are ubiquitous in many practical applications ranging from health care, geoscience, astronomy, to biology and others. They often inevitably carry missing observations due to various reasons, such as medical events, saving costs, anomalies, inconvenience and so on. It has been noted that these missing values are usually informative missingness (Rubin, 1976), i.e., the missing values and patterns provide rich information about target labels in supervised learning tasks (e.g, time series classification). To illustrate this idea, we show some examples from MIMIC-III, a real world health care dataset in Figure 1. We plot the Pearson correlation coefficient between variable missing rates, which indicates how often the variable is missing in the time series, and the labels of our interests such as mortality and ICD-9 diagnoses. We observe that the missing rate is correlated with the labels, and the missing rates with low rate values are usually highly (either positive or negative) correlated with the labels. These findings demonstrate the usefulness of missingness patterns in solving a prediction task. In the past decades, various approaches have been developed to address missing values in time series (Schafer & Graham, 2002). A simple solution is to omit the missing data and to perform analysis only on the observed data. A variety of methods have been developed to fill in the missing values, such as smoothing or interpolation (Kreindler & Lumsden, 2012), spectral analysis (Mondal & Percival, 2010), kernel methods (Rehfeld et al., 2011), multiple imputation (White et al., 2011), and EM algorithm (Garcı́a-Laencina et al., 2010). Schafer & Graham (2002) and references therein provide excellent reviews on related solutions. However, these solutions often result in a twostep process where imputations are disparate from prediction models and missing patterns are not effectively explored, thus leading to suboptimal analyses and predictions (Wells et","Neural machine translation by jointly learning to align and translate | Recurrent neural networks for missing or asynchronous data | Deep computational phenotyping | Learning phrase representations using rnn encoder-decoder for statistical machine translation | Doctor ai: Predicting clinical events via recurrent neural networks | Empirical evaluation of gated recurrent neural networks on sequence modeling | A theoretically grounded application of dropout in recurrent neural networks | Pattern classification with missing data: a review | Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups | Long short-term memory | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Mimic-iii, a freely accessible critical care database | Adam: A method for stochastic optimization | Auto-encoding variational bayes | The effects of the irregular sample and missing data in time series analysis. Nonlinear Dynamical Systems Analysis for the Behavioral Sciences | Directly modeling missing data in sequences with rnns: Improved classification of clinical time series | Gesture unit segmentation using support vector machines: segmenting gestures from rest positions | Recurrent neural network based language model | Wavelet variance analysis for gappy time series | Speech recognition with missing data using recurrent neural nets | Scikit-learn: Machine learning in Python | Deepcare: A deep dynamic memory model for predictive medicine | Comparison of correlation analysis techniques for irregularly sampled time series | Stochastic backpropagation and approximate inference in deep generative models | Missing data: our view of the state of the art | Predicting in-hospital mortality of icu patients: The physionet/computing in cardiology | Dropout: a simple way to prevent neural networks from overfitting | Sequence to sequence learning with neural networks. In Advances in neural information processing | A solution for missing data in recurrent neural networks with an application to blood glucose prediction | A systems engineering perspective on homeostasis and disease | Strategies for handling missing data in electronic health record derived data. EGEMS | Multiple imputation using chained equations: issues and guidance for practice | Temporal reasoning with medical dataa review with emphasis on medical natural language processing",iclr,010
600.pdf.json,,"Question classification has applications in question answering (QA), dialog systems, etc., and has been increasingly popular in recent years. Most existing approaches to this problem simply use existing sentence modeling frameworks and treat questions as general sentences, without any special treatment. For example, several recent efforts employ Convolutional Neural Networks (CNNs) to achieve remarkably strong performance in the TREC question classification task as well as other sentence classification tasks such as sentiment analysis (Kim, 2014; Kalchbrenner et al., 2014; Ma et al., 2015). We argue, however, that the general sentence modeling frameworks neglect several unique properties in question classification not found in other sentence classification tasks (such as sentimental classification or sarcasm detection), which we detail below: • The categories for most sentence classification tasks are flat and coarse (notable exceptions such as the Reuters Corpus RCV1 (Lewis et al., 2004) notwithstanding), and in many cases, even binary (i.e. sarcasm detection). However, question sentences commonly belong to multiple categories, and these categories often have a hierarchical (tree or DAG) structure such as those from the New York State DMV FAQ section 1 in Fig. 1. • Question sentences from different categories often share similar information or language patterns. This phenomenon becomes more obvious when categories are hierarchical. Fig. 2 shows one example of questions sharing similar information from different categories. This cross-category shared patterns are not only shown in questions but can also be found in answers corresponding to these questions. • Another unique characteristic for question classification is the well prepared answer set with detailed descriptions or instructions for each corresponding question category. These answer sets generally cover a broader range of vocabulary (than the questions themselves) and carry more distinctive semantic meanin","K-svd: Design of dictionaries for sparse representation | Greedy layer-wise training of deep networks | An Introduction To Compressive Sampling | Natural language processing (almost) from scratch | A deniable and efficient question and answer service over ad hoc social networks. volume 15, pp. 296–331 | Improving neural networks by preventing co-adaptation of feature detectors | A convolutional neural network for modelling sentences. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) | Convolutional neural networks for sentence classification | Dictionary learning algorithms for sparse representation | Comparison of learning algorithms for handwritten digit recognition | Efficient sparse coding algorithms | Rcv1: A new benchmark collection for text categorization research | Learning question classifiers | Dependency-based convolutional neural networks for sentence embedding | K-sparse autoencoders | Sparse autoencoder | Classification with the sparse group lasso | Fields of experts: A framework for learning image priors | Dictionaries for sparse representation modeling | Evaluating and predicting answer quality in community qa | A sparse-group lasso | Extracting and composing robust features with denoising autoencoders | Locality-constrained linear coding for image classification | Linear spatial pyramid matching using sparse coding for image classification | Model selection and estimation in regression with grouped variables | Adadelta: An adaptive learning rate method | Hierarchical feature selection incorporating known and novel biological information: Identifying genomic features related to prostate cancer recurrence",iclr,010
601.pdf.json,NEWSQA: A MACHINE COMPREHENSION DATASET,"Almost all human knowledge is recorded in the language of text. As such, comprehension of written language by machines, at a near-human level, would enable a broad class of artificial intelligence applications. In human students we evaluate reading comprehension by posing questions based on a text passage and then assessing a student’s answers. Such comprehension tests are appealing because they are objectively gradable and may measure a range of important abilities, from basic understanding to causal reasoning to inference (Richardson et al., 2013). To teach literacy to machines, the research community has taken a similar approach with machine comprehension (MC). Recent years have seen the release of a host of MC datasets. Generally, these consist of (document, question, answer) triples to be used in a supervised learning framework. Existing datasets vary in size, difficulty, and collection methodology; however, as pointed out by Rajpurkar et al. (2016), most suffer from one of two shortcomings: those that are designed explicitly to test comprehension (Richardson et al., 2013) are too small for training data-intensive deep learning models, while those that are sufficiently large for deep learning (Hermann et al., 2015; Hill et al., 2016; Bajgar et al., 2016) are generated synthetically, yielding questions that are not posed in natural language and that may not test comprehension directly (Chen et al., 2016). More recently, Rajpurkar et al. (2016) sought to overcome these deficiencies with their crowdsourced dataset, SQuAD. Here we present a challenging new largescale dataset for machine comprehension: NewsQA. NewsQA contains 119,633 natural language questions posed by crowdworkers on 12,744 news articles from CNN. Answers to these questions consist in spans of text within the corresponding article highlighted by a distinct set of crowdworkers. To build NewsQA we utilized a four-stage collection process designed to encourage exploratory, curiosity-based questions th","Neural machine translation by jointly learning to align and translate | Embracing data abundance: Booktest dataset for reading comprehension | Theano: a CPU and GPU math expression compiler | A thorough examination of the cnn / daily mail reading comprehension | Understanding the difficulty of training deep feedforward neural networks | Teaching machines to read and comprehend | The goldilocks principle: Reading children’s books with explicit memory representations | Text understanding with the attention sum reader network | Adam: A method for stochastic optimization | On the difficulty of training recurrent neural networks | Glove: Global vectors for word representation | Squad: 100,000+ questions for machine comprehension of text | Mctest: A challenge dataset for the open-domain machine comprehension of text | Learning answerentailing structures for machine comprehension | Exact solutions to the nonlinear dynamics of learning in deep linear neural networks | Iterative alternating neural attention for machine reading | A parallelhierarchical model for machine comprehension on sparse data | Natural language comprehension with the epireader | Machine comprehension with syntax, frames, and semantics | Learning natural language inference with lstm | Machine comprehension using match-lstm and answer pointer",iclr,010
602.pdf.json,,"A recent trend to measure progress towards machine reading is to test a system’s ability to answer questions about a document it has to comprehend. Towards this end, several large-scale datasets of cloze-style questions over a context document have been introduced recently, which allow the training of supervised machine learning systems (Hermann et al., 2015; Hill et al., 2015; Onishi et al., 2016). Such datasets can be easily constructed automatically and the unambiguous nature of their queries provides an objective benchmark to measure a system’s performance at text comprehension. Deep learning models have recently been shown to outperform traditional shallow approaches on text comprehension tasks (Hermann et al., 2015). The success of many recent models can be attributed primarily to two factors: (1) Multi-hop architectures allow a (Weston et al., 2014; Sordoni et al., 2016; Shen et al., 2016), model to scan the document and the question iteratively for multiple passes. (2) Attention mechanisms, (Weston et al., 2014; Chen et al., 2016; Hermann et al., 2015) borrowed from the machine translation literature (Bahdanau et al., 2014), allow the model to focus on appropriate subparts of the context document. Intuitively, the multi-hop architecture allows the reader to incrementally refine token representations, and the attention mechanism re-weights different parts in the document according to their relevance to the query. The effectiveness of multi-hop reasoning and attentions have been explored orthogonally so far in the literature. In this paper, we focus on combining both in a complementary manner, by designing a novel attention mechanism which gates the evolving token representations across hops. More specifically, unlike existing models where the query attention is applied either token-wise (Hermann et al., 2015; Kadlec et al., 2016; Chen et al., 2016; Hill et al., 2015) or sentence-wise (Weston et al., 2014; Sukhbaatar et al., 2015) to allow weighted aggregation",Neural machine translation by jointly learning to align and translate | Embracing data abundance: Booktest dataset for reading comprehension | A thorough examination of the cnn/daily mail reading comprehension | Learning phrase representations using rnn encoder-decoder for statistical machine translation | Broad context language modeling as reading comprehension | Attention-overattention neural networks for reading comprehension | Tweet2vec: Character-based distributed representations for social media | Teaching machines to read and comprehend | The goldilocks principle: Reading children’s books with explicit memory representations | Long short-term memory | Text understanding with the attention sum reader network | Adam: A method for stochastic optimization | A multiplicative model for learning distributed text-based attribute representations | Dynamic entity representations with max-pooling improves machine reading | Ask me anything: Dynamic memory networks for natural language processing | Dataset and neural recurrent sequence labeling model for open-domain factoid question answering | Vector-based models of semantic composition | Recurrent models of visual attention | Neural semantic encoders | Reasoning with memory augmented neural networks for language comprehension | Who did what: A large-scale person-centered cloze dataset | The lambada dataset: Word prediction requiring a broad discourse context | On the difficulty of training recurrent neural networks | Glove: Global vectors for word representation | Reasonet: Learning to stop reading in machine comprehension | Iterative alternating neural attention for machine reading | End-to-end memory networks | Natural language comprehension with the epireader | On multiplicative integration with recurrent neural networks | Learning multi-relational semantics using neural-embedding models | Multi-task cross-lingual sequence tagging from scratch,iclr,010
603.pdf.json,NEURAL CODE COMPLETION,"As the scale and complexity of modern software libraries and tools continue to grow, code completion has become an essential feature in modern integrated development environments (IDEs). By suggesting the right libraries, APIs, and even variables in real-time, intelligent code completion engines can substantially accelerate software development. Furthermore, as many projects move to dynamically typed and interpreted languages, effective code completion can help to reduce costly errors by eliminating typos and identifying the right arguments from context. However, existing approaches to intelligent code completion either rely on strong typing (e.g., Visual Studio for C++), which limits their applicability to widely used dynamically typed languages (e.g., JavaScript and Python), or are based on simple heuristics and term frequency statistics which are often brittle and are relatively error-prone. In particular, Raychev et al. (2016a) proposes the state-ofthe-art probabilistic model for code, which generalizes both simple n-gram models and probabilistic grammar approaches. This approach, however, examines only a limited number of elements in the source code when completing the code. Therefore, the effectiveness of this approach may not scale well to large programs. In this paper we explore the use of deep learning techniques to address the challenges of code completion for the widely used and dynamically typed JavaScript programming language. We formulate the code completion problem as a sequential prediction task over the traversal of a parse-tree structure consisting of both non-terminal structural nodes and terminal nodes encoding program text. We then present simple, yet expressive, LSTM-based (Hochreiter & Schmidhuber (1997)) models that leverage additional side information obtained by parsing the program structure. Compared to widely used heuristic techniques, deep learning for code completion offers the opportunity to learn rich contextual models that can captur",Tensorflow: Large-scale machine learning on heterogeneous distributed systems | Mining idioms from source code | Suggesting accurate method and class names | Improved semantic parsers for if-then statements | PHOG: Probabilistic Model for Code | Latent attention for if-then program synthesis | Head-driven statistical models for natural language parsing | Language to logical form with neural attention | On the naturalness of software | Long short-term memory | Adam: A method for stochastic optimization | Learning programs: A hierarchical bayesian approach | Latent predictor networks for code generation | Structured generative models of natural source code | A statistical semantic language model for source code | Code completion with statistical language models | Probabilistic model for code with decision trees | Learning programs from noisy data | On the localness of software | Toward deep learning software repositories,iclr,010
604.pdf.json,HERE’S MY POINT: ARGUMENTATION MINING WITH POINTER NETWORKS,"Computational approaches to argument mining/understanding have become very popular (Persing & Ng, 2016; Cano-Basave & He, 2016; Wei et al., 2016; Ghosh et al., 2016; Palau & Moens, 2009; Habernal & Gurevych, 2016). One important avenue in this work is to understand the structure in argumentative text (Persing & Ng, 2016; Peldszus & Stede, 2015; Stab & Gurevych, 2016; Nguyen & Litman, 2016). One fundamental assumption when working with argumentative text is the presence of Arguments Components (ACs). The types of ACs are generally characterized as a claim or a premise (Govier, 2013), with premises acting as support (or possibly attack) units for claims. To model more complex structures of arguments, some annotation schemes also include a major claim AC type (Stab & Gurevych, 2016; 2014b). Generally, the task of processing argument structure encapsulates four distinct subtasks: 1) Given a sequence of tokens that represents an entire argumentative text, determine the token subsequences that constitute non-intersecting ACs; 2) Given an AC, determine the type of AC (claim, premise, etc.); 3) Given a set/list of ACs, determine which ACs have a link that determine overall argument structure; 4) Given two linked ACs, determine whether the link is of a supporting or attacking relation. In this work, we focus on subtasks 2 and 3. There are two key assumptions our work makes going forward. First, we assume subtask 1 has been completed, i.e. ACs have already been identified. Second, we follow previous work that assumes a tree structure for the linking of ACs (Palau & Moens, 2009; Cohen, 1987; Peldszus & Stede, 2015; Stab & Gurevych, 2016) Specifically, a given AC can only have a single outgoing link, but can have numerous incoming links. Furthermore, there is a ‘head’ component that has First, [ :::::: cloning :::: will ::: be ::::::::: beneficial :::: for :::: many :::::: people ::::: who ::: are :: in :::: need ::: of ::::: organ ::::::::: transplants]AC1. In addition, [it sh","TensorFlow: Large-scale machine learning on heterogeneous systems | Neural machine translation by jointly learning to align and translate | Recursive neural networks can learn logical semantics | Tree-structured composition in neural networks without tree-structured architectures | A study of the impact of persuasive argumentation in political debates | Deep computational phenotyping | Analyzing the structure of argumentative discourse | Coarse-grained argumentation features for scoring persuasive essays | Offline handwriting recognition with multidimensional recurrent neural networks. In Advances in neural information processing | Which argument is more convincing? analyzing and predicting convincingness of web arguments using bidirectional lstm | Long short-term memory | Adam: A method for stochastic optimization | Ask me anything: Dynamic memory networks for natural language processing | Identifying and classifying subjective claims | Context-aware argumentative relation mining | Argumentation mining: the detection, classification and structure of arguments in text | Towards segment-based recognition of argumentation structure in short texts | Joint prediction in mst-style discourse parsing for argumentation mining | Glove: Global vectors for word representation | End-to-end argumentation mining in student essays | An application of recurrent nets to phone probability estimation | Applying kernel methods to argumentation mining | Dropout: a simple way to prevent neural networks from overfitting | Annotating argument components and relations in persuasive essays | Identifying argumentative discourse structures in persuasive essays | Parsing argumentation structures in persuasive essays | Sequence to sequence learning with neural networks. In Advances in neural information processing | Order matters: Sequence to sequence for sets | Grammar as a foreign language | Is this post persuasive? ranking argumentative comments in the online forum | Towards ai-complete question answering: A set of prerequisite toy tasks | Mitre at semeval-2016 task 6: Transfer learning for stance detection",iclr,010
605.pdf.json,TREE-STRUCTURED VARIATIONAL AUTOENCODER,"A significant amount of recent and ongoing work has explored the use of neural networks for modeling and generating various kinds of data. Newer techniques like the variational autoencoder (Rezende et al., 2014; Kingma & Welling, 2013) and generative-adversarial networks (Goodfellow et al., 2014) enable training of graphical models where the likelihood function is a complicated neural network which normally makes it infeasible to specify and optimize the marginal distribution analytically. Another family of techniques involves choosing an ordering of the dimensions of the data (which is particularly natural for sequences such as sentences) and training a neural network to estimate the distribution over the value of the next dimension given all the dimensions we have observed so far. These techniques have led to significant advances in modeling images, text, sounds, and other kinds of complicated data. Language modeling with sequential neural models have halved perplexity (roughly, the error at predicting each word) compared to n-gram methods (Jozefowicz et al., 2016). Neural machine translation using sequence-to-sequence methods have closed half of the gap in quality between prior machine translation efforts and human translation (Wu et al., 2016). Generative image models have similarly progressed such that they can generate samples largely indistinguishable from the original data, at least for relatively small and simple images (Gregor et al., 2015; 2016; Kingma et al., 2016; Salimans et al., 2016; van den Oord et al., 2016), although the quality of the model here is harder to measure in an automated way (Theis et al., 2015). However, many kinds of data we might wish to model are naturally structured as a tree. Computer program code follows a rigorous grammar, and the usual first step in processing it involves parsing it into an abstract syntax tree, which simultaneously discards aspects of the code irrelevant to the semantics such as whitespace and extraneous pare","Deepmathdeep sequence models for premise selection | Generating sentences from a continuous space | Importance weighted autoencoders | Empirical evaluation of gated recurrent neural networks on sequence modeling | A recurrent latent variable model for sequential data | Language to logical form with neural attention | Recurrent neural network grammars | Sequential neural models with stochastic layers | Generative adversarial nets | Draw: A recurrent neural network for image generation | Towards conceptual compression | Memory-efficient backpropagation through time | Deep recursive neural networks for compositionality in language | A neural network for factoid question answering over paragraphs | Exploring the limits of language modeling | Auto-encoding variational bayes | Improving variational inference with inverse autoregressive flow | Stochastic backpropagation and approximate inference in deep generative models | Variational inference with normalizing flows | Improved techniques for training gans | Semantic compositionality through recursive matrix-vector spaces | Recursive deep models for semantic compositionality over a sentiment treebank | Ladder variational autoencoders | Improved semantic representations from tree-structured long short-term memory networks | A note on the evaluation of generative models | Conditional image generation with pixelcnn decoders | Grammar as a foreign language | Google’s neural machine translation system: Bridging the gap between human and machine translation | Top-down tree long short-term memory networks | 2016). Specifically, it is easy for the KL divergence term DKL(qφ(z | x) ‖ p(z)) to collapse to zero, which means that qφ(z | x) is equal to the prior and does not convey any information about x. This leads to uninteresting latent representations and reduces the generative model to one that does not use a latent representation at all | 2016), this phenomenon occurs as at the beginning of training it is much easier for the optimization process to move qφ(z | x) closer to the prior p(z) than to improve p(x | z), especially when qφ(z | x) has not yet learned how to convey any useful information. To combat this, we use a combination of two techniques described in the previous work: • Anneal the weight on the KL cost term slowly from 0 to 1",iclr,010
606.pdf.json,LEARNING APPROXIMATE DISTRIBUTION-SENSITIVE DATA STRUCTURES,"Recent progress in artificial intelligence is driven by the ability to learn representations from data. Yet not all kinds of representations are equal, and many of the fundamental properties of representations (both as theoretical constructs and as observed experimentally in humans) are missing. Perhaps the most critical property of a system of representations is compositionality, which as described succinctly in (Fodor & Lepore, 2002), is when (i) it contains both primitive symbols and symbols that are complex; and (ii) the latter inherit their syntactic/semantic properties from the former. Compositionality is powerful because it enables a system of representation to support an infinite number of semantically distinct representations by means of combination. This argument has been supported experimentally; a growing body of evidence (Spelke & Kinzler, 2007) has shown that humans possess a small number of primitive systems of mental representation - of objects, agents, number and geometry - and new representations are built upon these core foundations. Representations learned with modern machine learning methods possess few or none of these properties, which is a severe impediment. For illustration consider that navigation depends upon some representation of geometry, and yet recent advances such as end-to-end autonomous driving (Bojarski et al., 2016) side-step building explicit geometric representations of the world by learning to map directly from image inputs to motor commands. Any representation of geometry is implicit, and has the advantage that it is economical in only possessing information necessary for the task. However, this form of representation lacks (i) the ability to reuse these representations for other related tasks such as predicting object stability or performing mental rotation, (ii) the ability to compose these representations with others, for instance to represent a set or count of geometric objects, and (iii) the ability to perform explicit i","Learning Deep Architectures for AI, volume | End to End Learning for Self-Driving Cars | Space-Efficient Data Structures, Streams, and Algorithms | Abstract Data Types: Specifications, Implementations, and Applications | The Number sense, volume | The Compositionality Papers | Learning to Transduce with Unbounded Memory | Algebraic Specification of Abstract Data Types | Abstract data types and software validation | Two Systems of Non-Symbolic Numerical Cognition | Geometry as a Universal Mental Construction, volume 1 | Distributed Representations ofWords and Phrases and their Compositionality | On the magnitude representations of two-digit numbers | Program Synthesis from Polymorphic Refinement Types. PLDI: Programming Languages Design and Implementation, 2016 | First-order probabilistic inference | Expressing and Verifying Probabilistic Assertions | Static Analysis for Probabilistic Programs : Inferring Whole Program Properties from Finitely Many Paths | The sketching approach to program synthesis. Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) | The verification and synthesis of data structures | End-To-End Memory Networks | The Neural Network Pushdown Automaton: Model, Stack and Learning Simulations",iclr,010
607.pdf.json,MEMORY-AUGMENTED ATTENTION MODELLING FOR VIDEOS,"Deep neural architectures have led to remarkable progress in computer vision and natural language understanding problems. Image captioning is one such application that has seen the combination of convolutional structures (Krizhevsky et al., 2012; LeCun et al., 1998), which have been shown to be very effective for problems like object detection, with sequential recurrent structures, which have been shown to be very effective for problems like machine translation (Sutskever et al., 2014). One of the key modelling paradigms shared by most models for image captioning is the notion of an attention mechanism that guide the model to attend to certain parts of the image while generating. The attention models used for problems such as image captioning typically depend on the single image under consideration and the partial output generated so far, jointly capturing one region of an image and the words being generated. However, such models cannot capture the temporal reasoning necessary to effectively produce words that refer to actions and events taking place over multiple frames in a video. For example, in a video depicting “someone waving a hand”, the “waving” action can start from any frame and can continue on for a variable number of following frames. More importantly, it is likely in a given video quite few frames do not contain any useful information or motion in regard to a given task. Given this, it is not surprising that even with recent advancements in image captioning Xu et al. (2015a); Johnson et al. (2016); Vinyals et al. (2015), video captioning has remained challenging. Motivated by these observations, we introduce a memory-based attention mechanism for video captioning and description. Our model utilizes memories of past attention in the video when reasoning about where to attend to in a current time step. This allows the model to not only effectively leverage local attention, but also to consider the entire video as it generates each word. This mechanism is ","Beyond caption to narrative: Video captioning with multiple sentences | Neural machine translation by jointly learning to align and translate | Delving deeper into convolutional networks for learning video representations | Random search for hyper-parameter optimization | Large displacement optical flow: Descriptor matching in variational motion estimation | High accuracy optical flow estimation based on a theory for warping | Collecting highly parallel data for paraphrase evaluation | Towards end-to-end speech recognition with recurrent neural networks | Deep residual learning for image recognition | Long short-term memory | Densecap: Fully convolutional localization networks for dense captioning | Adam: A method for stochastic optimization | Imagenet classification with deep convolutional neural networks | Gradient-based learning applied to document recognition | Hierarchical recurrent neural encoder for video representation with application to captioning | Jointly modeling embedding and translation to bridge video and language. CVPR, 2016b | On the difficulty of training recurrent neural networks | Reasoning about entailment with neural attention | Translating video content to natural language descriptions | Action recognition using visual attention | Hollywood in homes: Crowdsourcing data collection for activity understanding | Very deep convolutional networks for large-scale image recognition | End-to-end memory networks | Sequence to sequence learning with neural networks | Learning spatiotemporal features with 3d convolutional networks | Sequence to sequence – video to text | Translating videos to natural language using deep recurrent neural networks | Show and tell: A neural image caption generator | Show, attend and tell: Neural image caption generation with visual attention | Jointly modeling deep video and compositional text to bridge vision and language in a unified framework | Encode, review, and decode: Reviewer module for caption generation | Describing videos by exploiting temporal structure | Video paragraph captioning using hierarchical recurrent neural networks",iclr,010
608.pdf.json,TAMING THE WAVES: SINE AS ACTIVATION FUNCTION IN DEEP NEURAL NETWORKS,"Most activation functions typically used nowadays in deep neural networks—such as sigmoid, tanh, ReLU, Leaky ReLU, ELU, parametric ReLU, maxout—are non-periodic. Moreover, these functions are all quasiconvex, and more specifically either monotonic (sigmoid, tanh, ReLU, Leaky ReLU, ELU) or piece-wise monotonic with two monotonic segments (parametric ReLU, maxout). Monotonicity makes sense from an intuitive point of view. At any layer of a network, neurons learn to respond to certain patterns, i.e. those that correlate with their weights; in case of monotonic functions, to a stronger positive correlation corresponds a stronger (or equal) activation, and viceversa, to a weaker positive correlation corresponds a weaker (or equal) activation. Neurons using piece-wise monotonic functions with two monotonic segments can be viewed as two separate neurons, each equipped with one of the two monotonic segments, and therefore independently looking for either the positive or the negative correlation between the weights and the input. Excluding the trivial case of constant functions, periodic functions are non-quasiconvex, and therefore non-monotonic. This means that for a periodic activation function, as the correlation with the input increases the activation will oscillate between stronger and weaker activations. This apparently undesirable behavior might suggest that periodic functions might be just as undesirable as activation functions in a typical learning task. But is this really the case? As shown in Section 2, there are several examples from the literature where sinusoidal functions were successfully used in neural networks. Moreover, as noted already in Gaynier & Downs (1995), networks using simple monotonic activation functions—such as sigmoids, tanh, ReLU—tend to have smaller VC dimension than those using non-monotonic functions. More specifically, even a network with a single hidden neuron using sinusoidal activation has infinite VC dimension1. Neural networks using ",Symbolic and connectionist learning techniques for grammatical inference | Implementing a weighted least squares procedure in training a neural network to solve the short-term load forecasting problem | Approximation by superpositions of a sigmoidal function | Learning the activation function for the neurons in neural networks | Modeling time series data with deep fourier neural networks | Sinusoidal and monotonic transfer functions: Implications for vc dimension | Understanding the difficulty of training deep feedforward neural networks | Fast and robust way of learning the fourier series neural networks on the basis of multidimensional discrete fourier transform | A simple lemma on greedy approximation in hilbert space and convergence rates for projection pursuit regression and neural network training | Adam: A method for stochastic optimization | Using fourier-neural recurrent networks to fit sequential input/output data | Nonlinear signal processing using neural networks: Prediction and system modelling | Multistability of recurrent neural networks with nonmonotonic activation functions and mixed time delays | On the properties of periodic perceptrons | An artificial neuron model with a periodic activation function | On function recovery by neural networks based on orthogonal expansions | Learnability of periodic activation functions: General results | Exact solutions to the nonlinear dynamics of learning in deep linear neural networks | Improvement of learning in recurrent networks by substituting the sigmoid activation function | Neural networks with periodic and monotonic activation functions: a comparative study in classification problems | Handwritten digit recognition using multilayer feedforward neural networks with periodic and monotonic activation functions,iclr,010
609.pdf.json,,"Convolutional Neural Networks (CNNs) (LeCun et al., 1998) are variants of multi-layer perceptrons that have been inspired by biological cells in the visual cortex. The cells act as local filters over the input space and are well-suited to exploit the strong local spatial correlation present in natural images (Hubel & Wiesel, 1968). In recent years, following a breakthrough by Krizhevsky et al. (2012) at the 2012 ImageNet challenge, CNN has repeatedly demonstrated significant improvements in a large number of computer vision problems. The major success of CNN for visual data is justly credited to the convolution. But its strength is dependent on three crucial underlying attributes found in visual data. 1. Local connectivity assumption: The signal in visual data tends to be highly correlated in local regions, and mostly uncorrelated in global regions. 2. Shared weights assumption: The same convolution is globally valid across the image, resulting in a significant parameter reduction. 3. Grid structure of the image: Enabling a straight forward re-scaling of the feature layers through the process of max pooling. These assumptions make it challenging to duplicate the success of CNN on a different data structure. Nevertheless, CNNs have also proved effective for non-image data, usually relying on the grid structure of the inputs. Results on acoustic data (Hinton et al., 2012), videos (Le et al., 2011) and even Go board (Silver et al., 2016) indicate that it might be sensible to generalize CNN on other data structures that lack the under-lying grid structure. The main contribution of this work is a generalization of CNNs to general graph-structured data, directed or undirected, offering a single method that incorporates the structural information present in the graph of the features into supervised learning algorithms. Due to the active research on learning the graph structure of features, this proves to be quite a general framework. As demonstrated by the examples, large ",Spectral networks and locally connected networks on graphs | High performance convolutional neural networks for document processing | Selecting receptive fields in deep networks | Convolutional networks on graphs for learning molecular fingerprints | Circular fingerprints: flexible molecular descriptors with applications from physical chemistry to adme. IDrugs | Deep convolutional networks on graph-structured data | Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups | Receptive fields and functional architecture of monkey striate cortex | A convolutional neural network for modelling sentences | Adam: A method for stochastic optimization | Imagenet classification with deep convolutional neural networks | Learning hierarchical invariant spatio-temporal features for action recognition with independent subspace analysis | Gradient-based learning applied to document recognition | Random walks on graphs: A survey | Deep architectures and deep learning in chemoinformatics: the prediction of aqueous solubility for drug-like molecules | Deep neural nets as a method for quantitative structure–activity relationships | Learning the 2-d topology of images | Mastering the game of go with deep neural networks and tree,iclr,010
610.pdf.json,,"Despite the success of deep neural networks (DNNs) in diverse areas, ranging from image recognition and machine translation to autonomous driving, its vulnerabilities have been exploited in the adversarial environments. Evasion attacks against such deep learning systems have recently received considerable attention. It has been shown that with small magnitude of noise added, the original instance can easily be misclassified by the otherwise accurate deep neural networks (Goodfellow et al., 2014; Papernot et al., 2016c; Nguyen et al., 2015; Szegedy et al., 2013). Such instances are also called adversarial examples. Given the strong evasion properties of these adversarial examples, some works have been proposed to test and investigate the robustness of the deep neural networks against the adversarial examples (Goodfellow et al., 2014; Kurakin et al., 2016; Huang et al., 2015; Gu & Rigazio, 2014; Jin et al., 2015). However, most of the existing works only evaluate the robustness of the proposed defense strategies over adversarial examples generated using a single attack method, or several similar methods. Meanwhile, since the evaluated adversary models, i.e., adversarial example generation methods, vary among different works that study the effectiveness of defense strategies, it remains a question how to make a comparison among different defense strategies. In this paper, we focus on providing thorough analysis for different algorithmic strategic defensive learners against various adversary models considering their robustness against adversarial examples, efficiency for cross-model learning process, resilience against additional attacks, and the vulnerabilities of these learners. Here by “cross-model test”, we mean to apply one adversarial model to generate adversarial examples, while test them on the learner trained with instances generated from different adversarial models. High “cross-model test” accuracy indicates higher robustness for learner. In addition, we prop",Security evaluation of pattern classifiers under attack. Knowledge and Data Engineering | Explaining and harnessing adversarial examples | Towards deep neural network architectures robust to adversarial examples | Learning with adversary | Neural network forecast model in deep excavation | Robust convolutional neural networks under adversarial noise | Behavioral experiments in email filter evasion | Adam: A method for stochastic optimization | Adversarial machine learning at scale | Gradient-based learning applied to document recognition | Feature cross-substitution in adversarial classification | A general retraining framework for scalable adversarial classification | Adversarial learning | Distributional smoothing with virtual adversarial training | Deep neural networks are easily fooled: High confidence predictions for unrecognizable images | Distillation as a defense to adversarial perturbations against deep neural networks | Transferability in machine learning: from phenomena to black-box attacks using adversarial samples | Practical black-box attacks against deep learning systems using adversarial examples | The limitations of deep learning in adversarial settings | Adversarial manipulation of deep representations | Intriguing properties of neural networks | Exploring the space of adversarial images | Extracting and composing robust features with denoising autoencoders | Optimal randomized classification in adversarial settings | Improving the robustness of deep neural networks via stability training,iclr,010
611.pdf.json,,"What do consumers really want? – this is a question to which everyone wishes to have an answer. Over the past decade, the unprecedented growth of web services and online commercial platforms such as Amazon, Netflix, and Spotify, gives rise to a vast amount of business data, which contain valuable information about the customers. However, “data don’t speak for themselves”. To accurately predict what the customers want, one needs not only the data, but also an effective means to extract useful messages therefrom. There has been extensive study on recommender systems. Existing methods roughly fall into two categories, namely content-based filtering (Pazzani & Billsus, 2007) and collaborative filtering (Mnih & Salakhutdinov, 2008; Hu et al., 2008; Yu et al., 2009). The former focuses on extracting relevant features from the content, while the latter attempts to exploit the common interest among groups of users. In recent efforts, hybrid methods (Agarwal & Chen, 2009; Van den Oord et al., 2013) that combine both aspects have also been developed. Whereas remarkable progress has been made on this topic, the state of the art remains far from satisfactory. The key challenges lie in several aspects. First, there is a large semantic gap between the true cause of a matching and what we observe from the data. For example, what usually attracts a book consumer is the implied emotion that one has to feel between the lines instead of the occurrences of certain words. It is difficult for classical techniques to extract such deep meanings from the observations. Second, the cold-start issue, namely making predictions for unseen items or users, has not been well addressed. Many collaborative filtering methods rely on the factorization of the matching matrix. Such methods implicitly assume that all the users and items are known in advance, and thus are difficult to be applied in real-world applications, especially online services. The success of deep learning brings new inspiration to t","The movielens datasets: History and context | Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups | Collaborative filtering for implicit feedback datasets | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | Learning content similarity for music recommendation | Probabilistic matrix factorization | Content-based recommendation systems | Bpr: Bayesian personalized ranking from implicit feedback | Introduction to recommender systems handbook | Learning a metric for music similarity | Parsing natural scenes and natural language with recursive neural networks | Inception-v4, inception-resnet and the impact of residual connections on learning | mTrust: Discerning multi-faceted trust in a connected world | Deep content-based music recommendation | Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion | Collaborative topic modeling for recommending scientific articles | Collaborative deep learning for recommender systems | Improving content-based and hybrid music recommendation using deep learning | Large-scale collaborative prediction using a nonparametric random effects model",iclr,010
612.pdf.json,,"There has been an increased interest in unsupervised learning of representations from video sequences (Mathieu et al., 2016; Srivastava et al., 2015; Vondrick et al., 2016). A popular formulation of the task is to learn to predict a small number of future frames given the previous K frames; the motivation being that predicting future frames requires understanding how objects interact and what plausible sequences of motion are. These methods directly aim to predict pixel values, with either MSE loss or adversarial loss. In this paper, we take a different approach to the problem of next frame prediction. In particular, our model operates in the space of transformations between frames, directly modeling the source of variability. We exploit the assumption that the transformations of objects from frame to frame should be smooth, even when the pixel values are not. Instead of predicting pixel values, we directly predict how objects transform. The key insight is that while there are many possible outputs, predicting one such transformation will yield motion that may not correspond to ground truth, yet will be realistic; see fig. 1. We therefore propose a transformation-based model that operates in the space of affine transforms. Given the affine transforms of a few previous frames, the model learns to predict the local affine transforms that can be deterministically applied on the image patches of the previous frame to generate the next frame. The intuition is that estimation errors will lead to a slightly different yet plausible motion. Note that this allows us to keep using the MSE criterion, which is easy to optimize, as long as it is in transformation space. No blur in the pixel space will be introduced since the output of the transformation model is directly applied to the pixels, keeping sharp edges intact. Refer to fig. 5 and our online material 1 for examples. The other contribution of this work is the evaluation protocol. Typically, generative models of video seq",High accuracy optical flow estimation based on a theory for warping | Generative adversarial nets | Large-scale video classification with convolutional neural networks | Deep multi-scale video prediction beyond mean square error | Modeling deep temporal dependencies with recurrent grammar cells | Action-conditional video prediction using deep networks in atari | Video (language) modeling: a baseline for generative models of natural videos | Ucf101: A dataset of 101 human actions classes from videos in the wild | Unsupervised learning of video representations using lstms | Learning spatiotemporal features with 3d convolutional networks | Generating videos with scene dynamics | Attribute2image: Conditional image generation from visual attributes,iclr,010
613.pdf.json,,"In domains such as healthcare, genomics or social science there is high demand for data analysis that reveals causal relationships between independent and target variables. For example, doctors not only want models that accurately predict the status of patients, but also want to identify the factors that can change the status. The distinction between prediction and causation has at times been subject to controversy in statistics and machine learning (Breiman et al., 2001; Shmueli, 2010; Donoho, 2015). On one hand, machine learning has been focusing almost exclusively on pure prediction tasks, enjoying great commercial success. On the other hand, in many scientific domains pure prediction without consideration of the underlying causal mechanisms is considered unscientific (Shmueli, 2010). In this work, we propose a neural causal regularizer that balances causal interpretability and high predictive power. Causal Inference: Our notion of causality follows the counterfactual framework of Pearl (2000). Thus, we will say that one random variable X causes another variable Y (which relationship we denote as X → Y ) if intervening or experimenting on X changes the distribution of Y . Consider the problem of identifying the causal relationship between drinking red wine and heart disease (Spirtes, 2010). Regular consumption of red wine correlates with healthy heart. That might mean that drinking red wine decreases heart attack rates. But it might be, for example, that people of high socio-economic status tend to drink more wine, while at the same time tend to suffer fewer heart problems due to better living conditions. To distinguish between these two possibilities, one could implement a controlled trial in which the subjects are told to drink (or not drink) red wine, independently of any other factors —including their socio-economic status. Such controlled trials are often undesirable or even impossible. In healthcare, it can be due to moral and regulatory reasons; in climate","Statistical modeling: The two cultures | Estimating the causal direction and confounding of two discrete variables | Optimal structure identification with greedy search | Learning high-dimensional directed acyclic graphs with latent and selection variables | Inferring deterministic causal relations | 50 years of data science | Is uniformitarianism necessary | Causal inference using the algorithmic markov condition | On causal and anticausal learning | Mimic-iii, a freely accessible critical care database | Estimating high-dimensional directed acyclic graphs with the pc-algorithm | Causal models as minimal descriptions of multivariate systems | From dependence to causation | Discovering causal signals in images | Distributed representations of words and phrases and their compositionality | A unified framework for high-dimensional analysis of m-estimators with decomposable regularizers | Glove: Global vectors for word representation | To explain or to predict | Introduction to causal inference | The hidden variables are selected to be categorical variables with cardinality selected uniformly from the integers in the interval | First, in the synthetic dataset, the test error is significantly lower. This is because the size of input to the neural causality detector is 32 compared to 4 for the binary case. Applying the causality detectors to our data, we observe that the causality scores generated by our sampling scheme has significantly higher correlation with the mutual information between independent variables and the target label",iclr,010
614.pdf.json,RECURRENT COEVOLUTIONARY FEATURE EMBEDDING PROCESSES FOR RECOMMENDATION,"E-commerce platforms and social service websites, such as Reddit, Amazon, and Netflix, attracts thousands of users every second. Effectively recommending the appropriate service items to users is a fundamentally important task for these online services. It can significantly boost the user activities on these sites and leads to increased product purchases and advertisement clicks. The interactions between users and items play a critical role in driving the evolution of user interests and item features. For example, for music streaming services, a long-time fan of Rock music listens to an interesting Blues one day, and starts to listen to more Blues instead of Rock music. Similarly, a single music may also serve different audiences at different times,e.g., a music initially targeted for an older generation may become popular among the young, and the features of this music need to be updated. Furthermore, as users interact with different items, users’ interests and items’ features can also co-evolve over time, i.e., their features are intertwined and can influence each other: • User → item. In online discussion forums such as Reddit, although a group (item) is initially created for statistics topics, users with very different interest profiles can join this group. Hence, the participants can shape the features of the group through their postings. It is likely that this group can finally become one about deep learning because most users concern about deep learning. • Item→ user. As the group is evolving towards topics on deep learning, some users may become more interested in deep learning topics, and they may participate in other specialized groups on deep learning. On the opposite side, some users may gradually gain interests in pure math groups, lose interests in statistics and become inactive in this group. Such co-evolutionary nature of user-item interactions raises very important questions on how to learn them from the increasingly available data. However, existin","Survival and event history analysis: a process point of view | Regression-based latent factor models | Dynamic poisson factorization | General functional matrix factorization using gradient boosting | Large-scale behavioral targeting | On tensors, sparsity, and nonnegative factorizations | Multivariate point processes. Selected Statistical Papers of Sir David Cox: Volume 1, Design of Investigations | Discriminative embeddings of latent variable models for structured data | An introduction to the theory of point processes: volume II: general theory and structure, volume | Time sensitive recommendation from recurrent user activities | Recurrent marked temporal point processes: Embedding event history to vector | Collaborative filtering recommender systems | Scalable recommendation with hierarchical poisson factorization | A collaborative kalman filter for time-evolving dyadic processes | Noise-contrastive estimation of unnormalized statistical models, with applications to natural image statistics | Spectra of some self-exciting and mutually exciting point processes | General factorization framework for context-aware recommendations | Session-based recommendations with recurrent neural networks | Just in time recommendations: Modeling the dynamics of boredom in activity streams | Multiverse recommendation: n-dimensional tensor factorization for context-aware collaborative filtering | Adam: A method for stochastic optimization | Collaborative recurrent neural networks for dynamic recommender systems | Collaborative filtering with temporal dynamics | Ordrec: an ordinal model for predicting personalized item rating distributions | Learning word embeddings efficiently with noise-contrastive estimation | Who, what, when, and where: Multidimensional collaborative recommendations using tensor factorization on sparse user-generated data | Bayesian probabilistic matrix factorization using markov chain monte carlo | Multi-rate deep learning for temporal recommendation | Improved recurrent neural networks for session-based recommendations | Collaborative deep learning for recommender systems | Recommending groups to users using user-group engagement and time-dependent matrix factorization | Detecting emotions in social media: A constrained optimization approach | Rubik: Knowledge guided tensor factorization and completion for health data analytics | Coevolutionary latent feature processes for continuous-time user-item interactions | Isotonic hawkes processes | Temporal collaborative filtering with bayesian probabilistic tensor factorization | Like like alike: joint friendship and interest propagation in social networks | Beyond clicks: Dwell time for personalization",iclr,010
615.pdf.json,L-SR1: A SECOND ORDER OPTIMIZATION METHOD,,"On solving l-sr1 trust-region | Limited memory bfgs updating in a trust-region framework | Representations of quasi-newton matrices and their use in limited-memory methods | A stochastic quasi-newton method for large-scale optimization | Convergence of quasi-newton matrices generated by the symmetric rank one update | A self-correcting variable-metric algorithm for stochastic optimization | Identifying and attacking the saddle point problem in high-dimensional non-convex optimization | Large scale distributed deep networks | Numerical methods for unconstrained optimization and nonlinear equations | Updating the inverse of a matrix | Delving deep into rectifiers: Surpassing human-level performance on imagenet classification | Deep residual learning for image recognition | Batch normalization: Accelerating deep network training by reducing internal covariate | adaqn: An adaptive quasi-newton algorithm for training rnns | A theoretical and experimental study of the symmetric rank one update | Adam: A method for stochastic optimization | On optimization methods for deep learning | On the limited memory bfgs method for large scale optimization | Deep learning via hessian-free optimization | Second-Order Optimization for Neural Networks | Learning recurrent neural networks with hessian-free optimization | RES: regularized stochastic BFGS algorithm | Global convergence of online limited memory bfgs | Updating quasi-newton matrices with limited storage | Numerical Optimization. Springer-Verlag, New York, 2 edition | Fast exact multiplication by the hessian | Fast Curvature Matrix-Vector Products for Second-Order Gradient Descent | Krylov subspace descent for deep learning | Stochastic Quasi-Newton Methods for Nonconvex Stochastic Optimization",iclr,010
616.pdf.json,ADVERSARIAL IMAGINATION PRIORS,,"Tensorflow: Large-scale machine learning on heterogeneous distributed systems, 2015. URL http://download.tensorflow.org/ paper/whitepaper2015.pdf | Nonrigid structure from motion in trajectory space | Seeing 3d chairs: exemplar part-based 2d-3d alignment using a large dataset of cad models | Shape, illumination, and reflectance from shading | Human pose estimation with iterative error feedback | Image super-resolution using deep convolutional networks | Texture synthesis by non-parametric sampling | Depth map prediction from a single image using a multi-scale deep network | Structured Prediction of Unobserved Voxels From a Single Depth Image | Generative adversarial nets | Ground-truth dataset and baseline evaluations for intrinsic image algorithms | gvnn: Neural network library for geometric computer | Learning a probabilistic latent space of object shapes via 3d generative-adversarial | Intrinsic video. In Computer Vision – ECCV 2014, volume 8690 of Lecture Notes in Computer Science, pp. 360–375 | Picture: A probabilistic programming language for scene perception | Deep convolutional inverse graphics network. CoRR, abs/1503.03167, 2015b | Learning lightness from human judgement on relative reflectance | Direct intrinsics: Learning albedo-shading decomposition by convolutional regression | Context encoders: Feature learning by inpainting | Unsupervised representation learning with deep convolutional generative adversarial networks | Iterative neural autoregressive distribution estimator (nade-k) | f-gan: Training generative neural samplers using variational divergence minimization | Gestalt Theory: An Essay in Philosophy | Amortised map inference for image super-resolution | A note on the evaluation of generative models | Optimizing neural networks that generate images | Shape and motion from image streams under orthography: A factorization method | Single Image 3D Interpreter Network, pp. 365–382 | Sun database: Large-scale scene recognition from abbey to zoo | Image super-resolution via sparse representation | Layered object models for image segmentation | Computational models of perceptual organization",iclr,010
617.pdf.json,,"Deep Learning (DL) algorithms are a class of Machine Learning and Data Mining (MLDM) algorithms, which use an inter-connection of neurons and synapses to emulate the computational structure of a mammalian brain. DL algorithms have demonstrated resounding success in many computer vision tasks and science domains such as high energy physics, computational chemistry and high performance computing use-cases. Several DL implementations such as TensorFlow, Caffe, Theano, and Torch have become available. These implementations are primarily geared towards compute nodes that may contain multi-core architecture (such as Intel Xeon/KNC/KNL) and or many-core architectures (GPUs). DL algorithms are under-going a tremendous revolution of their own. Widely used DL algorithms such as Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) are computationally expensive. Their computational requirements are further worsened by: 1) Very deep neural networks such as recently proposed 1000-layer complex Residual Networks (ResNet), 2) Increasing volume of data produced by simulations, experiments and handheld devices. An important solution to these problems is the design and implementation of DL algorithms that are capable of execution on distributed memory large scale cluster/cloud computing systems. A few distributed DL implementations such as CaffeonSpark, Distributed TensorFlow, CNTK, Machine Learning Toolkit on Extreme Scale (MaTEx), and FireCaffe have become available. Implementations such as CNTK, FireCaffe and MaTEx use MPI (Gropp et al., 1996; Geist et al., 1996) – which makes them a natural fit for high-end systems. DL algorithms primarily use gradient descent – an iterative technique in which the weights of synapes are updated using the difference between the ground truth (actual value) and the predicted value (using the current state of the neural network). The larger the difference, the steeper the de- scent to a minima (a low value of minima generates the ","TensorFlow: Large-scale machine learning on heterogeneous systems | An introduction to computational networks and the computational network toolkit | Theano: new features and speed improvements | Greedy layer-wise training of deep networks | Theano: a CPU and GPU math expression compiler | On the complexity of neural network classifiers: A comparison between shallow and deep architectures | Revisiting distributed synchronous SGD | Torch: A modular machine learning software | Large scale distributed deep networks | Adaptive subgradient methods for online learning and stochastic optimization | A High-Performance, Portable Implementation of the MPI Message Passing Interface Standard | Reducing the dimensionality of data with neural networks | A fast learning algorithm for deep belief nets | Firecaffe: nearlinear acceleration of deep neural network training on compute clusters | Caffe: Convolutional architecture for fast feature embedding | Imagenet classification with deep convolutional neural networks | Parallel netcdf: A highperformance scientific i/o interface | On the momentum term in gradient descent learning algorithms | Netcdf: an interface for scientific data access | Going deeper with convolutions | Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion",iclr,010
618.pdf.json,DYNAMIC STEERABLE FRAME NETWORKS,"For images, as well as any other sensory data, convolutional networks are typically learned from individual pixel values. Using them as a basis of the learned parameters is the standard approach for almost all CNNs. In this paper, we argue, that the pixel basis is not necessarily the best choice for representing signals. We show, that suitable alternatives yield increased classification performance by replacement only, while such a replacement adds additional properties to the learned filters that allow us to transform them under arbitrary pre-defined Lie groups. From our perspective, the pixel values span an orthogonal basis for the filters in the network (in every layer). Such a pixel basis is complete as it may represent an arbitrary vector in Rn by linear combination, where n is the dimensionality of the filter. In this paper we consider alternatives to this basis, both orthogonal bases, and non-orthogonal frames, arriving at superior expressiveness through steerable function spaces that allow us to transform filters locally and continuously, conditioned on their input. Utilizing the steerability properties of frames in practice, we propose Dynamic Steerable Frame Networks (DSFNs) that fill the gap between Spatial Transformer Networks (STNs) (Jaderberg et al., 2015) and Dynamic Filter Networks (DFNs) (De Brabandere et al., 2016). STNs are not locally adaptive, thus they fail in many cases where it is not beneficial to transform the image globally as it would destroy discriminative information (multiple deformable objects, discriminative dynamic movements) or where global registration is performed as a preprocessing step (medical images). DFNs are overcoming this restriction by locally transforming filters instead of globally transforming the whole feature stack as STNs do. However, DFNs are black boxes and not data-efficient, as they introduce many unconstrained parameters. Such a behavior is undesirable when data is limited and interpretability is key. DSFNs ar","Tensorflow: Large-scale machine learning on heterogeneous distributed systems | Unitary evolution recurrent neural networks | Invariant scattering convolution networks | An introduction to frames and Riesz bases, volume 7 | Learning the irreducible representations of commutative lie groups | Group equivariant convolutional networks | Framelets: Mra-based constructions of wavelet frames | Dynamic filter networks | Exploiting cyclic symmetry in convolutional neural networks | Scale and the differential structure of images | The design and use of steerable filters | Deep symmetry networks | Identity mappings in deep residual networks | Canonical decomposition of steerable functions | Transforming auto-encoders | Densely connected convolutional networks | Structured receptive fields in cnns | Spatial transformer networks | Canonical correlation analysis of video volume tensors for action categorization and detection | Scale-space processing using polynomial representations | Learning multiple layers of features from tiny images | A lie group approach to steerable filters | Deep roto-translation scattering for object classification | Steerable-scalable kernels for edge detection and junction analysis | Spectral representations for convolutional neural networks | Lie generators for computing steerable functions | A mathematical motivation for complex-valued convolutional networks | A unifying parametric framework for 2d steerable wavelet transforms",iclr,010
619.pdf.json,ADDING GRADIENT NOISE IMPROVES LEARNING FOR VERY DEEP NETWORKS,"Deep neural networks have shown remarkable success in diverse domains including image recognition (Krizhevsky et al., 2012), speech recognition (Hinton et al., 2012) and language processing applications (Sutskever et al., 2014; Bahdanau et al., 2014). This broad success comes from a confluence of several factors. First, the creation of massive labeled datasets has allowed deep networks to demonstrate their advantages in expressiveness and scalability. The increase in computing power has also enabled training of far larger networks with more forgiving optimization dynamics (Choromanska et al., 2015). Additionally, architectures such as convolutional networks (LeCun et al., 1998) and long short-term memory networks (Hochreiter & Schmidhuber, 1997) have proven to be easier to optimize than classical feedforward and recurrent models. Finally, the success of deep networks ∗First two authors contributed equally †Work was done when author was at Google, Inc. is also a result of the development of simple and broadly applicable learning techniques such as dropout (Srivastava et al., 2014), ReLUs (Nair & Hinton, 2010), gradient clipping (Pascanu et al., 2013; Graves, 2013), optimization algorithms and weight initialization strategies (Glorot & Bengio, 2010; Sutskever et al., 2013; He et al., 2015). Recent work has aimed to push neural network learning into more challenging domains, such as question answering or program induction. These more complicated problems demand more complicated architectures (e.g. Graves et al. (2014); Sukhbaatar et al. (2015)), thereby posing new optimization challenges. While there is very active research in improving learning in deep feedforward and recurrent networks, such as layer-wise deep supervision (Lee et al., 2015), novel activation functions (Maas et al., 2013), initialization schemes (He et al., 2015), and cell architectures (Cho et al., 2014a; Yao et al., 2015), these are not always sufficient or applicable in networks with complex struct","Natural gradient works efficiently in learning | The effects of adding noise during backpropagation training on a generalization performance | Normalization propagation: A parametric technique for removing internal covariate shift in deep networks | Neural machine translation by jointly learning to align and translate | Weight uncertainty in neural networks | Stochastic gradient learning in neural networks | The tradeoffs of large scale learning | Bridging the gap between stochastic gradient mcmc and stochastic optimization, 2016 | On the properties of neural machine translation: Encoder-decoder approaches | Learning phrase representations using RNN encoder-decoder for statistical machine translation | The loss surfaces of multilayer networks | Recurrent batch normalization | Large scale distributed deep networks | Adaptive subgradient methods for online learning and stochastic optimization | Understanding the difficulty of training deep feedforward neural networks | Practical variational inference for neural networks | Generating sequences with recurrent neural networks | Delving deep into rectifiers: Surpassing human-level performance on imagenet classification | Stochastic neighbor embedding | Deep neural networks for acoustic modeling in speech recognition | Long short-term memory | Batch normalization: accelerating deep network training by reducing internal covariate shift | Neural GPUs learn algorithms | Adam: A method for stochastic optimization | Optimization by simulated annealing | ImageNet classification with deep convolutional neural networks | Neural random-access machines | Batch normalized recurrent neural networks | Gradient-based learning applied to document recognition | Preconditioned stochastic gradient langevin dynamics for deep neural networks, 2016 | Rectifier nonlinearities improve neural network acoustic models | Building a large annotated corpus of english: The penn treebank | Optimizing neural networks with kronecker-factored approximate curvature | Training recurrent neural networks by diffusion, 2016 | Rectified linear units improve Restricted Boltzmann Machines | MCMC using Hamiltonian dynamics | Neural Programmer: Inducing latent programs with gradient descent | On the difficulty of training recurrent neural networks | Stochastic gradient riemannian langevin dynamics on the probability simplex | Towards neural network-based reasoning | Some methods of speeding up the convergence of iteration methods | A stochastic approximation method | Weight normalization: A simple reparameterization to accelerate training of deep neural networks. 2016 | Dropout: A simple way to prevent neural networks from overfitting | A recurrent network that performs a context-sensitive prediction task | End-to-end memory networks | Random walks: Training very deep nonlinear feed-forward networks with smart initialization | On the importance of initialization and momentum in deep learning | Sequence to sequence learning with neural networks | Bayesian learning via stochastic gradient Langevin dynamics | Towards AI-complete question answering: a set of prerequisite toy tasks | Depth-gated recurrent neural networks | Recurrent neural network regularization | Adadelta: An adaptive learning rate method",iclr,010
621.pdf.json,,,Harmonising chorales by probabilistic inference | Dynamic capacity networks | Statistical inference for probabilistic functions of finite state markov chains | Modeling temporal dependencies in high-dimensional sequences: Application to polyphonic music generation and transcription | music21: A toolkit for computer-aided musicology and symbolic music | A learned representation for artistic style | A neural algorithm of artistic style | Polyphonic music generation by modeling temporal dependencies using a rnn-dbn | Style imitation and chord invention in polyphonic music with exponential families | Deep residual learning for image recognition | A fast learning algorithm for deep belief nets | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Adam: A method for stochastic optimization | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | Discriminative regularization for generative models | Bachbot: Automatic composition in style of bach chorales | The collapsed gibbs sampler in bayesian computations with applications to a gene regulation problem | URL https://research.googleblog.com/2015/06/ inceptionism-going-deeper-into-neural.html | Context encoders: Feature learning by inpainting | Learning representations by backpropagating errors | Information processing in dynamical systems: Foundations of harmony theory | Nonuniversal critical dynamics in monte carlo simulations | A note on the evaluation of generative models | A deep and tractable density estimator | Neural autoregressive distribution estimation | On the equivalence between deep nade and generative stochastic networks,iclr,010
622.pdf.json,,"Residual Networks (He et al., 2015) (ResNets) are neural networks with skip connections. These networks, which are a specific case of Highway Networks (Srivastava et al., 2015), present state of the art results in the most competitive computer vision tasks including image classification and object detection. The success of residual networks was attributed to the ability to train very deep networks when employing skip connections (He et al., 2016). A complementary view is presented by Veit et al. (2016), who attribute it to the power of ensembles and present an unraveled view of ResNets that depicts ResNets as an ensemble of networks that share weights, with a binomial depth distribution around half depth. They also present experimental evidence that short paths of lengths shorter than half-depth dominate the ResNet gradient during training. The analysis presented here shows that ResNets are ensembles with a dynamic depth behavior. When starting the training process, the ensemble is dominated by shallow networks, with depths lower than half-depth. As training progresses, the effective depth of the ensemble increases. This increase in depth allows the ResNet to increase its effective capacity as the network becomes more and more accurate. Our analysis reveals the mechanism for this dynamic behavior and explains the driving force behind it. This mechanism remarkably takes place within the parameters of Batch Normalization (Ioffe & Szegedy, 2015), which is mostly considered as a normalization and a fine-grained whitening mechanism that addresses the problem of internal covariate shift and allows for faster learning rates. We show that the scaling introduced by batch normalization determines the depth distribution in the virtual ensemble of the ResNet. These scales dynamically grow as training progresses, shifting the effective ensemble distribution to bigger depths. The main tool we employ in our analysis is spin glass models. Choromanska et al. (2015a) have created a l","Complexity of random smooth functions on the highdimensional sphere | Random matrices and complexity of spin glasses | The loss surfaces of multilayer networks | Open problem: The landscape of the loss surfaces of multilayer networks | Understanding the difficulty of training deep feedforward neural networks | Deep residual learning for image recognition | Identity mappings in deep residual networks | Densely connected convolutional networks | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Learning Multiple Layers of Features from Tiny Images | Fractalnet: Ultra-deep neural networks without residuals | Neural networks: tricks of the trade | Residual networks behave like ensembles of relatively shallow networks | 2015a), γ refers to the number of paths. The multiplicative factor of Batch normalization appears as λ in Sec. 4. Fig. 2 depicts the results. There are two types of plots: Fig. 2(a,c) presents for CIFAR-10 and CIFAR-100 respectively the magnitude of the various convolutional layers for multiple epochs (sim",iclr,010
623.pdf.json,,"Given a (piece-wise) differentiable loss function, and a gradient based algorithm to minimize it, the knowledge of the second order information about it can tell us quite a bit about how the landscape looks like, and how we could modify our algorithm to make it go faster and find better solutions. But, one of the biggest challenges in second order optimization methods is in accessing that second order information itself. In particular, in deep learning there have been many proposals to accelerate training using second order information. Ngiam et al. (2011) has an in depth review of some of the proposals for approximating the Hessian of the loss function. Nevertheless, given the computational complexity of the problems at hand, it is hard to acquire information on what the actual Hessian looks like. This work is part of a series of papers that explore the data-model-algorithm connection along with Sagun et al. (2014; 2015) and it builds on top of the intuition developed in LeCun et al. (2012). We also note that the singularity of the Fisher information matrix have been explored (see for instance Watanabe (2007)). In another recent work, Dauphin et al. (2014) investigate saddle points of the landscape, in particular, they locate saddle points that are near the training path. In this work, however, we strictly focus on the Hessian of the loss function at the exact point of the training. We train the main examples using gradient descent. We perform our calculations of the Hessian using the implementation for the exact Hessian vector product that has been introduced in Pearlmutter (1994). And we find two new observations: one where the eigenvalues are zero, and one where we have a large, positive, and discrete set of eigenvalues. In this short note, we show how the data and the architecture depends on the eigenvalues of the Hessian of the loss function. In particular, we observe that the top discrete eigenvalues depend on the data, and the bulk of the eigenvalues depend ","Identifying and attacking the saddle point problem in high-dimensional non-convex optimization | Topology and geometry of deep rectified network optimization landscapes | Train faster, generalize better: Stability of stochastic gradient descent | Efficient backprop | Gradient descent converges to minimizers | On optimization methods for deep learning | Gradient descent only converges to minimizers: Nonisolated critical points and invariant regions | Fast exact multiplication by the hessian | Explorations on high dimensional landscapes | Under review as a conference paper at ICLR",iclr,010
624.pdf.json,LOCAL MINIMA IN TRAINING OF DEEP NETWORKS,"Deep Learning (LeCun et al., 2015; Schmidhuber, 2015) is a fast growing subfield of machine learning, with many impressive results. One particular criticism often brought up against this family of models is the fact that it relies on non-convex functions which are optimized using local gradient descent methods. This means one has no guarantee that the optimization algorithm will converge to a meaningful minimum or even that it will converge at all. However, this theoretical concern seems to have little bearing in practice. In Dauphin et al. (2013) a conjecture had been put forward for this based on insights from statistical physics which point to the scale of neural networks as a possible answer. The claim is that the error structure of neural networks might follow the same structure as that of random Gaussian fields which have been recently understood and studied in Fyodorov & Williams (2007); Bray & Dean (2007). The critical points of these functions, as the dimensionality of the problem increases, seem to have a particularly friendly behaviour where local minima align nicely close to the global minimum of the function. Choromanska et al. (2015) provides a study of the conjecture by mapping deep neural models onto spin-glass ones for whom the above structure holds. These work has been extended further (see Section 2 for a review of the topic). We believe many of these results do not trivially extend to the case of finite size datasets/finite size models. The learning dynamics of the neural network in this particular case can be arbitrarily bad. Our assertions are based on constructions of counterexamples that exploit particular architectures, the full domain of the parameters and particular datasets.","Neural networks and principal component analysis: Learning from examples without local minima | Statistics of critical points of gaussian fields on large-dimensional spaces | The loss surfaces of multilayer networks | Identifying and attacking the saddle point problem in high dimensional non-convex optimization | Replica symmetry breaking condition exposed by random matrix calculation of landscape complexity | Understanding the difficulty of training deep feedforward neural networks | Qualitatively characterizing neural network optimization problems | Deep learning without poor local minima | Adam: A method for stochastic optimization | Efficient backprop. In Neural Networks: Tricks of the Trade | Why does deep and cheap learning work so well?, 2016 | Humanlevel control through deep reinforcement learning | Asynchronous methods for deep reinforcement learning | Mean field theory of spin glasses: statistics and dynamics | On the difficulty of training recurrent neural networks | On the quality of the initial basin in overspecified neural networks | Learning hierarchical category structure in deep neural networks | Exact solutions to the nonlinear dynamics of learning in deep linear neural network | Deep learning in neural networks: An overview | Distribution-specific hardness of learning | No bad local minima: Data independent training error guarantees for multilayer neural networks | On the importance of initialization and momentum in deep learning | On the distribution of the roots of certain symmetric matrices | Understanding deep learning requires rethinking generalization",iclr,010
625.pdf.json,COMMUNICATING HIERARCHICAL NEURAL CONTROLLERS FOR LEARNING ZERO-SHOT TASK GENERALIZATION,"Humans can often generalize to novel tasks even without any additional learning by leveraging past learning experience. We would like our artificial agents to have similar “zero-shot” generalization capabilities. For example, after learning to solve tasks with instructions such as ‘Go to X (or Y)’ and ‘Pick up Y (or Z)’, our agent should be able to infer the underlying goal of new tasks with instructions like ‘Go to Z’, which requires disentangling the verbs (‘Go to/Pick up’) and the nouns/objects (‘X, Y, Z’). Furthermore, we would like our agents to learn to compose policies to solve novel tasks composed of sequences of seen and unseen instructions. Developing the ability to achieve such generalizations is a key challenge in artificial intelligence and the subfield of reinforcement learning (RL). In this paper, we study the problem of zero-shot task generalization in RL by introducing the “instruction execution” problem where the agent is required to learn through interaction with its environment how to achieve an overall task specified by a list of high-level instructions (see Figure 1). As motivation for this problem consider a human owner training its new household robot to execute complex tasks specified by natural language text that decompose the task into a sequence of instructions. Given that it is infeasible to explicitly train the robot on all possible instruction-sequences, this problem involves two types of generalizations: to unseen and longer sequences of previously seen instructions, and sequences where the some of the instructions themselves were previously not seen. Of course, the usual RL problem of learning policies through interaction to accomplish the goals of an instruction remains part of the problem as well. We assume that the agent does not receive any signal on completing or fail- ing to complete individual instructions from the environment/owner and so the informative reward signal is delayed until the end. Furthermore, there can be random","Programmable reinforcement learning agents | State abstraction for programmable reinforcement learning agents | The option-critic architecture | Learning feed-forward oneshot learners | Learning shared representations for value functions in multi-task reinforcement learning | Reinforcement learning for mapping instructions to actions | Learning to interpret natural language navigation instructions from observations | Learning parameterized skills | Hierarchical reinforcement learning with the maxq value function decomposition | Hierarchical policy gradient algorithms | Neural turing machines | Dimensionality reduction by learning an invariant mapping | Deep recurrent q-learning for partially observable mdps | Long short-term memory | Using task features for zero-shot knowledge transfer in lifelong learning | Actor-critic algorithms | Building portable options: Skill transfer in reinforcement learning | Transfer in reinforcement learning via shared features | Hierarchical deep reinforcement learning: Integrating temporal abstraction and intrinsic motivation | Predicting deep zero-shot convolutional neural networks using textual descriptions | Walk the talk: Connecting language, knowledge, and action in route instructions | Listen, attend, and walk: Neural mapping of navigational instructions to action sequences | Learning to represent spatial transformations with factored higherorder boltzmann machines | Asynchronous methods for deep reinforcement learning | Memory-based control of active perception and action in minecraft | Actor-mimic: Deep multitask and transfer reinforcement learning | Reinforcement learning with hierarchies of machines | Learning to disentangle factors of variation with manifold interaction | Deep visual analogy-making | Policy distillation | Universal value function approximators | High-dimensional continuous control using generalized advantage estimation | The efficient learning of multiple task sequences | Transfer of learning by composing solutions of elemental sequential tasks | Mazebase: A sandbox for learning from games | Between mdps and semi-mdps: A framework for temporal abstraction in reinforcement learning | Understanding natural language commands for robotic navigation and mobile manipulation | Asking for help using inverse semantics | A deep hierarchical approach to lifelong learning in minecraft | Strategic attentive writer for learning macro-actions | Reinforcement learning neural turing machines",iclr,010
626.pdf.json,THE PREIMAGE OF RECTIFIER NETWORK ACTIVITIES,"The activity of the nodes at each level of a deep network contains all the information that will be used for classification. Ideally, if the activities are generated by two inputs from the same class, they should be similar and if the classes are distinct the activities should be distinct. The map from the input to any layer of a deep network can however easily be shown to be many to one. This means that classes can potentially get mixed at any level of the network by mapping to the same activity. This mixing cannot be undone at later stages and must therefore be avoided. Given a certain activity it is therefore essential to know the set of inputs to the network that result in this activity. This set should obviously not contain exemplars from more than one class. This means that they are potential building blocks for designing efficient classifiers. In this paper we will demonstrate that the set of inputs resulting in a specific activity at any level of a deep rectifier network can be completely characterised and we will give a procedure for computing them. For a specific activity at any level they are known as the preimage of the function mapping the input to the activity. In this procedure we disregard the effects of pooling the outputs of node activities. This can be seen as complementary to the work in Mahendran & Vedaldi (2015; 2016) where specific preimages are computed numerically by a regularised optimisation procedure that tries to map the image to the natural image manifold. For multi layer rectifier networks where each layer consists of linear mappings followed by a rectifying linear unit (ReLU), the set of possible functions that map inputs to node activities can be shown to be piecewise linear Glorot et al. (2011); Montufar et al. (2014). We will demonstrate that for a specific activity at any level, the equivalence class of inputs that can generate this activity consists of piecewise linear manifolds in the input space. For efficient classification by",How can deep rectifier networks achieve linear separability and preserve distances | Efficient representation of low-dimensional manifolds using deep | Why deep learning works: A manifold disentanglement perspective | The double algebra: An effective tool for computing invariants in computer vision | Deep sparse rectifier neural networks | Explaining and harnessing adversarial examples | Understanding deep image representations by inverting them | Visualizing deep convolutional neural networks using natural pre-images | On the number of linear regions of deep neural networks | Deep neural networks are easily fooled: High confidence predictions for unrecognizable images | Intriguing properties of neural networks,iclr,010
627.pdf.json,,"Neural machine translation (NMT) has achieved great success in recent years (Sutskever et al., 2014; Bahdanau et al., 2015). In contrast to statistical machine translation, which requires huge phrase and rule tables, NMT requires much less memory. However, the most standard model, NMT with attention (Bahdanau et al., 2015) entails the shortcoming that the attention mechanism cannot capture the entire meaning of a sentence because it generates a target word while depending heavily on the relevant parts of the source sentence (Tu et al., 2016). To overcome this problem, Variational Neural Machine Translation (VNMT), which outperforms NMT with attention introduces a latent variable to capture the underlying semantic from source and target (Zhang et al., 2016). We follow the motivation of VNMT, which is to capture underlying semantic of a source. Image information is related to language. For example, we human beings understand the meaning of language by linking perceptual information given by the surrounding environment and language (Barsalou, 1999). Although it is natural and easy for humans, it is difficult for computers to understand different domain’s information integrally. Solving this difficult task might, however, bring great improvements in natural language processing. Several researchers have attempted to link language and images such as image captioning by Xu et al. (2015) or image generation from sentences by Reed et al. (2016). They described the possibility of integral understanding of images and text. In machine translation, we can expect an improvement using not only text information but also image information because image information can bridge two languages. As described herein, we propose the neural machine translation model which introduces a latent variable containing an underlying semantic extracted from texts and images. Our model includes an explicit latent variable z, which has underlying semantics extracted from text and images by introducing ","Neural machine translation by jointly learning to align and translate | Perceptual symbol Systems | Does Multimodality Help Human and Machine for Translation and Image Captioning | DCU-UvA Multimodal MT System Report | Meteor Universal: Language Specific Translation Evaluation for Any Target Language | Multilingual Image Description with Neural Sequence Models | Fast R-CNN | Deep Residual Learning for Image Recognition | Multimodal Pivots for Image Caption Translation | Attention-based Multimodal Neural Machine Translation | Semi-supervised Learning with Deep Generative Models | Open Source Toolkit for Statistical Machine Translation | CUNI System for WMT16 Automatic Post-Editing and Multimodal Translation Tasks | BLEU: A Method for Automatic Evaluation of Machine Translation | Generative Adversarial Text to Image Synthesis | Stochastic Backpropagation and Approximate Inference in Deep Generative Models | Costa-jussà. WMT 2016 Multimodal Translation System Description based on Bidirectional Recurrent Neural Networks with Double-Embeddings | Neural Machine Translation of Rare Words with Subword Units | SHEF-Multimodal: Grounding Machine Translation on Images | Very Deep Convolutional Networks for Large-Scale Image Recognition | Sequence to Sequence Learning with Neural Networks | Modeling Coverage for Neural Machine Translation | Show, Attend and Tell: Neural Image Caption Generation with Visual Attention | Variational Neural Machine Translation | CONDITIONAL GRU Conditional GRU is implemented in dl4mt. Caglayan et al. (2016) extends Conditional GRU to make it capable of receiving image information",iclr,010
628.pdf.json,,"Sum-product networks (SPNs) (Poon & Domingos, 2011; Gens & Domingos, 2012) are a class of deep probabilistic models that consist of many layers of hidden variables and can have unbounded treewidth. Despite this depth and corresponding expressivity, exact inference in SPNs is guaranteed to take time linear in their size, allowing their structure and parameters to be learned effectively from data. However, there are still many models for which the corresponding SPN has size exponential in the number of variables and is thus intractable. For example, in scene understanding (or semantic segmentation), the goal is to label each pixel of an image with its semantic class, which requires simultaneously detecting, segmenting, and recognizing each object in the scene. Even the simplest SPN for scene understanding is intractable, as it must represent the exponentially large set of segmentations of the image into its constituent objects. Scene understanding is commonly formulated as a flat Markov (or conditional) random field (MRF) over the pixels or superpixels of an image (e.g., Shotton et al. (2006); Gould et al. (2009)). Inference in MRFs is intractable in general; however, there exist restrictions of the MRF that enable tractable inference. For pairwise binary MRFs, if the energy of each pairwise term is submodular (alternatively, attractive or regular) (Kolmogorov & Zabih, 2004), meaning that each pair of neighboring pixels prefers to have the same label, then the exact MAP labeling of the MRF can be recovered in low-order polynomial time through the use of a graph cut algorithm1 (Greig et al., 1989; Boykov & Kolmogorov, 2004). This result from the binary case has been used to develop a number of powerful approximate algorithms for the multi-label case (e.g., Komodakis et al. (2007); Lempitsky et al. (2010)), the most well-known of which is α-expansion (Boykov et al., 2001), which efficiently returns an approximate labeling that is within a constant factor of the true opt","Network flows: theory, algorithms and applications | An experimental comparison of min-cut/max-flow algorithms for energy minimization in vision | Fast approximate energy minimization via graph cuts | Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs | DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs | On Certain Formal Properties of Grammars | AND/OR search spaces for graphical models | Discriminative learning of sum-product networks | Learning the structure of sum-product networks | Decomposing a scene into geometric and semantically consistent regions | Exact maximum a posteriori estimation for binary images | Introduction to Automata Theory, Languages, and Computation | Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition | Minimizing nonsubmodular functions with graph cuts a review | What Energy Functions Can Be Minimized via Graph Cuts | Fast, approximately optimal solutions for single and dynamic MRFs | Fusion Moves for Markov Random Field Optimization | A Pylon Model for Semantic Segmentation | Sum-product networks: A new deep architecture | Exact and Approximate Inference in Associative Hierarchical Networks using Graph Cuts | Recursive Context Propagation Network for Semantic Scene Labeling | TextonBoost: Joint Appearance, Shape and Conext Modeling for Muli-class object Recognition and Segmentation | Parsing natural scenes and natural language with recursive neural networks | Image Parsing via Stochastic Scene Grammar | A Stochastic Grammar of Images",iclr,010
629.pdf.json,HUMAN PERCEPTION IN COMPUTER VISION / CONFERENCE SUBMISSIONS,"Deep neural networks (DNNs) are a class of computer learning algorithms that have become widely used in recent years (LeCun et al., 2015). By training with millions of examples, such models achieve unparalleled degrees of task-trained accuracy (Krizhevsky et al., 2012). This is not unprecedented on its own - steady progress has been made in computer vision for decades, and to some degree current designs are just scaled versions of long-known principles (Lecun et al., 1998). In previous models, however, only the design is general-purpose, while learning is mostly specific to the context of a trained task. Interestingly, for current DNNs trained to solve a large-scale image recognition problem (Russakovsky et al., 2014), the learned computation is useful as a building block for drastically different and untrained visual problems (Huh et al., 2016; Yosinski et al., 2014). For example, orientation- and frequency-selective features (Gabor patches) can be considered general-purpose visual computations. Such features are routinely discovered by DNNs (Krizhevsky et al., 2012; Zeiler & Fergus, 2013), by other learning algorithms (Hinton & Salakhutdinov, 2006; ∗https://sites.google.com/site/rondekelhomepage/ Lee et al., 2008; 2009; Olshausen & Field, 1997), and are extensively hard-coded in computer vision (Jain & Farrokhnia, 1991). Furthermore, a similar computation is believed to underlie the spatial response properties of visual neurons of diverse animal phyla (Carandini et al., 2005; DeAngelis et al., 1995; Hubel & Wiesel, 1968; Seelig & Jayaraman, 2013), and is evident in human visual perception (Campbell & Robson, 1968; Fogel & Sagi, 1989; Neri et al., 1999). This diversity culminates in satisfying theoretical arguments as to why Gabor-like features are so useful in general-purpose vision (Olshausen, 1996; Olshausen & Field, 1997). As an extension, general-purpose computations are perhaps of universal use. For example, a dimensionality reduction transformation that opti","Local masking in natural images: A database and analysis | A computational model for predicting local distortion visibility via convolutional neural network trainedon natural scenes | Deep neural networks rival the representation of primate IT cortex for core visual object recognition | Application of Fourier analysis to the visibility of gratings | Do we know what the early visual system does | Receptive-field dynamics in the central visual pathways | Brain dynamics underlying the nonlinear threshold for access to consciousness | Generating images with perceptual similarity metrics based on deep networks | Examining Representational Similarity in ConvNets and the Primate Visual Cortex | A 3D shape inference model matches human visual object similarity judgments better than deep convolutional neural networks | Rapid categorization of natural images by rhesus monkeys | Contour integration by the human visual system: evidence for a local association field | Gabor filters as texture discriminator | A Neural Algorithm of Artistic Style. aug 2015a | Texture synthesis and the controlled generation of natural stimuli using convolutional neural networks. may 2015b | Contrast constancy: deblurring in human vision by spatial frequency channels | Generative adversarial nets | A power law for perceived contrast in human vision | Target selective tilt-after effect during texture learning | Deep Residual Learning for Image Recognition | Reducing the dimensionality of data with neural networks. Science (New York, N.Y.) | Receptive fields and functional architecture of monkey striate cortex | What makes ImageNet good for transfer learning? aug 2016 | Fast readout of object identity from macaque inferior temporal cortex | Unsupervised texture segmentation using Gabor filters | Perceptual losses for real-time style transfer and super-resolution | Where practice makes perfect in texture discrimination: evidence for primary visual cortex plasticity | Deep Supervised, but Not Unsupervised, Models May Explain IT Cortical Representation | Deep neural networks: A new framework for modeling biological vision and brain information processing | ImageNet Classification with Deep Convolutional Neural Networks | Deep Neural Networks as a Computational Model for Human Shape Sensitivity | The distinct modes of vision offered by feedforward and recurrent processing | Most apparent distortion: full-reference image quality assessment and the role of strategy | Gradient-based learning applied to document recognition | Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network. sep 2016 | Sparse deep belief net model for visual area V2 | Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations | Convergent Learning: Do different neural networks learn the same representations | Near-threshold perceptual distortion prediction based on optimal structure classification | Configuration influence on crowding | Inceptionism: Going deeper into neural networks | Probing the human stereoscopic system with reverse correlation | Emergence of simple-cell receptive field properties by learning a sparse code for natural images | Sparse coding with an overcomplete basis set: A strategy employed by V1 | Crowding is unlike ordinary masking: Distinguishing feature integration from detection | Expectation and the tilt aftereffect | Target-selective tilt aftereffect during texture learning | Lateral interactions between spatial channels: suppression and facilitation revealed by lateral masking experiments | Do computational models differ systematically from human object perception | Hierarchical models of object recognition in cortex | ImageNet Large Scale Visual Recognition Challenge | Perceptual learning in vision research | Feature detection and orientation tuning in the Drosophila central complex | Hierarchical Models of the Visual System | Very Deep Convolutional Networks for Large-Scale Image Recognition | Intriguing properties of neural networks | Going Deeper with Convolutions | Matconvnet: Convolutional neural networks for matlab | Predicting visual acuity from wavefront aberrations | Adaptation and visual coding | Visual Detection of Line Segments: An Object-Superiority Effect | Using goal-driven deep learning models to understand sensory cortex | Performance-optimized hierarchical models predict neural responses in higher visual cortex | How transferable are features in deep neural networks | Visualizing and Understanding Convolutional Networks. nov | Object Detectors Emerge in Deep Scene CNNs | The noiseless images",iclr,010
630.pdf.json,,"Encoder-decoder models have been widely used in sequence to sequence tasks such as machine translation (Cho et al. (2014); Sutskever et al. (2014)). They consist of an encoder which represents the whole input sequence with a single feature vector. The decoder then takes this representation and generates the desired output sequence. The most successful models are LSTM and GRU as they are much easier to train than vanilla RNNs. In this paper we are interested in summarization where the input sequence is a sentence/paragraph and the output is a summary of the text. Several encoding-decoding approaches have been proposed (Rush et al. (2015); Hu et al. (2015); Chopra et al. (2016)). Despite their success, it is commonly believed that the intermediate feature vectors are limited as they are created by only looking at previous words. This is particularly detrimental when dealing with large input sequences. Bi-directorial RNNs (Schuster & Paliwal (1997); Bahdanau et al. (2014)) try to address this problem by computing two different representations resulting of reading the input sequence left-to-right and right-to-left. The final vectors are computed by concatenating the two representations. However, the word representations are computed with limited scope. The decoder employed in all these methods outputs at each time step a distribution over a fixed vocabulary. In practice, this introduces problems with rare words (e.g., proper nouns) which are out of vocabulary. To alleviate this problem, one could potentially increase the size of the decoder vocabulary, but decoding becomes computationally much harder, as one has to compute the soft-max over all possible words. Gulcehre et al. (2016), Nallapati et al. (2016) and Gu et al. (2016) proposed to use a copy mechanism that dynamically copy the words from the input sequence while decoding. However, they lack the ability to extract proper embeddings of out-of-vocabulary words from the input context. Bahdanau et al. (2014) propose","Neural machine translation by jointly learning to align and translate | Headline generation based on statistical translation | Neural summarization by extracting sentences and words | Learning phrase representations using rnn encoder-decoder for statistical machine translation | Abstractive sentence summarization with attentive recurrent neural networks | Sentence compression beyond word deletion | Natural language processing (almost) from scratch | Heads: Headline generation as sequence prediction using an abstract feature-rich | Lexrank: Graph-based lexical centrality as salience in text summarization | Overcoming the lack of parallel data in sentence compression | Incorporating copying mechanism in sequence-to-sequence learning | Pointing the unknown words | Lcsts: A large scale chinese short text summarization dataset | Recurrent continuous translation models | Addressing the rare word problem in neural machine translation | Abstractive text summarization using sequence-to-sequence rnns and beyond | Annotated gigaword. In Proceedings of the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction, pp. 95–100 | Automatic text summarization using a machine learning approach | A neural attention model for abstractive sentence summarization | Bidirectional recurrent neural networks | Random walk initialization for training very deep feedforward networks | Sequence to sequence learning with neural networks. In Advances in neural information processing | Extractive summarization using supervised and semisupervised learning | Generation with quasi-synchronous grammar | Bbn/umd at duc-2004: Topiary",iclr,010
631.pdf.json,LAYER RECURRENT NEURAL NETWORKS,"In computer vision tasks, such as image classification or pixel level prediction, multi-scale contextual information plays a very important role in achieving high performance. The original architectures for these tasks (e.g. He et al. (2016a); Krizhevsky et al. (2012); Long et al. (2015); Ronneberger et al. (2015); Simonyan & Zisserman (2015); Szegedy et al. (2015)) were able to obtain multi-scale context with a large spatial footprint by the combination of filters through the layers of the network, so that a large receptive field was effectively built up. Indeed, the final layers of these networks use average pooling or fully connected layers (convolution with a large kernel) so that the effective receptive field covers the entire input image patch. More recent pixel prediction architectures have used dilated convolutions (Yu & Koltun, 2016; Chen et al., 2016) which are able to aggregate multi-scale contextual information without losing resolution (due to the spatial pooling and strides in the original architectures), and without incurring the penalty of having to learn many parameters for convolutions with very large kernels. In this paper we introduce an alternative ‘module’ for learning multi-scale spatial contextual information by using Recurrent Neural Networks (RNNs) within layers. This approach is inspired by the ReNet architecture of Visin et al. (2015), which we extend here into a hybrid architecture that interleaves traditional convolutional neural network (CNN) modules with layer recurrent modules, and we term a Layer Recurrent Neural Network (L-RNN). A L-RNN module is a combination of 1D RNNs, and is able to learn contextual information adaptively, with the effective receptive field able to reach across the entire feature map or image, if that is required for the task. The hybrid network combines the best of both worlds: canonical CNNs are composed of filters that are efficient in capturing features in a local region, whilst the L-RNNs are able to learn","Inside-outside net: Detecting objects in context with skip pooling and recurrent neural networks | Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs | Gated feedback recurrent neural networks | Identifying and attacking the saddle point problem in high-dimensional non-convex optimization | Imagenet: A large-scale hierarchical image database | Offline handwriting recognition with multidimensional recurrent neural networks | Simultaneous detection and segmentation | Deep residual learning for image recognition | Identity mappings in deep residual networks. ECCV, 2016b | Densely connected convolutional networks | Efficient inference in fully connected crfs with gaussian edge potentials | ImageNet classification with deep convolutional neural networks | Convolutional neural networks with intra-layer recurrent connections for scene labeling | Learning recursive filters for low-level vision via a hybrid neural network | Fully convolutional networks for semantic segmentation | Recurrent convolutional neural networks for scene labeling | Fitnets: Hints for thin deep nets | U-net: Convolutional networks for biomedical image segmentation | Very deep convolutional networks for large-scale image recognition | Generative image modeling using spatial lstms | Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude | Renet: A recurrent neural network based alternative to convolutional networks | Reseg: A recurrent neural network-based model for semantic segmentation | Multi-scale context aggregation by dilated convolutions | Conditional random fields as recurrent neural networks | Traditionally, the learning rate is decreased every several epochs, and gradients that are used to update parameters depend on both the learning rate and the derivatives w.r.t loss functions",iclr,010
632.pdf.json,,"There is a growing interest in incorporating external memory into neural networks. For example, memory networks (Weston et al., 2014; Sukhbaatar et al., 2015) are equipped with static memory slots that are content or location addressable. Neural Turing machines (Graves et al., 2014) implement memory slots that can be read and written as in Turing machines (Turing, 1938) but through differentiable attention mechanism. Each memory slot in these models stores a vector corresponding to a continuous representation of the memory content. In order to recall a piece of information stored in memory, attention is typically employed. Attention mechanism introduced by Bahdanau et al. (2014) uses a network that outputs a discrete probability mass over memory items. A memory read can be implemented as a weighted sum of the memory vectors in which the weights are given by the attention network. Reading out a single item can be realized as a special case in which the output of the attention network is peaked at the desired item. The attention network may depend on the current context as well as the memory item itself. The attention model is called location-based and content-based, if it depends on the location in the memory and the stored memory vector, respectively. Knowledge bases, such as WordNet and Freebase, can also be stored in memory either through an explicit knowledge base embedding (Bordes et al., 2011; Nickel et al., 2011; Socher et al., 2013) or through a feedforward network (Bordes et al., 2015). When we embed entities from a knowledge base in a continuous vector space, if the capacity of the embedding model is appropriately controlled, we expect semantically similar entities to be close to each other, which will allow the model to generalize to unseen facts. However the notion of proximity may strongly depend on the type of a relation. For example, Benjamin Franklin was an engineer but also a politician. We would need different metrics to capture his proximity to oth","Neural machine translation by jointly learning to align and translate | Learning structured embeddings of knowledge bases | Translating embeddings for modeling multi-relational data | Open question answering with weakly supervised embedding models | Large-scale simple question answering with memory networks | Fast and accurate deep network learning by exponential linear units (elus) | Sequence transduction with recurrent neural networks | Neural turing machines | Traversing knowledge graphs in vector space | Long short-term memory | Adam: A method for stochastic optimization | Gated graph sequence neural networks | Efficient estimation of word representations in vector space | Compositional vector space models for knowledge base completion | Efficient non-parametric estimation of multiple embeddings per word in vector space | A three-way model for collective learning on multi-relational data | Reasoning with neural tensor networks for knowledge base completion | End-to-end memory networks | Sequence to sequence learning with neural networks. In Advances in neural information processing | On computable numbers, with an application to the entscheidungsproblem: A correction | Word representations via gaussian embedding | Knowledge graph embedding by translating on hyperplanes | Nonlinear latent factorization by embedding multiple user interests | Fast and easy language understanding for dialog systems with microsoft language understanding intelligent service (LUIS) | TRANSGAUSSIAN EMBEDDING OF WORLDCUP2014 We trained our TransGaussian model on triplets and paths from WorldCup2014 dataset and illustrated the embeddings in Fig 3 and 4. Recall that we modeled every relation as a Gaussian with diagonal covariance matrix. Fig 3 shows the learned variance parameters of different relations | The atomic triplets in this dataset was originally created by Socher et al. (2013) and Guu et al. (2015) added path queries that were randomly sampled from the knowledge graph. We build our TransGaussian model by training on these triplets and paths and tested our model on the same link prediction task | 2015), we trained TransGaussian (SINGLE) with atomic triplets only and trained TransGaussian (COMP) with the union of atomic triplets and paths",iclr,010
633.pdf.json,,,Imagenet: A large-scale hierarchical image database | Deep generative image models using a laplacian pyramid of adversarial networks | Learning to generate chairs with convolutional neural networks | Generative adversarial nets | Alternating back-propagation for generator network | Training products of experts by minimizing contrastive divergence | Deep directed generative models with energy-based probability estimation | Auto-encoding variational bayes | Imagenet classification with deep convolutional neural networks | Gradient-based learning applied to document recognition | A tutorial on energy-based learning | Deep learning face attributes in the wild | Neural variational inference and learning in belief networks | Learning deep energy models | Unsupervised representation learning with deep convolutional generative adversarial networks | Stochastic backpropagation and approximate inference in deep generative models | A stochastic approximation method | Energy-based models for sparse overcomplete representations | Matconvnet – convolutional neural networks for matlab | A theory of generative convnet | On the convergence of markovian stochastic algorithms with rapidly decreasing ergodicity rates | Learning deep features for scene recognition using places database | Statistical modeling and conceptualization of visual patterns | Minimax entropy principle and its application to texture modeling,iclr,010
634.pdf.json,,"Due to tremendous progress over the last several years, the most advanced deep neural networks (DNNs) have managed to approach and even surpass human level performance on a wide range of challenging machine learning tasks (Parkhi et al., 2015; Schroff et al., 2015; Szegedy et al., 2015; He et al., 2016). Despite the fact that we are able to design and train learning models that perform well, our understanding of these complex networks is still incomplete. This was highlighted by the discovery of the intriguing properties of machine learning models by Szegedy et al. (2014). Gaining intuitive insights and, thus, building a better understanding of how these models work has a long history in the literature. For visual recognition tasks, various techniques have been proposed to address the problem of understanding what kind of features are captured and used by learning models (Erhan et al., 2009; Mahendran & Vedaldi, 2016) and how the different internal representations of object classes or input images can be better visualized (Zeiler & Fergus, 2014; Yosinski et al., 2015; Simonyan et al., 2014; Mahendran & Vedaldi, 2016). While exploring the internal details of DNNs in order to further advance their performance via visualization is particularly relevant and the subject of this paper, recent research has also been focusing on the unpleasant properties revealed by Szegedy et al. (2014). Namely, machine learning models, including the best performing DNNs, suffer from highly unexpected instability as they can confidently misclassify adversarial examples that are formed by adding imperceptible, non-random perturbations to otherwise correctly classified inputs. As DNNs are expected to be robust to small perturbations to their inputs due to their excellent generalization capabilities, the existence of such adversarial perturbations challenges our understanding of DNNs, and questions the utility of such vulnerable learning models in real-world applications. Researchers proposed",Visualizing higher-layer features of a deep network | Rich feature hierarchies for accurate object detection and semantic segmentation | Explaining and harnessing adversarial examples | Deep residual learning for image recognition | Caffe: Convolutional architecture for fast feature embedding | Learning algorithms for classification: A comparison on handwritten digit recognition | Training invariant support vector machines using selective sampling | Visualizing deep convolutional neural networks using natural pre-images | Deep face recognition | Adversarial diversity and hard positive generation | Adversarial manipulation of deep representations | FaceNet: A unified embedding for face recognition and clustering | Deep inside convolutional networks: Visualising image classification models and saliency maps | Going deeper with convolutions | Intriguing properties of neural networks | Understanding neural networks through deep visualization | Visualizing and understanding convolutional networks,iclr,010
636.pdf.json,,"Weight initialization and Batch Normalization greatly influence a neural network’s ability to learn. Both methods can allow for a unit-variance neuron input distribution. This is desirable because variance larger or smaller than one may cause activation outputs to explode or vanish. In order to encourage unit-variance, early weight initialization attempts sought to adjust for a neuron’s fan-in (LeCun et al., 1998). More recent initializations correct for a neuron’s fan-out (Glorot & Bengio, 2010). Meanwhile, some weight initializations compensate for the compressiveness of the ReLU nonlinearity (the ReLU’s tendency to reduce output variance) (He et al., 2015). Indeed, He et al. (2015) also show that initializations without a specific, small corrective factor can render a neural network untrainable. To address this issue Batch Normalization (Ioffe & Szegedy, 2015) reduces the role of weight initialization at the cost of up to 30% more computation (Mishkin & Matas, 2015). A less computationally expensive solution is the LSUV weight initialization, yet this still requires computing batch statistics, a special forward pass, and makes no adjustment for backpropagation error signal variance (Mishkin & Matas, 2015). Similarly, weight normalization uses a special feedforward pass and computes batch statistics (Salimans & Kingma, 2016). The continued development of variance stabilizing techniques testifies to its importance for neural networks. Both Batch Normalization and previous weight initializations do not accommodate the variance introduced by dropout, and we contribute methods to fix this. First we demonstrate a new weight initialization technique which includes a new correction factor for a layer’s dropout rate and adjusts for an arbitrary nonlinearity’s effect on the neuron output variance. All of this is obtained without computing batch statistics or special adjustments to the forward pass, unlike recent methods to control variance (Ioffe & Szegedy, 2015; Mishkin &",Fast and accurate deep network learning by exponential linear units (ELUs) | Understanding the difficulty of training deep feedforward neural networks | Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification | Bridging nonlinearities and stochastic regularizers with Gaussian error linear units | Densely connected convolutional networks | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Adam: A Method for Stochastic Optimization | Learning Multiple Layers of Features from Tiny Images | Efficient backprop | All you need is a good init | Weight normalization: A simple reparameterization to accelerate training of deep neural networks | Very deep convolutional networks for large-scale image recognition | Wide residual networks,iclr,010
637.pdf.json,,"Knowledge Bases (KB) capture relational knowledge about a domain of choice by modelling entities and facts relating them. In so doing, KBs allow for rich answers to user queries, as happens with the knowledge panels powered by the Google Knowledge Graph. Furthermore, KBs can be mined for rules, i.e. patterns of relations which are frequently found to hold in the KB. Mining theories from data is the task of Rule Mining (Dzeroski & Lavrac, 2000) and Inductive Logic Programming (Dzeroski & Lavrac, 1994; Muggleton et al., 1992). Classical ILP methods mine theories by searching over the (exponentially large) space of logical theories, resorting to language biases and heuristics to simplify the learning problem. While powerful, pure ILP methods do not scale to large relational datasets, preventing them from mining Web-scale KBs such as YAGO (Hoffart et al., 2013) and DBpedia (Auer et al., 2007). Further, purely logical methods can not gracefully deal with noise. Next-generation miners that specialize on large KBs, such as AMIE (Galárraga et al., 2015), work around these issues by trading off theory expressiveness for runtime efficiency. A general strategy for processing huge datasets is dimensionality reduction: instead of working on the original KB directly, one first squeezes it to a summary of manageable size, and then performs the required operations on the summary itself. Common summarization techniques for relational data include relational factorization (Nickel et al., 2011; London et al., 2013; Riedel et al., 2013) and representation learning (Bordes et al., 2011; Socher et al., 2013). The core idea is to learn compressed latent representations, or embeddings, of entities and relations able to reconstruct the original KB by minimizing a suitable reconstruction loss. Until recently, relational embeddings have been mostly employed for link prediction and knowledge base completion (Nickel et al., 2016). However, Yang et al. (2015) have shown that low-dimensional rep","Dbpedia: A nucleus for a web of open data | Learning structured embeddings of knowledge bases | Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency information | Atomic decomposition by basis pursuit | Inductive logic programming: Techniques and applications | Relational Data Mining, New York | Kinship classification by modeling facial feature heredity | Fast rule mining in ontological knowledge bases with amie+ | Composing relationships with translations | Traversing knowledge graphs in vector space | Yago2: A spatially and temporally enhanced knowledge base from wikipedia | Learning systems of concepts with an infinite relational model | Learning markov logic network structure via hypergraph lifting | Non-negative tensor factorization with rescal | kfoil: Learning simple relational kernels | Multi-relational learning using weighted tensor decomposition with modular loss | Exact rule learning via boolean compressed sensing | Inverse entailment and progol | Inductive logic programming, volume 168 | Compositional vector space models for knowledge base completion | A three-way model for collective learning on multi-relational data | Factorizing yago: scalable machine learning for linked data | A review of relational machine learning for knowledge graphs | Orthogonal matching pursuit: Recursive function approximation with applications to wavelet decomposition | Learning logical definitions from relations | Learning relations by pathfinding | Relation extraction with matrix factorization and universal schemas | Injecting logical background knowledge into embeddings for relation extraction | Reasoning with neural tensor networks for knowledge base completion | Interpretable two-level boolean rule learning for classification | Online search orthogonal matching pursuit | Embedding entities and relations for learning and inference in knowledge bases",iclr,010
640.pdf.json,BEYOND BILINGUAL: MULTI-SENSE WORD EMBED-,"Word embeddings (Turian, Ratinov, and Bengio, 2010; Mikolov, Yih, and Zweig, 2013, inter alia) represent a word as a point in a vector space. This space is able to capture semantic relationships: vectors of words with similar meanings have high cosine similarity. Use of embeddings as features has been shown to benefit several NLP tasks and serve as good initializations for deep architectures ranging from dependency parsing (Bansal, Gimpel, and Livescu, 2014) to named entity recognition (Guo et al., 2014b). Although these representations are now ubiquitous in NLP, most algorithms for learning wordembeddings do not allow a word to have different meanings in different contexts, a phenomenon known as polysemy. For example, the word bank assumes different meanings in financial (eg. “bank pays interest”) and geographical contexts (eg. “river bank”) and which cannot be represented adequately with a single embedding vector. Unfortunately, there are no large sense-tagged corpora available and such polysemy must be inferred from the data during the embedding process. Several attempts (Reisinger and Mooney, 2010; Neelakantan et al., 2014; Li and Jurafsky, 2015) have been made to infer multi-sense word representations by modeling the sense as a latent variable in a Bayesian non-parametric framework. These approaches rely on the ”one-sense per collocation” heuristic (Yarowsky, 1995), which assumes that presence of nearby words correlate with the sense of the word of interest. This heuristic provides only a weak signal for sense identification, and such algorithms require large amount of training data to achieve competitive performance. Recently, several approaches (Guo et al., 2014a; Šuster, Titov, and van Noord, 2016) propose to learn multi-sense embeddings by exploiting the fact that different senses of the same word may be translated into different words in a foreign language (Dagan and Itai, 1994; Resnik and Yarowsky, 1999; Diab and Resnik, 2002; Ng, Wang, and Chan, 2003). ","The berkeley framenet project | Unsupervised translation sense clustering | Tailoring continuous word representations for dependency parsing | Breaking sticks and ambiguities with adaptive skip-gram | Findings of the 2011 workshop on statistical machine translation | Trans-gram, fast cross-lingual wordembeddings | Word sense disambiguation using a second language monolingual corpus | An unsupervised method for word sense tagging using parallel corpora | A simple, fast, and effective reparameterization of ibm model | MultiUN: A multilingual corpus from united nation documents | Retrofitting sense-specific word vectors using parallel text | Improving vector space word representations using multilingual correlation | Retrofitting word vectors to semantic lexicons | Problems with evaluation of word embeddings using word similarity tasks | A bayesian analysis of some nonparametric problems | Learning sense-specific word embeddings by exploiting bilingual resources | Revisiting embedding features for simple semi-supervised learning | A representation learning framework for multisource transfer parsing | Multilingual Distributed Representations without Word Alignment | Stochastic variational inference | Improving word representations via global context and multiple word prototypes | Comparing partitions | Ontologically grounded multi-sense representation learning for semantic vector space models | Learning to represent words in context with multilingual supervision | I don’t believe in word senses | Europarl: A parallel corpus for statistical machine translation | Do multi-sense embeddings improve natural language understanding | Topical word embeddings | Learning context-sensitive word embeddings with neural tensor skipgram model | Bilingual word representations with monolingual quality in mind | Linguistic regularities in continuous space word representations | Wordnet: a lexical database for english | A state of the art of word sense induction: A way towards word sense disambiguation for under-resourced languages | Word sense disambiguation: A survey | Efficient non-parametric estimation of multiple embeddings per word in vector space | Exploiting parallel texts for word sense disambiguation: An empirical study | Learning word representation considering proximity and ambiguity | Multi-prototype vector-space models of word meaning | Distinguishing systems and distinguishing senses: New evaluation methods for word sense disambiguation | A constructive definition of dirichlet priors | A conditional random field word segmenter for sighan bakeoff 2005 | Word representations: a simple and general method for semisupervised learning | Cross-lingual models of word embeddings: An empirical comparison | Bilingual learning of multi-sense embeddings with discrete autoencoders | Sense-aaware semantic analysis: A multi-prototype word representation model using wikipedia | Unsupervised word sense disambiguation rivaling supervised methods",iclr,010
641.pdf.json,TWO METHODS FOR WILD VARIATIONAL INFERENCE,"Probabilistic modeling provides a principled approach for reasoning under uncertainty, and has been increasingly dominant in modern machine learning where highly complex, structured probabilistic models are often the essential components for solving complex problems with increasingly larger datasets. A key challenge, however, is to develop computationally efficient Bayesian inference methods to approximate, or draw samples from the posterior distributions. Variational inference (VI) provides a powerful tool for scaling Bayesian inference to complex models and big data. The basic idea of VI is to approximate the true distribution with a simpler distribution by minimizing the KL divergence, transforming the inference problem into an optimization problem, which is often then solved efficiently using stochastic optimization techniques (e.g., Hoffman et al., 2013; Kingma & Welling, 2013). However, the practical design and application of VI are still largely restricted by the requirement of using simple approximation families, as we explain in the sequel. Let p(z) be a distribution of interest, such as the posterior distribution in Bayesian inference. VI approximates p(z) with a simpler distribution q∗(z) found in a set Q = {qη(z)} of distributions indexed by parameter η by minimizing the KL divergence objective: min η { KL(qη || p) ≡ Ez∼qη [log(qη(z)/p(z))] } , (1) where we can get exact result p = q∗ if Q is chosen to be broad enough to actually include p. In practice, however, Q should be chosen carefully to make the optimization in (1) computationally tractable; this casts two constraints on Q: 1. A minimum requirement is that we should be able to sample from qη efficiently, which allows us to make estimates and predictions based on qη in placement of the more intractable p. The samples from qη can also be used to approximate the expectation Eq[·] in (1) during optimization. This means that there should exist some computable function f(η; ξ), called the inference netw",An auxiliary variational method | A tutorial on adaptive mcmc | Learning to learn by gradient descent by gradient descent | Stein’s method and poisson process convergence | A kernel test of goodness of fit | Nonparametric variational inference | Amortized inference in probabilistic reasoning | Measuring sample quality with Stein’s method | Deep residual learning for image recognition | Training products of experts by minimizing contrastive divergence | The no-u-turn sampler: adaptively setting path lengths in hamiltonian monte carlo | Stochastic variational inference | Auto-encoding variational Bayes | Stein variational gradient descent: A general purpose bayesian inference algorithm | A kernelized Stein discrepancy for goodness-of-fit tests | Early stopping is nonparametric variational inference | A variational analysis of stochastic gradient algorithms | Control functionals for Monte Carlo integration | Inference networks for sequential monte carlo in graphical models | Operator variational inference | Black box variational inference | Hierarchical variational models | Variational inference with normalizing flows | Variational inference with normalizing flows | Examples of adaptive mcmc | Markov chain monte carlo and variational inference: Bridging the gap | Variational gaussian process | Learning to draw samples: With application to amortized mle for generative adversarial learning | Bayesian learning via stochastic gradient Langevin dynamics,iclr,010
642.pdf.json,DEEP NEURAL NETWORKS,"Recently, deep neural networks (DNNs) have yielded state-of-the-art performance on a wide array of AI tasks, including image classification Krizhevsky et al. (2012), speech recognition Hannun et al. (2014), and language understanding Sutskever et al. (2014). In addition to algorithmic innovations Nair & Hinton (2010); Srivastava et al. (2014); Taigman et al. (2014), a key driver behind these successes are advances in computing infrastructure that enable large-scale deep learning—the training and inference of large DNN models on massive datasets Dean et al. (2012); Farabet et al. (2013). Indeed, highly efficient GPU implementations of DNNs played a key role in the first breakthrough of deep learning for image classification Krizhevsky et al. (2012). Given the ever growing amount of data available for indexing, analysis, and training, and the increasing prevalence of everlarger DNNs as key building blocks for AI applications, it is critical to design computing platforms to support faster, more resource-efficient DNN computation. A set of core design decisions are common to the design of these infrastructures. One such critical choice is the numerical representation and precision used in the implementation of underlying storage and computation. Several recent works have investigated the numerical representation for DNNs Cavigelli et al. (2015); Chen et al. (2014); Du et al. (2014); Muller & Indiveri (2015). One recent work found that substantially lower precision can be used for training when the correct numerical rounding method is employed Gupta et al. (2015). Their work resulted in the design of a very energy-efficient DNN platform. This work and other previous numerical representation studies for DNNs have either limited themselves to a small subset of the customized precision design space or drew conclusions using only small neural networks. For example, the work from Gupta et al. 2015 evaluates 16-bit fixed-point and wider computational precision on LeNet-5 LeCun",Origami: A convolutional network accelerator | Compressing neural networks with the hashing trick | Dadiannao: A machine-learning supercomputer | A ultra-low-energy convolution engine for fast brain-inspired vision in multicore clusters | Low precision arithmetic for deep learning | Large scale distributed deep networks | Efficient implementation of stdp rules on spinnaker neuromorphic hardware | Leveraging the error resilience of machine-learning applications for designing highly energy efficient accelerators | Learning hierarchical features for scene labeling | PerforatedCNNs: Acceleration through elimination of redundant convolutions | Deep learning with limited numerical precision | Deepspeech: Scaling up end-to-end speech recognition | Caffe: Convolutional architecture for fast feature embedding | Learning multiple layers of features from tiny images | Imagenet classification with deep convolutional neural networks | Gradient-based learning applied to document recognition | Rounding methods for neural networks with low resolution synaptic weights | Rectified linear units improve restricted boltzmann machines | Very deep convolutional networks for large-scale image recognition | Dropout: A simple way to prevent neural networks from overfitting | Sequence to sequence learning with neural networks | Going deeper with convolutions | Deepface: Closing the gap to human-level performance in face verification,iclr,010
643.pdf.json,NEUROGENESIS-INSPIRED DICTIONARY LEARNING: ONLINE MODEL ADAPTION IN A CHANGING WORLD,"The ability to adapt to a changing environment is essential for successful functioning in both natural and artificial intelligent systems. In human brains, adaptation is achieved via neuroplasticity, which takes different forms, including synaptic plasticity, i.e. changing connectivity strength among neurons, and neurogenesis, i.e. the birth and maturation of new neurons (accompanied with the death of some new or old neurons). Particularly, adult neurogenesis (Kempermann, 2006) (i.e., neurogenesis in the adult brain) in the dentate gyrus of the hippocampus is associated with improved cognitive functions such as pattern separation (Sahay et al., 2011), and is often implicated as a “candidate mechanism for the specific dynamic and flexible aspects of learning” (Stuchlik, 2014). In the machine-learning context, synaptic plasticity is analogous to parameter tuning (e.g., learning neural net weights), while neurogenesis can be viewed as an online model selection via addition (and deletion) of hidden units in specific hidden-variable models used for representation learning (where hidden variables represent extracted features), from linear and nonlinear component analysis methods such as PCA, ICA, sparse coding (dictionary learning), nonlinear autoencoders, to deep neural nets and general hidden-factor probabilistic models. However, optimal model selection in large-scale hidden-variable models (e.g., adjusting the number of layers, hidden units, and their connectivity), is intractable due to enormous search space size. Growing a model gradually can be a more feasible alternative; after all, every real brain’s “architecture” development process starts with a single cell. Furthermore, the process of adapting the model’s architecture to dynamically changing environments is necessary for achieving a lifelong, continual learning. Finally, an online approach to dynamically expanding and contracting model’s architecture can serve as a potentially more effective alternative to the","K-svd: An algorithm for designing overcomplete dictionaries for sparse representation | Do deep nets really need to be deep? In Advances in neural information processing | Group sparse coding | Neurogenic deep learning | Neurogenesis deep learning | The cascade-correlation learning architecture | Sparse overcomplete word vector representations | Distilling the knowledge in a neural network | Proximal methods for hierarchical sparse coding | Adult neurogenesis: stem cells and neuronal development in the adult brain | Dictionary learning algorithms for sparse representation | Efficient sparse coding algorithms | Online dictionary learning for sparse coding | Online learning for matrix factorization and sparse coding | Sparse coding with an overcomplete basis set: A strategy employed by v1 | An mdl framework for sparse coding and dictionary learning | Adult neurogenesis as efficient sparsification. In Society for Neuroscience meeting (poster presentation) | Increasing adult hippocampal neurogenesis is sufficient to improve pattern separation | Dropout: a simple way to prevent neural networks from overfitting | Dynamic learning and memory, synaptic plasticity and neurogenesis: an update | Sparse word embeddings using l1 regularized online learning | Regression shrinkage and selection via the lasso | Learning word representations with hierarchical sparse coding | Model selection and estimation in regression with grouped variables",iclr,010
644.pdf.json,DIVERSE BEAM SEARCH: DECODING DIVERSE SOLUTIONS FROM NEURAL SEQUENCE MODELS,"In the last few years, Recurrent Neural Networks (RNNs), Long Short-Term Memory networks (LSTMs) or more generally, neural sequence models have become the standard choice for modeling time-series data for a wide range of applications including speech recognition (Graves et al., 2013), machine translation (Bahdanau et al., 2014), conversation modeling (Vinyals & Le, 2015), image and video captioning (Vinyals et al., 2015; Venugopalan et al., 2015), and visual question answering (Antol et al., 2015). RNN based sequence generation architectures model the conditional probability, Pr(y|x) of an output sequence y = (y1, . . . , yT ) given an input x (possibly also a sequence); where the output tokens yt are from a finite vocabulary, V . Inference in RNNs. Maximum a Posteriori (MAP) inference for RNNs is the task of finding the most likely output sequence given the input. Since the number of possible sequences grows as |V|T , exact inference is NP-hard – so, approximate inference algorithms like beam search (BS) are commonly employed. BS is a heuristic graph-search algorithm that maintains the B top-scoring partial sequences expanded in a greedy left-to-right fashion. Fig. 1 shows a sample BS search tree. Lack of Diversity in BS. Despite the widespread usage of BS, it has long been understood that solutions decoded by BS are generic and lacking in diversity (Finkel et al., 2006; Gimpel et al., a train steam black locomotive is traveling on engine train train coming down a the train engine down track train tracks traveling is the with near track down through tracks a with train tracks a in a tracks forest lush a an train steam an the is engine old train a an coming train train steam train black traveling is engine locomotive train and down through train is is white train a is traveling coming on tracks forest down through the a Beam Search Diverse Beam Search A steam engine train travelling down train tracks. A steam engine train travelling down tracks. A steam engine train","Spice: Semantic propositional image caption evaluation | VQA: Visual question answering | Neural machine translation by jointly learning to align and translate | Diverse M-Best Solutions in Markov Random Fields | Chameleons in imagined conversations: A new approach to understanding coordination of linguistic style in dialogs | Visual storytelling | Solving the problem of cascading errors: Approximate bayesian inference for linguistic annotation pipelines | A systematic exploration of diversity in machine translation | Speech recognition with deep recurrent neural networks | How hard can it be? Estimating the difficulty of visual search in an image | Smart reply: Automated reeponse suggestion for email | Deep visual-semantic alignments for generating image descriptions | Inferring m-best diverse labelings in a single one | Mutual information and diverse decoding improve neural machine translation | A diversity-promoting objective function for neural conversation models | How NOT to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response | Effective approaches to attentionbased neural machine translation | Distributed representations of words and phrases and their compositionality | Generating natural questions about an image | Bleu: a method for automatic evaluation of machine translation | N-best maximal decoders for part models | Submodular meets structured: Finding diverse subsets in exponentially-large structured item sets | Cider: Consensus-based image description evaluation | Sequence to sequence-video to text | A neural conversational model | Show and tell: A neural image caption generator | Google’s neural machine translation system: Bridging the gap between human and machine translation | METEOR Oracle accuracy on COCO and PASCAL-50S datasets for image captioning at B = 20 | Modified SPICE evaluation. To measure both the quality and the diversity of the generated captions, we compute SPICE-score by comparing the graph union of all the generated hypotheses with | HUMAN STUDIES For image-captioning, we conduct a human preference study between BS and DBS captions",iclr,010
645.pdf.json,DEEP GENERALIZED CANONICAL CORRELATION ANALYSIS,"Multiview representation learning refers to settings where one has access to many “views” of data, at train time. Views often correspond to different modalities or independent information about examples: a scene represented as a series of audio and image frames, a social media user characterized by the messages they post and who they friend, or a speech utterance and the configuration of the speaker’s tongue. Multiview techniques learn a representation of data that captures the sources of variation common to all views. Multiview representation techniques are attractive for intuitive reasons. A representation that is able to explain many views of the data is more likely to capture meaningful variation than a representation that is a good fit for only one of the views. They are also attractive for the theoretical reasons. For example, Anandkumar et al. (2014) show that certain classes of latent variable models, such as Hidden Markov Models, Gaussian Mixture Models, and Latent Dirichlet Allocation models, can be optimally learned with multiview spectral techniques. Representations learned from many views will generalize better than one, since the learned representations are forced to accurately capture variation in all views at the same time (Sridharan & Kakade, 2008) – each view acts as a regularizer, constraining the possible representations that can be learned. These methods are often based on canonical correlation analysis (CCA), a classical statisical technique proposed by Hotelling (1936). In spite of encouraging theoretical guarantees, multiview learning techniques cannot freely model nonlinear relationships between arbitrarily many views. Either they are able to model variation across many views, but can only learn linear mappings to the shared space (Horst, 1961), or they simply cannot be applied to data with more than two views using existing techniques based on kernel CCA (Hardoon et al., 2004) and deep CCA (Andrew et al., 2013). Here we present Deep General",Tensor decompositions for learning latent variable models | Deep canonical correlation analysis | Multi-view learning with supervision for transformed bottleneck features | Learning multiview embeddings of twitter users | Nearest neighbor pattern classification | Canonical correlation analysis: An overview with application to learning methods | Generalized canonical correlations and their applications to experimental data | Relations between two sets of variates | Canonical analysis of several sets of variables | Adam: A method for stochastic optimization | Co-regularized multi-view spectral clustering | Multimodal similarity-preserving hashing | URL http://www2 | Bridge correlational neural networks for multilingual multimodal representation learning | Generalized multiview analysis: A discriminative latent space | An information theoretic framework for multi-view learning | Unsupervised learning of acoustic features via deep canonical correlation analysis | On deep multi-view representation learning | Stochastic optimization for deep cca via nonlinear orthogonal iterations | X-ray microbeam speech production database users handbook | Multi-View Signal Processing and Learning on Graphs,iclr,010
646.pdf.json,A CONTEXT-AWARE ATTENTION NETWORK FOR INTERACTIVE QUESTION ANSWERING,"The ultimate goal of Question Answering (QA) research is to build intelligent systems capable of naturally communicating with humans, which poses a major challenge for natural language processing and machine learning. Inspired by recent success of sequence-to-sequence models with an encoder-decoder framework (Sutskever et al., 2014; Cho et al., 2014), researchers have attempted to apply variants of such models with explicit memory and attention to QA tasks, aiming to move a step further from machine learning to machine reasoning (Sainbayar et al., 2015; Kumar et al., 2016; Xiong et al., 2016). Similarly, all these models employ encoders to map statements and questions to fixed-length feature vectors, and a decoder to generate outputs. Empowered by the adoption of memory and attention, they have achieved remarkable success on several challenging datasets, including the recently acclaimed Facebook bAbI dataset. However, previous models suffer from the following important limitations. First, they fail to model context-dependent meaning of words. Different words may have different meanings in different contexts, which increases the difficulty of extracting the essential semantic logic flow of each sentence in different paragraphs. Second, many existing models only work in ideal QA settings and fail to address the uncertain situations under which models require additional user input to gather complete information to answer a given question. As shown in Table 1, the example on the left is an ideal QA problem. We can clearly understand what the question is and then locate the relevant sentences to generate the answer. However, it is hard to answer the question in the right example, because there are two types of bedrooms mentioned in the story and we do not know which bedroom the user refers to. These scenarios with incomplete information naturally appear in human conversations, and thus, effectively handling them is a key capability of intelligent QA models. To address th","Neural machine translation by jointly learning to align and translate | Meteor: An automatic metric for mt evaluation with improved correlation with human judgments | Learning long-term dependencies with gradient descent is difficult | Learning end-to-end goal-oriented | Learning phrase representations using RNN encoder-decoder for statistical machine translation | Open question answering over curated and extracted knowledge bases | Character-level question answering with attention | Teaching machines to read and comprehend | Long short-term memory | Adam: A method for stochastic optimization | Ask me anything: Dynamic memory networks for natural language processing | Hierarchical question-image co-attention for visual question answering | Effective approaches to attentionbased neural machine translation | Recurrent models of visual attention | Bleu: A method for automatic evaluation of machine translation | End-to-end memory networks | When a knowledge base is not enough: Question answering over knowledge bases with external text data | Sequence to sequence learning with neural networks | Dialog-based language learning | Towards ai-complete question answering: A set of prerequisite toy | Ask me anything: Free-form visual question answering based on knowledge from external sources | Dynamic memory networks for visual and textual question answering | Show, attend and tell: Neural image caption generation with visual attention | Stacked attention networks for image question answering | Hierarchical attention networks for document classification | Recurrent neural network regularization",iclr,010
647.pdf.json,,"Inverse Problems are a broad class of problems which can be encountered in all scientific disciplines, from the natural sciences to engineering. The task in inverse problems is to reconstruct a signal from observations that are subject to a known (or inferred) corruption process known as the forward model. A typical example of an inverse problem is the linear measurement problem y = Ax + n, (1) where x is the signal of interest, A is an m × d corruption matrix, n is an additive noise vector, and y is the actual measurement. If A is a wide matrix such that m d, this problem is typically ill-posed. Many signal reconstruction problems can be phrased in terms of the linear measurement problem such as image denoising, super-resolution, deconvolution and so on. The general form of A typically defines the problem class. If A is an identity matrix the problem is a denoising problem, while in tomography A represents a Fourier transform and a consecutive sub-sampling of the Fourier coefficients. Inverse problems are often formulated as an optimization problem of the form min x d(y,Ax) + λR(x), (2) where d(y,Ax) is the data fidelity term that enforces x to satisfy the observations y, and R(x) is a regularization term which restricts the solution to comply with a predefined model over x. The difficulties that arise in this framework are two-fold: (1) it is difficult to choose R(x) such that it is an appropriate model for complex signals such as natural images, and (2) even under a well chosen R(x) the optimization procedure might become difficult. Compressed sensing approaches give up on a versatileR(x) in order to define a convex optimization procedure. The idea is that the signal x has a sparse representation in some basis Ψ such that x = Ψu and that the optimization problem can be rephrased as min u d(y,AΨu) + λ ‖u‖1 , (3) where ‖·‖1 is the sparsity inducing L1-norm (Donoho, 2006a). Under certain classes of d(y,AΨu) such as quadratic errors the optimization problem becomes c",K-SVD: An algorithm for designing overcomplete dictionaries for sparse representation | Learning to learn by gradient descent by gradient descent. jun 2016 | Image denoising: Can plain neural networks compete with BM3D | Learning how to combine internal and external denoising methods | Stable signal recovery from incomplete and inaccurate measurements | Revisiting Loss-Specific Training of Filter-Based MRFs for Image Restoration | Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling | Image Denoising by Sparse 3-D TransformDomain Collaborative Filtering | Color Image Denoising via Sparse 3D Collaborative Filtering with Grouping Constraint in Luminance-Chrominance Space | Learning a deep convolutional network for image super-resolution | For most large underdetermined systems of linear equations the minimal L1-norm solution is also the sparsest solution | Compressed sensing | Image Denoising Via Sparse and Redundant Representations Over Learned Dictionaries | Gradient Projection for Sparse Reconstruction: Application to Compressed Sensing and Other Inverse Problems | Learning Fast Approximations of Sparse Coding | Towards Conceptual Compression | Single image super-resolution from transformed self-exemplars | Auto-Encoding Variational Bayes | Exploiting Inference for Approximate Parameter Learning in Discriminative Fields: An Empirical Study | Non-local sparse models for image restoration | A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics | Convex variational Bayesian inference for large scale generalized linear models | Stochastic backpropagation and approximate inference in deep generative models | Fields of experts: A framework for learning image priors | Cascades of regression tree fields for image restoration | A+: Adjusted anchored neighborhood regression for fast super-resolution | Extracting and composing robust features with denoising autoencoders | Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion | Estimating the wrong graphical model: Benefits in the computation-limited setting | From learning models of natural image patches to whole image restoration,iclr,010
648.pdf.json,CONTEXT-CONDITIONAL GENERATIVE ADVERSARIAL NETWORKS,"Deep neural networks have yielded dramatic performance gains in recent years on tasks such as object classification (Krizhevsky et al., 2012), text classification (Zhang et al., 2015) and machine translation (Sutskever et al., 2014; Bahdanau et al., 2015). These successes are heavily dependent on large training sets of manually annotated data. In many settings however, such large collections of labels may not be readily available, motivating the need for methods that can learn from data where labels are rare. We propose a method for harnessing unlabeled image data based on image in-painting. A generative model is trained to generate pixels within a missing hole, based on the context provided by surrounding parts of the image. These in-painted images are then used in an adversarial setting (Goodfellow et al., 2014) to train a large discriminator model whose task is to determine if the image was real (from the unlabeled training set) or fake (an in-painted image). The realistic looking fake examples provided by the generative model cause the discriminator to learn features that generalize to the related task of classifying objects. Thus adversarial training for the in-painting task can be used to regularize large discriminative models during supervised training on a handful of labeled images.","Neural machine translation by jointly learning to align and translate | Natural language processing (almost) from scratch | Deep generative image models using a laplacian pyramid of adversarial networks | Unsupervised visual representation learning by context prediction | Discriminative unsupervised feature learning with convolutional neural networks | Learning to generate chairs, tables and cars with convolutional networks | Training generative neural networks via maximum mean discrepancy optimization | Generative adversarial nets | Draw: A recurrent neural network for image generation | A fast learning algorithm for deep belief nets | Adam: A method for stochastic optimization | Auto-encoding variational bayes | Semi-supervised learning with deep generative models | Skip-thought vectors | Imagenet classification with deep convolutional neural networks | Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks | Generative moment matching networks | Generating images from captions with attention | Deep multi-scale video prediction beyond mean square error | Distributed representations of words and phrases and their compositionality | Conditional generative adversarial nets | Unsupervised learning of visual representations by solving jigsaw puzzles | Context encoders: Feature learning by inpainting | Unsupervised representation learning with deep convolutional generative adversarial networks | Video (language) modeling: a baseline for generative models of natural videos | Semi-supervised learning with ladder network | Learning deep generative models | Improved techniques for training gans | Very deep convolutional networks for large-scale image recognition | Deep unsupervised learning using nonequilibrium thermodynamics | Unsupervised and semi-supervised learning with categorical generative adversarial networks | Sequence to sequence learning with neural networks | Multi-task bayesian optimization | Generative image modeling using spatial lstms | Pixel recurrent neural networks | Extracting and composing robust features with denoising autoencoders | Unsupervised learning of visual representations using videos | Character-level convolutional networks for text classification | Stacked what-where auto-encoders | Learning with local and global consistency | Semi-supervised learning literature",iclr,010
649.pdf.json,,,A study on similarity and relatedness using distributional and wordnet-based approaches | Tailoring continuous word representations for dependency parsing | A neural probabilistic language model | Distributional semantics in technicolor | Intrinsic evaluation of word vectors fails to predict extrinsic performance | A unified architecture for natural language processing: Deep neural networks with multitask learning | Natural language processing (almost) from scratch | Semi-supervised sequence learning | Placing search in context: The concept revisited | Analogy-based detection of morphological and semantic relations with word embeddings: What works and what doesnt | Simlex-999: Evaluating semantic models with (genuine) similarity estimation | Bidirectional lstm-crf models for sequence tagging | Convolutional neural networks for sentence classification | Skip-thought vectors | Linguistic regularities in sparse and explicit word representations | Neural word embedding as implicit matrix factorization | Dependency-based word embeddings | Improving distributional similarity with lessons learned from word embeddings | Two/too simple adaptations of word2vec for syntax problems | Issues in evaluating semantic spaces using word analogies | Better word representations with recursive neural networks for morphology | End-to-end sequence labeling via bi-directional lstm-cnns-crf | Learning word vectors for sentiment analysis | The Stanford CoreNLP natural language processing toolkit | The role of context types and dimensionality in learning word embeddings | Efficient estimation of word representations in vector space | Distributed representations of words and phrases and their compositionality | Linguistic regularities in continuous space word representations | Three new graphical models for statistical language modelling | Dependency tree-based sentiment classification using crfs with hidden variables | A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts | Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales | Glove: Global vectors for word representation | A word at a time: computing word relatedness using temporal semantic analysis | Evaluation methods for unsupervised word embeddings | Continuous space language models | Parsing natural scenes and natural language with recursive neural networks | Recursive deep models for semantic compositionality over a sentiment treebank | A unified learning framework of skip-grams and global vectors | Is ”universal syntax” universally useful for learning distributed word representations | Learning syntactic categories using paradigmatic representations of word context | Learning word meta-embeddings | Using wiktionary for computing semantic relatedness,iclr,010
651.pdf.json,,"Early artificial neurons utilized binary threshold units (Hopfield, 1982; McCulloch & Pitts, 1943). These hard binary decisions are smoothed with sigmoid activations, enabling a neuron to have a “firing rate” interpretation and to train with backpropagation. But as networks became deeper, training with sigmoid activations proved less effective than the non-smooth, less-probabilistic ReLU (Nair & Hinton, 2010) which makes hard gating decisions based upon an input’s sign. Despite having less of a statistical motivation, the ReLU remains a competitive engineering solution which often enables faster and better convergence than sigmoids. Building on the successes of ReLUs, a recent modification called ELUs (Clevert et al., 2016) allows a ReLU-like nonlinearity to output negative values which sometimes increases training speed. In all, the activation choice has remained a necessary architecture decision for neural networks lest the network be a deep linear classifier. Deep nonlinear classifiers can fit their data so well that network designers are often faced with the choice of including stochastic regularizer like adding noise to hidden layers or applying dropout (Srivastava et al., 2014), and this choice remains separate from the activation function. Some stochastic regularizers can make the network behave like an ensemble of networks, a pseudoensemble (Bachman et al., 2014), and can lead to marked accuracy increases. For example, the stochastic regularizer dropout creates a pseudoensemble by randomly altering some activation decisions through zero multiplication. Nonlinearities and dropout thus determine a neuron’s output together, yet the two innovations have remained distinct. More, neither subsumed the other because popular stochastic regularizers act irrespectively of the input and nonlinearities are aided by such regularizers. In this work, we bridge the gap between stochastic regularizers and nonlinearities. To do this, we consider an adaptive stochastic regulari",Adaptive dropout for training deep neural networks | Learning with pseudo-ensembles | A simple approximation to the area under standard normal curve | Fast and accurate deep network learning by exponential linear units (ELUs) | Natural neural networks | Adjusting for dropout variance in batch normalization and weight initialization | Neural networks and physical systems with emergent collective computational abilities | Bayesian active learning for classification and preference learning | Adam: A Method for Stochastic Optimization | Learning Multiple Layers of Features from Tiny Images | Zoneout: Regularizing RNNs by randomly preserving hidden activations | SGDR: Stochastic gradient descent with restarts | Rectifier nonlinearities improve neural network acoustic models | A logical calculus of the ideas immanent in nervous activity | All you need is a good init | Acoustic modeling using deep belief networks | Rectified linear units improve restricted boltzmann machines | Improved part-of-speech tagging for online conversational text with word clusters | Weight normalization: A simple reparameterization to accelerate training of deep neural networks | Exact solutions to the nonlinear dynamics of learning in deep linear neural networks | Deep residual networks with exponential linear unit | Improving neural networks with dropout | Dropout: A simple way to prevent neural networks from overfitting | Fast dropout training | Wide residual networks,iclr,010
653.pdf.json,,"Stochastic gradient descent (SGD) and its parallel variants form the backbone of most popular deep learning applications. Consequently, there has been a significant interest in investigating their convergence properties. SGD has been shown to satisfy an asymptotic convergence rate of O(1/S) for convex objective functions [Nemirovski et al. (2009)] and an asymptotic convergence rate of O(1/ √ S) for general non-convex objective functions with mini-batch size 1 in [Ghadimi & Lan (2013)] or with arbitrary mini-batch sizes in [Dekel et al. (2012)]. Although SGD converges asymptotically with the same rate irrespective of mini-batch size, it has been reported that for large mini-batch sizes, often it is slower to converge - for example, see Wilson & Martinez (2003) for the detailed graphical illustrations therein for the effect of increasing batchsize or see Bottou (2010) for the comments on the tradeoffs of mini-batching. In this work, we are interested in using theoretical analysis for justifying such practical observations or comments. In particular, we show the following: • We consider general non-convex objective functions and show that prior to reaching asymptotic regime, SGD convergence could get much slower (inferred from the difference in the convergence rate guarantees from Theorem 2) with using higher mini-batch size, assuming a constant learning rate. Here, to evaluate the convergence rate guarantee we use the measure of average gradient norm since we are considering general non-convex objectives. As a consequence of slower convergence, the number of training samples required to attain a certain convergence guarantee (in terms of average gradient norm) increases as the mini-batch size increases. We build the analysis based on the framework in Ghadimi & Lan (2013). • Further, we investigate Asynchronous Stochastic Gradient Descent (ASGD) which is one of the most popular asynchronous variants of SGD [Dean et al. (2012); Li et al. (2014a); Chilimbi et al. (2014)]","Large-scale machine learning with stochastic gradient descent | Accelerating stochastic gradient descent via online learning to sample | Sample size selection in optimization methods for machine learning | Distributed asynchronous optimization of convolutional neural networks | Project adam: Building an efficient and scalable deep learning training system | Big batch sgd: Automated inference using adaptive batch sizes | Large scale distributed deep networks | Optimal distributed online prediction using mini-batches | Fast distributed coordinate descent for non-strongly convex losses | Stochastic first-and zeroth-order methods for nonconvex stochastic programming | A dual coordinate descent method for large-scale linear svm | Communication-efficient distributed dual coordinate ascent | Accelerating stochastic gradient descent using predictive variance reduction | Semi-stochastic coordinate descent | Scaling distributed machine learning with the parameter server | Efficient mini-batch training for stochastic optimization | Asynchronous parallel stochastic gradient for nonconvex optimization | Asynchronous stochastic coordinate descent: Parallelism and convergence properties | An asynchronous parallel stochastic coordinate descent algorithm | Asynchronous accelerated stochastic gradient descent | Stochastic gradient descent, weighted sampling, and the randomized kaczmarz algorithm | Robust stochastic approximation approach to stochastic programming | Efficiency of coordinate descent methods on huge-scale optimization problems | Introductory lectures on convex optimization: A basic course, volume 87 | Coordinate descent with arbitrary sampling i: Algorithms and complexity | Distributed coordinate descent method for learning with big data | Iteration complexity of randomized block-coordinate descent methods for minimizing a composite function | On parallelizability of stochastic gradient descent for speech dnns | Dropout: a simple way to prevent neural networks from overfitting | Barzilai-borwein step size for stochastic gradient descent | The general inefficiency of batch training for gradient descent learning | A proximal stochastic gradient method with progressive variance reduction",iclr,010
654.pdf.json,,"Although earlier research focused on generating data through Monte Carlo Markov chains (MCMCs), e.g. with various Boltzmann machines (Salakhutdinov & Hinton, 2009), most of the recent effort in designing deep generative models is based on single-step generation, e.g., with variational auto-encoders (VAEs) (Kingma & Welling, 2013; Rezende et al., 2014) and generative adversarial networks (GANs) (Goodfellow et al., 2014). However, generating a sample by going through a series of stochastic transformations that gradually improve the generated sample (or its latent representation) to make it more plausible could hold some advantages. A generative process can be seen as a mapping from simple noise variates (e.g., uniform, Gaussian) to samples from a very complicated distribution (maybe concentrated near a low-dimensional manifold) approximating the one which we are trying to learn from. If the data distribution is complex (e.g., the corresponding manifold is highly convoluted and non-linear), the generative process may involve a highly non-linear transformation which could be difficult to learn and optimize. Such highly non-linear transformations are probably best represented (and learned) by composing a large number of slightly non-linear transformations, either with a fixed-depth deep network, or with a variable depth recurrent computation, which is what the repeated application of a transition operator corresponds to.",Theano: A python framework for fast computation of mathematical expressions | What regularized auto-encoders learn from the data-generating distribution | Better mixing via deep representations | Deep generative stochastic networks trainable by backprop | Generalized denoising auto-encoders as generative models | Towards biologically plausible deep learning | Generative adversarial nets | Draw: A recurrent neural network for image generation | Adam: A method for stochastic optimization | Auto-encoding variational bayes | Learning multiple layers of features from tiny | Discriminative regularization for generative models | Deep learning face attributes in the wild | Unsupervised representation learning with deep convolutional generative adversarial networks | Stochastic backpropagation and approximate inference in deep generative models | Deep boltzmann machines | Deep unsupervised learning using nonequilibrium thermodynamics | Extracting and composing robust features with denoising autoencoders,iclr,010
655.pdf.json,DISTRIBUTED TRANSFER LEARNING FOR DEEP CONVOLUTIONAL NEURAL NETWORKS BY BASIC PROBABILITY ASSIGNMENT,"In supervised learning, many classification algorithms assume the same distribution for training and testing data. Consequently, change of distribution requires rebuilding of the statistical models which is not always practical because of the hardship of recollecting of training data or heavy learning process. One of the solutions is transfer learning that transfers the classification knowledge into a new domain Pan & Yang (2010). This aims at learning of highly-generalized models with different probability distributions across domains to learn novel domains without labeled data Wang & Schneider (2014) Zhang et al. (2013). Here, the main challenge is to reduce the shifts in data distribution between domains by algorithms that minimize the discriminant of the domains. It is worth mentioning that this could not get rid of domain-specific variations Long et al. (2016). Transfer learning for deep neural networks has been proved highly beneficial to boost their overall performance. Deep learning practices usually require huge amount of labeled data to learn powerful models. The transfer learning enables adaptation to a different source with small training samples. On the other hand, deep neural networks practically learn intermediate features. They could provide better transfer among domains because some of them generalize well among various domains of knowledge Glorot et al. (2011). These transferable features generally underlies several probability distributions Oquab et al. (2014) which reduce the cross-domain discrepancy Yosinski et al. (2014). The common observation among several deep architectures is that features learned in bottom layers are not that specific, but transiting towards top layers makes them tailored to a dataset or task. A recent study Yosinski et al. (2014) of the generality or specificity of deep layers for the sake of transfer learning reveals two difficulties which may affect the transfer of deep features. First, top layers get quite specialized ","Deep learning of representations for unsupervised and transfer learning | An improved method to construct basic probability assignment based on the confusion matrix for classification problem | Domain adaptation for large-scale sentiment classification: A deep learning approach | Learning multiple layers of features from tiny images | Gradient-based learning applied to document recognition | Deep transfer learning with joint adaptation networks | Reading digits in natural images with unsupervised feature learning | Learning and transferring mid-level image representations using convolutional neural networks | A survey on transfer learning | Encyclopedia of machine learning | Combination of evidence in Dempster-Shafer theory, volume 4015 | Overfeat: Integrated recognition, localization and detection using convolutional networks | VLFeat: An open and portable library of computer vision algorithms | Flexible transfer learning under support and model shift | Methods of combining multiple classifiers and their applications to handwriting recognition | How transferable are features in deep neural networks",iclr,010
656.pdf.json,,"Deep architectures builds generic and low-dimensional representations that lead to state-of-the-art results on tasks such as classification (He et al., 2015), games (Silver et al., 2016), or generative models (Radford et al., 2015). These architectures are designed as cascades of non-linear modules that are fully learned. This paper addresses several questions: is it necessary to learn each module? Can a scattering networks replace the first layers? What are the potential benefits? Hybrid architectures composed of a supervised representation learned on top of an unsupervised representation (Philbin et al., 2007) have been progressively abandoned for the end-to-end training approach (LeCun et al., 2010). Understanding the nature of the cascade of deep operators is difficult (Szegedy et al., 2013), since they are learned via back-propagation, and not layer-wise. However, the learned features appear to be transferable to other datasets and helpful for classification(Zeiler & Fergus, 2014), which implies that the learned representations have captured generic properties for image classification tasks. Scattering representations (Mallat, 2012) are predefined and generic representations which only require the learning of a few hyper parameters. They consist of a cascade of wavelet transforms and modulus nonlinearities are have proven to be successful in classification tasks such as textures (Bruna & Mallat, 2013b; Sifre & Mallat, 2013), small digits (Bruna & Mallat, 2013b), sounds (Andén & Mallat, 2014) or complex image datasets with unsupervised representations (Oyallon & Mallat, 2015). Nevertheless, these representations do not adapt to the specific bias of each dataset and there is a huge performance gap between supervised and unsupervised representations(Oyallon & Mallat, 2015). A convnet is typically a cascade of convolutional layers and nonlinearities, followed by a final average pooling or a sequence of fully connected layers. They lead to state of the art results ","Deep scattering spectrum | Generalized analytic signals in image processing: comparison, theory and applications | Audio texture synthesis with scattering moments | Invariant scattering convolution networks | Learning stable group invariant representations with convolutional networks | Unregistered multiview mammogram analysis with pre-trained deep learning models | Approximation by superpositions of a sigmoidal function | Discriminative unsupervised feature learning with convolutional neural networks | cleverhans v0. 1: an adversarial machine learning library | Explaining and harnessing adversarial examples | Deep residual learning for image recognition | Unsupervised learning of discriminative attributes and visual representations | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | Convolutional networks and applications in vision | Group invariant scattering | Understanding deep convolutional networks | Deepfool: a simple and accurate method to fool deep neural networks | Deep roto-translation scattering for object classification | Fisher vectors meet neural networks: A hybrid classification architecture | Object retrieval with large vocabularies and fast spatial matching | Unsupervised representation learning with deep convolutional generative adversarial networks | Improved techniques for training gans | Rotation, scaling and deformation invariant scattering for texture discrimination | Mastering the game of go with deep neural networks and tree | Very deep convolutional networks for large-scale image recognition | Striving for simplicity: The all convolutional net | Training very deep networks | Multi-task bayesian optimization. In Advances in neural information processing | Intriguing properties of neural networks | Wide residual networks | Visualizing and understanding convolutional networks",iclr,010
657.pdf.json,,"Text classification is an important problem in Natural Language Processing (NLP). Real world usecases include spam filtering or e-mail categorization. It is a core component in more complex systems such as search and ranking. Recently, deep learning techniques based on neural networks have achieved state of the art results in various NLP applications. One of the main successes of deep learning is due to the effectiveness of recurrent networks for language modeling and their application to speech recognition and machine translation (Mikolov, 2012). However, in other cases including several text classification problems, it has been shown that deep networks do not convincingly beat the prior state of the art techniques (Wang & Manning, 2012; Joulin et al., 2016). In spite of being (typically) orders of magnitude slower to train than traditional techniques based on n-grams, neural networks are often regarded as a promising alternative due to compact model sizes, in particular for character based models. This is important for applications that need to run on systems with limited memory such as smartphones. This paper specifically addresses the compromise between classification accuracy and the model size. We extend our previous work implemented in the fastText library1. It is based on n-gram features, dimensionality reduction, and a fast approximation of the softmax classifier (Joulin et al., 2016). We show that a few key ingredients, namely feature pruning, quantization, hashing, and retraining, allow us to produce text classification models with tiny size, often less than 100kB when trained on several popular datasets, without noticeably sacrificing accuracy or speed. We plan to publish the code and scripts required to reproduce our results as an extension of the fastText library, thereby providing strong reproducible baselines for text classifiers that optimize the compromise between the model size and accuracy. We hope that this will help the engineering community to","Streaming submodular maximization: Massive data summarization on the fly | Submodular secretary problem and extensions. In Approximation, Randomization, and Combinatorial Optimization | Similarity estimation techniques from rounding algorithms | Strategies for training large vocabulary neural language models | Max-cover in map-reduce | Binarized neural networks: Training neural networks with weights and activations constrained to +1 or -1 | Locality-sensitive hashing scheme based on pstable distributions | Indexing by latent semantic analysis | Predicting parameters in deep learning | A threshold of ln n for approximating set cover | Optimized product quantization for approximate nearest neighbor search | Iterative quantization: A procrustean approach to learning binary codes | Compressing deep convolutional networks using vector quantization | Efficient softmax approximation for gpus | Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding | Hamming embedding and weak geometric consistency for large scale image search | Product quantization for nearest neighbor search | Text categorization with support vector machines: Learning with many relevant features | Bag of tricks for efficient text classification | Optimal brain damage | Neural networks with few multiplications | A comparison of event models for naive bayes text classification | The group lasso for logistic regression | Statistical language models based on neural networks | Subword language modeling with neural networks | On symmetric and asymmetric lshs for inner product search | Opinion mining and sentiment analysis | How should we evaluate supervised hashing | High-dimensional signature compression for large-scale image classification | Asymmetric LSH for sublinear time maximum inner product search | Entropy-based pruning of backoff language models | Randomized language models via perfect hash functions | Yfcc100m: The new data in multimedia research | Hashing for similarity search: A survey | Learning to hash for indexing big data - A survey | Baselines and bigrams: Simple, good sentiment and topic classification | Feature hashing for large scale multitask learning | Spectral hashing | Efficient character-level document classification by combining convolution and recurrent layers | Character-level convolutional networks for text classification",iclr,010
658.pdf.json,,"On a high level, the generative approach to machine learning can be described as follows: Given a set of samples D, drawn (usually i.i.d.) from an unknown distribution p∗ over random variables (RVs) X, recover p∗ from D. To a certain extent, generative learning (GL) can be seen as the “kingclass” paradigm in machine learning. It is well known that an optimal predictor – given an additional loss function – can just be derived from p∗. For example, assuming that Y is a class variable and X are observed features, the classifier with minimal expected 0/1-loss is given by argmaxy p ∗(y,X). It is therefore not surprising that GL and representation learning (RL) (Bengio et al., 2012) are highly related, as both aim at “formally understanding” data. GL can be described as a “black-box” approach, since we are usually interested in the capability of some model pθ to capture the underlying distribution p∗. In RL, however, one may be interested in interpreting the “inner parts” of pθ as abstract features of the original raw data. Both perspectives can be seen in the seminal RL approaches (Hinton & Salakhutdinov, 2006; Bengio et al., 2006), as the activations of generatively trained models are employed as data representations for initializing deep architectures. As another simple example, consider a Bayes classifier, which estimates the joint distribution p(Y,X) by using the class-prior p(Y ) and class-conditionals p(X |Y ). In a purist GL view, we estimate p(Y ) and p(X |Y ) to compute p(Y,X) = p(X |Y ) p(Y ) ∝ p(Y |X). In an RL approach, however, we would recognize that the parts of our model p(X |Y ) (or also p(Y |X)) can be interpreted as a kind of soft one-hot encoding for Y , and would use them as features in a discriminative approach. The same argument holds for an unsupervised learning scenario, i.e. when Y is unobserved: we would deal with latent mixture models for which p(X |Y ) are the mixture components. In summary, we note that any generative model – depending on it","Learning the structure of Sum-Product Networks via an SVD-based algorithm | Label-embedding for attribute-based classification | Sum product networks for activity | An ensemble of bayesian networks for multilabel classification | Greedy layer-wise training of deep networks | Unsupervised Feature Learning and Deep Learning: A review and new perspectives | Sparse local embeddings for extreme multi-label classification | LAIM discretization for multi-label data | Language modeling with SumProduct Networks | Modeling and Reasoning with Bayesian Networks | On label dependence and loss minimization in multi-label classification | Learning the Architecture of Sum-Product Networks Using Clustering on Varibles | Multi-label classification with cutset networks | Visualizing Higher-Layer Features of a Deep Network | Training structural svms when exact inference is intractable | Discriminative Learning of Sum-Product Networks | Learning the Structure of Sum-Product Networks | MADE: masked autoencoder for distribution estimation | Reducing the dimensionality of data with neural networks | Transductive multilabel learning via label set propagation | Classification Using Discriminative Restricted Boltzmann Machines | The Neural Autoregressive Distribution Estimator | An Empirical Evaluation of Deep Architectures on Problems with Many Factors of Variation | Tractable Multivariate Binary Density Estimation and the Restricted Boltzmann Forest | Inductive Principles for Restricted Boltzmann Machine Learning | Greedy Part-Wise Learning of Sum-Product Networks | Learning selective sum-product networks | Modeling speech with sum-product networks: Application to bandwidth extension | On theoretical properties of sum-product networks | On the latent variable interpretation in sum-product networks | Sum-Product Networks: a New Deep Architecture | Learning Sum-Product Networks with Direct and Indirect Variable Interactions | Information processing in dynamical systems: Foundations of harmony theory | Simplifying, Regularizing and Strengthening Sum-Product Network Structure Learning | Visualizing and understanding sum-product networks | A Nonlinear Label Compression and Transformation Method for Multi-label Classification Using Autoencoders | How transferable are features in deep neural networks | Visualizing and understanding convolutional networks | Representation learning for single-channel source separation and bandwidth extension | They have been binarized as in (Di Mauro et al., 2016) by implementing the Label-Attribute Interdependence Maximization (LAIM) (Cano et al., 2016) discretization method5 | Following the experiments | MANIAC we build a random forest comprising 100 trees",iclr,010
659.pdf.json,HARD MONOTONIC ATTENTION,"Neural sequence to sequence transduction became a prominent approach to natural language processing tasks like morphological inflection generation (Faruqui et al., 2016) and automatic summarization (Rush et al., 2015) among others. A common way to improve the vanilla encoder-decoder framework for sequence to sequence tasks is the (soft) attention mechanism (Bahdanau et al., 2014) which enables the decoder to attend at specific elements in the encoded sequence, overcoming the issues in encoding very long sequences to a single vector. It was also shown that the attention mechanism effectively learns an alignment between the input and the output sequences which is naturally found in the data, and practically learns this alignment to attend at the relevant elements of the input. However, in many NLP tasks like automatic transliteration or morphological inflection generation, the data is roughly monotonically aligned – meaning the ability of the soft attention model to attend at the entire input sequence may be sub-optimal for such tasks, while also requiring a relatively large amount of training examples which is not always available (especially for morphologically rich, low resource languages). There have been several works on neural sequence transduction with monotonic assumptions. One approach is to train an alignment-aware RNN-based transducer which is composed of two independent RNN’s – one over the input sequence and one over the output sequence. The output distribution is computed by feeding a pair of aligned RNN states through an MLP, where the alignment is defined by null symbols in the output (Graves, 2012) or by a parameterized transition probability (Yu et al., 2016). In both cases training is performed by marginalizing over all possible alignments using a forward-backward procedure. This approach lacks an attention mechanism, as a dependency between the input and output RNN’s would make the inference intractable. Other related approaches employ modification",Paradigm classification in supervised learning of morphology | Neural machine translation by jointly learning to align and translate | End-to-end attentionbased large vocabulary speech recognition | Translating into morphologically rich languages with synthetic phrases | Attention-based models for speech recognition | The SIGMORPHON 2016 shared task—morphological reinflection | Discovering morphological paradigms from plain text using a dirichlet process mixture model | Latent-variable modeling of string transductions with finite-state methods | Supervised learning of complete morphological paradigms | Parameter estimation for probabilistic finite-state transducers | Morphological inflection generation using character sequence to sequence learning | Factored neural machine translation | Framewise phoneme classification with bidirectional LSTM and other neural network architectures | Sequence transduction with recurrent neural networks | Semi-supervised learning of morphological paradigms and lexicons | A neural transducer | Single-model encoder-decoder with explicit morphological representation for reinflection | Med: The lmu system for the sigmorphon 2016 shared task on morphological reinflection | Regular models of phonological rule systems | Two-level morphology: A general computational model of word-form recognition and production | Segmental recurrent neural networks for end-to-end speech recognition | Effective approaches to attentionbased neural machine translation | A rational design for a weighted finite-state transducer library | Inflection generation as discriminative string transduction | Weighting finite-state transductions with neural context | A neural attention model for abstractive sentence summarization | Noise-aware character alignment for bootstrapping statistical machine transliteration from bilingual corpora | Minimally supervised morphological analysis by multimodal alignment | Online segment to segment neural transduction | Adadelta: an adaptive learning rate method,iclr,010
660.pdf.json,,"Despite several breakthrough results in the last few years, the training of deep learning models remains a challenging problem. This training is a complex, high-dimensional, non-convex, stochastic optimization problem which is not amenable to many standard methods. Currently, the most common approach is to use some variant of stochastic gradient descent. Many extensions have been proposed to the basic gradient descent algorithm - designed to handle specific issues in the training of deep learning models. We review some of these methods in the next section. Although variants of simple stochastic gradient descent work quite well in practice, there is still room for improvement. This is easily evidenced by the existence of numerous methods to simplify the optimization problem itself like weight initialization techniques and normalization methods. In this work, we seek to improve stochastic gradient descent with a simple method that incorporates feedback from the objective function. The relative changes in the objective function indicate progress of the optimization algorithm. Our main hypothesis is that incorporating information about this change into the optimization algorithm can lead to improved performance - quantified in terms of the progress rate. We keep a running average of the relative changes in the objective function and use it to divide the learning rate. When the average relative change is high, the learning rate is reduced. This can improve the progress if, for example, the algorithm is bouncing around the walls of the objective function. Conversely, when the relative change is low, the learning rate is increased. This can help the algorithm accelerate through flat areas in the loss surface. As we discuss in the next section, such “plateaus” pose a significant challenge for first order methods and can create the illusion of local minima. While our method is general i.e. independent of any particular optimization algorithm, in this work we specifically app",Statistics of critical points of gaussian fields on large-dimensional spaces | Empirical evaluation of gated recurrent neural networks on sequence modeling | Identifying and attacking the saddle point problem in high-dimensional non-convex optimization | Adaptive subgradient methods for online learning and stochastic optimization | Understanding the difficulty of training deep feedforward neural networks | Deep learning without poor local minima | Adam: A method for stochastic optimization | Learning multiple layers of features from tiny images | Building a large annotated corpus of english: The penn treebank | A method for unconstrained convex minimization problem with the rate of convergence o (1/k2) | Dropout: a simple way to prevent neural networks from overfitting | Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude | Towards ai-complete question answering: A set of prerequisite toy tasks | Adadelta: an adaptive learning rate method,iclr,010
661.pdf.json,NEURAL GRAPH MACHINES: LEARNING NEURAL NETWORKS USING GRAPHS,"Semi-supervised learning is a powerful machine learning paradigm that can improve the prediction performance compared to techniques that use only labeled data, by leveraging a large amount of unlabeled data. The need of semi-supervised learning arises in many problems in computer vision, natural language processing or social networks, in which getting labeled datapoints is expensive or unlabeled data is abundant and readily available. There exist a plethora of semi-supervised learning methods. The simplest one uses bootstrapping techniques to generate pseudo-labels for unlabeled data generated from a system trained on labeled data. However, this suffers from label error feedbacks (Lee, 2013). In a similar vein, autoencoder based methods often need to rely on a two-stage approach: train an autoencoder using unlabeled data to generate an embedding mapping, and use the learnt embeddings for prediction. In practice, this procedure is often costly and inaccurate in practice. Another example is transductive SVMs (Joachims, 1999), which is too computationally expensive to be used for large datasets. Methods that are based on generative models and amortized variational inference (Kingma et al., 2014) can work well for images and videos, but it is not immediately clear on how to extend such techniques to handle sparse and multi-modal inputs or graphs over the inputs. In contrast to the methods above, graph-based techniques such as label propagation (Zhu & Ghahramani; Bengio et al., 2006) often provide a versatile, scalable, and yet effective solution to a wide range of problems. These methods construct a smooth graph over the unlabeled and labeled data. Graphs are also often a natural way to describe the relationships between nodes, such as similarities between embeddings, phrases or images, or connections between entities on the web or relations in a social network. Edges in the graph connect semantically similar nodes or datapoints, and if present, edge weights reflect how",TensorFlow: Large-scale machine learning | A social identity approach to identify familiar strangers in a social network | Label propagation and quadratic criterion | node2vec: Scalable feature learning for networks | Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups | Transductive inference for text classification using support vector machines | Smart reply: Automated response suggestion for email | Semi-supervised learning with deep generative models | Imagenet classification with deep convolutional neural networks | Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks | Learning convolutional neural networks for graphs | Large scale distributed semi-supervised learning using streaming approximation | Sequence to sequence learning with neural networks | Deep learning via semisupervised embedding | Character-level convolutional networks for text classification,iclr,010
662.pdf.json,UOUS AND DISCRETE ADDRESSING SCHEMES,"Designing general-purpose learning algorithms is one of the long-standing goals of artificial intelligence. Despite the success of deep learning in this area (see, e.g., (Goodfellow et al., 2016)) there are still a set of complex tasks that are not well addressed by conventional neural networks. Those tasks often require a neural network to be equipped with an explicit, external memory in which a larger, potentially unbounded, set of facts need to be stored. They include, but are not limited to, episodic question-answering (Weston et al., 2015b; Hermann et al., 2015; Hill et al., 2015), compact algorithms (Zaremba et al., 2015), dialogue (Serban et al., 2016; Vinyals & Le, 2015) and video caption generation (Yao et al., 2015). Recently two promising approaches based on neural networks to this type of tasks have been proposed. Memory networks (Weston et al., 2015b) explicitly store all the facts, or information, available for each episode in an external memory (as continuous vectors) and use the attention-based mechanism to index them when returning an output. On the other hand, neural Turing machines (NTM, (Graves et al., 2014)) read each fact in an episode and decides whether to read, write the fact or do both to the external, differentiable memory. A crucial difference between these two models is that the memory network does not have a mechanism to modify the content of the external memory, while the NTM does. In practice, this leads to easier learning in the memory network, which in turn resulted in it being used more in real tasks (Bordes et al., 2015; Dodge et al., 2015). On the contrary, the NTM has mainly been tested on a series of small-scale, carefully-crafted tasks such as copy and associative recall. The NTM, however is more expressive, precisely because it can store and modify the internal state of the network as it processes an episode. The original NTM supports two modes of addressing (which can be used simultaneously.) They are content-based and locat","VQA: visual question answering | Unitary evolution recurrent neural networks | Neural machine translation by jointly learning to align and translate | Learning long-term dependencies with gradient descent is difficult | Large-scale simple question answering with memory networks | Learning phrase representations using rnn encoder-decoder for statistical machine translation | Attention-based models for speech recognition | Recurrent batch normalization | Evaluating prerequisite qualities for learning end-to-end dialog systems | Deep learning. Book in preparation for MIT Press, 2016 | Neural turing machines | Hybrid computing using a neural network with dynamic external memory | Learning to transduce with unbounded memory | Noisy activation functions | Teaching machines to read and comprehend | The goldilocks principle: Reading children’s books with explicit memory representations | Untersuchungen zu dynamischen neuronalen netzen | Long short-term memory | Robust estimation of a location parameter | Inferring algorithmic patterns with stack-augmented recurrent nets | Adam: A method for stochastic optimization | Zoneout: Regularizing rnns by randomly preserving hidden activations | A simple way to initialize recurrent networks of rectified linear units | Effective approaches to attention-based neural machine translation | Key-value memory networks for directly reading | Neural variational inference and learning in belief networks | Scaling memory-augmented neural networks with sparse reads and writes | A neural attention model for abstractive sentence summarization | One-shot learning with memory-augmented neural networks | Building end-to-end dialogue systems using generative hierarchical neural network models | End-to-end memory networks | The neural network pushdown automaton: Architecture, dynamics and training | A neural conversational model | Towards ai-complete question answering: a set of prerequisite toy tasks | Simple statistical gradient-following algorithms for connectionist reinforcement learning | Dynamic memory networks for visual and textual question answering | Show, attend and tell: Neural image caption generation with visual attention | Describing videos by exploiting temporal structure | Reinforcement learning neural turing machines | Learning simple algorithms from examples | 2014) with its learning rate set to 0.003 and 0.007 respectively for GRU",iclr,010
663.pdf.json,,"Product classification is a key issue in e-commerce domains. A product is typically represented by metadata such as its title, image, color, weight and so on, and most of them are assigned manually by the seller. Once a product is uploaded to an e-commerce website, it is typically placed in multiple categories. Categorizing products helps e-commerce websites to provide costumers a better shopping experience, for example by efficiently searching the products catalog or by developing recommendation systems. A few examples of categories are internal taxonomies (for business needs), public taxonomies (such as groceries and office equipment) and the product’s shelf (a group of products that are presented together on an e-commerce web page). These categories vary with time in order to optimize search efficiency and to account for special events such as holidays and sports events. In order to address these needs, e-commerce websites typically hire editors and use crowdsourcing platforms to classify products. However, due to the high amount of new products uploaded daily and the dynamic nature of the categories, machine learning solutions for product classification are very appealing as means to reduce the time and economic costs. Thus, precisely categorizing items emerges as a significant issue in e-commerce domains. A shelf is a group of products presented together on an e-commerce website page, and usually contain products with a given theme/category (e.g., Women boots, folding tables). Product to shelf classification is a challenging problem due to data size, category skewness, and noisy metadata and labels. In particular, it presents three fundamental challenges for machine learning algorithms. First, it is typically a multi-class problem with thousands of classes. Second, a product may belong to multiple shelves making it a multi-label problem. And last, a product has both an image and a text input making it a multi-modal problem. Products classification is typically ","Representation learning: A review and new perspectives | Lecun. Very deep convolutional networks for natural language processing | Devise: A deep visual-semantic embedding model | Improving image-sentence embeddings using large weakly annotated photo collections | Multimodal semi-supervised learning for image classification | Neural network ensembles | Deep residual learning for image recognition | Improving product classification using images | Convolutional neural networks for sentence classification | On combining classifiers | Imagenet classification with deep convolutional neural networks | Recurrent convolutional neural networks for text classification | Images don’t lie: Transferring deep visual semantic features to large-scale multimodal learning to rank | Visualizing data using t-sne | Multimodal deep learning | Fusing audio, visual and textual clues for sentiment analysis from multimodal content | Large-scale item categorization in e-commerce using multiple recurrent neural networks | Very deep convolutional networks for large-scale image recognition | Intriguing properties of neural networks | Efficient character-level document classification by combining convolution and recurrent layers | Character-level convolutional networks for text classification | A sensitivity analysis of (and practitioners’ guide to) convolutional neural networks for sentence classification",iclr,010
664.pdf.json,GENERATIVE ADVERSARIAL NETWORKS FOR IMAGE STEGANOGRAPHY,"Recently developed Generative Adversarial Networks (GAN, see Goodfellow et al. (2014)) are powerful generative models, the main idea of which is to train a generator and a discriminator network through playing a minimax game. In the image domain, for a dataset generated by some density pdata(x) a generator G attempts to approximate the image generating distribution and to synthesize as realistic image as possible, while a discriminator D strives to distinguish real images from fake ones. There are several modifications of GAN that can generate realistic images: • Deep Convolutional Generative Adversarial Networks (DCGAN, see Radford et al. (2015)) — this model is a modification of a GAN, specialized for generation of images; • Conditional GAN — it allows generating objects from a specified class, see Mirza & Osindero (2014); • Generation of images from textual description, see Reed et al. (2016). In the present study we apply the DCGAN model to the problem of secure steganography. We construct a special container-image generator, synthetic output of which is less susceptible to successful steganalysis compared to containers, directly derived from original images. In particular, we investigate whether this methodology allows to deceive a given steganography analyzer, represented by a binary classifier detecting presence of hidden messages in an image.","Rich models for steganalysis of digital images | Generative adversarial nets | Designing steganographic distortion using directional filters | Universal distortion function for steganography in an arbitrary domain | Resampling and the detection of lsb matching in color bitmaps | Adam: A method for stochastic optimization | Conditional generative adversarial nets | Steganalysis by subtractive pixel adjacency matrix. information Forensics and Security | Using High-Dimensional Image Models to Perform Highly Undetectable Steganography | Deep learning for steganalysis is better than a rich model with an ensemble classifier, and is natively robust to the cover sourcemismatch | Deep learning for steganalysis via convolutional neural networks | Deep learning for steganalysis via convolutional neural networks | Unsupervised representation learning with deep convolutional generative adversarial networks | Generative adversarial text to image synthesis | Stacked convolutional auto-encoders for steganalysis of digital images | Deep learning face attributes in the wild",iclr,010
665.pdf.json,MS MARCO: A HUMAN GENERATED MACHINE READING COMPREHENSION DATASET,"Building intelligent agents with the ability for reading comprehension (RC) or open-domain question answering (QA) over real world data is a major goal of artificial intelligence. Such agents can have tremendous value for consumers because they can power personal assistants such as Cortana web (b), Siri web (e), Alexa web (a), or Google Assistant web (d) found on phones or headless devices like Amazon Echo web (c), all of which have been facilitated by recent advances in deep speech recognition technology Hinton et al. (2012); Dahl et al. (2012). As these types of assistants rise in popularity, consumers are finding it more convenient to ask a question and quickly get an answer through voice assistance as opposed to navigating through a search engine result page and web browser. Intelligent agents with RC and QA abilities can also have incredible business value by powering bots that automate customer service agents for business found through messaging or chat interfaces. Real world RC and QA is an extremely challenging undertaking involving the amalgamation of multiple difficult tasks such as reading, processing, comprehending, inferencing/reasoning, and finally summarizing the answer. The public availability of large datasets has led to many breakthroughs in AI research. One of the best examples is ImageNet’s Deng et al. (2009) exceptional release of 1.5 million labeled examples and 1000 object categories which has led to better than human level performance on object classification from images He et al. (2015). Another example is the very large speech databases collected over 20 years by DARPA that enabled successes of deep learning in speech recognition Deng & Huang (2004). Recently there has been an influx of datasets for RC and QA as well. These databases, however, all have notable drawbacks. For example, some are not large enough to train deep models Richardson et al. (2013), and others are larger but are synthetic. One characteristic in most, if not all, of th","Neural machine translation by jointly learning to align and translate | Meteor: An automatic metric for mt evaluation with improved correlation with human judgments. In Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation | Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition | Challenges in adopting speech recognition | Deep Learning: Methods and Applications | Rich feature hierarchies for accurate object detection and semantic segmentation | Hybrid computing using a neural network with dynamic external memory | Deep residual learning for image recognition | Teaching machines to read and comprehend | The goldilocks principle: Reading children’s books with explicit memory representations | Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups | Long short-term memory | Learning deep structured semantic models for web search using clickthrough data | Text understanding with the attention sum reader network | Imagenet classification with deep convolutional neural networks | Rouge: A package for automatic evaluation of summaries. In Text summarization branches out | Bleu: a method for automatic evaluation of machine translation | Squad: 100,000+ questions for machine comprehension of text. 2016 | Mctest: A challenge dataset for the open-domain machine comprehension of text | Reasonet: Learning to stop reading in machine comprehension | End-to-end memory networks | Sequence to sequence learning with neural networks | Towards ai-complete question answering: A set of prerequisite toy tasks | Wikiqa: A challenge dataset for open-domain question answering",iclr,010
666.pdf.json,,"As many deep learning network architectures have been proposed, several key models have emerged as default models for many image classification tasks. In particular, deep neural network architectures such as the VGG network by Karen & Zisserman (2014), Inception by Christian et al. (2015) and ResNets by Kaiming et al. (2015), have proven their superb performance on image classification when using datasets such as ImageNet (Alex et al. (2012)) and MS COCO (Lin et al. (2014)). With enough data and fine tuning, these ‘go to’ models have been shown to be successful for many visual classification tasks. However, there is a problem when one does not have access to a large labeled training dataset to fine-tune these models. This task of training a classifier using only a small k number of examples is often referred to as k-shot learning and has problems when dealing with high capacity models such as deep convolutional neural networks. The problem of training with only a small number of training examples is that it often leads to overfitting, where the model essentially memories those data points without gaining the ability to generalize to new instances. Current state-of-the-art methods (Oriol et al. (2016) Adam et al. (2016)) apply deep learning techniques by using specialized network architectures for k-shot learning to avoid overfitting. While this is a reasonable strategy for proposing diverse kinds of new frameworks for k-shot learning tasks, it is hard for different k-shot learning methods to borrow structures from each other since they are all highly customized networks. We propose a method called the Orthogonal Method of Grouping (OMG) to facilitate a better k-shot learning process. OMG ensures that similar (near duplicate) features in the classifier will be grouped and modified together during the training process. This process of grouping features naturally induces dimension reduction of the parameter space and imposes a form of subspace regularization during tra",Survey on independent component analysis | Oneshot Learning with Memory-Augmented | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | One Shot Learning via Compositions of Meaningful Patches | Unsupervised visual domain adaptation using subspace alignment | Geodesic flow kernel for unsupervised domain adaptation | Return of the Devil in the Details: Delving Deep into Convolutional Nets | Going deeper with convolutions | Frustratingly easy domain adaptation | Reducing the dimensionality of data with neural networks | Siamese neural networks for one-shot image recognition | One-shot adaptation of supervised deep convolutional models | One-shot adaptation of supervised deep convolutional models | One-shot adaptation of supervised deep convolutional models | Deep residual learning for image recognition | Very deep convolutional networks for large-scale image recognition | Gradient-based learning applied to document | Microsoft coco: Common objects in context | Front-end factor analysis for speaker verification | Matching Networks for One Shot Learning | Adapting visual category models to new domains | Best practices for convolutional neural networks applied to visual document analysis,iclr,010
667.pdf.json,HEALTHCARE REPRESENTATION LEARNING,"The rapid growth in volume and diversity of health care data from electronic health records (EHR) and other sources is motivating the use of predictive modeling to improve care for individual patients. In particular, novel applications are emerging that use deep learning methods such as word embedding (Choi et al., 2016c;e), recurrent neural networks (RNN) (Che et al., 2016; Choi et al., 2016a;b; Lipton et al., 2016), convolutional neural networks (CNN) (Nguyen et al., 2016) or stacked denoising autoencoders (SDA) (Che et al., 2015; Miotto et al., 2016), demonstrating significant performance enhancement for diverse prediction tasks. Deep learning models appear to perform significantly better than logistic regression or multilayer perceptron (MLP) models that depend, to some degree, on expert feature construction (Lipton et al., 2015; Razavian et al., 2016). Training deep learning models typically requires large amounts of data that often cannot be met by a single health system or provider organization. Sub-optimal model performance can be particularly challenging when the focus of interest is predicting onset of a specific disease (e.g. heart failure) or related events such as accelerated disease progression. For example, using Doctor AI (Choi et al., 2016a), we discovered that RNN alone was ineffective to predict the onset of diseases such as cerebral degenerations (e.g. Leukodystrophy, Cerebral lipidoses) or developmental disorders (e.g. autistic disorder, Heller’s syndrome), partly because their rare occurrence in the training data provided little learning opportunity to the flexible models like RNN. The data requirement of deep learning models comes from having to assess exponential number of combinations of input features. This can be alleviated by exploiting medical ontologies that encodes hierarchical clinical constructs and relationships among medical concepts. Fortunately, there are many well-organized ontologies in healthcare such as the International Clas","Freebase: a collaboratively | Recurrent neural networks | Multi-layer representation learning for medical concepts | Physiobank, physiotoolkit, and physionet components of a new research resource | Node2vec: Scalable feature learning for networks | A simple way to initialize recurrent networks of rectified | Visualizing data using t-sne | predict the future of patients from the electronic health records | Glove: Global vectors for word representation | Deepwalk: Online learning of social representations | Under review as a conference paper at ICLR | Graph Laplacian Regularization for Large-Scale",iclr,010
668.pdf.json,REGULARIZING NEURAL NETWORKS BY PENALIZING CONFIDENT OUTPUT DISTRIBUTIONS,"Large neural networks with millions of parameters achieve strong performance on image classification (Szegedy et al., 2015a), machine translation (Wu et al., 2016), language modeling (Jozefowicz et al., 2016), and speech recognition (Graves et al., 2013). However, despite using large datasets, neural networks are still prone to overfitting. Numerous techniques have been proposed to prevent overfitting, including early stopping, L1/L2 regularization (weight decay), dropout (Srivastava et al., 2014), and batch normalization (Ioffe & Szegedy, 2015). These techniques, along with most other forms of regularization, act on the hidden activations or weights of a neural network. Alternatively, regularizing the output distribution of large, deep neural networks has largely been unexplored. To motivate output regularizers, we can view the knowledge of a model as the conditional distribution it produces over outputs given an input (Hinton et al., 2015) as opposed to the learned values of its parameters. Given this functional view of knowledge, the probabilities assigned to class labels that are incorrect (according to the training data) are part of the knowledge of the network. For example, when shown an image of a BMW, a network that assigns a probability of 10−3 to “Audi” and 10−9 to “carrot” is clearly better than a network that assigns 10−9 to “Audi” and 10−3 to carrot, all else being equal. One reason it is better is that the probabilities assigned to incorrect classes are an indication of how the network generalizes. Distillation (Hinton et al., 2015; Bucilu et al., 2006) exploits this fact by explicitly training a small network to assign the same probabilities to incorrect classes as a large network or ensemble of networks that generalizes well. Further, by operating on the output distribution that has a natural scale rather than on internal weights, whose significance depends on the values of the other weights, output regularization has the property that it is invarian","Tensorflow: Large-scale machine learning on heterogeneous distributed systems | End-to-end attention-based large vocabulary speech recognition | Neural machine translation by jointly learning to align and translate | A maximum entropy approach to natural language processing | N-gram counts and language models from the common crawl | Listen, attend and spell | Latent sequence decompositions | On using very large target vocabulary for neural machine translation | Attention-based models for speech recognition | A theoretically grounded application of dropout in recurrent neural networks | Towards end-to-end speech recognition with recurrent neural networks | Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks | Speech recognition with deep recurrent neural networks | Deep residual learning for image recognition | Distilling the knowledge in a neural network | Densely connected convolutional networks | Deep networks with stochastic depth | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Information theory and statistical mechanics | Exploring the limits of language modeling | Fractalnet: Ultra-deep neural networks without residuals | Learning online alignments with continuous rewards policy gradient | Effective approaches to attentionbased neural machine translation | Building a large annotated corpus of english: The penn treebank | Pointer sentinel mixture models | A global optimization technique for statistical classifier design | Distributional smoothing by virtual adversarial examples | Asynchronous methods for deep reinforcement learning | Acoustic modeling using deep belief networks | Reward augmented maximum likelihood for neural structured prediction | The kaldi speech recognition toolkit | Using the output embedding to improve language models | Training deep neural networks on noisy labels with bootstrapping | Deterministic annealing for clustering, compression, classification, regression, and related optimization problems | Dropout: a simple way to prevent neural networks from overfitting | Going deeper with convolutions | Rethinking the inception architecture for computer vision | Combining time-and frequency-domain convolution in convolutional neural networkbased phone recognition | Regularization of neural networks using dropconnect | Function optimization using connectionist reinforcement learning algorithms | Google’s neural machine translation system: Bridging the gap between human and machine translation | Disturblabel: Regularizing cnn on the loss layer | Recurrent neural network regularization | Under review as a conference paper at ICLR",iclr,010
670.pdf.json,,,"Multitask learning | Learning parameterized skills | Hierarchical Relative Entropy Policy Search | Multi-task policy search for robotics | Hidden parameter markov decision processes: A semiparametric regression approach for discovering latent task parametrizations | Deep unsupervised network for multimodal perception, representation and classification | Mosaic model for sensorimotor learning and control | Discovering hierarchy in reinforcement learning with HEXQ | Coupled Learning of Action Parameters and Forward Models for Manipulation | Learning piecewise control strategies in a modular neural network | Adaptive mixtures of local experts | Learning state representations with robotic priors | Patterns for Learning with Side Information | Data-Efficient Generalization of Robot Skills with Contextual Policy Search | Building Machines That Learn and Think Like People | Autonomous reinforcement learning on raw visual input data in a real world application | End-to-End Training of Deep Visuomotor Policies | The knn-td reinforcement learning algorithm. Methods and Models in Artificial and Natural Computation | Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem | Human-level control through deep reinforcement learning | Actor-Mimic: Deep Multitask and Transfer Reinforcement Learning | Policy Distillation | Gated networks: an inventory | Simultaneous On-line Discovery and Improvement of Robotic Skill Options | Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning | Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images | Slow Feature Analysis: Unsupervised Learning of Invariances | Graying the black box: Understanding DQNs",iclr,010
671.pdf.json,DRAGNN: A TRANSITION-BASED FRAMEWORK FOR DYNAMICALLY CONNECTED NEURAL NETWORKS,"To apply deep learning models to structured prediction, machine learning practitioners must address two primary issues: (1) how to represent the input, and (2) how to represent the output. The seq2seq encoder/decoder framework (Kalchbrenner & Blunsom, 2013; Cho et al., 2014; Sutskever et al., 2014) proposes solving these generically. In its simplest form, the encoder network produces a fixed-length vector representation of an input, while the decoder network produces a linearization of the target output structure as a sequence of output symbols. Encoder/decoder is state of the art for several key tasks in natural language processing, such as machine translation (Wu et al., 2016). However, fixed-size encodings become less competitive when the input structure can be explicitly mapped to the output. In the simple case of predicting tags for individual tokens in a sentence, stateof-the-art taggers learn vector representations for each input token and predict output tags from those (Ling et al., 2015; Huang et al., 2015; Andor et al., 2016). When the input or output is a syntactic parse tree, networks that explicitly operate over the compositional structure of the network typically outperform generic representations (Dyer et al., 2015; Li et al., 2015; Bowman et al., 2016). Implictly learned mappings via attention mechanisms can significantly improve the performance of sequence-to-sequence (Bahdanau et al., 2015; Vinyals et al., 2015), but require runtime that’s quadratic in the input size. In this work, we propose a modular neural architecture that generalizes the encoder/decoder concept to include explicit structure. Our framework can represent sequence-to-sequence learning as well as models with explicit structure like bi-directional tagging models and compositional, tree-structured models. Our core idea is to define any given architecture as a series of modular units, where connections between modules are unfolded dynamically as a function of the intermediate activat",Globally normalized transition-based neural networks | Reverse revision and linear tree combination for dependency parsing | Neural machine translation by jointly learning to align and translate | A fast unified model for parsing and sentence understanding | Learning phrase representations using rnn encoder-decoder for statistical machine | Multi-task learning for multiple language translation | Transition-based dependency parsing with stack long short-term memory | Overcoming the lack of parallel data in sentence compression | Learning task-dependent distributed representations by backpropagation through structure | Bidirectional lstm-crf models for sequence tagging | Recurrent continuous translation models | Simple and accurate dependency parsing using bidirectional lstm feature representations | Distilling an ensemble of greedy dependency parsers into one mst parser | Neural architectures for named entity recognition | When are tree structures necessary for deep learning of representations | Finding function in form: Compositional character models for open vocabulary word representation | Multi-task sequence to sequence learning | Inductive dependency parsing | A decomposable attention model for natural language inferencfne | Learning continuous phrase representations and syntactic parsing with recursive neural networks | Dynamic pooling and unfolding recursive autoencoders for paraphrase detection | Sequence to sequence learning with neural networks. In Advances in neural information processing | Improved semantic representations from tree-structured long short-term memory | Grammar as a foreign language | Structured training for neural network transition-based parsing | Google’s neural machine translation system: Bridging the gap between human and machine translation | Transition-based neural word segmentation | Stack-propagation: Improved representation learning for syntax,iclr,010
672.pdf.json,,"In our world, information is represented through various modalities. While images are represented by pixel information, these can also be described with text or tag information. People often exchange such information bi-directionally. For instance, we can not only imagine what “a young female with a smile who does not wear glasses” looks like, but also add this caption to a corresponding photograph. To do so, it is important to extract a joint representation that captures high-level concepts among all modalities. Then we can bi-directionally generate modalities through the joint representations. However, each modality typically has a different kind of dimension and structure, e.g., images (real-valued and dense) and texts (discrete and sparse). Therefore, the relations between each modality and the joint representations might become high nonlinearity. To discover such relations, deep neural network architectures have been used widely for multimodal learning (Ngiam et al., 2011; Srivastava & Salakhutdinov, 2012). The common approach with these models to learn joint representations is to share the top of hidden layers in modality specific networks. Among them, generative approaches using deep Boltzmannmachines (DBMs) (Srivastava & Salakhutdinov, 2012; Sohn et al., 2014) offer the important advantage that these can generate modalities bi-directionally. Recently, variational autoencoders (VAEs) (Kingma & Welling, 2013; Rezende et al., 2014) have been proposed to estimate flexible deep generative models by variational inference methods. These models use back-propagation during training, so that it can be trained on large-scale and highdimensional dataset compared with DBMs with MCMC training. Some studies have addressed to handle such large-scale and high-dimensionalmodalities on VAEs, but they are forced to model conditional distribution (Kingma et al., 2014; Sohn et al., 2015; Pandey & Dukkipati, 2016). Therefore, it can only generate modalities in one direction. For e",Generating sentences from a continuous space | Importance weighted autoencoders | Lasagne: First release | Generative adversarial nets | Adam: A method for stochastic optimization | Auto-encoding variational bayes | Semi-supervised learning with deep generative models | Deep convolutional inverse graphics network | Autoencoding beyond pixels using a learned similarity metric | Deep learning face attributes in the wild | The variational fair auto encoder | Generating images from captions with attention | Multimodal deep learning | Variational methods for conditional multimodal learning: Generating human faces from attributes | Stochastic backpropagation and approximate inference in deep generative models | Deep boltzmann machines | Improvedmultimodal deep learning with variation of information | Learning structured output representation using deep conditional generative models | Ladder variational autoencoders | Multimodal learning with deep boltzmann machines | Theano: A python framework for fast computation of mathematical expressions | Attribute2image: Conditional image generation from visual attributes,iclr,010
673.pdf.json,HIERARCHICAL MEMORY NETWORKS,"Until recently, traditional machine learning approaches for challenging tasks such as image captioning, object detection, or machine translation have consisted in complex pipelines of algorithms, each being separately tuned for better performance. With the recent success of neural networks and deep learning research, it has now become possible to train a single model end-to-end, using backpropagation. Such end-to-end systems often outperform traditional approaches, since the entire model is directly optimized with respect to the final task at hand. However, simple encode-decode style neural networks often underperform on knowledge-based reasoning tasks like question-answering or dialog systems. Indeed, in such cases it is nearly impossible for regular neural networks to store all the necessary knowledge in their parameters. Neural networks with memory (Graves et al., 2014; Weston et al., 2015b) can deal with knowledge bases by having an external memory component which can be used to explicitly store knowledge. The memory is accessed by reader and writer functions, which are both made differentiable so that the entire architecture (neural network, reader, writer and memory components) can be trained end-to-end using backpropagation. Memory-based architectures can also be considered as generalizations of RNNs and LSTMs, where the memory is analogous to recurrent hidden states. However they are much richer in structure and can handle very long-term dependencies because once a vector (i.e., a memory) is stored, it is copied from time step to time step and can thus stay there for a very long time (and gradients correspondingly flow back time unhampered). There exists several variants of neural networks with a memory component: Memory Networks (Weston et al., 2015b), Neural Turing Machines (NTM) (Graves et al., 2014), Dynamic Memory Net- ∗Corresponding author: apsarathchandar@gmail.com works (DMN) (Kumar et al., 2015). They all share five major components: memory, input m",Clustering is efficient for approximate maximum inner product search | Speeding up the xbox recommender system using a euclidean transformation for inner-product spaces | Translating embeddings for modeling multi-relational data | Large-scale simple question answering with memory networks | Evaluating prerequisite qualities for learning end-to-end dialog systems | Neural turing machines | On using very large target vocabulary for neural machine translation | Adam: A method for stochastic optimization | Ask me anything: Dynamic memory networks for natural language processing | Efficient estimation of word representations in vector space | Neural variational inference and learning in belief networks | Hierarchical probabilistic neural network language model | On symmetric and asymmetric lshs for inner product search | Scaling memory-augmented neural networks with sparse reads and writes | Maximum inner-product search using cone trees | Asymmetric LSH (ALSH) for sublinear time maximum inner product search (MIPS) | Improved asymmetric locality sensitive hashing (alsh) for maximum inner product search (mips) | Scalable and sustainable deep learning via randomized hashing | End-to-end memory networks | Deep networks with large output spaces | Towards ai-complete question answering: a set of prerequisite toy tasks | Simple statistical gradient-following algorithms for connectionist reinforcement learning | Dynamic memory networks for visual and textual question answering | Reinforcement learning neural turing machines | Efficient online spherical k-means clustering,iclr,010
674.pdf.json,CONVOLUTIONAL NEURAL NETWORKS,"Deep learning has achieved remarkable success in many technological areas (Bengio et al., 2013; Schmidhuber, 2015), including computer vision (Krizhevsky et al., 2012; Szegedy et al., 2015; Simonyan and Zisserman, 2015), automatic speech recognition (Hinton et al., 2012; Hannun et al., 2014), natural language processing (Collobert et al., 2011; Mikolov et al., 2013; Cho et al., 2014), bioinformatics (Chicco et al., 2014), even high energy particle physics (Baldi et al., 2014). In particular, deep Convolutional Neural Networks (CNNs) (LeCun et al., 1989; Krizhevsky et al., 2012; Simonyan and Zisserman, 2015) have been a critical enabling technique for analyzing images and sequential data. Following the unprecedented success of deep networks, there has been some theoretical work (e.g., Arora et al. (2014; 2015); Paul and Venkatasubramanian (2014)) that suggest several mathematical models for different deep learning architectures. However, theoretical analysis and understanding lag behind the very rapid evolution and empirical success of deep architectures, and more theoretical analysis is needed to better understand the state-of-the-art deep architectures, and possibly to improve them further. In this paper, we attempt to address the gap between the empirical success and theoretical understanding of the Convolutional Neural Nets, in particular its invertibility (i.e., reconstructing the input from the hidden activations), by analyzing a simplified mathematical model using random weights.1 This property is intriguing because convolutional neural networks are typically trained with discriminative objectives (i.e., unrelated to reconstruction) with a large amount of labels, such as the ImageNet dataset. For example, Dosovitskiy and Brox (2016) used upsampling-deconvolutional architectures to invert the hidden activations of feedforward CNNs to the input domain. In other related work, Zhao et al. (2016) proposed stacked a what-where network via a (deconvolutional) decoder","Provable Bounds for Learning Some Deep Representations | Why are deep nets reversible: A simple theory, with implications for training | Searching for exotic particles in high-energy physics with deep learning | Model-Based Compressive Sensing | A fast iterative shrinkage-thresholding algorithm for linear inverse problems | Representation Learning: A Review and New Perspectives | Iterative hard thresholding for compressed sensing | Sparse feature learning for deep belief networks | l1-norm methods for convex-cardinality problems, ee364b: Convex optimization ii lecture notes, 2014-2015 | Signal recovery from pooling representations | Candés. The restricted isometry property and its implications for compressed sensing | Deep autoencoder neural networks for gene ontology annotation predictions | Learning phrase representations using rnn encoder-decoder for statistical machine translation | Natural language processing (almost) from scratch | Imagenet: A large-scale hierarchical image database | Inverting visual representations with convolutional networks | Deep neural networks with random gaussian weights: A universal classification strategy | Deep speech: Scaling up end-to-end speech recognition | A powerful generative model using random weights for the deep image representation | Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups | What is the best multi-stage architecture for object recognition | Caffe: Convolutional architecture for fast feature embedding | Imagenet classification with deep convolutional neural networks | Building high-level features using large scale unsupervised learning | Backpropagation applied to handwritten zip code recognition | Sparse deep belief net model for visual area v2 | Matching pursuits with time-frequency dictionaries | Distributed representations of words and phrases and their compositionality | Emergence of simple-cell receptive field properties by learning a sparse code for natural images | Concentration of Measure for Block Diagonal Matrices With Applications to Compressive Signal Processing | Why does Deep Learning work? - A perspective from Group Theory | Unsupervised learning of invariant feature hierarchies with applications to object recognition | On random weights and unsupervised feature learning | Deep learning in neural networks: An overview | Understanding and improving convolutional neural networks via concatenated rectified linear units | Very deep convolutional networks for large-scale image recognition | Going deeper with convolutions | Matconvnet – convolutional neural networks for matlab | Introduction to the non-asymptotic analysis of random matrices | Image super-resolution via sparse representation | Augmenting neural networks with reconstructive decoding pathways for large-scale image classification | Vershynin (2010) that the sum of squares of sub-Gaussian random variables tightly concentrate",iclr,010
675.pdf.json,,,"Scheduled sampling for sequence prediction with recurrent neural networks | Representation learning: A review and new perspectives | Curriculum learning | Mixture density networks | Multitask learning | Multi-column deep neural networks for image classification | A coevolutionary approach to representation development | Incremental learning, or the importance of starting small | Learning and development in neural networks: The importance of starting small | A note on the utility of incremental learning | Generating sequences with recurrent neural networks | Deep residual learning for image recognition | Inferring motor programs from images of handwritten digits | Long short-term memory | On large-batch training for deep learning: Generalization gap and sharp minima | A critical review of recurrent neural networks for sequence learning | Symbiotic Evolution Of Neural Networks In Sequential Decision Tasks | Actor-mimic: Deep multitask and transfer reinforcement learning | Discriminability-based transfer between neural networks | Sim-to-real robot learning from pixels with progressive nets | Incremental learning from noisy data | Structure learning in random fields for heart motion abnormality detection | Sequence learning: from recognition and prediction to sequential decision making | Is learning the n-th thing any easier than learning the first | Learning to execute | A fast parallel algorithm for thinning digital patterns",iclr,010
677.pdf.json,SKIP-GRAPH: LEARNING GRAPH EMBEDDINGS WITH AN ENCODER-DECODER MODEL,"The skip-gram model (Mikolov et al., 2013) was originally introduced in the natural language processing (NLP) domain as a model for learning vector representations of words. Recently, it has been adapted successfully to solve the problem of learning node representations for graph-structured data (Grover & Leskovec, 2016; Perozzi et al., 2014). The learned vectors can then be used directly in problems such as link prediction (Miller et al., 2009), or clustering of nodes on a graph (Vinayak et al., 2014). However, in many real-world applications we need to learn a feature representation for the entire graph instead of representations for just the nodes in the graph. In this paper, we study the graph representation learning problem, where the task is to learn a feature representation for any graph object. We propose a novel solution based upon the encoder-decoder model. Graph-structured data can be found in many different domains including biology, chemistry, and the study of social networks. For instance, in chemistry, chemical compounds can be represented as molecular graphs (Duvenaud et al., 2015). In social network analysis, the interaction among different entities of a community can be captured using a social graph (Yanardag & Vishwanathan, 2015). A natural question that arises in these scenarios is what the structure of a graph tells us about the properties of the graph (e.g., what does the molecular graph tell us about the compound’s aqueous solubility, or its anti-cancer activity?). In other words, we are often interested in performing machine learning tasks on graph-structured data. Many techniques have been proposed to solve this problem, these include learning graph kernels (Vishwanathan et al., 2010), identifying discriminative subgraphs (Kong et al., 2011), using specially designed neural network models such as the graph neural network (Scarselli et al., 2009), and learning the graph fingerprint (Duvenaud et al., 2015). Most of the approaches for learning ","Empirical evaluation of gated recurrent neural networks on sequence modeling | Convolutional networks on graphs for learning molecular fingerprints | node2vec: Scalable feature learning for networks | Learning the k in k-means | Recurrent continuous translation models | Learning image embeddings using convolutional neural networks for improved multi-modal semantics | Adam: A method for stochastic optimization | Skip-thought vectors | Dual active feature and sample selection for graph classification | Kernel pca and de-noising in feature spaces | Efficient estimation of word representations in vector space | Nonparametric latent feature models for link prediction | The generation of a unique machine description for chemical structure | Popular ensemble methods: An empirical study | Deepwalk: online learning of social representations | Extended-connectivity fingerprints | Computational capabilities of graph neural networks | Weisfeiler-lehman graph kernels | Graph clustering with missing data: Convex algorithms and analysis | Smiles, a chemical language and information system | A reduction of a graph to a canonical form and an algebra arising during this reduction | Deep graph kernels",iclr,010
678.pdf.json,,"Machine intelligence has had some notable successes, however often in narrow domains which are sometimes of little practical use to humans – for instance games like chess (Campbell et al., 2002) or Go (Silver et al., 2016). If we aimed to build a general AI that would be able to efficiently assist humans in a wide range of settings, we would want it to have a much larger set of skills – among them would be an ability to understand human language, to perform common-sense reasoning and to be able to generalize its abilities to new situations like humans do. If we want to achieve this goal through Machine Learning, we need data to learn from. A lot of data if the task at hand is complex – which is the case for many useful tasks. One way to achieve wide applicability would be to provide training data for each specific task we would like the machine to perform. However it is unrealistic to obtain a sufficient amount of training data for some domains – it may for instance require expensive human annotation or all domains of application may be difficult to predict in advance – while the amount of training data in other domains is practically unlimited, (e.g. in language modelling or Cloze-style question answering). The way to bridge this gap – and to achieve the aforementioned adaptability – is transfer learning (Pan & Yang, 2010) and closely related semi-supervised learning (Zhu & Goldberg, 2009) which allow the system to acquire a set of skills on domains where data are abundant and then use these skills to succeed on previously unseen domains. Despite how important generalization is for general AI, a lot of research keeps focusing on solving narrow tasks. In this paper we would like to examine transfer of learnt skills and knowledge within the domain of text comprehension, a field that has lately attracted a lot of attention within the NLP community (Hermann et al., 2015; Hill et al., 2015; Kobayashi et al., 2016; Kadlec et al., 2016b; Chen et al., 2016; Sordoni et al.,","Embracing data abundance: BookTest Dataset for Reading Comprehension | A Thorough Examination of the CNN / Daily Mail Reading Comprehension Task | Broad Context Language Modeling as Reading Comprehension | Natural Language Processing ( Almost ) from Scratch | Attention-overAttention Neural Networks for Reading Comprehension | Consensus Attention-based Neural Networks for Chinese Reading Comprehension | Semi-supervised Sequence Learning | Gated-Attention Readers for Text Comprehension | Hybrid Computing Using a Neural Network with Dynamic External Memory. Nature, 2016 | A JOINT MANYTASK MODEL: GROWING A NEURAL NETWORK FOR MULTIPLE NLP TASKS | Teaching machines to read and comprehend | The goldilocks principle: Reading children’s books with explicit memory representations | From Particular to General : A Preliminary Case Study of Transfer Learning in Reading Comprehension | Neural Text Understanding with Attention Sum Reader | Dynamic Entity Representation with Max-pooling Improves Machine Reading | Dataset and Neural Recurrent Sequence Labeling Model for Open-Domain Factoid Question Answering | Efficient Estimation of Word Representations in Vector Space | How Transferable are Neural Networks in NLP Applications | Reasoning with Memory Augmented Neural Networks for Language Comprehension | A Survey on Transfer Learning | SQuAD: 100,000+ Questions for Machine Comprehension of Text | ReasoNet: Learning to Stop Reading in Machine Comprehension | Mastering the game of Go with deep neural networks and tree | Iterative Alternating Neural Attention for Machine Reading | End-To-End Memory Networks | Natural Language Comprehension with the EpiReader | Separating Answers from Queries for Neural Reading Comprehension | Towards AI-complete Question Answering: A Set of Prerequisite | Dynamic Memory Networks for Visual and Textual Question Answering | End-to-End Reading Comprehension with Dynamic Answer Chunk Ranking | Introduction to semi-supervised learning",iclr,010
680.pdf.json,DEEP CHARACTER-LEVEL NEURAL MACHINE TRANSLATION BY LEARNING MORPHOLOGY,"Neural machine translation (NMT) attempts to build a single large neural network that reads a sentence and outputs a translation (Sutskever et al., 2014). Most of the extant neural machine translations models belong to a family of word-level encoder-decoders (Sutskever et al., 2014; Cho et al., 2014). Recently, Bahdanau et al. (2015) proposed a model with attention mechanism which automatically searches the alignments and greatly improves the performance. However, the use of a large vocabulary seems necessary for the word-level neural machine translation models to improve performance (Sutskever et al., 2014; Cho et al., 2015). Chung et al. (2016a) listed three reasons behind the wide adoption of word-level modeling: (i) word is a basic unit of a language, (ii) data sparsity, (iii) vanishing gradient of character-level modeling. Consider that a language itself is an evolving system. So it is impossible to cover all words in the language. The problem of rare words that are out of vocabulary (OOV) is a critical issue which can effect the performance of neural machine translation. In particular, using larger vocabulary does improve performance (Sutskever et al., 2014; Cho et al., 2015). However, the training becomes much harder and the vocabulary is often filled with many similar words that share a lexeme but have different morphology. There are many approaches to dealing with the out-of-vocabulary issue. For example, Gulcehre et al. (2016); Luong et al. (2015); Cho et al. (2015) proposed to obtain the alignment information of target unknown words, after which simple word dictionary lookup or identity copy can be performed to replace the unknown words in translation. However, these approaches ignore several important properties of languages such as monolinguality and crosslinguality as pointed out by Luong and Manning (2016). Thus, Luong and Manning (2016) proposed a hybrid neural machine translation model which leverages the power of both words and characters to achiev","Character-based neural machine translation | Hierarchical neural network generative models for movie dialogues | Neural machine translation of rare words with subword units | Character-aware neural language models | Fully character-level neural machine translation without explicit segmentation | Bidirectional recurrent neural networks | Empirical evaluation of gated recurrent neural networks on sequence modeling | Long short-term memory | Theano: new features and speed improvements | Theano: a CPU and GPU math expression compiler | Blocks and fuel: Frameworks for deep learning | Adam: A method for stochastic optimization | Bleu: a method for automatic evaluation of machine translation. pages 311–318 | Multi-way, multilingual neural machine translation with a shared attention mechanism | Eye movements when reading transposed text: the importance of word-beginning letters | Hierarchical multiscale recurrent neural networks | Google’s neural machine translation system: Bridging the gap between human and machine translation",iclr,010
681.pdf.json,,,"Deep scattering spectrum | Scattering decomposition for massive signal classification: from theory to fast algorithm and implementation with validation on international bioacoustic benchmark | Invariant scattering convolution networks. Pattern Analysis and Machine Intelligence | Music genre classification using multiscale scattering and sparse representations | Unsupervised deep haar scattering on graphs | Wavelet analysis and signal processing | Image denoising via sparse and redundant representations over learned dictionaries | Backpropagation for energy-efficient neuromorphic computing | Numerical recipes in c. Press Syndicate of the University | An introduction to wavelets | Lifeclef 2015: multimedia life species identification challenges | Convolutional networks for images, speech, and time series | Classification and regression by randomforest | A wavelet tour of signal processing | Group invariant scattering | Understanding deep convolutional networks | A theory for multiresolution signal decomposition: the wavelet representation | Deep roto-translation scattering for object classification | Boosting the margin: A new explanation for the effectiveness of voting methods | Rotation, scaling and deformation invariant scattering for texture discrimination | Sparse image and signal processing: wavelets, curvelets, morphological diversity | Experimental perspectives on learning from imbalanced data | Exponential decay of scattering coefficients | From learning models of natural image patches to whole image restoration | Natural images, gaussian mixtures and dead leaves",iclr,010
682.pdf.json,,"In this paper, we are interested in deep generative models. One may naively classify these models into a family of directed deep generative models trainable by back-propagation (e.g., Kingma & Welling, 2013; Goodfellow et al., 2014), and deep energy-based models, such as deep belief network (Hinton et al., 2006) and deep Boltzmann machine (Salakhutdinov & Hinton, 2009). The building block of deep energy-based models is a bipartite graphical model called restricted Boltzmann machine (RBM). The RBM model consists of two layers, visible and hidden. The resulting graphical model which can account for higher-order interactions of the visible units (visible layer) using the hidden units (hidden layer). It also makes the inference easier that there are no interactions between the variables in each layer. The conventional RBM uses Bernoulli units for both the hidden and visible units (Smolensky, 1986). One extension is using Gaussian visible units to model general natural images (Freund & Haussler, 1994). For hidden units, we can also generalize Bernoulli units to the exponential family (Welling et al., 2004; Ravanbakhsh et al., 2016). Nair & Hinton (2010) propose a variation using Rectified Linear Unit (ReLU) for the hidden layer with a heuristic sampling procedure, which has promising performance in terms of reconstruction error and classification accuracy. Unfortunately, due to its lack of strict monotonicity, ReLU RBM does not fit within the framework of exponential family RBMs (Ravanbakhsh et al., 2016). Instead we study leaky-ReLU RBM (leaky RBM) in this work and address two important issues i) a better training (sampling) algorithm for ReLU RBM and; ii) a better quantification of leaky RBM –i.e., evaluation of its performance in terms of likelihood. We study some of the fundamental properties of leaky RBM, including its joint and marginal distributions (Section 2). By analyzing these distributions, we show that the leaky RBM is a union of truncated Gaussian distribut","Learning deep architectures for ai | Reweighted wake-sleep | Accurate and conservative estimates of mrf loglikelihood using reverse annealing | Partition functions from rao-blackwellized tempered sampling | Enhanced gradient for training restricted boltzmann machines | An introduction to restricted boltzmann machines | Unsupervised learning of distributions on binary vectors using two layer networks | Generative adversarial nets | Annealing between distributions by averaging moments | Training products of experts by minimizing contrastive divergence | A practical guide to training restricted boltzmann machines | A fast learning algorithm for deep belief nets | Sparse inverse covariance matrix estimation using quadratic approximation | Auto-encoding variational bayes | Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations | Estimating the partition function by discriminance sampling | Rectifier nonlinearities improve neural network acoustic models | Rectified linear units improve restricted boltzmann machines | Exact hamiltonian monte carlo for truncated multivariate gaussians | Modeling pixel means and covariances using factorized third-order boltzmann machines | Stochastic neural networks with monotonic activation functions | Deep Boltzmann machines | On the quantitative analysis of Deep Belief Networks | Nonlinear statistical learning with truncated gaussian graphical models | Unsupervised learning with truncated gaussian graphical models | A note on the evaluation of generative models | Training restricted boltzmann machines using approximations to the likelihood gradient | Using Fast Weights to Improve Persistent Contrastive Divergence | Exponential family harmoniums with an application to information retrieval | Graphical models via generalized linear models | 2016), the conditional distribution is defined as p(hj |ηj | Therefore, we instead focused on quantitative evaluation of the log-likelihood in Table 3. F.2 COMPUTATIONAL TIME BETWEEN DIFFERENT SAMPLING STRATEGIES The comparison in terms of CPU time of different sampling algorithms discussed in Section 5 is shown in Figure 8. Please note that the complexity of CD and Mix are the almost the same | From Appendix E, the two-stage algorithm used here can also be improved by applying",iclr,010
683.pdf.json,,"Residual Networks, a type of deep network recently introduced in He et al. (2015a), are characterized by the use of shortcut connections (sometimes also called skip connections), which connect the input of a layer of a deep network to the output of another layer positioned a number of levels “above” it. The result is that each one of these shortcuts shows that networks can be build in blocks, which rely on both the output of the previous layer and the previous block. Residual Networks have been developed with many more layers than traditional Deep Networks, in some cases with over 1000 blocks, such as the networks in He et al. (2016). A recent study in Veit et al. (2016) compares Residual Networks to an ensemble of smaller networks. This is done by unfolding the shortcut connections into the equivalent tree structure, which closely resembles an ensemble. An example of this can be shown in Figure 1. Dense Convolutional Neural Networks Huang et al. (2016) are another type of network that makes use of shortcuts, with the difference that each layer is connected to all its ancestor layers directly by a shortcut. Similarly, these could be also unfolded into an equivalent ensemble. True ensemble methods are often left as an afterthought in Deep Learning models: it is generally considered sufficient to treat the Deep Learning method as a “black-box” and use a well-known generic Ensemble method to obtain marginal improvements on the original results. Whilst this is an effective way of improving on existing results without much additional effort, we find that it can amount to a waste of computations. Instead, it would be much better to apply an Ensemble method that is aware, and makes us of, the underlying Deep Learning algorithm’s architecture. We define such methods as “white-box” Ensembles, which allow us to improve on the generalisation and training speed compared to traditional Ensembles, by making use of particular properties of the base classifier’s learning algorithm ",Deep residual learning for image recognition | Delving deep into rectifiers: Surpassing human-level performance on imagenet classification | Identity mappings in deep residual networks | Densely connected convolutional networks | Deep incremental boosting | Training convolutional networks with weight-wise adaptive learning rates | Regularizing deep learning ensembles by distillation | The strength of weak learnability | Residual Networks Behave Like Ensembles of Relatively Shallow Networks | How transferable are features in deep neural networks,iclr,010
684.pdf.json,MULTI-TASK LEARNING WITH DEEP MODEL BASED REINFORCEMENT LEARNING,"Recently, there has been a lot of success in applying neural networks to reinforcement learning, achieving super-human performance in many ATARI games (Mnih et al. (2015); Mnih et al. (2016)). Most of these algorithms are based on Q-learning, which is a model free approach to reinforcement learning. This approaches learn which actions to perform in each situation, but do not learn an explicit model of the environment. Apart from that, learning to play multiple games simultaneously remains an open problem as these approaches heavily degrade when increasing the number of tasks to learn. In contrast, we present a model based approach that can learn multiple tasks simultaneously. The idea of learning predictive models has been previously proposed (Schmidhuber (2015); Santana & Hotz (2016)), but all of them focus on learning the predictive models in an unsupervised way. We propose using the reward as a means to learn a representation that captures only that which is important for the game. This also allows us to do the training in a fully supervised way. In the experiments, we show that our approach can surpass human performance simultaneously on three different games. In fact, we show that transfer learning occurs and it benefits from learning multiple tasks simultaneously. In this paper, we first discuss why Q-learning fails to learn multiple tasks and what are its drawbacks. Then, we present our approach, Predictive Reinforcement Learning, as an alternative to overcome those weaknesses. In order to implement our model, we present a recurrent neural network architecture based on residual nets that is specially well suited for our task. Finally, we discuss our experimental results on several ATARI games. 2 PREVIOUS WORK: DEEP Q-LEARNING In recent years, approaches that use Deep Q-learning have achieved great success, making an important breakthrough when Mnih et al. (2015) presented a neural network architecture that was able to achieve human performance on many differe","The arcade learning environment: An evaluation platform for general agents | Deep Residual Learning for Image Recognition | Long Short-Term Memory | Batch normalization: Accelerating deep network training by reducing internal covariate | Deep visual-semantic alignments for generating image descriptions | Adam: A method for stochastic optimization | Human-level control through deep reinforcement learning | Asynchronous Methods for Deep Reinforcement Learning | Actor-Mimic: Deep Multitask and Transfer | Learning a Driving Simulator. arXiv, 2016 | On Learning to Think: Algorithmic Information Theory for Novel Combinations of Reinforcement Learning Controllers and Recurrent | Understanding Neural Networks",iclr,010
685.pdf.json,OPENING THE VOCABULARY OF NEURAL LANGUAGE MODELS WITH CHARACTER-LEVEL WORD REPRESEN- TATIONS,"Most of neural language models, such as n-gram models Bengio et al. (2003) are word based and rely on the definition of a finite vocabulary V . As a consequence, a Look-up table is associated to V in which each word w ∈ V is mapped to a vector of dE real valued features stored in a matrix L ∈ R|V|∗dE . While this approach has proven successful for a variety of tasks and languages, see for instance Schwenk (2007) in speech recognition and Le et al. (2012); Devlin et al. (2014); Bahdanau et al. (2014) in machine translation, it induces several limitations. For morphologically-rich languages, like Czech or German, the lexical coverage is still an important issue, since there is a combinatorial explosion of word forms, most of which are hardly observed on training data. On the one hand, growing the Look-up table is not a solution, since it would increase the number of parameters without having enough training example for a proper estimation. On the other hand, rare words can be replaced by a special token. Nevertheless, this acts as a word class merging very different words without any distinction and using different word classes to handle outof-vocabulary words Allauzen & Gauvain (2005) does not really solve this issue, since rare words are difficult to classify. Moreover, for most inflected or agglutinative forms, as well as for compound words, the word structure is overlooked, wasting parameters for modeling forms that could be more efficiently handled by word decomposition. While the use of subword units Botha & Blunsom (2014); Sennrich et al. (2016) could improve the generalization power of such models, it relies on a proper and efficient method to induce these subword units. To overcome these issues, we propose to investigate a word based language model with an open vocabulary. Since most of existing models and training criteria rely on the assumption of a finite vocabulary, the definition of an open vocabulary model, along with a training criterion, constitutes a","Open vocabulary asr for audiovisual document indexation | Neural machine translation by jointly learning to align and translate | Improved transition-based parsing by modeling characters instead of words with lstms | Quick training of probabilistic neural nets by importance sampling | A neural probabilistic language model | Compositional Morphology for Word Representations and Language Modelling | Strategies for training large vocabulary neural language models. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016 | Batch tuning strategies for statistical machine translation. In Proceedings of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT) | Natural language processing (almost) from scratch | N-code: an open-source Bilingual N-gram SMT Toolkit | Fast and robust neural network joint models for statistical machine translation | Adaptive subgradient methods for online learning and stochastic optimization | Generating sequences with recurrent neural networks | Hybrid speech recognition with deep bidirectional LSTM | Noise-contrastive estimation of unnormalized statistical models, with applications to natural image statistics | Exploring the limits of language modeling | Character-aware neural language models | Non-lexical neural architecture for finegrained pos tagging | Neural architectures for named entity recognition | Structured output layer neural network language model | Continuous space translation models with neural networks. In Proceedings of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT) | Finding function in form: Compositional character models for open vocabulary word representation | Achieving open vocabulary neural machine translation with hybrid word-character models | Deep neural language models for machine translation | Limsi@wmt’15 : Translation task | Subword language modeling with neural networks | A scalable hierarchical distributed language model | A fast and simple algorithm for training neural probabilistic language models | Learning character-level representations for part-of-speech tagging | Continuous space language models | Neural machine translation of rare words with subword units | Generating text with recurrent neural networks | Decoding with large-scale neural language models improves translation | Readings in Speech Recognition, chapter Phoneme Recognition Using Time-delay Neural Networks, pp. 393–404 | Text understanding from scratch",iclr,010
686.pdf.json,HFH: HOMOLOGICALLY FUNCTIONAL HASHING FOR COMPRESSING DEEP NEURAL NETWORKS,"Deep Neural networks (DNNs) have been receiving ubiquitous success in wide applications, ranging from computer vision (Krizhevsky et al., 2012), to speech recognition (Hinton et al., 2012), natural language processing (Collobert et al., 2011), and domain adaptation (Glorot et al., 2011). As the sizes of data mount up, people usually have to increase the number of parameters in DNNs so as to absorb the vast volume of supervision. High performance computing techniques are studied to speed up training, concerning optimization algorithms, parallel synchronisations on clusters w/o GPUs, and stochastic binarization/ternarization, etc (Courbariaux et al., 2015; Dettmers, 2016; Lin et al., 2016). On the other hand the memory and energy consumption is usually, if not always, constrained in industrial applications (Kim et al., 2016; Yang et al., 2015). For instance, for commercial search engines (e.g., Google and Baidu) and recommendation systems (e.g., NetFlix and YouTube), the ratio between the increased model size and the improved performance should be considered given limited online resources. Compressing the model size becomes more important for applications on mobile and embedded devices (Han et al., 2016; Kim et al., 2016). Having DNNs running on mobile apps owns many great features such as better privacy, less network bandwidth and real time processing. However, the energy consumption of battery-constrained mobile devices is usually dominated by memory access, which would be greatly saved if a DNN model can fit in on-chip storage rather than DRAM storage (c.f. Han et al. (2016) for details). A recent trend of studies are thus motivated to focus on compressing the size of DNNs while mostly keeping their predictive performance (Han et al., 2016; Kim et al., 2016; Yang et al., 2015). With different intuitions, there are mainly two types of DNN compression methods, which could be used in conjunction for better parameter savings. The first type tries to revise the training","Neural Networks for Pattern Recognition | Pattern Recognition and Machine Learning | Multilevel adaptive hashing | Using multiple hash functions to improve IP lookups | Compressing neural networks with the hashing trick | Compressing convolutional neural networks | Natural language processing (almost) from scratch | An improved data stream summary: The Count-Min sketch and its application | BinaryConnect: Training deep neural networks with binary weights during propagations | Predicting parameters in deep learning | Exploiting linear structure within convolutional networks for efficient evaluation | 8-bit approximations for parallelism in deep learning | Domain adaptation for large scale sentiment classification: a deep learning approach | Sketch algorithms for estimating point queries in NLP | Dynamic network surgery for efficient dnns | Learning both weights and connections for efficient neural networks | Deep compression: Compressing deep neural networks with pruning, trained quantization and Huffman coding | Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups | Distilling the knowledge in a neural network | Learning deep structured semantic models for web search using clickthrough data | Deep learning to hash with multiple representations | Compression of deep convolutional neural networks for fast and low power mobile applications | Learning multiple layers of features from tiny images | Imagenet classification with deep convolutional neural networks | Learning to hash with binary reconstructive embeddings | An empirical evaluations of deep architectures on problems with many factors of variation | Fastfood – approximating kernel expansions in loglinear time | Neural networks with few multiplications | Rectified linear units improve restricted Boltzmann machines | Sparse feature learning for deep belief networks | A latent semantic model with convolutional-pooling structure for information retrieval | Hash kernels for structured data | Learning to hash for indexing big data – a survey | Feature hashing for large scale multitask learning | Milestones in Systematics | Deep fried convnets",iclr,010
687.pdf.json,THE INCREDIBLE SHRINKING NEURAL NETWORK: NEW PERSPECTIVES,"In this work we propose and evaluate a novel algorithm for pruning whole neurons from a trained neural network without any re-training and examine its performance compared to two simpler methods. We then analyze the kinds of errors made by our algorithm and use this as a stepping off point to launch an investigation into the fundamental nature of learning representations in neural networks. Our results corroborate an insightful though largely forgotten observation by Mozer & Smolensky (1989a) concerning the nature of neural network learning. This observation is best summarized in a quotation from Segee & Carter (1991) on the notion of fault-tolerance in multilayer perceptron networks: Contrary to the belief widely held, multilayer networks are not inherently fault tolerant. In fact, the loss of a single weight is frequently sufficient to completely disrupt a learned function approximation. Furthermore, having a large number of weights does not seem to improve fault tolerance. [Emphasis added] Essentially, Mozer & Smolensky (1989b) observed that during training neural networks do not distribute the learning representation evenly or equitably across hidden units. What actually happens is that a few, elite neurons learn an approximation of the input-output function, and the remaining units must learn a complex interdependence function which cancels out their respective influence on the network output. Furthermore, assuming enough units exist to learn the function in question, increasing the number of parameters does not increase the richness or robustness of the learned approximation, but rather simply increases the likelihood of overfitting and the number of noisy parameters to be canceled during training. This is evinced by the fact that in many cases, multiple neurons can be removed from a network with no re-training and with negligible impact on the quality of the output approximation. In other words, there are few bipartisan units in a trained network. A unit is t","Weight quantization in boltzmann machines | What size net gives valid generalization | Generalization performance of overtrained back-propagation networks | The effects of quantization on multilayer neural networks | The cascade-correlation learning architecture | Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding | Second order derivatives for network pruning: Optimal brain surgeon | Learning with limited numerical precision using the cascade-correlation algorithm | Optimal brain damage | Skeletonization: A technique for trimming the fat from a network via relevance assessment | Using relevance to reduce network size automatically | Reducing communication overhead in distributed learning by an order of magnitude (almost) | On the compression of recurrent neural networks with an application to lvcsr acoustic modeling for embedded speech recognition | Pruning algorithms-a survey | Fault tolerance of pruned multilayer networks | Dropout: A simple way to prevent neural networks from overfitting",iclr,010
688.pdf.json,,"Recently, reinforcement learning has seen a surge in popularity, in part because of its successes in playing Atari games (Mnih et al., 2013) and Go (Silver et al., 2016). Due to its ability to act in settings where the actions taken influence the environment and, more generally, the input distribution of examples, reinforcement learning is now used in other domains, such as online advertising. The goal is to learn a good policy, i.e. a good mapping from states to actions, which will maximize the final score, in the case of Atari games, the probability of winning, in Go, or the number of sales, in online advertising. We have at our disposal logs of past events, where we know the states we were in, the actions we took and the resulting rewards we obtained. In this paper, we shall focus on how to efficiently use these logs to obtain a good policy. In some cases, in addition to (state, action, reward) triplets, we have access to a teacher which provides the optimal, or at least a good, action for a given state. The use of such a teacher to find a good initial policy is outside the scope of this paper. There are many ways to learn good policies using past data. The two most popular are Q-learning and direct policy optimization. In Q-learning (Sutton & Barto, 1998), we are trying to learn a mapping from a (state, action) pair to the reward. Given this mapping and a state, we can then find the action which leads to the maximal predicted reward. This method has been very successful, especially when the action space is small, since we need to test all the actions, and the reward somewhat predictable, since taking the maximum is unstable and a small error can lead to suboptimal actions. Direct policy optimization, rather than trying to estimate the value of a (state, action) pair, directly parameterizes a policy, i.e. a conditional distribution over actions given the current state. More precisely, and using the notation from Kober (2014), we wish to maximize the expected retu","Natural gradient works efficiently in learning | Using expectation-maximization for reinforcement learning | Maximum likelihood from incomplete data via the em algorithm. Journal of the royal statistical society | Doubly robust policy evaluation and learning | Continuous deep q-learning with model-based acceleration | On a connection between importance sampling and the likelihood ratio policy gradient | A natural policy gradient | Learning motor skills: from algorithms to robot experiments | Policy search for motor primitives in robotics | Continuous control with deep reinforcement learning | On the limited memory bfgs method for large scale optimization | Playing atari with deep reinforcement learning | Variational inference for policy search in changing situations | Reinforcement learning by reward-weighted regression for operational space control | Gradient estimation using stochastic computation graphs. CoRR, abs/1506.05254, 2015a. URL http://arxiv.org/ abs/1506.05254 | Highdimensional continuous control using generalized advantage estimation | Mastering the game of go with deep neural networks and tree | Reinforcement learning: An introduction, volume 1 | Policy gradient methods for reinforcement learning with function approximation | Counterfactual risk minimization: Learning from logged bandit feedback",iclr,010
689.pdf.json,TENSORIAL MIXTURE MODELS,"Generative models have played a crucial part in the early development of the field of Machine Learning. However, in recent years they were mostly cast aside in favor of discriminative models, lead by the rise of ConvNets (LeCun et al., 2015), which were found to perform equally well or better than classical generative counter-parts on almost any task. Despite the increased interest in unsupervised learning, many of the recent studies on generative models choose to focus solely on the generation capabilities of these models (Goodfellow et al., 2014; Gregor et al., 2015; van den Oord et al., 2016; Dinh et al., 2016; Tran et al., 2016; Chen et al., 2016; Kingma et al., 2016; Kim and Bengio, 2016). There is much less emphasis on leveraging generative models to solve actual tasks, e.g. semi-supervised learning (Kingma et al., 2014; Springenberg, 2016; Maaløe et al., 2016; Forster et al., 2015; Salimans et al., 2016), image restoration (Dinh et al., 2014; Bengio et al., 2014; van den Oord et al., 2016; Zoran and Weiss, 2011; Rosenbaum and Weiss, 2015; Sohl-Dickstein et al., 2015; Theis and Bethge, 2015) or unsupervised feature representation (Radford et al., 2016; Coates et al., 2011). Nevertheless, work on generative models for solving actual problems are yet to show a meaningful advantage over competing discriminative models. On the most fundamental level, the difference between a generative model and a discriminative one is simply the difference between learning P (X,Y ) and learning P (Y |X), respectively. While it is always possible to infer P (Y |X) given P (X,Y ), it might not be immediately apparent why the generative objective is preferred over the discriminative one. In Ng and Jordan (2002), this question was studied w.r.t. the sample complexity, proving that under some cases it can be significantly lesser in favor of the generative classifier. However, their analysis was limited only to specific pairs of discriminative and generative classifiers, and they did n","Learning the Structure of Sum-Product Networks via an SVD-based Algorithm | Tensor decompositions for learning latent variable models | Memory Access Patterns: The Missing Piece of the Multi-GPU Puzzle | Deep Generative Stochastic Networks Trainable by Backprop | Latent dirichlet allocation | The Zero Set of a Polynomial | InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets | An Analysis of Single-Layer Networks in Unsupervised Feature Learning | SimNets: A Generalization of Convolutional Networks | Convolutional Rectifier Networks as Generalized Tensor Decompositions | Inductive Bias of Deep Convolutional Networks through Pooling Geometry. arXiv.org, May 2016b | On the Expressive Power of Deep Learning: A Tensor Analysis | Deep SimNets. In Computer Vision and Pattern Recognition CVPR, May 2016b | Learning to classify with missing and corrupted features | NICE: Non-linear Independent Components Estimation | Density estimation using Real NVP | Neural Simpletrons - Minimalistic Probabilistic Networks for Learning With Few Labels | Learning the Structure of Sum-Product Networks | Discriminative Learning of Sum-Product Networks | Nightmare at test time: robust learning by feature deletion | Multi-Prediction Deep Boltzmann Machines | Generative Adversarial Nets | DRAW: A Recurrent Neural Network For Image Generation | A New Scheme for the Tensor Representation | Probabilistic latent semantic analysis | Scalable Latent Tree Model and its Application to Health Analytics | Caffe: Convolutional Architecture for Fast Feature Embedding | Deep Directed Generative Models with Energy-Based Probability Estimation | Adam: A Method for Stochastic Optimization | Auto-Encoding Variational Bayes | Semi-Supervised Learning with Deep Generative Models | Improving Variational Inference with Inverse Autoregressive Flow | Gradient-based learning applied to document recognition | A Bayesian Hierarchical Model for Learning Natural Scene Categories | Statistical analysis with missing data (2nd edition) | Auxiliary Deep Generative Models | Adversarial Autoencoders | A Survey on Latent Tree Models and Applications | On Discriminative vs. Generative Classifiers: A comparison of logistic regression and naive Bayes | Context Encoders: Feature Learning by Inpainting | Scikit-learn: Machine Learning in Python | Greedy Part-Wise Learning of Sum-Product Networks. In Machine Learning and Knowledge Discovery in Databases, pages 612–627 | Sum-Product Networks: A New Deep Architecture | Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks | Learning Sum-Product Networks with Direct and Indirect Variable Interactions | The return of the gating network: combining generative models and discriminative training in natural image priors | Inference and missing data | Under review as a conference paper at ICLR | Deep Unsupervised Learning using Nonequilibrium Thermodynamics | Hierarchical Tensor Decomposition of Latent Tree Graphical Models | Unsupervised and Semi-supervised Learning with Categorical Generative Adversarial Networks | DeepFace: Closing the Gap to HumanLevel Performance in Face Verification | Generative Image Modeling Using Spatial LSTMs | The Variational Gaussian Process | Pixel Recurrent Neural Networks | Spatial Latent Dirichlet Allocation | Visualizing and Understanding Convolutional Networks | Hierarchical Latent Class Models for Cluster Analysis | From learning models of natural image patches to whole image restoration | 2016a) as a theoretical framework for studying standard convolutional networks, sharing many of the defining traits of the latter, most noteworthy, the locality, sharing and pooling properties of ConvNets. Unlike general circuits, the structure of the network is determined solely by two parameters, the number of channels of each conv layer and the size of pooling windows, which indirectly controls the depth of the network | 2016a), our main proof relies on following notations and facts: • We denote by [A] the matricization of an N -order tensor A",iclr,010
690.pdf.json,AN ANALYSIS OF DEEP NEURAL NETWORK MODELS FOR PRACTICAL APPLICATIONS,"Since the breakthrough in 2012 ImageNet competition (Russakovsky et al., 2015) achieved by AlexNet (Krizhevsky et al., 2012) — the first entry that used a Deep Neural Network (DNN) — several other DNNs with increasing complexity have been submitted to the challenge in order to achieve better performance. In the ImageNet classification challenge, the ultimate goal is to obtain the highest accuracy in a multi-class classification problem framework, regardless of the actual inference time. We believe that this has given rise to several problems. Firstly, it is now normal practice to run several trained instances of a given model over multiple similar instances of each validation image. This practice, also know as model averaging or ensemble of DNNs, dramatically increases the amount of computation required at inference time to achieve the published accuracy. Secondly, model selection is hindered by the fact that different submissions are evaluating their (ensemble of) models a different number of times on the validation images, and therefore the reported accuracy is biased on the specific sampling technique (and ensemble size). Thirdly, there is currently no incentive in speeding up inference time, which is a key element in practical applications of these models, and affects resource utilisation, power-consumption, and latency. This article aims to compare state-of-the-art DNN architectures, submitted for the ImageNet challenge over the last 4 years, in terms of computational requirements and accuracy. We compare these architectures on multiple metrics related to resource utilisation in actual deployments: accuracy, memory footprint, parameters, operations count, inference time and power consumption. The purpose of this paper is to stress the importance of these figures, which are essential hard constraints for the optimisation of these networks in practical deployments and applications.","cuDNN: Efficient Primitives for Deep Learning | Torch7: A matlab-like environment for machine learning | Training enet. https://culurciello.github.io/tech/2016/06/20/ training-enet.html, 2016 | Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding | Deep residual learning for image recognition | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | Enet: A deep neural network architecture for real-time semantic segmentation | Imagenet large scale visual recognition challenge | Very deep convolutional networks for large-scale image recognition | Going deeper with convolutions | Rethinking the inception architecture for computer vision | Inception-v4, inception-resnet and the impact of residual connections on learning",iclr,010
691.pdf.json,,"Controlling artificial agents using only raw high-dimensional input data such as image or sound is a difficult and important task in the field of Reinforcement Learning (RL). Recent breakthroughs in the field allow its utilization in real-world applications such as autonomous driving (Shalev-Shwartz et al., 2016), navigation (Bischoff et al., 2013) and more. Agent interaction with the real world is usually either expensive or not feasible, as the real world is far too complex for the agent to perceive. Therefore in practice the interaction is simulated by a virtual environment which receives feedback on a decision made by the algorithm. Traditionally, games were used as a RL environment, dating back to Chess (Campbell et al., 2002), Checkers (Schaeffer et al., 1992), backgammon (Tesauro, 1995) and the more recent Go (Silver et al., 2016). Modern games often present problems and tasks which are highly correlated with real-world problems. For example, an agent that masters a racing game, by observing a simulated driver’s view screen as input, may be usefull for the development of an autonomous driver. For high-dimensional input, the leading benchmark is the Arcade Learning Environment (ALE) (Bellemare et al., 2013) which provides a common interface to dozens of Atari 2600 games, each presents a different challenge. ALE provides an extensive benchmarking platform, allowing a controlled experiment setup for algorithm evaluation and comparison. The main challenge posed by ALE is to successfully play as many Atari 2600 games as possible (i.e., achieving a score higher than an expert human player) without providing the algorithm any game-specific information (i.e., using the same input available to a human - the game screen and score). A key work to tackle this problem is the Deep Q-Networks algorithm (Mnih et al., 2015), which made a breakthrough in the field of Deep Reinforcement Learning by achieving human level performance on 29 out of 49 games. In this work we present",The arcade learning environment: An evaluation platform for general agents | Unifying countbased exploration and intrinsic motivation | Hierarchical reinforcement learning for robot navigation | Multi-agent reinforcement learning: An overview | Improving elevator performance using reinforcement learning | An empirical investigation of catastrophic forgetting in gradient-based neural networks | The malmo platform for artificial intelligence experimentation | Markov games as a framework for multi-agent reinforcement learning | Value-function reinforcement learning in markov games | Reinforcement learning in the multi-robot domain | Human-level control through deep reinforcement learning | A world championship caliber checkers program | Long-term planning by short-term prediction | Mastering the game of go with deep neural networks and tree | Temporal difference learning and td-gammon | Super mario evolution | Deep reinforcement learning with double q-learning | Dueling network architectures for deep reinforcement learning | Target-driven visual navigation in indoor scenes using deep reinforcement learning,iclr,010
692.pdf.json,,"Sentiment classification, a key problem in sentiment analysis, has drawn lots of interest since 2000s (Pang & Lee, 2008). Traditional machine learning based methods often use one-hot features to represent a text. In these methods, each word (or n-gram) is treated as an independent token, and a text is represented as the words within. Though convenient intuitively, these methods cannot model the semantic dependencies between words, and often lead to the curse of dimensionality problem. Neural models have shown their great performance in learning representation. Bengio et al. (2003) proposed the feed forward neural network language model. Ever since, many neural network based models have been widely used in many natural language processing (NLP) tasks, such as named entity recognization (Collobert & Weston, 2008), machine translation (Cho et al., 2014) and sentiment analysis (dos Santos & Gatti, 2014). Compared to one-hot representation, words are represented as distributed, dense vectors (also called word embeddings) in these neural models. Mikolov et al. (2013b) showed that, through proper training, these vectors can model syntactic and semantic relationships between words. More importantly, these vectors can be calculated naturally, which leads to another problem — semantic composition. For many NLP tasks, we often face the problem of representing a sentence or paragragh using word embeddings of its containing words. Simply methods such as concatenation or weighted sum cannot give us satisfactory results. Many neural models, such as recursive neural network (Socher et al., 2011), recurrent neural network (Mikolov et al., 2010) and convolutional neural networks (Collobert & Weston, 2008) have been proposed to solve this problem. Since a sentence or paragraph is naturally a sequence of word tokens, recurrent neural networks (RNN) can be used to composite word embeddings into a sentence or paragraph embedding. Recurrent networks utilize special units which are connect","Neural machine translation by jointly learning to align and translate | A neural probabilistic language model | Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification | Learning phrase representations using rnn encoder-decoder for statistical machine translation | A unified architecture for natural language processing: Deep neural networks with multitask learning | Deep convolutional neural networks for sentiment analysis of short texts | Neural networks. In Supervised Sequence Labelling with Recurrent Neural Networks, pp. 15–35 | Gradient flow in recurrent nets: the difficulty of learning | Improving word representations via global context and multiple word prototypes | Convolutional neural networks for sentence classification | Recurrent convolutional neural networks for text classification | Distributed representations of sentences and documents | When are tree structures necessary for deep learning of representations | Sentiment analysis and opinion mining | Learning word vectors for sentiment analysis | Recurrent neural network based language model | Efficient estimation of word representations in vector space | Distributed representations of words and phrases and their compositionality | Three new graphical models for statistical language modelling | A scalable hierarchical distributed language model | Opinion mining and sentiment analysis | Thumbs up?: sentiment classification using machine learning techniques | Glove: Global vectors for word representation | Reasoning about entailment with neural attention | Neural attention models for sequence classification: Analysis and application to key term extraction and dialogue act detection | Semi-supervised recursive autoencoders for predicting sentiment distributions | Semantic compositionality through recursive matrix-vector spaces | Recursive deep models for semantic compositionality over a sentiment treebank | Learning semantic representations of users and products for document level sentiment classification | Aspect level sentiment classification with deep memory network | Lecture 6.5-rmsprop, coursera: Neural networks for machine learning | Show, attend and tell: Neural image caption generation with visual attention | A sensitivity analysis of (and practitioners’ guide to) convolutional neural networks for sentence classification",iclr,010
693.pdf.json,GENERATIVE MATCHING NETWORKS,"Deep generative models are currently one of the most promising directions in generative modelling. In this class of models the generative process is defined by a composition of conditional distributions modelled using deep neural networks which form a hierarchy of latent and observed variables. This approach allows to build models with complex, non-linear dependencies between variables and efficiently learn the variability across training examples. Such models are trained by stochastic gradient methods which can handle large datasets and a wide variety of model architectures but also present certain limitations. The training process usually consists of small, incremental updates of networks’ parameters and requires many passes over training data. Notably, once a model is trained it cannot be adapted to newly available data without complete re-training to avoid catastrophic interference (McCloskey & Cohen, 1989; Ratcliff, 1990). There is also a risk of overfitting for concepts that are not represented by enough training examples which is caused by high capacity of the models. Hence, most of deep generative models are not well-suited for rapid learning in one-shot scenario which is often encountered in real-world applications where data acquisition is expensive or fast adaptation to new data is required. A potential solution to these problems is explicit learning of adaptation mechanisms complementing the shared generative process. In probabilistic modelling framework, adaptation may be expressed as conditioning the model on additional input examples serving as induction bias. Notable steps in this direction have been made by Rezende et al. (2016) whose model was able to condition on a single object to produce new examples of the concept it represents. Later, Edwards & Storkey (2016) proposed a model that maintained a global latent variable capturing statistics about multiple input objects which was used to condition the generative distribution. It allowed to implemen","Curriculum learning | Importance weighted autoencoders | Finite exchangeable sequences | Towards a neural statistician | Amortized inference in probabilistic reasoning | Generative adversarial nets | Noise-contrastive estimation of unnormalized statistical models, with applications to natural image statistics | Delving deep into rectifiers: Surpassing human-level performance on imagenet classification | Learning to learn using gradient descent | An introduction to variational methods for graphical models | Auto-encoding variational bayes | Human-level concept learning through probabilistic program induction | Catastrophic interference in connectionist networks: The sequential learning problem | Connectionist models of recognition memory: constraints imposed by learning and forgetting functions | Stochastic backpropagation and approximate inference in deep generative models | Oneshot generalization in deep generative models | Learning with hierarchicaldeep models | Oneshot learning with memory-augmented neural networks | Lifelong learning algorithms | A perspective view and survey of meta-learning | Order matters: Sequence to sequence for sets | Matching networks for one shot learning",iclr,010
694.pdf.json,LIPNET: END-TO-END SENTENCE-LEVEL LIPREADING,"Lipreading plays a crucial role in human communication and speech understanding, as highlighted by the McGurk effect (McGurk & MacDonald, 1976), where one phoneme’s audio dubbed on top of a video of someone speaking a different phoneme results in a third phoneme being perceived. Lipreading is a notoriously difficult task for humans, specially in the absence of context1. Most lipreading actuations, besides the lips and sometimes tongue and teeth, are latent and difficult to disambiguate without context (Fisher, 1968; Woodward & Barber, 1960). For example, Fisher (1968) gives 5 categories of visual phonemes (called visemes), out of a list of 23 initial consonant phonemes, that are commonly confused by people when viewing a speaker’s mouth. Many of these were asymmetrically confused, and observations were similar for final consonant phonemes. Consequently, human lipreading performance is poor. Hearing-impaired people achieve an accuracy of only 17±12% even for a limited subset of 30 monosyllabic words and 21±11% for 30 compound words (Easton & Basala, 1982). An important goal, therefore, is to automate lipreading. Machine lipreaders have enormous practical potential, with applications in improved hearing aids, silent dictation in public spaces, security, speech recognition in noisy environments, biometric identification, and silent-movie processing. Machine lipreading is difficult because it requires extracting spatiotemporal features from the video (since both position and motion are important). Recent deep learning approaches attempt to extract those features end-to-end. Most existing work, however, performs only word classification, not sentence-level sequence prediction. †These authors contributed equally to this work. 1LipNet video: https://youtube.com/playlist?list=PLXkuFIFnXUAPIrXKgtIpctv2NuSo7xw3k In this paper, we present LipNet, which is to the best of our knowledge, the first end-to-end sentence-level lipreading model. As with modern deep learning based auto","Improved speaker independent lip reading using speaker adaptive training and deep neural networks | Deep Speech 2: End-to-end speech recognition in English and Mandarin | Understanding phonetics | Lip reading in the wild | Out of time: automated lip sync in the wild | Empirical evaluation of gated recurrent neural networks on sequence modeling | An audio-visual corpus for speech perception and automatic speech recognition | Gimson’s pronunciation of English | Context-dependent pre-trained deep neural networks for largevocabulary speech recognition | The story of lip-reading, its genesis and development | Perceptual dominance during lipreading | Formant frequencies of vowels in 13 accents of the british isles | Confusions among visually perceived consonants | Classification and feature extraction by simplexization | Lip reading using CNN and LSTM | Dynamic stream weighting for turbodecoding-based audiovisual ASR | Continuous automatic speech recognition by lipreading | Towards end-to-end speech recognition with recurrent neural networks | Framewise phoneme classification with bidirectional LSTM and other neural network architectures | Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks | Information theoretic feature extraction for audio-visual speech recognition | Delving deep into rectifiers: Surpassing human-level performance on imagenet classification | Comparison of human and machine-based lip-reading | Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups | Long short-term memory | Temporal multimodal learning in audiovisual speech recognition | 3d convolutional neural networks for human action recognition | Large-scale video classification with convolutional neural networks | Dlib-ml: A machine learning | Adam: A method for stochastic optimization | Deep learning of mouth shapes for sign language | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | Patch-based representation of visual speech | Lexicon-free conversational speech recognition with neural networks | Extraction of visual features for lipreading | Hearing lips and seeing | Audio visual speech recognition | Multimodal deep learning | Integration of deep bottleneck features for audio-visual speech recognition | Lipreading using convolutional neural network | Multimodal fusion and learning with uncertain features applied to audiovisual speech recognition | Adaptive multimodal fusion by uncertainty compensation with application to audiovisual speech recognition | Deep complementary bottleneck features for visual speech recognition | Adaptive multimodal fusion by uncertainty compensation | Recent advances in the automatic recognition of audiovisual speech | 300 faces in-the-wild challenge: The first facial landmark localization challenge | Deep inside convolutional networks: Visualising image classification models and saliency maps | Striving for simplicity: The all convolutional net | Listening with your eyes: Towards a practical visual speech recognition system using deep boltzmann machines | Audio-visual speech recognition using bimodal-trained bottleneck features for a person with severe hearing | Lipreading with long short-term memory | Phoneme perception in lipreading | Visualizing and understanding convolutional networks | Lipreading with local spatiotemporal descriptors | A review of recent advances in visual speech decoding | Under review as a conference paper at ICLR 2017 B PHONEMES AND VISEMES Table 4 shows the phoneme to viseme clustering of Neti et al. (2000) and Figure 4 shows LipNet’s full phoneme confusion matrix. Table 4: Phoneme to viseme clustering",iclr,010
695.pdf.json,,"Neural networks and deep learning recently achieved state-of-the-art solutions to many problems in computer vision (Krizhevsky et al. (2012); He et al. (2015)), speech recognition (Graves et al. (2013)), natural language processing (Mikolov et al. (2013)) and reinforcement learning (Silver et al. (2016)). Using large and oversized networks in these tasks is a common practice. Such oversized networks can easily overfit on the training dataset while having poor generalization on the testing data (Sabo & Yu (2008)). A rule of thumb for obtaining useful generalization is to use the smallest number of parameters that can fit the training data (Reed (1993)). Unfortunately, this optimal size is not usually obvious and therefore the size of the neural networks is determined by a few rules-of-thumb (Heaton (2008)) which do not guarantee an optimal size for a given problem. One common approach to overcome overfitting is to choose an over-sized network and then apply regularization (Ng (2004)) and Dropout (Srivastava et al. (2014)). However, these techniques do not reduce the number of parameters and therefore do not resolve the high demand of resources at test time. Another method is to start with an oversized network and then use pruning algorithms to remove redundant parameters while maintaining the network’s accuracy (Augasta & Kathirvalavakumar (2013)). These methods need to estimate the upper-bound size of a network, a task for which there are adequate estimation methods (Xing & Hu (2009)). If the size of a neural network is bigger than what is necessary, in theory, it should be possible to remove some of the extra neurons without affecting its accuracy. To achieve this goal, the pruning algorithm should find neurons which once removed result into no additional prediction errors. However, this may not be as easy as it sounds since all the neurons contribute to the final prediction and removing them usually leads to error. It is easy to demonstrate this problem by fitting","Pruning algorithms of neural networks—a comparative study | Compressing neural networks with the hashing trick | An exploration of parameter redundancy in deep networks with circulant projections | Speech recognition with deep recurrent neural networks | Learning both weights and connections for efficient neural network | Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding | Comparing biases for minimal network construction with backpropagation | Second order derivatives for network pruning: Optimal brain surgeon | Deep residual learning for image recognition | Introduction to neural networks with Java | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | Optimal brain damage | Gradient-based learning applied to document recognition | Efficient estimation of word representations in vector space | Feature selection, l 1 vs. l 2 regularization, and rotational invariance | Pruning algorithms-a survey | A new pruning algorithm for neural network dimension analysis | Mastering the game of go with deep neural networks and tree | Dropout: A simple way to prevent neural networks from overfitting | Going deeper with convolutions | Two-phase construction of multilayer perceptrons using information theory | Deep fried convnets",iclr,010
696.pdf.json,,"Reading comprehension is a type of question answering task where the answer is to be found in a passage about particular entities and events not otherwise familiar to the reader. In particular, the entities and events should not be mentioned in structured databases of general knowledge. Reading comprehension problems are intended to measure a systems ability to extract semantic information about entities and relations directly from unstructured text. Several large scale reading comprehension datasets have been introduced recently. In particular the CNN & DailyMail datasets (Hermann et al., 2015), the Children’s Book Test (CBT) (Hill et al., 2016), and the Who-did-What dataset (Onishi et al., 2016). The large sizes of these datasets enable the application of deep learning. These are all cloze-style datasets where a question is constructed by deleting a word or phrase from an article summary (in CNN/DailyMail), from a sentence in a Children’s story (in CBT), or by deleting a person from the first sentence of a different news article on the same entities and events (in Who-did-What). In this paper we present empirical evidence for the emergence of predication structure in a certain class of neural readers. To understand predication structure is it helful to review the anonymization performed in the CNN/DailyMail dataset. In this dataset named entities are replaced by anonymous entity identifiers such as “entity37”. The passage might contain “entity52 gave entity24 a rousing applause” and the question might be “X received a rounding applause from entity52”. The task is to fill in X from a given multiple choice list of candidate entity identifiers. A fixed relatively small set of the same entity identifiers are used over all the problems and the same problem is presented many times with the entity identifiers shuffled. This prevents a given entity identifier from having any semantically meaningful vector embedding. The embeddings of the entity identifiers are ∗Authors co","A thorough examination of the cnn/daily mail reading comprehension task | Broad context language modeling as reading comprehension | Attention-overattention neural networks for reading comprehension | English gigaword ldc2003t05 | The lambada dataset: Word prediction requiring a broad discourse context | Gated-attention readers for text comprehension | Teaching machines to read and comprehend | The goldilocks principle: Reading childrens books with explicit memory representations | Glove: Global vectors for word representation | Text understanding with the attention sum reader network | Adam: A method for stochastic optimization | Dynamic entity representation with max-pooling improves machine reading | Reasoning in vector space: An exploratory study of question answering | Reasoning with memory augmented neural networks for language comprehension | Who did what: A large-scale person-centered cloze dataset | Squad: 100,000+ questions for machine comprehension of text | On the difficulty of training recurrent neural networks | Mctest: A challenge dataset for the open-domain machine comprehension of text | Exact solutions to the nonlinear dynamics of learning in deep linear neural networks | Reasonet: Learning to stop reading in machine comprehension | Iterative alternating neural attention for machine reading | End-to-end memory networks | Natural language comprehension with the epireader | Separating answers from queries for neural reading comprehension | Towards ai complete question answering: A set of prerequisite toy tasks | Theano: new features and speed improvements",iclr,010
697.pdf.json,SKIP-GRAM NEGATIVE SAMPLING,"In this paper, we consider the problem of embedding words into a low-dimensional space in order to measure the semantic similarity between them. As an example, how to find whether the word “table” is semantically more similar to the word “stool” than to the word “sky”? That is achieved by constructing a low-dimensional vector representation for each word and measuring similarity between the words as the similarity between the corresponding vectors. One of the most popular word embedding models by Mikolov et al. (2013) is a discriminative neural network that optimizes Skip-Gram Negative Sampling (SGNS) objective (see Equation 3). It aims at predicting whether two words can be found close to each other within a text. As shown in Section 2, the process of word embeddings training using SGNS can be divided into two general steps with clear objectives: Step 1. Search for a low-rank matrix X that provides a good SGNS objective value; Step 2. Search for a good low-rank representation X = WC⊤ in terms of linguistic metrics, where W is a matrix of word embeddings and C is a matrix of so-called context embeddings. Unfortunately, most previous approaches mixed these two steps into a single one, what entails a not completely correct formulation of the optimization problem. For example, popular approaches to train embeddings (including the original “word2vec” implementation) do not take into account that the objective from Step 1 depends only on the product X = WC⊤: instead of straightforward computing of the derivative w.r.t. X , these methods are explicitly based on the derivatives w.r.t. W and C, what complicates the optimization procedure. Moreover, such approaches do not take into account that parametrization WC⊤ of matrix X is non-unique and Step 2 is required. Indeed, for any invertible matrix S, we have X = W1C⊤1 = W1SS −1C⊤1 = W2C ⊤ 2 , therefore, solutions W1C1 and W2C2 are equally good in terms of the SGNS objective but entail different cosine similarities between emb","Low-rank retractions: a survey and new results | A study on similarity and relatedness using distributional and wordnet-based approaches | Block power method for svd decomposition | Multimodal distributional semantics | Placing search in context: The concept revisited | word2vec explained: deriving mikolov et al.’s negative-sampling word-embedding method | Simlex-999: Evaluating semantic models with (genuine) similarity estimation | Towards a better understanding of predict and count models | Dynamical low-rank approximation | Low-rank tensor completion by riemannian optimization | How to generate a good word embedding | Neural word embedding as implicit matrix factorization | Improving distributional similarity with lessons learned from word embeddings | A projector-splitting integrator for dynamical low-rank approximation | Distributed representations of words and phrases and their compositionality | Fixed-rank matrix factorizations and riemannian low-rank optimization | On the degrees of freedom of reduced-rank estimators in multivariate regression | word2vec parameter learning explained | Evaluation methods for unsupervised word embeddings | Riemannian pursuit for big matrix recovery | Convex functions and optimization methods on Riemannian manifolds, volume 297 | Low-rank matrix completion by riemannian optimization",iclr,010
700.pdf.json,,"Deep learning methods have achieved desirable performance in many domains, such as image classification and detection, document analysis and recognition, natural language processing, video analysis (Krizhevsky et al., 2012; Chan et al., 2014; Ciresan et al., 2010; Collobert & Weston, 2008; Le et al., 2011). Deep learning methods learn the data representation by using multiple processing layers, which discover the intricate structure of high dimensional data with multiple levels of abstraction (LeCun et al., 2015). For example, for face recognition, the learned features of first layer may be the edges, directions and some local information. The second layer typically detects some object parts which are combination of edges and directions. The higher layers may further abstract the face image by combining the features of previous layers (outline of the eyes, nose, lips). This procedure is very similar with human visual and perceptual system. In recently years, many deep learning methods have been proposed (l. Boureau & others, 2008; Lee et al., 2009b;a; Hinton & Salakhutdinov, 2006). However, most models meet some difficult problems to solve, such as some parameters need to be randomly initialized, like the weight matrix of two successive layers in deep belief networks (DBNs) and the convolution kernel in convolutional neural networks (CNNs). In addition, traditional deep learning methods need a large scale training data to train the complex networks. It causes many problems in the training process. If we don’t initialize the parameters properly, the optimization procedure might need a long training time and fall into local minima. Alternatively, many feature learning models have been proposed to learn the intrinsic structures of high-dimensional data and avoid the curse of dimensionality. In particular, most of them can be trained with small and middle scale of data and their learning algorithms are generally based on closed-form solution or convex optimization. For ","PCANet: A simple deep learning baseline for image classification | Deep, big, simple neural nets for handwritten digit recognition | A unified architecture for natural language processing: Deep neural networks with multitask learning | Decaf: A deep convolutional activation feature for generic visual recognition | The use of multiple measurements in taxonomic problems | A Deep Semi-NMF Model for Learning Hidden Representations | Reducing the Dimensionality of Data with | Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups | Stochastic neighbor embedding | Improving neural networks by preventing co-adaptation of feature detectors | Principal component analysis | Imagenet classification with deep convolutional neural networks | Cunand others. Sparse feature learning for deep belief networks | Learning hierarchical invariant spatio-temporal features for action recognition with independent subspace analysis | Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations | Unsupervised feature learning for audio classification using convolutional deep belief networks | Learning Transferable Features with Deep Adaptation Networks | Multimodal deep learning | Locality preserving projections | Learning representations by back-propagating errors | Sequence to sequence learning with neural networks | An introduction to dimensionality reduction using matlab | Dimensionality reduction: A comparative review | Extracting and composing robust features with denoising autoencoders | Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion | The human splicing code reveals new insights into the genetic determinants of disease | Graph Embedding and Extensions: A General Framework for Dimensionality Reduction | Visual Texture Perception with Feature Learning Models and Deep Architectures | Stretching Deep Architectures for Text Recognition | An Empirical Evaluation of Supervised Dimensionality Reduction for Recognition | Learning deep features for scene recognition using places database",iclr,010
701.pdf.json,BEYOND FINE TUNING: A MODULAR APPROACH TO LEARNING ON SMALL DATA,"Training generalizable models using only a small amount of data has proved a significant challenge in the field of machine learning since its inception. This is especially true when using artificial neural networks, with millions or billions of parameters. Conventional wisdom gleaned from the surge in popularity of neural network models indicates that extremely large quantities of data are required for these models to be effectively trained. Indeed the work from Krizhevsky et al. (2012) has commonly been cited as only being possible through the development of ImageNet (Russakovsky et al. (2015)). As neural networks become explored by practitioners in more specialized domains, the volume of available labeled data also narrows. Although training methods have improved, it is still difficult to train deep learning models on small quantities of data, such as only tens or hundreds of examples. The current paradigm for solving this problem has come through the use of pre-trained neural networks. Bengio et al. (2012) were able to show that transfer of knowledge in networks could be achieved by first training a neural network on a domain for which there is a large amount of data and then retraining that network on a related but different domain via fine-tuning its weights. Though this approach demonstrated promising results on small data, these models do not retain the ability to function as previously trained. That is, these models end up fine tuning their weights to the new learning task, forgetting many of the important features learned from the previous domain. The utility of pre-training models extends beyond training on small data. It is also used as an effective initialization technique for many complicated models (Jaderberg et al. (2015); Lakkaraju et al. (2014)). This, in addition to the continuing trend of treating specific network layer architectures as modular components to compose more advanced models (He et al. (2015); Larsson et al. (2016); Szegedy et al. (201",Tensorflow: Large-scale machine learning on heterogeneous distributed systems | Deep learning of representations for unsupervised and transfer learning | Net2net: Accelerating learning via knowledge transfer | Unsupervised domain adaptation by backpropagation | Domain adaptation with conditional transferable components | Deep residual learning for image recognition | Identity mappings in deep residual networks | Spatial transformer networks | Adam: A method for stochastic optimization | 3d object representations for fine-grained categorization | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | Aspect specific sentiment analysis using hierarchical deep learning | Fractalnet: Ultra-deep neural networks without residuals | Learning transferable features with deep adaptation networks | Deep transfer learning with joint adaptation | Learning word vectors for sentiment analysis | Unsupervised and transfer learning challenge: a deep learning approach | The usefulness of past knowledge when learning a new task in deep neural networks | Learning and transferring mid-level image representations using convolutional neural networks | A survey on transfer learning | Domain adaptation via transfer component analysis | Very deep convolutional networks for large-scale image recognition | Direct importance estimation with model selection and its application to covariate shift adaptation | Going deeper with convolutions | Deep domain confusion: Maximizing for domain invariance | Simultaneous deep transfer across domains and tasks | Flexible transfer learning under support and model shift | How transferable are features in deep neural networks | Visualizing and understanding convolutional networks,iclr,010
702.pdf.json,EXTRACTIVE DOCUMENT SUMMARIZATION,"Document summarization is an important problem that has many applications in information retrieval and natural language understanding. Summarization techniques are mainly classified into two categories: extractive and abstractive. Extractive methods aim to select salient snippets, sentences or passages from documents, while abstractive summarization techniques aim to concisely paraphrase the information content in the documents. A vast majority of the literature on document summarization is devoted to extractive summarization. Traditional methods for extractive summarization can be broadly classified into greedy approaches (e.g., Carbonell & Goldstein (1998)), graph based approaches (e.g., Radev & Erkan (2004)) and constraint optimization based approaches (e.g., McDonald (2007)). Recently, neural network based approaches have become popular for extractive summarization. For example, Kageback et al. (2014) employed the recursive autoencoder (Socher et al. (2011)) to summarize documents, producing best performance on the Opinosis dataset (Ganesan et al. (2010)). Yin & Pei (2015) applied Convolutional Neural Networks (CNN) to project sentences to continuous vector space and then select sentences by minimizing the cost based on their ‘prestige’ and ‘diverseness’, on the task of multi-document extractive summarization. Another related work is that of Cao et al. (2016), who address the problem of query-focused multi-document summarization using query-attention-weighted CNNs. Recently, with the emergence of strong generative neural models for text Bahdanau et al. (2014), abstractive techniques are also becoming increasingly popular (Rush et al. (2015), Nallapati et al. (2016b) and Nallapati et al. (2016a)). Despite the emergence of abstractive techniques, extractive techniques are still attractive as they are less complex, less expensive, and generate grammatically and semantically correct summaries most of the time. In a very recent work, Cheng & Lapata (2016) proposed an","Neural machine translation by jointly learning to align and translate | Tgsum: Build tweet guided multi-document summarization | Attsum: Joint learning of focusing and summarization with neural attention | The use of mmr, diversity-based reranking for reordering documents and producing summaries | Neural summarization by extracting sentences and words. 54th Annual Meeting of the Association for Computational Linguistics, 2016 | Empirical evaluation of gated recurrent neural networks on sequence modeling | Opinosis: a graph-based approach to abstractive summarization of highly redundant opinions | Teaching machines to read and comprehend | Extractive summarization using continuous vector space models | A study of global inference algorithms in multi-document summarization | Textrank: Bringing order into texts | Distributed representations of words and phrases and their compositionality | Abstractive text summarization using sequence-to-sequence rnns and beyond | Sequence-to-sequence rnns for text summarization | Order matters: Sequence to sequence for sets | Topical coherence for graph-based extractive summarization | Lexrank: Graph-based lexical centrality as salience in text summarization | A neural attention model for abstractive sentence summarization | Document summarization using conditional random fields | Dynamic pooling and unfolding recursive autoencoders for paraphrase detection | Enhancing single-document summarization by combining ranknet and third-party sources | Towards a unified approach to simultaneous single-document and multidocument summarizations | Automatic generation of story highlights | Optimizing sentence modeling and selection for document summarization | ADADELTA: an adaptive learning rate method",iclr,010
703.pdf.json,WORKS BY EXPLOITING NUMERICAL PRECISION VARIABILITY,"It is only recently that commodity computing hardware in the form of graphics processors delivered the performance necessary for practical, large scale Deep Neural Network applications Krizhevsky et al. (2012). At the same time, the end of Dennard Scaling in semiconductor technology Esmaeilzadeh et al. (2011) makes it difficult to deliver further advances in hardware performance using existing general purpose designs. It seems that further advances in DNN sophistication would have to rely mostly on algorithmic and in general innovations at the software level which can be helped by innovations in hardware design. Accordingly, hardware DNN accelerators have emerged. The DianNao accelerator family was the first to use a wide single-instruction single-data (SISD) architecture to process up to 4K operations in parallel on a single chip Chen et al. (2014a;b) outperforming graphics processors by two orders of magnitude. Development in hardware accelerators has since proceeded in two directions: either toward more general purpose accelerators that can support more machine learning algorithms while keeping performance mostly on par with DaDianNao (DaDN) Chen et al. (2014b), or toward further specialization of specific layers or classes of DNNs with the goal of outperforming DaDN in execution time and/or energy efficiency, e.g., Han et al. (2016); Albericio et al. (2016a); Judd et al. (2016a); Chen, Yu-Hsin and Krishna, Tushar and Emer, Joel and Sze, Vivienne (2016); Reagen et al. (2016). This work is along the second direction. Section 5 reviews several other accelerator designs. While DaDN’s functional units process 16-bit fixed-point values, DNNs exhibit varying precision requirements across and within layers, e.g., Judd et al. (2015). Accordingly, it is possible to use shorter, per layer representations for activations and/or weights. However, with existing bit-parallel functional units doing so does not translate into a performance nor an energy advantage as the values a","TensorFlow: Large-scale machine learning on heterogeneous systems | Cnvlutin: Ineffectual-neuron-free deep neural network computing | Bit-pragmatic deep neural network computing. Arxiv | Fused-layer cnn accelerators | Diannao: A small-footprint highthroughput accelerator for ubiquitous machine-learning | Dadiannao: A machine-learning supercomputer | Eyeriss: An Energy-Efficient Reconfigurable Accelerator for Deep Convolutional Neural Networks | Binaryconnect: Training deep neural networks with binary weights during propagations | Dark silicon and the end of multicore scaling | EIE: efficient inference engine on compressed deep neural network | Caffe model zoo | Caffe: Convolutional architecture for fast feature embedding | Reduced-Precision Strategies for Bounded Memory in Deep Neural Nets, arXiv:1511.05236v4 [cs.LG | Stripes: Bit-serial Deep Neural Network Computing | Proteus: Exploiting numerical precision variability in deep neural networks | Stripes: Bit-serial Deep Neural Network Computing | Deep visual-semantic alignments for generating image descriptions | Imagenet classification with deep convolutional neural networks. In Advances in Neural Information Processing Systems | Cambricon: An instruction set architecture for neural networks | A survey of architectural approaches for data compression in cache and main memory systems | Bit-serial neural networks | Destiny: A tool for modeling emerging 3d nvm and edram caches | Minerva: Enabling low-power, highly-accurate deep neural network accelerators | ImageNet Large Scale Visual Recognition Challenge | Execution of neural network algorithms on an array of bitserial processors | Cambricon-x: An accelerator for sparse neural networks",iclr,010
705.pdf.json,,,"Self-taught object localization with deep networks | Unsupervised object discovery and localization in the wild: Part-based matching with bottom-up region proposals | Weakly supervised object localization with multi-fold multiple instance learning | NLP on spoken documents without ASR | From captions to visual concepts and back | Devise: A deep visual-semantic embedding model | The TIMIT acoustic-phonetic continuous speech | Chrupaa. From phonemes to images: levels of representation in a recurrent neural model of visually-grounded language learning | A Bayesian framework for word segmentation: exploring the effects of context | Deep multimodal semantic embeddings for speech and images | Zero resource spoken audio corpus analysis | Unsupervised learning of spoken language with visual context | Efficient spoken term discovery using randomized algorithms | Toward spoken term discovery at scale with zero resources | Densecap: Fully convolutional localization networks for dense captioning | Unsupervised word segmentation for sesotho using adaptor grammars | Deep visual-semantic alignments for generating image descriptions | Deep fragment embeddings for bidirectional image sentence mapping | A nonparametric Bayesian approach to acoustic model discovery | Unsupervised lexicon discovery from acoustic input | Ethnologue: Languages of the World, Nineteenth edition | Variational inference for acoustic unit discovery | Unsupervised pattern discovery in speech | The Kaldi speech recognition toolkit | Very deep convolutional networks for large-scale image recognition | Connecting modalities: Semi-supervised segmentation and annotation of images using unaligned text corpora | Grounded compositional semantics for finding and describing images with sentences | Visualizing high-dimensional data using t-sne | Show and tell: A neural image caption generator | Unsupervised spoken keyword spotting via segmental DTW on Gaussian posteriorgrams | Learning deep features for scene recognition using places database | Object detectors emerge in deep scene CNNs",iclr,010
706.pdf.json,MULTI-MODAL VARIATIONAL ENCODER-DECODERS,"With the development of the variational autoencoding framework (Kingma & Welling, 2013; Rezende et al., 2014), a tremendous amount of progress has been made in learning large-scale, directed latent variable models. This approach has lead to improved performance in applications ranging from computer vision (Gregor et al., 2015; Larsen et al., 2015) to natural language processing (Mnih & Gregor, 2014; Miao et al., 2015; Bowman et al., 2015; Serban et al., 2016b). Furthermore, these models naturally incorporate a Bayesian modeling perspective, by enabling the integration of problem-dependent knowledge in the form of a prior on the generating distribution. However, the majority of models proposed assume an extremely simple prior in the form of a multivariate Gaussian distribution in order to maintain mathematical and computational tractability. Although this assumption on the prior has lead to favorable results on several tasks, it is clearly a restrictive and often unrealistic assumption. First, it imposes a strong uni-modal structure on the latent variable space; latent samples from the generating model (prior distribution) all cluster around a single mean. Second, it encourages local smoothness on the latent variables; the similarity between two latent variables decreases exponentially as their distance increase. Thus, for complex, multi-modal distributions — such as the distribution over topics in a text corpus, or natural language responses in a dialogue system — the uni-modal Gaussian prior inhibits the model’s ability to extract and represent important structure in the data. To learn more powerful and expressive models — in particular, models with multi-modal latent variable structures for natural language processing applications — we seek a suitable and flexible prior than can be automatically adapted to model multiple modes of a target distribution. ∗First two authors contributed equally. In this paper, we propose the multi-modal variational encoder-decoder fra","Learning the structure of task-driven human–human dialogs | Latent dirichlet allocation | Reweighted wake-sleep | Generating sentences from a continuous space | Importance weighted autoencoders | Improving Methods for Single-label Text Categorization | One billion word benchmark for measuring progress in statistical language modeling | Unsupervised classification of dialogue acts using a dirichlet process mixture model | Varieties of helmholtz machine | Sample-based non-uniform random variate generation | Lower and upper bounds for approximation of the kullbackleibler divergence between gaussian mixture models | Amazon’s ’Alexa Prize | DRAW: A recurrent neural network for image generation | Replicated softmax: an undirected topic model | Autoencoders, minimum description length and helmholtz free energy | The"" wake-sleep"" algorithm for unsupervised neural networks | Probabilistic latent semantic indexing | An introduction to variational methods for graphical models | Smart Reply: Automated Response Suggestion for Email | Adam: A method for stochastic optimization | Auto-encoding variational bayes | Improving variational inference with inverse autoregressive flow | A neural autoregressive topic model | Autoencoding beyond pixels using a learned similarity metric | Document neural autoregressive distribution estimation | A diversity-promoting objective function for neural conversation models | How NOT to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation | The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems | Auxiliary deep generative models | Mozur. For Sympathetic Ear, More Chinese Turn to Smartphone Program | Neural variational inference for text processing | Neural variational inference and learning in belief networks | Connectionist learning of belief networks | Learning a deep hybrid model for semi-supervised text classification | Online semi-supervised learning with deep hybrid boltzmann machines and denoising autoencoders | On the difficulty of training recurrent neural networks | Variational inference with normalizing flows | Stochastic backpropagation and approximate inference in deep generative models | Data-driven response generation in social media | I couldn’t agree more: The role of conversational structure in agreement and disagreement detection in online discussions | Efficient learning of deep boltzmann machines | Markov chain monte carlo and variational inference: Bridging the gap | Neural machine translation of rare words with subword units | Building end-to-end dialogue systems using generative hierarchical neural network models | A hierarchical latent variable encoder-decoder model for generating dialogues | A neural network approach to context-sensitive generation of conversational responses | Modeling documents with deep boltzmann machines | A deep and tractable density estimator | Discovering latent structure in task-oriented dialogues",iclr,010
707.pdf.json,REFERENCE-AWARE LANGUAGE MODELS,"Referring expressions (REs) in natural language are noun phrases (proper nouns, common nouns, and pronouns) that identify objects, entities, and events in an environment. REs occur frequently and they play a key role in communicating information efficiently. While REs are common, previous works neglect to model REs explicitly, either treating REs as ordinary words in the model or replacing them with special tokens. Here we propose a language modeling framework that explicitly incorporates reference decisions. In Figure 1 we list examples of REs in the context of the three tasks that we consider in this work. Firstly, reference to a database is crucial in many applications. One example is in task oriented dialogue where access to a database is necessary to answer a user’s query (Young et al., 2013; Li et al., 2016; Vinyals & Le, 2015; Wen et al., 2015; Sordoni et al., 2015; Serban et al., 2016; Bordes & Weston, 2016; Williams & Zweig, 2016; Shang et al., 2015; Wen et al., 2016). Here we consider the domain of restaurant recommendation where a system refers to restaurants (name) and their attributes (address, phone number etc) in its responses. When the system says “the nirala is a nice restaurant”, it refers to the restaurant name the nirala from the database. Secondly, many models need to refer to a list of items (Kiddon et al., 2016; Wen et al., 2015). In the task of recipe generation from a list of ingredients (Kiddon et al., 2016), the generation of the recipe will frequently reference these items. As shown in Figure 1, in the recipe “Blend soy milk and . . . ”, soy milk refers to the ingredient summaries. Finally, we address references within a document (Mikolov et al., 2010; Ji et al., 2015; Wang & Cho, 2015), as the generation of words will ofter refer to previously generated words. For instance the same entity will often be referred to throughout a document. In Figure 1, the entity you refers to I in a previous utterance. In this work we develop a language mo","A neural knowledge language model | A convolutional attention network for extreme summarization of source | Neural machine translation by jointly learning to align and translate | Learning end-to-end goal-oriented dialog | Incorporating copying mechanism in sequence-to-sequence learning | Coreference resolution in a modular, entity-centered model | Dialog state tracking challenge 2  | Teaching machines to read and comprehend | Long short-term memory | Document context language models | Exploring the limits of language modeling | Globally coherent text generation with neural checklist models | Deep reinforcement learning for dialogue generation | Latent predictor networks for code generation | Pointer sentinel mixture models | Recurrent neural network based language model | Building end-to-end dialogue systems using generative hierarchical neural network models | Neural responding machine for short-text conversation | A neural network approach to context-sensitive generation of conversational responses | Sequence to sequence learning with neural networks. In Advances in neural information processing | A neural conversational model | Larger-context language modelling | Semantically conditioned LSTM-based natural language generation for spoken dialogue systems | A network-based end-to-end trainable task-oriented dialogue system | End-to-end lstm-based dialog control optimized with supervised and reinforcement learning | Learning global features for coreference resolution | DWilliams. Pomdp-based statistical spoken dialog systems: A review",iclr,010
708.pdf.json,,"Convolutional neural networks (CNNs) are among the most popular techniques employed for computer vision tasks, including but not limited to image recognition, localization, video tracking, and image and video segmentation (Goodfellow et al., 2016). Though these deep networks have exhibited good performances for these tasks, they have recently been shown to be particularly susceptible to adversarial perturbations to the input images (Szegedy et al., 2014; Goodfellow et al., 2015; MoosaviDezfooli et al., 2016; Papernot et al., 2016c;b; Kurakin et al., 2016; Grosse et al., 2016; Zagoruyko, 2016b). Vulnerability of these networks to adversarial attacks can lead to undesirable consequences in many practical applications using them. For example, adversarial attacks can be used to subvert fraud detection, malware detection, or mislead autonomous navigation systems (Papernot et al., 2016c; Grosse et al., 2016). Further strengthening these results is a recent observation by Kurakin et al. (2016) who showed that a significant fraction of adversarial images crafted using the original network are misclassified even when fed to the classifier through a physical world system (such as a camera). In this paper, we investigate the problem of robustness of state-of-the-art convolutional neural networks (CNNs) to simple black-box adversarial attacks. The rough goal of adversarial attacks is as follows: Given an image I that is correctly classified by a machine learning system (say, a CNN), is it possible to construct a transformation of I (say, by adding a small perturbation to some or all the pixels) that now leads to misclassification by the system. Since large perturbations can trivially lead to misclassification, the attacks seek to limit the amount of perturbation applied under some chosen metric. More often than not, in these attacks, the modification done to the image is so subtle that the changes are imperceptible to a human eye. Our proposed attacks also share this property, ","Deep learning with differential privacy | What is the class of this image ? http://rodrigob.github.io/are_we_ there_yet/build/classification_datasets_results.html, 2016 | Differential cryptanalysis of des-like cryptosystems | Caffe model description: VGG_CNN_S | Return of the devil in the details: Delving deep into convolutional nets | Analysis of classifiers’ robustness to adversarial perturbations | Robustness of classifiers: from adversarial to random noise | Deep learning. Book in preparation for MIT Press, 2016 | Explaining and harnessing adversarial examples | Adversarial perturbations against deep neural networks for malware classification | Towards deep neural network architectures robust to adversarial examples | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Adversarial examples in the physical world | Local search in combinatorial optimization | Machine learning in adversarial settings | Deepfool: a simple and accurate method to fool deep neural networks | Transferability in machine learning: from phenomena to black-box attacks using adversarial samples | Practical black-box attacks against deep learning systems using adversarial examples | The limitations of deep learning in adversarial settings | Distillation as a defense to adversarial perturbations against deep neural networks | Faster R-CNN: towards real-time object detection with region proposal networks | Very deep convolutional networks for large-scale image recognition | Deep inside convolutional networks: Visualising image classification models and saliency maps | Intriguing properties of neural networks | Cifar-10 in torch | Loadcaffe. https://github.com/szagoruyko/loadcaffe, 2016a | Are deep learning algorithms easily hackable? http://coxlab.github.io/ ostrichinator, 2016b",iclr,010
709.pdf.json,,"Sequence to sequence (seq2seq) models (Sutskever et al., 2014; Cho et al., 2014; Kalchbrenner & Blunsom, 2013; Allen, 1987; Ñeco & Forcada, 1997) are extremely effective on a variety of tasks that require a mapping between a variable-length input sequence to a variable-length output sequence. The main weakness of sequence to sequence models, and deep networks in general, lies in the fact that they can easily overfit when the amount of supervised training data is small. In this work, we propose a simple and effective technique for using unsupervised pretraining to improve seq2seq models. Our proposal is to initialize both encoder and decoder networks with pretrained weights of two language models. These pretrained weights are then fine-tuned with the labeled corpus. We benchmark this method on machine translation for English→German and abstractive summarization on CNN and Daily Mail articles. Our main result is that a seq2seq model, with pretraining, exceeds the strongest possible baseline in both neural machine translation and phrase-based machine translation. Our model obtains an improvement of 1.3 BLEU from the previous best models on both WMT’14 and WMT’15 English→German. On abstractive summarization, our method achieves competitive results to the strongest baselines. We also perform ablation study to understand the behaviors of the pretraining method. Our study confirms that among many other possible choices of using a language model in seq2seq with attention, the above proposal works best. Our study also shows that, for translation, the main gains come from the improved generalization due to the pretrained features, whereas for summarization the gains come from the improved optimization due to pretraining the encoder which has been unrolled for hundreds of timesteps. On both tasks, our proposed method always improves generalization on the test sets. ∗Work done as an intern on Google Brain.","Several studies on natural language and back-propagation | Neural machine translation by jointly learning to align and translate | Findings of the 2015 workshop on statistical machine translation | Listen, attend and spell | Unsupervised learning of predictors from unpaired input-output samples | Semi-supervised learning for neural machine translation | Learning phrase representations using RNN encoder-decoder for statistical machine translation | Context-dependent pre-trained deep neural networks for largevocabulary speech recognition | Semi-supervised sequence learning | Zeroresource translation with multi-lingual neural machine translation | On using monolingual corpora in neural machine translation | Teaching machines to read and comprehend | Montreal neural machine translation systems for WMT’15 | Exploring the limits of language modeling | Recurrent continuous translation models | Adam: A method for stochastic optimization | ROUGE: a package for automatic evaluation of summaries | Multi-task sequence to sequence learning | Effective approaches to attention-based neural machine translation | Distributed representations of words and phrases and their compositionality | Sequence-to-sequence RNNs for text summarization | Annotated gigaword | BLEU: A method for automatic evaluation of machine translation | On the difficulty of training recurrent neural networks | Glove: Global vectors for word representation | Long short-term memory recurrent neural network architectures for large scale acoustic modeling | Neural machine translation of rare words with subword units | Improving neural machine translation models with monolingual data | The edit distance transducer in action: The university of cambridge english-german system at wmt16 | Sequence to sequence learning with neural networks | Improving LSTM-based video description with linguistic knowledge mined from text | Edinburgh’s statistical machine translation systems for wmt16 | Achieving human parity in conversational speech recognition | Recurrent neural network regularization | Exploiting source-side monolingual data in neural machine translation | Very deep convolutional networks for end-to-end speech recognition | Transfer learning for low-resource neural machine translation | Asynchronous translations with recurrent neural nets",iclr,010
710.pdf.json,,"Acoustic communication is common in the animal world where individuals communicate with sequences of some different acoustic elements (Kershenbaum et al., 2014). An accurate analysis is important in order to give a better identification of some animal species and interpret the identified song units in the course of time. In this paper, we automatically model the sequence of a non-human signal and determine their acoustic song units. As highlighted in Kershenbaum et al. (2014), the way according to which non-human acoustic sequences can be interpreted can be summarized as shown in Fig 4. We distinguish four common properties that are used to define potential criteria for segmenting such signals into song units. The first way, shown in Fig 4(A), consists in separating the signals using silent gaps. The second way, shown in Fig 4(B), consists in separating the signals according to the changes in the acoustic properties in the signal. The third way, shown in Fig 4(C) consists in grouping similar sounds separated with silent gaps as a single unit. The last common way, shown in Fig 4(D) consists in separating signal in organized sound structure, considered as fundamental units. Acoustic units can be determined either manually (e.g. from spectrogram representation), or automatically (e.g. based on a model). Manual segmentation is time consuming and not possible for a large acoustic dataset. That is why automatic approaches are needed. Furthermore, in bioacoustic signals, the problem of segmenting signals of many species, is still an issue, including for bioacoustic. Hence, a well-principled learning system based on unsupervised approach can help them to have a better understanding of bioacoustics species. In this context, we investigate statistical latent data models to automatically identify song units. First, we study Hidden Markov Models (HMMs) (Rabiner & Juang, 1986). Which are the gold standard for sequential data, and thus could be relevant for acoustic data modeling","A new look at the statistical model identification | Aggressive behavior between humpback whales (Megaptera novaeangliae) wintering in Hawaiian waters | A maximization technique occurring in the statistical analysis of probabilistic functions of markov chains | The infinite hidden markov model | Assessing a mixture model for clustering with the integrated completed likelihood | Bird Song - Biological Themes and Variations | Maximum likelihood from incomplete data via the EM algorithm | Deroussen. La sonotheque du Museum | A Bayesian Analysis of Some Nonparametric Problems | Stochastic variational inference for hidden Markov models | An HDP-HMM for systems with state persistence | Spatial distribution, habitat utilization, and social interactions of humpback whales, Megaptera novaeangliae, off Hawai’i, determined using acoustic and visual techniques | Dynamic horizontal cultural transmission of humpback whale song at the ocean basin scale | Geographic Variation in South Pacific Humpback Whale Songs | An Introduction to Variational Methods for Graphical Models | Acoustic sequences in nonhuman animals: a tutorial review and prospectus | Ecology and evolution of acoustic communication in birds | Sex identification of humpback whales, Megaptera novaeangliae, on the wintering grounds of the Mexican Pacific Ocean | Subunit definition and analysis for humpback whale call classification | Automatic prosodic clustering of humpback whales song. In New Trends for Environmental Monitoring | Exchangeable and partially exchangeable random partitions | An introduction to hidden Markov models | Estimating the dimension of a model | A constructive definition of Dirichlet priors | Cluster ensembles—a knowledge reuse framework for combining multiple partitions | Hierarchical dirichlet processes",iclr,010
711.pdf.json,EXTRACTIVE QUESTION ANSWERING,"A primary goal of natural language processing is to develop systems that can answer questions about the contents of documents. The reading comprehension task is of practical interest – we want computers to be able to read the world’s text and then answer our questions – and, since we believe it requires deep language understanding, it has also become a flagship task in NLP research. A number of reading comprehension datasets have been developed that focus on answer selection from a small set of alternatives defined by annotators (Richardson et al., 2013) or existing NLP pipelines that cannot be trained end-to-end (Hill et al., 2016; Hermann et al., 2015). Subsequently, the models proposed for this task have tended to make use of the limited set of candidates, basing their predictions on mention-level attention weights (Hermann et al., 2015), or centering classifiers (Chen et al., 2016), or network memories (Hill et al., 2016) on candidate locations. Recently, Rajpurkar et al. (2016) released the less restricted SQUAD dataset1 that does not place any constraints on the set of allowed answers, other than that they should be drawn from the evidence document. Rajpurkar et al. proposed a baseline system that chooses answers from the constituents identified by an existing syntactic parser. This allows them to prune the O(N2) answer candidates in each document of length N , but it also effectively renders 20.7% of all questions unanswerable. Subsequent work by Wang & Jiang (2016) significantly improve upon this baseline by using an endto-end neural network architecture to identify answer spans by labeling either individual words, or the start and end of the answer span. Both of these methods do not make independence assumptions about substructures, but they are susceptible to search errors due to greedy training and decoding. In contrast, here we argue that it is beneficial to simplify the decoding procedure by enumerating all possible answer spans. By explicitly represent","Neural machine translation by jointly learning to align and translate | A thorough examination of the cnn/daily mail reading comprehension task | A theoretically grounded application of dropout in recurrent neural networks | LSTM: A search space odyssey | Teaching machines to read and comprehend | The goldilocks principle: Reading children’s books with explicit memory representations | Long Short-term Memory | Adam: A method for stochastic optimization | Dataset and neural recurrent sequence labeling model for open-domain factoid question answering | Rectified linear units improve restricted boltzmann machines | A decomposable attention model for natural language inference | Glove: Global vectors for word representation | SQuAD: 100, 000+ questions for machine comprehension of text | Mctest: A challenge dataset for the open-domain machine comprehension of text | Cloze procedure: A new tool for measuring readability | Convolutional neural networks vs. convolution kernels: Feature engineering for answer sentence reranking | Building a question answering test collection | Inner attention based recurrent neural networks for answer selection | Machine comprehension using match-lstm and answer pointer | Wikiqa: A challenge dataset for open-domain question answering",iclr,010
712.pdf.json,A NEURAL STOCHASTIC VOLATILITY MODEL,"The volatility of the price movements reflects the ubiquitous uncertainty within financial markets. It is critical that the level of risk, indicated by volatility, is taken into consideration before investment decisions are made and portfolio are optimised (Hull, 2006); volatility is substantially a key variable in the pricing of derivative securities. Hence, estimating and forecasting volatility is of great importance in branches of financial studies, including investment, risk management, security valuation and monetary policy making (Poon & Granger, 2003). Volatility is measured typically by using the standard deviation of price change in a fixed time interval, such as a day, a month or a year. The higher the volatility, the riskier the asset. One of the primary challenges in designing volatility models is to identify the existence of latent (stochastic) variables or processes and to characterise the underlying dependences or interactions between variables within a certain time span. A classic approach has been to handcraft the characteristic features of volatility models by imposing assumptions and constraints, given prior knowledge and observations. Notable examples include autoregressive conditional heteroskedasticity (ARCH) model (Engle, 1982) and its generalisation GARCH (Bollerslev, 1986), which makes use of autoregression to capture the properties of time-variant volatility within many time series. Heston (1993) assumed that the volatility follows a Cox-Ingersoll-Ross (CIR) process (Cox et al., 1985) and derived a closed-form solution for options pricing. While theoretically sound, those approaches require strong assumptions which might involve complex probability distributions and non-linear dynamics that drive the process, and in practice, one may have to impose less prior knowledge and rectify a solution under the worst-case volatility case (Avellaneda & Paras, 1996). In this paper, we take a fully data driven approach and determine the configurations w","Answering the skeptics: Yes, standard volatility models do provide accurate forecasts | Managing the volatility risk of portfolios of derivative securities: the lagrangian uncertain volatility model | Neural machine translation by jointly learning to align and translate | Learning stochastic recurrent networks | Pattern recognition | Generalized autoregressive conditional heteroskedasticity | Time series analysis: forecasting and control | Learning phrase representations using rnn encoder-decoder for statistical machine translation | Attention-based models for speech recognition | A recurrent latent variable model for sequential data | A theory of the term structure of interest rates | Incorporating nesterov momentum into adam | Autoregressive conditional heteroscedasticity with estimates of the variance of united kingdom inflation | Multivariate simultaneous generalized arch | Variational recurrent auto-encoders | Sequential neural models with stochastic layers | On the relation between the expected value and the volatility of the nominal excess return on stocks | Generating sequences with recurrent neural networks | Speech recognition with deep recurrent neural networks | Draw: A recurrent neural network for image generation | On the approximation capability of recurrent neural | Deep residual learning for image recognition | A closed-form solution for options with stochastic volatility with applications to bond and currency options | Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups | Long short-term memory | Options, futures, and other derivatives | Determining embedding dimension for phase-space reconstruction using a geometrical construction | Adam: A method for stochastic optimization | Auto-encoding variational bayes | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | Effective approaches to attentionbased neural machine translation | Conditional heteroskedasticity in asset returns: A new approach | Forecasting volatility in financial markets: A review | Stochastic backpropagation and approximate inference in deep generative models | Deep learning in neural networks: An overview | Bidirectional recurrent neural networks | Introduction to numerical analysis, volume 12 | Sequence to sequence learning with neural networks. In Advances in neural information processing | Pixel recurrent neural networks | Gaussian process volatility model | Recurrent neural network regularization",iclr,010
713.pdf.json,PARAMETRIC EXPONENTIAL LINEAR UNIT FOR DEEP CONVOLUTIONAL NEURAL NETWORKS,"Over the past few years, Convolutional Neural Networks (CNNs) have become the leading approach in computer vision (Krizhevsky et al., 2012; LeCun et al., 2015; Vinyals et al., 2015; Jaderberg et al., 2015; Ren et al., 2015; Hosang et al., 2016). Through a series of non-linear transformations, CNNs can process high-dimensional input observations into simple low-dimensional concepts. The key principle of CNNs is that features at each layer are composed of features from the layer below. This creates a hierarchical organization of increasingly abstract concepts. Since levels of organization are often seen in complex biological structures, such a hierarchical organization makes CNNs particularly well-adapted for capturing high-level abstractions from real-world observations. The activation function plays a crucial role in learning representative features. Defined as max{h, 0}, the Rectified Linear Unit (ReLU) is one of the most popular activation function (Nair & Hinton, 2010). It has interesting properties, such as low computational complexity, non-contracting first-order derivative and induces sparse activations, which have been shown to improve performance Krizhevsky et al. (2012). The main drawback of ReLU is its zero derivative for negative arguments. This blocks the back-propagated error signal from the layer above, which may prevent the network from reactivating dead neurons. To overcome this limitation, Leaky ReLU (LReLU) adds a positive slope a to the negative part of ReLU (Maas et al., 2013). Defined as max{h, 0}+ amin{h, 0}, where a > 0, LReLU has a non-zero derivative for negative arguments. Unlike ReLU, its parameter a allows a small portion of the back-propagated error signal to pass to the layer below. By using a small enough value a, the network can still output sparse activations while preserving its ability to reactivate dead neurons. In order to avoid specifying by hand the slope parameter a, Parametric ReLU (PReLU) directly learns its value during bac","Learning activation functions to improve deep neural networks | Fast and accurate deep network learning by exponential linear units (elus) | Deep residual learning for image recognition | Delving deep into rectifiers: Surpassing human-level performance on imagenet classification | What makes for effective detection | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Spatial transformer networks | Deep learning with s-shaped rectified linear activation units | Imagenet classification with deep convolutional neural networks | Rectifier nonlinearities improve neural network acoustic models | Rectified linear units improve restricted boltzmann machines | Faster r-cnn: Towards real-time object detection with region proposal networks | Overfeat: Integrated recognition, localization and detection using convolutional networks | Deep residual networks with exponential linear unit | Very deep convolutional networks for large-scale image recognition | Striving for simplicity: The all convolutional net | Show and tell: A neural image caption generator",iclr,010
714.pdf.json,SENTATION USING ROBOTIC PRIORS,"The environment we live in is ruled by complex physical laws. However humans are likely to interact with it without any detailed knowledge of these laws. The human brain constructs simple models of the world in order to come up with an easy, though approximate, understanding of it. This paper aims to reproduce this behavior for robots. We want to build a simple representation of the world that retains enough information to make a machine able to use it to interact afterwards i.e. to perform an assigned task. Finding such a minimal representation (e.g., the position of an object extracted from an image) is the standard way to implement behaviors in robots. However, this is most of the time done in a task specific and supervised way. In this paper, we want to learn such representation without supervision, based on generic learning objectives. This representation is learned using deep learning. The deep neural network is trained by using images of robot experiences in a given environment and has to estimates for each image a state which is the representation we want to learn. Instead of using a ground truth for supervised training, we make use of an approach that ensures consistency between the states representation. For this purpose, the states are constrained by “robotics priors” (Jonschkowski & Brock, 2015) which are an expression of the knowledge we have about physics. The main contribution of this paper is the use of the robotics prior approach in a siamese network to train a deep convolutional neural network. The network is trained with images of the robot environment, information on the actions performed by the robot and rewards defining a task. The neural network learns a state representation usable for the robot to perform this task. The resulting neural network also displays useful feature detectors for environment analysis that could be a basis for transfer learning to similar tasks.","Learning deep architectures for ai | Representation learning: A review and new perspectives | Learning a similarity metric discriminatively, with application to face verification | ImageNet: A Large-Scale Hierarchical Image Database | Adaptive subgradient methods for online learning and stochastic optimization | Deep spatial autoencoders for visuomotor learning | Deep residual learning for image recognition | Batch normalization: Accelerating deep network training by reducing internal covariate | State representation learning in robotics: Using prior knowledge about physical interaction | Learning state representations with robotic priors | Efficient skill learning using abstraction selection | Imagenet classification with deep convolutional neural networks | Autonomous reinforcement learning on raw visual input data in a real world application. doi: 10.1109/IJCNN.2012.6252823 | A tutorial on energy-based learning | A physics-based model prior for object-oriented mdps | Efficient abstraction selection in reinforcement learning | Very deep convolutional networks for large-scale image recognition | Stable reinforcement learning with autoencoders for tactile and visual data | Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion | Embed to control: A locally linear latent dynamics model for control from raw images | Distance metric learning, with application to clustering with side-information",iclr,010
715.pdf.json,,"Deep and wider neural networks have the capacity to learn a complex unknown function from the training data. The network reported in Dean et al. (2012) has 1.7 billion parameters and is trained on tens of thousands of CPU cores. Similarly (Simonyan & Zisserman, 2014) has employed 11-19 layers and achieved excellent classification results on the ImageNet dataset. However, the increasing depth and width demands higher computational power. This high computational complexity is a major obstacle in porting the benefits of deep learning to resource limited devices. Further, the hotspot for optimization are the convolution layers, as most of the computations are conducted there. Therefore, many researchers have proposed ideas to accelerate deep networks for real-time inference Yu et al. (2012); Han et al. (2015b;a); Mathieu et al. (2013); Anwar et al. (2015b). Network pruning is one promising technique that first learns a function with a sufficiently large sized network followed by removing less important connections Yu et al. (2012); Han et al. (2015b); Anwar et al. (2015b). This enables smaller networks to inherit knowledge from the large sized predecessor networks and exhibit a comparable level of performance. The works of Han et al. (2015b;a) introduce fine grained sparsity in a network by pruning scalar weights. Due to unstructured sparsity, the authors employ compressed sparse row/column (CSR/CSC) for sparse representation. Thus the fine grained irregular sparsity cannot be easily translated into computational speedups. Sparsity in a deep convolutional neural network (CNN) can be induced at various levels. Figure 1 shows four pruning granularities. At the coarsest level, a full hidden layer can be pruned. This is shown with a red colored rectangle in Fig. 1(a). Layer wise pruning affects the depth of the network and a deep network can be converted into a shallow network. Increasing the depth improves the network performance and layer-wise pruning therefore demand int","Fixed point optimization of deep convolutional neural networks for object recognition | Structured pruning of deep convolutional neural networks | An iterative pruning algorithm for feedforward neural networks | High performance convolutional neural networks for document processing | Memory bounded deep convolutional networks | Binaryconnect: Training deep neural networks with binary weights during propagations | Large scale distributed deep networks | A deep neural network compression pipeline: Pruning, quantization, huffman encoding | Learning both weights and connections for efficient neural network | Fixed-point feedforward deep neural network design using weights+ | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Learning multiple layers of features from tiny | Fast convnets using group-wise brain damage | Gradient-based learning applied to document recognition | Pruning filters for efficient convnets | Fast training of convolutional networks through ffts | All you need is a good init | Channel-level acceleration of deep face representations | Pruning algorithms-a survey | Very deep convolutional networks for large-scale image recognition | Pruning backpropagation neural networks using modern stochastic optimisation techniques | Exploiting sparseness in deep neural networks for large vocabulary speech recognition",iclr,010
716.pdf.json,ENET: A DEEP NEURAL NETWORK ARCHITECTURE FOR REAL-TIME SEMANTIC SEGMENTATION,"Recent interest in augmented reality wearables, home-automation devices, and self-driving vehicles has created a strong need for semantic-segmentation (or visual scene-understanding) algorithms that can operate in real-time on low-power mobile devices. These algorithms label each and every pixel in the image with one of the object classes. In recent years, the availability of larger datasets and computationally-powerful machines have helped deep convolutional neural networks (CNNs) (LeCun & Bengio (1998); Krizhevsky et al. (2012); Simonyan & Zisserman (2014a); Szegedy et al. (2015a)) surpass the performance of many conventional computer vision algorithms (Shotton et al. (2009); Perronnin et al. (2010); van de Sande et al. (2011)). Even though CNNs are increasingly successful at classification and categorization tasks, they provide coarse spatial results when applied to pixel-wise labeling of large images. Therefore, they are often cascaded with other algorithms to refine the results, such as color based segmentation (Farabet et al. (2013)) or conditional random fields (Chen et al. (2014)), to name a few. In order to both spatially classify and finely segment images, several neural network architectures have been proposed, such as SegNet (Badrinarayanan et al. (2015a;b)) or fully convolutional networks (Long et al. (2015)). All these works are based on a VGG16 (Simonyan & Zisserman (2014b)) architecture, which is a very large model designed for multi-class classification. These references use models with a large number of parameters, and slow inference time. In these conditions, they become unusable for many mobile or battery-powered applications, which require processing images at rates higher than 10 fps. In this paper, we propose a new neural network architecture optimized for high-accuracy and also fast inference. In our work, beside neural network processing, we chose not to use any other post-processing steps, in order to focus on the intrinsic performance of a","Segnet: A deep convolutional encoderdecoder architecture for robust semantic pixel-wise labelling | Segnet: A deep convolutional encoderdecoder architecture for image segmentation | Segmentation and recognition using structure from motion point clouds | Semantic image segmentation with deep convolutional nets and fully connected crfs | cudnn: Efficient primitives for deep learning | The cityscapes dataset for semantic urban scene understanding | Predicting depth, surface normals and semantic labels with a common multi-scale convolutional architecture | Learning hierarchical features for scene labeling | Deep compression: Compressing deep neural network with pruning, trained quantization and huffman coding | Delving deep into rectifiers: Surpassing human-level performance on imagenet classification | Deep residual learning for image recognition | Identity mappings in deep residual networks | Decoupled deep neural network for semisupervised semantic segmentation | Deep networks with stochastic depth | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Flattened convolutional neural networks for feedforward acceleration | Adam: A method for stochastic optimization | Imagenet classification with deep convolutional neural networks | Convolutional networks for images, speech, and time series | Fully convolutional networks for semantic segmentation | Multimodal deep learning | Learning deconvolution network for semantic segmentation | Large-scale image retrieval with compressed fisher vectors | Unsupervised learning of invariant feature hierarchies with applications to object recognition | Textonboost for image understanding: Multi-class object recognition and segmentation by jointly modeling texture, layout, and context | Very deep convolutional networks for large-scale image recognition | Very deep convolutional networks for large-scale image recognition | Sun rgb-d: A rgb-d scene understanding benchmark suite | Combining appearance and structure from motion features for road scene understanding | Going deeper with convolutions | Rethinking the inception architecture for computer vision | Efficient object localization using convolutional networks | Segmentation as selective search for object recognition | Multi-scale context aggregation by dilated convolutions | Conditional random fields as recurrent neural networks",iclr,010
717.pdf.json,,"In parallel with the success of CNNs to solve vision problems, there is a growing interest in developing methodologies to understand and visualize the internal representations of these networks. How the responses of a trained CNN encode the visual information is a fundamental question for computer and eventually for human vision. Several works have proposed different methodologies to address the understanding problem. Recently, in Li et al. (2016) two main groups of works are mentioned. On one side those works that deal with the problem from a theoretical point of view. These are works such as Montavon et al. (2011) where kernel sequences are used to conclude that deep networks create increasingly better representations as the number of layer increases, Paul & Venkatasubramanian (2014) which explains why a deep learning network learns simple features first and that the representation complexity increases as the layers get deeper, Goodfellow et al. (2014) where an explanation for why an adversarial example created for one network is still valid in many others and they usually assign it the same (wrong) class, or Arora et al. (2014) that presents algorithms for training certain deep generative models with provable polynomial running time. On the other side, an empirical point of view, which comprises approaches that pursuit methodologies to visualize intermediate features in the image space, or approaches that analyze the effect of modifying a given feature map in a neuron activation. Our work is framed in the first subset of empirical approaches. Visualizing intermediate features seeks to describe the activity of individual neurons. This description is the basis of this work hypothesis that is based on the idea that a proper understanding of the activity of the individual neurons allow us to draw a map of the CNN behavior. This behavior can be understood either in terms of relevant image features or in terms of the discriminative power of the neurons across the full ",Learning to generate chairs with convolutional neural networks | Provable bounds for learning some deep representations | Understanding deep features with computer-generated imagery | Parametric fuzzy sets for automatic color | Deep neural networks rival the representation of primate it cortex for core visual object recognition | Return of the devil in the details: Delving deep into convolutional nets | Color-tuned neurons are spatially clustered according to color preference within alert macaque posterior inferior temporal cortex | Weighted principal component analysis: a weighted covariance eigendecomposition approach | ImageNet: A Large-Scale Hierarchical Image Database | Inverting visual representations with convolutional networks | Explaining and harnessing adversarial examples | Visual Population Codes - Toward a Common Multivariate Framework for Cell Recording and Functional Imaging | Convergent learning: Do different neural networks learn the same representations | Understanding deep image representations by inverting them | Why does deep learning work? - A perspective from group theory | Color spaces emerging from deep convolutional networks | Color in the cortex: Single- and double-opponent cells | Deep inside convolutional networks: Visualising image classification models and saliency maps | Striving for simplicity: The all convolutional net | Matconvnet – convolutional neural networks for matlab | Understanding neural networks through deep visualization | Visualizing and understanding convolutional networks,iclr,010
718.pdf.json,MULTIAGENT SYSTEM FOR LAYER FREE NETWORK,"Deep networks are used in many tasks, especially in image recognition, signal processing, NLP and robot manipulation. Almost all deep network models utilize structure with layers. One of the primary reasons to use those layer structure is to utilize parallel computation techniques and hardware level technologies such as GPU or dedicated tensor processors. Layers can be viewed as a restriction on the connection pattern of the units that they must be aligned in a row to form a vector. Though layers are related to vector-matrix processing technologies and necessary to make use of them, it is not evident that this vector-matrix restriction is the most appropriate model to capture the latent representation of the data. Vector-matrix approach requires dense matrices to store weight parameters even after sparse representations and weights are learned, which requires inefficient use of memory. There are several methods to reduce the cost by downsize the model such as distillation(Hinton et al. (2014)), and limiting the model space with binarizing(Courbariaux et al. (2015)) and hashing Han et al. (2015), but they still needs dense matrix filled with many zeros. In this paper we propose a framework of multiagent calculation network that has feedforward matrix-vector network as a subset but free from the notion of layer to solve these problems. Our multiagent network consists of many agents that replaces each unit in standard deep networks. The agents act autonomously and calculations are executed as an accumulation of many local level communication among the agents. This local calculation scheme is contrary to the previous feedforward network implementation that all computations in the units in the same layer is done simultaneously (Figure 1). Specifically, we reimplemented Stacked Denoising Autoencoder(SDAE) (Vincent et al. (2008)) as one of the variations in our framework. SDAE is one of the earliest successful deep network model and free from spatiality assumption in CNNs ","Spiking Deep Convolutional Neural Networks for Energy-Efficient Object Recognition | BinaryConnect: Training Deep Neural Networks with binary weights during propagations | Learning to Communicate with Deep Multi-Agent Reinforcement Learning | Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding | Distilling the Knowledge in a Neural Network | Adam: A Method for Stochastic Optimization | Difference Target Propagation | MADE: Masked Autoencoder for Distribution Estimation | Spike Frequency Adaptation Implements Anticipative Tracking in Continuous Attractor Neural Networks | Seven neurons memorizing sequences of alphabetical images via spike-timing dependent plasticity | Semi-supervised Learning with Ladder Networks | Guided Self-organization in Indirectly Encoded and Evolving Topographic Maps | Learning Multiagent Communication with Backpropagation | Generating Coherent Patterns of Activity from Chaotic | Extracting and composing robust features with denoising autoencoders",iclr,010
719.pdf.json,CLASSLESS ASSOCIATION USING NEURAL NETWORKS,"Infants are able to learn the binding between abstract concepts to the real world via their sensory input. For example, the abstract concept ball is binding to the visual representation of a rounded object and the auditory representation of the phonemes /b/ /a/ /l/. This scenario can be seen as the Symbol Grounding Problem (Harnad, 1990). Moreover, infants are also able to learn the association between different sensory input signals while they are still learning the binding of the abstract concepts. Several results have shown a correlation between object recognition (visual) and vocabulary acquisition (auditory) in infants (Balaban & Waxman, 1997; Asano et al., 2015). One example of this correlation is the first words that infants have learned. In that case, the words are mainly nouns, which are visible concepts, such as, dad, mom, ball, dog, cat (Gershkoff-Stowe & Smith, 2004). As a result, we can define the previous scenario in terms of a machine learning tasks. More formally, the task is defined by learning the association between two parallel streams of data that represent the same unknown class (or abstract concept). Note that this task is different from the supervised association where the data has labels. First, the semantic concept is unknown in our scenario whereas it is known in the supervised case. Second, both classifiers needs to agree on the same coding scheme for each sample pair during training. In contrast, the coding-scheme is already pre-defined before training in the supervised case. Figure 1 shows an example of the difference between a supervised association task and our scenario. Usually, classifiers requires labeled data for training. However, the presented scenario needs an alternative training mechanism. One way is to train based on statistical distributions. Casey (1986) proposed to solve the OCR problem using language statistics for inferring form images to characters. Later on, Knight et al. (2006) applied a similar idea to machine trans","Sound symbolism scaffolds language development in preverbal infants | Do words facilitate object categorization in 9-month-old infants | Text OCR by solving a cryptogram | Learning a similarity metric discriminatively, with application to face verification | Maximum likelihood from incomplete data via the EM algorithm | Shape and the first hundred nouns | The symbol grounding problem | Neural network-based clustering using pairwise constraints | Tvgraz: Multi-modal learning of object categories by combining textual and visual features | Unsupervised analysis for decipherment problems | The MNIST database of handwritten digits | Scikit-learn: Machine learning in Python | A New Approach to Cross-Modal Multimedia Retrieval | Towards principled unsupervised learning",iclr,010
720.pdf.json,,"There are different abstraction levels within data. For the low-abstraction continuous sensory data (such as images, videos, and audio) directly acquired from the physical world, quite often, the strong correlations (local patterns) are known a priori within the data. As such, one can directly embed the prior knowledge into a learning model such as neural networks to automatically distil such patterns and perform predictions (Krizhevsky et al., 2012; Graves et al., 2013). However, on the other hand, for high-abstraction data from our social and business activities, such as natural language and transnational log data, the data is commonly discrete and contains atomic symbols, whose meaning and correlation are unknown a priori. A typical solution is to employ embedding techniques (Bengio et al., 2003; Mikolov et al., 2013) to map the discrete tokens into a (low-dimensional) continuous space and further build neural networks to learn the latent patterns. Multi-field categorical data is a type of high-abstraction data where the categories in each field are heterogeneous with those in other fields. Such a type of data is very widely used in data mining tasks based on transaction logs from many social or commercial applications, such as recommender systems, social link prediction, and computational advertising. Table 1 gives an example of multifield categorical data in user behaviour targeting where we observe user browsing patterns, and given those multi-field categorical features, a common task is to predict their actions such as clicks and conversions (Zhang et al., 2014; Liao et al., 2014; Yuan et al., 2013). As there is no explicit dependency among these inter-field categories, two solutions are mainly used for building machine learning models that extract the local patterns of the data and make good predictions. The first solution is to create combining features across fields, such as CITY:SHANGHAI&WEEKDAY:FRIDAY (Chapelle et al., 2015). Such feature engineering is ",Fast algorithms for mining association rules | A neural probabilistic language model | Simple and scalable response prediction for display advertising | Speech recognition with deep recurrent neural networks | Learning distributed representations of concepts | Imagenet classification with deep convolutional neural networks | ipinyou global rtb bidding algorithm competition dataset | A convolutional click prediction model | Efficient estimation of word representations in vector space | Factorization machines | Factorization machines with libfm | Predicting clicks: estimating the clickthrough rate for new ads | On the importance of initialization and momentum in deep learning | Extracting and composing robust features with denoising autoencoders | Real-time bidding for online advertising: measurement and analysis | Real-time bidding benchmarking with ipinyou dataset | Deep learning over multi-field categorical data,iclr,010
721.pdf.json,TRANSFORMATIONAL SPARSE CODING,"A challenging problem in computer vision is the reliable recognition of objects under a wide range of transformations. Approaches such as deep learning that have achieved success in recent years usually require large amounts of labeled data, whereas the human brain has evolved to solve the problem using an almost unsupervised approach to learning object representations. During early development, the brain builds an internal representation of objects from unlabeled images that can be used in a wide range of tasks. Much of the complexity in learning efficient and general-purpose representations comes from the fact that objects can appear in different poses, at different scales, locations, orientations and lighting conditions. Models have to account for these transformed versions of objects and their features. Current successful approaches to recognition use pooling to allow limited invariance to two-dimensional translations (Ranzato et al. (2007)). At the same time pooling discards information about the location of the detected features. This can be problematic because scaling to large numbers of objects requires modeling objects in terms of parts and their relative pose, requiring the pose information to be retained. Previous unsupervised learning techniques such as sparse coding (Olshausen & Field (1997)) can learn features similar to the ones in the visual cortex but these models have to explicitly learn large numbers of transformed versions of the same feature and as such, quickly succumb to combinatorial explosion, preventing hierarchical learning. Other approaches focus on computing invariant object signatures (Anselmi et al. (2013; 2016)), but are completely oblivious to pose information. Ideally, we want a model that allows object features and their relative transformations to be simultaneously learned, endowing itself with a combinatorial explanatory capacity by being able to apply learned object features with object-specific transformations across large numb","Unsupervised learning of invariant representations in hierarchical architectures | Unsupervised learning of invariant representations | Group equivariant convolutional networks | Learning transport operators for image manifolds | Exploiting cyclic symmetry in convolutional neural networks. CoRR, abs/1602.02660, 2016 | The lie transformation group model of visual perception | Deep symmetry networks | Bilinear sparse coding for invariant vision | Transforming auto-encoders | Minimum distance between pattern transformation manifolds: Algorithm and applications | Efficient sparse coding algorithms | Learning the Lie Groups of Visual Invariance | Sparse coding with an overcomplete basis set: A strategy employed by v1 | The computation of the exponential and logarithmic mappings and their first and second linearizations | Under review as a conference paper at ICLR | Learning lie groups for invariant visual perception",iclr,010
723.pdf.json,,"Taking inspiration in Biology is sometimes very efficient. For example, deep neural networks (NN) – which are outperforming all other methods (including support vector machines, SVM) in image recognition – are based on a series of several (usually 5 to 15) neurons layers, each layer involving sparsity in the activation pattern (a biological trait of the cortical map). The analogy continues with the modeling of the cortex as a hierarchy of cortical maps. Thanks to the analysis of reaction time in cognitive psychology experiments, the minimal number of cortical maps involved in a cognitive process is estimated to about ten, the same order of magnitude as the number of layers in deep neural networks for computer vision tasks. In the case of handwritten word recognition, Dehaene et al. have proposed a biologically plausible model of the cortical organization of reading (Dehaene et al., 2005) that assumes seven successive steps of increasing complexity, from the retinal ganglion cells to a cortical map of the orthographic word forms (Figure 1). One of the most recent successes of experimental psychology was the demonstration that human visual word recognition uses an explicit representation of letter position order based on letter pairs: the open-bigram coding (Whitney et al., 2012; Gomez et al., 2008; Grainger & Van Heuven, 2003; Glotin et al., 2010; Dufau, 2008). As demonstrated in (Touzet et al., 2014), open-bigrams (OB) allow an over-coding of the orthographic form of words that facilitates recognition. OB coding favors same length words (i.e., neighbors of similar lengths). In the context of learning to read, the existence of the OB layer just before the orthographic word representation has been used to explain the lack of efficiency of whole language method (today banned from reading teaching) compared to the phonics method which explic- itly supervises the organization of the OB map (with syllables), where the global method does not (Figure 1). Since cognitive psy",Word spotting and recognition with embedded attributes | Preteux. RIMES evaluation campaign for handwritten mail processing | Lerec: A NN/HMM hybrid for on-line handwriting recognition | Dynamic and Contextual Information in HMM modeling for Handwriting Recognition | A Comparison of Sequence-Trained Deep Neural Networks and Recurrent Neural Networks Optical Modeling for Handwriting Recognition | A structural and relational approach to handwritten word recognition | The neural code for written words: a proposal | Auto-organisation des représentations lexicales au cours de l’apprentissage de la lecture: approches comportementale électrophysiologique et neuro-computationnelle | An adaptive resonance theory account of the implicit learning of orthographic word forms | The overlap model: a model of letter position coding | Modeling letter position coding in printed word perception | Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks | Offline handwriting recognition with multidimensional recurrent neural networks | Long short-term memory | Deep structured output learning for unconstrained text recognition | Sophisticated topology of hidden Markov models for cursive script recognition | Lattice-based optimization of sequence classification criteria for neural-network acoustic modeling | Hidden Markov model based word recognition and its application to legal amount reading on French checks | Gradient-based learning applied to document recognition | Holistic lexicon reduction for handwritten word recognition | The IAM-database: an English sentence database for offline handwriting recognition | Global word shape processing in off-line recognition of handwriting | Cnn-n-gram for handwriting word recognition | The Theory of neural Cognition applied to Robotics | A Biologically Plausible SOM Representation of the Orthographic Form of 50000 French Words. In Advances in Self-Organizing Maps and Learning Vector Quantization | Visualizing data using t-SNE | On coding the position of letters in words: a test of two models,iclr,010
725.pdf.json,MAKING STOCHASTIC NEURAL NETWORKS FROM DETERMINISTIC ONES,"Recently, deterministic deep neural networks (DNN) have demonstrated state-of-the-art performance on many supervised tasks, e.g., speech recognition (Hinton et al., 2012a) and object recognition (Krizhevsky et al., 2012). One of the main components underlying these successes is on the efficient training methods for deeper and wider DNNs, which include backpropagation (Rumelhart et al., 1988), stochastic gradient descent (Robbins & Monro, 1951), dropout/dropconnect (Hinton et al., 2012b; Wan et al., 2013), batch/weight normalization (Ioffe & Szegedy, 2015; Salimans & Kingma, 2016), and various activation functions (Nair & Hinton, 2010; Gulcehre et al., 2016). On the other hand, stochastic feedforward neural networks (SFNN) (Neal, 1990) having random latent units are often necessary in order to model complex stochastic natures in many real-world tasks, e.g., structured prediction (Tang & Salakhutdinov, 2013), image generation (Goodfellow et al., 2014) and memory networks (Zaremba & Sutskever, 2015). Furthermore, it has been believed that SFNN has several advantages beyond DNN (Raiko et al., 2014): it has more expressive power for multi-modal learning and regularizes better for large-scale learning. Training large-scale SFNN is notoriously hard since backpropagation is not directly applicable. Certain stochastic neural networks using continuous random units are known to be trainable efficiently using backpropagation under the variational techniques and the reparameterization tricks (Kingma & Welling, 2013). On the other hand, training SFNN having discrete, i.e., binary or multi-modal, random units is more difficult since intractable probabilistic inference is involved requiring too many random samples. There have been several efforts developing efficient training methods for SFNN having binary random latent units (Neal, 1990; Saul et al., 1996; Tang & Salakhutdinov, 2013; Bengio et al., 2013; Raiko et al., 2014; Gu et al., 2015) (see Section 2.1 for more details). Howe",Estimating or propagating gradients through stochastic neurons for conditional computation | Mixture density networks | Net2net: Accelerating learning via knowledge transfer | Generative adversarial nets | Muprop: Unbiased backpropagation for stochastic neural networks | Noisy activation functions | Identity mappings in deep residual networks | Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups | Improving neural networks by preventing co-adaptation of feature detectors | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Adam: A method for stochastic optimization | Auto-encoding variational bayes | Learning multiple layers of features from tiny images | Imagenet classification with deep convolutional neural networks | Gradient-based learning applied to document recognition | Rectified linear units improve restricted boltzmann machines | Learning stochastic feedforward networks | Reading digits in natural images with unsupervised feature learning | Techniques for learning binary stochastic feedforward neural networks | A stochastic approximation method | Learning internal representations by error propagation | Weight normalization: A simple reparameterization to accelerate training of deep neural networks | Mean field theory for sigmoid belief networks | The toronto face database | Learning stochastic feedforward neural networks | Regularization of neural networks using dropconnect | Wide residual networks | Reinforcement learning neural turing machines,iclr,010
726.pdf.json,,"In the general supervised setting, we want to learn the conditional distribution p(y|x) of some random variable y, which we refer to as the task, given (samples of the) input data x. In typical applications, x is often high dimensional (for example an image or a video), while y is low dimensional, such as a label or a coarsely-quantized location. In such cases, a large part of the variability in x is actually due to nuisance factors that affect the data, but are otherwise irrelevant for the task. Since by definition these nuisance factors are not predictive of the task, they should be disregarded during the inference process. However, it often happens that modern machine learning algorithms, in part due to their high flexibility, will fit spurious correlations, present in the training data, between the nuisances and the task, thus leading to poor generalization performance. In view of this, Tishby & Zaslavsky (2015) argue that the success of deep learning is in part due to the capability of neural networks to build incrementally better representations that expose the relevant information, while at the same time discarding nuisance variability. This interpretation is intriguing, as it establishes a connection between machine learning, probabilistic inference, and information theory. However, the commonly used training methods do not seem to stem from this insight, and indeed deep networks may maintain even in the topmost layers dependencies on easily ignorable nuisances (see for example Figure 2). To bring the practice in line with the theory, and to better understand these connections, we introduce a new layer, that we call Information Dropout, which allows the network to selectively introduce multiplicative noise in the layer activations, and thus to control the flow of information. We then introduce a modified cost function, that can be seen as an approximation of the Information Bottleneck Lagrangian of Tishby et al. (1999), which encourages the creation of repre",TensorFlow: Large-scale machine learning on heterogeneous systems | On invariance and selectivity in representation learning | Classification with scattering operators | Auto-encoding variational bayes | Variational dropout and the local reparameterization trick | Learning multiple layers of features from tiny images | Recurrent models of visual attention | Visual representations: Defining properties and deep approximations | Striving for simplicity: The all convolutional net | Dropout: a simple way to prevent neural networks from overfitting | On the set of images modulo viewpoint and contrast changes | Deep learning and the information bottleneck principle,iclr,010
728.pdf.json,REINFORCEMENT LEARNING THROUGH NEURAL ENCODING,"In the early days of RL, understanding the behavior of trained policies could be done rather easily (Sutton, 1990). Researchers focused on simpler problems (Peng and Williams, 1993), and policies were built using lighter models than today (Tesauro, 1994). As a result, a meaningful analysis of policies was possible even by working with the original state representation and relating to primitive actions. However, in recent years research has made a huge step forward. Fancier models such as Deep Neural Networks (DNNs) have become a commodity (Mnih et al., 2015), and the RL community tackles bigger and more challenging problems (Silver et al., 2016). Artificial agents are even expected to be used in autonomous systems such as self-driving cars. The need to reason the behavior of trained agents, and understand the mechanisms that govern its choice of actions is pressing more than ever. Analyzing a trained policy modeled by a DNN (either graphically using the state-action diagram, or by any other mean) is practically impossible. A typical problem consists of an immense number of states, and policies often rely on skills (Mankowitz, Mann, and Mannor, 2014), creating more than a single level of planning. The resulting Markov reward processes induced by such policies are too complicated to comprehend through observation. Simplifying the behavior requires finding a suitable representation of the state space; a long-standing problem in machine learning, where extensive research has been conducted over the years (Boutilier, Dean, and Hanks, 1999). There, the goal is to come up with a transformation of the state space φ : s → ŝ, that can facilitate learning. ∗These authors contributed equally In the field of RL, where problems are sequential in nature, this problem is exacerbated since the representation of a state needs to account for the dynamics of the problem as well. Finding a suitable state representation can be phrased as a learning problem itself (Ng, 2011; Lee et al., ","Markovian state and action abstractions for mdps via hierarchical mcts | Decision-theoretic planning: Structural assumptions and computational leverage | Model selection in markovian processes | Efficient sparse coding algorithms | Some methods for classification and analysis of multivariate observations | Time regularized interrupting options | Automatic discovery of subgoals in reinforcement learning using diverse density | Autonomous discovery of abstractions through interaction with an environment | Human-level control through deep reinforcement learning | Variable resolution dynamic programming: Efficiently learning action maps in multivariate real-valued state-spaces | Sparse autoencoder | Efficient learning and planning within the dyna framework | Towards perceptual shared autonomy for robotic mobile manipulation | Mastering the game of go with deep neural networks and tree search. Nature 529:484–503 | Skill characterization based on betweenness | Reinforcement learning with soft state aggregation | Learning options in reinforcement learning | Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning | Integrated architectures for learning, planning, and reacting based on approximating dynamic programming | TD-gammon, a self-teaching backgammon program, achieves master-level play | A tutorial on spectral clustering | Graying the black box: Understanding dqns",iclr,010
730.pdf.json,BINING RECENT INSIGHTS FOR LSTMS,"When exploring a new problem, having a simple yet competitive off-the-shelf baseline is fundamental to new research. For instance, Caruana et al. (2008) showed random forests to be a strong baseline for many high-dimensional supervised learning tasks. For computer vision, off-the-shelf convolutional neural networks (CNNs) have earned their reputation as a strong baseline (Sharif Razavian et al., 2014) and basic building block for more complex models like visual question answering (Xiong et al., 2016). For natural language processing (NLP) and other sequential modeling tasks, recurrent neural networks (RNNs), and in particular Long Short-Term Memory (LSTM) networks, with a linear projection layer at the end have begun to attain a similar status. However, the standard LSTM is in many ways lacking as a baseline. Zaremba (2015), Gal (2015), and others show that large improvements are possible using a forget bias, inverted dropout regularization or bidirectionality. We add three major additions with similar improvements to off-the-shelf LSTMs: Monte Carlo model averaging, embed average pooling, and residual connections. We analyze these and other more common improvements.","An empirical evaluation of supervised learning in high dimensions | A theoretically grounded application of dropout in recurrent neural networks | Lstm: A search space odyssey | Deep residual learning for image recognition | Deep networks with stochastic depth | Modeling compositionality with multiplicative recurrent neural networks | Deep unordered composition rivals syntactic methods for text classification | Visualizing and understanding recurrent networks | Convolutional neural networks for sentence classification | Ask me anything: Dynamic memory networks for natural language processing | Distributed representations of sentences and documents | Bridging the gaps between residual learning, recurrent neural networks and visual cortex | Learning word vectors for sentiment analysis | Ensemble of generative and discriminative techniques for sentiment analysis of movie reviews | Virtual adversarial training for semi-supervised text classification | Neural tree indexers for text understanding | Glove: Global vectors for word representation | Cnn features off-the-shelf: An astounding baseline for recognition | Very deep convolutional networks for large-scale image recognition | Recursive deep models for semantic compositionality over a sentiment treebank | Dropout: a simple way to prevent neural networks from overfitting | Going deeper with convolutions | Inception-v4, inception-resnet and the impact of residual connections on learning | Improved semantic representations from tree-structured long short-term memory networks | Residual networks are exponential ensembles of relatively shallow networks | Baselines and bigrams: Simple, good sentiment and topic classification | Dynamic memory networks for visual and textual question answering | An empirical exploration of recurrent network architectures",iclr,010
731.pdf.json,BINARY PARAGRAPH VECTORS,"One of the significant challenges in contemporary information processing is the sheer volume of available data. Gantz & Reinsel (2012), for example, claim that the amount of digital data in the world doubles every two years. This trend underpins efforts to develop algorithms that can efficiently search for relevant information in huge datasets. One class of such algorithms, represented by, e.g., Locality Sensitive Hashing (Indyk & Motwani, 1998), relies on hashing data into short, localitypreserving binary codes (Wang et al., 2014). The codes can then be used to group the data into buckets, thereby enabling sublinear search for relevant information, or for fast comparison of data items. In this work we focus on learning binary codes for text documents. An important work in this direction has been presented by Salakhutdinov & Hinton (2009). Their semantic hashing leverages autoencoders with sigmoid bottleneck layer to learn binary codes from a word-count bag-ofwords (BOW) representation. Salakhutdinov & Hinton demonstrated that semantic hashing codes used as an initial document filter can improve precision of TF-IDF-based retrieval. Learning from BOW, however, has its disadvantages. First, word-count representation, and in turn the learned codes, are not in itself stronger than TF-IDF. Second, BOW is an inefficient representation: even for moderate-size vocabularies BOW vectors can have thousands of dimensions. Learning fullyconnected autoencoders for such high-dimensional vectors is impractical. Salakhutdinov & Hinton restricted the BOW vocabulary in their experiments to 2000 most frequent words. Recently several works explored simple neural models for unsupervised learning of distributed representations of words, sentences and documents. Mikolov et al. (2013) proposed log-linear models that learn distributed representations of words by predicting a central word from its context (CBOW model) or by predicting context words given the central word (Skip-gram model). Th","Estimating or propagating gradients through stochastic neurons for conditional computation | Similarity estimation techniques from rounding algorithms | On using very large target vocabulary for neural machine translation | Hierarchical multiscale recurrent neural networks | Adaptive subgradient methods for online learning and stochastic optimization | The digital universe in 2020: Big data, bigger digital shadows, and biggest growth in the far east | Iterative quantization: A procrustean approach to learning binary codes | Noise-contrastive estimation: A new estimation principle for unnormalized statistical models | Approximate nearest neighbors: towards removing the curse of dimensionality | Cumulated gain-based evaluation of ir techniques | Skip-thought vectors. In Advances in neural information processing | Using very deep autoencoders for content-based image retrieval | Distributed representations of sentences and documents | Learning document embeddings by predicting n-grams for sentiment classification of long movie reviews | Deep learning of binary hash codes for fast image retrieval | Efficient estimation of word representations in vector space | Fast search in hamming space with multiindex hashing | Dropout: A simple way to prevent neural networks from overfitting | Visualizing data using t-SNE | Hashing for similarity search: A survey | Exponential family harmoniums with an application to information retrieval",iclr,010
732.pdf.json,GENERATIVE PARAGRAPH VECTOR,"A central problem in many text based applications, e.g., sentiment classification (Pang & Lee, 2008), question answering (Stefanie Tellex & Marton., 2003) and machine translation (I. Sutskever & Le, 2014), is how to capture the essential meaning of a piece of text in a fixed-length vector. Perhaps the most popular fixed-length vector representations for texts is the bag-of-words (or bag-of-ngrams) (Harris, 1954). Besides, probabilistic latent semantic indexing (PLSI) (Hofmann, 1999) and latent Dirichlet allocation (LDA) (Blei & Jordan, 2003) are two widely adopted alternatives. A recent paradigm in this direction is to use a distributed representation for texts (T. Mikolov & Dean, 2013a). In particular, Le and Mikolov (Quoc Le, 2014; Andrew M.Dai, 2014) show that their method, Paragraph Vector (PV), can capture text semantics in dense vectors and outperform many existing representation models. Although PV is an efficient method for learning high-quality distributed text representations, it suffers a similar problem as PLSI that it provides no model on text vectors: it is unclear how to infer the distributed representations for texts outside of the training set with the learned model (i.e., learned text and word vectors). Such a limitation largely restricts the usage of the PV model, especially in those prediction focused scenarios. Inspired by the completion and improvement of LDA over PLSI, we first introduce the Generative Paragraph Vector (GPV) with a complete generation process for a corpus. Specifically, GPV can be viewed as a probabilistic extension of the Distributed Bag of Words version of Paragraph Vector (PVDBOW), where the text vector is viewed as a hidden variable sampled from some prior distributions, and the words within the text are then sampled from the softmax distribution given the text and word vectors. With a complete generative process, we are able to infer the distributed representations of new texts based on the learned model. Meanwhile, the p","Document embedding with paragraph vectors | Latent dirichlet allocation | Supervised topic models | Learning distributed representations of sentences from unlabelled data | Self-adaptive hierarchical sentence model | Probabilistic latent semantic indexing | Sequence to sequence learning with neural networks | Generating text with recurrent neural networks | Deep recursive neural networks for compositionality in language | Improved semantic representations from tree-structured long short-term memory networks | Convolutional neural networks for sentence classification | Learning question classifiers | Deep unordered composition rivals syntactic methods for text classification | A convolutional neural network for modelling sentences | Improving distributional similarity with lessons learned from word embeddings | A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts | Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales | Opinion mining and sentiment analysis | Distributed representations of sentences and documents | Semantic compositionality through recursive matrix-vector spaces | Learning representations by back-propagating | Indexing by latent semantic analysis | Baselines and bigrams: Simple, good sentiment and topic classification | Introduction to Modern Information Retrieval | Recursive deep models for semantic compositionality over a sentiment treebank | Quantitative evaluation of passage retrieval algorithms for question answering | Distributed representations of words and phrases and their compositionality | Efficient estimation of word representations in vector space",iclr,010
733.pdf.json,HOST-BASED INTRUSION DETECTION SYSTEMS,"An intrusion detection system (IDS) refers to a hardware/software platform for monitoring network or system activities to detect malicious signs therefrom. Nowadays, practically all existing computer systems operate in a networked environment, which continuously makes them vulnerable to a variety of malicious activities. Over the years, the number of intrusion events is significantly increasing across the world, and intrusion detection systems have already become one of the most critical components in computer security. With the explosive growth of logging data, the role of machine learning in effective discrimination between malicious and benign system activities has never been more important. A survey of existing IDS approaches needs a multidimensional consideration. Depending on the scope of intrusion monitoring, there exist two main types of intrusion detection systems: networkbased (NIDS) and host-based (HIDS). The network-based intrusion detection systems monitor communications between hosts, while the host-based intrusion detection systems monitor the activity on a single system. From a methodological point of view, intrusion detection systems can also be classified into two classes (Jyothsna et al., 2011): signature-based and anomaly-based. The signaturebased approaches match the observed behaviors against templates of known attack patterns, while the anomaly-based techniques compare the observed behaviors against an extensive baseline of normal behaviors constructed from prior knowledge, declaring each of anomalous activities to be an attack. The signature-based methods detect already known and learned attack patterns well but have an innate difficulty in detecting unfamiliar attack patterns. On the other hand, the anomaly-based methods can potentially detect previously unseen attacks but may suffer from making a robust baseline of normal behavior, often yielding high false alarm rates. The ability to detect a ‘zero-day’ attack (i.e., vulnerability unknown ",Neural machine translation by jointly learning to align and translate | Learning long-term dependencies with gradient descent is difficult | A neural probabilistic language model | The use of the area under the roc curve in the evaluation of machine learning algorithms | Analysis of the 1999 darpa/lincoln laboratory ids evaluation data with netadhict | Learning phrase representations using rnn encoder-decoder for statistical machine translation | Generation of a new ids test dataset: Time to retire the kdd collection | A semantic approach to host-based intrusion detection systems using contiguousand discontiguous system call patterns | A neural network component for an intrusion detection system | A sense of self for unix processes | The evolution of system-call monitoring | Speech recognition with deep recurrent neural networks | Teaching machines to read and comprehend | A multi-layer model for anomaly intrusion detection using program sequences of system calls | Long short-term memory | Intrusion detection using sequences of system calls | A simple and efficient hidden markov model scheme for host-based anomaly intrusion detection | Exploring the limits of language modeling | A review of anomaly based intrusion detection systems | Adam: A method for stochastic optimization | Using text categorization techniques for intrusion detection | Evaluating intrusion detection systems: The 1998 darpa off-line intrusion detection evaluation | Rectifier nonlinearities improve neural network acoustic models | Testing intrusion detection systems: a critique of the 1998 and 1999 darpa intrusion detection system evaluations as performed by lincoln laboratory | Linguistic regularities in continuous space word representations | Intrusion detection using neural networks and support vector machines | A neural attention model for abstractive sentence summarization | Intrusion detection with neural networks | Unearthing stealthy program attacks buried in extremely long execution paths | Dropout: A simple way to prevent neural networks from overfitting | Applying long short-term memory recurrent neural networks to intrusion detection | Evaluating performance of long short-term memory recurrent neural networks on intrusion detection data | Determining the operational limits of an anomaly-based intrusion detector | Visualizing data using t-sne | Mimicry attacks on host-based intrusion detection systems | A new approach to intrusion detection using artificial neural networks and fuzzy clustering | Detecting intrusions using system calls: Alternative data models | Evaluating host-based anomaly detection systems: Application of the frequency-based algorithms to adfa-ld | System call anomaly detection using multihmms | Recurrent neural network regularization,iclr,010
734.pdf.json,DEEP VARIATIONAL CANONICAL CORRELATION ANALYSIS,"In the multi-view representation learning setting, we have multiple views/measurements of the same underlying signal, and the goal is to learn useful features of each view using complementary information contained in the views. The intuition underlying this setting is that the learned features can help uncover the common sources of variation in the views, which can be helpful for exploratory analysis or for downstream tasks. A classical approach in this setting is canonical correlation analysis (CCA, Hotelling, 1936) and its nonlinear extensions, including the kernel extension (Lai and Fyfe, 2000; Akaho, 2001; Melzer et al., 2001; Bach and Jordan, 2002) and the deep neural network (DNN) extension (Andrew et al., 2013; Wang et al., 2015b). CCA projects two random vectors x ∈ Rdx and y ∈ Rdy into a lowerdimensional subspace so that the projections are maximally correlated. There is a probabilistic latent variable model interpretation of linear CCA (Bach and Jordan, 2005) as shown in Figure 1 (left). Assume that x and y are linear functions of some lower-dimensional random variable z ∈ Rdz , where dz ≤ min(dx, dy). When the prior distribution of the latent variable p(z) and the conditional distributions p(x|z) and p(y|z) are Gaussian, Bach and Jordan (2005) showed that E[z|x] (resp. E[z|y]) lives in the same space as the linear CCA projection for x (resp. y). This generative interpretation of CCA is often lost in nonlinear extensions of CCA. For example, in deep CCA (DCCA, (Andrew et al., 2013)), to extend CCA to nonlinear mappings with greater representation power, one extracts nonlinear features from the original inputs of each view using two DNNs, f for x and g for y, so that the canonical correlation of the DNN outputs (measured by a linear CCA with projection matrices U and V) is maximized. Formally, given a dataset of N pairs of observations (x1,y1), . . . , (xN ,yN ) of the random vectors (x,y), DCCA optimizes max Wf ,Wg U,V tr ( U>f(X)g(Y)>V ) s.t. U> ( f(X)f(X",A kernel method for canonical correlation analysis | GSNs: Generative stochastic networks | Deep canonical correlation analysis | Kernel independent component analysis | A probabilistic interpretation of canonical correlation analysis | Image classification using random forests and ferns | Importance weighted autoencoders | Generative adversarial nets | DRAW: A recurrent neural network for image generation | Multilingual distributed representations without word alignment | Tandem connectionist feature extraction for conventional HMM systems | Relations between two sets of variates | The mir flickr retrieval evaluation | Factorized latent spaces with structured sparsity | ADAM: A method for stochastic optimization | Auto-encoding variational Bayes | Semi-supervised learning with deep generative models | Bayesian canonical correlation analysis | Kernel and nonlinear canonical correlation analysis | Gradient-based learning applied to document recognition | Deep multilingual correlation for improved word embeddings. In The 2015 Conference of the North American Chapter of the Association for Computational Linguistics - Human Language Technologies (NAACL-HLT | Adversarial autoencoders | Color and texture descriptors | Nonlinear feature extraction using generalized canonical correlation analysis | Shared kernel information embedding for discriminative inference | Rectified linear units improve restricted Boltzmann machines | Multimodal deep learning | Modeling the shape of the scene: A holistic representation of the spatial envelope | The Kaldi speech recognition toolkit | Stochastic backpropagation and approximate inference in deep generative models | Factorized orthogonal latent spaces | Improved multimodal deep learning with variation of information | Learning structured output representation using deep conditional generative models | Multimodal learning with deep boltzmann machines | Dropout: A simple way to prevent neural networks from overfitting | Visualizing data using t-SNE | Bayesian CCA via group sparsity | Variational Bayesian approach to canonical correlation analysis | Large-scale approximate kernel canonical correlation analysis | Unsupervised learning of acoustic features via deep canonical correlation analysis | On deep multi-view representation learning | X-Ray Microbeam Speech Production | Deep correlation for matching images and text | The HTK book version 2.2,iclr,010
735.pdf.json,SOLVING INVERSE PROBLEMS,"Dimensionality reduction techniques are widely used in data modeling, visualization and unsupervised learning. Principal component analysis (PCAJolliffe (2002)), Kernel PCA (KPCASchölkopf et al. (1998)) and Latent Variable Models (LVMsLawrence (2005)) are some of the well known techniques used to create low dimensional representations of the given data while preserving its significant information. One key deployment of low-dimensional modeling occurs in solving ill-posed inference problems. Assuming the valid solutions to the problem lie near a low-dimensional manifold (i.e. can be parametrized with a reduced set of variables) allows for a tractable inference for otherwise underconstrained problems. After the seminal work of Candès & Recht (2009); Recht et al. (2010) on guaranteed rank minimization of the matrix via trace norm heuristics Fazel (2002), many ill-posed computer vision problems have been tackled by using the trace norm — a convex surrogate of the rank function — as a regularization term in an energy minimization frameworkCandès & Recht (2009); Zhou et al. (2014). The flexible and easy integration of low-rank priors is one of key factors for versatility and success of many algorithms. For example, pre-trained active appearance models Cootes et al. (2001) or 3D morphable models Blanz & Vetter (1999) are converted to robust feature tracking Poling et al. (2014), dense registration Garg et al. (2013b) and vivid reconstructions of natural videos Garg et al. (2013a) with no a priori knowledge of the scene. Various bilinear factorization problems like background modeling, structure from motion or photometric stereo are also addressed with a variational formulation of the trace norm regularization Cabral et al. (2013). On the other hand, although many non-linear dimensionality reduction techniques — in particular KPCA — have been shown to outperform their linear counterparts for many data modeling tasks, they are seldom used to solve inverse problems without","Input space regularization stabilizes pre-images for kernel pca de-noising | Nonrigid structure from motion in trajectory space. In Advances in neural information processing | Learning to find pre-images | Analysis of multiphase flows using dual-energy gamma densitometry and neural networks. Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers | A morphable model for the synthesis of 3d faces | Recovering non-rigid 3d shape from image streams | Unifying nuclear norm and bilinear factorization approaches for low-rank matrix decomposition | Exact matrix completion via convex optimization | A first-order primal-dual algorithm for convex problems with applications to imaging | Active appearance models | A simple prior-free method for non-rigid structurefrom-motion factorization | Dense reconstruction using 3d object shape priors | 1/2-based iterative matrix completion for data transmission in lossy environment | Matrix rank minimization with applications | Dense variational reconstruction of non-rigid surfaces from monocular video | A variational approach to video registration with subspace constraints | Rank priors for continuous non-linear dimensionality reduction | Kernel non-rigid structure from motion | Non-rigid structure from motion with complementary rank-3 spaces | Robust regression | Principal component analysis | The pre-image problem in kernel methods | Probabilistic non-linear principal component analysis with gaussian process latent variable models | Kernel pca and de-noising in feature spaces | Robust kernel principal component analysis | Better feature tracking through subspace constraints | Nonlinear shape manifolds as shape priors in level set segmentation and tracking | Guaranteed minimum-rank solutions of linear matrix equations via nuclear norm minimization | Conjugate duality and optimization, volume | Missing data in kernel pca | Nonlinear component analysis as a kernel eigenvalue problem | Probabilistic principal component analysis | Robust principal component analysis: Exact recovery of corrupted low-rank matrices via convex optimization | Robust sparse principal component analysis | Low-rank modeling and its applications in image analysis | L1/2 regularization: a thresholding representation theory and a fast solver | 3D reconstruction errors for different NRSfM approaches and our TNH Algorithm given ground truth camera projection matrices. Results for all the methods (except TNH",iclr,010
736.pdf.json,REVISITING BATCH NORMALIZATION FOR PRACTICAL DOMAIN ADAPTATION,"Training a DNN for a new image recognition task is expensive. It requires a large amount of labeled training images that are not easy to obtain. One common practice is to use labeled data from other related source such as a different public dataset, or harvesting images by keywords from a search engine. Because 1) the distributions of the source domains (third party datasets or Internet images) are often different from the target domain (testing images); and 2) DNN is particularly good at capturing dataset bias in its internal representation (Torralba & Efros, 2011), which eventually leads to overfitting, imperfectly paired training and testing sets usually leads to inferior performance. Known as domain adaptation, the effort to bridge the gap between training and testing data distributions has been discussed several times under the context of deep learning (Tzeng et al., 2014; Long et al., 2015; Tzeng et al., 2015; Ganin & Lempitsky, 2015). To make the connection between the domain of training and the domain of testing, most of these methods require additional optimization steps and extra parameters. Such additional computational burden could greatly complicate the training of a DNN which is already intimidating enough for most people. In this paper, we propose a simple yet effective approach called AdaBN for batch normalized DNN domain adaptation. We hypothesize that the label related knowledge is stored in the weight matrix of each layer, whereas domain related knowledge is represented by the statistics of the Batch Normalization (BN) (Ioffe & Szegedy, 2015) layer. Therefore, we can easily transfer the trained model to a new domain by modulating the statistics in the BN layer. This approach is straightforward to implement, has zero parameter to tune, and requires minimal computational resources. Moreover, our AdaBN is ready to be extended to more sophisticated scenarios such as multi-source domain adaptation and semi-supervised settings. Fig. 1 illustrates the fl","Landmarks-based kernelized subspace alignment for unsupervised domain adaptation | Unsupervised domain adaptation by domain invariant projection | Domain adaptations for computer vision applications | Exploiting weakly-labeled web images to improve object classification: a domain adaptation approach | Domain separation networks | Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs | MXNet: A flexible and efficient machine learning library for heterogeneous distributed systems | DLID: Deep learning for domain adaptation by interpolating between domains | DeCAF: A deep convolutional activation feature for generic visual recognition | The art of computer programming | Unsupervised visual domain adaptation using subspace alignment | Unsupervised domain adaptation by backpropagation | Domain adaptive neural networks for object recognition | Geodesic flow kernel for unsupervised domain adaptation | Connecting the dots with landmarks: Discriminatively learning domain-invariant features for unsupervised domain adaptation | Domain adaptation for object recognition: An unsupervised approach | A kernel two-sample test | Caltech-256 object category dataset | Deep residual learning for image recognition | Correcting sample selection bias by unlabeled data | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Caffe: Convolutional architecture for fast feature embedding | Undoing the damage of dataset bias | Imagenet classification with deep convolutional neural networks | Learning transferable features with deep adaptation networks | Unsupervised domain adaptation with residual transfer networks | Domain adaptation via transfer component analysis | Visual domain adaptation: A survey of recent advances | ImageNet large scale visual recognition challenge | Adapting visual category models to new domains | Improving predictive inference under covariate shift by weighting the loglikelihood function | Deep coral: Correlation alignment for deep domain adaptation | Return of frustratingly easy domain adaptation | Rethinking the inception architecture for computer vision | A deeper look at dataset bias | Unbiased look at dataset bias | Deep domain confusion: Maximizing for domain invariance | Simultaneous deep transfer across domains and tasks | Visualizing data using t-sne | How transferable are features in deep neural networks",iclr,010
737.pdf.json,,"Much of the recent research on deep convolutional neural networks (CNNs) has focused on increasing accuracy on computer vision datasets. For a given accuracy level, there typically exist multiple CNN architectures that achieve that accuracy level. Given equivalent accuracy, a CNN architecture with fewer parameters has several advantages: • More efficient distributed training. Communication among servers is the limiting factor to the scalability of distributed CNN training. For distributed data-parallel training, communication overhead is directly proportional to the number of parameters in the model (Iandola et al., 2016). In short, small models train faster due to requiring less communication. • Less overhead when exporting new models to clients. For autonomous driving, companies such as Tesla periodically copy new models from their servers to customers’ cars. This practice is often referred to as an over-the-air update. Consumer Reports has found that the safety of Tesla’s Autopilot semi-autonomous driving functionality has incrementally improved with recent over-the-air updates (Consumer Reports, 2016). However, over-theair updates of today’s typical CNN/DNN models can require large data transfers. With AlexNet, this would require 240MB of communication from the server to the car. Smaller models require less communication, making frequent updates more feasible. • Feasible FPGA and embedded deployment. FPGAs often have less than 10MB1 of onchip memory and no off-chip memory or storage. For inference, a sufficiently small model could be stored directly on the FPGA instead of being bottlenecked by memory bandwidth (Qiu et al., 2016), while video frames stream through the FPGA in real time. Further, when deploying CNNs on Application-Specific Integrated Circuits (ASICs), a sufficiently small model could be stored directly on-chip, and smaller models may enable the ASIC to fit on a smaller die. ∗http://deepscale.ai 1For example, the Xilinx Vertex-7 FPGA has a maximum ","Shallow networks for high-accuracy road object-detection | SegNet: A deep convolutional encoderdecoder architecture for image segmentation | A implementation of squeezenet in chainer | An optimization methodology for neural network weights and architectures | Mxnet: A flexible and efficient machine learning library for heterogeneous distributed systems | 3d object proposals for accurate object class detection | cuDNN: efficient primitives for deep learning | Keras: Deep learning library for theano and tensorflow | Torch7: A matlab-like environment for machine learning | Distributed deep learning using synchronous stochastic gradient descent | ImageNet: A large-scale hierarchical image database | Exploiting linear structure within convolutional networks for efficient evaluation | Decaf: A deep convolutional activation feature for generic visual recognition | From captions to visual concepts and back | Deformable part models are convolutional neural networks | Zynqnet: An fpga-accelerated embedded convolutional neural network | Ristretto: Hardware-oriented approximation of convolutional neural networks | Deep compression: Compressing DNNs with pruning, trained quantization and huffman coding. arxiv:1510.00149v3, 2015a | Learning both weights and connections for efficient neural networks | Eie: Efficient inference engine on compressed deep neural network | Song han and jeff pool and sharan narang and huizi mao and shijian tang and erich elsen and bryan catanzaro and john tran and william | convert squeezenet to mxnet | Delving deep into rectifiers: Surpassing human-level performance on imagenet classification | Convolutional neural networks at constrained time cost | Deep residual learning for image recognition | Densenet: Implementing efficient convnet descriptor pyramids | DeepLogo: Hitting logo recognition with the deep neural network hammer | FireCaffe: near-linear acceleration of deep neural network training on compute clusters | Batch normalization: Accelerating deep network training by reducing internal covariate | Caffe: Convolutional architecture for fast feature embedding | ImageNet Classification with Deep Convolutional Neural Networks | Backpropagation applied to handwritten zip code recognition | An optimization methodology for neural network weights and architectures | Systematic evaluation of cnn advances on the imagenet | Rectified linear units improve restricted boltzmann machines | Going deeper with embedded fpga platform for convolutional neural network | Very deep convolutional networks for large-scale image recognition | Practical bayesian optimization of machine learning algorithms | Dropout: a simple way to prevent neural networks from overfitting | Evolving neural networks through augmenting topologies | Rethinking the inception architecture for computer vision | Inception-v4, inception-resnet and the impact of residual connections on learning | Chainer: a next-generation open source framework for deep learning | FireModule.lua. https://github.com/Element-Research/dpnn/ blob/master/FireModule.lua, 2016 | Deformable part descriptors for fine-grained recognition and attribute prediction",iclr,010
738.pdf.json,,"Deep neural networks have achieved state-of-the-art performance in many different tasks, such as computer vision (Krizhevsky et al., 2012) (Simonyan & Zisserman, 2015), speech recognition, and natural language processing (Karpathy et al., 2016). The underlying representational power of these neural networks comes from the huge parameter space, which results in an extremely large amount of computation operations and memory footprint. To reduce the memory usage and accelerate the training process, the research community has strived to eliminate the redundancy in the deep neural networks (Han et al., 2016b). Exploiting the sparsity in both weights and activations of Convolutional Neural Networks (CNNs), sparsity-centric optimization techniques (Han et al., 2016a) (Albericio et al., 2016) have been proposed to improve the speed and energy efficiency of CNN accelerators. These sparsity-centric approaches can be classified into two categories: (1) pruning unimportant weight parameters and (2) skipping zero values in activations to eliminate multiply-accumulate (MAC) operations with zero operands. Although both categories have achieved promising results for CNNs, it remains unclear if they are applicable to training other neural networks, such as LSTMbased RNNs. The network pruning approach is not suitable for training because it only benefits the inference phase of neural networks by iteratively pruning and re-training. The approach that exploits the sparsity in the activations can be used for training because the activations are involved in both the forward propagation and the backward propagation. But there are still some issues if we directly apply it to LSTM-based RNNs. The sparsity in CNN activations mostly comes from the Rectified Linear Unit (ReLU) activation function, which sets all negative values to zero. However, Long Short-Term Memory, one of the most popular RNN cells, does not adopt the ReLU function. Therefore, LSTM should exhibit much less sparsity in acti","Cnvlutin: Ineffectual-Neuron-Free Deep Neural Network Computing | Optimizing Performance of Recurrent | Predicting Parameters in Deep Learning | Deep Learning with Limited Numerical Precision | EIE: Efficient Inference | Deep Compression - Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding | Deep visual-semantic alignments for generating image descriptions | Visualizing and Understanding Recurrent Networks | ImageNet Classification with Deep Convolutional Neural Networks | Microsoft COCO: Common objects in context. Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) | Very Deep Convolutional Networks for Large-Scale Image Recognition | Sequence to sequence learning with neural networks",iclr,010
739.pdf.json,,"Polynomial feature expansion has long been used in statistics to approximate nonlinear functions Gergonne (1974); Smith (1918). The compressed sparse row (CSR) matrix format is a widelyused data structure to hold design matrices for statistics and machine learning applications. However, polynomial expansions are typically not performed directly on sparse CSR matrices, nor on any sparse matrix format for that matter, without intermediate densification steps. This densification not only adds extra overhead, but wastefully computes combinations of features that have a product of zero, which are then discarded during conversion into a sparse format. We provide an algorithm that allows CSR matrices to be the input of a polynomial feature expansion without any densification. The algorithm leverages the CSR format to only compute products of features that result in nonzero values. This exploits the sparsity of the data to achieve an improved time complexity of O(dkDk) on each vector of the matrix where k is the degree of the expansion, D is the dimensionality, and d is the density. The standard algorithm has time complexity O(Dk). Since 0 ≤ d ≤ 1, our algorithm is a significant improvement. While the algorithm we describe uses CSR matrices, it could be modified to operate on other sparse formats.",The application of the method of least squares to the interpolation of sequences | Scikit-learn: Machine learning in Python | On the standard deviations of adjusted and interpolated values of an observed polynomial function and its constants and the guidance they give towards a proper choice of the distribution of observations,iclr,010
740.pdf.json,,"Serial computing has reached a plateau and parallel, distributed architectures are becoming widely available, from machines with a few cores to cloud computing with 1000s of machines. The combination of powerful nested models with large datasets is a key ingredient to solve difficult problems in machine learning, computer vision and other areas, and it underlies recent successes in deep learning (Hinton et al., 2012; Le et al., 2012; Dean et al., 2012). Unfortunately, parallel computation is not easy, and many good serial algorithms do not parallelise well. The cost of communicating (through the memory hierarchy or a network) greatly exceeds the cost of computing, both in time and energy, and will continue to do so for the foreseeable future. Thus, good parallel algorithms must minimise communication and maximise computation per machine, while creating sufficiently many subproblems (ideally independent) to benefit from as many machines as possible. The load (in runtime) on each machine should be approximately equal. Faults become more frequent as the number of machines increases, particularly if they are inexpensivemachines. Machines may be heterogeneous and differ in CPU and memory; this is the case with initiatives such as SETI@home, which may become an important source of distributed computation in the future. Big data applications have additional restrictions. The size of the data means it cannot be stored on a single machine, so distributedmemory architectures are necessary. Sending data between machines is prohibitive because of the size of the data and the high communication costs. In some applications, more data is collected than can be stored, so data must be regularly discarded. In others, such as sensor networks, limited battery life and computational power imply that data must be processed locally. In this paper, we focus on machine learning models of the form y = FK+1(. . .F2(F1(x)) . . . ), i.e., consisting of a nested mapping from the inputx to the ou","TensorFlow: Large-scale machine learning | Out-of-sample extensions for LLE, Isomap, MDS, Eigenmaps, and spectral clustering | Incremental gradient, subgradient, and proximal methods for convex optimization: A survey | Large-scale machine learning with stochastic gradient descent | The tradeoffs of large scale learning | Distributed optimization and statistical learning via the alternating direction method of multipliers | Parallel coordinate descent for L1-regularized loss minimization | ParMAC: Distributed optimisation of nested functions, with application to learning binary autoencoders | Hashing with binary autoencoders | A fast, universal algorithm to learn parametric nonlinear embeddings | Distributed optimization of deeply nested systems | Convex optimization for big data: Scalable, randomized, and parallel algorithms for big data analytics | Deep learning with COTS HPC systems | On the Nyström method for approximating a Gram matrix for improved kernel-based learning | Iterative quantization: A Procrustean approach to learning binary codes for large-scale image retrieval | Learning binary hash codes for large-scale image search | Using MPI: Portable Parallel Programming with the Message-Passing Interface | Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups | Product quantization for nearest neighbor search | Searching in one billion vectors: Re-rank with source coding | Learning multiple layers of features from tiny images | Building high-level features using large scale unsupervised learning | Asynchronous stochastic coordinate descent: Parallelism and convergence properties | Distributed GraphLab: A framework for machine learning and data mining in the cloud | The EM Algorithm and Extensions | HOGWILD!: A lock-free approach to parallelizing stochastic gradient descent | Stochastic alternating direction method of multipliers | Optimizing affinity-based binary hashing using auxiliary coordinates | Distributed coordinate descent method for learning with big data | 1-bit stochastic gradient descent and its application to data-parallel distributed training of speech | Large-scale manifold learning | Locally Linear Landmarks for large-scale manifold learning | The Variational Nyström method for large-scale spectral problems | The role of dimensionality reduction in classification | Using the Nyström method to speed up kernel machines | Coordinate descent algorithms | Petuum: A new platform for distributed machine learning on big data | Spark: Cluster computing with working sets | Asynchronous distributed ADMM algorithm for global variable consensus optimization | Parallelized stochastic gradient descent",iclr,010
741.pdf.json,,,Learning grimaces by watching tv | Learning aligned cross-modal representations from weakly aligned data | Cross modal distillation for supervision transfer | Early visual concept learning with unsupervised deep learning | Visual concept learning: Combining machine vision and bayesian generalization on concept hierarchies | Imagenet classification with deep convolutional neural networks | Human-level concept learning through probabilistic program induction | Human-level control through deep reinforcement learning | Ambient sound provides supervision for visual learning | Deep inside convolutional networks: Visualising image classification models and saliency | Per-sample multiple kernel approach for visual concept learning | Object detectors emerge in deep scene cnns | Learning deep features for discriminative localization | On the sampling of web images for learning visual concept classifiers,iclr,010
742.pdf.json,ON THE EXPRESSIVE POWER OF DEEP NEURAL NET- WORKS,"Neural network architectures have proven “unreasonably effective” (LeCun, 2014; Karpathy, 2015) on many tasks, including image classification (Krizhevsky et al., 2012), identifying particles in high energy physics (Baldi et al., 2014), playing Go (Silver et al., 2016), and modeling human student learning (Piech et al., 2015). Despite their power, we have limited knowledge of how and why neural networks work, and much of this understanding is qualitative and heuristic. To aim for a more precise understanding, we must disentangle factors influencing their effectiveness, trainability, or how well they can be fit to data; generalizability, or how well they perform on novel examples; and expressivity, or the set of functions they can compute. All three of these properties are crucial for understanding the performance of neural networks. Indeed, for success at a particular task, neural nets must first be effectively trained on a dataset, which has prompted investigation into properties of objective function landscapes (Dauphin et al., 2014; Goodfellow et al., 2014; Choromanska et al., 2014), and the design of optimization procedures specifically suited to neural networks (Martens and Grosse, 2015). Trained networks must also be capable of generalizing to unseen data, and understanding generalization in neural networks is also an active line of research: (Hardt et al., 2015) bounds generalization error in terms of stochastic gradient descent steps, (Sontag, 1998; Bartlett and Maass, 2003; Bartlett et al., 1998) study generalization error through VC dimension, and (Hinton et al., 2015) looks at developing smaller models with better generalization. In this paper, we focus on the third of these properties, expressivity — the capability of neural networks to accurately represent different kinds of functions. As the class of functions achievable by a neural network is dependent on properties of its architecture, e.g. depth, width, fully connected, convolutional, etc; a better u","The unreasonable effectiveness of deep learning | The unreasonable effectiveness of recurrent neural networks | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | Searching for exotic particles in high-energy physics with deep learning | Mastering the game of go with deep neural networks and tree | Deep knowledge tracing | Identifying and attacking the saddle point problem in high-dimensional non-convex optimization | Qualitatively characterizing neural network optimization problems | The loss surfaces of multilayer networks | Optimizing neural networks with kronecker-factored approximate curvature | Train faster, generalize better: Stability of stochastic gradient descent | Vc dimension of neural networks | Vapnik-chervonenkis dimension of neural nets | Almost linear vc-dimension bounds for piecewise polynomial networks | Distilling the knowledge in a neural network | Multilayer feedforward networks are universal approximators | Approximation by superpositions of a sigmoidal function | A comparison of the computational power of sigmoid and Boolean threshold circuits | Expressiveness of rectifier networks | The power of depth for feedforward neural networks | Representation benefits of deep feedforward networks | On the representational efficiency of restricted boltzmann machines | On the complexity of neural network classifiers: A comparison between shallow and deep architectures | On the number of response regions of deep feed forward networks with piece-wise linear activations | On the number of linear regions of deep neural networks | Exponential expressivity in deep neural networks through transient chaos | Links between perceptrons, mlps and svms | On some inequalities for the gamma function",iclr,010
743.pdf.json,,"In this paper we discuss both the presence and application of universality in optimization algorithms. More precisely, in order to optimize an energy functional when the functional itself and the initial guess are random, we consider the following iterative algorithms: conjugate gradient for solving a linear system, gradient descent for spin glasses, and stochastic gradient descent for deep learning. A bounded, piecewise differentiable random field (See Adler & Taylor (2009) for an account on the connection of random fields and geometry), where the randomness is non-degenerate, yields a landscape with many saddle points and local minima. Given such a landscape and a moving particle that takes steps to reach a low-energy level, an essential quantity is the time the particle takes until it stops which we call the halting time. Many useful bounds on the halting time are known for convex cases, where the stopping condition produces a halting time that is, essentially, the time to find the minimum. In non-convex cases, however, the particle knows only the information that can be calculated locally. And a locally measurable stopping condition, such as the norm of the gradient at the present point, or the difference in altitude with respect to the previous step, can lead the algorithm to locate a local minimum. This feature allows the halting time to be calculated in a broad range of non-convex, high-dimensional problems. A prototypical example of such a random field is the class of polynomials with random coefficients. Spin glasses and deep learning cost functions are then special cases of such fields that yield different landscapes. Polynomials with random coefficients are not only a broad class of functions, but also they are hard to study mathematically in any generality. Therefore, in order to capture essential features of such problems, we focus on their subclasses that are well studied (spin glasses) and practically relevant (deep learning cost functions). The halti","Random fields and geometry | Random matrices and complexity of spin glasses | A neural computation model for decision-making times | The loss surface of multilayer networks | Identifying and attacking the saddle point problem in high-dimensional non-convex optimization | Orthogonal polynomials and random matrices: a Riemann-Hilbert approach, volume 3 | Universality for the Toda algorithm to compute the eigenvalues of a random matrix | Universality for eigenvalue algorithms on sample covariance matrices | Universality in numerical computations with random data | On the condition number of the critically-scaled laguerre unitary ensemble | Behavior of slightly perturbed lanczos and conjugate-gradient recurrences | Predicting the behavior of finite precision lanczos and conjugate gradient computations | Train faster, generalize better: Stability of stochastic gradient descent | Method of Conjugate Gradients for solving Linear Systems | Complexity theory of numerical linear algebra | Gradient descent converges to minimizers | Sampling unitary ensembles | Under review as a conference paper at ICLR | APPENDIX FURTHER MOTIVATION FOR THE STUDY Asymptotic error bounds for loss functions have been useful in the study of convergence properties of various models under various algorithms, for instance, at the heart",iclr,010
744.pdf.json,LEARNING IDENTITY MAPPINGS WITH RESIDUAL GATES,"As the number of layers of neural networks increase, effectively training its parameters becomes a fundamental problem (Larochelle et al. (2009)). Many obstacles challenge the training of neural networks, including vanishing/exploding gradients (Bengio et al. (1994)), saturating activation functions (Xu et al. (2016)) and poor weight initialization (Glorot & Bengio (2010)). Techniques such as unsupervised pre-training (Bengio et al. (2007)), non-saturating activation functions (Nair & Hinton (2010)) and normalization (Ioffe & Szegedy (2015)) target these issues and enable the training of deeper networks. However, stacking more than a dozen layers still lead to a hard to train model. Recently, models such as Residual Networks (He et al. (2015b)) and Highway Neural Networks (Srivastava et al. (2015)) permitted the design of networks with hundreds of layers. A key idea of these models is to allow for information to flow more freely through the layers, by using shortcut connections between the layer’s input and output. This layer design greatly facilitates training, due to shorter paths between the lower layers and the network’s error function. In particular, these models can more easily learn identity mappings in the layers, thus allowing the network to be deeper and learn more abstract representations (Bengio et al. (2012)). Such networks have been highly successful in many computer vision tasks. On the theoretical side, it is suggested that depth contributes exponentially more to the representational capacity of networks than width (Eldan & Shamir (2015) Telgarsky (2016) Bianchini & Scarselli (2014) Montúfar et al. (2014)). This agrees with the increasing depth of winning architectures on challenges such as ImageNet (He et al. (2015b) Szegedy et al. (2014)). Increasing the depth of networks significantly increases its representational capacity and consequently its performance, an observation supported by theory (Eldan & Shamir (2015) Telgarsky (2016) Bianchini & Sca","Learning long-term dependencies with gradient descent is difficult | Greedy layer-wise training of deep networks | Representation Learning: A Review and New Perspectives | On the complexity of neural network classifiers: A comparison between shallow and deep architectures | Torch7: A matlab-like environment for machine learning | The Power of Depth for Feedforward Neural Networks | Understanding the difficulty of training deep feedforward neural networks | Understanding the difficulty of training deep feedforward neural networks | Deep sparse rectifier neural networks | Highway and Residual Networks learn Unrolled Iterative Estimation | Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification | Deep Residual Learning for Image Recognition. ArXiv e-prints, December 2015b | Identity Mappings in Deep Residual Networks | Deep Networks with Stochastic Depth | Densely connected convolutional networks | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Adam: A Method for Stochastic Optimization | Learning multiple layers of features from tiny images | Exploring strategies for training deep neural networks | FractalNet: Ultra-Deep Neural Networks without Residuals | Gradient-based learning applied to document recognition | On the Number of Linear Regions of Deep Neural Networks | Rectified linear units improve restricted boltzmann machines | FitNets: Hints for Thin Deep Nets | Striving for Simplicity: The All Convolutional Net | Dropout: A simple way to prevent neural networks from overfitting | Resnet in Resnet: Generalizing Residual Architectures | Benefits of depth in neural networks | Revise Saturated Activation Functions | Understanding deep learning requires rethinking generalization",iclr,010
745.pdf.json,,"Stochastic Gradient Descent (SGD) is an effective method for many regression and classification tasks. It is a simple algorithm with few hyper-parameters and its convergence rates are well understood both theoretically and empirically. However, its performance scalability is severely limited by its inherently sequential computation. SGD iteratively processes its input dataset where the computation at each iteration depends on the model parameters learned from the previous iteration. Current approaches for parallelizing SGD do not honor this inter-step dependence across threads. Each thread learns a local model independently and combine these models in ways that can break sequential behavior. For instance, threads in HOGWILD! Recht et al. (2011) racily update a shared global model without holding any locks. In parameter-server Li et al. (2014a), each thread (or machine) periodically sends its model deltas to a server that applies them to a global model. In ALLREDUCE Agarwal et al. (2014), threads periodically reach a barrier where they compute a weightedaverage of the local models. Although these asynchronous parallel approaches reach the optimal solution eventually, they can produce a model that is potentially different from what a sequential SGD would have produced after processing a certain number of examples. Our experiments indicate that this makes their convergence rate slower than sequential SGD in terms of total number of examples studied. Our experiments show that all these algorithms either do not scale or their accuracy on the same number of examples falls short of a sequential baseline. To address this problem, this paper presents SYMSGD, a parallel SGD algorithm that seeks to retain its sequential semantics. The key idea is for each thread to generate a sound combiner that allows the local models to be combined into a model that is the same as the sequential model. This paper describes a method for generating sound combiners for a class of SGD algorithms","Database-friendly random projections | A reliable effective terascale linear learning system | Twelve ways to fool the masses | Adaptive subgradient methods for online learning and stochastic optimization | Extensions of Lipschitz mappings into a Hilbert space. In Conference in modern analysis and probability (New Haven, Conn., 1982), volume 26 of Contemporary Mathematics, pp. 189–206 | Slow learners are fast | Scaling distributed machine learning with the parameter server | Scalability! but at what cost | Hogwild: A lock-free approach to parallelizing stochastic gradient descent | High performance parallel stochastic gradient descent in shared memory | Parallelized stochastic gradient descent",iclr,010
746.pdf.json,,"Many algorithmic tasks can be described as discrete input-output mappings, but this “black-box” vision hides all the fundamental questions that explain how and why the task can be optimally solved, which is the starting point of the study of algorithms and complexity. A powerful and general framework that breaks into this vision is the principle that many tasks have some degree of scale invariance or self-similarity, meaning that the ability to solve the task for a certain input size is essentially all that is needed in order to solve it for larger sizes. This principle is the basis of dynamic programming and is ubiquitous in most areas of discrete mathematics, from geometry to graph theory. In the case of images and audio signals, invariance principles are also critical for success: CNNs exploit both translation invariance and scale separation with multilayer, localized convolutional operators, which breaks the curse of dimensionality and brings the essential inductive bias explaining the success of CNNs. In our scenario of discrete algorithmic tasks, we build our model on the principle of divide and conquer, which provides us with a form of parameter sharing across scales akin to that of CNNs across space or RNNs across time. While neural networks have been successful so far at providing flexible models for discrete regression and prediction tasks, mostly in Natural Language processing and discrete Reinforcement Learning, they are typically unaware and uninterested in complexity questions. Whereas some models are trained and tested at a fixed input/output scale (such as regression problems with generic fully connected neural networks), authors have explored ways to make training and testing less dependent of the input scale. The most prominent examples are Convolutional architectures, that ∗Currently on leave from UC Berkeley exploit translation invariance to accept variable size inputs by averaging their predictions at the last layer; and recurrent neural network",Neural turing machines | Learning to transduce with unbounded memory | Long short-term memory | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Inferring algorithmic patterns with stack-augmented recurrent nets | Neural gpus learn algorithms | The induction of dynamical recognizers | The graph neural network model | End-to-end memory networks | Learning multiagent communication with backpropagation | Sequence to sequence learning with neural networks. In Advances in neural information processing | Fractal encoding of context-free grammars in connectionist networks | Order matters: Sequence to sequence for sets | Learning to execute | Reinforcement learning neural turing machines-revised,iclr,010
747.pdf.json,,"Practitioners of machine learning regularly inspect the coefficients of linear models as a measure of feature importance. This process allows them to understand and debug these models. The natural analog of these coefficients for deep models are the gradients of the prediction score with respect to the input. For linear models, the gradient of an input feature is equal to its coefficient. For deep nonlinear models, the gradient can be thought of as a local linear approximation (Simonyan et al. (2013)). Unfortunately, (see the next section), the network can saturate and as a result an important input feature can have a tiny gradient. While there has been other work (see Section 2.10) to address this problem, these techniques involve instrumenting the network. This instrumentation currently involves significant developer effort because they are not primitive operations in standard machine learning libraries. Besides, these techniques are not simple to understand—they invert the operation of the network in different ways, and have their own peculiarities—for instance, the feature importances are not invariant over networks that compute the exact same function (see Figure 14). In contrast, the method we propose builds on the very familiar, primitive concept of the gradient—all it involves is inspecting the gradients of a few carefully chosen counterfactual inputs that are scaled versions of the initial input. This allows anyone who knows how to extract gradients—presumably even novice practitioners that are not very familiar with the network’s implementation—to debug the network. Ultimately, this seems essential to ensuring that deep networks perform predictably when deployed.","Values of Non-Atomic Games | How to explain individual classification decisions | Allocation of shared costs: A set of axioms yielding A unique procedure | Layer-wise relevance propagation for neural networks with local renormalization layers | Inverting visual representations with convolutional networks, 2015. URL http://arxiv.org/abs/1506.02753 | Visualizing higher-layer features of a deep network | Understanding the difficulty of training deep feedforward neural networks | Molecular graph convolutions: moving beyond fingerprints | Building high-level features using large scale unsupervised learning | Understanding deep image representations by inverting them | Building a large annotated corpus of english: The penn treebank | why should I trust you?”: Explaining the predictions of any classifier | Model-agnostic interpretability of machine learning | ImageNet Large Scale Visual Recognition Challenge | Evaluating the visualization of what a deep neural network has learned | Not just a black box: Learning important features through propagating activation differences | Deep inside convolutional networks: Visualising image classification models and saliency | Striving for simplicity: The all convolutional net | Axiomatic attribution for multilinear functions | Understanding neural networks through deep visualization | Feature selection for high-dimensional data: A fast correlation-based filter solution | Recurrent neural network regularization | Visualizing and understanding convolutional networks",iclr,010
748.pdf.json,A CONVOLUTIONAL ENCODER MODEL FOR NEURAL MACHINE TRANSLATION,"Neural machine translation (NMT) is an end-to-end approach to machine translation (Sutskever et al., 2014). The most successful approach to date encodes the source sentence with a bi-directional recurrent neural network (RNN) into a variable length representation and then generates the translation left-to-right with another RNN where both components interface via a soft-attention mechanism (Bahdanau et al., 2015; Luong et al., 2015a; Bradbury & Socher, 2016; Sennrich et al., 2016b). The recurrent networks are typically parameterized as long short term memory networks (LSTM; Hochreiter et al. 1997) or gated recurrent units (GRU; Cho et al. 2014), often with residual or skip connections (Wu et al., 2016; Zhou et al., 2016) to enable stacking of several layers (§2). There have been several attempts to use convolutional encoder models for neural machine translation in the past but they were either only applied to rescoring n-best lists of classical systems (Kalchbrenner & Blunsom, 2013) or were not competitive to recurrent alternatives (Cho et al., 2014a). This is despite several attractive properties of convolutional networks. For example, convolutional networks operate over a fixed-size window of the input sequence which enables the simultaneous computation of all features for a source sentence. This contrasts with RNNs which maintain a hidden state of the entire past that prevents parallel computation within a sequence. Furthermore, a succession of convolutional layers provides a shorter path to capture relationships between elements of a sequence compared to recurrent networks.1 This also eases learning because the resulting tree-structure applies a fixed number of non-linearities compared to a recurrent neural network. Because processing is bottom-up, all words undergo the same number of transformations, whereas for recurrent networks the first word is over-processed and the last word is transformed only once. In this paper we show that an architecture based on con","Report on the 11th IWSLT evaluation campaign | On the Properties of Neural Machine Translation: Encoder-decoder Approaches | Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation | A Character-level Decoder without Explicit Segmentation for Neural Machine Translation | Torch7: A Matlab-like Environment for Machine Learning | A Simple, Fast, and Effective Reparameterization of IBM Model 2 | Deep Residual Learning for Image Recognition | Long short-term memory | On Using Very Large Target Vocabulary for Neural Machine Translation | Montreal Neural Machine Translation systems for WMT15 | Is Neural Machine Translation Ready for Deployment? A Case Study on 30 Translation Directions | Recurrent Continuous Translation Models | Adam: A Method for Stochastic Optimization | Moses: Open Source Toolkit for Statistical Machine Translation | Convolutional Encoders for Neural Machine Translation | Vocabulary Selection Strategies for Neural Machine Translation | Effective approaches to attentionbased neural machine translation | Addressing the Rare Word Problem in Neural Machine Translation | Encoding Source Language with Convolutional Neural Network for Machine Translation | Vocabulary Manipulation for Neural Machine Translation | On the Difficulty of Training Recurrent Neural Networks | Convolutional Neural Network Language Models | Sequence level Training with Recurrent Neural Networks | Neural Machine Translation of Rare Words with Subword Units | Edinburgh neural machine translation systems for wmt | Dropout: a simple way to prevent Neural Networks from overfitting | End-to-end Memory Networks | Sequence to Sequence Learning with Neural Networks | Context-dependent Translation selection using Convolutional Neural Network | Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation | Neural Machine Translation with Recurrent Attention Modeling | Deep Recurrent Models with FastForward Connections for Neural Machine Translation | BLEU per sentence length on WMT’15 English-German newstest2015. The test set is partitioned into 15 equally-sized buckets according to source sentence length. One characteristic of our convolutional encoder architecture is that the context over which outputs",iclr,010
749.pdf.json,DEEP CONVOLUTIONAL NEURAL NETWORK DESIGN PATTERNS,"Many recent articles discuss new architectures for neural networking, especially regarding Residual Networks (He et al. (2015; 2016); Larsson et al. (2016); Zhang et al. (2016); Huang et al. (2016b)). Although the literature covers a wide range of network architectures, we take a high-level view of the architectures as the basis for discovering universal principles of the design of network architecture. We discuss 14 original design patterns that could benefit inexperienced practitioners who seek to incorporate deep learning in various new applications. This paper addresses the current lack of guidance on design, a deficiency that may prompt the novice to rely on standard architecture, e.g., Alexnet, regardless of the architecture’s suitability to the application at hand. This abundance of research is also an opportunity to determine which elements provide benefits in what specific contexts. We ask: Do universal principles of deep network design exist? Can these principles be mined from the collective knowledge on deep learning? Which architectural choices work best in any given context? Which architectures or parts of architectures seem elegant? Design patterns were first described by Christopher Alexander (Alexander (1979)) in regards to the architectures of buildings and towns. Alexander wrote of a timeless quality in architecture that “lives” and this quality is enabled by building based on universal principles. The basis of design patterns is that they resolve a conflict of forces in a given context and lead to an equilibrium analogous to the ecological balance in nature. Design patterns are both highly specific, making them clear to follow, and flexible so they can be adapted to different environments and situations. Inspired by Alexander’s work, the “gang of four” (Gamma et al. (1995)) applied the concept of design patterns to the architecture of object-oriented software. This classic computer science book describes 23 patterns that resolve issues prevalent i","Understanding intermediate layers using linear classifier probes | The timeless way of building, volume 1 | Xception: Deep learning with depthwise separable convolution | The elements of statistical learning, volume 1. Springer series in statistics | Design patterns: elements of reusable object-oriented software | Noisy activation functions | Deep pyramidal residual networks | Deep residual learning for image recognition | Identity mappings in deep residual networks | Frankenstein: Learning deep face representations using small data | Densely connected convolutional networks | Deep networks with stochastic depth | Decision forests, convolutional networks and the models in-between | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Caffe: Convolutional architecture for fast feature embedding | Driving in the matrix: Can virtual worlds replace human-generated annotations for real world tasks | The unreasonable effectiveness of noisy data for fine-grained recognition | Learning multiple layers of features from tiny images | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | Zoneout: Regularizing rnns by randomly preserving hidden activations | Fractalnet: Ultra-deep neural networks without residuals | Streaming normalization: Towards simpler and more biologically-plausible normalizations for online and recurrent learning | Competitive multi-scale convolution | Bilinear cnn models for fine-grained visual recognition | On the computational efficiency of training neural networks | Convolutional residual memory networks | Neural networks: tricks of the trade | Deconstructing the ladder network architecture | Deep learning made easier by linear transformations in perceptrons | Semisupervised learning with ladder networks | Data programming: Creating large training sets, quickly | Imagenet large scale visual recognition challenge | Weight normalization: A simple reparameterization to accelerate training of deep neural networks | Convolutional neural fabrics | Boosting neural networks | Weighted residuals for very deep networks | Very deep convolutional networks for large-scale image recognition | Swapout: Learning an ensemble of deep architectures | Gradual dropin of layers to train very deep neural networks | Gradual dropin of layers to train very deep neural networks | Striving for simplicity: The all convolutional net | Dropout: a simple way to prevent neural networks from overfitting | Training very deep networks | Understanding locally competitive networks | Going deeper with convolutions | Rethinking the inception architecture for computer vision | Understanding data | Residual networks",iclr,010
750.pdf.json,,"The current success of deep learning hinges on the ability to apply gradient-based optimization to high-capacity models. It has achieved impressive results on many large-scale supervised tasks such as image classification Krizhevsky et al. (2012); He et al. (2016) and speech recognition Yu & Deng (2012). Notably, these models are extensively hungry for data. In contrast, human beings have strong ability to learn novel concepts efficiently from very few or even one example. As pointed out in Lake et al. (2016), human learning is distinguished by its richness and efficiency. To test whether machines can approach this goal, Lake et al. propose the invaluable “Omniglot” hand-written character classification benchmark Lake et al. (2011), where each training class has very few examples and the ability to fast-learn is evaluated on never-seen classes with only one example. There has been previous work on attaining rapid learning from sparse data, denoted as meta-learning or learning-to-learn Thrun. (1998); Baxter. (1998). Although used in numerous senses, the term generally refers to exploiting meta-knowledge within a single learning system across tasks or algorithms. In theory, a meta-learning is able to identify the right “inductive bias shifts” from previous experiences given enough data and many tasks Baxter. (1998). However, even if a well-designed convolutional neural network is a good “inductive bias shift” for a visual recognition task, it is still elusive to find the optimal parameter from a small training set without any prior knowledge. To alleviate this issue, low-shot learning methods have been proposed to transfer knowledge from various priors to avoid over-fitting, such as Bart & Ullman (2005). Recently, Hariharan & Girshick. (2016) propose a novel prior of gradient penalty, which works pretty well experimentally. Although an intuitive explanation is provided in Hariharan & Girshick. (2016) that a good solution of the network parameters should be stable with","Neural networks and principal component analysis: Learning from examples without local minima | Cross-generalization: Learning novel classes from a single example by feature replacement | Theoretical models of learning to learn. Learning to learn | Neural networks for pattern recogsontag, eduardo d. ”vc dimension of neural networks.” nato asi series f computer and systems sciences | Learning a similarity metric discriminatively, with application to face verification | Reducing overfitting in deep networks by decorrelating representations | Object classification from a single example utilizing class relevance metrics | Neighborhood components analysis | Low-shot visual object recognition | Deep residual learning for image recognition | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Deep learning without poor local minima | Adam: A method for stochastic optimization | Siamese neural networks for one-shot image recognition | Imagenet classification with deep convolutional neural networks | Building machines that learn and think like people | One shot learning of simple visual concepts | The multiverse loss for robust transfer learning | Imagenet large scale visual recognition challenge | One-shot learning with memory-augmented neural networks | Vc dimension of neural networks | Dropout: a simple way to prevent neural networks from overfitting | Lifelong learning algorithms | The nature of statistical learning theory | Matching networks for one shot learning | A convergence analysis of log-linear training | Automatic speech recognition",iclr,010
751.pdf.json,COMBATING DEEP REINFORCEMENT LEARNING’S SISYPHEAN CURSE WITH INTRINSIC FEAR,"Following success on Atari games (Mnih et al., 2015) and the board game Go (Silver et al., 2016), many researchers have begun exploring practical applications of deep reinforcement learning (DRL). With DRL, we might hope to replace simple hand-coded control policies with continuously learning agents. Some investigated applications include robotics (Levine et al., 2016), dialogue systems (Fatemi et al., 2016; Lipton et al., 2016), energy management (Night, 2016), and self-driving cars (Shalev-Shwartz et al., 2016). Amid this push to apply DRL, we might ask, can we trust these agents in the wild? Agents acting in real world environments might possess the ability to cause catastrophic outcomes. Consider a self-driving car that might hit pedestrians, or a domestic robot that might injure a child. We might hope to prevent DRL agents from ever making catastrophic mistakes. But doing so requires extensive prior knowledge of the environment in order to constrain the exploration of policy space (Garcıa & Fernández, 2015). Such knowledge may not always exist. In this paper, we don’t assume prior knowledge of the state-space. Already, we should note that multiple, conflicting definitions of safety and catastrophe exist, a problem that invites further philosophical consideration. We will return to this matter in Section 3. For now, we introduce a specific but plausible notion of a catastrophe. Suppose that catastrophes are a subset of states that are terminal, yielding a return of 0 and that returns are greater than or equal to ∗http://zacklipton.com 0 for non-catastrophic states. Moreover, we assume that an optimal policy never even comes near a catastrophe state. Note that this doesn’t hold in general RL problems. In a cliff world, the pot of gold might lie on the ledge of a cliff. But for a self-driving car, we don’t suspect that it ever should have to come within a split-second decision of committing murder. Finally, while we don’t assume prior knowledge of which states ar","Residual algorithms: Reinforcement learning with function approximation | Unifying count-based exploration and intrinsic motivation | Generalization in reinforcement learning: Safely approximating the value function | Intrinsically motivated reinforcement learning | Policy networks with two-stage training for dialogue systems | A comprehensive survey on safe reinforcement learning | Chattering in SARSA(λ) - a CMU learning lab internal report | Safe exploration for reinforcement learning | Consideration of risk in reinforcement learning | Adam: A method for stochastic optimization | End-to-end training of deep visuomotor policies | Self-improving reactive agents based on reinforcement learning, planning and teaching | Efficient exploration for dialogue policy learning with BBQ networks & replay buffer spiking | Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory | Catastrophic interference in connectionist networks: The sequential learning problem | Human-level control through deep reinforcement learning | Safe exploration in markov decision processes | A memory-based reinforcement learning model utilizing macroactions | The AI that cut googles energy bill could soon help you | A possibility for implementing curiosity and boredom in model-building neural controllers. In From animals to animats: proceedings of the first international conference on simulation of adaptive behavior (SAB90) | Safe, multi-agent, reinforcement learning for autonomous driving | Mastering the game of go with deep neural networks and tree search | Machine learning in non-stationary environments: Introduction to covariate shift adaptation | Learning to predict by the methods of temporal differences | Reinforcement learning: An introduction",iclr,010
754.pdf.json,LEARNING PYTHON CODE SUGGESTION WITH A SPARSE POINTER NETWORK,"Integrated development environments (IDEs) are essential tools for programmers. Especially when a developer is new to a codebase, one of their most useful features is code suggestion: given a piece of code as context, suggest a likely sequence of next tokens. Typically, the IDE suggests an identifier or a function call, including API calls. While extensive support exists for statically-typed languages such as Java, code suggestion for dynamic languages like Python is harder and less well supported because of the lack of type annotations. Moreover, suggestion engines in modern IDEs do not propose expressions or multi-statement idiomatic code. Recently, methods from statistical natural language processing (NLP) have been used to train code suggestion systems from code usage in large code repositories (Hindle et al., 2012; Allamanis & Sutton, 2013; Tu et al., 2014). To this end, usually an n-gram language model is trained to score possible completions. Neural language models for code suggestion (White et al., 2015; Das & Shah, 2015) have extended this line of work to capture more long-range dependencies. Yet, these standard neural language models are limited by the so-called hidden state bottleneck, i.e., all context information has to be stored in a fixed-dimensional internal vector representation. This limitation restricts such models to local phenomena and does not capture very long-range semantic relationships like suggesting calling a function that has been defined many tokens before. To address these issues, we create a large corpus of 41M lines of Python code by using a heuristic for crawling high-quality code repositories from GitHub. We investigate, for the first time, the use of attention (Bahdanau et al., 2014) for code suggestion and find that, despite a substantial improvement in accuracy, it still makes avoidable mistakes. Hence, we introduce a model that leverages long-range Python dependencies by selectively attending over the introduction of identifier","Tensorflow: A system for large-scale machine learning | Mining idioms from source code | Mining source code repositories at massive scale using language modeling | Learning natural coding conventions | A convolutional attention network for extreme summarization of source code | Neural machine translation by jointly learning to align and translate | Pypl popularity of programming language. http://pypl.github.io/ PYPL.html, 2016 | Long short-term memory-networks for machine reading | Contextual code completion using machine learning | Generating sequences with recurrent neural networks | Teaching machines to read and comprehend | On the naturalness of software | Long short-term memory | On using very large target vocabulary for neural machine translation | An empirical exploration of recurrent network architectures | A deep language model for software code | Improved backing-off for m-gram language modeling | Latent predictor networks for code generation | Structured generative models of natural source code | Building a large annotated corpus of english: The penn treebank | Kylm - the kyoto language modeling toolkit | On the difficulty of training recurrent neural networks | Reasoning about entailment with neural attention | Recurrent memory networks for language modeling | On the localness of software | Grammar as a foreign language | Backpropagation through time: what it does and how to do it | Toward deep learning software repositories | Githut - programming languages and github. http://githut.info/, 2016",iclr,010
755.pdf.json,,"Residual network (ResNet) was first proposed in He et al. (2015a) and extended in He et al. (2016). It followed a principled approach to add shortcut connections every two layers to a VGG-style network (Simonyan & Zisserman, 2014). The new network becomes easier to train, and achieves both lower training and test errors. Using the new structure, He et al. (2015a) managed to train a network with 1001 layers, which was virtually impossible before. Unlike Highway Network (Srivastava et al., 2015a;b) which not only has shortcut paths but also borrows the idea of gates from LSTM (Sainath et al., 2013), ResNet does not have gates. Later He et al. (2016) found that by keeping a clean shortcut path, residual networks will perform even better. Many attempts have been made to improve ResNet to a further extent. “ResNet in ResNet” (Targ et al., 2016) adds more convolution layers and data paths to each layer, making it capable of representing several types of residual units. “ResNets of ResNets” (Zhang et al., 2016) construct multilevel shortcut connections, which means there exist shortcuts that skip multiple residual units. Wide Residual Networks (Zagoruyko & Komodakis, 2016) makes the residual network shorter but wider, and achieves state of the art results on several datasets while using a shallower network. Moreover, some existing models are also reported to be improved by shortcut connections, including Inceptionv4 (Szegedy et al., 2016), in which shortcut connections make the deep network easier to train. Why are residual networks so easy to train? He et al. (2015a) suggests that layers in residual networks are learning residual mappings, making them easier to represent identity mappings, which prevents the networks from degradation when the depths of the networks increase. However, Veit et al. (2016) claims that ResNets are actually ensembles of shallow networks, which means they do not solve the problem of training deep networks completely. We propose a theoretical exp","Efficient approaches for escaping higher order saddle points in non-convex optimization | Exact calculation of the hessian matrix for the multilayer perceptron | The loss surfaces of multilayer networks | Open problem: The landscape of the loss surfaces of multilayer networks | Identifying and attacking the saddle point problem in high-dimensional non-convex optimization | Escaping from saddle pointsonline stochastic gradient for tensor decomposition | Understanding the difficulty of training deep feedforward neural networks | Toeplitz and circulant matrices: A review | Identity matters in deep learning | Deep residual learning for image recognition | Delving deep into rectifiers: Surpassing human-level performance on imagenet classification | Identity mappings in deep residual networks | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Deep learning without poor local minima | Rectified linear units improve restricted boltzmann machines | Efficient methods in convex programming | On the saddle point problem for non-convex optimization | Convolutional, Long short-term memory, fully connected deep neural networks | Exact solutions to the nonlinear dynamics of learning in deep linear neural networks | Very deep convolutional networks for large-scale image recognition | Training very deep networks | Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning. feb 2016 | Resnet in resnet: Generalizing residual architectures | Residual networks are exponential ensembles of relatively shallow networks | Wide residual networks | Residual networks of residual networks: Multilevel residual networks",iclr,010
756.pdf.json,TIONS WITH NEURAL SIMILARITY AND CONTEXT EN- CODERS,"Many dimensionality reduction or manifold learning algorithms optimize for retaining the pairwise similarities, distances, or local neighborhoods of data points. Classical scaling (Cox & Cox, 2000), kernel PCA (Schölkopf et al., 1998), isomap (Tenenbaum et al., 2000), and LLE (Roweis & Saul, 2000) achieve this by performing an eigendecomposition of some similarity matrix to obtain a low dimensional representation of the original data. However, this is computationally expensive if a lot of training examples are available. Additionally, out-of-sample representations can only be created when the similarities to the original training examples can be computed (Bengio et al., 2004). For some methods such as t-SNE (van der Maaten & Hinton, 2008), great effort was put into extending the algorithm to work with large datasets (van der Maaten, 2013) or to provide an explicit mapping function which can be applied to new data points (van der Maaten, 2009). Current attempts at finding a more general solution to these issues are complex and require the development of specific cost functions and constraints when used in place of existing algorithms (Bunte et al., 2012), which limits their applicability to new objectives. In this paper we introduce a new neural network architecture, that we will denote as similarity encoder (SimEc), which is able to learn representations that can retain arbitrary pairwise relations present in the input space, even those obtained from unknown similarity functions such as human ratings. A SimEc can learn a linear or non-linear mapping function to project new data points into a lower dimensional embedding space. Furthermore, it can take advantage of large datasets since the objective function is optimized iteratively using stochastic mini-batch gradient descent. We show on both image and text datasets that SimEcs can, on the one hand, recreate solutions found by traditional methods such as kPCA or isomap, and, on the other hand, obtain meaningful embed","Out-of-sample extensions for LLE, Isomap, MDS, Eigenmaps, and Spectral Clustering | A general framework for dimensionality-reducing data visualization mapping | Intrinsic evaluation of word vectors fails to predict extrinsic performance | Natural language processing (almost) from scratch | Reducing the dimensionality of data with neural networks | Improving word representations via global context and multiple word prototypes | Improving distributional similarity with lessons learned from word embeddings | Issues in evaluating semantic spaces using word analogies | Modeling word meaning in context with substitute vectors | Efficient estimation of word representations in vector space | Distributed representations of words and phrases and their compositionality | An introduction to kernel-based learning algorithms | GloVe: Global Vectors for Word Representation | Random features for large-scale kernel machines | Autoextend: Extending word embeddings to embeddings for synsets and lexemes | Nonlinear dimensionality reduction by locally linear embedding | Nonlinear component analysis as a kernel eigenvalue problem | A global geometric framework for nonlinear dimensionality reduction | The information bottleneck method | Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition | sense2vec-a fast and accurate method for word sense disambiguation in neural word embeddings | Word representations: a simple and general method for semi-supervised learning. In Proceedings of the 48th annual meeting of the association for computational linguistics, pp. 384–394 | Learning a parametric embedding by preserving local structure | Visualizing data using t-SNE",iclr,010
760.pdf.json,,"Deep neural networks coupled with the availability of vast amounts of data have proved very successful over the last few years at visual discrimination (Goodfellow et al., 2014; Kingma & Welling, 2013; LeCun et al., 1998; Mnih & Gregor, 2014). A basic desire of deep architectures is to discover the blocks –or features– that compose an image (or in general, a sensory input) at different levels of abstraction. Tasks that require some degree of image understanding can be performed more easily when using representations based on these building blocks. It would make intuitive sense that if we were to train one of the above models (particularly, those that are generative, such as variational autoencoders or generative adversarial networks) on images containing, e.g. text, the learned features would be individual letters, since those are the building blocks of the provided images. In addition to matching our intuition, a model that realizes (from noisy raw pixels) that the building blocks of text are letters, and is able to extract a representation based on those, has found meaningful structure in the data, and can prove it by being able to efficiently compress text images. However, this is not the case with existing incarnations of the above models1. We can see in Fig. 1 the features recovered by the hierarchical compositional network (HCN) from a single image with no supervision. They appear to be reasonable building blocks and are easy to find for a human. Yet we are not aware of any model that can perform such apparently simple recovery with no supervision. The HCN is a multilayer generative model with features defined at each layer. A feature (at a given position) is defined as the composition of features of the layer immediately below (by specifying their relative positions). To increase flexibility, the positions of the composing features can be perturbed slightly with respect to their default values (pooling). This results in a latent variable model, with some of t","Variational algorithms for approximate Bayesian inference | Binaryconnect: Training deep neural networks with binary weights during propagations | Learning a hierarchical compositional shape vocabulary for multi-class object representation | Fixing max-product: Convergent message passing algorithms for MAP LP-relaxations | Generative adversarial nets | Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding | Stable fixed points of loopy belief propagation are local minima of the bethe free energy | A fast learning algorithm for deep belief nets | Variational probabilistic inference and the qmr-dt network | Context and hierarchy in a probabilistic image model | Auto-encoding variational bayes | Probabilistic graphical models: principles and techniques | Convergent tree-reweighted message passing for energy minimization | Gradient-based learning applied to document recognition | Learning the parts of objects by non-negative matrix factorization | Convergent message passing algorithms - a unifying view | The discrete basis problem | Divergence measures and message passing | Neural variational inference and learning in belief networks | A probabilistic theory of deep learning | Probabilistic reasoning in intelligent systems: networks of plausible inference | Sum-product networks: A new deep architecture | Boolean matrix factorization and noisy completion via message passing | Deep boltzmann machines | Learning and-or templates for object recognition and detection | Noisy-or component analysis and its application to link analysis | The set basis problem is NP-complete | Subproblem-tree calibration: A unified approach to max-product message passing | A linear programming approach to max-sum problem: A review | Dts: dynamic trees | Learning active basis model for object detection and recognition | Max margin and/or graph learning for parsing the human body | Latent hierarchical structural learning for object detection | Under review as a conference | The AND-OR template learning methods of (Zhu et al., 2008; 2010) use respectively max-margin and incremental concave-convex procedures to optimize a discriminative score. Therefore they require supervision (unlike HCN) and a tractable inference procedure (to make the discriminative score easy to optimize)",iclr,010
761.pdf.json,,"Can programming language tools, such as static analyzers, be learned from data using deep learning? While research projects trying to use machine learning to design better programming language tools are burgeoning, they all rely on feature engineering (Brun & Ernst, 2004; Kolter & Maloof, 2006; Yamaguchi et al., 2012; Tripp et al., 2014; Raychev et al., 2015; Allamanis et al., 2015; Nguyen & Nguyen, 2015; Gvero & Kuncak, 2015; Long & Rinard, 2016). Unfortunately, feature engineering for programs is difficult and indeed the features often seem ad-hoc and superficial. This raises the question of whether it could be possible to approach a complicated problem such as static analysis – the automated detection of program properties – from almost raw features. In this paper, our goal is to present a very simple experiment that clearly shows that not only feature engineering can completely fail for even the simplest static analysis task, but that deep learning with neural networks can indeed be successful. The task in which we are interested is simple: we want to ensure that program variables are defined before they are used. We design a toy language to focus on the problem, and indeed our language is so simple that if it satisfies the aforementioned property, then it is semantically valid. Since programs are sequences of tokens, we experiment with different types of sequence learning methods (Xing et al., 2010). We try feature-based methods in which we extract features from the sequence and then use a classifier to decide whether or not the program is semantically valid. We show that they all fail, including methods that compute a sequence embedding. Then, we try different modelbased methods (Lipton, 2015): hidden Markov models (HMM), recurrent neural networks (RNN), and long short-term memory networks (LSTM). Our results show that HMM and RNN do poorly (albeit better than random), while an LSTM is almost perfectly accurate. This finding is somewhat surprising as static an",Suggesting accurate method and class names | Finding latent code errors via machine learning over program executions | Semi-supervised sequence learning | Discovering affine equalities using random interpretation | Global value numbering using random interpretation | Precise interprocedural analysis using random interpretation | Synthesizing java expressions from free-form queries | Learning to detect and classify malicious executables in the wild | A critical review of recurrent neural networks for sequence learning | Automatic patch generation by learning correct code | Graph-based statistical language model for code | Predicting program properties from ”big code | Aletheia: Improving the usability of static security analysis | Formal verification of translation validators: A case study on instruction scheduling optimizations | A brief survey on sequence classification | Generalized vulnerability extrapolation using abstract syntax trees,iclr,010
762.pdf.json,PERCEIVING FROM LOW FIDELITY VISUAL INPUT,"Most deep learning architectures process every visual input component when performing a task; for example, the input layer of many ImageNet architectures considers all pixels in every region of a preprocessed image when learning an image classifier or making classification decisions (Krizhevsky et al., 2012; Simonyan & Zisserman, 2014; Szegedy et al., 2014). In contrast, the human visual system has just a small fovea of high resolution chromatic input allowing it to more judiciously budget computational resources (Lennie, 2003). In order to receive additional information in the field of view, we make either covert or overt shifts of attention. Overt shifts of attention or eyemovements allow us to bring the fovea over particular locations in the environment that are relevant to current behavior. To avoid the serial nature of processing as demanded from overt shifts of attention, our visual system can also engage in covert shifts of attention in which the eyes remain fixated on one location but attention is deployed to a different location. Yet, even without resorting to overt shifts of attention, we still perceive the world in high detail. This is somewhat remarkable if you consider that the human retina receives an estimated 10 million bits per second which far exceeds the computational resources available to our visual system to assimilate at any given time (Koch et al., 2006). Our own fovea takes up only 4% of the entire retina (Michels & CP Rice, 1990) and is solely responsible for sharp central full color vision with maximum acuity; acuity which diminishes rapidly with eccentricity from the fovea (Cowey & ∗Email: fwick@cs.umb.edu Rolls, 1974). As a result, visual performance is best at the fovea and progressively worse towards the periphery (Low, 1946). Indeed, our visual cortex is receiving distorted color-deprived visual input except for the central two degrees of the visual field (Hansen et al., 2009). Additionally, we have blind spots in the retina that rece","Neural machine translation by jointly learning to align and translate | Learning iterative image reconstruction in the neural abstraction pyramid | Training with noise is equivalent to tikhonov regularization | Human cortical magnification factor and its relation to visual acuity | Deep network cascade for image super-resolution | Automatic colorization. http://tinyclouds.org/colorize | Learning a deep convolutional network for image super-resolution | Adaptive subgradient methods for online learning and stochastic optimization | A neural algorithm of artistic style | Color perception in the intermediate periphery of the visual field | Natural image denoising with convolutional networks | How much the eye tells the brain | The neural mechanisms of perceptual filling-in | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | Learning to combine foveal glimpses with a third-order boltzmann machine | Backpropagation applied to handwritten zip code recognition | The cost of cortical computation | Some characteristics of peripheral visual performance | Retinal detachment | Recurrent models of visual attention | Recognition memory for a rapid sequence of pictures | Contractive auto-encoders: Explicit invariance during feature extraction | Scholkopf. A machine learning approach for non-blind image deconvolution | Very deep convolutional networks for large-scale image recognition | Face recognition by humans: Nineteen results all computer vision researchers should know about | Atoms of recognition in human and computer vision | Extracting and composing robust features with denoising autoencoders | Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion | Searching for the neural mechanisms of color filling-in. Filling-in: From perceptual completion to cortical reorganization | Image denoising and inpainting with deep neural networks | Show, attend and tell: Neural image caption generation with visual attention",iclr,010
763.pdf.json,,"Relational time series, i.e. multiple time series where the observations are correlated both inside each series and between series occur in many domains such as ecology, medicine, biology, earth observation by satellite imagery or local measurements, multimedia or even social data analysis. The correlations between the different observed series can come from a proximity (e.g. earth observation or epidemic diffusion) or from a similarity of behavior (e.g. user traces in social data). In the statistical literature, the modeling of relational time series has been the topic of a dedicated field: spatio-temporal statistics (Cressie & Wikle (2011); Wikle & Hooten (2010)). Different methodologies have been developed for handling a large variety of spatio-temporal phenomena, with an emphasis on the analysis of natural observations like weather prediction, ecology or remote sensing. In the machine learning domain, there exists a vast literature dedicated to sequence or time series prediction. Recently, deep recurrent neural networks have witnessed notable successes in different sequence and time series modeling tasks leading to an increasing number of publications, e.g. (Barbounis et al. (2006); Hsieh et al. (2011); Cao et al. (2012); Hermans & Schrauwen (2013)). Despite a large number of recent developments, the modeling and analysis of relational time series has only attracted a few attention in the field of representation learning. In addition, most of the models are deterministic in the sense that they are trained to learn a fixed mapping for modeling the dynamics of the series. We propose a new state space model for relational time series able to model the uncertainty at the observation and at the modeling levels. The principle of this approach is to associate each point of a time series to a Gaussian distribution in a latent space, the distribution over the observed values being directly computed from these latent distributions. The model has two main components. One i",Long-term wind speed and power forecasting using local recurrent neural network models | Gaussian process for nonstationary time series prediction | Forecasting wind speed with recurrent neural networks | Learning phrase representations using rnn encoder-decoder for statistical machine | Recurrent neural networks and robust time series prediction | Statistics for spatio-temporal data. Wiley series in probability and statistics | 25 years of time series forecasting | Multilabel classification on heterogeneous graphs with gaussian embeddings | Sequential neural models with stochastic layers. Advances in neural information processing systems | Speech recognition with deep recurrent neural networks | Multiple Gaussian process models for direct time series forecasting | Learning to represent knowledge graphs with gaussian embedding | Training and analysing deep recurrent neural networks | Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm | A new approach to linear filtering and prediction problems | Adam: A method for stochastic optimization | Auto-encoding variational bayes | Deep kalman filters | Dynamic factor graphs for time series modeling | Stochastic backpropagation and variational inference in deep latent gaussian models | Generating text with recurrent neural networks | Word representations via gaussian embedding | Modern perspectives on statistics for spatio-temporal data | A general science-based framework for dynamical spatio-temporal models | Learning embeddings for completion and prediction of relational multivariate time-series,iclr,010
765.pdf.json,,"When humans or animals receive reward for taking a particular action in a given situation, the probability is increased that they will act similarly in similar situations in the future. This is described by principles such as the law of effect (Thorndike, 1898), operant conditioning (Skinner, 1938) and trial-and-error learning (Thorpe, 1979) in behaviorist psychology, and has inspired a discipline of artificial intelligence called reinforcement learning (RL, Sutton & Barto (1998)). RL is concerned with finding optimal behavior policies in order to maximize agents’ cumulative future reward. Approaches to RL can be divided into model-free and model-based approaches. In model-free approaches, agents learn by trial and error but do not aim to explicitly capture the dynamics of the environment or the structure of the reward function underlying the environment. State-of-the-art modelfree approaches, such as DQN (Mnih et al., 2015), effectively approximate so-called Q-values, i.e., the value of taking specific actions in a given state, using deep neural networks. The impressive effectiveness of these approaches comes from their ability to learn complex policies directly from high-dimensional input (e.g., video frames). Despite their effectiveness, model-free approaches require large amounts of training data that have to be collected through direct interactions with the environment, which makes them expensive to apply in settings where interactions are costly (such as most real-world applications). Additionally, model-free RL requires access to reward observations during training, which is problematic in environments with sparse reward structure—unless coupled with an explicit exploration mechanism. RL approaches that explicitly learn statistics about the environment or the reward are generally referred to as model-based—in a more narrow definition these statistics comprise environment dynamics and the reward function. In recent work, model-based techniques were successfull","The Arcade Learning Environment: an evaluation platform for general agents | Unifying count-based exploration and intrinsic motivation | Learning deep architectures for AI | Curriculum learning | Dynamic programming & optimal control, volume 1 | Dynamic programming & optimal control, volume 2 | A survey of monte carlo tree search methods | Learning to generate chairs with convolutional neural networks | Deep spatial autoencoders for visuomotor learning | Understanding the difficulty of training deep feedforward neural networks | Deep sparse rectifier neural networks | Learning to linearize under uncertainty | DRAW: a recurrent neural network for image generation | Deep learning for real-time Atari game play using offline Monte-Carlo tree search planning | Transforming auto-encoders | The Malmo platform for artificial intelligence experimentation | Adam: a method for stochastic optimization | Auto-encoding variational Bayes | Deep convolutional inverse graphics network | Autonomous reinforcement learning on raw visual input data in a real world application | Modeling deep temporal dependencies with recurrent grammar cells | Human-level control through deep reinforcement learning | Action-conditional video prediction using deep networks in Atari games | On the difficulty of training recurrent neural networks | Unsupervised learning of invariant feature hierarchies with applications to object recognition | Stochastic backpropagation and approximate inference in deep generative models | Best practices for convolutional neural networks applied to visual document analysis | The behavior of organisms: an experimental analysis | Dropout : a simple way to prevent neural networks from overfitting | Unsupervised learning of video representations using LSTMs | Integrated architectures for learning, planning, and reacting based on approximating dynamic programming | Reinforcement learning: an introduction | The origins and rise of ethology | Compress and control | From pixels to torques: policy learning with deep dynamical models | Embed to control: a locally linear latent dynamics model for control from raw images | Generalization of backpropagation with application to a recurrent gas market model | The dataset for training comprised around 500, 000 video frames per game in addition to actions chosen by the DQN agent and rewards collected during game play. Video frames used as network input were 84×84 grey-scale images with pixel values between 0 and 255 down-sampled from the full-resolution | For each game, we sample 300 minibatches of size I = 50 from the underlying test set and compute the test loss over K = 100 look ahead steps with the formula presented in the main paper in Section 3.3 used for learning network parameters, but without averaging over look ahead steps because we aim to illustrate the test loss as a function of look ahead steps—statistics of this analysis",iclr,010
766.pdf.json,,"In recent years, pedestrian detection has become an important branch of object detection and has attracted wide attention in computer vision Dalal & Triggs (2005); Dollár et al. (2014; 2009); Viola et al. (2005); Wang et al. (2009). In real life, it is a key problem in automotive safety, video surveillance, smart vehicles and intelligent robotics. Because of the diversity of pedestrian body pose, object occlusions, clothing, lighting change and complicated backgrounds in the video sequence or image, the pedestrian detection is still a challenging task in computer vision. In pedestrian detection, feature extraction is an important factor to influent the performance. Many features have been proposed by researchers for pedestrian detection, such as Haar-like features Viola & Jones (2004), Integral Channel Features (ICF) Dollár et al. (2009), Histogram of Oriented Gradients (HOG) Dalal & Triggs (2005), Local Binary Pattern (LBP) Mu et al. (2008), Dense SIFT Vedaldi et al. (2009) etc. And the proposed Deformable Part Based Model (DPM) Felzenszwalb et al. (2010) which is based on HOG, has maken a breakthrough in pedestrian detection. However, these features are hand-craft and are considered to be low-level. They use the low-level information while the high-level information is usually very important for pedestrian detection Sermanet et al. (2013). Recently, with the development of deep learning techniques, deep neural networks have been successfully applied in object recognition tasks Girshick et al. (2014); He et al. (2015); Girshick (2015); Zhao et al. (2014). Deep neural networks can achieve more excellent results due to their capability to learn discriminative features from raw pixels. Many researchers have applied deep learning techniques to pedestrian detection. Sermanet et al. Sermanet et al. (2013) proposed a two layers convolutional model which adopts convolutional sparse coding to pre-train convolutional neural network for pedestrian detection. Chen et al. Che","Detection evolution with multi-order contextual co-occurrence | Pedestrian detection with deep convolutional neural network | Bing: Binarized normed gradients for objectness estimation at 300fps | Histograms of oriented gradients for human detection | Integral channel features | Pedestrian detection: An evaluation of the state of the art | Fast feature pyramids for object detection | Object detection with discriminatively trained part-based models | Fast r-cnn | Rich feature hierarchies for accurate object detection and semantic segmentation | Spatial pyramid pooling in deep convolutional networks for visual recognition | How good are detection proposals, really | What makes for effective detection proposals | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Caffe: Convolutional architecture for fast feature embedding | Sketch tokens: A learned mid-level representation for contour and object detection | Scale-aware fast r-cnn for pedestrian detection | Switchable deep network for pedestrian detection | Discriminative local binary patterns for human detection in personal album | Local decorrelation for improved pedestrian detection | Joint deep learning for pedestrian detection | Strengthening the effectiveness of pedestrian detection with spatially pooled features | Pedestrian detection at 100 frames per second | Seeking the strongest rigid detector | Pedestrian detection with unsupervised multi-stage feature learning | Pedestrian detection aided by deep learning semantic tasks | Selective search for object recognition | Multiple kernels for object detection | Robust real-time face detection | Detecting pedestrians using patterns of motion and appearance | Pedestrian detection based on region proposal fusion | An hog-lbp human detector with partial occlusion handling | Plant leaf identification via a growing convolution neural network with progressive sample learning | Edge boxes: Locating object proposals from edges",iclr,010
767.pdf.json,AN ACTOR-CRITIC ALGORITHM FOR LEARNING RATE LEARNING,"While facing large scale of training data, stochastic learning such as stochastic gradient descent (SGD) is usually much faster than batch learning and often results in better models. An observation for SGD methods is that their performances are highly sensitive to the choice of learning rate LeCun et al. (2012). Clearly, setting a static learning rate for the whole training process is insufficient, since intuitively the learning rate should decrease when the model becomes more and more close to a (local) optimum as the training goes on over time Maclaurin et al. (2015). Although there are some empirical suggestions to guide how to adjust the learning rate over time in training, it is still a difficult task to find a good policy to adjust the learning rate, given that good policies are problem specific and depend on implementation details of a machine learning algorithm. One usually needs to try many times and adjust the learning rate manually to accumulate knowledge about the problem. However, human involvement often needs domain knowledge about the target problems, which is inefficient and difficult to scale up to different problems. Thus, a natural question arises: can we automatically adjust the learning rate? This is exactly the focus of this work and we aim to automatically learn the learning rates for SGD based machine learning (ML) algorithms without human-designed rules or hand-crafted features. By examining the current practice of learning rate control/adjustment, we have two observations. First, learning rate control is a sequential decision process. At the beginning, we set an initial learning rate. Then at each step, we decide whether to change the learning rate and how to change it, based on the current model and loss, training data at hand, and maybe history of the training process. As suggested in Orr & Müller (2003), one well-principled method for estimating the ideal learning rate that is to decrease the learning rate when the weight vector oscill","Tensorflow: Large-scale machine learning on heterogeneous systems | An actor-critic algorithm for sequence prediction | Neuronlike adaptive elements that can solve difficult learning control problems | Learning step size controllers for robust neural network training | Fast adaptive k-means clustering: some empirical results | Adaptive subgradient methods for online learning and stochastic optimization | Increased rates of convergence through learning rate adaptation | Adam: A method for stochastic optimization | Learning multiple layers of features from tiny images | Gradient-based learning applied to document recognition | Efficient backprop | Gradient-based hyperparameter optimization through reversible learning | Human-level control through deep reinforcement learning | Neural networks: tricks of the trade | No more pesky learning rates | An empirical study of learning rates in deep neural networks for speech recognition | Deterministic policy gradient algorithms | Mastering the game of go with deep neural networks and tree | Very deep convolutional networks for large-scale image recognition | Learning to predict by the methods of temporal differences | Adapting bias by gradient descent: An incremental version of delta-bar-delta | Time-derivative models of pavlovian reinforcement | Reinforcement learning: An introduction, volume 1 | Policy gradient methods for reinforcement learning with function approximation | Temporal credit assignment in reinforcement learning | Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude | Show, attend and tell: Neural image caption generation with visual attention | Adadelta: an adaptive learning rate method",iclr,010
768.pdf.json,TRAINING GROUP ORTHOGONAL NEURAL NETWORKS WITH PRIVILEGED INFORMATION,"Deep convolutional neural networks (CNNs) have brought a series of breakthroughs in image classification tasks (He et al., 2015; Girshick, 2015; Zheng et al., 2015). Many recent works (Simonyan & Zisserman, 2014; He et al., 2015; Krizhevsky et al., 2012) have observed that CNNs with different architectures or even different weight initializations may learn slightly different feature representations. Combining these heterogeneous models can provide richer and more diverse feature representation which can further boost the final performance. Such observation motivate us to directly pursue feature diversity within a single model in the work. Besides, many existing datasets (Everingham et al., 2010; Deng et al., 2009; Xiao et al., 2010) provide more than one types of annotations. For example, the PASCAL VOC (Everingham et al., 2010) provides image level tags, object bounding box, and image segmentation masks; the ImageNet dataset (Deng et al., 2009) provide image level tags and a small portion of bounding box. Only using the image level tags for training image classification model would be a great waste on the other annotation resources. Therefore, in this work, we investigate whether these auxiliary annotations could also help a CNN model learn richer and more diverse feature representation. In particular, we take advantage of these extra annotated information during training a CNN model for obtaining a single CNN model with sufficient inherent diversity, with the expectation that the model is able to learn more diverse feature representations and offers stronger generalization ability for image classification than vanilla CNNs. We therefore propose a group orthogonal convolutional neural network (GoCNN) model that is able to exploit these extra annotated information as privileged information. The idea is to learn different groups of convolutional functions which are “orthogonal” to the ones in other groups. Here by “orthogonal”, we mean there is no significant correla",Mxnet: A flexible and efficient machine learning library for heterogeneous distributed systems | Reducing overfitting in deep networks by decorrelating representations | Boxsup: Exploiting bounding boxes to supervise convolutional networks for semantic segmentation | Imagenet: A large-scale hierarchical image database | The pascal visual object classes (voc) challenge | Fast r-cnn | Simultaneous detection and segmentation | Deep residual learning for image recognition | Distilling the knowledge in a neural network | Deep learning with s-shaped rectified linear activation units | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | Learning using privileged information: Svm+ and weighted svm | Unifying distillation and privileged | Fast optimization algorithms for solving svm+ | Object-centric spatial pooling for image classification | Learning to transfer privileged information | Very deep convolutional networks for large-scale image recognition | Contextualizing object detection and classification | Multimodal learning with deep boltzmann machines | Deep learning using linear support vector machines | Sun database: Large-scale scene recognition from abbey to zoo | Conditional random fields as recurrent neural networks,iclr,010
770.pdf.json,A NEURAL KNOWLEDGE LANGUAGE MODEL,"Kanye West, a famous <unknown> and the husband of <unknown>, released his latest album <unknown> in <unknown>. A core purpose of language is to communicate knowledge. Thus, for human-level language understanding, it is important for a language model to take advantage of knowledge. Although traditional language models are good at capturing statistical co-occurrences of entities as long as they are observed frequently in a corpus (e.g., words like verbs, pronouns, and prepositions), they are in general limited in their ability to encode or decode knowledge, which is often represented by named entities such as person names, place names, years, etc. (as shown in the above example sentence of Kanye West.) When trained with a very large corpus, traditional language models have demonstrated to some extent the ability to encode/decode knowledge (Vinyals & Le, 2015; Serban et al., 2015). However, we claim that simply feeding a larger corpus into a bigger model hardly results in a good knowledge language model. The primary reason for this is the difficulty in learning good representations for rare or unknown words because these are a majority of the knowledge-related words. In particular, for applications such as question answering (Iyyer et al., 2014; Weston et al., 2016; Bordes et al., 2015) and dialogue modeling (Vinyals & Le, 2015; Serban et al., 2015), these words are of our main interest. Specifically, in the recurrent neural network language model (RNNLM) (Mikolov et al., 2010) the computational complexity is linearly dependent on the number of vocabulary words. Thus, including all words of a language is computationally prohibitive. Instead, we typically fill our vocabulary with a limited number of frequent words and regard all the other words as the unknown (UNK) word. Even if we can include a large number of words in the vocabulary, according to Zipf’s law, a large portion of the words will be rarely observed in the corpus and thus learning good representations for t",Neural machine translation by jointly learning to align and translate | Theano: new features and speed improvements | A neural probabilistic language model | Freebase: a collaboratively created graph database for structuring human knowledge | Learning structured embeddings of knowledge bases | Translating embeddings for modeling multi-relational data | Large-scale simple question answering with memory networks | Enriching word embeddings using knowledge graph for semantic tagging in conversational dialog systems | Neural turing machines | Incorporating copying mechanism in sequence-to-sequence | Traversing knowledge graphs in vector space | Long short-term memory | A neural network for factoid question answering over paragraphs | On using very large target vocabulary for neural machine | Exploring the limits of language modeling | Convolutional neural networks for sentence classification | Leveraging lexical resources for learning entity embeddings in multi-relational data | Recurrent neural network based language model | Wordnet: a lexical database for english | A scalable hierarchical distributed language model | A fast and simple algorithm for training neural probabilistic language models | Hierarchical probabilistic neural network language model | A review of relational machine learning for knowledge graphs: From multi-relational link prediction to automated knowledge graph construction | Building end-to-end dialogue systems using generative hierarchical neural networks | A neural conversational model | Towards ai-complete question answering: A set of prerequisite toy | Recurrent neural network regularization,iclr,010
771.pdf.json,TATIONS WITH A LEXICON,"Vector-space representations of words are reported useful and improve the performance of the machine learning algorithms for many natural language processing tasks such as name entity recognition and chunking (Turian et al., 2010), text classification (Socher et al., 2012; Le & Mikolov, 2014; Kim, 2014; Joulin et al., 2016), topic extraction (Das et al., 2015; Li et al., 2016), and machine translation (Zaremba et al., 2014; Sutskever et al., 2014). People are still trying to improve the vector-space representations for words. Bojanowski et al. (2016) attempt to improve word vectors by involving character level information. Other works (Yu & Dredze, 2014; Xu et al., 2014; Faruqui et al., 2015; Bollegala et al., 2016) try to estimate better word vectors by using a lexicon or ontology. The idea is simple: because a lexicon or ontology contains well-defined relations about words, we can use them to improve word vectors. However, for a polysemous word, one of its synonym does not always mean the same thing with the original one under different contexts. For example, the word ”point” equals ”score” in ”Team A got 3 points”, but does not in ”my point of view.” A method to address this issue is to estimate a vector for each word sense (Huang et al., 2012; Chen et al., 2014) or per word type (Neelakantan et al., 2014). However, it requires additional word sense disambiguation or part-of-speech tagging to use such word vectors. In this paper, we propose a method to improve the vector-space representations using a lexicon and alleviate the adverse effect of polysemy, keeping one vector per word. We estimate the degree of reliability for each paraphrase in the lexicon and eliminate the ones with lower degrees in learning. The experimental results show that the proposed method is effective and outperforms the prior works. The major contributions of our work include: • We propose a novel approach involving fuzzy sets to reduce the noise brought by polysemous words in the word vec","The wacky wide web: a collection of very large linguistically processed web-crawled corpora | A critique of word similarity as a method for evaluating distributional semantic models. the 54th annual meeting of the Association for Computational Linguistics | Enriching word vectors with subword information | Joint word representation learning using a corpus and a semantic lexicon | Multimodal distributional semantics | A unified model for word sense representation and disambiguation | Intrinsic evaluation of word vectors fails to predict extrinsic performance | Gaussian lda for topic models with word embeddings. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers) | Retrofitting word vectors to semantic lexicons | Placing search in context: The concept revisited | PPDB: The paraphrase database | Simlex-999: Evaluating semantic models with (genuine) similarity estimation | Improving word representations via global context and multiple word prototypes | Bag of tricks for efficient text classification | Convolutional neural networks for sentence classification | Distributed representations of sentences and documents | Dependencybased word embeddings | Neural word embedding as implicit matrix factorization | Improving distributional similarity with lessons learned from word embeddings | Generative topic embedding: a continuous representation of documents. In the 54th annual meeting of the Association for Computational Linguistics (ACL 2016) | Better word representations with recursive neural networks for morphology | Efficient estimation of word representations in vector space | Distributed representations of words and phrases and their compositionality | Efficient nonparametric estimation of multiple embeddings per word in vector space | Adding semantics to data-driven paraphrasing. In Association for Computational Linguistics, Beijing, China, July 2015a | Ppdb 2.0: Better paraphrase ranking, fine-grained entailment relations, word embeddings, and style classification | Glove: Global vectors for word representation | Contextual correlates of synonymy | Semantic compositionality through recursive matrix-vector spaces | Sequence to sequence learning with neural networks | Word representations: a simple and general method for semi-supervised learning. In Proceedings of the 48th annual meeting of the association for computational linguistics (ACL | Domain and function: A dual-space model of semantic relations and compositions | Rc-net: A general framework for incorporating knowledge into word representations | Improving lexical embeddings with semantic knowledge | Recurrent neural network regularization",iclr,010
772.pdf.json,,"Image retrieval is an important problem both for academic research and for industrial applications. Although it has been studied for many years (Sivic & Zisserman, 2003; Philbin et al., 2007; Tolias et al., 2015), it is still a challenging task. Generally, image retrieval is divided into two groups. The first one is the category-level image retrieval (Sharma & Schiele, 2015), in which an image in the dataset is deemed to be similar to the query image if they share the same class or they are similar in shape and local structures. The other group is the instance-level image retrieval (Tolias et al., 2015), in which an image is considered to match the query if they contain the same object or the same scene. The instance-level image retrieval is harder in that the retrieval method need to encode the local and detailed information in order to tell two images apart, e.g., the algorithm should be able to detect the differences between the Eiffel Tower and other steel towers although they have similar shapes. In this paper, we focus on the instance-level image retrieval. Traditionally, visual instance retrieval is mainly addressed by the BoF (bag of features) based methods using the local feature descriptors such as SIFT (Lowe, 2004). In order to boost the retrieval performances, post-processing techniques such as query expansion (Chum et al., 2007) and spatial verification (Philbin et al., 2007) are also employed. With the decisive victory (Krizhevsky et al., 2012) over traditional models in the ImageNet (Russakovsky et al., 2015) image classification challenge, convolutional neural networks (Lecun et al., 1998) continue to achieve remarkable success in diverse fields such as object detection (Liu et al., 2015; Shaoqing Ren, 2015), semantic segmentation (Dai et al., 2016) and even image style transfer (Gatys et al., 2016). Networks trained on the Imagenet classification task can generalize quite well to other tasks, which are either used off-the-shelf (Razavian et al., 201","Three things everyone should know to improve object retrieval | All about vlad | NetVLAD: CNN architecture for weakly supervised place recognition | From generic to specific deep representations for visual recognition | Aggregating local deep features for image retrieval | Neural Codes for Image Retrieval, pp. 584–599 | Total recall: Automatic query expansion with a generative feature model for object retrieval | Instance-aware semantic segmentation via multi-task network cascades | Image style transfer using convolutional neural networks | Fast r-cnn | Multi-scale Orderless Pooling of Deep Convolutional Activation Features, pp. 392–407 | Deep residual learning for image recognition | Triangulation embedding and democratic aggregation for image search | Aggregating local descriptors into a compact image representation | Caffe: Convolutional architecture for fast feature embedding | Spatial pyramid pooling in deep convolutional networks for visual recognition | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories | Gradient-based learning applied to document recognition | SSD: Single shot multibox detector | Fully convolutional networks for semantic segmentation | Distinctive image features from scale-invariant keypoints | Scalable recognition with a vocabulary tree | Lost in quantization: Improving particular object retrieval in large scale image databases | Object retrieval with large vocabularies and fast spatial matching | Cnn features off-the-shelf: An astounding baseline for recognition | Visual instance retrieval with deep convolutional networks | Visual instance retrieval with deep convolutional networks | Faster R-CNN: Towards real-time object detection with region proposal networks | Scalable nonlinear embeddings for semantic category-based image retrieval | Very deep convolutional networks for large-scale image recognition | Video google: A text retrieval approach to object matching in videos | Going deeper with convolutions | Particular object retrieval with integral max-pooling of CNN activations | Visualizing and understanding convolutional networks",iclr,010
773.pdf.json,RECTIFIED FACTOR NETWORKS FOR BICLUSTERING,"Biclustering is widely-used in statistics (A. Kasim & Talloen, 2016), and recently it also became popular in the machine learning community (O´ Connor & Feizi, 2014; Lee et al., 2015; Kolar et al., 2011), e.g., for analyzing large dyadic data given in matrix form, where one dimension are the samples and the other the features. A matrix entry is a feature value for the according sample. A bicluster is a pair of a sample set and a feature set for which the samples are similar to each other on the features and vice versa. Biclustering simultaneously clusters rows and columns of a matrix. In particular, it clusters row elements that are similar to each other on a subset of column elements. In contrast to standard clustering, the samples of a bicluster are only similar to each other on a subset of features. Furthermore, a sample may belong to different biclusters or to no bicluster at all. Thus, biclusters can overlap in both dimensions. For example, in drug design biclusters are compounds which activate the same gene module and thereby indicate a side effect. In this example different chemical compounds are added to a cell line and the gene expression is measured (Verbist et al., 2015). If multiple pathways are active in a sample, it belongs to different biclusters and may have different side effects. In e-commerce often matrices of costumers times products are available, where an entry indicates whether a customer bought the product or not. Biclusters are costumers which buy the same subset of products. In a collaboration with the internet retailer Zalando the biclusters revealed outfits which were created by customers which selected certain clothes for a particular outfit. FABIA (factor analysis for bicluster acquisition, (Hochreiter et al., 2010)) evolved into one of the most successful biclustering methods. A detailed comparison has shown FABIA’s superiority over existing biclustering methods both on simulated data and real-world gene expression data (Hochreiter et ","Applied Biclustering Methods for Big and High-Dimensional Data Using R | Discovering local structure in gene expression data: the order-preserving submatrix problem | On the Goldstein-Levitin-Polyak gradient projection method | Biclustering of expression data | Rectified factor networks | Posterior regularization for structured latent variable models | HapFABIA: Identification of very short segments of identity by descent characterized by rare variants in large sequencing data | FABIA: factor analysis for bicluster | Subclass mapping: Identifying common subtypes in independent disease data sets | Non-negative matrix factorization with sparseness constraints | Defining transcription modules using large-scale gene expression data | Iterative Methods for Optimization | Spectral biclustering of microarray data: Coclustering genes and conditions | Minimax localization of structural information in large noisy matrices | Plaid models for gene expression data | Evaluating the statistical significance of biclusters | Extracting conserved gene expression motifs from gene expression data | Biclustering using message passing | Sharing of very short IBD segments between humans, neandertals, and denisovans | A systematic comparison and evaluation of biclustering methods for gene expression data | The use of molecular profiling to predict survival after chemotherapy for diffuse large-B-cell lymphoma | Large-scale analysis of the human and mouse transcriptomes | The gibbs-plaid biclustering model | Discovering statistically significant biclusters in gene expression data | Improved biclustering of microarray data demonstrated through systematic performance tests | Gene expression profiling predicts clinical outcome of breast cancer | Using transcriptomics to guide lead optimization in drug discovery projects: Lessons learned from the QSTAR project | Identification of transcription factors for drug-associated gene modules and biomedical implications | An improved biclustering method for analyzing gene expression profiles",iclr,010
774.pdf.json,,"Generative models are a popular approach to unsupervised machine learning. Generative neural network models are trained to produce data samples that resemble the training set. Because the number of model parameters is significantly smaller than the training data, the models are forced to discover efficient data representations. These models are sampled from a set of latent variables in a high dimensional space, here called a latent space. Latent space can be sampled to generate observable data values. Learned latent representations often also allow semantic operations with vector space arithmetic (Figure 1). Generative models are often applied to datasets of images. Two popular generative models for image data are the Variational Autoencoder (VAE, Kingma & Welling, 2014) and the Generative Adversarial Network (GAN, Goodfellow et al., 2014). VAEs use the framework of probabilistic graphical models with an objective of maximizing a lower bound on the likelihood of the data. GANs instead formalize the training process as a competition between a generative network and a separate discriminative network. Though these two frameworks are very different, both construct high dimensional latent spaces that can be sampled to generate images resembling training set data. Moreover, these latent spaces are generally highly structured and can enable complex operations on the generated images by simple vector space arithmetic in the latent space (Larsen et al., 2016). Generative models are beginning to find their way out of academia and into creative applications. In this paper we present techniques for improving the visual quality of generative models that are generally independent of the model itself. These include spherical linear interpolation, visualizing analogies with J-diagrams, and generating local manifolds with MINE grids. These techniques can be combined generate low dimensional embeddings of images close to the trained manifold. These can be used for visualization and c",Facial Attributes Classification Using Multi-Task Representation Learning | Generative adversarial nets | Automatic chemical design using a data-driven continuous representation of molecules | Auto-encoding variational Bayes | Facetracer: A search engine for large collections of images with faces | Discriminative Regularization for Generative Models | Autoencoding beyond pixels using a learned similarity metric | Word-level training of a handwritten word recognizer based on convolutional neural networks | Learning surf cascade for fast and accurate object detection | Linguistic Regularities in Continuous Space Word Representations | Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks | Deep visual analogy-making | Animating rotation with quaternion curves | Panda: Pose aligned networks for deep attribute modeling,iclr,010
775.pdf.json,LEARNING LOCOMOTION SKILLS USING DEEPRL: DOES,"The introduction of deep learning models to reinforcement learning (RL) has enabled policies to operate directly on high-dimensional, low-level state features. As a result, deep reinforcement learning (DeepRL) has demonstrated impressive capabilities, such as developing control policies that can map from input image pixels to output joint torques (Lillicrap et al., 2015). However, the quality and robustness often falls short of what has been achieved with hand-crafted action abstractions, e.g., Coros et al. (2011); Geijtenbeek et al. (2013). While much is known about the learning of state representations, the choice of action parameterization is a design decision whose impact is not yet well understood. Joint torques can be thought of as the most basic and generic representation for driving the movement of articulated figures, given that muscles and other actuation models eventually result in joint torques. However this ignores the intrinsic embodied nature of biological systems, particularly the synergy between control and biomechanics. Passive-dynamics, such as elasticity and damping from muscles and tendons, play an integral role in shaping motions: they provide mechanisms for energy storage, and mechanical impedance which generates instantaneous feedback without requiring any explicit computation. Loeb coins the term preflexes (Loeb, 1995) to describe these effects, and their impact on motion control has been described as providing intelligence by mechanics (Blickhan et al., 2007). This can also be thought of as a kind of partitioning of the computations between the control and physical system. In this paper we explore the impact of four different actuation models on learning to control dynamic articulated figure locomotion: (1) torques (Tor); (2) activations for musculotendon units (MTU); (3) target joint angles for proportional-derivative controllers (PD); and (4) target joint velocities (Vel). Because Deep RL methods are capable of learning control policies f","Intelligence by mechanics | Locomotion skills for simulated quadrupeds | Feature-based locomotion controllers | Flexible muscle-based locomotion for bipedal creatures | Positive force feedback in bouncing gaits | Deep reinforcement learning for robotic manipulation | Deep reinforcement learning in parameterized action | Actor-critic algorithms | End-to-end training of deep visuomotor policies | Continuous control with deep reinforcement learning | Guided learning of control graphs for physicsbased characters | Control implications of musculoskeletal mechanics. In Engineering in Medicine and Biology Society, 1995 | Interactive control of diverse complex characters with neural networks | Highdimensional continuous control using generalized advantage estimation | Deterministic policy gradient algorithms | Policy gradient methods for reinforcement learning with function approximation | Learning bicycle stunts | Reinforcement learning in continuous state and action spaces | Optimizing locomotion controllers using biologically-based actuators and objectives | Autonomous reinforcement learning with experience replay",iclr,010
776.pdf.json,,"Existing decoding schemes for translation generate outputs either left-to-right, such as for phrasebased or neural translation models, or bottom-up as in syntactic models (Koehn et al., 2003; Galley et al., 2004; Bahdanau et al., 2015). All decoding algorithms for those models make decisions which cannot be revisited at a later stage, such as when the model discovers that it made an error earlier on. On the other hand, humans generate all but the simplest translations by conceiving a rough draft of the solution and then iteratively improving it until it is deemed complete. The translator may modify a clause she tackled earlier at any point and make arbitrary modifications to improve the translation. It can be argued that beam search allows to recover from mistakes, simply by providing alternative translations. However, reasonable beam sizes encode only a small number of binary decisions. A beam of size 50 contains fewer than six binary decisions, all of which frequently share the same prefix (Huang, 2008).1 In this paper, we present models that tackle translation similar to humans. The model iteratively edits the target sentence until it cannot improve it further. As a preliminary study, we address the problem of finding mistakes in an existing translation via a simple classifier that predicts if a word in a translation is correct (§2). Next, we model word substitutions for an existing translation via a convolutional neural network that attends to the source when suggesting substitutions (§3). Finally, we devise a model that attends both to the source as well as to the existing translation (§4). We repeatedly apply the models to their own output by determining the best substitution for each word in the previous translation and then choosing either one or zero substitutions for each sentence. For the latter we consider various heuristics as well as a classifier-based selection method (§5). Our results demonstrate that we can improve the output of a phrase-based trans",Neural machine translation by jointly learning to align and translate | A neural probabilistic language model | Confidence estimation for machine translation | Torch7: A matlab-like environment for machine learning | What’s in a translation rule | Forest-based algorithms in natural language processing | Statistical Phrase-Based Translation | Moses: Open source toolkit for statistical machine translation | Word embeddings through hellinger pca | Neural network-based word alignment through score aggregation | Effective approaches to attention-based neural machine translation | Bleu: A method for automatic evaluation of machine translation | A neural attention model for sentence summarization | Word lattices for multi-source translation | Statistical phrase-based post-editing | Word-level confidence estimation for machine translation,iclr,010
777.pdf.json,,"Enhancing the generalization performance against unseen data given some sample data is the main objective in machine learning. Under that point of view, deep learning has been achieved many breakthroughs in several domains such as computer vision (Krizhevsky et al., 2012; Simonyan & Zisserman, 2015; He et al., 2016), natural language processing (Collobert & Weston, 2008; Bahdanau et al., 2015), and speech recognition (Hinton et al., 2012; Graves et al., 2013). Deep learning is basically realized on deep layered neural network architecture, and it learns appropriate taskspecific latent representation based on given training data. Better latent representation learned from training data results in better generalization over the future unseen data. Representation learning or latent space modeling becomes one of the key research topics in deep learning. During the past decade, researchers focused on unsupervised representation learning and achieved several remarkable landmarks on deep learning history (Vincent et al., 2010; Hinton et al., 2006; Salakhutdinov & Hinton, 2009). In terms of utilizing good base features for supervised learning, the base representation learned from unsupervised learning can be a good solution for supervised tasks (Bengio et al., 2007; Masci et al., 2011). The definition of ‘good’ representation is, however, different according to target tasks. In unsupervised learning, a model is learned from unlabelled examples. Its main objective is to build a model ∗Corresponding author to estimate true data distribution given examples available for training, so the learned latent representation normally includes broadly-informative components of the raw input data (e.g., mutual information between the input and the latent variable can be maximized for this objective). In supervised learning, however, a model is learned from labelled examples. In the case of classification, a supervised model learns to discriminate input data in terms of the target task usi",TensorFlow: Large-scale machine learning on heterogeneous systems | Neural machine translation by jointly learning to align and translate | Greedy layer-wise training of deep networks | Classifying and visualizing motion capture sequences using deep neural networks | A unified architecture for natural language processing: Deep neural networks with multitask learning | Multi-prediction deep boltzmann machines | Speech recognition with deep recurrent neural networks | Deep residual learning for image recognition | Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups | A fast learning algorithm for deep belief nets | Adam: A method for stochastic optimization | Imagenet classification with deep convolutional neural networks | Classification using discriminative restricted boltzmann machines | Classification using discriminative restricted boltzmann machines | Gradient-based learning applied to document recognition | Visualizing data using t-sne | Stacked convolutional autoencoders for hierarchical feature extraction | Semisupervised learning with ladder networks | Deep boltzmann machines | Very deep convolutional networks for large-scale image recognition | Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion | Information theoretical analysis of multivariate correlation | Augmenting supervised neural networks with unsupervised objectives for large-scale image classification | Stacked what-where auto-encoders,iclr,010
778.pdf.json,,,"SPADE : Scalar Product Accelerator by Integer Decomposition | Predicting Parameters in Deep Learning | Learning both Weights and Connections for Efficient Neural Networks | Deep Compression - Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding | Efficient Online Structured Output Learning for Keypoint-Based Object Tracking | Distilling the Knowledge in a Neural Network | Labeled Faces in the Wild: a Database for Studying Face Recognition in Unconstrained Environments | Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift | Speeding up Convolutional Neural Networks with Low Rank Expansions | Gradient-Based Learning Applied to Document Recognition | XNOR-Net: ImageNet Classification | Very Deep Convolutional Networks for Large-Scale Image Recognition | Improving the Speed of Neural Networks on CPUs | MatConvNet: Convolutional Neural Networks for MATLAB | Deep Fried Convnets | Asymmetric Feature Representation for Object Recognition in Client Server System | Accelerating Very Deep Convolutional Networks for Classification and Detection",iclr,010
779.pdf.json,VOCABULARY SELECTION STRATEGIES FOR NEURAL MACHINE TRANSLATION,"Neural Machine Translation (NMT) has made great progress in recent years and improved the state of the art on several benchmarks (Jean et al., 2015b; Sennrich et al., 2016b; Zhou et al., 2016). However, neural systems are typically less efficient than traditional phrase-based translation models (PBMT; Koehn et al. 2003), both at training and decoding time. The efficiency of neural models depends on the size of the target vocabulary and previous work has shown that vocabularies of well over 50k word types are necessary to achieve good accuracy (Jean et al., 2015a; Zhou et al., 2016). Neural translation systems compute the probability of the next target word given both the previously generated target words as well as the source sentence. Estimating this conditional distribution is linear in the size of the target vocabulary which can be very large for many language pairs (Grave et al., 2016). Recent work in neural translation has adopted sampling techniques from language modeling which do not leverage the input sentence (Mikolov et al., 2011; Jean et al., 2015a; Chen et al., 2016; Zhou et al., 2016). On the other hand, classical translation models generate outputs in an efficient two-step selection procedure: first, a subset of promising translation rules is chosen by matching rules to the source sentence, and by pruning them based on local scores such as translation probabilities. Second, translation hypotheses are generated that incorporate non-local scores such as language model probabilities. Recently, Mi et al. (2016) proposed a similar strategy for neural translation: a selection method restricts the target vocabulary to a small subset, specific to the input sentence. The subset is then scored by the neural model. Their results demonstrate that vocabulary subsets that are only about 1% of the original size result in very little to no degradation in accuracy. This paper complements their study by experimenting with additional selection techniques and by analyzing","Neural machine translation by jointly learning to align and translate | Statistical machine translation through global lexical selection and sentence reconstruction | A neural probabilistic language model | Large-scale machine learning with stochastic gradient descent | Class-based n-gram models of natural language | The mathematics of statistical machine translation: Parameter estimation | Strategies for training large vocabulary neural language models | A simple, fast, and effective reparameterization of ibm model 2 | BilBOWA: Fast bilingual distributed representations without word alignments | Efficient softmax approximation for GPUs | On using very large target vocabulary for neural machine translation | Montreal neural machine translation systems for wmt15 | Statistical Machine Translation | Statistical Phrase-Based Translation | Moses: Open source toolkit for statistical machine translation | Word embeddings through hellinger pca | Achieving open vocabulary neural machine translation with hybrid word-character models | Effective approaches to attentionbased neural machine translation | Addressing the rare word problem in neural machine translation | Vocabulary manipulation for neural machine translation | Distributed representations of words and phrases and their compositionality | Strategies for Training Large Scale Neural Network Language Models | A scalable hierarchical distributed language model | Sequence Level Training with Recurrent Neural Networks | Tutorial on neural machine translation | Neural machine translation of rare words with subword units | Edinburgh neural machine translation systems for WMT 16 | A cheap and fast way to build useful translation lexicons | Flexible finite-state lexical selection for rule-based machine translation | Deep recurrent models with fast-forward connections for neural machine translation",iclr,010
780.pdf.json,,"Scaling up neural networks with respect to parameter sizes, training sets, or both has drastically improved the state-of-the-art performance in several domains ranging from scene understanding, speech recognition, even to playing Go against professional players. Although training a large network saturated with nonlinearities is extremely time-consuming, the benefits brought forth by large-scale models has sparked a surge of interest in parallelizing training on multi-GPUs. The parallelization of SGD demands synchronizations to exchange gradients and parameters per iteration, and this introduces significant communication overhead. Previous studies have focused on trading the SGD convergence rate for fast gradient updates, such as stale or asynchronous SGD, 1-bit compressed gradient, etc. However, these methods are rarely adopted by Deep Learning frameworks as they depend on the balance between the enhanced iteration throughput and the decelerated convergence rate. Since BSP retains the convergence properties of SGD, its optimization should be of interest. The gradient aggregations and parameter exchanges in BSP SGD are typical operations of communication collectives (Chan et al., 2007). Messages in the large-scale neural networks training are dense, long, and fixed-length, while the performance of collective algorithms is drastically sensitive to these attributes. Besides, the processing speed is several orders of magnitude faster than the network unidirectional transmission rate. These prioritize the utilization of network bandwidth in the collective design. However, we have seen sub-optimal collective algorithms, e.g. MST and BE, widely adopted by the deep learning community (Agarwal et al., 2014) (Jia et al., 2014) (Duchi et al., 2011). MST is only suitable for the latency dominant case such as frequent short message exchanges, while the bandwidth term of BE can be further improved (Thakur et al., 2005). In this paper, we introduce new Linear Pipeline based collec","Distributed delayed stochastic optimization | A reliable effective terascale linear learning system | Optimization of mpi collective communication on bluegene/l systems | Collective communication: theory, practice, and experience | Deep learning with cots hpc systems | Geeps: Scalable deep learning on distributed gpus with a gpu-specialized parameter server | Large scale distributed deep networks | Optimal distributed online prediction using mini-batches | Adaptive subgradient methods for online learning and stochastic optimization | Open mpi: Goals, concept, and design of a next generation mpi implementation | More effective distributed ml via a stale synchronous parallel parameter server | Caffe: Convolutional architecture for fast feature embedding | Communication efficient distributed machine learning with the parameter server | Hogwild: A lock-free approach to parallelizing stochastic gradient descent | 1-bit stochastic gradient descent and its application to data-parallel distributed training of speech dnns | Fundamental limits of online and distributed algorithms for statistical learning and estimation | Infiniband scalability in open mpi | Improving the performance of collective operations in mpich | Optimization of collective communication operations in mpich | Blasx: A high performance level-3 blas library for heterogeneous multi-gpu computing | Accelerating deep neural network training with inconsistent stochastic gradient descent | Pipelining and overlapping for mpi collective operations | Parallelized stochastic gradient descent",iclr,010
781.pdf.json,DYNAMIC PARTITION MODELS,"We consider the task of learning a compact binary representation (e.g. Goessling & Amit, 2015). That means we are seeking a parsimonious set of experts, which can explain a given collection of multivariate data points. In contrast to most existing approaches the emphasis here is on finding experts that are individually meaningful and that have disjoint responsibilities. Ideally, each expert explains only one factor of variation in the data and for each factor of variation there is exactly one expert that focuses on it. Formally, the experts Pk, k = 1, . . . ,K, are probability distributions that depend on binary latent variables h(k). The latent state h specifies which experts are active and has to be inferred for each D-dimensional data point x. The active experts then define a probability distribution P. The goal of representation learning is to train experts such that the conditional likelihood P(x |h) of the data given the latent activations is maximized. We start by describing a simple model family, which forms the basis of our work. A partition model (Hartigan, 1990) makes use of a manually specified partitioning of the D variables into subsets {1, . . . , D} = L∪ ℓ=1 Sℓ. For each subset of variablesx(Sℓ) = (x(d))d∈Sℓ there exists a separate model Pℓ. It is then typically assumed that variables in different subsets are conditionally independent, i.e., P(x |h) = L∏ ℓ=1 Pℓ(x(Sℓ) |h(ℓ)). (1) The model is completed by specifying a prior distribution P(h) for the latent state h. One advantage of partition models is that estimating Pℓ from observations is straightforward, while learning expert models in general requires computationally involved procedures (Bengio et al., 2013). However, in order to be able to define a satisfactory partitioning of the variables some prior knowledge about the dependence structure is needed. For image data a common choice is to use a regular grid that divides the image into patches (e.g. Pal et al., 2002). In general, a good partitioni",Patchwork of parts models for object recognition | Representation learning: A review and new perspectives | Combined top-down/bottom-up segmentation | Maximum likelihood from incomplete data via the em algorithm | Sparse and redundant representations | The shape boltzmann machine: a strong model of object shape | Learning generative visual models from few training examples: An incremental bayesian approach tested on 101 object categories | Compact compositional models | Mixtures of sparse autoregressive networks | Tracking the best expert | Training products of experts by minimizing contrastive divergence | A hierarchical community of experts | Gradient-based learning applied to document recognition | Maximal causes for non-linear component extraction | Finite mixture models | Sparse autoencoder | Learning montages of transformed latent images as representations of objects that change in appearance | Training restricted boltzmann machines using approximations to the likelihood gradient | Extracting and composing robust features with denoising autoencoders,iclr,010
782.pdf.json,,,Neural machine translation by jointly learning to align and translate | Neural turing machines | Learning to transduce with unbounded memory | Long short-term memory | Inferring algorithmic patterns with stack-augmented recurrent nets | Neural gpus learn algorithms | Grid long short-term memory | Adam: A method for stochastic optimization | Neural random-access machines | Gated graph sequence neural networks | Hierarchical probabilistic neural network language model | Rectified linear units improve restricted boltzmann machines | Understanding the exploding gradient problem | Gradient estimation using stochastic computation graphs | End-to-end memory networks | Sequence to sequence learning with neural networks. In Advances in neural information processing | Show and tell: A neural image caption generator | Simple statistical gradient-following algorithms for connectionist reinforcement learning | Reinforcement learning neural turing machines | Learning simple algorithms from examples,iclr,010
783.pdf.json,REVISITING DISTRIBUTED SYNCHRONOUS SGD,"The recent success of deep learning approaches for domains like speech recognition (Hinton et al., 2012) and computer vision (Ioffe & Szegedy, 2015) stems from many algorithmic improvements but also from the fact that the size of available training data has grown significantly over the years, together with the computing power, in terms of both CPUs and GPUs. While a single GPU often provides algorithmic simplicity and speed up to a given scale of data and model, there exist an operating point where a distributed implementation of training algorithms for deep architectures becomes necessary. Currently, popular distributed training algorithms include mini-batch versions of stochastic gradient descent (SGD) and other stochastic optimization algorithms such as AdaGrad (Duchi et al., 2011), RMSProp (Tieleman & Hinton, 2012), and ADAM (Kingma & Ba, 2014). Unfortunately, bulksynchronous implementations of stochastic optimization are often slow in practice due to the need to wait for the slowest machine in each synchronous batch. To circumvent this problem, practitioners have resorted to asynchronous approaches which emphasize speed by using potentially stale information for computation. While asynchronous training have proven to be faster than their synchronous counterparts, they often result in convergence to poorer results. In this paper1, we revisit synchronous learning, and propose a method for mitigating stragglers in synchronous stochastic optimization. Specifically, we synchronously compute a mini-batch gradient with only a subset of worker machines, thus alleviating the straggler effect while avoiding any staleness in our gradients. The primary contributions of our paper are: • Illustration of how gradient staleness in asynchronous training negatively impacts test accuracy and is exacerbated by deep models. • Measurement of machine response times for synchronous stochastic optimization in a large deployment of 100 GPUs, showing how stragglers in the tail end affect","TensorFlow: Large-scale machine learning on heterogeneous systems | Revisiting distributed synchronous sgd | Project adam: Building an efficient and scalable deep learning training system | Distributed deep learning using synchronous stochastic gradient descent | Taming the wild: A unified analysis of hogwild-style algorithms | Large scale distributed deep networks | The tail at scale | Adaptive subgradient methods for online learning and stochastic optimization | Estimation, optimization, and parallelism when data is sparse | Deep neural networks for acoustic modeling in speech recognition | Batch normalization: Accelerating deep network training by reducing internal covariate shift | On large-batch training for deep learning: Generalization gap and sharp minima | Adam: A method for stochastic optimization | Learning multiple layers of features from tiny images | Asaga: Asynchronous parallel saga | Scaling distributed machine learning with the parameter server | Perturbed iterate analysis for asynchronous stochastic optimization | Conditional image generation with pixelcnn decoders | Hogwild: A lock-free approach to parallelizing stochastic gradient descent | On variance reduction in stochastic gradient descent and its asynchronous variants | Imagenet large scale visual recognition challenge | Rethinking the inception architecture for computer vision | Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude | Ako: Decentralised deep learning with partial gradient exchange | Petuum: A new platform for distributed machine learning on big data | Deep learning with elastic averaging sgd | Staleness-aware async-sgd for distributed deep learning | Splash: User-friendly programming interface for parallelizing stochastic algorithms | Parallelized stochastic gradient descent",iclr,010
785.pdf.json,,"Progress in advanced driving assistance systems (ADASs) has led to an autonomous driving function applicable for highway driving . The vehicle control logic of ADAS is typically developed by hand. There are a few related works on controlling vehicles comfortably , but the complex nature of vehicle environments prevents development by hand. Therefore, recent research has focused on the application of machine learning to autonomous driving systems. The convolutional neural network (CNN) shows particular promise as a core algorithm (Krizhevsky et al. (2012)). C. Chen & Xiao (2015) estimates affordance for driving directly from a front camera image. They train a CNN to generate key perception indicators from images to easily control a vehicle. Similarly, Bojarski et al. (2016) predict the desired steering command directly from front camera images. They train a CNN with a human command as training data and drive in traffic on local roads with or without lane marking and on highways. Our objective is to provide drivers with a comfortable trip featuring automatic vehicle control . The above methods provide a uniform control for various scenarios, but drivers have an assortment of preference behaviors, and individuals may drive in different ways even if the scenario or situation is the same. For example, on the highway, one person might drive hard to arrive at a destination quickly while another might drive relatively slowly to arrive at a destination safely. Therefore, we want to provide autonomous driving adapted to each individual to improve ease of driving and to generate control targets that imitate individual behavior. To imitate individual behavior, we predict future vehicle states resulting from an individualfs decision. There are many studies on the imitation of human behavior within the context of driving. Ma & Andréasson (2006) proposed a vehicle interaction model that predicts future acceleration on the basis of current acceleration, velocity, relative velocity",Competitive learning algorithms for vector quantization | Getting to Know OBD II | End to end learning for self-driving cars | Deepdriving: Learning affordance for direct perception in autonomous driving | Why does unsupervised pre-training help deep learning | A probabilistic model for estimating driver behaviors and vehicle trajectories in traffic environments | Generating sequences with recurrent neural networks | Theory of the backpropagation neural network | On-Board Diagnostics for Light and Medium Duty Vehicles | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Adam: A method for stochastic optimization | Imagenet classification with deep convolutional neural networks. In Advances in neural information processing | Driver reaction time estimation from real car following data and application in gm-type model evaluation | A driver model for vehicle lateral dynamics | Noise-enhanced clustering and competitive learning algorithms | Competitive learning with feedforward supervisory signal for pre-trained multilayered networks | Chainer: a nextgeneration open source framework for deep learning | On driver’s braking behavior in car following | Backpropagation through time: what it does and how to do it,iclr,010
787.pdf.json,,"The multi-label learning problem is to learn to predict potentially multiple relevant labels given an instance. Instances that have multiple labels naturally occur in many application domains, including multimedia information retrieval, tag recommendation, semantic scene classification, query categorization, gene function prediction, medical diagnosis, drug discovery, and marketing. A popular approach to the multi-label learning problem is to embed the labels in a low-dimensional latent space via linear or local non-linear embeddings. The approach of Hsu et al. (2009) projects the label vectors to a random low-dimensional space, fits a regression model in this space, then projects these predictions back to the original label space. Balasubramanian & Lebanon (2012) use a sparsity-regularized least squares reconstruction objective to select a small set of landmark labels that are used to predict the remaining labels. Bi & Kwok (2013) take a similar approach, with a greatly decreased computation cost, by posing the problem of selecting the landmark labels as one of column subset selection and adopting the leverage score sampling approach (Boutsidis et al., 2009). Recently, Yu et al. (2014) and Jing et al. (2015) propose using trace norm regularization to identify a low-dimensional representation of the original large label space. Mineiro & Karampatziakis (2015) use randomized dimensionality reduction to learn a low-dimensional embedding that explicitly captures correlations between the instance features and their labels. These approaches, like other linear embedding methods, assume that the label matrix is low-rank. However, the label matrix in most applications of multi-label learning is a sparse binary matrix, and thus is extremely likely to violate this low-rank assumption (Bhatia et al., 2015). Rather than working with the original label and feature matrices, some methods work instead with label or feature similarity matrices, and seek to preserve the local structu","The landmark selection method for multiple output prediction | Sparse local embeddings for extreme multi-label classification | Efficient multi-label classification with many labels | An improved approximation algorithm for the column subset selection problem | Feature-aware label space dimension reduction for multi-label classification | ADIOS: Architectures Deep in Output Space | Adaptive subgradient methods for online learning and stochastic optimization | Multi-label prediction via compressed sensing | Semi-supervised low-rank mapping learning for multi-label classification | Multi-label classification via feature-aware implicit label space encoding | Fast label embeddings via randomized linear algebra | Bayesian Exponential Family PCA | Large-scale multi-label text classification revisiting neural networks | In All Likelihood: Statistical Modeling and Inference Using Likelihood | Fastxml: a fast, accurate and stable tree-classifier for extreme multi-label learning | Random features for large-scale kernel machines | Large-scale bayesian multi-label learning via topic-based label embeddings | Multi-label classification with principle label space transformation | Kullback-leibler divergence for nonnegative matrix factorization | Large-scale multi-label learning with missing labels | A review on multi-label learning algorithms",iclr,010
789.pdf.json,,"Unsupervised learning has benefited greatly from the introduction of deep generative models. In particular, the introduction of generative adversarial networks (GANs) (Goodfellow et al., 2014) and variational autoencoders (VAEs) (Kingma & Welling, 2014; Rezende et al., 2014) has led to a plethora of research into learning latent variable models that are capable of generating data from complex distributions, including the space of natural images (Radford et al., 2015). Both of these models, and their extensions, operate by placing a prior distribution, P (Z), over a latent space Z ⊆ Rb, and learn mappings from the latent space, Z, to the space of the observed data, X ⊆ Ra. We are interested in autoencoding generative models, models which learn not just the generative mapping Z 7→ X , but also the inferential mapping X 7→ Z. Specifically, we define generative autoencoders as autoencoders which softly constrain their latent distribution, to match a specified prior distribution, P (Z). This is achieved by minimising a loss, Lprior, between the latent distribution and the prior. This includes VAEs (Kingma & Welling, 2014; Rezende et al., 2014), extensions of VAEs (Kingma et al., 2016), and also adversarial autoencoders (AAEs) (Makhzani et al., 2015). Whilst other autoencoders also learn an encoding function, e : Ra → Z, together with a decoding function, d : Rb → X , the latent space is not necessarily constrained to conform to a specified probability distribution. This is the key distinction for generative autoencoders; both e and d can still be deterministic functions (Makhzani et al., 2015). The functions e and d are defined for any input from Ra and Rb respectively, however the outputs of the functions may be constrained practically by the type of functions that e and d are, such that e maps to Z ⊆ Rb and d maps to X ⊆ Ra. During training however, the encoder, e is only fed with training data samples, x ∈ X and the decoder, d is only fed with samples from the encoder",Generalized denoising auto-encoders as generative models | Deep generative stochastic networks trainable by backprop | Torch7: A matlab-like environment for machine learning | Generating images with perceptual similarity metrics based on deep networks | Generative Adversarial Nets | Denoising criterion for variational auto-encoding framework | Batch normalization: Accelerating deep network training by reducing internal covariate shift | Adam: A method for stochastic optimization | Auto-encoding variational Bayes | Improving variational inference with inverse autoregressive flow | Discriminative regularization for generative models | Autoencoding beyond pixels using a learned similarity metric | Deep learning face attributes in the wild | Reading digits in natural images with unsupervised feature learning | Unsupervised representation learning with deep convolutional generative adversarial networks | Stochastic backpropagation and approximate inference in deep generative models | A review of asymptotic convergence for general state space markov chains | Learning continuous attractors in recurrent networks | Extracting and composing robust features with denoising autoencoders | Sampling generative networks: Notes on a few effective techniques,iclr,010
790.pdf.json,,"As neural networks are applied to increasingly complex tasks, they are often trained to meet endto-end objectives that go beyond simple functional specifications. These objectives include, for example, generating realistic images (e.g., (Goodfellow et al., 2014a)) and solving multiagent problems (e.g., (Foerster et al., 2016a;b; Sukhbaatar et al., 2016)). Advancing these lines of work, we show that neural networks can learn to protect their communications in order to satisfy a policy specified in terms of an adversary. Cryptography is broadly concerned with algorithms and protocols that ensure the secrecy and integrity of information. Cryptographic mechanisms are typically described as programs or Turing machines. Attackers are also described in those terms, with bounds on their complexity (e.g., limited to polynomial time) and on their chances of success (e.g., limited to a negligible probability). A mechanism is deemed secure if it achieves its goal against all attackers. For instance, an encryption algorithm is said to be secure if no attacker can extract information about plaintexts from ciphertexts. Modern cryptography provides rigorous versions of such definitions (Goldwasser & Micali, 1984). Adversaries also play important roles in the design and training of neural networks. They arise, in particular, in work on adversarial examples (Szegedy et al., 2013; Goodfellow et al., 2014b) and on generative adversarial networks (GANs) (Goodfellow et al., 2014a). In this latter context, the adversaries are neural networks (rather than Turing machines) that attempt to determine whether a sample value was generated by a model or drawn from a given data distribution. Furthermore, in contrast with definitions in cryptography, practical approaches to training GANs do not consider all possible adversaries in a class, but rather one or a small number of adversaries that are optimized by training. We build on these ideas in our work. Neural networks are generally not meant to ",TensorFlow: Large-scale machine learning on heterogeneous distributed systems | TensorFlow: A system for large-scale machine learning | On the (im)possibility of obfuscating programs | Fully automated analysis of padding-based encryption in the computational model | InfoGAN: Interpretable representation learning by information maximizing generative adversarial nets | Deep generative image models using a Laplacian pyramid of adversarial networks | Applied neuro-cryptography | Censoring representations with an adversary | Learning to communicate to solve riddles with deep distributed recurrent Q-networks | Learning to communicate with deep multi-agent reinforcement learning | Cryptonets: Applying neural networks to encrypted data with high throughput and accuracy | Probabilistic encryption | Generative adversarial nets | Explaining and harnessing adversarial examples | Adam: A method for stochastic optimization | Analysis of neural cryptography | The variational fair autoencoder | Neural programmer: Inducing latent programs with gradient descent | f-GAN: Training generative neural samplers using variational divergence minimization | Characterization and computation of local nash equilibria in continuous games | Neural synchronization and cryptography | Improved techniques for training GANs | Learning multiagent communication with backpropagation | Intriguing properties of neural networks | Simple statistical gradient-following algorithms for connectionist reinforcement learning | Crypto-nets: Neural networks over encrypted data,iclr,010
791.pdf.json,DEEP UNSUPERVISED LEARNING THROUGH SPATIAL CONTRASTING,"For the past few years convolutional networks (ConvNets, CNNs) LeCun et al. (1998) have proven themselves as a successful model for vision related tasks Krizhevsky et al. (2012) Mnih et al. (2015) Pinheiro et al. (2015) Razavian et al. (2014). A convolutional network is composed of multiple convolutional and pooling layers, followed by a fully-connected affine transformations. As with other neural network models, each layer is typically followed by a non-linearity transformation such as a rectified-linear unit (ReLU). A convolutional layer is applied by cross correlating an image with a trainable weight filter. This stems from the assumption of stationarity in natural images, which means that parameters learned for one local region in an image can be shared for other regions and images. Deep learning models, including convolutional networks, are usually trained in a supervised manner, requiring large amounts of labeled data (ranging between thousands to millions of examples per-class for classification tasks) in almost all modern applications. These models are optimized using a variant of stochastic-gradient-descent (SGD) over batches of images sampled from the whole training dataset and their ground truth-labels. Gradient estimation for each one of the optimized parameters is done by back propagating the objective error from the final layer towards the input. This is commonly known as ”backpropagation” Rumelhart et al.. In early works, unsupervised training was used as a part of pre-training procedure to obtain an effective initial state of the model. The network was later fine-tuned in a supervised manner as displayed by Hinton (2007). Such unsupervised pre-training procedures were later abandoned, since they provided no apparent benefit over other initialization heuristics in more careful fully supervised training regimes. This led to the de-facto almost exclusive usage of neural networks in supervised environments. In this work we will present a novel unsupervis","Pn-net: Conjoined triple deep network for learning local image descriptors | Signature verification using a siamese time delay neural network | Learning a similarity metric discriminatively, with application to face verification | Learning feature representations with k-means | An analysis of single-layer networks in unsupervised feature learning | Torch7: A matlab-like environment for machine learning | Unsupervised visual representation learning by context prediction | Discriminative unsupervised feature learning with convolutional neural networks | Generative adversarial nets | Noise-contrastive estimation: A new estimation principle for unnormalized statistical models | Deep residual learning for image recognition | To recognize shapes, first learn to generate images | Deep metric learning using triplet network | Direct modeling of complex invariances for visual object features | Batch normalization: Accelerating deep network training by reducing internal covariate shift | What is the best multistage architecture for object recognition | Learning multiple layers of features from tiny images | ImageNet Classification with Deep Convolutional Neural Networks | Gradient-based learning applied to document recognition | Distributed representations of words and phrases and their compositionality | Learning word embeddings efficiently with noise-contrastive estimation | Human-level control through deep reinforcement learning | An analysis of unsupervised pre-training in light of recent advances | Learning to segment object candidates | Unsupervised representation learning with deep convolutional generative adversarial networks | Semisupervised learning with ladder networks | Cnn features off-theshelf: an astounding baseline for recognition | Improved techniques for training gans | Facenet: A unified embedding for face recognition and clustering | Unsupervised and semi-supervised learning with categorical generative adversarial networks | Going deeper with convolutions | Extracting and composing robust features with denoising autoencoders | Regularization of neural networks using dropconnect | Deep representation learning with target coding | Deconvolutional networks | Stacked what-where auto-encoders",iclr,010
792.pdf.json,SOFTTARGET REGULARIZATION AN EFFECTIVE TECHNIQUE TO REDUCE OVER-FITTING IN NEURAL NETWORKS,"Many regularization techniques have been created to rectify the problem of over-fitting in deep neural networks, but the majority of these methods reduce models capacities to force them to learn general enough features. For example, Dropout reduces the amount of learn-able parameters by randomly dropping activations, and DropConnect extends this idea by randomly dropping weights (Srivastava et al., 2014), (Wan et al., 2013). Weight decay regularization reduces the capacity of the model, not by dropping learn-able parameters, but by reducing the space of viable solutions (Krogh & Hertz, 1992).","Random search for hyper-parameter optimization | URL https://github.com/ fchollet/keras | Categorization, prototype theory and neural dynamics | Semi-supervised Learning by Entropy | Deep Residual Learning for Image Recognition | Distilling the Knowledge in a Neural Network | Matplotlib: A 2D Graphics Environment | Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift | Learning Multiple Layers of Features from Tiny Images | ImageNet Classification with Deep Convolutional Neural Networks | A Simple Weight Decay Can Improve Generalization | Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks | Reading Digits in Natural Images with Unsupervised Feature Learning | On the adequacy of prototype theory as a theory of concepts | Training Deep Neural Networks on Noisy Labels with Bootstrapping | Principles of Categorization | Evaluation of Pooling Operations in Convolutional Architectures for Object Recognition, pp. 92–101 | Dropout: A Simple Way to Prevent Neural Networks from Overfitting | Development Team. Theano: A Python framework for fast computation of mathematical expressions | Regularization of Neural Networks using DropConnect | ADADELTA: An Adaptive Learning Rate Method",iclr,010
793.pdf.json,,"Based on human performance on the same task, it is believed that an important ingredient which is missing in state-of-the-art variants of recurrent networks is top-down feedback. Despite evidence of its existence, it is not entirely clear how mammalian brain might implement such a mechanism. It is important to understand what kind of top-down interaction contributes to improved prediction capability in order to tackle more challenging AI problems requiring interpretation of deeper contextual information. Furthermore, it might provide clues as what makes human cognitive abilities so unique. Existing approaches which consider top-down feedback in neural networks are primarily focused on stacked layers of neurons, where higher-level representations constitute a top-down signal source. In this paper, we propose that the discrepancy between most recent predictions and observations might be effectively used as a feedback signal affecting further predictions. It is very common to use such a discrepancy during learning phase as the error which is subject to minimization, but not during inference. We show that is also possible to use such top-down signal without losing generality of the algorithm and that it improves generalization capabilities when applied to Long-Short Term Memory (Hochreiter & Schmidhuber, 1997) architecture. It is important to point out that the feedback idea presented here applies only to temporal data.","Gated feedback recurrent neural networks | Understanding the difficulty of training deep feedforward neural networks | Long short-term memory | Grid long short-term memory | Zoneout: Regularizing rnns by randomly preserving hidden activations | Semisupervised learning with ladder | Recurrent memory array structures | Generating text with recurrent neural networks | Backpropagation through time: what does it do and how to do it | On multiplicative integration with recurrent neural networks | Recurrent highway networks, 2016",iclr,010
0804.2155.pdf.json,From Qualitative to Quantitative Proofs of Security Properties Using First-Order Conditional Logic,"Security protocols, such as key-exchange and keymanagement protocols, are short, but notoriously difficult to prove correct. Flaws have been found in numerous protocols, ranging from the the 802.11 Wired Equivalent Privacy (WEP) protocol used to protect link-layer communications from eavesdropping and other attacks (Borisov, Goldberg, & Wagner 2001) to standards and proposed standards for Secure Socket Layer (Wagner & Schneier 1996; Mitchell, Shmatikov, & Stern 1998) to Kerberos (Bella & Paulson 1998). Not surprisingly, a great deal of effort has been devoted to proving the correctness of such protocols. There are two largely disjoint approaches. The first essentially ignores the details of cryptography by assuming perfect cryptography (i.e., nothing encrypted can ever be decrypted without the encryption key) and an adversary that controls the network. By ignoring the cryptography, it is possible to give a more qualitative proof of correctness, using logics designed for reasoning about security protocols. Indeed, this approach has enabled axiomatic proofs of correctness and model checking of proofs (see, for example, (Mitchell, Mitchell, & Stern 1997; Paulson 1994)). The second approach applies the tools of modern cryptography to proving correctness, using more quantitative arguments. Typically it is shown that, given some security parameter k (where k may be, for example, the length of the key used) an adversary ∗Supported in part by NSF under under grants ITR-0325453 and IIS-0534064, and by AFOSR under grant FA9550-05-1-0055. Copyright c© 2008, American Association for Artificial Intelligence (www.aaai.org). All rights reserved. whose running time is polynomial in k has a negligible probability of breaking the security, where “negligible” means “less than any inverse polynomial function of k” (see, for example, (Bellare, Canetti, & Krawczyk 1998; Goldreich 2001)). There has been recent work on bridging the gap between these two approaches, with the goal of constru","and Rogaway | L | A modular approach to the design and analysis of authentication and key exchange protocols | Intercepting mobile communications: the insecurity of 802.11 | J | J | J | H | J | J | and Pearl | A maximum entropy approach to nonmonotonic reasoning | Nonmonotonic reasoning, preferential models and cumulative logics | Automated analysis of cryptographic protocols using Murφ | J | L | and Schneier",rejected,000
0806.4686.pdf.json,Sparse Online Learning via Truncated Gradient,"We are concerned with machine learning over large datasets. As an example, the largest dataset we use here has over 107 sparse examples and 109 features using about 1011 bytes. In this setting, many common approaches fail, simply because they cannot load the dataset into memory or they are not su ciently e cient. There are roughly two approaches which can work: 1. Parallelize a batch learning algorithm over many machines (e.g., [3]). 2. Stream the examples to an online learning algorithm (e.g., [8], [9], [2], and [5]). This paper focuses on the second approach. Typical online learning algorithms have at least one weight for every feature, which is too much in some applications for a couple reasons: 1. Space constraints. If the state of the online learning algorithm over ows RAM it can not e ciently run. A similar problem occurs if the state over ows the L2 cache. 1 ar X iv :0 80 6. 46 86 v1 [ cs .L G ] 2 8 Ju n 2. Test time constraints on computation. Substantially reducing the number of features can yield substantial improvements in the computational time required to evaluate a new sample. This paper addresses the problem of inducing sparsity in learned weights while using an online learning algorithm. There are several ways to do this wrong for our problem. For example: 1. Simply adding L1 regularization to the gradient of an online weight update doesn't work because gradients don't induce sparsity. The essential di culty is that a gradient update has the form a+b where a and b are two oats. Very few oat pairs add to 0 (or any other default value) so there is little reason to expect a gradient update to accidentally produce sparsity. 2. Simply rounding weights to 0 is problematic because a weight may be small due to being useless or small because it has been updated only once (either at the beginning of training or because the set of features appearing is also sparse). Rounding techniques can also play havoc with standard online learning guarantees. 3. Black-box w","University of California, Irvine, School of Information and Computer Sciences, http://www.ics.uci.edu/∼mlearn/MLRepository.html | Worst-case quadratic loss bounds for prediction using linear functions and gradient descent | Map-reduce for machine learning on multicore | Exponentiated gradient versus gradient descent for linear predictors | RCV1: A new benchmark collection for text categorization research | Learning quickly when irrelevant attributes abound: A new linear-threshold algorithms | On-line learning of linear functions | Pegasos: Primal Estimated sub- GrAdient SOlver for SVM | Matlab implementation of LASSO, LARS, the elastic net and SPCA | Regression shrinkage and selection via the lasso | Solving large scale linear prediction problems using stochastic gradient descent algorithms",rejected,000
0807.1997.pdf.json,,"In multi-instance learning [14], the training set consists of many bags of instances. It is known that a bag is positive if it contains at least one positive instance; otherwise it is a negative bag. However, although the labels of the training bags are known, the labels of the instances in the bags are unknown. The goal is to generate a learner to classify unseen bags. Multi-instance learning has been found useful in diverse domains such as image categorization [9, 10], image retrieval [37, 40], text categorization [2, 29], computer security [27], face detection [33, 38], computer-aided medical diagnosis [15], etc. In our opinion, the usefulness of multi-instance learning mainly lies in the fact that many real objects have inherent structures, and by adopting the multiinstance representation we are able to represent such objects more naturally and capture more information than simply using the flat single-instance representation. For example, suppose we can partition an image into several parts. In contrast to representing the whole image as a single-instance, if we represent each part as an instance, then the partition information is captured by the multi-instance representation; and if the partition is meaningful (e.g., each part corresponds to a region of saliency), then the additional information captured by the multi-instance representation is helpful to make the learning task easier to deal with. It is obviously not a good idea to apply multi-instance learning techniques everywhere since if the single-instance representation is sufficient, using multiinstance representation just gilds the lily. Even on tasks where the objects have inherent structure, we should keep in mind that the power of multi-instance representation exists in its ability of capturing some structure information. However, previous studies on multi-instance learning typically treat the instances in the bags as independently and identically distributed [41], which neglects the fact that the r",Multiple-instance learning of real-valued data | Support vector machines for multiple-instance learning | On learning from multi-instance examples: Empirical evaluation of a theoretical approach | A boosting approach to multiple instance learning | UCI repository of machine learning databases | Multi-instance tree learning | Shortest-path kernels on graphs | Multiple instance learning for sparse positive bags | MILES: Multiple-instance learning via embedded instance selection | Image categorization by learning and reasoning with regions | A regularization framework for multiple-instance learning | A framework for learning rules from multiple instance data | Visual categorization with bags of keypoints | Solving the multipleinstance problem with axis-parallel rectangles | Multiple instance learning for computer aided diagnosis | A survey of kernels for structured data | Multi-instance kernels | Composite kernels for hypertext categorisation | Marginalized kernels between labeled graphs | Marginalized multi-instance kernels | Laerning the kernel matrix with semidefinite programming | A framework for multiple-instance learning | A quadratic programming approach to the graph edit distance problem | MISSL: Multiple-instance semi-supervised learning | Supervised versus multiple instance learning: An empirical comparison | Multiple instance regression | Learning single and multiple instance decision trees for computer security applications | On generalized multiple-instance learning | Multiple-instance active learning | Toward memory-based reasoning | SVM-based generalized multiple-instance learning via approximate box counting | A global geometric framework for nonlinear dimensionality reduction | Multiple instance boosting for object detection | Solving the multi-instance problem: A lazy learning approach | A two-level learning method for generalized multi-instance problem | Logistic regression and boosting for labeled bags of instances | Image database retrieval with multiple-instance learning techniques | Multiple-instance pruning for learning efficient cascade detectors | Adapting RBF neural networks to multi-instance learning | Content-based image retrieval using multiple-instance learning | On the relation between multi-instance learning and semi-supervised learning | Ensembles of multi-instance learners | Neural networks for multi-instance learning | Multi-instance multi-label learning with application to scene classification | Solving multi-instance problems with classifier ensemble based on constructive clustering | Semi-supervised learning literature survey,rejected,000
0810.5631.pdf.json,Temporal Difference Updating without a Learning Rate,"In the field of reinforcement learning, perhaps the most popular way to estimate the future discounted reward of states is the method of temporal difference learning. It is unclear who exactly introduced this first, however the first explicit version of temporal difference as a learning rule appears to be Witten [Wit77]. The idea is as follows: The expected future discounted reward of a state s is, V s := E { rk + γrk+1 + γ 2rk+2 + · · · |sk = s } , where the rewards rk, rk+1, . . . are geometrically discounted into the future by γ < 1. From this definition it follows that, V s = E { rk + γV sk+1|sk = s } . (1) Our task, at time t, is to compute an estimate V ts of V s for each state s. The only information we have to base this estimate on is the current history of state transitions, s1, s2, . . . , st, and the current history of observed rewards, r1, r2, . . . , rt. Equation (1) suggests that at time t + 1 the value of rt + γVst+1 provides us with information on what V ts should be: If it is higher than V t st then perhaps this estimate should be increased, and vice versa. This intuition gives us the following estimation heuristic for state st, V t+1st := V t st + α ( rt + γV t st+1 − V tst ) , where α is a parameter that controls the rate of learning. This type of temporal difference learning is known as TD(0). One shortcoming of this method is that at each time step the value of only the last state st is updated. States before the last state are also affected by changes in the last state’s value and thus these could be updated too. This is what happens with so called temporal difference learning with eligibility traces, where a history, or trace, is kept of which states have been recently visited. Under this method, when we update the value of a state we also go back through the trace updating the earlier states as well. Formally, for any state s its eligibility trace is computed by, Ets := { γλEt−1s if s 6= st, γλEt−1s + 1 if s = st, where λ is used to control t",Adaptive stepsizes for recursive estimation with applications in approximate dynamic programming | Least-squares policy iteration | Increamental multi-step Q-learning | On-line Q-learning using connectionist systems | Rummery. Problem solving with reinforcement learning | Reinforcement learning: An introduction | Learning to predict by the methods of temporal differences | Learning from Delayed Rewards | An adaptive optimal controller for discrete-time markov environments,rejected,000
0902.2206.pdf.json,Feature Hashing for Large Scale Multitask Learning,"Kernel methods use inner products as the basic tool for comparisons between objects. That is, given objects x1, . . . , xn ∈ X for some domain X, they rely on k(xi, xj) := 〈φ(xi), φ(xj)〉 (1) to compare the features φ(xi) of xi and φ(xj) of xj respectively. Eq. (1) is often famously referred to as the kernel-trick. It allows the use of inner products between very high dimensional feature vectors φ(xi) and φ(xj) implicitly through the definition of a positive semi-definite kernel matrix k without ever having to compute a vector φ(xi) directly. This can be particularly powerful in classification settings where the original input representation has a non-linear decision boundary. Often, linear separability can be achieved in a high dimensional feature space φ(xi). Preliminary work. Under review by the International Conference on Machine Learning (ICML). Do not distribute. In practice, for example in text classification, researchers frequently encounter the opposite problem: the original input space is almost linearly separable (often because of the existence of handcrafted non-linear features), yet, the training set may be prohibitively large in size and very high dimensional. In such a case, there is no need to map the input vectors into a higher dimensional feature space. Instead, limited memory makes storing a kernel matrix infeasible. For this common scenario several authors have recently proposed an alternative, but highly complimentary variation of the kernel-trick, which we refer to as the hashing-trick: one hashes the high dimensional input vectors x into a lower dimensional feature space Rm with φ : X → Rm (Langford et al., 2007; Shi et al., 2009). The parameter vector of a classifier can therefore live in Rm instead of in Rn with kernel matrices or Rd in the original input space, where m ≪ n and m ≪ d. Different from random projections, the hashing-trick preserves sparsity and introduces no additional overhead to store projection matrices. To our knowledge, we",Database-friendly random projections: Johnson-lindenstrauss with binary coins | The Netflix Prize | The theory of probabilities. Moscow: Gastehizdat Publishing House | An improved data stream summary: The count-min sketch and its applications | Small statistical models by random feature mixing | Similarity search in high dimensions via hashing | Vowpal wabbit online learning project (Technical Report) | The concentration of measure phenomenon | Conditional random sampling: A sketch-based sampling technique for sparse | Random features for largescale kernel machines | Randomized kitchen sinks,rejected,000
0903.2851.pdf.json,,"In this paper we consider the decision-theoretic framework for online learning (DTOL) proposed by Freund and Schapire [FS97]. DTOL is a variant of the framework of prediction with expert advice introduced by Littlestone and Warmuth [LW94] and Vovk [Vov98]. In this setting, a forecaster repeatedly assigns probabilities to a fixed set of actions. After each assignment, the actual loss associated with each action is revealed. The losses are restricted to the range [0, 1]. The forecaster’s loss on each round is the average loss of actions for that round, where the average is computed according to the forecaster’s current probability assignment. The goal of the forecaster is to achieve, on any sequence of losses, a cumulative loss close to the lowest cumulative loss among all single actions. We call this action the best action; and we call regret the difference between the cumulative loss achieved by the forecaster on a fixed loss sequence, and the cumulative loss of the best action. Freund and Schapire [FS97, FS99] use the Hedge algorithm, which assigns to the ith action a probability proportional to exp(−ηXi) where Xi is the cumulative loss of action i and η > 0 is a parameter called the learning rate. By appropriately tuning η, Hedge can achieve a regret bounded by O( √ T lnN), where T is the number of iterations and N is the number of actions. A matching lower bound of Ω( √ T lnN) is proven in [FS99]. A disadvantage of the upper bound is that it holds only for particular values of T and N because the learning rate η is set as a function of these parameters. It is clear that setting T in advance is a serious limitation; we would like an algorithm that performs close to optimally for every sequence length. It is less obvious why fixing the number of actions ahead of time is a limitation. To appreciate this, suppose that the actions consist of two equalsized sets where all of the actions in each set have an identical sequence of losses. While the number of actions N mig",Adaptive and self-confident on-line learning algorithms | How to use expert advice | On-line prediction and conversion strategies | Potentialbased algorithms in on-line prediction and game theory | Improved second-order bounds for prediction with expert advice | Drifting games and Brownian motion | A decisiontheoretic generalization of on-line learning and an application to boosting | Adaptive game playing using multiplicative weights | The robustness of p-norm algorithms | General convergence results for linear discriminant updates | Approximation to bayes risk in repeated play | Extracting certainty from uncertainty: Regret bounded by variation in costs | Adaptive online prediction by following the perturbed leader | Efficient algorithms for the online optimization | The weighted majority algorithm | Learning with continuous experts using drifting games | A game of prediction witih expert advice | How to better use expert advice,rejected,000
0904.2623.pdf.json,Exponential Family Graph Matching and Ranking,"The Maximum-Weight Bipartite Matching Problem (henceforth ‘matching problem’) is a fundamental problem in combinatorial optimization [26]. This is the problem of finding the ‘heaviest’ perfect match in a weighted bipartite graph. An exact optimal solution can be found in cubic time by standard methods such as the Hungarian algorithm. This problem is of practical interest because it can nicely model real-world applications. For example, in computer vision the crucial problem of finding a correspondence between sets of image features is often modeled as a matching problem [2, 3]. Ranking algorithms can be based on a matching framework [19], as can clustering algorithms [14, 11]. When modeling a problem as one of matching, one central question is the choice of the weight matrix. The problem is that in real applications we typically observe edge feature vectors, not edge weights. Consider a concrete example in computer vision: it ∗NICTA’s Statistical Machine Learning program, Locked Bag 8001, ACT 2601, Australia, and Research School of Information Sciences and Engineering, Australian National University, ACT 0200, Australia. NICTA is funded by the Australian Government’s Backing Australia’s Ability initiative, and the Australian Research Council’s ICT Centre of Excellence program. e-mails: first.last@nicta.com.au ar X iv :0 90 4. 26 23 v2 [ cs .L G ] 5 J un 2 is difficult to tell what the ‘similarity score’ is between two image feature points, but it is straightforward to extract feature vectors (e.g. SIFT) associated with those points. In this setting, it is natural to ask whether we could parameterize the features, and use labeled matches in order to estimate the parameters such that, given graphs with ‘similar’ features, their resulting max-weight matches are also ‘similar’. This idea of ‘parameterizing algorithms’ and then optimizing for agreement with data is called structured estimation [31, 33]. [31] and [3] describe max-margin structured estimation formalisms fo","Matching with shape contexts. CBAIVL00 | Shape matching and object recogniti n sing shape contexts | Learning graph matching | Learning to rank: from pairwise approach to listwise approach | Frank: A ranking method with fidelity | An efficient boosting algorithm for combining preferences | Multicategory ψ-learning and support vector machine | Approximate inference using planar graph decomposition | Large margin rank boundaries for ordinal regression | Loopy belief propagation for bipartite maximum weight b-matching. AISTATS | Structured ranking learning using cumulative distribution networks | Fast approximation of the permanent for very dense problems | B-matching for spectral clustering. ECML | Cumulated gain-based evaluation of ir techniques | A shortest augmenting path algorithm for dense and sparse linear assignment problems | Structured prediction models via the matrix-tree | Conditional random fields: Probabilistic modeling for segmenting and labeling sequence data | Direct optimization of ranking measures. http://arxiv.org/abs/0704.3359 | Letor: Benchmark dataset for research on learning to rank for information | Generalization bounds and consistency for structured labeling | Selection bias in the letor datasets. LR4IR | Combinatorial optimization: Algorithms and complexity | Global ranking using continuous conditional random fields | Sortnet: Learning to rank by a neural-based sorting algorithm. LR4IR | On a Theorem of Hardy, Littlewood, Polya, and Blackwell | Learning structured prediction models: a large-margin approach | Large margin methods for structured and interdependent output variables | The complexity of computing the permanent | Graphical models, exponential families, and variational inference (Technical Report 649) | Adarank: a boosting algorithm for information | Query-level learning to rank using isotonic regression. LR4IR",rejected,000
0911.0460.pdf.json,Feature-Weighted Linear Stacking,"“Stacking” is a technique in which the predictions of a collection of models are given as inputs to a second-level learning algorithm. This second-level algorithm is trained to combine the model predictions optimally to form a final set of predictions. Many machine learning practitioners have had success using stacking and related techniques to boost prediction accuracy beyond the level obtained by any of the individual models. In some contexts, stacking is also referred to as blending, and we will use the terms interchangeably here. Since its introduction [23], modellers have employed stacking successfuly on a wide variety of problems, including chemometrics [8], spam filtering [16], and large collections of datasets drawn from the UCI Machine learning repository [21, 7]. One prominent recent example of the power of model blending was the Netflix Prize1 collaborative filtering competition. The team BellKor’s Pragmatic Chaos won the $1 million prize using a blend of hundreds of different models [22, 11, 14]. Indeed, the winning solution was a blend at multiple levels, i.e., a blend of blends. Intuition suggests that the reliability of a model may vary as a function of the conditions in which it is used. For instance, in a collaborative filtering context where we wish to predict the preferences of customers for various products, the amount of data collected may vary significantly depending on which customer or which product is under consideration. Model A may be more reliable than model B for users who have rated many products, but model B may outperform model A for users who have only rated a few products. In an attempt to capitalize on this intuition, many researchers have developed approaches that attempt to improve the accuracy of stacked regression by adapting the blending on the basis of side information. Such an additional source of information, like the number of products rated by a user or the number of days since a product was released, is often referred to","Applying machine learning for prediction, recommmendation, and integration | The bellkor solution to the netflix prize | The bellkor 2008 solution to the netflix prize | Scalable collaborative filtering with jointly derived neighborhood interpolation weights | Stacked regressions | Is combining classifiers with stacking better than selecting the best one | Mccv stacked regression for model combination and fast spectral interval selection in multivariate calibration | Factorization meets the neighborhood: a multifaceted collaborative filtering model | The bellkor solution to the netflix grand prize | Collaborative filtering with temporal dynamics | Improving regularized singular value decomposition for collaborative filtering | The pragmatic theory solution to the netflix grand prize | A dynamic integration algorithm for an ensemble of classifiers | Stacking classifiers for anti-spam filtering of E-mail | Restricted boltzmann machines for collaborative filtering | Adjustment of an inverse matrix corresponding to changes in the elements of a given column or 16  a given row of the original matrix | Ordinal matrix factorization, September 2009. http:// www.netflixprize.com/community/viewtopic.php?id=1541 | Scalable collaborative filtering approaches for large recommender | Issues in stacked generalization | The bigchaos solution to the netflix grand prize | Stacked generalization",rejected,000
0911.1965.pdf.json,Active Learning for Mention Detection: A Comparison of Sentence Selection Strategies,"Human annotation is expensive, yet it is needed in many tasks in order to create training data. Given the high cost, it is critical to improve the e ciency of such annotation. Active learning involves selecting samples intelligently rather than randomly, for human annotation. By doing so, it is possible for systems to attain better performance with the same amount of annotation or achieve the same level of performance with a lot less annotated data. In this paper, we present several new active learning strategies for the task of Mention Detection (MD). Here, we employ the terminology used in the Automatic Content Extraction Conferences [1]. Mentions are references to real-world entities that can be named (e.g. John ), nominal (e.g. survivor ) or pronominal (e.g. he ). We propose and investigate a variety of sentence selection criteria for active learning, including various sentence scoring metrics that combine uncertaintybased and query-by-committee like measurements. Experimental results show that these sentence selection strategies are quite e ective for mention detection: compared to the random selection strategy, the best strategy reduces the amount of required annotated training data by over 50% while achieving the same performance. The e ect is even more signi cant when only named mentions are considered: the system achieves the same performance by using only 42% of the training data required by the random strategy. In the next section, we discuss related work on active learning. Section 3 describes our framework in detail and presents our experimental setup. Section 4 ar X iv :0 91 1. 19 65 v1 [ cs .C L ] 1 0 N ov presents the results of the di erent experiments. Finally, we discuss observations from our experiments and present some ideas for future work.",Automatic Content Extraction | Heterogeneous uncertainty sampling for supervised learning | Employing EM in pool-based active learning for text classi cation | Less is more: Active learning with support vector machines | Support vector machine active learning with applications to text classi cation | Committee-based sample selection for probabilistic classi ers | Active learning for natural language parsing and information extraction | Active learning for statistical natural language parsing | Example selection for bootstrapping statistical parsers | Ensemble-based active learning for parse selection | Rule writing or annotation: Cost-e cient resource usage for base noun phrase chunking | An empirical study of active learning with support vector machines for japanese word segmentation | Scaling to very very large corpora for natural language disambiguation | Active learning selection strategies for information extraction | Multi-criteria-based active learning for named entity recognition | Investigating the e ects of selective sampling on the annotation task | Active learning with statistical models | Query by committee | Supporting access to large digital oral history archives | Building an information retrieval test collection for spontaneous conversational speech | A statistical model for multilingual entity detection and tracking,rejected,000
0911.3209.pdf.json,,,"Coordinate multi-population genetic algorithms for multimodal function optimization | The simulated annealing algorithm for multi-modal function problem | Effective optimization algorithm for multimodal functions | Application-oriented fast optimizer for multi-peak searchin | New algorithm for multimodal function optimization based on immune algorithm and Hopfield neural network | Positive feedback as a search strategy | Distributed Optimization by Ant Colonies | Optimization Learning and Natural Algorithms | THE Ant System: Optimization by a colony of cooperating agents | HANDBOOKS IN OPER- ATIONS RESEARCH AND MANAGEMENT SCIENCE, 7: NETWORK MODELS | Nemhauser,HANDBOOKS IN OPERA- TIONS RESEARCH AND MANAGEMENT SCIENCE, 8: NETWORK ROUTING | Pareto ant colony optimization with IP preprocessing in multiobjective project portfolio selection | Ant Colony System: A cooperative learning approach to the traveling salesman problem | Parallel ant colony optimization for the traveling salesman problem | Ant colonies for the quadratic assignment problem | Ant-Q: A reinforcement learning approach to the traveling salesman problem | Applying the ant system to the vehicle routing problem | An ant systemfor bus driver scheduling | Data mining with an ant colony optimization algorithm | On the invariance of ant colony optimization | A graph-based ant system and its convergence | A Short Convergence Proof for a Class of ACO Algorithms | Experiment study of entropy convergence of ant colony optimization | Runtime analysis of ant colony optimization with best-so-far reinforcement | First steps to the runtime complexity analysis of ant colony optimization | Applying local clustering method to improve the running speed of Ant Colony Optimization | Applying local clustering method to improve the running speed of Ant Colony Optimization | The ant colony metaphor for searching continuous spaces | Multi-Colony Ant Algorithm for Continuous Multi-Reservoir Operation Optimization Problem | Cooperative distributed search: the ant’s way | Ant colony approach to continuous function optimization | Semi-continuous ACO algorithms (technical report) | P.-Siarry,“A new ant colony algorithm using the hierarchical concept aimed at optimization of multiminima continuous functions,",rejected,000
0911.3708.pdf.json,Manipulability of Single Transferable Vote,"A simple mechanism for collaborating agents to reach consensus on a plan of action is to vote. One issue is the possibility of agents trying to manipulate such an election by mis-reporting their preferences in order to get a better result. Fortunately, it is often computationally difficult to find a successful manipulation [1]. For example, Bartholdi and Orlin proved that the Single Transferable Vote (STV) rule is NP-hard to manipulate [2]. This remains one of the few commonly used voting rules which is NP-hard to manipulate without weights on the votes, or uncertainty in how the other agents have voted. NP-hardness is only a worst-case result and may not reflect the difficulty of manipulation in practice. Indeed, a number of recent theoretical results suggest that manipulation can often be computationally easy [3,4,5,6,7]. Most recently, Walsh has suggested that empirical studies might provide insights into the computational complexity of manipulation that can complement such theoretical results [8]. For example, when theoretical analysis is asymptotic, empirical studies can reveal if hidden constants and the finite size of elections met in practice are significant. As a second example, theoretical analysis is often restricted to simple distributions. Manipulation may be very different in practice due to correlations between votes. Walsh’s empirical study was limited to the simple veto rule, weighted votes and elections with only three candidates. In this paper, we relax these assumptions and consider the more complex multi-round STV rule, unweighted votes, and large numbers of candidates. Our experiments suggest that we should treat worst-case results about the complexity of manipulating voting rules like STV with some care. It was easy for a single agent to manipulate almost every election in our experiments or to prove that manipulation by a single agent was impossible. In the millions of elections studied, we computed a ar X iv :0 91 1. 37 08 v1 [ cs .A I] 1 9 ","The computational difficulty of manipulating an election | Single transferable vote resists strategic voting | Nonexistence of voting rules that are usually hard to manipulate | Junta distributions and the average-case complexity of manipulating elections | Generalized scoring rules and the frequency of coalitional manipulability | Elections can be manipulated often | A sufficient condition for voting rules to be frequently manipulable | Where are the really hard manipulation problems? The phase transition in manipulating the veto rule | When are elections with few candidates hard to manipulate | On the complexity of manipulating elections | Computational Aspects of Preference Aggregation | Where the really hard problems are | Hard and Easy Distributions of SAT Problems | The SAT phase transition | Scaling effects in the CSP phase transition | Random constraint satisfaction: Flaws and structure | Phase transitions and annealed theories: Number partitioning as a case study | Analysis of heuristics for number partitioning | Search in a small world | Search on high degree graphs | The TSP phase transition | Threshold phenomena in random graph colouring and satisfiability | From P to NP: COL, XOR, NAE, 1-in-k, and Horn SAT | Paradox of voting under an urn model: the effect of homogeneity | Phase transitions from real computational problems | Morphing: Combining structure and randomness | An actual application of collective choice theory to the selection of trajectories for the mariner jupiter/saturn 1977 project | An approach to empirical studies of voting paradoxes: An update and extension | Average-case tractability of manipulation in voting via the fraction of manipulators | Complexity of unweighted coalitional manipulation under some common voting rules",rejected,000
0911.5043.pdf.json,A Semantic Similarity Measure for Expressive Description Logics,"Ontological knowledge plays a key role for interoperability in the Semantic Web perspective. Nowadays, standard ontology markup languages are supported by well-founded semantics of Description Logics (DLs) together with a series of available automated reasoning services [1]. However, several tasks in an ontology life-cycle [2], such as their construction and/or integration, are still almost entirely delegated to knowledge engineers. In the Semantic Web perspective, the construction of the knowledge bases should be supported by automated inductive inference services. The induction of structural knowledge like the T-box taxonomies is not new in machine learning, especially in the context of concept formation [3] where clusters of similar objects are aggregated in hierarchies according to heuristic criteria or similarity measures. Almost all of these methods apply to zero-order representations while, as mentioned above, ontologies are expressed through fragments of first-order logic. Yet, the problem of the induction of structural knowledge turns out to be hard in first-order logic or equivalent representations [4]. In Inductive Logic Programming (ILP) attempts have been made to extend relational learning techniques towards hybrid representations based on both clausal and description logics [5, 6, 7]. In order to cope with the problem complexity, these methods are based on a heuristic search and generally implement bottom-up algorithms that tend to induce overly specific concept definitions which may suffer for poor predictive capabilities. So far, the automated induction of knowledge bases expressed in DLs representations has not been investigated in depth. Classic approaches to learning DL concept definitions generally adopt heuristic search strategies to cope with the inherent complexity of the problem and generally implement bottom-up algorithms (e.g. [8]). Other approaches propose a top-down search for correct concept definitions [9]. These methods are not complet",eds.: The Description Logic Handbook | Concept formation in structured domains | Learning conjuntive concepts in structural domains | AL-log: Integrating Datalog and description logics | Towards learning in CARIN-ALN | Learnability of description logic programs | A polynomial approach to the constructive induction of structural knowledge | A refinement operator for description logics | Attributive concept descriptions with complements | Information retrieval based on conceptual distance in is-a hierarchies | Experiments on using semantic distances between words in image caption retrieval | Semantic symilarity based on corpus statistic and lexical taxonomy | Ontoseek: Content-based access to the web | Resource integration using a large knowledge base in carnot | Knowledge based integration of heterogeneous databases | Automated resolution of semantic heterogeneity in multidatabases | Semantic aspects of interoperable GIS | Features od similarity | Semantic similarity in a taxonomy: An information-based measure and its application to problems of ambiguity in natural language | Comparing concepts in differentiated ontologies | Determining semantic similarity among entity classes from different ontologies | Commonality-based ABox retrieval. Technical Report FBI-HH-M- 291/2000 | Symbolic Logic and Mechanical Theorem Proving | An information-theroretic defintion of similarity | Analysis of Symbolic Data: Exploratory Methods for Extracting Statistical Information from Complex Data,rejected,000
0911.5394.pdf.json,Covering rough sets based on neighborhoods,"Rough set theory, proposed by Pawlak in the early 1980s [11, 12], is a new mathematical tool to deal with vague concepts. Since then we have witnessed a systematic, world-wide growth of interest in rough set theory [1, 7, 13, 16, 26, 27, 28, 33, 34, 35, 37] and its applications [6, 14, 15, 29, 36, 39]. Nowadays, it turns out that this approach is of fundamental importance to artificial intelligence and cognitive sciences, especially in the areas of data mining, machine learning, decision analysis, knowledge management, expert systems, and pattern recognition. Rough set theory bears on the assumption that some elements of a universe may be indiscernible in view of the available information about the elements. Thus, the indiscernibility relation is the starting point of rough set theory. Such a relation was first described by equivalence relation in the way that two elements are related by the relation if and only if they are indiscernible from each other. In this framework, a rough set is a formal approximation of a subset of the universe in terms of a pair of unions of equivalence classes which give the lower and upper approximations of the subset. However, the requirement of equivalence relation as the indiscernibility relation is too restrictive for many applications. In other words, many practical data sets cannot be handled well by classical rough sets. In light of this, equivalence relation has been generalized to similarity relation [20], tolerance relation [3, 4, 10, 18], and even arbitrary binary relation [5, 9, 24, 25, 26, 32] in some extensions of the classical rough sets. Another approach is the relaxation of the partition arising from equivalence relation to a cover. The cover of a universe is used to construct the lower and upper approximations of any subset of the universe [1, 2, 16, 27, 35]. In the literature, several different types of covering-based rough sets have been proposed and investigated; see, for example, [17, 23, 31, 34, 37] and the biblio","Extensions and intentions in the rough set theory | A calculus of rough sets of the first order | Abstract approximation spaces for rough theory | Algebraic structures for rough sets | On the structure of generalized rough sets | N | The axiomatization of the rough set upper approximation operations | A comparison of two types of rough sets induced by coverings | The algebraic structures of generalized rough set theory | A fast approach to attribute reduction in incomplete decision systems with tolerance relation-based rough sets | Rough sets | Rough Sets: Theoretical Aspects of Reasoning about Data | Rudiments of rough sets | A | A | Approximation operations in approximation space | On covering rough sets | Tolerance approximation spaces | The on-line encyclopedia of integer sequences | A generalized definition of rough approximations based on similarity | Approximations and reducts with covering generalized rough sets | Topology theory on rough sets | Measuring roughness of generalized rough sets induced by a covering | Relational interpretations of neighborhood operators and rough set approximation operators | On generalizing pawlak approximation operators | Constructive and algebraic methods of theory of rough sets | Approximations in the space (u | Two new operators in rough set theory with applications to fuzzy sets | Peculiarity oriented multidatabase mining | On covering generalized rough sets | Topological approaches to covering rough sets | Generalized rough sets based on relations | Relationship between generalized rough sets based on binary relation and covering | Relationship among basic concepts in covering-based rough sets | Reduction and axiomization of covering generalized rough sets | Covering based granular computing for conflict analysis | On three types of covering rough sets | Topological properties in covering-based rough sets | Rough Sets, Fuzzy Sets, and Knowledge Discovery",rejected,000
0911.5395.pdf.json,An axiomatic approach to the roughness measure of rough sets,"Rough set theory was proposed by Pawlak in the early 1980s [22, 23] as a new mathematical approach for dealing with inexact, uncertain or vague knowledge in information systems. Since then we have witnessed a systematic, world-wide growth of interest in rough set theory [4, 20, 25, 28, 37, 43, 44, 48, 49, 50, 52]. Nowadays, it is widely recognized that rough set applications have a great importance in several fields, such as granular computing, data mining, and approximate reasoning [19, 26, 27, 46, 51, 53]. A basic hypothesis in rough set theory is that some elements of a universe may be indiscernible in view of the available information about the elements. Such an indiscernibility relation was first described by equivalence relation in the way that two elements are related by the relation if and only if they are indiscernible from each other [22, 23]. In this framework, a rough set is a formal approximation of a subset of the universe in terms of a pair of unions of equivalence classes which give the lower and upper approximations of the subset. In order to measure numerically the accuracy of an approximation, Pawlak introduced two quantitative measures of accuracy and roughness in [23]: The accuracy of a subset is defined as the ratio of the cardinalities of the lower and upper approximations of the subset, which is bounded by 0 and 1; the roughness of a subset is calculated by subtracting the accuracy of the subset from 1. Therefore, roughness is a complementary concept to the accuracy of approximation. The roughness is, in some sense, the amount of uncertainty of the underlying subset. A roughness of 1 shows that we have no certain knowledge on the underlying subset, and a roughness of 0 means we know everything for sure about the underlying subset. From this point of view, the roughness measure is an important indicator of the uncertainty and accuracy associated with a given subset. It has been observed [2, 17, 35] that the roughness (and its dual, accuracy) d","Rough set algorithms in classification problem. Rough Set Methods and Applications: New Developments in Knowledge Discovery in Information Systems, Studies in Fuzziness and Soft Computing 56 | Information-theoretic measures of uncertainty for rough sets and rough relational databases | Entropies and co-entropies of coverings with application to incomplete information systems | Extensions and intentions in the rough set theory | Introductory Combinatorics, 4th Edition | A calculus of rough sets of the first order | Attribute selection with fuzzy decision reducts | Rough fuzzy sets and fuzzy rough sets | Uncertainty measures of rough set prediction | Roughian: Rough information analysis | A rough sets approach for personalized support of face recognition | Fuzzy Sets, Uncertainty, and Information | On a criterion of similarity between partitions based on rough set theory | An information-theoretic analysis of relational databases–Part I: Data dependencies and information metric | Information entropy, rough entropy and knowledge granulation in incomplete information systems | The information entropy, rough entropy and knowledge granulation in rough set theory | A new measure of uncertainty based on knowledge granulation for rough sets | Uncertainty measure of randomness of knowledge and rough sets in incomplete information systems | The axiomatization of the rough set upper approximation operations | The calculation of knowledge granulation and its application (in Chinese) | Rough Sets: Theoretical Aspects of Reasoning about Data | Rough sets and boolean reasoning | Rough Sets and Current Trends in Computing | Rough Sets in Knowledge Discovery. Vol. 1 and 2 | Approximation operations in approximation space | Combination entropy and combination granulation in rough set theory | An Introduction to Information Theory. Dover Publications, New York, originally published by Mc Graw-Hill | The lower system, the upper system and rules with stability factor in non-deterministic information systems | Various approaches to reasoning with frequency based decision reducts: a survey | Uncertainty measure of rough sets based on a knowledge granulation for incomplete information systems | Measuring uncertainty in rough set theory | An improved accuracy measure for rough sets | Partition measures for data mining. Advances in Machine Learning I: Dedicated to the Memory of Professor | Constructive and algebraic methods of theory of rough sets | Information-theoretic measures for knowledge discovery and data mining. in: Karmeshu (Ed.), Entropy Measures | Probabilistic approaches to rough sets | A partition model of granular computing | A First Course in Information Theory. Information Technology: Transmission, Processing, and Storage | Approximations in the space (u, π) | Two new operators in rough set theory with applications to fuzzy sets | Data analysis based on discernibility and indiscernibility | Peculiarity oriented multidatabase mining | An improved axiomatic definition of information granulation | Relationship among basic concepts in covering-based rough sets | Relationship between generalized rough sets based on binary relation and covering | Reduction and axiomization of covering generalized rough sets | Covering based granular computing for conflict analysis | On three types of covering rough sets | Rough Sets, Fuzzy Sets, and Knowledge Discovery",rejected,000
0911.5548.pdf.json,A Decision-Optimization Approach to Quantum Mechanics and Game Theory,,Cooperative optimization for solving large scale combinatorial problems | 100 years of quantum mysteries | Do deeper principles underlie quantum uncertainty and nonlocality? | Equilibrium points in n-player games,rejected,000
0911.5568.pdf.json,Acquisition d’informations lexicales à partir de corpus,"L’existence de gros corpus (plusieurs millions de mots) et d’analyseurs syntaxiques performants fait qu’il est actuellement possible d’extraire automatiquement des connaissances à large couverture sur les mots et les constructions associées, directement à partir de corpus. Cette démarche permet d’obtenir des lexiques très complets à moindre coût, avec également des informations sur la fréquence et la productivité de différentes constructions, c’est-à-dire des données difficilement calculables à la main. Depuis une quinzaine d’années, plusieurs systèmes ont ainsi été conçus afin d’extraire automatiquement des informations sur la construction de mots essentiels du lexique, en général les verbes. On peut citer les travaux de (Brent (1993), Manning (1993), Briscoe and Carroll (1997), Korhonen (2002), Schulte im Walde (2002) parmi de nombreux autres. Nous avons nous-mêmes réalisé un système du même type pour le français, avec une première expérience qui s’appuie sur le corpus Le Monde (200 millions de mots, 1990–1999) et sur l’analyseur Syntex (Bourigault, 2007) pour inférer des connaissances sur la souscatégorisation de plus de 3000 verbes (Messiant et Poibeau, 2008 ; Messiant 2008). Le processus se décompose en 3 grandes étapes : 1) on rassemble d’abord l’ensemble des occurrences du verbe considéré ainsi que tous ses compléments, 2) on fait ensuite l’inventaire de toutes les constructions possibles pour le verbe considéré et enfin, 3) les constructions les plus rares sont éliminées, à partir de l’hypothèse qu’un nombre trop faible d’occurrences est le révélateur d’une erreur d’analyse (simple rencontre de surface). Tous les systèmes reposent sur cette architecture, même s’ils varient quant à la finesse de l’analyse considérée ou des stratégies de filtrage utilisées. Quelques difficultés récurrentes des approches à base de corpus Malgré les avantages décrits, l’approche n’est pas sans inconvénient. Comme elle se fonde sur des outils automatiques qui ne sont pas parfaits","Les Grammaires de Propriétés : des contraintes pour le traitement automatique des langues naturelles | Un analyseur syntaxique opérationnel : SYNTEX. Mémoire d’Habilitation, Université de Toulouse-le-Mirail | From Grammar to Lexicon: Unsupervised Learning of Lexical Syntax | Automatic extraction of subcategorization from corpora | Cognitive linguistics. (Cambridge Textbooks in Linguistics.) | A synopsis of linguistic theory | Subcategorization Acquisition. PhD thesis publiée sous la réf | Automatic Acquisition of a Large Subcategorization Dictionary from Corpora | ASSCI: A Subcategorization Frames Acquisition System for French Verbs | LexSchem: A Large Subcategorization Lexicon for French Verbs | A Subcategorisation Lexicon for German Verbs induced from a Lexicalised PCFG | Constraint-based Grammar Formalisms",rejected,000
0912.0071.pdf.json,Differentially Private Support Vector Machines,"An emerging problem at the interface of statistics and machine learning, is how to learn from statistical databases that contain sensitive information. Statisticians for health insurance or credit-card companies, and epidemiologists studying disease risk, are faced with the task of performing data analysis on medical or financial records of private individuals. Machine learning algorithms applied to the data of many individuals can discover novel population-wide patterns but the results of such algorithms may reveal certain individuals’ sensitive information, thereby violating their privacy. This is a growing concern, due to the massive increase in personal information stored in electronic databases. Our goal is to provide learning algorithms whose outputs are provably guaranteed to preserve privacy. The support vector machine (SVM) algorithm is one of the most widely used machine learning algorithms in practice. In this paper we develop privacy-preserving 1 SVM algorithms for linear and nonlinear kernels. We also develop a method for privacy-preserving parameter-tuning for general machine learning algorithms. Our work is inspired by the approach of Chaudhuri and Monteleoni [Chaudhuri and Monteleoni, 2008]. They provide algorithms for regularized logistic regression that are privacy-preserving with respect to the ǫ-differential privacy model [Dwork et al., 2006], a strong, cryptographically-motivated definition of privacy that has recently received a significant amount of research attention for its robustness to known attacks. The privacy-preserving technique proposed by [Chaudhuri and Monteleoni, 2008], for machine learning algorithms involving convex optimization, is to solve a perturbed optimization problem. For the case of regularized logistic regression, they provide a differentially private algorithm, with learning performance guarantees. However, their analysis does not apply directly to the more widely used support vector machine algorithm. In this paper we ","Privacy-preserving data mining | Privacy, accuracy, and consistency too: a holistic solution to contingency table release | A learning theory approach to non-interactive database privacy | Privacy-preserving logistic regression | Differential privacy and robust statistics | Calibrating noise to sensitivity in private data analysis | Limiting privacy breaches in privacy preserving data mining | Composition attacks and auxiliary information in data privacy | The UCI KDD Archive | What can we learn privately | A correspondence between Bayesian estimation on stochastic processes and smoothing by splines | Cryptographically private support vector machines | l-diversity: Privacy beyond k-anonymity | Privacy: Theory meets practice on the map | Privacy-preserving classification of vertically partitioned data via random kernels | Mechanism design via differential privacy | Smooth sensitivity and sampling in private data analysis | Random features for large-scale kernel machines | Uniform approximation of functions with random bases | Weighted sums of random kitchen sinks : Replacing minimization with randomization in learning | SVM optimization : Inverse dependence on training set size | Fast rates for regularized objectives | Privacy-preserving support vector machine classification",rejected,000
0912.0132.pdf.json,Opportunistic Adaptation Knowledge Discovery,"Case-based reasoning (CBR [6]) is a reasoning paradigm based on the reuse of previous problem-solving experiences, called cases. A CBR system often has profit of a retrieval procedure, selecting in a case base a source case similar to the target problem, and an adaptation procedure, that adapts the retrieved source case to the specificity of the target problem. The adaptation procedure depends on domain-dependent adaptation knowledge (AK, in the following). Acquiring AK can be done from experts or by using machine learning techniques. An intermediate approach is knowledge discovery (KD) that combines efficient learning algorithms with human-machine interaction. Most of previousAK acquisition strategies are off-line: they are disconnected from the use of the CBR system. By contrast, recent work aims at integrating AK acquisition from experts to specific reasoning sessions: this opportunistic AK acquisition takes advantage of the problem-solving context. This paper presents an approach to AK discovery that is opportunistic: the KD is triggered at problem-solving time. The paper is organized as follows. Section 2 introduces some basic notions and notations about CBR. Section 3 presents the CBR system Taaable, which constitutes the application context of the study, and motivates the need for adaptation knowledge acquisition in this application context. Section 4 presents the proposed opportunistic and interactive AK discovery method. In Sect. 5, this method is applied to acquire adaptation knowledge in the context of the Taaable system. Section 6 discusses this approach and situates it among related work. Section 7 concludes and presents some future work.","Knowledge-Intensive Case-Based Reasoning in Creek | Representing Case Variations for Learning General and Spe- cific Adaptation Rules | Taaable: Text Mining, Ontology Engineering, and Hierarchical Classification for Textual Case-Based Cooking, in Computer Cooking Contest - Workshop at European Con- ference on Case-Based Reasoning (ECCBR’08), eds | Case Base Mining for Adaptation Knowledge Acquisition | Case-Based Reasoning: An Overview | Interactive and Opportunistic Knowledge Acquisition in Case-Based Reasoning | Opportunistic Ac- quisition of Adaptation Knowledge and Cases - The IakA Approach, in Proceedings of the 9th European Conference on Case-Based Reasoning (ECCBR’08) | LearningAdaptation Knowledge to ImproveCase- Based Reasoning | CHEF: A model of case-based planning | The Adaptation Knowledge Bottleneck: How to Unblock it By Learning | Acquiring Case Adaptation Knowledge: A Hybrid Approach | Reformulation in Case-Based Reasoning, in Fourth EuropeanWorkshop on Case-Based Reasoning, EWCBR-98, eds B",rejected,000
0912.0224.pdf.json,A Multi-stage Probabilistic Algorithm for Dynamic Path-Planning,,An On-the-fly Evolutionary Algorithm for Robot Motion Planning | An Evolutionary Navigator for Autonomous Agents on Unknown Large-Scale Environments | Real-time randomized path planning for robot navigation | Replanning with rrts | Gross motion planning—a survey | Probabilistic roadmaps for path planning in high-dimensional configuration spaces | Rrt-connect: An efficient approach to single-query path planning | Rapidly-exploring random trees: A new tool for path planning | An incremental learning approach to motion planning with roadmap management | Optimal and efficient path planning for partiallyknownenvironments | The Focussed Dˆ* Algorithm for Real-Time Replanning | Adaptive evolutionary planner/navigator for mobile robots | Multipartite rrts for rapid replanning in dynamic environments,rejected,000
0912.0266.pdf.json,Combining a Probabilistic Sampling Technique and Simple Heuristics to solve the Dynamic Path Planning Problem,"The dynamic path-planning problem consists in finding a suitable plan for each new configuration of the environment by recomputing a collision free path using the new information available at each time step [5]. This kind of problem can be found for example by a robot trying to navigate through an area crowded with people, such as a shopping mall or supermarket. The problem has been addressed widely in its several flavors, such as cellular decomposition of the configuration space [12], partial environmental knowledge [11], high-dimensional configuration spaces [6] or planning with non-holonomic constraints [8]. However, simpler variations of this problem are complex enough that cannot be solved with deterministic techniques, and therefore they are worthy to study. This paper is focused on finding and traversing a collision-free path in two dimensional space, for a holonomic robot 1, without kinodynamic restrictions 2, in two different scenarios: • Dynamic environment: several unpredictably moving obstacles or adversaries. • Partially known environment: some obstacles only become visible when approached by the robot. Besides from one (or few) new obstacle(s) in the second scenario we assume that we have perfect information of the environment at all times. We will focus on continuous space algorithms and won’t consider algorithms that use discretized representations of the configuration space, such as D* [12], because for high dimensional problems, the configuration space becomes intractable in terms of both memory and computation time, and there is the extra difficulty of calculating the discretization size, trading off accuracy versus computational cost. The offline RRT is efficient at finding solutions but they are far from being optimal, and must be postprocessed for shortening, smoothing or other qualities 1. A holonomic robot is a robot in which the controllable degrees of freedom is equal to the total degrees of freedom. 2. Kinodynamic planning is a problem in ",An On-the-fly Evolutionary Algorithm for Robot Motion Planning | An Evolutionary Navigator for Autonomous Agents on Unknown Large-Scale Environments | Real-time randomized path planning for robot navigation | Replanning with rrts | Gross motion planning—a survey | Probabilistic roadmaps for path planning in highdimensional configuration spaces | Rrt-connect: An efficient approach to single-query path planning | Rapidly-exploring random trees: A new tool for path planning | An incremental learning approach to motion planning with roadmap management | Optimal and efficient path planning for partially-knownenvironments | The Focussed Dˆ* Algorithm for Real- Time Replanning | Adaptive evolutionary planner/navigator for mobile robots | Multipartite rrts for rapid replanning in dynamic environments,rejected,000
0912.0270.pdf.json,,1.1 Problem Formulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 1.2 Document Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3,"Efficient nearest neighbor searching for motion planning | Un algoritmo evolutivo para la resolución del problema de planificación de rutas de un robot móvil | An on-the-fly evolutionary algorithm for robot motion planning | An evolutionary navigator for autonomous agents on unknown large-scale environments | Combining a probabilistic sampling technique and simple heuristics to solve the dynamic path planning problem | Multidimensional binary search trees used for associative searching | Real-time randomized path planning for robot navigation | Genetic algorithm for dynamic path planning | Replanning with RRTs | Gross motion planning — a survey | RRT-connect: An efficient approach to single-query path planning | Probabilistic roadmaps for path planning in high-dimensional configuration spaces | Rapidly-Exploring Random Trees: A new tool for path planning | Randomized kinodynamic planning | An incremental learning approach to motion planning with roadmap management | Offline and online evolutionary bi-directional RRT algorithms for efficient re-planning in dynamic environments | Path planning for a mobile robot using genetic algorithms | Evolutionary algorithm based offline/online path planner for UAV navigation | Optimal and efficient path planning for partially-known environments | The focussed D* algorithm for real-time replanning | Adding memory to the Evolutionary Planner/Navigator | Handbook of Evolutionary Computation, chapter G3.6 The Evolutionary Planner/Navigator in a Mobile Robot Environment | Evolutionary Planner/Navigator: Operator performance and self-tuning | Adaptive Evolutionary Planner/Navigator for mobile robots | Multipartite RRTs for rapid replanning in dynamic environments | An efficient retraction-based RRT planner",rejected,000
0912.2282.pdf.json,Design of Intelligent layer for flexible querying in databases,,"Fundamentals of Database Systems | System R: Relational Approach to Database Management | Zarri, “Intelligent database | Intelligent databases-object-oriented,  deductive hypermedia technologies | Petrographer: Managing peterographic data and knowledge using an intelligent database application | Future Intelligent Information Systems: AI and Database Technologies Working Together | The Intelligent Database Interface: Integrating AI and Database systems | Intelligent Information Processing"", Series: IFIP International Federation for Information | CD-Trees: An ISSN | Flexible Querying in an Intelligent Object- Oriented Database Environment | Towards a logical multidimensional model for spatial data warehousing and OLAP | Ontologies and reasoning techniques for (legal) intelligent information retrieval systems | Fuzzy XML data modeling with the UML and relational data models | Towards an intelligent database system founded on the SP theory of computing and cognition | Medical diagnosis as pattern recognition in a framework of information compression by multiple alignment”, unification and search, Decision Support Systems, vol.42 | Integrity Checking and Maintenance in Relational and Deductive Databases - and Beyond"", in the book Intelligent Databases: Technologies and Applications, chapter X | Getting Rid of Straitjackets for Flexible Integrity Checking | Integrity Constraints Checking In Deductive Databases | Integrity Checking and Maintenance with Active Rules in XML Databases | Fuzzy Queries in Romanian Language: An Intelligent Interface,"" The Annals of”DUNAREA DE JOS | Applications of SQL for Informetric Data Processing | A fuzzy Petri net model for intelligent databases | EDUCE a Marriage of Convenience: Prolog and a Relational DBMS | Interfacing Predicate Logic Languages and Relational Databases | DEDUCE 2: Further investigations of deduction in relational databases | PROSQL: A Prolog Programming Interface with SQL/DS | A new incremental data mining algorithm using pre-large itemsets | Application of Decision Tree as a Data mining Tool in a Manufacturing System | An improved algorithm for mining association roles using multiple support values | Efficient automatic discovery of 'hot' itemsets"", Information Processing Letters, Volume 90, Issue 2, Pages: 65",rejected,000
0912.2415.pdf.json,Adapting Heuristic Mastermind Strategies to Evolutionary Algorithms,"Mastermind in its current version is a board game that was introduced by the telecommunications expert Mordecai Merowitz [15] and sold to the company Invicta Plastics, who renamed it to its actual name; in fact, Mastermind is a version of a traditional puzzle called bulls and cows that dates back to the Middle Ages. In any case, Mastermind is a puzzle (rather than a game) in which two persons, the codemaker and codebreaker try to outsmart each other in the following way: • The codemaker sets a length ℓ combination of κ symbols. In the classical version, ℓ= 4 and κ = 6, and color pegs are used as symbols over a board with rows of ℓ = 4 holes; however, in this paper we will use uppercase letters starting with A instead of colours. ∗University of Iceland, email tpr@hi.is †Department of Architecture and Computer Technology, ETSIIT, University of Granada, Spain, email jmerelo@geneura.ugr.es • The codebreaker then tries to guess this secret code by producing a combination. • The codemaker gives a response consisting on the number of symbols guessed in the right position (usually represented as black pegs) and the number of symbols in an incorrect position(usually represented as white pegs). • The codebreaker then, using that information as a hint, produces a new combination until the secret code is found. For instance, a game could go like this: The codemaker sets the secret code ABBC. The rest of the game is shown in Table 1. Different variations of the game include giving information on which position has been guessed correctly, avoiding repeated symbols in the secret combination (bulls and cows is actually this way), or allowing the codemaker to change the code during the game (but only if this does not make responses made so far false). In any case, the codebreaker is allowed to make a maximum number of combinations (usually fifteen, or more for larger values of κ and ℓ), and score corresponds to the number of combinations needed to find the secret code; after repeati","Efficient solutions for Mastermind using genetic algorithms | Solving mastermind using GAs and simulated annealing: a case of dynamic constraint optimization | Mastermind, a game of diagnosis strategies. Bulletin of the Faculty of Engineering, Alexandria | Towards an optimum mastermind strategy | A survey of NPcomplete puzzles | The computer as Master Mind | An optimal Mastermind strategy | Finding a needle in a haystack using hints and evolutionary computation: the case of genetic mastermind. In: A.S.W. Scott Brave (ed.) Late breaking papers at the GECCO99 | Finding a needle in a haystack using hints and evolutionary computation: the case of evolutionary MasterMind | Algorithm::Evolutionary, a flexible Perl module for evolutionary computation | From recombination of genes to the estimation of distributions: I. binary parameters | Some strategies for mastermind | Mastermind is np-complete",rejected,000
0912.3309.pdf.json,New Generalization Bounds for Learning Kernels,"Kernel methods are widely used in statistical learning [17, 18]. Positive definite symmetric (PDS) kernels specify an inner product in an implicit Hilbert space where large-margin methods are used for learning and estimation. They can be combined with algorithms such as support vector machines (SVMs) [5, 10, 20] or other kernel-based algorithms to form powerful learning techniques. But, the choice of the kernel, which is critical to the success of the algorithm, is typically left to the user. Rather than requesting the user to commit to a specific kernel, which may not be optimal for the task, especially if the user’s prior knowledge about the task is poor, learning kernel methods require him only to specify a family of kernels. The learning algorithm then selects both the specific kernel out of that family, and the hypothesis defined with respect to that kernel. There is a large body of literature dealing with various aspects of the problem of learning kernels, including theoretical questions, optimization problems related to this problem, and experimental results [13, 15, 2, 1, 19, 16, 14, 23, 11, 3, 8, 22, 9]. Some of this previous work considers families of Gaussian kernels [15] or hyperkernels [16]. Non-linear combinations of kernels have been recently considered by [21, 3, 9]. But, the most common family of kernels examined is that of non-negative combinations of some fixed kernels constrained by a trace condition, which can be viewed as an L1 regularization [13], or by an L2 regularization [8]. This paper presents several novel generalization bounds for the problem of learning kernels for the family of convex combinations of base kernels or linear combinations with an L2 constraint. One of the first learning bounds given by Lanckriet et al. [13] for the family of convex combinations of p base kernels is similar to that of Bousquet and Herrmann [6] and has the following form: R(h) ≤ R̂ρ(h) + O ( 1√ m √ maxpk=1 Tr(Kk)max p i=1(‖Kk‖/Tr(Kk))/ρ2 ) where R(h) is th",A DC-programming algorithm for kernel selection | Learning convex combinations of continuously parameterized basic kernels | Exploring large feature spaces with hierarchical multiple kernel learning | Rademacher and Gaussian complexities: Risk bounds and structural results | A training algorithm for optimal margin classifiers | On the complexity of learning the kernel matrix | Invited talk: Can learning kernels help performance | L2 regularization for learning kernels | Learning non-linear combinations of kernels | Multi-task feature and kernel selection for SVMs | Rademacher processes and bounding the risk of function learning | Learning the kernel matrix with semidefinite programming | Nonstationary kernel combination | Learning the kernel function via regularization | Learning the kernel with hyperkernels | Learning with Kernels | Kernel Methods for Pattern Analysis | Learning bounds for support vector machines with learned kernels | Statistical Learning Theory | More generality in efficient multiple kernel learning | Generalization bounds for learning the kernel problem | Multiclass multiple kernel learning,rejected,000
0912.5511.pdf.json,,"Answer set programming (ASP) [Gelfond and Lifschitz 1988; Baral 2003] has emerged as a major area of research in knowledge representation and reasoning (KRR). On the one hand, ASP has an elegant and conceptually simple theoretical foundation, while on the other hand efficient implementations of ASP solvers exist which have been finding applications to practical problems. However, as is the case with any large program or body of knowledge, a logic program is not a static object in general, but rather it will evolve and be subject to change, whether as a result of correcting information in the program, adding to the information already present, or in some other fashion modifying the knowledge represented in the program. Since knowledge is continually evolving and subject to change, there is a need to be able to revise logic programs as new information is received. In KRR, the area of belief revision [Alchourrón et al. 1985; Gärdenfors 1988] addresses just such change to a knowledge base. In AGM belief revision (named after the aforecited developers of the approach) one has a knowledge baseK and a formulaα, and the issue is how to consistently incorporateα inK to obtain a new knowledge base K ′. The interesting case is whenK ∪ {α} is inconsistent, since beliefs have to be dropped from K before α can be consistently added. Hence, a fundamental issue concerns how such change should be managed. In classical propositional logic, specific belief revision operators have been proposed based on the distance between models of a knowledge base and a formula for revision. That is, a characterisation of the revision of a knowledge base K by formula α is to set the models of the revised knowledge base K ′ to be the models of α that are “closest” to those of K . Of course the notion of “closest” needs to be pinned down, but natural definitions based on the Hamming distance [Dalal 1988] and set containment with regards to propositional letters [Satoh 1988] are well known. In additi",,rejected,000
0912.5533.pdf.json,Oriented Straight Line Segment Algebra: Qualitative Spatial Reasoning about Oriented Objects,"Qualitative Reasoning about space abstracts from the physical world and enables computers to make predictions about spatial relations, even when precise quantitative information is not available [1]. A qualitative representation provides mechanisms which characterize the essential properties of objects or configurations. In contrast, a quantitative representation establishes a measure in relation to a unit of measurement which must be generally available [2]. The constant and general availability of common measures is now self-evident. However, one needs only recall the history of length measurement technologies to see that the more local relative measures, which are represented qualitatively1, can be managed by biological/epigenetic cognitive systems much more easily than absolute quantitative representations. Qualitative spatial calculi usually deal with elementary objects (e.g. positions, directions, regions) and qualitative relations between them (e.g. ”adjacent”, ”to the left of”, ”included in”). This is the reason why qualitative descriptions are quite natural for people. The two main trends in Qualitative Spatial Reasoning (QSR) are topological reasoning about regions [3, 4, 5, 6, 7] and positional (e.g. direction and distance) reasoning about point configurations [8, 9, 10, 11, 12, 13, 14]. Positions can refer to a global reference system, e.g. cardinal directions, or just to local reference systems, e.g. egocentric views. Positional calculi can be related to the results of Psycholinguistic research [15] in the field of reference systems. In Psycholinguistics, local reference systems are divided into two modalities: intrinsic reference systems and extrinsic reference systems. Then, the three resulting options for giving a linguistic description of the spatial arrangements of objects are: intrinsic, extrinsic, and absolute (i.e. global) reference systems [16]2. Corresponding QSR calculi can be found in Psycholinguistics for all three types of reference system",,rejected,000
1001.0054.pdf.json,Cryptographic Implications for Artificially Mediated Games,,Bridging Game Theory and Cryptography: Recent Results and Future Directions. | Game Theory and Cryptography. | A Cryptographic Solution to a Game Theoretic Problem. | Non-Cooperative Games. | A Simple Adaptive Procedure Leading To Correlated Equilibrium. | Correlated Equilibrium as an Expression of Bayesian Rationality.,rejected,000
1001.0820.pdf.json,,"Answer Set Programming (ASP) is a methodology commonly used for solving combinatorial search problems (Lifschitz 2008). In the development of ASP solvers, computational ideas behind SAT solvers (Gomes et al. 2008) play an important role. Influence of SAT solvers development on ASP systems is twofold. On the one hand, such ASP solvers as assat1 and cmodels2 follow the so called SAT-based approach where a SAT solver is invoked for search, possibly multiple times. On the other hand, “native” ASP solvers that implement search procedures specifically suited for logic programs often adopt computational techniques from SAT solvers. For instance, dlv3 implements backjumping (Ricca et al. 2006), and smodelscc 4 (Ward and Schlipf 2004) extends the answer set solver smodels5 by introducing restarts, conflict-driven 1 http://assat.cs.ust.hk/ . 2 http://www.cs.utexas.edu/users/tag/cmodels . 3 http://www.dbai.tuwien.ac.at/proj/dlv/ . 4 http://www.nku.edu/∼wardj1/Research/smodels cc.html . 5 http://www.tcs.hut.fi/Software/smodels/ . backjumping, learning, and forgetting – techniques widely used in SAT solvers. The ASP solver sup6 (Lierler 2008) implements these features also. In this paper our main goal is to show how the “abstract” approach to describing SAT solvers proposed in (Nieuwenhuis et al. 2006) can be extended to ASP solvers that use these sophisticated features. Usually computation procedures are described in terms of pseudocode. In (Nieuwenhuis et al. 2006), the authors proposed an alternative approach to describing dpll-like procedures. They introduced an abstract framework that captures what ”states of computation” are, and what transitions between states are allowed. In this way, it defines a directed graph such that every execution of the dpll procedure corresponds to a path in this graph. Some edges may correspond to unit propagation steps, some to branching, some to backtracking. This allows the authors to model a dpll-like algorithm by a mathematically simple an","Negation as failure | A machine program for theorem proving | An extensible sat-solver | Consistency of Clark’s completion and existence of stable models | Conflict-driven answer set solving | Tableau calculi for answer set programming | The stable model semantics for logic programming | Answer set programming based on propositional satisfiability | On the relation between answer set and SAT procedures (or, between smodels and cmodels) | Satisfiability solvers | A model-theoretic counterpart of loop formulas | Abstract answer set solvers | What is answer set programming? In Proceedings of the AAAI Conference on Artificial Intelligence | ASSAT: Computing answer sets of a logic program by SAT solvers | ASSAT: Computing answer sets of a logic program by SAT solvers | Fast SAT-based answer set solver | Conflict analysis in search algorithms for propositional satisfiability | A SAT solver primer | Solving SAT and SAT modulo theories: From an abstract Davis-Putnam-Logemann-Loveland procedure to DPLL(T) | A backjumping technique for disjunctive logic programming | Stable models and non-determinism in logic programs with negation | Extending and implementing the stable model semantics | The well-founded semantics for general logic programs | Answer set programming with clause learning | Answer set programming with clause learning | Efficient conflict driven learning in a boolean satisfiability solver",rejected,000
1001.0827.pdf.json,,"The XML Mining track consists of two tasks, classification and clustering. Classification labels documents in known categories. Clustering groups similar documents without any knowledge of categories. The corpus consisted of 114,366 documents and 636,187 document-to-document links. It is a subset of the XML Wikipedia corpus [1]. Submissions were made for both tasks using several techniques. We introduce K-tree in the Information Retrieval context. K-tree is a tree structured clustering algorithm introduced by Geva [2] in the context of signal processing. It is particularly suitable for large collections due to its low complexity. Non-negative Matrix Factorization (NMF) was also used to solve the clustering task. Applying NMF to document clustering was first described by Xu et. al. at SIGIR 2003 [3]. Negentropy has been used to measure clustering performance using the labels provided for documents. Entropy has been used by many researchers [4–6] to measure clustering results. Negentropy differs slightly but is fundamentally measuring the same system property. The classification task was solved using a multi-class Support Vector Machine (SVM). Similar approaches have been taken by Joachims [7] and Tong and Koller [8]. We introduce a representation for links named Link Frequency Inverse Document Frequency (LF-IDF) and make several extensions to it. Sections 2, 3, 4, 5, 6 and 7 discuss document representation, classification, cluster quality, K-tree, NMF and clustering respectively. The paper ends with a discussion of future research and a conclusion in Sects. 8 and 9.","The Wikipedia XML Corpus | K-tree: a height balanced tree structured vector quantizer | Document clustering based on non-negative matrix factorization | A hybrid unsupervised approach for document clustering | Ontologies improve text document clustering | A comparison of document clustering techniques | Text categorization with Support Vector Machines: Learning with many relevant features | Support vector machine active learning with applications to text classification | Extended boolean information retrieval | Simple, proven approaches to text retrieval | An algorithm for suffix stripping | Large Margin Methods for Structured and Interdependent Output Variables | Authoritative sources in a hyperlinked environment | The mathematical theory of communication | k-means++: the advantages of careful seeding | Projected Gradient Methods for Nonnegative Matrix Factorization",rejected,000
1001.0830.pdf.json,K-tree: Large Scale Document Clustering,,"The Wikipedia XML Corpus | K-tree: a height balanced tree structured vector quantizer | CLUTO-A Clustering Toolkit | Delft(Netherlands). Dept. of Mathematics Technische Hogeschool, and Informatics. Clustering by means of medoids | BIRCH: A New Data Clustering Algorithm and Its Applications",rejected,000
1001.0833.pdf.json,,"The purpose of this paper is to present and analyse the combination of Random Indexing (RI) with the K-tree algorithm. Both RI and K-tree adapt to changing data and decrease the cost of computationally intensive vector based applications. This combination is particularly suitable to the representation and clustering of very large document collections. Documents are typically represented in vector space as very sparse high dimensional vectors. RI can reduce the dimensionality and sparsity of this representation. In turn, the condensed representation is highly effective when working with K-tree. The paper is focused on determining the effectiveness of using RI with K-tree through experiments and comparative analysis of results. Sections 2 to 6 discuss K-tree, Random Indexing, Document Representation, Experimental Setup and Experimental results respectively. The paper ends with a conclusion in Section 7.",Database-friendly random projections: Johnson-Lindenstrauss with binary coins | k-means++: the advantages of careful seeding | Random projection in dimensionality reduction: applications to image and text data | Document clustering with k-tree | K-tree: large scale document clustering | Indexing by latent semantic analysis | The Wikipedia XML Corpus | Vector quantization and signal compression | K-tree: a height balanced tree structured vector quantizer | Extensions of Lipschitz mappings into a Hilbert space | The spatter code for encoding concepts at many levels | CLUTO-A Clustering Toolkit | Least squares quantization in pcm | Distributed representations and nested compositional structure | An algorithm for suffix stripping | Simple | An introduction to random indexing | Human behavior and the principle of least effort: An introduction to human ecology,rejected,000
1001.0921.pdf.json,Graph Quantization,"Vector quantization is a classical technique from signal processing suitable for lossy data compression, density estimation, and prototype-based clustering [7, 14, 30]. The problem of optimal vector quantizer design is to find a codebook consisting of a finite set of prototypes such that an expected distortion with respect to some (differentiable) distortion measure is minimized. Since the probability distribution of the input patterns is usually unknown, vector quantizer design techniques use empirical data. Extensively studied design techniques are, for example, k-means and simple competitive learning. The kmeans algorithm is also commonly referred to as the Linde-Buzo-Gray (LBG) algorithm [24] the generalized Lloyd algorithm [25]. This algorithm is a local optimizer of the empirical sum-of-squared-error distortion without any global optimal or consistency guarantees. In contrast to k-means, competitive learning directly minimizes the expected distortion and is a consistent learner under very general conditions in the sense that it almost surely converges to a local optimal solution of the expected distortion. One limitation of VQ is its restriction to patterns that are represented by vectors. For patterns that are more naturally represented by finite combinatorial structures, the theoretical framework of VQ as well its design techniques are no longer applicable. Examples of such structures include, for example, point patterns, strings, trees, and graphs arising from diverse application areas like proteomics, chemoinformatics, and computer vision. To overcome this limitation, we generalize vector quantization to quantization of graphs. A number of graph quantizer design techniques for the purpose of ar X iv :1 00 1. 09 21 v1 [ cs .A I] 6 J an 2 01 0 prototype-based clustering have already been proposed. Examples include competitive learning algorithms in the domain of graphs [16–20, 22] and k-means as well as k-medoids algorithms [12, 13, 19, 20, 23, 28, 29]. Rela","Duffuaa, ""A linear programming approach for the weighted graph matching problem | Messmer, ""Similarity measures for structured representations | Graph clustering using the weighted minimum common supergraph"" Graph Based Representations in Pattern Recognition, Lecture | Riemannian geometry of orbifolds | Learning graph matching | Balanced graph matching | Norkin, ""Normalized convergence in stochastic optimization | The minimization of discontinuous functions: mollifier subgradients | Norkin, ""On nonsmooth and discontinuous problems of stochastic systems optimization | Norkin, ""Stochastic generalized gradient method for nonconvex nonsmooth stochastic optimization | Theory and algorithms on the median graph. application to graph-based classification and clustering | Graph-Based kMeans Clustering: A Comparison of the Set Median versus the Generalized Median Graph | Vector Quantization and Signal Compression | Graduated Assignment Algorithm for Graph Matching | Learning with preknowledge: clustering with point and graph matching distance measures | Self-organizing map for clustering in the graph domain | ÒA Self-Organizing Map for Adaptive Processing of Structured Data,Ó | Central Clustering of Attributed Graphs | On the sample mean of graphs | Structure Spaces | Accelerating Competitive Learning Graph Quantization | Elkan’s k-Means for Graphs | ÒLeast squares quantization in PCMÓ | ACM attributed graph clustering for learning classes of images | Stochastic generalized-differentiable functions in the problem of nonconvex nonsmooth stochastic optimization | Clustering of web documents using a graph model"", Web Document Analysis: Challenges and Opportunities | Graph-Theoretic Techniques for Web Content Mining, World | Learning shape-classes using a mixture of tree-unions | An eigendecomposition approach to weighted graph matching problems | A RKHS interpolator-based graph matching algorithm",rejected,000
1001.1257.pdf.json,,"Humans usually categorize incoming information into stable concepts which can be upgraded, related and nested one into another. The characteristics of information are analyzed and classified into (i.e. they activate) existing concepts but, whenever they would represent a novelty, they will induce the formation of a new concept or the upgrade of the existing ones. This adaptive modality of knowledge organization makes cognitive system able to classify, store and employ at best incoming information, in order to solve the eventual cognitive demand during next steps of processing. Subsequently, human cognitive or behavioral responses to a given set of inputs are built following several and different decisional strategies. The role of context, the kind of information and past experiences are central for the choice of what kind of decision making will be made. In general, we can take into consideration at least five strategies of output production: 1) Reflexive responses: direct associations of inputs with an output pattern. They require no attentional resources and are out of possible controls. Typical examples are reflexive genetically implemented motor responses (e.g. the evade reflex) and associative behaviors (e.g. the Pavlov’s dog salivation reflex). 2) Automatic processes: standardized quick responses associated to a frequent activation of simple concepts while the behavioral relevance of the input/event is under an “alert red-line” (i.e. it requires a behavioral response but not a direct attentional monitoring, for instance during the vehicle driving). 3) Routine processes: processes triggered by several related concepts or complex events sufficiently frequent to constitute a stereotypical routine. Routines can be solved by a script [1, 2] and need the emergence of mental schemes [2, 3, 4], namely representations of complex concepts or events easily connectable to a fast cognitive or behavioral response. Note that even if the strategy requires an attentive control","Psychological status of the script concept | Scripts, plans, goals and understanding | Piaget’s theory | Conceptual dependency: a theory of natural language understanding | Reasoning. In New horizons in psychology | Models of deduction. In Reasoning: representation and process in childreen and adults | A logical calculus of the ideas immanent in nervous activity | Judgment under Uncertainty: Heuristics and Biases | Insensitivity to future consequences following damage to human prefrontal cortex | The Iowa Gambling Task and the somatic marker hypothesis: some questions and answers",rejected,000
1001.2155.pdf.json,,,Danger theory: The link between ais and ids | Immune system approaches to intrusion detection - a review | A cooperative immunization system for an untrusting internet | Two ways to grow tissue for artificial immune systems | Immunology : A Short Course | Introducing dendritic cells: A novel immune-inspired algorithm for anomaly detection | Immunobiology : the immune system in health and disease | Integrating Artificial Immune Algorithms for Intrusion Detection | An innate sense of danger | Inside the slammer worm | Code-red: a case study on the spread and victims of an internet worm | Cooperative response strategies for large scale attack mitigation | A hybrid quarantine defense | Soma - a self-orgnasing mobile agent immune system for computer networks | Very fast containment of scanning worms,rejected,000
1001.2170.pdf.json,Comparing Simulation Output Accuracy of Discrete Event and Agent Based Models: A Quantitative Approach,"Simulation has become a preferred tool in Operation Research for modelling complex systems. Studies in human behaviour modelling have received increased focus and attention from simulation research in the UK [Robinson 2004]. The research in human behaviour modelling has been applied to various application areas such as manufacturing (e.g. [Siebers 2004]), healthcare (e.g. [Brailsford et al. 2006]), military operations (e.g. [Wray and Laird 2003]) crowd behaviour (e.g. [Loftin et al. 2005]) retail management (e.g. [Siebers et al. 2008]) and consumer behaviour (e.g. [Schenk et al. 2007]). As found in the literature, some researchers choose Discrete Event Simulation (DES) as a means to investigate their human behaviour problems; others choose Agent Based Simulation (ABS) for this purpose. The choice of which simulation method to use relies on the individual judgment of the modeller and their experienced with the modelling method. The issue here will be how accurate and difference the simulation output will be when we model human behaviour using both DES and ABS model. The representation of human behaviour contains complexity and variability; therefore when investigating such systems it is very important to choose a suitable technique. Consequently, we have done some quantitative experiments and our findings will be discussed in this paper. In this research we aim to provide an empirical study in order to find out more about the differences in output accuracy by comparing traditional DES and ABS. The main difference between traditional DES and ABS is that in traditional DES the modelling focus is on the process flow while in the ABS the modelling focus is on the individual entities in the system and their interactions. To achieve our aim we will compare the simulation output accuracy of DES and ABS models when modelling human reactive behaviour in a department store. In this context human reactive behaviour means responding to a request. For example, a sales staff membe","Towards a theoretical framework of human performance modelling within manufacturing systems design. | Agent-based and Discrete Event Simulation of Autonomous Logistic Processes.”In | D.Love, and P.Albores | Discrete-event simulation: from | An Agent-Based Simulation of In-Store Customer Experiences.”In | Discrete Event Simulation Optimization Using Ranking,Selection, and Multiple Comparison Procedures: A Survey. | Towards An Empirical Comparison of Discrete-Event Simulation and System Dynamics in the Supply Chain Context. | Comparison of System Dynamic and Agent-Based Simulation Applied to the Study of Cellular Receptor Dynamics. | Varibility in Human Behaviour Modeling for Military Simulations, | AgentBased and Discrete-Event Modelling: A quantitative approach.",rejected,000
1001.2195.pdf.json,DCA for Bot Detection,,"An Inside Look at Botnets | Extrusion Detection: Security Monitoring for Internal Intrusions | An Algorithm for Anomaly-based Botnet Detection | The Zombie Roundup: Understanding, Detecting, and Disrupting Botnets | Dendritic Cells for SYN Scan Detection | Information Fusion for Anomaly Detection with the Dendritic Cell Algorithm | The Dendritic Cell Algorithm | Botnets as a Vehicle for Online Crime | Internet Relay Chat: Architecture |  Immature | Analysis of Internet Relay Chat Usage by DDoS Zombies | Biological Inspiration for Artificial Immune Systems",rejected,000
1001.2208.pdf.json,,,"Application Areas of AIS: The Past, The Present and The Future | Artificial immune systems - today and tomorrow | Reconstructing immune phylogeny: new perspectives | An innately interesting decade of research in immunology | The Plant Immune System | Plant pathogens and integrated defence responses to infection | Plant responses to insect herbivory: the emerging molecular analysis | Quality Control in Self/Nonself Discrimination | Recognition and Rejection of Self in Plant Reproduction | Invertebrate immune systems - not homogeneous, not simple, not well understood | Alternative adaptive immunity in invertebrates | AgDscam, a Hypervariable Immunoglobulin Domain-Containing Receptor of the Anopheles gambiae Innate Immune System | Diversification of Ig Superfamily Genes in an Invertebrate | Specific memory within innate immune systems | Evolution of antigen binding receptors | Variable lymphocyte receptors in hagfish | Diversity and function of adaptive immune receptors in a jawless vertebrate | Towards a Conceptual Framework for Innate Immunity | Integrated Innate and Adaptive Artificial Immune Systems applied to Process Anomaly Detection | A short history of time and space in immune discrimination | Essay 1: the Danger model in its historical context | The Great Debate: The web debate on self-nonself | Regulatory T cells: Meden Agan | The Self Model and the Conception of Biological Identity in Immunology | The Clonal Selection Theory of Acquired Immunity | A Theory of Self-Nonself Discrimination | The elusive immune self: a case of category errors | Approaching the asymptote? Evolution and revolution in immunology | Decoding the patterns of self and nonself by the innate immune system | Tolerance, Danger, and the Extended Family | Friendly and dangerous signals: is the tissue in control | Anderson and Matzinger: Round 3 | The Normal and the Pathological | The Biopolitics of Postmodern Bodies: Constitutions of Self in Immune System Discourse | The cognitive principle challenges clonal selection | Tending Adam’s Garden: Evolving the Cognitive Immune Self | Inspiration for the Next Generation of Artificial Immune Systems | Morphostasis and immunity | Tissue Homeostasis and Immunity - More on Models | Do we need integrity | Immune system protects integrity of tissues",rejected,000
1001.2277.pdf.json,Application of a Fuzzy Programming Technique to Production Planning in the Textile Industry,,"A General Model For Fuzzy Linear Programming | On Formalization Of A General Fuzzy Mathematical Programming Problem | Fuzzy Theories on Decision-Making: Frontiers in Systems Research | Fuzzy Sets, Decision Making, and Experts Systems. Boston: Kluwer | Multi-objective programming and goal programming: theories and applications | Fuzzy Set Theory-and Its Applications, (2 rev | Fuzzy Logic with Engineering Applications, New York: McGraw- Hill | Fuzzy Sets and Fuzzy Logic: Theory and Applications | Fuzzy Sets and Applications-Selected Papers by L | Application of Fuzzy Set Theory To Mathematical Programming | Fuzzy Sets and Systems, Theory and Applications, California | Detection of level of satisfaction and fuzziness patterns for MCDM model with modified flexiable S-curve MF | Tus, “Interactive fuzzy linear programming and an application sample at a textile firm | Fuzzy Optimization with Robust Logistic Membership Function: A Case Study In For Home Textile Industry",rejected,000
1001.2279.pdf.json,The Application of Mamdani Fuzzy Model for Auto Zoom Function of a Digital Camera,,"An Advanced Video Camera System with Robust AF, AE, and AWB Control, | A Fuzzy Control Processor for Automatic Focusing | An Advanced Autofocus System for Video Camera using Quasi Condition Reasoning | Automatic Control of Camera Pan, Zoom and Focus for Improving Object Recognition | A neural approach to zoom-lens camera calibration from data with outliers | Modeling of a computercontrolled zoom lens | Modeling The Variation Of The Intrinsic Parameters Of An Automatic Zoom Camera System Using Moving Least-Squares | Mamdani Model based Adaptive Neural Fuzzy Inference System and its Application | A Suitability Measure for Automatic Selection of Fuzzy Model based on User's Data | Enhancement of Auto Image Zooming using Fuzzy Set Theory, 2nd International Conference on Control, Instrumentation and Mechatronics, (CIM | A Video Camera System With Enhanced, Zoom Tracking And Auto White Balance | Outline of a New Approach to the Analysis of Complex Systems and Decision Processes | Applications of Fuzzy Algorithms for Simple Dynamic Plants | Fuzzy Logic in Control Systems: Fuzzy Logic Controller | 5-speed Automatic Transmission Installed Fuzzy Reasoning | Twenty Years of Fuzzy Control: Experiences Gained and Lessons Learnt | Fuzzy logic control of a multispectral imaging sensor for in-field plant sensing, computers and electronics in agriculture | Mamdani Model based Adaptive Neural Fuzzy Inference System and its Application | A general approach to linguistic approximation,Fuzzy Reasoning and Its Applications, Academic Press,1981 | Application of Fuzzy Logic to Approximate Reasoning Using Linguistic Synthesis | Derivation of fuzzy control rules from human operators control actions | Fuzzy identification of systems and its applications to modeling and control",rejected,000
1001.2665.pdf.json,Detecting Botnets Through Log Correlation,,"The Zombie Roundup: Understanding, Detecting, and Disrupting Botnets | Botnet Tracking: Exploring a Root-Cause Methodology to Prevent Distributed Denial-of-Service Attacks | Binary Interception of Win32 Functions | The Evolution of Malicious IRC bots. White Paper: Symantec Security Response | Bots and Botnets: Risks, Issues and Prevention | Three ways to Inject Your Code into Another Process. Retrieved Jun | Intercepting System API Calls | Anomaly Detection for Internet Worms",rejected,000
1001.2709.pdf.json,Kernel machines with two layers and multiple kernel learning,"Learning by minimizing costs in functional spaces has proven to be an important approach to better understand many estimation problems. Indeed, the functional analytic point of view is the theoretical core of many successful learning methodologies such as smoothing splines, Gaussian processes, and support vector machines [54, 18, 41, 52, 45, 37], collectively referred to as kernel methods. One of the most appealing properties of kernel methods is optimality according to a variety of representer theorems. These results are usually presented within the theory of RKHS [5], and formalize the intuition that optimal learning machines trained with a finite number of data must be expressed by ∗Francesco Dinuzzo is with Department of Mathematics, University of Pavia, Pavia, Italy e-mail: francesco.dinuzzo@unipv.it. ar X iv :1 00 1. 27 09 v1 [ cs .L G ] 1 5 Ja n a finite number of parameters, even when the hypothesis space is infinite dimensional. Representer theorems have been generalized and analyzed in many forms [10, 40, 49, 12, 31, 53, 14, 4], since their first appearance [26]. Recently, has been pointed out that standard kernel machines are somehow limited in their ability to approximate complex functional classes, as a consequence of being shallow architectures. In addition, existing representer theorems only apply to single-layer architectures, though an extension of the theory to include multi-layer networks would be useful to better understand the behavior of current multi-layer architectures and characterize new methods with more flexible approximation capabilities. Such extension is also suggested by complexity theory of circuits [8] as well as by biological motivated learning models, [43]. In the field of kernel methods, the need for complex hypothesis spaces reflecting “broad” prior knowledge has led to the idea of learning the kernel from empirical data simultaneously with the predictor [7, 27, 33, 30, 3, 55, 32]. Indeed, the difficulty of choosing a good hypot","Information theory and an extension of the maximum likelihood principle | A DC-programming algorithm for kernel selection | Learning convex combinations of continuously parameterized basic kernels | When there is a representer theorem? Vector versus matrix regularizers | Theory of reproducing kernels | Consistency of the Group Lasso and multiple kernel learning | Multiple kernel learning, conic duality, and the SMO algorithm | Scaling learning algorithms towards AI | Convex Optimization | Asymptotic analysis of penalized likelihood and related estimators | Smoothing noisy data with spline functions | Some properties of regularized kernel methods | An algebraic characterization of the optimum of regularized kernel methods | On the representer theorem and equivalent degrees of freedom of SVR | The estimation of prediction error: Covariance penalties and crossvalidation | LIBLINEAR: A library for large linear classification | Multicategory proximal support vector machine classifiers | Regularization theory and neural networks architectures | Feature Extraction: Foundations and Applications (Studies in Fuzziness and Soft Computing) | The Elements of Statistical Learning | Approximate maximum a posteriori with Gaussian process priors | Ridge regression: biased estimation for nonorthogonal problems | A dual coordinate descent method for large-scale linear SVM | Training linear SVMs in linear time | Learning the kernel via convex optimization | Some results on Tchebycheffian spline functions | Learning the kernel matrix with semidefinite programming | Some comments on Cp | The support vector machine under test | Learning the kernel function via regularization | On learning vector-valued functions | Feature space perspectives for learning the kernel | Learning the kernel with hyperkernels | Fast training of support vector machines using sequential minimal optimization | SimpleMKL | Multiclass cancer diagnosis using tumor gene expression signatures | Gaussian Processes for Machine Learning | Regularized least squares classification | Convex Analysis | A generalized representer theorem | Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond | Estimating the dimension of a model | A quantitative theory of immediate visual recognition | PEGASOS: Primal Estimated sub- GrAdient SOlver for Svm | Kernel Methods for Pattern Analysis | Large scale multiple kernel learning | Prostate specific antigen in the diagnosis and treatment of adenocarcinoma of the prostate ii radical prostatectomy treated patients | Estimation of the mean of a multivariate normal distribution | Sparseness of support vector machines | Regression shrinkage and selection via the lasso | Solutions of Ill Posed Problems | Statistical Learning Theory | Kernel extrapolation | Spline Models for Observational Data | Multi-kernel regularized classifiers",rejected,000
1001.4892.pdf.json,Janus: Automatic Ontology Builder from XSD files,"Over the past ten years, the Semantic Web wave has shown a new vision of ontology use for application integration systems. Researchers have produced several software tools for building ontologies (like Protégé [1]) and merging them two by two (like Mafra [2]) or producing alignments (like S-Match [3]). These solutions, as well as adopted ontology building methodologies, are mainly human or, as shown in [4], sometimes assisted by semi-automatic software tools. Limitations to their adoption for integration of internet and enterprise applications, among others reasons, are: (i) the lack of tools capable of extracting and acquiring information from a collection of XML files (the “de-facto” format for applications information exchange definition); (ii) the complexity of aligning and merging two or more knowledge sources, a task excessively consuming of computational time; (iii) the difficulty of validation based on background knowledge hard to produce and maintain. Janus, the tool that we have developed, implements a new approach to ontology generation capable of providing a solution to the limitations described above. It is able to automatically generate and maintain, (in a meta-model OWL compatible), a collective memory resource that facilitates the discovery of alignments for matching concepts in a given domain. The knowledge source is automatically acquired from an extensible set of XSD files. The aim of this short paper is to introduce Janus, how it works and to show some different views (produced by the tool) of knowledge automatically acquired.",The knowledge model of Protege-2000: Combining interoperability and flexibility | MAFRA - Mapping Distributed Ontologies in the Semantic Web | Semantic matching: Algorithms and implementation | Automatic Ontology Generation: State of the Art | Building Reference Ontologies from B2B XML Schema Files,rejected,000
1002.0102.pdf.json,-Discounting Method for Multi-Criteria Decision Making (α-D MCDM),,On a Short-coming of Saaty’s Method of Analytic Hierarchies | The Dempster-Shafer theory of evidence: An alternative approach to multicriteria decision modeling | An expert system for multi-criteria decision making using Dempster-Shafer theory | The analytical hierarchy process: an exposition | Some Comment on the Analytic Hierarchy Process | Scale sensitivity in the multiplicative AHP and SMART | Professional Decision-Making | Some comments on Saaty’s AHP | Multicriteria Decision Making | Decision-making with the AHP: Why is the principal eigenvector necessary,rejected,000
1002.0134.pdf.json,Constraint solvers: An empirical evaluation of design decisions,"Contemporary constraint solvers are very complex software systems. Each one of the many available today has its own characteristics, its own design decisions that the implementers made, and its own philosophy. The traits of a solver which will affect the performance for a particular problem class or instance often cannot be determined easily. Picking a particular solver is therefore a difficult task which requires specialist knowledge about each solver and is likely to have a significant impact on performance. On top of that, each solver has different ways of modelling problems. Not only do users need experience with a particular solver to model a problem in a way that enables it to be solved efficiently, but it is also hard to objectively compare solvers. This paper studies a small selection of constraint solvers and assesses their performance on problem models which were made as similar as possible.","MINION: A fast scalable constraint solver | Watched literals for constraint propagation in Minion | CSPLib: a benchmark library for constraints | Use of ranks in one-criterion variance analysis | Third international CSP solver competition | Programming Constraint Services, volume | Paltzer, and Patrick Pekczynski | The proof and measurement of association between two things | Individual comparisons by ranking methods",rejected,000
1002.0136.pdf.json,,"Currently, applying constraint technology to a large, complex problem requires significant manual tuning by an expert. Such experts are rare. The central aim of this project is to improve the scalability of constraint technology, while simultaneously removing its reliance on manual tuning by an expert. We propose a novel, elegant means to achieve this – a constraint solver synthesiser, which generates a constraint solver specialised to a given problem. Constraints research has mostly focused on the incremental improvement of general-purpose solvers so far. The closest point of comparison is currently the G12 project [1], which aims to combine existing general constraint solvers and solvers from related fields into a hybrid. There are previous efforts at generating specialised constraint solvers in the literature, e.g. [2]; we aim to use state-of-the-art constraint solver technology employing a broad range of different techniques. Synthesising a constraint solver has two key benefits. First, it will enable a fine-grained optimisation not possible for a general solver, allowing the solving of much larger, more difficult problems. Second, it will open up many new research possibilities. There are many techniques in the literature that, although effective in a limited number of cases, are not suitable for general use. Hence, they are omitted from current general solvers and remain relatively undeveloped. Among these are for example conflict recording [3], backjumping [4], singleton arc consistency [5], and neighbourhood inverse consistency [6]. The synthesiser will select such techniques as they are appropriate for an input problem. Additionally, it can also vary basic design decisions, which can have a significant impact on performance [7]. The system we are proposing in this paper, Dominion, implements a design that is capable of achieving said goals effectively and efficiently. The design decisions we have made are based on our experience with Minion [9] and other co",The G12 project: Mapping solver independent models to efficient solutions | Automatically configuring constraint satisfaction programs: A case study | Generalized nogoods in CSPs | Hybrid algorithms for the constraint satisfaction problem | Theoretical analysis of singleton arc consistency and its extensions | Neighborhood inverse consistency preprocessing | Constraint solvers: An empirical evaluation of design decisions | Tailoring solver-independent constraint models: A case study with Essence’ and Minion | MINION: A fast scalable constraint solver,rejected,000
1002.0908.pdf.json,,"Information systems [5, 8], also called knowledge representation systems, are a formalism for representing knowledge about some objects in terms of attributes (e.g., color) and values of attributes (e.g., green). Over the last decades, the concept of information systems has gained considerable attention, including some successful applications in information processing, decision, and control (see, for example, [1, 7, 10, 11, 16, 18, 20]). To study transformations of information systems while preserving their basic functions, a mathematical tool, homomorphism, has been introduced and investigated in the literature [2, 3, 6, 14, 15, 19, 21]. Most recently, Wang et al. discussed the properties of fuzzy information systems under homomorphisms in [12, 13]. In particular, they showed that attribute reductions in the original fuzzy information system and homomorphic image are equivalent to each other under a homomorphism. Thereby, homomorphisms are applicable in simulation of big systems by their smaller homomorphic images. The concept of homomorphisms, in turn, is based upon the notions of consistent functions and fuzzy relation mappings. Some basic properties of consistent functions and fuzzy relation mappings have been presented in [12]. In this paper, we revisit the homomorphisms between fuzzy information systems. More concretely, we classify consistent functions in [12] as predecessor-consistent and successor-consistent, and then proceed to present more properties of consistent functions. We improve some characterizations of fuzzy relation mappings provided in [12]. In particular, we present a new relationship between fuzzy neighborhoods and fuzzy relation mappings, which provides an approach to computing the fuzzy predecessor and fuzzy successor neighborhoods of an element of codomain with respect to the induced fuzzy relation. The theory presented here is helpful in establishing homomorphisms from the original fuzzy information system to a simpler fuzzy information s","Entropies and co-entropies of coverings with application to incomplete information systems | Algebraic properties of knowledge representation systems | On rough sets and information system homomorphism | Fuzzy Sets and Fuzzy Logic: Theory and Applications | Rough set approach to incomplete information systems | Invariant characters of information systems under some homomorphisms | Information entropy, rough entropy and knowledge granulation in incomplete information systems | Information systems − theoretical foundations | An Introduction to Fuzzy Sets: Analysis and Design | The lower system, the upper system and rules with stability factor in non-deterministic information systems | Various approaches to reasoning with frequency based decision reducts: a survey | Homomorphisms between fuzzy information systems | Some invariant properties of fuzzy information systems under homomorphism | Some properties of relation information systems under homomorphisms | Communicating between information systems | Uncertainty measure of rough sets based on a knowledge granulation for incomplete information systems | Relational interpretations of neighborhood operators and rough set approximation operators | Information-theoretic measures for knowledge discovery and data mining. in: Karmeshu (Ed.), Entropy Measures, Maximum Entropy and Emerging Applications, 115–136 | On characteristics of information system homomorphisms | An improved axiomatic definition of information granulation | A note on “communicating between information systems",rejected,000
1002.2202.pdf.json,Modeling of Human Criminal Behavior using Probabilistic Networks,,"Introduction to inference for Bayesian networks | How To Use Bayes Net Toolbox | Sexual Homicide: Patterns and motives | Profiling homicide: A multidimensional approach | Greek homocide, a behavioral examination of offender crime-scene actions | Offender interaction with victims in homicide: A multidimensional analysis of crime scene behaviors | Canadian homicide: An investigation of crime scene actions | Classifying homicide offenders and predicting their  characteristics from crime scene behavior",rejected,000
1002.2755.pdf.json,Multibiometrics Belief Fusion,,"Multibiometric systems | An introduction to biometrics recognition | Robust feature-level multibiometric classification | Face identification by SIFT-based complete graph topology | On model-based analysis of ear biometrics, | Comparison and combination of ear and face images in appearance-based biometrics | Algorithms for Dempster-Shafer theory | Image representation using 2D Gabor wavelets | On Convergence Properties of the EM Algorithm for Gaussian Mixtures | Facial features detection by saccadic exploration of the Gabor decomposition and Support Vector Machines | Ear identification",rejected,000
1002.2897.pdf.json,Model-Driven Constraint Programming,"In constraint programming (CP), programmers define a model of a problem using constraints over variables. The variables may take values from domains, typically boolean, integer, or rational values. The solutions to be found are tuples of values of the variables satisfying the constraints. The search process is performed by powerful solving techniques, for instance backtracking-like procedures and consistency algorithms to explore and reduce the space of potential solutions. In the past, CP has been shown to be efficient for solving hard combinatorial problems. CP systems evolved from the early days of constraint logic programming (CLP). In a CLP system, the constraint language is embedded in a logic language, and the solving procedure combines the SLD-resolution with calls to constraint solvers [15]. The logic language can be replaced with any computer programming language Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. PPDP’08, July 16–18, 2008, Valencia, Spain. Copyright c© 2008 ACM 978-1-60558-117-0/08/07. . . $5.00 (e.g. C++ in ILOG Solver [26] or Java in Gecode/J [12]) and even term rewriting [11]. It turns out that the programming task may be hard, especially for non experts of CP or computer programming. In this approach, modeling concerns are not enough to write programs, and it is often mandatory to deal with the encoding aspects of the host language or to tune the solving strategy. In response to this problem, almost pure modeling languages have been built, such as OPL [30] and Zinc [27]. The design of the last generation of CP systems has been governed by the idea of separating modeling and solving ","Term rewriting and all | The Programming Languages Aspects of ThingLab, a Constraint-Oriented Simulation Laboratory | CoJava: Optimization Modeling by Nondeterministic Simulation | Flexible, Rule- Based Constraint Model Linearisation | The GNU Prolog System and its Implementation | The Rules of Constraint Modelling | The Design of ESSENCE: A Constraint Language for Specifying Combinatorial Problems | Modelica – A Unified Object-Oriented Language for System Modeling and Simulation | Theory and Practice of Constraint Handling Rules | Minion: A Fast Scalable Constraint Solver | Algorithm 852: RealPaver: an interval solver using constraint satisfaction techniques | Constraint Logic Programming | Modeling Engineering Structures with Constrained Objects | Transforming Models with ATL | KM3: A DSL for Metamodel Specification | KM3: A DSL for Metamodel Specification | Model-based DSL frameworks | MiniZinc: Towards a Standard CP Modelling Language | A Visual Constraint-Programming Environment | A C++ implementation of CLP | From Zinc to Design Model | The Design of COMMA: An Extensible Framework for Mapping Constrained Objects to Native Solver Models | The OPL Language",rejected,000
1002.3023.pdf.json,,"In constraint programming (CP), users describe properties of problems as constraints involving variables. The computer system calls constraint solvers to calculate the solutions. The automatic mapping from constraint models to solvers is the key issue of this paper. The goal is to develop middle software tools that are able to reformulate and rewrite models according to solving requirements. Modeling real-world problems requires high-level languages with many constructions such as constraint definitions, programming statements, and modularity features. In the recent past, a variety of languages has been designed for a variety of users and problem categories. On one hand, there are many modeling languages for combinatorial problems such as OPL (Van Hentenryck et al. 1999), Essence (Frisch et al. 2007), and MiniZinc (Nethercote et al. 2007) or numerical constraint and optimization problems such as Numerica (Van Hentenryck, Michel, and Deville 1997) and Realpaver (Granvilliers and Benhamou 2006). On the Copyright c© 2010, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. other hand, constraint solving libraries have been plugged in computer programming languages, for instance ILOG Solver (Puget 1994), Gecode (Schulte and Tack 2006), and ECLiPSe (Apt and Wallace 2007). In the following, we will only consider modeling languages as input constraint models. However, computer programming languages can be chosen as targets of the mapping process. Our aim is therefore to provide a many-to-many mapping tool that is able to cope with a variety of languages. Many constructions are shared among the different languages, in particular the definitions of constraints. Other constructions are specific such as classes in object-oriented languages or predicates in logic languages. We propose to embed this collection of concepts in a so-called metamodel, that is a model of constraint models. This pivot metamodel describes the relations betwee",and Wallace | Model-Driven Constraint Programming | and Codognet | P | The Rules of Constraint Modelling | B | I | and Benhamou | and Bézivin | TCS: a DSL for the Specification of Textual Concrete Syntaxes in Model Engineering | Rule-based Modularization in Model Transformation Languages Illustrated with ATL | Weaving Executability into Object-Oriented Meta-Languages | G | and Tack | and Granvilliers | Constraint Programming in OPL | Numerica: a Modeling Language for Global Optimization,rejected,000
1002.3078.pdf.json,Using ATL to define advanced and flexible constraint model transformations,"Constraint programming (CP) systems must combine a modeling language and a solving engine. The modeling language is used to represent problems with variables, constraints, or statements. The solving engine computes assignments of variables satisfying the constraints by exploring and pruning the space of potential solutions. This paper considers the constraint modeling process as constraint model transformations between arbitrary modeling or solver languages. It follows several important consequences on the architecture of systems and user practices. Constraint programming languages are rich, combining common constraint domains, e.g. integer constraints or linear real constraints, with global constraints like alldifferent, and even statements like if-then-else or forall. Moreover the spectrum of syntaxes is large, ranging from computer programming languages like Java or Prolog to high-level languages intended to be more humancomprehensible. This may be contrasted with the existence of a standard language in the field of mathematical programming, which improves model sharing, writing and understanding. The quest of a standard CP language is a recent thread, dating back to the talk of Puget [15]. Another important concern is to employ the best solving technology for a given model. As a consequence, a new kind of architecture emerged. The key idea is to map models written with a high-level CP language to many solvers. For instance within the G12 project, MiniZinc [13] is intended to be a standard modeling language, and Cadmium [3] is able to map MiniZinc models to a set of solvers. Essence [5] is another CP platform offering an high level modeling language refining Essence specifications to Essence’ models using Conjure [6]. Then hand-written translators can generate models for several different solvers. The role of a mapping tool is to bridge modeling and solver languages and to optimize models for improving the solving process. Cadmium is based on Constraint Handling ","Nonlinear oscillations and boundary-value problems for Hamiltonian systems | Solutions périodiques, du période donnée, des équations hamiltoniennes | Subharmonic solutions with prescribed minimal period for nonautonomous Hamiltonian systems",rejected,000
1002.3174.pdf.json,A New Approach to Content-based File Type Detection,,File Type Classification for Adaptive Object File System | Automatic File Type Detection Algorithm | Content based file type detection algorithms | Approximation by superpositions of a sigmoidal function,rejected,000
1002.3195.pdf.json,Efficiently Discovering Hammock Paths from Induced Similarity Networks,"There is significant current interest in modeling and understanding network structures, especially in online social communities, web graphs, and biological networks. We focus here on (unipartite) similarity networks induced from bipartite graphs, such as a movies × people dataset. Two movies can be connected if they have been rated similarly by sufficient number of people; this is the basis for the popular itembased recommendation algorithms [4]. A similarity network thus exposes an indirect level of clustering, community formation, and organization that is not immediately apparent from the bipartite network. Similarity networks are key abstractions in recommender systems but they also find uses in other information management applications such as collection analysis and medical informatics. We focus on how these networks can be used for exploratory discovery, i.e., to see how similarities can be composed to reach potentially distant entities. For instance, how is the movie ‘Roman Holiday’ (a romantic classic) connected to ‘Terminator 3’ (a Sci-Fi movie)? What are the in-between movies and waypoints that help link these two disparate movies? Are these waypoints characteristic to the domain or to the dataset? For recommender systems, these questions are especially germane to tasks such as serendipitous recommendation, gift buying, and characterizing the movie watching interests of its users. In addition to recommender systems, we consider similarity networks induced from literature and semistructured sources of data. Here path finding has applications to literature-based discovery (similar to the ARROWSMITH program [12]) and clinical diagnosis. For instance, how is congestive heart failure related to kidney disease? The discovered waypoints correspond to possibilities by which different disease response pathways interact with each other. Admittedly, these questions can be answered by first inducing the similarity network and running shortest path queries over it, but",Cover Trees for Nearest Neighbor | Sparsification—A Technique for Speeding up Dynamic Graph Algorithms | Outcomes of Simultaneous Heart-Kidney Transplant in the US: A Retrospective Analysis Using OPTN/UNOS Data | Evaluation of Item-Based Top-N Recommendation Algorithms | Algorithms for Storytelling | Connectivity Structure of Bipartite Graphs via the KNC-plot | Introduction to Chemoinformatics | Studying Recommendation Algorithms by Graph Analysis | A Lattice-Based Model for Recommender Systems | A Browser for Bibliographic Information Retrieval | Turning CARTwheels: an Alternating Algorithm for Mining Redescriptions | Using ARROWSMITH: A Computer-assisted Approach to Formulating and Assessing Scientific Hypotheses | The vertex degree distribution of random intersection graphs | Reasoning About Sets Using Redescription Mining,rejected,000
1002.3307.pdf.json,,"Pearl’s belief propagation [1] provides an efficient method for exact computation in the inference with probabilistic models associated to trees. As an extension to general graphs allowing cycles, Loopy Belief Propagation (LBP) algorithm [2] has been proposed, showing successful performance in various problems such as computer vision and error correcting codes. One of the interesting theoretical aspects of LBP is its connection with the Bethe free energy [3]. It is known, for example, the fixed points of LBP correspond to the stationary points of the Bethe free energy. Nonetheless, many of the properties of LBP such as exactness, convergence and stability are still unclear, and further theoretical understanding is needed. This paper theoretically analyzes LBP by establishing a formula asserting that the determinant of the Hessian of the Bethe free energy equals the reciprocal of the edge zeta function up to a positive factor. This formula derives a variety of results on the properties of LBP such as stability and uniqueness, since the zeta function has a direct link with the dynamics of LBP as we show. The first application of the formula is the condition for the positive definiteness of the Hessian of the Bethe free energy. The Bethe free energy is not necessarily convex, which causes unfavorable behaviors of LBP such as oscillation and multiple fixed points. Thus, clarifying the region where the Hessian is positive definite is an importance problem. Unlike the previous approaches which consider the global structure of the Bethe free energy such as [4, 5], we focus the local structure. Namely, we provide a simple sufficient condition that determines the positive definite region: if all the correlation coefficients of the pseudomarginals are smaller than a value given by a characteristic of the graph, the Hessian is positive definite. Additionally, we show that the Hessian always has a negative eigenvalue around the boundary of the domain if the graph has at least t",,rejected,000
1002.4286.pdf.json,"REDUNDANCY, DEDUCTION SCHEMES, AND MINIMUM-SIZE BASES FOR ASSOCIATION RULES","The relatively recent discipline of Data Mining involves a wide spectrum of techniques, inherited from different origins such as Statistics, Databases, or Machine Learning. Among them, Association Rule Mining is a prominent conceptual tool and, possibly, a cornerstone notion of the field, if there is one. Currently, the amount of available knowledge regarding association rules has grown to the extent that the tasks of creating complete surveys and websites that maintain pointers to related literature become daunting. A survey, with plenty 1998 ACM Subject Classification: I.2.3, H.2.8, I.2.4, G.2.3, F.4.1. Key words and phrases: Data mining, association rules, implications, redundancy, deductive calculus, optimum bases. This work is supported in part by project TIN2007-66523 (FORMALISM) of Programa Nacional de Investigación, Ministerio de Ciencia e Innovación (MICINN), Spain, and by the PASCAL2 Network of Excellence of the European Union. LOGICAL METHODSl IN COMPUTER SCIENCE DOI:10.2168/LMCS-6 (2:3) 2010 c© José L. BalcázarCC© Creative Commons of references, is [12], and additional materials are available in [25]; see also [2], [3], [18], [36], [44], [45], and the references and discussions in their introductory sections. Given an agreed general set of “items”, association rules are defined with respect to a dataset that consists of “transactions”, each of which is, essentially, a set of items. Association rules are customarily written as X → Y , for sets of items X and Y , and they hold in the given dataset with a specific “confidence” quantifying how often Y appears among the transactions in which X appears. A close relative of the notion of association rule, namely, that of exact implication in the standard propositional logic framework, or, equivalently, association rule that holds in 100% of the cases, has been studied in several guises. Exact implications are equivalent to conjunctions of definite Horn clauses: the fact, well-known in logic and knowledge repr",A New Approach to Online Generation of Association Rules | A Swami: Mining Association Rules between Sets of Items in Very Large Databases | A I Verkamo: Fast Discovery of Association Rules | Construction and Learnability of Canonical Horn Formulas. Submitted. Preliminary version in ALT’2009 | Deduction Schemes for Association Rules | Mining Implications from Lattices of Closed Trees | Efficient Implementations of Apriori and Eclat | Free-Sets: A Condensed Representation of Boolean Data for the Approximation of Frequency Queries | Mining All Non-Derivable Frequent Itemsets | Boulicaut: A Survey on Condensed Representations for Frequent Sets. Constraint-Based Mining and Inductive Databases | Generating an Informative Cover for Association Rules | A Priestley: Introduction to Lattices and Order | Pearl: Structure Identification in Relational Data | Identifying the Minimal Transversals of a Hypergraph and Related Problems | Understanding the Crucial Differences between Classification and Discovery of Association Rules | Statistical Strategies for Pruning All the Uninteresting Association Rules | Interestingness Measures for Data Mining: A Survey | Mining Non-Derivable Association Rules | Famille minimale d’implications informatives résultant d’un tableau de données binaires | Discovering All Most Specific Sentences | Reasoning with Models | Fast Discovery of Representative Association Rules | Concise Representations of Association Rules | Pruning and Summarizing the Discovered Associations | Multi-Level Organization and Summarization of the Discovered Rules | Discovering Predictive Association Rules | Closed Non-Derivable Itemsets | Generating a Condensed Representation for Association Rules | Taylor: Scientific Discovery through Iterative Transformations of Concept Lattices | The Representative Basis for Association Rules | The Closed Keys Base of Frequent Itemsets | Using Closed Itemsets for Discovering Representative Association Rules | Cristofor: Mining Purity Dependencies in Databases | Querying Multiple Sets of Discovered Rules | A Theory of Finite Closure Spaces Based on Implications | Mining Non-Redundant Association Rules | Theoretical Foundations of Association Rules,rejected,000
1002.4665.pdf.json,Syntactic Topic Models,,"Mixtures of Dirichlet processes with applications to Bayesian nonparametric problems | Variational inference for Dirichlet process mixtures | Dynamic topic models | Supervised topic models | The nested chinese restaurant process and hierarchical topic models, Oct | Bayesian synchronous grammar induction | A topic model for word sense disambiguation | Bayesian word sense induction | Logistic normal priors for unsupervised probabilistic grammar induction | Form and content: Dissociating syntax and semantics in sentence comprehension | Indexing by latent semantic analysis | Describing disability through individual-level mixture models for multivariate binary data | Bayesian density estimation and inference using mixtures | A Bayesian analysis of some nonparametric problems | The infinite tree | Finding scientific topics | Integrating topics and syntax | Topics in semantic representation | Hidden topic Markov models | Studying the history of ideas using topic models | A probabilistic model of unsupervised learning for musical-key profiles | Extended constituent-to-dependency conversion for English | Adaptor grammars: A framework for specifying compositional nonparametric Bayesian models | An introduction to variational methods for graphical models | Fast exact inference with a factored model for natural language parsing | Accurate unlexicalized parsing | Accelerated variational Dirichlet process mixtures | A Bayesian hierarchical model for learning natural scene categories | Structured Bayesian nonparametric models with variational inference (tutorial) | The infinite PCFG using hierarchical Dirichlet processes | Foundations of Statistical Natural Language Processing | Building a large annotated corpus of English: The Penn treebank | Mining a digital library for influential authors | Probabilistic inference using Markov chain Monte Carlo methods | Markov chain sampling methods for Dirichlet process mixture models | Inference of population structure using multilocus genotype | Unsupervised topic modelling for multi-party spoken discourse | Minimized models for unsupervised part-of-speech tagging | The interaction of syntax and semantics during sentence processing — Eye-movements in the analysis of semantically biased sentences | The author-topic model for authors and documents | Hierarchical Dirichlet processes | A hierarchical Bayesian language model based on Pitman-Yor processes | A joint model of text and aspect ratings for sentiment summarization | A Bayesian LDA-based model for semi-supervised part-of-speech tagging | Graphical models, exponential families, and variational inference. Foundations and Trends in Machine Learning, 1(1–2):1–305 | Topic modeling: beyond bag-of-words | Continuous time dynamic topic models | Fully distributed EM for very large datasets | TagLDA: Bringing document structure knowledge into topic models",rejected,000
1002.4862.pdf.json,Less Regret via Online Conditioning,"In the past few years, online algorithms have emerged as state-of-the-art techniques for solving large-scale machine learning problems [2, 13, 16]. In addition to their simplicity and generality, online algorithms are natural choices for problems where new data is constantly arriving and rapid adaptation is imporant. Compared to the study of convex optimization in the batch (offline) setting, the study of online convex optimization is relatively new. In light of this, it is not surprising that performance-improving techniques that are well known and widely used in the batch setting do not yet have online analogues. In particular, convergence rates in the batch setting can often be dramatically improved through the use of preconditioning. Yet, the online convex optimization literature provides no comparable method for improving regret (the online analogue of convergence rates). A simple and effective form of preconditioning is to re-parameterize the loss function so that its magnitude is the same in all coordinate directions. Without this modification, a batch algorithm such as gradient descent will tend to take excessively small steps along some axes and to oscillate back and forth along others, slowing convergence. In the online setting, this rescaling cannot be done up front because the loss functions vary over time and are not known in advance. As a result, when existing no-regret algorithms for online convex optimization are applied to machine learning problems, they tend to overfit the data with respect to certain features and underfit with respect to others (we give a concrete example of this behavior in §2). We show that this problem can be overcome in a principled way by using online gradient descent1 with adaptive, per-coordinate learning rates. Our algorithm comes with worst-case regret bounds (see Theorem 3) that are never worse than those of standard online gradient descent, and are much better when the magnitude of the gradients varies greatly across co",Adaptive online gradient descent | The tradeoffs of large scale learning | Online passiveaggressive algorithms | Adaptive regularization of weight vectors | Multi-domain sentiment dataset (v2.0) | Confidence-weighted linear classification | Adaptive subgradient methods for online learning and stochastic optimization | Extracting certainty from uncertainty: Regret bounded by variation in costs | Efficient learning algorithms for changing environments | Periodic step-size adaptation in second-order gradient descent for single-pass on-line structured learning | Increased rates of convergence through learning rate adaptation | Identifying suspicious URLs: an application of large-scale online learning | Adaptive bound optimization for online convex optimization | Two problems with backpropagation and other steepest-descent learning procedures for networks | Solving large scale linear prediction problems using stochastic gradient descent algorithms | Online convex programming and generalized infinitesimal gradient ascent,rejected,000
1003.0120.pdf.json,Learning from Logged Implicit Exploration Data,,The nonstochastic multiarmed bandit problem | Probability inequalities for sums of bounded random variables | Approximate planning in large pomdps via reusable trajectories | The epoch-greedy algorithm for multi-armed bandits with side information | Exploration scavenging | Safe and effective importance sampling | Eligibility traces for off-policy policy evaluation,rejected,000
1003.0590.pdf.json,Application of CACS approach for distributed logistic systems,"Simultaneous rapid grow of logistics market in different regions of the world [1, 2], and its important role in modern economy require wide application of logistics information and management systems for coordinated planning and control. Distributed organizational structure and application of holonic management principles in modern organizations inevitably determine distributed and autonomous features of information systems supporting logistic operations [5]. In such kinds of the systems it is very difficult to apply usual centralized approaches and algorithms for decision support and optimization. Swarm Intelligence [3, 4] represents one of the interesting paradigm for maintaining self-organization and control in the distributed systems. One of the principal aspect of the swarmoriented distributed intelligent systems is presence of multiple intellectual and autonomous particles which interact with each other in some way. As it is started in [4]: ‖Swarm is a population of interacting elements that is able to optimize some global objectives thought collaborative search in space‖. Different projects offered approaches for practical application of Swarm Intelligence paradigm in the form of multi-agent systems [6, 28, 30]. Although some of them (i.e. [28]) offer a formal framework for declarative expression and analysis, researchers and practitioners still lack proper generic methods for engineering of the multi-agent systems which have such properties of Swarm Intelligence as emergent behavior, peer-topeer communication, etc. Analysis of known logistic problems and algorithms shows that in the domain of applied logistics and optimization general principles of swarm-oriented organization may be realized using proper combination of multi-agent systems (MAS) and constraints satisfaction approach (CSP). So, in this research we 1 LITIS Laboratory, INSA Rouen, France. Email: {almaqtari, abdulrab}@insa-rouen.fr. 2 TAPRADESS Laboraotry, State University – Higher School of Econ","Logistics Management in China. Building Supply Chain Excellence in Emerging Economies | Growth Prospects of Russian Transportation and Logistics Market. Das Beste der Logistik:Innovationen, Strategien, Umsetzungen. pp.369-379 | Swarm Intelligence: From Natural to Artifical Systems | Approaches to Methods of Autonomous Cooperation and Control for the Management-, Information- and Communication-Layer of Logistics. Understanding Autonomous Cooperation and Control in Logistics (Katja Windt and Michael Hülsmann eds.) | Agent-Based Approaches to Transport Logistics | Collective Intelligence in Multi-Agent Robotics: Stigmergy, Self-Organization and Evolution | COLLECTIVE INTELLIGENCE: Creating a Prosperous World at Peace | Modélisation d’accompagnement Simulations multiagents et gestion des ressources naturelles et renouvelables | Multi-agent Systems-An Introduction to Distributed Artificial Intelligence | A Nonlinear Multi-agent System designed for Swarm Intelligence: the Logistic MAS | Constraint Programming: In Pursuit of the Holy Grail, in Proceedings of WDS99 (invited lecture) | Distributed Constraint Satisfaction for Coordinating and Integrating a Large-Scale, Heterogeneous Enterprise, University of London | On the Conversion between Non-Binary and Binary Constraint Satisfaction Problems | NoGood Caching for MultiAgent Backtrack Search | Algorithms for Distributed Constraint Satisfaction: A Review. in Autonomous Agents and Multi-Agent Systems, pp | The Asynchronous Backtracking Family, LIRMM-CNRS | Asynchronous Backtracking without Adding Links: A New Member in the ABT Family | Distributed Stable Matching Problems with Ties and Incomplete Lists | Bound Consistency on Linear Constraints in Finite Domain Constraint Programming | Constraint Satisfaction with Preferences | A Cooperative Mediation-Based Protocol for Dynamic, Distributed Resource Allocation. In IEEE Transaction on Systems, Man, and Cybernetics, Part C, Special Issue on Game-theoretic Analysis and Stochastic Simulation of Negotiation | Developing Multi- Agent Systems with JADE, Wiley | OPERAS: A Framework for the Formal Modelling of Multi-Agent Systems and Its Application to Swarm-Based Systems",rejected,000
1003.0617.pdf.json,Agent Based Approaches to Engineering Autonomous Space Software∗,"Modern control systems are limited in their ability to react flexibly and autonomously to changing situations. The limiting factor is the complexity inherent in analysing situations where many variables are present. There are many complex, real-world, control systems but we are primarily interested in the (autonomous) control of satellite systems. Consider the problem of a single satellite attempting to maintain a geostationary orbit. Current satellite control systems maintain orbits using feedback controllers. These implicitly assume that any errors in the orbit will be minor and easily corrected. In situations where more significant errors occur, for example caused by a thruster malfunction, it is desirable to modify or change the controller. The complexity of the decision task is a challenge to standard approaches, and has led, for example, to complex, evolutionary control systems. These become very difficult to understand. We approach the problem from the perspective of rational agents [6]. We consider a satellite to be an agent which consists of a discrete (rational decision making) part and a continuous (calculation) part. The discrete part uses the Belief-Desire-Intention (BDI) theory of agency [5] and governs high level decisions about when to generate new feedback controllers. The continuous, calculational part is used to ∗Work funded by EPSRC grants EP/F037201/1 and EP/F037570/1 derive controllers and to calculate information from continuous data which can be used in the decision making process; this part can be viewed as a hybrid system.",Automated verification of multi-agent programs | Gwendolen: A BDI Language for Verifiable Agents | A Fully Automated Framework for Control of Linear Systems From Temporal Logic Specifications | Components of a Vision Assisted Constrained Autonomous Satellite Formation | BDI Agents: From Theory to Practice | Foundations of Rational Agency,rejected,000
1003.0659.pdf.json,Particle Filtering on the Audio Localization Manifold,"There is an increasing interest in locating audio sources with a microphone array as a means to direct the pointing of a camera. Camera pointing applications include video conferencing, surveillance, game playing and interactive displays. In addition, speech enhancement with microphone arrays rely critically on knowing the correct source location. One popular method for locating an audio source is based on measuring the delays observed between spatially separated pairs of microphones known as the time delay of arrival (TDOA). For locating a source a two stage process can be employed: First TDOAs for all pairs of microphones are estimated, and then a source location is derived from this delay information. If microphone positions are given, the second step becomes approximately solving a set of non-linear phys- ical equations such as in [6]. However, localizing an audio source accurately in a large room requires that the microphones are far apart from each other. As a result of placing the microphones far apart, it becomes difficult to estimate their positions within a coordinate system accurately. If the positions are not known, then a regressor can be learned that maps TDOAs to camera pointing directives as in [7, 4]. In this work we focus on accurately estimating and tracking TDOAs for a microphone array in a large room. There is an extensive literature on using particle filters for tracking audio sources when the microphone positions are known [13, 11]. Since positional information is known, the state space for the particles is typically only two or three spatial dimensions for the location of the sound source. When the microphone positions are not known and we attempt to track in the native TDOA space we become victim to the slew of problems that come with tracking in high dimensions. With N microphones in the array each pair has a TDOA that needs to be tracked making the state space be of dimension D = ( N 2 ) . D can be quite large for a microphone array in a l","A tutorial on particle filters for online nonlinear/non-Gaussian Bayesian tracking | A parameterfree hedging algorithm | Tracking using explanation-based modeling | Detecting, tracking and interacting | Random projection trees for vector quantization | Robust localization in reverberant rooms. In Microphone arrays: signal processing techniques and applications, page | Coordinate-free calibration of an acoustically driven camera pointing system | Learning the structure of manifolds using random projections | Novel approach to nonlinear/non-Gaussian Bayesian state estimation | Escaping the curse of dimensionality with a tree-based regressor | Particle filter with integrated voice activity detection for acoustic source tracking | Which spatial partition trees are adaptive to intrinsic dimension | Particle filtering algorithms for tracking an acoustic source in a reverberant environment",rejected,000
1003.0746.pdf.json,Automatically Discovering Hidden Transformation Chaining Constraints,"One of the main objectives of Model-Driven Engineering (MDE) is to automatize software engineering tasks such as: the production of code from abstract models in forward engineering scenarios, the production of abstract models from code in reverse engineering scenarios, or a combination of the two previous cases in modernization scenarios. To achieve this automation, MDE relies on precisely defined models that can be processed by a computer. Each model conforms to a metamodel that defines concepts as well as relations between them. For instance, a Java metamodel has the concept of Java class, with the corresponding singlevalued superclass relation (i.e., a class can only extend one other class). Similarly, the UML metamodel defines the concept of a UML class, with a multi-valued generalization relation (i.e., a class may extend several other classes). Many software engineering tasks such as those mentioned above can be performed by model transformations. In order to reduce the effort of writing these transformations, complex tasks are generally not performed by complex transformations but rather by chains of simpler transformations. A model transformation chain is formed by feeding the output of a first transformation as input to second one. Complex chains can consist of a large number of transformations. For instance, in order to analyze a Java model with a Petri net tool, a first transformation may operate from Java to UML, and a second one from UML to Petri net. Model transformations are reusable. In our previous example, if a different target formalism is to be used, the Java to UML transformation may be reused, while the second one is replaced. Some model transformation libraries such as [1] are already available to leverage this possibility. Typically, each entry specifies the name of the transformation as well as its source and target metamodels. Some documentation may also be available. A model-driven engineer confronted to a model transformation problem may ",Language  (ATL)  Library | Constraint Logic Programming using Eclipse | On the unification power of models | Model-Driven Constraint Programming | Rewriting Constraint Models with Metamodels | Applying generic model management to data mapping | The Design of ESSENCE: A Constraint Language for Specifying Combinatorial Problems | The OPL Optimization Programming Language | Atl: a model transformation tool | Km3: a dsl for metamodel specification | On the architectural alignment of atl and qvt | Transforming models with atl | A C++ Implementation of CLP | Constraint Programming Next Challenge: Simplicity of Use | Handbook of Constraint Programming (Foundations of Artificial Intelligence) | Views and Iterators for Generic Constraint Implementations | The Design of COMMA: An Extensible Framework for Mapping Constrained Objects to Native Solver Models | On the use of higher-order model transformations | Measuring model repositories | Typing in Model Management,rejected,000
1003.0789.pdf.json,,,"Danger theory: The link between ais and ids | Early detection of internet worm activity by metering icmp destination unreachable messages | Two ways to grow tissue for artificial immune systems | Stopping spam by extrusion detection | Tending Adam’s Garden : Evolving the Cognitive Immune Self | Death by design: apoptosis, necrosis and autophagy | An innately interesting decade of research in immunology | The Dendritic Cell Algorithm | Introducing dendritic cells as a novel immune-inspired algorithm for anomaly detection | Articulation and clarification of the dendritic cell algorithm | Dendritic cells for anomaly detection | A role for immunology in ”next generation” robot controllers | Architecture for an artificial immune system | Approaching the asymptote? evolution and revolution in immunology | Immunobiology:the immune system in health and disease | Danger is ubiquitous: Detecting malicious activities in sensor networks using the dendritic cell algorithm | Immature, semi-mature and fully mature dendritic cells: which signals induce 20  tolerance or immunity | Tolerance, danger and the extended family | An innate sense of danger | The danger model: A renewed sense of self | Decoding the patterns of self and nonself by the innate immune system | Dendritic cells: the immune information management experts | Emerald: Event monitoring enabling responses to anomalous live disturbances | Snort - lightweight intrusion detection for networks | Fast detection of scanning worm infections | Practical automated detection of stealthy portscans | Grids: A graph-based intrusion detection system for large networks | Integrated Innate and Adaptive Artificial Immune Systems Applied to Process Anomaly Detection | Towards a conceptual framework for innate immunity | libtissue - implementing innate immunity | Mechanisms of apoptosis induced dc suppression",rejected,000
1003.1256.pdf.json,Integrating Innate and Adaptive Immunity for Intrusion Detection,,"Danger Theory: The Link between AIS and IDS? | An innately interesting decade of research in immunology | Approaching the Asymptote? Evolution and Revolution in Immunology. | Introducing Dendritic Cells as a Novel Immune-Inspired Algorithm for Anomaly Detection. | Tolerance, danger and the extended family. | Hypothesizing and Reasoning about Attacks Missed by Intrusion Detection Systems. | Building Attack Scenarios through Integration of Complementary Alert Methods | Jajoda. “An Efficient Unified Approach to Correlating Hypothesising, and Predicting Intrusion Alerts. | Towards a Conceptual Framework for Innate Immunity. | libtissue - implementing innate immunity. | Transforming the Search Space with Gray Coding. | Coverage and Generalization in an Artificial Immune System. | An Architecture for Generating Semantics-Aware Signatures.",rejected,000
1004.2624.pdf.json,Symmetry within Solutions,"Symmetry is an important feature of many combinatorial search problems. To be able to solve such problems, we often need to take account of symmetry. For example, when finding magic squares (prob019 in CSPLib (Gent and Walsh 1999)), we have the symmetries that rotate and reflect the square. Factoring such symmetry out of the search space is often critical when trying to solve large instances of a problem. Up till now, research on symmetry has mostly focused on symmetries between different solutions of the same problem. In this paper, we propose considering in addition the internal symmetries (that is, symmetries within each solution). Whilst it appears to be challenging to identify useful internal symmetries, such symmetries are easy to exploit. We simply add constraints that restrict search to those solutions with the required internal symmetry and limit branching to the subset of decisions that generate a complete solution. We will demonstrate the value of exploiting internal symmetries within solutions with experimental results on two benchmark domains: Van der Waerden numbers and graceful graphs.",and Sais | Backtrack searching in the presence of symmetry | Symmetry definitions for constraint satisfaction problems | Symmetry breaking predicates for search problems | Breaking row and column symmetry in matrix models | Global Constraints for Lexicographic Orderings | 1998 | and Walsh | M | Breaking symmetry of interchangeable variables and values | B | J | General Symmetry Breaking Constraints | Symmetry Breaking using Value Precedence | Breaking Value Symmetry,rejected,000
1004.2626.pdf.json,Propagating Conjunctions of ALLDIFFERENT Constraints,"Global constraints are a critical factor in the success of constraint programming. They capture patterns that often occur in practice (e.g. “these courses must occur at different times”). In addition, fast propagation algorithms are associated with each global constraint to reason about potential solutions (e.g. “these 4 courses have only 3 time slots between them so, by a pigeonhole argument, the problem is infeasible”). One of the oldest and most useful global constraints is the ALLDIFFERENT constraint (Laurière 1978). This specifies that a set of variables takes all different values. Many different algorithms have been proposed for propagating the ALLDIFFERENT constraint (Régin 1994; Leconte 1996; Puget 1998). Such propagators can have a significant impact on our ability to solve problems (Stergiou & Walsh 1999). Problems often contain multiple ALLDIFFERENT constraints (e.g. “The CS courses must occur at different times, as must the IT courses. In addition, CS and IT have several courses in common”). Currently, constraint solvers ignore information about the overlap between multiple constraints (except for the limited communication provided by the domains of common variables). Here, we show the benefits of reasoning about such overlap. This is a challenging problem Copyright c© 2013, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. as finding a solution to just two ALLDIFFERENT constraints is NP-hard (Kutz et al. 2008) and existing approaches to deal with such overlaps require exponential space (Lardeux et al. 2008). Our approach is to focus on domains that are ordered, as often occurs in practice. For example in our time-tabling problem, values might represent times (which are naturally ordered). In such cases, domains can be compactly represented by intervals. Propagation algorithms can narrow such intervals using the notion of bound consistency. Our main result is to prove we can enforce bound consistency on two","Filtering algorithms for the NVALUE | The Parameterized Complexity of Global Constraints | Decompositions of all different, global cardinality and related constraint | Encodings of the Sequence Constraint | Simultaneous matchings: Hardness and approximation | Interleaved Alldifferent Constraints: CSP vs. SAT Approaches | A fast and simple algorithm for bounds consistency of the alldifferent constraint | The difference all-difference makes",rejected,000
1005.1475.pdf.json,,"We are all familiar with games such as Chess or Checkers. Such games are purely rational as they do not involve any element of chance; they are also zero-sum, as the players’ interests are dual: what one “wins”, the other “loses” — which is the origin of the min-max evaluation mechanism. The two fundamental questions to be asked in a rational game are “Who will win?” and “How much will she win?”. Answering such questions involves searching for a strategy trough a (typically large) game tree. Some optimized search techniques were developed, which in the case of combinatorial two-player games include the α-β pruning technique [1,2]. α-β is not an approximated algorithm: its correctness relies on the mutual distributive properties of min and max. In this work we explore the implications of assuming only one player to be rational, breaking the symmetry of the traditional “double-sided” rationality. Quite unsurprisingly our tropical α-pruning depends on just one distributive property, a requirement satisfied by tropical algebras (Section 3). Following the style introduced by [3] and [4], we will distinguish two aspects of two-player combinatorial games: a first one that we call syntactic, consisting This work is partially financed by Marie Curie action n. 29849 Websicola and ANR06-JCJC-0122. The final publication of this paper is available at www.springerlink.com. in a description of the possible game positions and the valid moves leading from a position to another; the game syntax is the formal equivalent of the intuitive notion of the “game rules”. By contrast the semantic aspect is concerned about the interpretation of the game according to the interests of the players, and ultimately about the answer to the two fundamental questions above. Our semantics will be based on tropical algebras, and as a consequence our technique is widely applicable, relying as it does only on their comparatively weak hypotheses. We formally define tropical α-pruning and prove its soundnes",The tree prune (TP) algorithm | An analysis of alpha-beta pruning | Généralisation des Jeux Combinatoires et Applications aux Langages Logiques | Playing logic programs with the alpha-beta algorithm | Alpha-beta pruning under partial orders | First-order term rewriting systems | Confluent reductions: Abstract properties and applications to term rewriting systems: Abstract properties and applications to term rewriting systems | Orthogonality,rejected,000
1005.1518.pdf.json,Recognizability of Individual Creative Style Within and Across Domains: Preliminary Studies,"The therapeutic nature of the creative process is well known. Eminent creators and laypeople alike often claim that through engagement in creative activities they gain a clearer sense of themselves as unique individuals. By making artistic choices, and observing how these choices guide subsequent thoughts about the work, eventually culminating in original, creative form, they acquire selfknowledge, and often, are left with a sense of completeness. The transformation that occurs on canvas or on the written page is said to be mirrored by a sense of personal transformation and self-discovery that occurs within. Artists often find a style that feels as if it is ‘theirs’ only after periods of exploration with different media and established styles and art forms. Similarly, writers speak of transitioning from a stage in which they were merely imitating the styles of authors they admired to a stage in which they discovered their own authentic ‘voice’. This sense of self-discovery may seem to the creator as real as anything he or she has ever experienced, and the transition from merely imitating others to finding one’s own identifiable style is often evident to anyone exposed to an individual’s creative works. But although the phenomenon of recognizable creative style seems obvious to artists themselves, and to those who appreciate what they do, it is not predicted by well-known theories of creativity. This paper presents the results of preliminary experiments designed to test the hypothesis that creative individuals possess a distinctly recognizable creative style, and that this creative style is recognizable not just within a domain but across domains. We begin by discussing by well-known theories of creativity, and how the phenomena of individual style and ‘voice’ are not predicted by them. Three studies are then presented. The first two studies test the hypothesis that the phenomenon of creative style is real; that is, that creative individuals such as artists and write","The case for domain specificity | Blind variation and selective | Is creativity a Darwinian process | Creativity and personality | Genius: The natural history | Conceptual closure: Weaving memories | Ideas are not replicators but minds | Why the creative process is not | The cultural evolution of socially | A model of the emergence | Human problem solving | Information-processing explanations of insight and related phenomena | The mind’s best work | Assessing everyday creativity: Characteristics of the Lifetime Creativity Scales and validation with three large samples | Explaining creativity: The science of human innovation | Donald Campbell's model of the creative process: Creativity as blind variation and selective retention | Creativity as blind variation and selective retention: Is the creative process Darwinian | Origins of genius: Darwinian perspectives on creativity | The creative process in Picasso’s Guernica sketches: Monotonic improvements versus nonmonotonic variants | Rejoinder: Picasso’s Guernica creativity as a Darwinian process: Definitions, clarifications, misconceptions, and applications | Cognitive mechanisms in human creativity: Is variation blind or sighted | Against evolutionary epistomology | Creativity and knowledge: a challenge to theories | An edifice built on sand? Review of Origins of Genius: Darwinian Perspectives on Creativity | Creativity: Understanding innovation in problem solving, science, invention, and the arts | Creativity: Understanding innovation in problem solving, science, invention, and the arts | We are all partly right: Comment on “The creative process in Picasso’s Guernica sketches: Monotonic improvements versus nonmonotonic variants",rejected,000
1005.1716.pdf.json,Heuristics in Conflict Resolution,"The popularity of Answer Set Programming (ASP; (Baral 2003)) as a paradigm for knowledge representation and reasoning is mainly due to two factors: first, its rich modeling language and, second, the availability of highperformance ASP systems. In fact, modern ASP solvers, such as clasp (Gebser et al. 2007a), cmodels (Giunchiglia, Lierler, & Maratea 2006), and smodelscc (Ward & Schlipf 2004), have meanwhile closed the gap to Boolean Satisfiability (SAT; (Mitchell 2005)) solvers. In both fields, conflict-driven learning and related techniques have led to significant performance boosts (Bayardo & Schrag 1997; Marques-Silva & Sakallah 1999; Moskewicz et al. 2001; Gebser et al. 2007d). The basic prerequisite for the application of such techniques is conflict analysis, that is, the extraction of non-trivial reasons for dead ends encountered during search. Even though ASP and SAT solvers exploit different inference patterns, their underlying search techniques are closely related to each other. For instance, the basic search strategy of SAT solver chaff (Moskewicz et al. 2001), nowadays a quasi standard in SAT solving, is also exploited by ASP solver clasp, in particular, the principles of conflict analysis are similar. Vice versa, the solution enumeration approach implemented in clasp (Gebser et al. 2007b) could also be applied by SAT solvers. Given these similarities, general search or, more specifically, conflict analysis techniques developed in one community can (almost) immediately be exploited in the other field too. In this paper, we address the problem of identifying “good” reasons for conflicts to be recorded within an ASP solver. In fact, conflict-driven learning exhibits several degrees of freedom. For instance, several constraints may become violated simultaneously, in which case one can choose the conflict(s) to be analyzed. Furthermore, distinct schemes may be used for conflict analysis, such as the resolutionbased First-UIP and Last-UIP scheme (Zhang et al. 2","Knowledge Representation, Reasoning and Declarative Problem Solving | Using CSP look-back techniques to solve real-world SAT instances | Towards understanding and harnessing the potential of clause learning | Negation as failure | Constraint Processing | A clausebased heuristic for SAT solvers | An extensible SATsolver | Tight logic programs | Consistency of Clark’s completion and the existence of stable models | clasp: A conflict-driven answer set solver | Conflict-driven answer set enumeration | Conflict-driven answer set solving | The first answer set programming system competition | Answer set programming based on propositional satisfiability | BerkMin: A fast and robust SAT solver | A model-theoretic counterpart of loop formulas | Why are there so many loop formulas | ASSAT: computing answer sets of a logic program by SAT solvers | Zchaff2004: An efficient SAT solver | GRASP: A search algorithm for propositional satisfiability | A SAT solver primer | Chaff: Engineering an efficient SAT solver | Efficient algorithms for clause-learning SAT solvers | The wellfounded semantics for general logic programs | Answer set programming with clause learning | Efficient conflict driven learning in a Boolean satisfiability solver",rejected,000
1005.1860.pdf.json,Feature Selection Using Regularization in Approximate Linear Programs for Markov Decision Processes,"Solving large Markov Decision Processes (MDPs) is a very useful, but computationally challenging problem addressed widely by reinforcement learning. It is widely accepted that large MDPs can only be solved approximately. This approximation is commonly done by relying on linear value function approximation, in which the value function is chosen from a small-dimensional vector space of features. While this framework offers computational benefits and protection from the overfitting in the training data, selecting Appearing in Proceedings of the 27 th International Conference on Machine Learning, Haifa, Israel, 2010. Copyright 2010 by the author(s)/owner(s). an effective, small set of features is difficult and requires a deep understanding of the domain. Feature selection, therefore, seeks to automate this process in a way that may preserve the computational simplicity of linear approximation (Parr et al., 2007; Mahadevan, 2008). We show in this paper that L1-regularized approximate linear programs (RALP) can be used with very rich feature spaces. RALP relies, like other value function approximation methods, on samples of the state space. The value function error on states that are not sampled is known as the sampling error. This paper shows that regularization in RALP can guarantee small sampling error. The bounds on the sampling error require somewhat limiting assumptions on the structure of the MDPs, as any guarantees must, but this framework can be used to derive tighter bounds for specific problems in the future. The relatively simple bounds can be used to determine automatically the regularization coefficient to balance the expressivity of the features with the sampling error. We derive the approach with the L1 norm, but it could be used with other regularizations with small modifications. The L1 norm is advantageous for two main reasons. First, the L1 norm encourages the sparse solutions, which can reduce the computational requirements. Second, the L1 norm preser",Dantzig selector homotopy with dynamic measurements | Reinforcement Learning: an Introduction | The Dantzig selector:statistical estimation when p is much larger than n | On constraint sampling for the linear programming approach to approximate dynamic programming | A smoothed approximate linear program | Regularized policy iteration | DASSO: Connections between the Dantzig selector and lasso | Regularization and feature selection in least-squares temporal difference learning | LeastSquares Policy Iteration | Learning representation and control in markov decision processes: New frontiers | Analyzing feature generation for value-function approximation | Constraint Relaxation in Approximate Linear Programs | Learning to drive a bicycle using reinforcement learning and shaping | Generalized polynomial approximations in Markovian decision processes | Kernelized Value Function Approximation for Reinforcement Learning | Regression shrinkage and selection via the LASSO | Linear Programming: Foundations and Extensions | An approach to fuzzy control of nonlinear systems: Stability and design issues,rejected,000
1005.3502.pdf.json,Using machine learning to make constraint solver implementation decisions,"Constraints are a natural, powerful means of representing and reasoning about combinatorial problems that impact all of our lives. Constraint solving is applied successfully in a wide variety of disciplines such as aviation, industrial design, banking, combinatorics and the chemical and steel industries, to name but a few examples. A constraint satisfaction problem (CSP [3]) is a set of decision variables, each with an associated domain of potential values, and a set of constraints. An assignment maps a variable to a value from its domain. Each constraint specifies allowed combinations of assignments of values to a subset of the variables. A solution to a CSP is an assignment to all the variables that satisfies all the constraints. Solutions are typically found for CSPs through systematic search of possible assignments to variables. During search, constraint propagation algorithms are used. These propagators make inferences, usually recorded as domain reductions, based on the domains of the variables constrained and the assignments that satisfy the constraints. If at any point these inferences result in any variable having an empty domain then search backtracks and a new branch is considered. When implementing constraint solvers and modelling constraint problems, many design decision have to be made – for example how much propagation to do, what data structures to use to enable the solver to backtrack and when and how often to check if a constraint is satisfied and which values could be removed. These decisions have so far been made mostly manually. Making the “right” decision often depends on the experience of the person making it. ar X iv :1 00 5. 35 02 v1 [ cs .A I] 1 9 M ay 2 01 0 We approach this problem using machine learning. Given a particular problem, we want to decide automatically which design decisions to make. This improves over the current state of the art in two ways. First, we do not require humans to more or less arbitrarily decide on something they",A gender-based genetic algorithm for the automatic configuration of algorithms | Adaptive constraint satisfaction: The quickest first principle | Constraint Processing | The adaptive constraint engine | Learning when to use lazy learning in constraint solving | Minion: A fast scalable constraint solver | Lazy explanations for constraint propagator | Generalised arc consistency for the alldifferent constraint: An empirical survey | Learning techniques for automatic algorithm portfolio selection | The WEKA data mining software: An update | Performance prediction and automated tuning of randomized and parametric algorithms | SATenstein: Automatically building local search SAT solvers from components | Constraint solvers: An empirical evaluation of design decisions | Reinforcement learning for algorithm selection | XCSP benchmarks | A portfolio approach to algorithm selection | Practical graph isomorphism | Automatically configuring constraint satisfaction programs: A case study | Using casebased reasoning in an algorithm portfolio for constraint solving | A filtering algorithm for constraints of difference in CSPs | The algorithm selection problem | Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations | SATzilla: Portfolio-based algorithm selection for SAT,rejected,000
1005.4025.pdf.json,A SOFT COMPUTING MODEL FOR PHYSICIANS’ DECISION PROCESS,,"Kajaulgi, Computer aided anesthesia | An analysis of diagnostic reasoning: The strategy of intermediate decisions | Lesis, An application of cluster analysis to construction of a diagnostic classification | Application of Fuzzy Sets to System Analysis (Wiley | Fuzzy Sets and System: Theory and Application | Sequential diagnosis by computer | Stephensio. A mathematical approach to medical diagnosis, Jou.Amer | Fuzzy Sets And Fuzzy Logic: Theory and Applications | Jecquez, Diagnosis I: Symptom non independence in mathematical models for diagnosis | Jacquez, Diagnosis, II: Diagnostic models based on attribute clusters. A proposal and comparisons | Artificial Intelligence",rejected,000
1005.4032.pdf.json,Combining Multiple Feature Extraction Techniques for Handwritten Devnagari Character Recognition,,Experiment with various neural Network Architecture for Handwritten Character Recognition | A Handwritten Character Recognition System Using Directional Element Feature and Asymmetric Mahalanobis Distance | A Study of Zernike Moments and its use in Devnagari Handwritten Character Recognition | Recognition of Off-Line Handwritten Devnagari Characters Using Quadratic Classifier | Indian script character recognition: A Survey | A complete printed Bangla OCR system | Machine Recognition of constrained Hand printed Devnagari | Fuzzy Model Based Recognition of Handwritten Hindi Numerals | Devnagari numeral recognition by combining decision of multiple connectionist classifiers | A Study of Zernike Moments and its use in Devnagari Handwritten Character Recognition | Machine Recognition of constrained Hand printed Devnagari | On Recognition of Handwritten Devnagari Numerals | An Introduction to neural Computation | Thinning Algorithms: A critique and new Methodology | Classification Of Gradient Change Features Using MLP for Handwritten Character Recognition | A Novel Approach for Handwritten Devnagari Character Recognition | A Two Stage Classification Approach for Handwritten Devanagari Characters | Vocabulary off-line handwritten word recognition | Handwritten Bangla alphabet recognition using MLP based classifier | Fuzzy Model based recognition of Handwritten Hindi characters | On the Encoding of Arbitrary Geometric Configurations,rejected,000
1005.4272.pdf.json,Inaccuracy Minimization by Partitioning Fuzzy Data Sets – Validation of an Analytical Methodology,,"A new method to forecasting enrollments using fuzzy time series | Forecasting enrollments based on fuzzy time series | Temperature prediction using fuzzy time series | Forecasting enrollments based on high-order fuzzy time series | Effective lengths of intervals to improve forecasting in fuzzy time series | S.M.Chen, C.H.Lee, “Handling forecasting problems using fuzzy time series | M-factor high order fuzzy time series forecasting for road accident data | Multivariate high order fuzzy time series forecasting for car road accidents | L.W.Wang and S.M.Chen, “Handling forecasting problems based on two-factors high-order time series | A dynamic neural network method for time series prediction using the KIII model | Lcland, “Adaptive learning defuzzification techniques and applications | Neural network based fusion of global and local information in predicting time series",rejected,000
1005.4446.pdf.json,,,,rejected,000
1005.4447.pdf.json,,"The research project entitled “Evidence Algorithm” was initiated by V.Glushkov in the early 60-s in Kiev. At that time, some fundamental facts concerning formal proof search and opportunities (potential in most cases) to use computers to find a proof, were already known. The domain that was called “automated theorem proving” (ATP or “machine reasoning” in the AI community) became a challenging one for logicians as well as for computer scientists (see e.g. [92] for short history). There were hopes! Recall the title of an early Hao Wang’s paper: “Towards mechanical mathematics” [104]. V.Glushkov as he personally told us, was motivated by two main reasons: (1) To get an aid while verifying long and routine algebraic transformation (as a working mathematician he obtained valuable results concerning Hilbert’s 5th problem). (2) To try the strength of the existent computers pushing them to run on the limits of their abilities. V.Glushkov formulated the main question in a slightly unusual way. Let us consider some relatively well formalized mathematical theory, e.g. Lie algebras. There are a small number of basic facts (axioms) which are considered to be 3 Below, we explain why this title was chosen; it was used first in [9]. 4 The final publication of this paper is available at www.springerlink.com evident even for beginners. Let’s apply simple purely logical tools to obtain several consequences. They are also evident. Then one can apply the same logical tools to the conclusions and so on. Are the results still evident? If the conclusions were obtained by a programmed inference engine, the answer is “yes, they are”. From the viewpoint of this engine. But probably not from the human point of view. Thus, provided the abovementioned engine, we would be able to prove/verify something that is not evident for humans. Further to that, this “evidence maintaining engine” may be reinforced with heuristics, proof methods, lemma application, definition expansion, and so on. In this wa","Intelligent” machines and the mental activity of a human | On an information language for mathematics | Algorithms and Mathematical Machines | Z | An algorithm for proving theorems in Set theory | Aspects of the development of digital computer architectures in the dependence of computer software systems | Asel’derov. Solving equations in free groups. Abstract of candidate dissertation in Physics and Mathematics, 12 pages, GIC | An algorithm of theorem proving in logical calculi | Some problems in the theory of automata and artificial intelligence | and Z | ANALITIK (algorithmic language for the description of computing processes using analytical transformations) | Asel’derov. The obviousness algorithm | Algorithm and computer experiment for seeking proofs of theorems in the predicate calculus | and Yu | Yu | Asel’derov. A brief review and bibliography of investigations into automation of search of theorem proofs in formal theories | Question of constructing a problem-oriented procedure for the proof of theorems | Use of heuristic procedures in search programs for proofs of theorems (survey) | Relationship between formal language of mathematical theories and axiomatic systems of the theory of sets | Yu | On heuristic procedure for proving theorems from vector spaces | The soundness and completeness of the obviousness algorithm | On the use of axioms of functional reflexivity in P&R refutation procedure | On a calculus of c-clauses | A calculus of c-clauses based on the clash-resolution rule | On the notion of the correctness of a TL-text | On minimal inferences in calculi of c-clauses | Structural processing of mathematical texts | Implementation of dynamic syntax tools for mathematical text processing systems | A monotonic paramodulation strategy | A strict paramodulation strategy | System for processing mathematical texts, Cybernetics and System Analysis, 15(2):209–210 | On a variant of Herbrand theorem | On a procedure of refutation search | On the issue of the construction of refutation procedures for which preliminary skolemization is not obligatory | On the implementation of logical inference procedures in the framework of a mathematical texts processing system | Application of auxiliary propositions in inference search | Refutation search and “natural” proofs | Decidability of the unification problem for second-order languages with unary functional symbols | Data representation in a system for processing of mathematical texts | Formalization of some deduction techniques | Some special tools of Evidence Algorithm for equality handling | The system for automatic theorem proving (SAD) (a brief informal description) | On editing proofs | Basic tools for data processing in an automatic theorem-proving system | Tools for computer-aided processing of mathematical texts | On some tools for the construction of an information environment in a computer-aided proving system | Logical inference in the system for automatic theorem proving, SAD | A variant of Herbrand’s theorem for formulas in prenex form | Equality handling in proof search in theories with the complete set of reductions | Methods and tools for equality handling in machine theorem proving | On a modification of Kanger’s method | Methods of machine proof search in the first-order predicate calculus | On the correctness of mathematical texts and its computer-aided verification | Generating sufficient statements in the SAD system | Strategies of the search for derivation of statements with restricted quantifiers | Deduction-seeking procedures and transitive relations | Equality handling methods for Horn sets | Equality control methods in machine theorem proving | Special strategies for theorem proof search in mathematics and tools for their implementation | Automatic theorem proving | Automatic theorem proving | Gentzen calculi and admissible substitutions | Ju | The Evidence Algorithm’2000 (a project) | Evidence Algorithm and sequent logical inference search | ForTheL — the language of formal theories | Goal-driven inference search in classical propositional logic | Linguistic tools and deductive technique of the System for Automated Deduction | System for Automated Deduction (SAD): Linguistic and deductive peculiarities | Reasoning inside a formula | SAD, a System for Automated Deduction: a current state | Admissible substitutions in sequent calculi | Evidential paradigm: the logical aspect | On verification tools implemented in the System for Automated Deduction | Theorem proving and proof verification in the system SAD | Tableau method with free variables for intuitionistic logic | Sequent forms of Herbrand theorem and their applications | On Herbrand’s theorem for intuitionistic logic | Deductive assistance in an intelligent linguistic environment | and K | Admissible substitutions and Herbrand’s theorems for classical and intuitionistic logics | Methodes de formalisation des connaissances et des raisonnements mathematiques: aspects appliques et theoriques | Reasoning inside a formula and ontological correctness of a formal mathematical text | System for Automated Deduction (SAD): a tool for proof verification | On some problems of efficient inference search in first-order cut-free modal sequent calculi | Herbrand theorems: the classical and intuitionistic cases | Connection tableaux with lazy paramodulation | On correctness of mathematical texts from a logical and practical point of view | On Herbrand-like Theorems for Cut-free Modal Sequent Logics | Proving theorems with the modification method | early history of automated deduction | Mechanical theorem proving in the USSR: The Leningrad school | What is the inverse method | An efficient unification algorithm | Maslov | The first All-union symposium on the problem of machine searching the logical deduction | The design and implementation of VAMPIRE | A machine-oriented logic based on the resolution principle | editors | System Description: E 0.81 | Towards mechanical mathematics | and D",rejected,000
1005.4496.pdf.json,,"An “Intrusion Detection System (IDS)” is a system for detecting intrusions that attempting to misuse the data or computing resources of a computer system. Mostly intrusions are the violation of information security policy. At first IDS was implemented for host-based that located in servers to examine the internal interfaces [1]-[3], but with the evolution of computer networks the focus gradually shifted toward network-based. Network intrusion detection system (NIDS) performs packet logging, real-time traffic analysis of IP network, and tries to discover if an intruder is attempting to break into the system [4]-[6]. Snort is an open source network intrusion detection and prevention system (NIDPS) developed by Sourcefire [7], [8]. Snort performs protocol analysis, content searching/matching, and commonly blocks a variety of intrusions such as buffer overflows, stealth port scans, web application attacks, SMB probes, and OS fingerprinting attempts. Normally, intruders in computer system are classified into two categories like internal and external intruders. Internal intruders are users in the network and have some authority, but seek to gain additional ability to take action without legitimate authorization. External intruders do not have any authorized access to the system that they attack. Two types of detection models: misuse and anomaly are commonly using by IDS. Misuse detection model performs simple pattern matching techniques to match an attack pattern corresponding to known attack patterns in the database and produces very low false positives (FP). Anomaly detection model identifies new attacks by analyzing the anomalous behaviors from normal behaviors [9], and achieves high detection rates (DR) for new attacks, but produces many false positives (FP). Anomaly based IDS generate rules by observing collected audit data that is the records of activities generated by the operating system. Currently adaptive intrusion detection aims to solve the problems of analyzi","An investigation of a compromised host on a honeynet being used to increase the security of a large enterprise network | Host-based intrusion detection using dynamic and static behavioral models | A reinforcement learning approach for host-based intrusion detection using sequences of system calls | The use of honeynets to increase computer network security and user awareness | SVM approach with a genetic algorithm for network intrusion detection | Adaptive network intrusion detection method based on PCA and support vector machines | SNORT: The open source network intrusion system | Building intrusion pattern miner for sonrt network intrusion detection system | A comparative study of anomaly detection schemes in network intrusion detection | Improving intrusion detection system through machine learning | ADAM: Detecting intrusion by data mining | A data mining and CIDF based approach for detecting novel and distributed intrusions | Adaptive Intrusion Detection: A Data Mining Approach | Cost-based modeling and evaluation for data mining with application to fraud and intrusion detection | Naïve Bayes vs. decision trees in intrusion detection systems | Intrusion detection using neural networks and support vector machines | Mining fuzzy association rules and fuzzy frequency episodes for intrusion detection | An ensemble approach to intrusion detection based on improved multi-objective genetic algorithm | Guide to intrusion detection and prevention systems (IDPS) | Multi-sensor agent-based intrusion detection system | Using internal sensors for computer intrusion detection | Intrusion detection systems and multi-sensor data fusion | Robust classification for imprecise environment | Evaluating boosting algorithms to classify rare classes: Comparison and Improvements | Predicting rare classes: can boosting make any weak learner stronger | Automated discovery of concise predictive rules for intrusion detection | Intrusion detection using a hybrid support vector machine based on entropy and TF-IDF | PNrule: a new framework for learning classifier models in data mining (a case-study in network intrusion detection) | Intelligent feature extraction for ensemble of classifiers | In defense of one-vs-all classification | Feature deduction and ensemble design of intrusion detection systems | Ensemble feature selection with the simple Bayesian classification | Identifying important features for intrusion detection using support vector machines and neural networks | Feature selection using multi-objective genetic algorithms for handwritten digit recognition | Identifying key features for intrusion detection using neural networks | A framework for constructing features and models for intrusion detection systems | A Detailed Analysis of the KDD CUP 99 Data Set | Testing intrusion detection systems: a critique of the 1998 and 1999 darpa intrusion detection system evaluations as performed by Lincoln laboratory | Computer security threat monitoring and surveillance | An intrusion detection model | Neumann “Requirement and model for IDES- A real-time intrusion detection system, | An intrusion detection system | A sense of self for Unix processes | Adaptive model-based monitoring for cyber attack detection | Bayesian event classification for intrusion detection | A novel anomaly detection scheme based on principal component classifier | Data mining approaches for intrusion detection | Fuzzy network profiling for intrusion detection",rejected,000
1005.4592.pdf.json,Automated Reasoning and Presentation Support for Formalizing Mathematics in Mizar,"Formal mathematics, in its interactive and verification aspects, and in the automated reasoning aspect, is becoming increasingly well-known, used, and experimented with [10]. Projects like FlySpeck [9], formal proof of the Four Color Theorem [8], verification of tiny (but real) operating systems [12], and the increased use of verification for software and hardware [7], are stimulating the development of interactive verification tools and interactive theorem provers (ITPs). Linked to this is the development of strong automated theorem proving (ATP) systems, used either independently to solve hard problems in suitable domains [14, 17, 3], or integrated with interactive tools [15, 11, 4]. ATP development has also stimulated interesting research in the context of automated reasoning in large theories [16, 34, 21]. The goal of the work presented here is to make formal mathematics and automated reasoning easily accessible to practitioners in these areas, by putting most of the work into their browsers, and providing a very fast (real-time) server-based experience with a number of ATP, ITP, presentation, and AI tools that work ? The final publication of this paper is available at www.springerlink.com ?? Supported by the NWO project “MathWiki a Web-based Collaborative Authoring Environment for Formal Proofs”. ar X iv :1 00 5. 45 92 v1 [ cs .A I] 2 5 M ay 2 well together. This is important for supporting existing users and attracting new users of Mizar, by providing them with an attractive environment for exploring the world of formal reasoning in mathematics. Fast server-based solutions make systems easy to use, to the extent of just “pushing a button” (clicking on a HTML link), rather than having to go through the pains of building an adequate local hardware and software installation, for benefits that might initially not be clear. Server-based solutions are becoming an important part of general computer use, and formal mathematics is no exception. It is not possible to na",,rejected,000
1005.4989.pdf.json,A Formalization of the Turing Test,,,rejected,000
1006.0289.pdf.json,Métodos para la Selección y el Ajuste de Caracterı́sticas en el Problema de la Detección de Spam,,The connectivity sonar: detecting site functionality by structural patterns | An evaluation of Naive Bayesian anti-spam filtering | Using rank propagation and probabilistic counting for linkbased spam detection | A survey of clustering data mining techniques | TREC 2007 Spam Track Overview | Recognizing nepotistic links on the Web | Support vector machines for spam categorization | editors | Spam | A Plan for Spam | Link spam alliances | The weka data mining software: an update | Challenges in web search engines | editors | Data clustering: a review | Tuning Topical Queries through Context Vocabulary Enrichment: A Corpus-based approach | A semi-supervised incremental algorithm to au-  tomatically formulate topical queries | Dynamic Extraction of Topic Descriptors and Discriminators: Towards automatic context-based topic search | A Comparison of Event Models for Naive Bayes Text Classification | Blocking Blog Spam with Language Model Disagreement | Detecting spam web pages through content analysis | Web page classification: Features and algorithms | A bayesian approach to filtering junk E-mail | Machine learning in automated text categorization | Identifying link farm spam pages | An evaluation of statistical spam filtering techniques,rejected,000
1006.0385.pdf.json,Brain-Like Stochastic Search:,"Evolutionary computing is probably the lead technology today for finding global minima or maxima to a function U(u). Of course, there are many forms of evolutionary computing. There are also classical methods, like Gibbs search and the sophisticated trust region approaches recently developed by Barhen et al and used on the Desert Storm tank routing problem. There are a few neural net designs (like Kohonen nets, but not Hopfield nets) which have had competitive performance on some specialized large-scale optimization problems. On the other had, it is hard to believe that the human brain uses these kinds of algorithms directly in making complex, novel decisions. As a result, many people doing basic research in neural networks have essentially ignored the need for this kind of systematic stochastic search. Some kinds of stochastic exploration methods have been developed (e.g., see Thrun in White and Sofge, 1992), but nothing with the kind of complexity and richness one finds in the evolutionary computation literature. The neural network field, in turn, still pays a lead role in developing the kind of highly functional network models which, in my view, are the only models which have a serious chance of eventually explaining the functional power of biological neural networks. (See Werbos in Pribram 1998.) More recent work on neural networks suggests that this is a major omission – that greater attention to stochastic search will be a necessary part of replicating or understanding the higher-order intelligence that we find even in the lowest of mammal brains. Because this goal is a major goal for research sponsored at NSF, we are changing our priorities in the Control, Network and Computational Intelligence (CNCI) program to encourage research in this topic, and to encourage several related topics. Section 2 of this paper will discuss those other, related topics, and will discuss my general reasoning here. From a practical viewpoint, BLiSS offers a number of obvious advan","Neural network design for J function approximation in dynamic programming, xxx.lanl.gov/abs/adap-org/9806001 | The Roots of Backpropagation, Wiley",rejected,000
1006.0991.pdf.json,Variational Program Inference,,On distribution-free lower confidence limits for the mean of a nonnegative random variable | An Introduction to Variational Methods for Graphical Models | Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference,rejected,000
1006.1190.pdf.json,,"There are many kinds of Information system and have been implemented in many sector. They are come in all shapes and sizes and interweave one and others, no matter what management level use that information system. Indeed there are some information system have been designed as management level’s need. They are such as: 1) Geographic Information system 2) Sale Information System 3) New Student Information system 4) Hospital Information system 5) Executive Information System 6) Etc They use information system for their naming although there are some which do not use information system for their naming like Decision Support System, Expert System, Transactional Processing system and etc[1]. Whatever the names, use information system name or not, they are part of information system. They can be called sub information system which can make collaboration each others as one information system to deliver the best information system services. Each of Information sector has their own specific character as a definition for each of sector. Example if we talk about Geographic Information system then will be associated with map. If we talk about hospital information system then will be associated with healthcare industry and if we talk about Sale information system then will be associated with selling. The same as if we talk about Game Information System then will be associated with game. 2. PROBLEM DEFINITION Information system is an arrangement of people, data, processes, and information technology that interact to collect, process, store, and provide as output the information needed to support an organization [4]. There are many information systems which become sub information system that will collaborate one and others in one information system. They are : 1) TPS (Transactional Processing System) 2) SCM (Supply Chain Management) 3) CRM (Customer Relationship Management) 4) OLTP (Online Transactional Processing) 5) ES (Expert System) 6) EIS (Executive Information System) 7) MIS","Object Oriented Systems Analysis and Design using UML, 2nd | Game Design Foundations, Wordware Publishing, Inc, Texas, USA | Teach yourself Games Programming | Virtual Information system on Working area | Multimedia; Making it Work,6th | Virtual Humans : a build-it-yourself kit, complete with software and stepby-step instructions, Amacom, New York,USA | Strategic planning for Information Systems,3rd,John | Dr. Tanya Byron’s report on games and children will be revealed today, recommending movie-style ratings for games released in the UK,Next Generation interactive entertainment today | Visualing Electronic Data Interchange(EDI) and Virtual Information System (VIS) for Manipal Institutions | Virtual Libraries : Their potential for less developed Countries | The Game Focus diamond, Mark’s Glog on Game design and game development | The Effect of rewards, Mark’s Glog on Game design and game development | More about rewards, Mark’s Glog on Game design and game development",rejected,000
1006.1407.pdf.json,"Begin, After, and Later: a Maximal Decidable Interval Temporal Logic","Interval temporal logics (ITLs) are logics for reasoning about temporal statements expressed over intervals instead of points. The most famous ITL studied so far is probably Halpern and Shoham’s HS [6], which is the logic of (the thirteen) Allen’s interval relations between intervals [1]. It features a modal operator for each relation, that is after (〈A〉) (also called meets), begins (〈B〉), ends (〈E〉), overlaps (〈O〉), during (〈D〉), later (〈L〉), and their inverses (denoted by 〈X〉, where 〈X〉 is a modal operator), although some of them are definable in terms of others. Since HS is undecidable when interpreted over almost all interesting classes of linearly ordered sets, it is natural to ask whether there exist decidable fragments of it, and how the properties of the underlying linearly ordered domain can influence its decidable/undecidable status. In the literature, the classes of linear orderings that have received more attention are i) the class of all linearly ordered sets, ii) the set of all discrete linearly ordered sets, iii) the class of all dense linearly ordered sets. In the second case one can also distinguish among strong discreteness (i.e., N,Z-like), and weak discreteness (which allows non-standard models such as N+Z). In recent years, a number of papers have been published in which new, sometimes unexpected, decidable and undecidable fragments are presented. Among them, we mention the fragment AA, also known as PNL, presented in [4], and studied also in [3], which is decidable over all interesting classes of models; and the fragment ABB (and, by symmetry, AEE) which is decidable when interpreted over natural numbers [9]. Interestingly enough, the extension ABBA (and AEEA) turns out to be decidable only when finite models are considered, and undecidable as soon as an infinite ascending (resp., descending) chain is admitted ∗This research was partly supported by the EU project FP7-ICT-223844 CON4COORD, by the Spanish-South African project HS2008-0006, by the","Maintaining Knowledge About Temporal Intervals | Decidable and Undecidable Fragments of Halpern and Shoham’s Interval Temporal Logic: towards a complete classification.  88  Begin, After, and Later: a Maximal Decidable Interval Temporal Logic In: Proceedings of the 15th International Conference on Logic for Programming, Artificial Intelligence, and Reasoning (LPAR), Lecture Notes in Computer Science 5330 | Propositional Interval Neighborhood Logics: expressiveness, decidability, and undecidable extensions | Propositional Interval Neighborhood Temporal Logics | A Road Map of Interval Temporal Logics and Duration Calculi | A Propositional Modal Logic of Time Intervals | Maximal decidable fragments of Halpern and Shoham’s modal logic of intervals | Decidability of the Interval Temporal Logic ABB Over the Natural Numbers | Decidability of the Interval Temporal Logic ABB on Natural Numbers | The Convenience of Tilings",rejected,000
1006.1434.pdf.json,Computing by Means of Physics-Based Optical Neural Networks,"About two decades ago, Optical Computing and Optical Neural Networks were the subjects of intense research interest.[1][2][3] They were seen as possible solutions to the expected limits of Moore´ s Law. However, several problems, such as slow learning speed, high component costs, and the pushing back of the Moore´ s limit by more conventional technology caused interest to fade. New technology is enabling the development of the next generation of optical computing devices. This new technology is largely driven by the explosion in optical communications. The hardware component costs have been reduced, speed has increased, and power requirements reduced. Within the past few years, very fast optical neural network learning algorithms have been developed, called Fixed Weight Learning Neural Networks (FWL-NNs).[4][5][6] We expect that interest in optical computing and optical neural networks will increase, especially since the Moore´ s Law limit seems to have been reached by conventional chip-making technology.[7] The new optical technology should allow a speed about 10,000 times faster than a high-end laptop computer, with projected component costs only about 10 times the cost of the laptop. Our work is at the level of research, design, and development of prototype optical hardware computing systems and development of Fixed-Weight Learning concepts . We have uncovered some difficulties and opportunities that we believe could be addressed by the Computational Modeling community. This paper reports on our work on a prototype Optical Fixed-Weight Learning Neural Network that we are developing. We will indicate some of the new technology used in our device. Next, we will present Fixed-Weight Learning results from previous experiments on optical hardware. Finally, we describe some of the problems encountered, and point out where we believe cross-boundary, interdisciplinary research opportunities exist.","Optical Neural Computers | Operational Parameters of an Opto-Electronic Neural Network Employing Fixed-Planar Holographic Interconnects | Parallel N4 weighted optical interconnections | Fixed-Weight Learning Neural Networks on Optical Hardware | Learning at the Speed of Light: A New Type of Optical Neural Network | Adaptive Behavior with Fixed Weights in RNN: An Overview | Introduction to Fourier Optics | FPGA-Based Stochastic Neural Networks Implementation | Learning algorithms and fixed dynamics | Neural Networks and Analog Computation: Beyond the Turing Limit | Neural Networks, Approximation Theory, and Finite Precision Computation | Neural and Super-Turing Computing",rejected,000
1006.1512.pdf.json,The Deterministic Dendritic Cell Algorithm,,"Danger theory: The link between AIS and IDS | DCA for detecting bots | The Dendritic Cell Algorithm | Introducing Dendritic Cells as a novel immuneinspired algorithm for anomaly detection | The DCA-SOMe comparison: A comparative study between two biologically-inspired algorithms | Information fusion for anomaly detection with the DCA | Articulation and clarification of the Dendritic Cell Algorithm | Dendritic cells for anomaly detection | Improving the reliability of real-time embedded systems using innate immune techniques | Immature, semi-mature and fully mature dendritic cells: which signals induce tolerance or immunity | The application of a dendritic cell algorithm to a robotic classifier | Frequency analysis for dendritic cell population tuning: Decimating the dendritic cell",rejected,000
1006.1518.pdf.json,,,"Danger theory: The link between AIS and IDS | Combining Self-Organizing Map Algorithms for 16  Robust and Scalable Intrusion Detection | RT-UNNID: A practical solution to real-time network-based 19  intrusion detection using unsupervised neural networks | Detection and characterization of port scan attacks | Coverage and generaliszation in an artificial immune 22  system | Extrusion Detection: Security Monitoring for Internal Intrusions | Two ways to grow tissue for artificial immune systems | Network-Based Intrusion Detection | Poseidon: a 2-tier anomaly-based network intrusion detection system | Incorporating soft computing techniques into a probabilitistic intrusion detection system | Anomaly Detection of Computer Usage Using Artificial Intelligence Techniques | Immunology: A Short Course | Introduction to neural networks | Artificial Immune Systems: A New Computational Approach. Springer-Verlag, 39  London | Attack Characterization and Intrusion Detection using an Ensemble of Self-Organizing Maps | Ciliz. An intelligent intrusion detection system (IDS) for 42  anomaly and misuse detection in computer networks | Self-nonself discrimination in a computer | A neural network approach towards intrusion 47  detection | Computer Security | Neuro-immune and self-organizing map approaches to anomaly detection: 50  A comparison | Anomaly detection using real-valued negative selection | Discriminating and visualizing anomalies 54  using negative selection and self-organizing maps | The Dendritic Cell Algorithm | Dendritic cells for syn scan detection | Introducing Dendritic Cells as a novel immune-inspired algo3 rithm for anomaly detection | Information fusion for anomaly detection with the dca | Articulation and clarification of the dendritic cell algorithm | Dendritic cells for anomaly detection | A hierarchical SOM-based intrusion detection system | An Introduction to Modern Nonparametric Statistics | Intrusion detection using sequences of system calls | Immunity by design | Computer network user behaviour visualization using self organizing maps | Intrusion Detection with Neural Networks–Combination of Self-Organizing Maps and Radial Basis Function Networks for Human Expert Integration | Real-valued negative selection algorithm with variable-sized detectors | Hybrid neural networks for intrusion detection system | Fast portscan detection using sequential hypothesis 28  testing | Jessell. Principles of Neural Science. McGraw-Hill/Appleton | On the capability of an SOM based intrusion detection system | Analysis of Three Intrusion Detection System Benchmark Datasets 33  Using Machine Learning Algorithms | System approach to intrusion detection using hidden Markov model | Evaluating negative selection in an artificial immune system for network intrusion 38  detection | Immune system approaches to intrusion detection - a review | Automatic formation of topological maps of patterns in a self-organizing system | Self-Organizing Maps | The self-organizing map | Training a neural-network based intrusion detector to recognizenovel attacks. Systems, Man and Cybernetics, Part A | Network intrusion detection using an improved competitive learning neural 47  network | Dynamic intrusion detection using self 50  organizing maps | Immature, semi-mature and fully mature dendritic cells: which signals induce 52  tolerance or immunity | Tolerance, danger and the extended family | Friendly and dangerous signals: is the tissue in control | Collaborative intrusion detection system | Janeway’s Immunobiology | The application of a dendritic cell 3 algorithm to a robotic classifier | Frequency analysis for dendritic cell population tuning: Decimating the dendritic cell | Detecting Anomalous Network Traffic with Self-organizing 7 Maps | Multiple self-organizing maps for intrusion detection | Neural Computation and Self-Organizing Maps; An Introduction. 11  Addison-Wesley Longman Publishing Co., Inc | Snort - lightweight intrusion detection for networks | Min-max hyperellipsoidal clustering for anomaly detection in network security. Systems, Man and Cybernetics, Part B | Hierarchical Kohonenen net for anomaly detection in network 16  security | Panel on the future of biologically-inspired security: Is there anything left to learn | Inflammatory mediators are insufficient for full dendritic cell activation and 21  promote expansion of cd4+ t cell populations lacking helper function | Practical automated detection of stealthy portscans | Is negative selection appropriate for anomaly detection | Artificial immune systems for IT-security | On permutation masks in hamming negative selection | Artificial immune systems: today and tomorrow | Integrated Innate and Adaptive Artificial Immune Systems Applied to Process Anomaly 31  Detection | Towards a conceptual framework for innate immunity | libtissue - implementing innate immunity | Profiling program behavior for anomaly intrusion detection based on the transition and frequency property of computer audit data | Mechanisms of apoptosis induced DC suppression | Visualizing windows executable viruses using self-organizing maps",rejected,000
1006.1526.pdf.json,The Motif Tracking Algorithm,,"A Dynamic Artificial Neural Network Model for Forecasting Time Series Events | Forecasting with Artificial Neural Networks: The State of the Art | Stock Market Prediction | Genetic Algorithms and Genetic Programming in Computational Finance | The Application of Antigenic Search Techniques to Time Series Forecasting | The Immune System as a Model for Pattern Recognition and Classification | Learning and Optimization Using the Clonal Selection Principle | AINE: An Immunological Approach to Data Mining | Finding Motifs in Time Series | Detecting Motifs in System Call Sequences | CD4+ T-cell memory, CD45R Subsets and the Persistence of Antigen - a Unifying Concept | A Fast Look Up Algorithm for Detecting Repetitive DNA Sequences | A Method for Fast Database Search for all K-Nucleotide Repeats | Combinatorial Pattern Discovery in Biological Sequences: TEIRESIAS | A Probabilistic Approach to Fast Pattern Matching in Time Series Databases | Fast Subsequence Matching in Time Series Databases | Pattern Modelling in Time Series Forecasting | Probabilistic Discovery of Time Series Motifs | Visualizing and Discovering Non Trivial Patterns in Large Time Series Databases | A Symbolic Representation of Time Series, with Implications for Streaming Algorithms | Modelling Immune Memory for Prediction and Computation | Immunology for Physicists | Immune Networks: An Example of Complex Adaptive Systems | Cell Death and the Maintenance of Immunological Memory | Predictive Control Using Fuzzy Models Applied to a Steam Generating Unit. Submitted for publication FLINS 98 third international workshop on fuzzy logic and intelligent technologies for nuclear science and industry | Nonlinear Control Oriented Boiler Modeling, A Benchamrk Problem for Controller Design | On the Need for Time Series Data Mining Benchmarks: A Survey and Empirical Demonstration. Data Mining and Knowledge Discovery, Volume 7, Number 4 / October | Finding Suprising Patterns in a Time Series Database in Linear Time and Space",rejected,000
1006.1537.pdf.json,New Worst-Case Upper Bound for #2-SAT and #3-SAT with the Number of Clauses as the Parameter,,Algorithms and complexity results for #SAT and Bayesian inference | Counting satisfying assignments in 2-SAT and 3-SAT | New upper bound for the #3SAT problem | An improved O(1.234)-time deterministic algorithm for SAT | Algorithms for counting 2-SAT solutions and colorings with applications,rejected,000
1006.1563.pdf.json,,,"REMUS: A security-enhanced operating system | An intrusion-detection model | The interleukin-1 receptor/toll-like receptor superfamily: signal transduction during inflammation and host defense | Challenging the Anomaly Detection Paradigm A provocative discussion | The role of suspicion in model-based intrusion detection | Self-Organizing Maps | Tolerance, danger, and the extended family | Use of diversity as a defense mechanism | Locality: a new paradigm for thinking about normal behavior and outsider threat | Don’t Touch Me, I’m Fine: Robot Autonomy Using an Artificial Innate Immune System | Network intrusion visualization with NIVA, an intrusion detection visual analyzer with haptic integration | Security meter: a practical decisiontree model to quantify risk | Risk: A good system security measure | Integrated Innate and Adaptive Artificial Immune Systems applied to Process Anomaly Detection",rejected,000
1006.1568.pdf.json,Towards a conceptual framework for innate immunity,,"Innate immunity | An innately interesting decade of research in immunology | Immune system approaches to intrusion detection - a review | Artificial Immune Systems: A New Computation Intelligence Approach | Conceptual frameworks for artificial immune systems | Innate immune recognition | Immunobiology | Molecular Biology of the Cell | Molecular Cell Biology | In search of the ‘missing self ’: MHC molecules and NK cell recognition | MHC-dependent antigen processing and peptide presentation: Providing ligands for T lymphocyte activation | Viral immune evasion strategies and the underlying cell biology | Natural killer cell receptor signaling | Dendritic-cell control of pathogen-driven T-cell polarization | Toll-like receptors and dendritic cells: from whom the bug tolls | Lipopolysaccharides from distinct pathogens induce different classes of immune responses in vivo | Consensual immunity: success-driven development of Thelper-1 and T-helper-2 responses | No driving without a license | Activation rules: the two-signal theories of immune activation | The anatomy of T-cell activation and tolerance | Self-representation in the thymus: an extended view | Constitutive presentation of a natural tissue autoantigen exclusively by dendritic cells in the draining lymph node | Inflammatory mediators are insufficient for full dendritic cell activation and promote expansion of CD4+ T cell populations lacking helper functions | Immature, semi-mature and fully mature dendritic cells: which signals induce tolerance or immunity | Induction of tolerogenic DCs: ‘you are what you eat | The B7-CD28 superfamily | The B7 family of ligands and its receptors: new pathways for costimulation and inhibition of immune responses | Exploiting parallelism inherent in AIRS, an artificial immune classifier | Artificial innate immune system: An instant defence layer of embryonics | Integration of immune models using petri nets",rejected,000
1006.2743.pdf.json,Global Optimization for Value Function Approximation Global Optimization for Value Function Approximation,,"Learning vehicular dynamics, with application to modeling helicopters | A price-directed approach to stochastic inventory/routing | Dynamic Programming | Bilinear separation of two sets in n-space | Temporal differences-based policy iteration and applications in neuro-dynamic programming | Bidimensional packing by bilinear programming | The Linear Programming Approach to Approximate Dynamic Programming: Theory and Application | The linear programming approach to approximate dynamic programming | On constraint sampling in the linear programming approach to approximate dynamic programming | Efficient solution algorithms for factored MDPs | Global optimization: Deterministic approaches | Least-squares policy iteration | The linear complementarity problem as a separable bilinear program | Error bounds for approximate policy iteration | Anytime coordination using separable bilinear programs",rejected,000
1006.2844.pdf.json,Outrepasser les limites des techniques classiques de Prise d’Empreintes grâce aux Réseaux de Neurones,"Le problème de la détection à distance du système d’exploitation, aussi appelé OS Fingerprinting (prise d’empreintes), est une étape cruciale d’un test de pénétration, puisque l’attaquant (professionnel de la sécurité, consultant ou hacker) a besoin de connâıtre l’OS de la machine cible afin de choisir les exploits qu’il va utiliser. La détection d’OS est accomplie en sniffant de façon passive des paquets réseau et en envoyant de façon active des paquets de test à la machine cible, pour étudier des variations spécifiques dans les réponses qui révèlent son système d’exploitation. Les premières implémentations de prise d’empreintes étaient basées sur l’analyse des différences entre les implémentations de la pile TCP/IP. La génération suivante utilisa des données de la couche d’applications, tels que les endpoints DCE RPC. Bien que l’analyse porte sur plus d’information, quelque variation de l’algorithme consistant à chercher le point le plus proche (“best fit”) est toujours utilisée pour interpréter cette information. Cette stratégie a plusieurs défauts : elle ne va pas marcher dans des situations non standard, et ne permet pas d’extraire les éléments clefs qui identifient de façon unique un système d’exploitation. Nous pensons que le prochain pas est de travailler sur les techniques utilisées pour analyser les données. Notre nouvelle approche se base sur l’analyse de la composition de l’information relevée durant le processus d’identification du système pour découvrir les éléments clef et leurs relations. Pour implémenter cette approche, nous avons développé des outils qui utilisent des réseaux de neurones et des techniques des domaines de l’Intelligence Artificielle et les Statistiques. Ces outils ont été intégrés avec succès dans un software commercial (Core Impact).","Neural Networks for Pattern Recognition | Practical Neural Network Recipes in C++ | Neural Networks : A Comprehensive Foundation, Prentice Hall, 2nd edition | TCP/IP Illustrated",rejected,000
1006.2899.pdf.json,Approximated Structured Prediction for Learning Large Scale Graphical Models,,"Convex Analysis and Optimization | Convex analysis | Relaxation methods for problems with strictly convex separable costs and linear constraints | Graphical models, exponential families, and variational inference",rejected,000
1006.3021.pdf.json,A General Framework for Equivalences in Answer-Set Programming by Countermodels in the Logic of Here-and-There ∗,"Answer-Set Programming (ASP) is a fundamental paradigm for nonmonotonic knowledge representation (Baral 2003) that encompasses logic programming under the answer-set semantics. It is distinguished by a purely declarative semantics and efficient solvers, such ∗ A preliminary version of this work appeared in the Proceedings of the 24th International Conference on Logic Programming (ICLP), M. Garcia de la Banda and E. Pontelli (Eds.), LNCS 5366, pp. 99–113, Springer, 2008. as, e.g., DLV (Leone et al. 2006), Smodels (Simons et al. 2002), clasp (Gebser et al. 2007), GnT (Janhunen and Niemelä 2004), and ASSAT (Lin and Zhao 2004). Initially providing a semantics for rules with default negation in the body, the answer-set semantics (or stablemodel semantics) (Gelfond and Lifschitz 1991) has been continually extended in terms of expressiveness and syntactic freedom. Starting with disjunctive rules, allowing for disjunctions in rule heads, negation in rule heads was considered and the development continued by allowing nested expressions, i.e., implication-free propositional formulas in the head and the body. Eventually, arbitrary propositional theories were given a non-classical minimal model semantics as their answer sets, which has recently been lifted to a general answer-set semantics for first-order theories (Ferraris et al. 2007). In a different line of research, the restriction to Herbrand domains for programs with variables, i.e., non-ground programs, has been relaxed in order to cope with open domains (Heymans et al. 2007), which is desirable for certain applications, e.g., in conceptual modelling and Semantic Web reasoning. The resulting open answer-set semantics has been further generalized by dropping the unique names assumption (Heymans et al. 2008) for application settings where it does not apply, for instance, when combining ontologies with nonmontonic rules (de Bruijn et al. 2007). As for a logical characterization of the answer-set semantics, the logic of Her",,rejected,000
1006.3035.pdf.json,,"Weighted logic programming is a technique that can be used to declaratively specify dynamic programming algorithms in a number of fields such as natural language processing (Manning and Schütze 1999) and computational biology (Durbin et al. 1998). Weighted logic programming is a generalization of bottom-up logic programming where each proof is assigned a score (or weight) that is a function of the scores of the axioms used in the proof. When these scores are interpreted as probabilities, then the solution to a whole weighted logic program can be interpreted in terms of probabilistic reasoning about unknowns, implying that the weighted logic program implements probabilistic inference.1 ∗ To appear in Theory and Practice of Logic Programming (TPLP). 1 The word inference has a distinct meaning in logic programming (e.g. “inference rule,” “valid in- ference”), and so we will attempt to avoid confusion by using the probabilistic modifier whenever we are talking about probabilistic reasoning about unknowns. ar X iv :1 00 6. 30 35 v1 [ cs .A I] 1 5 Ju Even though weighted logic programming is not limited to probabilistic inference, it is worth detailing their relationship. Let I, A, and P be random variables, where the values of I and A are known and the value of P is not known. Often there is a correspondence where • I corresponds to a conditional “input,” encoded as axioms, known to be true; • A corresponds to a set of axioms known to be true; and • P corresponds to a deductive proof of the goal theorem using the axioms. In the setting of weighted logic programming, there may be many different proofs of the goal given the set of axioms. We must therefore distinguish the weighted logic program from the “world” we are reasoning about in which these many different proofs of the goal correspond to different, mutually exclusive events, each of which has some probability of occurring. Weighted logic programming implements probabilistic inference over the value of the proof ra",,rejected,000
1006.3215.pdf.json,Solving Functional Constraints by Variable Substitution,"Functional constraints are a common class of constraints occurring in Constraint Satisfaction Problem(s) (CSP) (Stallman and Sussman 1977; Van Hentenryck et al. 1992; Kirousis 1993). Roughly speaking, a constraint c(x, y) is functional if the value of variable y is some function of the value of variable x (see Definition 1). Functional constraints arise in two ways, they may occur quite naturally since one may have “functions” or “equations” in the constraint model. Functional constraints also occur systematically in in Constraint Programming (CP) when the system is a Constraint Logic Programming (CLP) system. Functional constraints arise naturally in CLP in two ways. Firstly, the equations which arise from matching the head of a rule with an atom in the body are functional constraints. Secondly, the basic (or primitive) constraints in a particular instance of a CLP language will often include functional constraints. Consider, one of the most widely used and successful constraint domains for CLP, namely, finite domains which we will call CLP(FD). The basic constraints in a CLP(FD) system, for example, CHIP (Van Hentenryck et al. 1992), can express functional constraints. An example would be the finite domain constraint, 3X + 2Y = 10, with finite domain variables for X and Y .1 Matching the head and body, gives rise to a number of equations, and in a FD system, the equations are functional constraints. For example, when matching p(Z2+1) with a rule on p(X) where both X and Z are finite domain variables, a functional constraint X = Z2+1 is produced.2 We remark that in logic programming, the equations are solved by unification but in the general setting, constraint solving over the particular domain is required. Recognizing and exploiting functional constraints can facilitate the development of more efficient constraint solvers for CLP systems. Most work on solving functional constraints follows the approach in CSP which is based on arc or path consistency (Van Hentenr",A labelling arc consistency method for functional constraints | An optimal coarse-grained arc consistency algorithm | Linear equation solving for constraint logic programming | Characterizing tractable constraints | Using pivot consistency to decompose and solve functional CSPs | Bucket elimination: A unifying framework for reasoning | A practically efficient and almost linear unification algorithm | Constraint Logic Programming | The CLP(R) language and system | Fast parallel constraint satisfaction | Increasing functional constraints need to be checked only once | Linear unification | Views and iterators for generic constraint implementations | Forward reasoning and dependency-directed backtracking in a system for computer-aided circuit analysis | A generic arc-consistency algorithm and its specializations | Incrementally solving functional constraints | Functional elimination and 0/1/all constraints | Efficient algorithms for functional constraints,rejected,000
1006.4035.pdf.json,TOWARDS THE DEVELOPMENT OF A SIMULATOR FOR INVESTIGATING THE IMPACT OF PEOPLE MANAGEMENT PRACTICES ON RETAIL PERFORMANCE,"The retail sector has been identified as one of the biggest contributors to the productivity gap that persists between the UK and other countries, in particular France, Germany and the USA (Reynolds et al, 2005). UK retail productivity measures paint a worrying picture, describing lower levels of efficiency than what we would expect (Department of Trade and Industry, 2003), and in particular lower than the benchmark countries already stated. Researchers have so far failed to explain fully the reasons accounting for the productivity gap, and management practices provide a valid and thoughtful way of looking at the problem. The analysis of management practices across different contexts has attempted to explain differences in organisational productivity and performance (for a review see Wall and Wood, 2005). A recent report on UK productivity asserted that “... the key to productivity remains what happens inside the firm and this is something of a ‘black box’…” (Delbridge et al, 2006). Siebers and colleagues conducted a comprehensive literature review of this research area to assess linkages between management practices and organisational productivity (Siebers et al, 2008). The authors concluded that management practices are multidimensional constructs that generally do not demonstrate a straightforward relationship with productivity variables. Empirical evidence affirms that both management practices and productivity measures must be context specific to be effective. Management practices need to be tailored to the particular organisation and the working environment, whereas productivity indices must also reflect a particular organisation’s activities on a local level to be a valid indicator of performance. It is challenging work to try and delineate the effects of management practices from other socially embedded factors. Most Operations Research (OR) methods can be applied as analytical tools once management practices have been implemented, however they are not very ","A queuing control model for retail services having back room operations and cross-trained workers | The impact of human resource and operational management practices on company productivity: A longitudinal study | Agent-based modeling: Methods and techniques for simulating human systems | An international survey of the use and effectiveness of modern manufacturing practices. Human Factors and Ergonomics in Manufacturing 12:171-191 | An agent-based model of a corrugated-box factory: The trade-off between finished goods stock and on-time-in-full delivery | The American customer satisfaction index: Nature, purpose, and findings | Using DEA and simulation in guiding operating units to improved performance | Behaviour in commons dilemmas: Homo Economicus and Homo Psychologicus in an ecological-economic model. Ecological Economics | Fashions, habits and changing preferences: Simulation of psychological factors affecting market dynamics | Pedestrian behaviour modelling: An application to retail movements using a genetic algorithm | Real-world market representation with agents: Modeling the electricity market as a complex adaptive system with an agent-based approach | Sociology and simulation: Statistical and qualitative crossvalidation | Agent-based modeling vs. equation-based modeling: A case study and users’ guide | System dynamics and intelligent agent-based simulation: Where is the synergy | BDI agents: From theory to practice | Modellierung und Analyse individuellen Konsumentenverhaltens mit probabilistischen Holonen | Agent-based interaction analysis of consumer behaviour | SimMarket: Multi-agent based customer simulation and decision support for category management | Enhancing productivity: The role of management practices in closing the productivity gap | Using intelligent agents to understand management practices and retail productivity | Modelling and simulating retail management practices: A first approach. International Journal of Simulation and Process Modelling, accepted for publication | Romance of human resource management and business performance and the case for big science. Human Relations 58:429-462",rejected,000
1006.4039.pdf.json,,"Online learning has emerged as an attractive and dominant paradigm in machine learning given the ever increasing amounts of data that is being increasing collected everyday. However, the key underlying assumption here is that all the training data is available at a central location. For many applications this is not the case. For instance, sensor networks may be deployed in rain forests and collect data autonomously. The cost of transmitting the data to a central server can be prohibitively high. Similarly, banks collect credit information about their customers but might not share the information with other financial institutions. Similar privacy concerns might prevent sharing of patient records across hospitals. Our aim in this paper is to devise an online learning algorithm which can work in the distributed data setting. Some research effort has been devoted to this problem recently. For instance, [1] cast many machine learning problems as a regularized risk minimization problem. Since the empirical risk is computed by averaging the loss over the entire data set, one can design a decentralized algorithm by letting individual slave processors take charge of a portion of the data. At every iteration, the master communicates the current parameter vector to all the slaves, and they in turn compute the loss and its gradient on the part of the data they own and communicate it back to the master. However, as [1] observe, when the number of processors increases Amdahls law [2] kicks in and the cost of communicating and synchronizing becomes prohibitively expensive. Another notable effort is the work by [3], where they show that one can avoid the expensive synchronization step above. The key idea here is that the slaves periodically poll the master node to receive the latest parameter vector. This is used to compute stochastic gradients which are then fed back to the master node. Even though the gradients received by the master may be out of sync, that is, it may not be co",Bundle methods for regularized risk minimization | Validity of the single processor approach to achieving large-scale computing capabilities | Slow learners are fast | Convex Analysis and Minimization Algorithms | Tracking the best linear predictor | Monte Carlo strategies in scientific computing | Online convex programming and generalised infinitesimal gradient ascent | Logarithmic regret algorithms for online convex optimization | Distributed subgradient methods for multi-agent optimization | Subgradient Methods for Convex Minimization | Mirror descent and nonlinear projected subgradient methods for convex optimization | Logarithmic regret algorithms for strongly convex repeated games | Relative loss bounds for on-line density estimation with the exponential family of distributions | Parallel Optimization | Convergence rate of incremental subgradient algorithms | Robust probabilistic inference in distributed systems | Constrained consensus and optimization in multiagent networks,rejected,000
1006.4540.pdf.json,A Novel Rough Set Reduct Algorithm for Medical Domain Based on Bee Colony Optimization,"HE main goal of feature selection is to find a minimal feature subset from a problem domain with high accuracy in representing the original features [4]. In real world problems feature selection is an important process must due to the abundance of noisy, irrelevant or misleading features. An extensive method may be used for this purpose, it is quite impractical for most datasets. Usually feature selection algorithms involve heuristic or random search strategies in an attempt to avoid this prohibitive complexity. However, the degree of optimality of the final feature subset is often reduced. Rough set theory [15,17,18] provides a mathematical tool that can be used for both feature selection and knowledge discovery. It helps us to find out the minimal attribute sets called ‘reducts’ to classify objects without deterioration of classification quality. The idea of reducts has encouraged many researchers in studying the effectiveness of rough set theory in a number of real world domains, including medicine, pharmacology, control systems, fault-diagnosis, text categorization, social sciences, switching circuits, economic/financial prediction, image processing, and so on. However, it is not possible in theory to say whether two attribute values are similar and to what extent they are the same; for example, two close values may only differ as a result of noise, but in the standard RST-based approach they are considered to be as different as two values of a different order of magnitude. Dataset discretization must take place before reduction methods based on crisp rough sets can be applied. This is often still inadequate. However, as the degrees of membership of values to discretised values are not considered at all. To solve this problem, a number of variations in this theory have been proposed. Among these methods, the Swarm Intelligence (SI) based methods perform better than the rest of the methods. Swarm Intelligence is the property of a system whereby the collective beh","Rough Sets and Current Trends in Computing | Swarm Intelligence: From Natural to Artificial Systems | Rough set-aided keyword reduction for text categorization | Feature Selection for Classification | Adaptation in Natural and Artificial Systems, The University of Michigan Press, Ann Arbour | A Rough Set-Aided System for Sorting WWW Bookmarks | Finding rough set reducts with ant colony optimization | Comparison of algorithms that select features for pattern classifiers | An idea based on honey bee swarm for numerical optimization | An Artificial Bee Colony (ABC) algorithm for numeric function optimization | A powerful and efficient algorithm for numerical function optimization: Artificial Bee Colony (ABC) algorithm | Artificial Bee Colony (ABC) Optimization Algorithm for Solving Constrained Optimization Problems | On the performance of Artificial Bee Colony (ABC) algorithm | Nature Inspired Population-Based Heuristics for Rough Set Reduction | Rough Sets | Rough Sets: Theoretical Aspects of Reasoning about Data, Kluwer Academic Publishers | Rough Sets: Present State and The Future | Rough Sets and Intelligent Data Analysis | Programs for Machine Learning, The Morgan Kaufmann Series in Machine Learning",rejected,000
1006.4544.pdf.json,Human Disease Diagnosis Using a Fuzzy Expert System,"NLINE diagnosis is becoming popular day by day. In today's world people are so busy, that they hardly have enough time to visit a doctor. So they can use the service of this online diagnosis system residing home or office and have an idea about the disease. After that they can consult the specialist doctor if it is necessary or serious. This research presents a novel method for online diagnosis. In this method, based on the selection of the problem area/ problem, the expert system gives some symptom from which the user needs to select symptoms. Based on the selection of symptoms, the user is again asked some questions. According to the answer selection, the fuzzy expert system diagnosis diseases based on it's knowledge, add catalyst factor (if any), do ranking and gives the result in fuzzy form. As fuzzy expert system deals with uncertainty and vague terms, it is generously accepted in different sphere of life [1]. Rest of the paper is organized as follows- Section 2 highlights the background study. Proposed System is presented in Section 3 and evaluation of the proposed system is shown in Section 4. Chapter 5 concludes the paper.","Implementation of evolutionary fuzzy systems | Artificial intelligence: A guide to intelligent systems | Introduction to Artificial Intelligence and Expert Systems”, Prentice-Hall Inc | C",rejected,000
1006.4551.pdf.json,Vagueness of Linguistic variable,"Theory of Vague Sets   [1]  First  of  all  we  recollect  basic  preliminaries  of  vague  theory. There are a number of generalizations  [1, 2, 3, 9,  10]    of Zadeh’s fuzzy set theory [2]   so far reported in the  literature  viz.,  i‐v  fuzzy  theory,  two‐fold  fuzzy  theory,  vague  theory,  intuitionistic  fuzzy  theory,  probabilistic  fuzzy  theory, L‐fuzzy  theory,  etc.     The  notion  of  vague  theory  recently  introduced  in  IEEE by Gau  and Buehrer  [1]  is of  interest  to us  for  this present work.       For  each  such  generalization,  one  (or more)  extra  edge  is  added  with  the  fuzzy  theory with  specialized  type  of  aim  and  objective.   Thus, a number of higher order  fuzzy sets are  now  in  literatures and are being applied  into  the  corres‐ ponding  more  specialized  application  domains.    While  fuzzy  sets are applicable  to each of  such application do‐ mains, higher  order  fuzzy  sets  can not,  because  of  their  specialization in character by birth.   Application of higher  order  fuzzy  sets  makes  the  solution‐procedure  more  complex,  but  if  the  complexity  on  computation‐time,  computation‐volume or memory‐space are not the matter  of concern then a better results could be achieved.  Vague  sets defined recently by Gau and Buehrer  [1]     have also  an extra edge over fuzzy sets.  Let U be a universe, say the  collection of all students of Calcutta High School.   Let A  be a vague set of all “good‐in‐maths students” of the un‐ iverse U,   and B be a fuzzy set of all “good‐in‐maths stu‐ dents”  of U.    Suppose  that  an  intellectual Manager M1  proposes the membership value μB(x) for the element x in  the fuzzy set B by his best  intellectual capability.   On the  contrary, another  intellectual Manager M2 proposes  inde‐ pendently  two membership values  tA(x) and  fA(x)  for  the  same  element  in  the vague  set A by his best  intellectual  capability. The amount tA(x) is the true‐membership valu","The concept of linguistic variable and its application to approximate reasoning | Mathematical principles of vague logic. (In Russian) FIZMATLIT | Intuitionistic Fuzzy Sets : Theory and Applications, Physica-Verlag | Vague sets are intuitionistic fuzzy sets | Evaluation of flexible queries: The quantified statement case”, Technologies for Constructing Intelligent Systems I, Physica-Verlag Heidelberg New York, pp | Analyzing fuzzy system reliability using vague set theory",rejected,000
1006.4561.pdf.json,An Efficient Technique for Similarity Identification between Ontologies,"It is quite difficult to retrieve relevant information from current web due to semantic heterogeneity problem in addition to other problems. Semantic web suggested solution of retrieval of specific information through ontologies, but ontologies may themselves suffer the heterogeneity problem when they are integrated, merged, shared, etc [1]. Same concept may be given different names or may be defined in different ways in two ontologies, although both ontologies belong to the same domain and may overlap. In order to use them together for different purposes such as merging, integrating, querying or even in creating a new ontology, those need to be aligned [2]. There are several techniques for aligning ontologies. They are mainly grouped into two classes: schema-based techniques and instance-based techniques. In schemabased techniques, the similarity among concepts of both ontologies is measured at structure-level while ignoring their actual data, whereas in instance-level techniques the similarity decision is made by taking actual data into consideration [3]. Ontology alignment at schema-level has different classifications such as structural, semantic, terminological and extensional [4]. Techniques for structural alignment are further divided into two classes: External structural alignment techniques and internal structural alignment techniques. External structure of a concept consists of the following elements [2], [5], [6]: super concepts; sub-concepts, sibling concepts and its nonAmjad Farooq, Syed Ahsan  and Abad Shah: Computer Science  and  Engineering  Department,  University  of  Engineering  and  Technology, Lahore –Pakistan.  taxonomic relations with the concepts. Therefore, when a concept Ci of ontology A is aligned with a concept Cj of ontology B, then all these elements i.e. super, sub and siblings are taken into consideration in the externalstructure level alignment of a concept. Structure-level similarities between concepts of ontologies are computed usi","Ontology matching,  | J | Web Explanations for Semantic Heterogeneity Discovery, | and I | A | H | and E | Dissimilarity measure for collections of objects and values, | A new Structural Similarity Measure for Ontology Alignment, | H | Anchor-prompt: using non-local context for semantic matching, | and E | An integrative proximity measure for ontology alignment, | Similarity for Ontologies - A Comprehensive Framework, | Semantic precision and recall for ontology alignment evaluation, | and Y | Ontology matching with semantic verification. Web Semantics, | Comparison of personal ontologies represented through conceptual graphs, | Similarity-based ontology alignment in OWL-lite, | Ontology mapping - an integrated approach,",rejected,000
1006.4563.pdf.json,The State of the Art: Ontology Web- Based Languages: XML Based,"Ontologies become a critical part in many areas, especially in Web Semantics. Consequently, a number of representational formats have been proposed to support and express them completely. Current languages used to express Ontologies fall generally into three categories [1]: vocabularies of Ontology defined using natural language, frame-based languages used to build the structure of Ontologies based on explicit statements of class and slot, and those languages based on logic, such as Description Logics. The main object of semantic web languages is to add semantics to the existing information on the Web. RDF/RDFS [7], OIL [14], DAML+OIL [9], and OWL [2] are modelling web languages that have already been developed to represent or express Ontologies. In general, most of these languages are based on XML [16] syntax, but they have different terminologies and expressions. Indeed, some of these languages have the ability to represent some logical relation but others do not. Because some languages have greater expressive power than others, languages chosen for representing Ontologies are based mainly on what the Ontology represents or what it will be used for. In other words, different kinds of Ontological knowledge-based applications need different language facilitators for enabling reasoning on Ontology data. These description languages provide richer constructors for forming complex class expressions and axioms. In fact, recently most Ontology developers have used Ontology Editors, which are environments or tools used directly for editing, developing or modifying Ontologies. These tools are used for providing support for the Ontological development process, as well as for conceptualising the Ontology; they transform the conceptualisation into executable code using translators. So the output Ontology of these tools will be in one of the Web Ontology languages supported by editors Such as Protégé [18], OWLP [21] and OilEd [22]. Alternatively Ontology reasoners are used to c","Using Ontologies - enabling knowledge sharing and reuse on the semantic web | Web Ontology Language: OWL | The Resource Description Framework (RDF) and its Vocabulary Description Language RDFS | Resource Description Framework (RDF) model and syntax specification | W3c resource description framework (rdf) schema specification | Resource Description Framework (RDF) Schema Specification 1.0 | DAML-ONT: An Ontology Language for the Semantic Web, | DAML+OIL (March 2001) Reference Description | ”OWL Web Ontology Language Overview | OWL Web Ontology  Language  Reference “http://www.w3.org/TR/2003/WD-owl-ref20030331 | OWL Web Ontology  Language  Guide | OWL Web Ontology Language Semantics and Abstract  Syntax | The Ontology Interchange Language OIL, | Ontology Learning for the Semantic Web | Extensible Markup Language (XML) 1.0 “, W3C Recommendation 10-February-1998, http://www.w3.org/TR/REC-xml  The comparison of these languages | DAML+OIL is not Enough | PROMPT: Algorithm and tool for automated Ontology merging and alignment | oller. RACER system description | The FaCT system | OWL-P: A Methodology for Business Process Development | OilEd Normalised Ontology Tutorial – Biomedical version (forOilEd version 3.4)",rejected,000
1006.4567.pdf.json,Understanding Semantic Web and Ontologies: Theory and Applications,"One of the most interesting inventions, in recent decades, is that of Web Services [36]. These are computer program “applications”: self-describing, selfcontained applications whose function is to automatically share information over the Internet with other applications. Some weaknesses such as browsing information without taking its meaning into account have recently appeared in Web Services. This creates a need for a new Web with more relevance to the user. Semantic Web is actually an extension of the current one in that it represents information more meaningfully for humans and computers alike. It enables the description of contents and services in machine-readable form, and enables annotating, discovering, publishing, advertising and composing services to be automated. It was developed based on Ontology, which is considered as the backbone of the Semantic Web. In other words, the current Web is transformed from being machine-readable to machineunderstandable. One function of the Web is to build a source of reference for information on several subjects, while the Semantic Web is designed to build a web of meaning. The foundation of vocabularies and effective communication on the Semantic Web is ontology. “Ontology provides a formal, explicit specification of a shared conceptualisation of a domain” [31, 36]. Therefore, it facilitates knowledge sharing over distributed systems; in other words, it allows systems or applications to cooperate that were not formerly designed to interoperate. Ontology plays a major part in solving the problem of interoperability between applications across different organizations, by providing a shared understanding of common domains. Several Ontologies have recently been built. Consequently, they should be accessed from other applications for use or information exchange. Ontologies in such numbers present interoperability problems, for which many solutions have been developed. One of these is to build a single Ontology, but this is ina","Web Ontology Language: OWL | The Semantic Web | OilEd: a Reason-able Ontology Editor for the Semantic Web | Sperberg-McQueen, ""Extensible Markup Language (XML) | OntoMorph: A Translation System for Symbolic Knowledge | Solving Integration Problems of E-Commerce Standards and Initiatives through Ontological Mappings | OWL-P: A Methodology for Business Process Development | Ontology Translation on the Semantic Web | Ontology Alignment: Bridging the  192 Semantic Gap (Semantic Web and Beyond) | QOM - Quick Ontology Mapping | State of the Art on Ontology Alignment"", Knowledge Web Deliverable D2.2.3 | Similarity-Based Ontology Alignment in OWL-Lite | OIL: An Ontology Infrastructure for the Semantic Web | Ontologies: Silver Bullet for Knowledge Management and Electronic Commerce | RACER System Description | A Semantics for Abstraction | An Improved Algorithm for Matching Biological Sequences | IF-Map: An Ontology-Mapping Method Based on Information-Flow Theory | Ontology Versioning on the Semantic Web | A Tool for Evaluating Ontology Alignment Strategies | The Grid: Core Technologies | WordNet: A Lexical Database for English"", presented at Commun | An Ontology Driven Approach to Ontology Translation | Semantic Integration: A Survey Of Ontology-Based Approaches | PROMPT: Algorithm and Tool for Automated Ontology Merging and Alignment | Semantic Matching of Web Services Capabilities | A Survey of Approaches to Automatic Schema Matching | Progressive Ontology Alignment for Meaning Coordination: An Information-theoretic Foundation | A Survey of SchemaBased Matching Approaches | Web Services-The Web’s Next Revolution | FaCT++ Description Logic Reasoner: System Description | Ontologies: Principles,  Methods  and Applications",rejected,000
1006.5896.pdf.json,Counterexample Guided Abstraction Refinement Algorithm for Propositional Circumscription,"Closed world reasoning (CWR) and circumscription (CIRC) are well-known nonmonotonic reasoning techniques, that find a wide range of practical applications. Part of the interest in these techniques is that they bring us closer to how humans reason [15,17,16]. While these techniques have been studied in the context of both first-order and propositional logic, this paper addresses the propositional case. Research directions that have characterized the study of nonmonotonic reasoning techniques include expressiveness, computational complexity, applications and algorithms. The different CWR rules proposed in the late 70s and 80s illustrate the evolution in terms of expressive power in first-order and propositional logics. The computational complexity of propositional CWR rules was studied in the early 90s [1,6] and showed that, with few exceptions, the complexity of CWR deduction problems are in the second level of the polynomial hierarchy, being ΠP2 -complete [6]. Nonmonotonic reasoning finds a wide range of applications in Artificial Intelligence (AI), but also in description logics [7] and in interactive configuration [13], among many others. Finally, different algorithms have been proposed over the years, examples of which include minimal model resolution [20], tableau calculus [18], Quantified Boolean Formula (QBF) solvers [5] and Disjunctive Logic Programming (DLP) [14,12,19]. The main contribution of this paper is to propose a new algorithm for solving the deduction problem for the propositional version of some CWR rules and for propositional circumscription. The new algorithm is based on iterative calls to a SAT solver, and is motivated by the practical success of modern SAT solvers. However, given the complexity class of entailment for CWR rules, a SAT solver can be expected to be called an exponential number of times in the worst case, or be required to process an exponentially large input. To cope with this issue, we utilize a technique inspired in counterexam",The complexity of closed world reasoning and circumscription | Using the Davis and Putnam procedure for an efficient computation of preferred models | Counterexample-guided abstraction refinement | Nonmonotonic reasoning: Towards efficient calculi and implementations | Solving advanced reasoning tasks using quantified boolean formulas | Propositional circumscription and extended closed-world reasoning are Π  2 -complete | Combining answer set programming with description logics for the Semantic Web | Predicate abstraction for software verification | On the relationship between circumscription and negation as failure | Solving optimization problems with DLL | Unfolding partiality and disjunctions in stable model semantics | Capturing parallel circumscription with disjunctive logic programs | How to complete an interactive configuration process? In: Conference on Current Trends in Theory and Practice of Computer Science | Foundations of logic programming | Circumscription - a form of non-monotonic reasoning | Applications of circumscription to formalizing common-sense knowledge | On indefinite databases and the closed world assumption | Implementing circumscription using a tableau method | circ2dlp - translating circumscription into disjunctive logic programming | An algorithm to compute circumscription | Solving satisfiability problems with preferences | On the complexity of derivation in propositional calculus | Deduction in non-Horn databases,rejected,000
1007.1024.pdf.json,Model Counting in Product Configuration,"Since R1/XCON [15] was used by DEC to support computer system configuration and assembly, product configuration systems have been among the most prominent and successful applications of AI methods in practice [19]. As a result computer aided configuration systems have been used in managing complex software, hardware or network settings. Another application area of these configuration systems is the automotive industry. Here they helped to realize the transition from the mass production paradigm to present-day mass customization. Model counting is a technique to count the number of different satisfying variable assignments of a formula in propositional logic. Up to now model counting has mostly been used within bayesian networks [22, 1] and planning problems [17, 14]. In contrast, our work aims at using propositional model counting for a quantitative analysis of comprehensive product configuration setups. To demonstrate the applicability of our novel methods, we provide examples within a well-studied car configuration context. The German automobile industry follows a build-to-order strategy based on an exceedingly large product variety. This makes it possible, especially for the manufacturers of luxury cars, to offer each customer their unique tailor-made car, and it differentiates the model lines from the mass market. Pil and Holweg [18] have discussed the interconnection of product variety and order-fulfillment strategies. In this context it is interesting for the management to know precisely how much variety there is in the product line. For the automobile industry, this question is surprisingly difficult to answer. In particular, sales options cannot simply be multiplied out because of complex interdependencies (e.g. automatic transmission being standard on U.S. exports, and not available on European cars with small engines). Pil and Holweg published data for the year 2002, based on an analysis of company material, about customer selectable variations. In summary",Algorithms and Complexity Results for #SAT and Bayesian Inference | Counting Models Using Connected Components | A Few Billion Lines Of Code Later: Using Static Analysis to Find Bugs in the Real World | The Good Old Davis-Putnam Procedure Helps Counting Models | Graph-Based Algorithms for Boolean Function Manipulation | Boolean Satisfiability with Transitivity Constraints | On the Tractable Counting of Theory Models and its Application to Truth Maintenance and Belief Revision | New Advances in Compiling CNF to Decomposable Negational Normal Form | A Machine Program for Theorem-Proving | A Computing Procedure for Quantification Theory | Fast Backtrack Free Product Configuration using Precompiled Solution Space Representations | A Structure-Based Variable Ordering Heuristic for SAT | Proving Consistency Assertions for Automotive Product Data Management | A Model Counting Characterization of Diagnoses | A Rule-Based Configurer of Computer Systems | Constraint and Variable Ordering Heuristics for Compiling Configuration Problems | Pruning Conformant Plans by Counting Models on Compiled D-DNNF Representations | Linking Product Variety to Order-Fulfillment Strategies | Product Configuration Frameworks-A Survey | Combining Component Caching and Clause Learning for Effective Model Counting | Heuristics for Fast Exact Model Counting | Performing Bayesian Inference by Weighted Model Counting | sharpSAT — Counting Models with Advanced Component Caching and Implicit BCP. In: Theory and Applications of Satisfiability Testing - SAT | The Complexity of Computing the Permanent,rejected,000
1007.1270.pdf.json,How to Maximize User Satisfaction Degree in Multi-service IP Networks,,"An optimal bandwidth adaptation algorithm for multi-class traffic in wireless network | Utility-maximization bandwidth adaptation for multi-class traffic QoS provisioning in wireless network | Techniques for dynamic and prioritized bandwidth allocation on incoming links | A heuristic for bandwidth allocation and management to maximize user satisfaction degree on multiple MPLS  paths | A two-level resource management scheme in wireless networks based on usersatisfaction | Resource management policies for e-commerce servers | A heuristic for Dynamic Bandwidth Allocation with Preemption and Degradation for Prioritized Requests | A simple rate control algorithm for maximizing total user utility | Dynamic utility-based bandwidth allocation policies: the case of overloaded network | Fundamental Design Issues for the Future Internet | An Engineering Approach to Computer Networking: ATM Networks, the Internet, and the Telephone Network | Dynamic trunk reservation for teletraffic links | Evaluation of expanded heuristics in a heterogeneous distributed data staging network | Time-aware utility-based QoS optimization | Z.A.H.R., “Dynamic bandwidth allocation with minimum long fluctuations | A bandwidth sharing theory for a large number of HTTP-like connections | A dynamic CPU bandwidth partitioning scheme for multimedia real-time systems | Non-convex optimization and rate control for multi-class services in the Internet | Java implementation of policy-based bandwidth management | Fair Bandwidth Allocation under User Capacity Constraint | Max-min fair bandwidth allocation algorithms for packet switches",rejected,000
1007.1766.pdf.json,AN SVM MULTICLASSIFIER APPROACH TO LAND COVER MAPPING,"One of the means through which land cover classes can be extracted from satellite imagery is by the use of algorithms called image classifiers. Image classification may be categorized into supervised or unsupervised, parametric or nonparametric, contextual or noncontextual classification (Keuchela et al, 2003). This paper explores the use of nonparametric supervised classification algorithms called Support Vector Machines (SVMs). SVMs are nonparametric in the sense that they do not attempt to model the distribution of the training data, but try to separate the different classes by directly searching for adequate boundaries between them (Keuchel, 2003). This is unlike traditional classifiers such as maximum likelihood and minimum-distance-to-means classifiers which fall under the category of parametric classifiers. The interest in the exploration of new and emerging classifiers stems from the importance of land cover information to various disciplines such as forestry, precision agriculture, disaster management etc. How accurate a land cover map is derived has implications on how well the various application areas will be effected, be it at policy or operational level. Most of the current research in the area tends to focus on the application of new algorithms to land cover mapping with an emphasis on how they compare or if they are better than existing methods. In this paper a paradigm shift is proposed whereby instead of looking at which classifier is better than the traditional and/or emerging classifiers, there is an interest in how the classifiers can be considered collectively. The final land cover class assigned to a pixel is dependent on a vote between the ‘committee’ of classifiers. Hence the name – ensemble classifiers. This paper gives an overview on SVMs which are the subject of this paper. The paper then continues to highlight the issues pertaining to ensemble classification, the developed methodology and the results thereof. ASPRS 2008 Annual Conference","An Introduction to Support Vector Machines: And Other Kernel-based | Image classification using SVMs: One-against-one vs one-againstall | An assessment of support vector machines for land cover | Text categorization with support vector machines—learning with many relevant features | Automatic land cover analysis for Tenerife | Support vector classifiers for land cover classification, In Proceedings of the 6 Annual International Conference, Map India | An ensemble-based incremental learning approach to data | Ensemble based systems in decision making, IEEE Circuits and Systems Magazine, pp | The Nature of Statistical Learning Theory, New York: Springer-Verlag",rejected,000
1007.2364.pdf.json,,"The idea of the Semantic Web is to annotate Web content and services with computer interpretable descriptions in order to automatize many tasks currently performed by human users. In the context of the Web services, this has led to the definition of semantic Web services, that is a semantic description of the capabilities and the structure of services in the languages of the semantic Web. The current proposals for the representation of semantic Web services, as OWL-S [10], view services as processes with pre- and post- conditions and effects. The representation by pre- and post- conditions describe the requirements and output of a service that is useful to retrieve the service; the representation of the process associated with a service describe the interaction with other given services. One of the main problems in the context of Web services is their composition. The problem can be stated as follows: given a composition goal, represented as a service with pre- and post- conditions, compose the available services so to satisfy the goal. Obviously in this context the challenge is to provide tools to support the definition of the composite service or, at best, to automatize the entire composition process. Using the well known relation between semantic Web languages and description logics, here we discuss the problem of service composition in the context of constructive description logics. This allows us to draw from the long tradition of use of constructive mathematics in the context of program synthesis. Indeed, the composition calculus we discuss in this paper is inspired by [13]. ⋆ Part of this work will appear as a position paper in Proceedings of the 4th International Conference on Web Reasoning and Rule Systems (RR 2010). In this paper we formalize the composition problem in the framework of the constructive description logic BCDL0. This paper represents an initial presentation for our approach: its main contribution is to lay down the definitions for a composit","editors | A description logic based approach to reasoning about web services | A decidable constructive description logic | editors | The Web Service Modeling Language WSML: An Overview | Integrating action calculi and description logics | BCDL: Basic Constructive Description Logic | Bringing Semantics to Web Services with OWL-S | Value-added web services composition using automatic program synthesis | Strategies of structural synthesis of programs and its extensions | Program specification and synthesis in constructive formal systems | Simulation, verification and automated composition of web services | Attributive concept descriptions with complements | Automated composition of semantic web services into executable processes | From constructivism to computer science",rejected,000
1007.2449.pdf.json,A Brief Introduction to Temporality and Causality,"Time and causality are sources of mystery and sometimes treated as philosophical curiosities. However, there is much benefit in being able to automatically extract temporal and causal relations in practical fields such as Artificial Intelligence or Data Mining. Doing so requires a rigorous treatment of temporality and causality. In this paper we present causality from very different view points and list a number of methods for automatic extraction of temporal and causal relations. The arrow of time is a unidirectional part of the space-time continuum, as verified subjectively by the observation that we can remember the past, but not the future. In this regard time is very different from the spatial dimensions, because one can obviously move back and forth spatially. However, there is a contradiction between the empirical observation that time is irreversible, and the time-reversibility of physical laws. Most laws in physics are expressed in a time-reversible manner, meaning that they can be applied in either temporal direction. An example is the relationship between force and acceleration, f = m × a (1), which does not enforce a specific direction of time. While formula (1) might suggest that the force f is caused by the mass and the acceleration, we can re-arrange the formula to read a = f / m and interpret the formula as saying that acceleration is caused by the mass and the force. The fact that many physical laws do not exhibit temporal asymmetry has prompted some researchers to consider them as incomplete approximations [32]. Others assume that there are two distinct types of physical laws. Time-symmetrical laws hold backwards in time, while asymmetrical laws are valid in only one direction [3]. Note that another possible view is that a formula such as f = m × a shows an instantaneous physical relationship: the force at any one moment is related to the acceleration at that same moment. In other words, they are created together and one cannot exist without the ot","Mining Sequential Patterns | Using Context-Free Grammars to Constrain Apriori-based Algorithms for Mining Temporal Association Rules, Workshop on Temporal Data Mining (KDD2002) | The Meaning of Quantum Theory: A Guide for Students of Chemistry and Physics | Finding Patterns in Time Series: A Dynamic Programming Approach, Advances in Knowledge Discovery and Data Mining | The Analysis of Time Series: An Introduction | Learning Bayesian Networks is NP-Hard | Possibility of Faster-Than-Light Particles | Are There Algorithms that Discover Causal Structure | Investigating Causal Relations by Econometrics Models and Cross-Spectral | Learning Sequential Decision Rules Using Simulation Models and Competition, Machine Learning | Pattern Directed Mining of Sequence Data | The Universe in a Nutshell | A Bayesian Approach to Learning Causal Networks, Microsoft Technical Report MSR-TR-95-04 | Learning Bayesian Networks: The Combination of Knowledge and Statistical Data | Statistics and Causal Inference | Knowledge Discovery from Sequential Data, PhD dissertation, Fachbereich für Mathematik und Informatik der Technischen Universität | Discovery of Temporal Patterns: Learning Rules about the Qualitative Behaviour of Time Series, Principles of Data Mining and Knowledge Discovery | The Grand Leap | Learning comprehensible descriptions of multivariate time series | TimeSleuth: A Tool for Discovering Causal and Temporal Rules | Scaling up Dynamic Time Warping for Data Mining Applications, The Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD’2000) | In Search of Philosopher's Stone: Remarks on Humphreys and Freedman's Critique of Causal Discovery | Clustering of streaming time series is meaningless, The eighth ACM SIGMOD Workshop on Research Issues in Data Mining and Knowledge | Where does the Weirdness Go | Discovering Frequent Episodes in Sequences | Some Philosophical Problems from the Standpoint of Artificial Intelligence | Equation of state calculation by fast computing machines | Understanding Quantum Physics: A User’s Manual | Searching for Structure in Multiple Streams of Data | Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference | Causality: Models, Reasoning, and Inference | The Emperor's New Mind: Concerning Computers, Minds, and the Laws of Physics | Programs for Machine Learning | Temporal Data Mining: Survey and Issues, Research Report ACRC-99-007 | Artificial Intelligence: A Modern Approach | Unsupervised Temporal Rule Mining with Genetic Programming and Specialized Hardware | Tetrad II: Tools for Causal Modeling | The TETRAD Project: Constraint-Based Aids to Causal Model Specification | Causation, Prediction, and Search | An Information Measure for Classification | Causal Discovery via MML | Causality is undefinable, Abstract of a Lecture Presented at the BISC Seminar, http://www.cs.berkeley.edu/~nikraves/zadeh/Zadeh2.doc",rejected,000
1007.2534.pdf.json,A GENERAL METHOD FOR DECIDING ABOUT LOGICALLY CONSTRAINED ISSUES,"1.1 Around 1990 Lewis A. Kornhauser and Lawrence G. Sager pointed out that collegial courts are liable to what they termed the doctrinal paradox [14, 15 ]. A simple example of it would be the following: A person is on trial for having committed a crime. The case involves two issues p and q whose conjunction, i. e. both of them being true, determines whether the accused is guilty or not. The case is heard by a jury of three members. One of them believes that p is true but not q ; accordingly, he finds the accused not guilty. Another one believes that q is true but not p ; so he also finds the accused not guilty. Finally, the third member of the jury believes that both p and q are true, so he finds the accused guilty. Altogether, one can say that the jury has reached a majority verdict of not guilty. However, one can also say that they have a majority opinion that p is true and that q is also true; accordingly, the accused should be considered guilty. The above-mentioned authors acknowledge that “We have no clear understanding of how a court should proceed in cases where the doctrinal paradox arises” [15 ]. The main issue in a trial is whether the accused is guilty or not. Let t denote the proposition that he is guilty. We are assuming that this proposition is logically connected to p and q as specified by the following doctrine: t ↔ p ∧ q . Every member of the jury is required to be consistent with it. Therefore, there are only four consistent opinions about the truth of (p, q, t), namely: (1, 1, 1), (1, 0, 0), (0, 1, 0) and (0, 0, 0), where 1 means true, and 0 means false. Let us consider all possibilities for a jury that is hearing such a case: let x, y, z, u be the fractions who adhere to, respectively, each of those four consistent opinions. In terms of these numbers, the fractions of the jury who believe in the truth of t, p, q are respectively vt = x , vp = x+y and vq = x+ z . These numbers can be seen as degrees of collective belief in the truth of the respect",Canonical Expressions in Boolean Algebra | Xavier Mora | Xavier Mora | The problem of constrained judgment aggregation | 2009–2011 (working paper). Propositionwise judgment aggregation: the general case. http://personal.lse.ac.uk/list/ PDF-files/PropositionwiseAggregation.pdf | Logic of Belief Revision | Modelling collegial courts · II: Legal doctrine | Lawrence G | Lawrence G | Introduction to judgment aggregation | Arnold B | Solving satisfiability in less than 2n steps | Consistent judgement aggregation: the truth-functional case | Abstract Arrovian aggregation | Collective Decisions and Voting: The Potential for Public Choice,rejected,000
1007.3159.pdf.json,,"Computational Sustainability (Gomes 2009) is a very recent, interdisciplinary research field that aims to apply techniques from computer science, information science, operations research, applied mathematics, and statistics to the problem of balancing environmental, economic, and societal needs for sustainable development. Among the many possible applications of information technology to sustainable development, decision support systems represent a very important topic. Currently, environmental experts take decisions, perform evaluations and build plans manually, simply relying on experience, with little or no support from automated tools. We believe the main reason why decision support systems are not widely applied in this field is twofold: first, despite significant advances in algorithmic research, the current state of decision support systems still faces severe difficulties or cannot cope at all with the highly complex structure of sustainability problems. Second, there is a lack of appropriate models for sustainability related applications. These models should be developed in tight collaboration between computer scientists and environmental scientists, economists and biologists that can provide not only models and data, but also feedback on system solutions. Computational Logic can play a very important role in the design and implementation of decision support systems in this setting. First it enables a very intuitive and expressive representation of reality, and second it provides a number of reasoning mechanisms that can be successfully applied to the many aspects of sustainability problems: logical inference, constraint reasoning and probabilistic reasoning. In addition, Computational Logic tools rely on a well-defined semantics, and one can reason on the program to give explanations of the obtained results (or failure). Sustainable development encompasses three pillars: society, economy and the environment. In this paper, we focus particularly on the envir",Semiring-based constraint satisfaction and optimization | Probabilistic logic programs and their semantics | INCLP(R) - interval-based nonlinear constraint logic programming over the reals | ProbLog: A probabilistic Prolog and its application in link discovery | Probabilistic Datalog: Implementing logical information retrieval for advanced applications | Challenges for constraint reasoning and optimization in computational sustainability | An overview of the Ciao multiparadigm language and program development environment and its design philosophy | Constraint logic programming: A survey | The CLP(R) language and system | CP-Logic theory inference with contextual variable elimination and comparison to BDD based inference methods | Causality | The independent choice logic for modelling multiple agents under uncertainty | A top down interpreter for LPAD and CP-logic | Inference with logic programs with annotated disjunctions under the well founded semantics | Extended semantics and inference for the Independent Choice Logic | PRISM: A language for symbolic-statistical modeling | Valued constraint satisfaction problems: Hard and easy problems | Eplex: Harnessing mathematical programming solvers for constraint logic programming | Procedures and programs to assist in the impact statement process | CP-logic: A language of causal probabilistic events and its relation to logic programming | Logic programs with annotated disjunctions | BProlog: A high performance Prolog compiler,rejected,000
1007.3223.pdf.json,Testing and Debugging Techniques for Answer Set Solver Development,"Answer set programming (ASP) (Gelfond and Lifschitz 1988; Niemelä 1999) is a rule-based declarative programming paradigm that has proven to be an effective approach to knowledge representation and reasoning in various hard combinatorial problem domains. This success has been enabled by the development of efficient answer set solvers (Simons et al. 2002; Ward and Schlipf 2004; Lin and Zhao 2004; Janhunen and Niemelä 2004; Liu and Truszczynski 2005; Anger et al. 2005; Leone et al. 2006; Giunchiglia et al. 2006; Janhunen 2006; Gebser et al. 2007; Drescher et al. 2008; Janhunen et al. 2009; Brain and De Vos 2009). Implementing robust, sound and complete answer set solvers is a demanding task. For achieving high solver performance, one needs to implement error-prone and complex inference rules, specialized data structures, and other complex optimizations. On the other hand, robustness and correctness are two essential criteria for answer set solvers. The users of answer set solvers heavily depend on correct results and, in particular, correct answer sets. The lack of systematized testing tools for answer set solver development may leave intricate implementation bugs unnoticed. Indeed, in practice, small sets of problem instances that are typically used during regression and unit testing are not enough for testing correctness during solver development. Moreover, while the availability of standard benchmark instances is of high importance for benchmarking solver implementations, testing during solver development should not solely rely on these instances. In support of these claims, by examining the detailed results of the first and second ASP programming competitions (Gebser et al. 2007; Denecker et al. 2009) one notices that, on the sets of (typical) benchmarks used in these competition, only very few solvers on very few benchmarks were judged as providing incorrect results. In other words, almost no defective behavior seems to have been detected. In contrast, we will s",The nomore++ approach to answer set solving | CVC3 | PicoSAT essentials | Debugging ASP programs by means of ASP | Debugging logic programs under the answer set semantics | The significance of memory costs in answer set solver implementation | Fuzzing and delta-debugging SMT solvers | A visual tracer for DLV | QuickCheck: a lightweight tool for random testing of Haskell programs | Z3: An efficient SMT solver | The second answer set programming competition | Conflict-driven disjunctive answer set solving | The Yices SMT solver | An extensible SAT-solver | Conflict-driven answer set solving | The first answer set programming system competition | A meta-programming technique for debugging answer-set programs | The stable model semantics for logic programming | Answer set programming based on propositional satisfiability | Some (in)translatability results for normal logic programs and propositional theories | GnT – a solver for disjunctive logic programs | Computing stable models via reductions to difference logic | The DLV system for knowledge representation and reasoning | ASSAT: Computing answer sets of a logic program by SAT solvers | Pbmodels - software to compute stable models by pseudoboolean solvers | HDD: hierarchical delta debugging | Simple random logic programs | Logic programs with stable model semantics as a constraint programming paradigm | Extending and implementing the stable model semantics | Fuzzing - Brute Force Vulnerability Discovery | Debugging inconsistent answer set programs | Fuzzing for Software Security Testing and Quality Assurance | A delta debugger for ILP query execution | On the complexity of derivation in propositional calculus | Answer set programming with clause learning | Why Programs Fail | Simplifying and isolating failure-inducing input | Answer set programming phase transition: A study on randomly generated programs,rejected,000
1007.4040.pdf.json,Loop Formulas for Description Logic Programs∗,"Logic programming under the answer set semantics (ASP) is a nonmonotonic reasoning paradigm for declarative problem solving (Marek and Truszczynski 1999; Niemelä 1999). Recently, there have been extensive interests in combining ASP with other computational and reasoning paradigms. One of the main interests in this direction is the integration of ASP with ontology reasoning, for the Semantic Web. The Semantic Web is an evolving development of the World Wide Web in which the meaning of information and services on the web are defined, so that the web content can be precisely understood and used by agents (Berners-Lee et al. 2001). For this purpose, a layered structure including the Rules Layer built on top of the Ontology Layer has been recognized as a fundamental framework. Description Logics (DLs) (Baader et al. 2007) provide a formal basis for the Web Ontology Language which is the standard of the Ontology Layer (W3C OWL Working Group 2009). ∗ This is the full version of (Wang et al. 2010). ar X iv :1 00 7. 40 40 v1 [ cs .A I] 2","The Description Logic Handbook: Theory, Implementation, and Applications , 2nd ed | The semantic web | Equilibria in heterogeneous nonmonotonic multi-context systems | Embedding non-ground logic programs into autoepistemic logic for knowledge-base combination | Declarative and computational properties of logic programs with aggregates | First-order loop formulas for normal logic programs | Quantified equilibrium logic and hybrid rules | Combining answer set programming with description logics for the semantic web | A proposal for an OWL rules language | On loop formulas with variables | ASSAT: computing answer sets of a logic program by SAT solvers | Lparse programs revisited: Semantics and representation of aggregates | Stable models and an alternative logic programming paradigm | Reconciling description logics and rules | Logic programs with stable model semantics as a constraint programming paradigm | On the decidability and complexity of integrating ontologies and rules | DL+log: Tight integration of description logics and disjunctive datalog | The well-founded semantics for general logic programs | Loop formulas for description logic programs",rejected,000
1009.2009.pdf.json,Hierarchical Semi-Markov Conditional Random Fields for Recursive Sequential Data,"∗Hung Bui is supported by the Defense Advanced Research Projects Agency (DARPA) under Contract No. FA8750-07-D-0185/0004. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of DARPA, or the Air Force Research Laboratory (AFRL).","Policy recognition in the abstract hidden Markov model | Hierarchical hidden Markov models with general state hierarchy | Log-linear models for wide-coverage CCG parsing | Discriminative training methods for hidden Markov models: Theory and experiments with the perceptron algorithm | The hierarchical hidden Markov model: Analysis and applications | Factor graphs and the sum-product algorithm | A hierarchical field framework for unified contextbased classification | Conditional random fields: Probabilistic models for segmenting and labeling sequence data | Graphical Models | Extracting places and activities from GPS traces using hierarchical conditional random fields | Foundations of Statistical Natural Language Processing | Maximum entropy estimation for feature forests | Dynamic Bayesian Networks: Representation, Inference and Learning | Linear time inference in hierarchical HMMs | Learning and detecting activities from movement trajectories using the hierarchical hidden Markov models | Layered representations for learning and inferring office activity from multiple sensory channels | Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference | Inside-outside reestimation from partially bracketed corpora | A tutorial on hidden Markov models and selected applications in speech recognition | Introduction to the CoNLL-2000 shared task: Chunking | Semi-Markov conditional random fields for information extraction | Dynamic conditional random fields: Factorized probabilistic models for labeling and segmenting sequence data | Discriminative probabilistic models for relational data | Max-margin Markov networks | AdaBoost.MRF: Boosted Markov random forests and application to multilevel activity recognition | Accelerated training of conditional random fields with stochastic gradient methods | Constructing free-energy approxima | Semi-Markov CRFs as Special Case of HSCRFs In this Appendix we first describe the semi-Markov CRF (SemiCRF) (Sarawagi and Cohen, 2004) in our HSCRF framework and show how to convert a SemiCRF into an HSCRF. Then under the light of HSCRF inference we show how to modify the original Semi",rejected,000
1010.3091.pdf.json,Near–Optimal Bayesian Active Learning with Noisy Observations,"How should we perform experiments to determine the most accurate scientific theory among competing candidates, or choose among expensive medical procedures to accurately determine a patient’s condition, or select which labels to obtain in order to determine the hypothesis that minimizes generalization error? In all these applications, we have to sequentially select among a set of noisy, expensive observations (outcomes of experiments, medical tests, expert labels) in order to determine which hypothesis (theory, diagnosis, classifier) is most accurate. This fundamental problem has been studied in a number of areas, including statistics [16], decision theory [12], machine learning [18, 7] and others. One way to formalize such active learning problems is Bayesian experimental design [6], where one assumes a prior on the hypotheses, as well as probabilistic assumptions on the outcomes of tests. The goal then is to determine the correct hypothesis while minimizing the cost of the experimentation. Unfortunately, finding this optimal policy is not just NP-hard, but also hard to approximate [5]. Several heuristic approaches have been proposed that perform well in some applications, but do not carry theoretical guarantees (e.g., [17]). In the case where observations are noise-free1, a simple algorithm, generalized binary search2(GBS) run on a modified prior, is guaranteed to be competitive with the optimal policy; the expected number of queries is a factor of O(log n) (where n is the number of hypotheses) more than that of the optimal policy [14], which matches lower bounds up to constant factors [5]. The important case of noisy observations, however, as present in most applications, is much less well understood. While there are some recent positive results in understanding the label complexity of noisy active learning [18, 1], to our knowledge, so far there are no algorithms that are provably 1This case is known as the Optimal Decision Tree (ODT) problem. 2GBS greedily sele",,rejected,000
1011.0041.pdf.json,Predictive State Temporal Difference Learning,"We examine the problem of estimating a policy’s value function within a decision process in a high dimensional and partially-observable environment, when the parameters of the process are unknown. In this situation, a common strategy is to employ a linear architecture and represent the value function as a linear combination of features of (sequences of) observations. A popular family of model-free algorithms called temporal difference (TD) algorithms [1] can then be used to estimate the parameters of the value function. Least-squares TD (LSTD) algorithms [2, 3, 4] exploit the linearity of the value function to find the optimal parameters in a least-squares sense from time-adjacent samples of features. Unfortunately, choosing a good set of features is hard. The features must be predictive of future reward, and the set of features must be small relative to the amount of training data, or TD learning will be prone to overfitting. The problem of selecting a small set of reasonable features has been approached from a number of different perspectives. In many domains, the features are selected by hand according to expert knowledge; however, this task can be difficult and time consuming in practice. Therefore, a considerable amount of research has been devoted to the problem of automatically identifying features that support value function approximation. Much of this research is devoted to finding sets of features when the dynamical system is known, but the state space is large and difficult to work with. For example, in a large fully observable Markov ar X iv :1 01 1. 00 41 v2 [ cs .L G ] 1 8 Ja n 20 11 decision process (MDP), it is often easier to estimate the value function from a low dimensional set of features than by using state directly. So, several approaches attempt to automatically discover a small set of features from a given larger description of an MDP, e.g., by using a spectral analysis of the state-space transition graph to discover a low-dimensional feature","Learning to predict by the methods of temporal differences | Least-squares temporal difference learning | Linear least-squares algorithms for temporal difference learning | Least-squares policy iteration | Representation policy iteration | Samuel meets amarel: automating value function approximation using global state space analysis | Compact spectral bases for value function approximation using kronecker factorization | Optimal control of Markov decision processes with incomplete state estimation | The Optimal Control of Partially Observable Markov Processes | Acting optimally in partially observable stochastic domains | Value-directed compression of pomdps | A novel orthogonal nmf-based belief compression for pomdps | Compressing pomdps using locality preserving non-negative matrix factorization | Predictive representations of state | Predictive state representations: A new theory for modeling dynamical systems | Observable operator models for discrete stochastic time series | Planning in pomdps using multiplicity automata | Regularization and feature selection in least-squares temporal difference learning | An analysis of linear models, linear value-function approximation, and feature selection for reinforcement learning | Learning low dimensional predictive representations | Closing the learning-planning loop with predictive state representations | Causality: models, reasoning, and inference | Learning predictive state representations using non-blind policies | Multivariate Reduced-rank Regression: Theory and Applications | Matrix Computations | The most predictable criterion | Dynamic data factorization | Subspace Identification for Linear Systems: Theory, Implementation, Applications | Subspace Methods for System Identification | A spectral algorithm for learning hidden Markov models | Improving approximate value iteration using memories and predictive state representations | Reduced-rank hidden Markov models | Optimal stopping of markov processes: Hilbert space theory, approximation algorithms, and an application to pricing high-dimensional financial derivatives",rejected,000
1011.4362.pdf.json,,,"Learning near-optimal policies with bellman-residual minimization based fitted policy iteration and a single sample path | Neurodynamic Programming | Regularized policy iteration | Stable function approximation in dynamic programming | Max-norm projections for factored mdps | Error bounds for approximate policy iteration | Finite-time bounds for fitted value iteration | Iterative Methods for Sparse Linear Systems, 2nd edition | Optimality of reinforcement learning algorithms with linear function approximation | Fast gradient-descent methods for temporaldifference learning with linear function approximation | The many proofs of an identity on the norm of oblique projections | Minkowski Geometry | An analysis of temporal-difference learning with function approximation | Tight performance bounds on greedy policies based on imperfect value functions | New error bounds for approximations from projected linear equations",rejected,000
1011.4632.pdf.json,,"The k-means clustering algorithm [16] was recently recognized as one of the top ten data mining tools of the last fifty years [20]. In parallel, random projections (RP) or the so-called Johnson-Lindenstrauss type embeddings [12] became popular and found applications in both theoretical computer science [2] and data analytics [4]. This paper focuses on the application of the random projection method (see Section 2.3) to the k-means clustering problem (see Definition 1). Formally, assuming as input a set of n points in d dimensions, our goal is to randomly project the points into d̃ dimensions, with d̃ ≪ d, and then apply a k-means clustering algorithm (see Definition 2) on the projected points. Of course, one should be able to compute the projection fast without distorting significantly the “clusters” of the original point set. Our algorithm (see Algorithm 1) satisfies both conditions by computing the embedding in time linear in the size of the input and by distorting the “clusters” of the dataset by a factor of at most 2 + ε, for some ε ∈ (0, 1/3) (see Theorem 1). We believe that the high dimensionality of modern data will render our algorithm useful and attractive in many practical applications [9]. Dimensionality reduction encompasses the union of two different approaches: feature selection, which embeds the points into a low-dimensional space by selecting actual dimensions of the data, and feature extraction, which finds an embedding by constructing new artificial features that are, for example, linear combinations of the original features. Let A be an n × d matrix containing n d-dimensional points (A(i) denotes the i-th point of the set), and let k be the number of clusters (see also Section 2.2 for more notation). We slightly abuse notation by also denoting by A the n-point set formed by the rows of A. We say that an embedding f : A → Rd̃ with f(A(i)) = Ã(i) for all i ∈ [n] and some d̃ < d, preserves the clustering structure of A within a factor φ, for some φ ",Database-friendly random projections: Johnson-Lindenstrauss with binary coins | Approximate nearest neighbors and the fast Johnson-Lindenstrauss transform | NP-hardness of Euclidean sum-of-squares clustering | Random projection in dimensionality reduction: applications to image and text data | Unsupervised feature selection for the k-means clustering problem | Clustering in large graphs and matrices | An optimal set of discriminant vectors | An introduction to variable and feature selection | Result analysis of the NIPS 2003 feature selection challenge | Laplacian score for feature selection | Approximate nearest neighbors: towards removing the curse of dimensionality | Extensions of Lipschitz mappings into a Hilbert space | A simple linear time (1+ε)-approximation algorithm for k-means clustering in any dimensions | The Mailman algorithm: A note on matrix-vector multiplication | Least squares quantization in PCM | The effectiveness of Lloyd-type methods for the k-means problem | Nonlinear dimensionality reduction by locally linear embedding | Improved approximation algorithms for large matrices via random projections | Top 10 algorithms in data mining,rejected,000
1011.4833.pdf.json,A Logical Characterisation of Ordered Disjunction,"Based on the answer set (or stable model) semantics [10] for logic programs, Answer Set Programming (ASP) [17,18] has become a successful paradigm for declarative problem solving. Typically, a logic program in ASP is used to encode some constraint-based problem in such a way that the answer sets of the program correspond to the problem solutions. In many practical scenarios, however, the set of feasible solutions is considerably large and the main problem, from the knowledge representation viewpoint, is not specifying them but selecting the most preferred ones under certain criteria instead. Although different approaches for representing preferences in ASP have been proposed (see [5] for a survey), one that has recently received much attention is the formalism of Logic Programs with Ordered Disjunction (LPOD) [3], probably due to its simplicity and expressiveness. This approach essentially consists in introducing a new operator ‘×’ standing for ordered disjunction (with its corresponding semantics ⋆ This research was partially supported by Spanish MEC project TIN-2009-14562C05-04 and Xunta de Galicia project INCITE08-PXIB105159PR. in terms of answer sets), plus several ordering relations for selecting preferred models among the obtained answer sets. LPODs have been applied, for instance, in Game Theory [9], for implementing policy languages with preferences [16,2], or in planning and argumentation scenarios [21], and they have been further investigated in [6] for studying strongly equivalent transformations and in [14] for introducing an extension called disjunctive LPOD (DLPOD) that combines ordered and regular disjunctions. Other ASP extensions like CR-Prolog, have also incorporated the use of ordered disjunctions [1]. The semantics of an LPOD is defined in two steps. First, the program with ordered disjunctions is translated into a set of normal programs, called split programs, whose answer sets become the potential solutions. In a second step, one of three possi","CR-Prolog with ordered disjunction | PDL with preferences | Logic programs with ordered disjunction | Propositional theories are strongly equivalent to logic programs | A classification and survey of preference handling approaches in nonmonotonic reasoning | Notions of strong equivalence for logic programs with ordered disjunction | A new perspective on stable models | Answer sets for propositional theories | LPOD answer sets and Nash equilibria | The stable models semantics for logic programming | Die formalen Regeln der intuitionistischen Logik | Negation as failure in the head | On the effect of default negation on the expressiveness of disjunctive rules | Towards logic programs with ordered and unordered disjunction | Strongly equivalent logic programs | Declarative policies for web service selection | Stable models and an alternative logic programming paradigm, pages 169–181 | Logic programs with stable model semantics as a constraint programming paradigm | A new logical characterisation of stable models and answer sets. In Non monotonic extensions of logic programming | The semantics of predicate logic as a programming language | Applications of preferences using answer set programming",rejected,000
1011.5202.pdf.json,Covered Clause Elimination,"Simplification techniques applied both before (i.e., in preprocessing) and during search have proven integral in enabling efficient conjunctive normal form (CNF) level Boolean satisfiability (SAT)1 solving for real-world application domains. Further, while many SAT solvers rely mainly on Boolean constraint propagation (i.e., unit propagation) during search, it is possible to improve solving efficiency by applying additional simplification techniques also during search. Noticeably, when scheduling combinations of simplification techniques during search, even quite simply ideas can bring additional gains by enabling further simplifications by other techniques. Generalizing the clause elimination procedures developed in [1], in this paper we introduce explicit (CCE), hidden (HCCE), and asymmetric (ACCE) variants of a clause elimination procedure that eliminates what we call covered clauses from CNF formulas. We compare these procedures to the analogous variants BCE, HBCE, and ABCE (see Sect. 1.1) of blocked clause elimination [1, 2] w.r.t. relative effectiveness. Definition 1. Assume two clause elimination procedures S1 and S2 that take as input an arbitrary CNF formula F and each outputs a CNF formula that consists of a subset of F that is satisfiability-equivalent to F. Procedure S1 is at least as effective as S2 if, for any F and any output S1(F) and S2(F) of S1 and S2 on input F, respectively, we have that S1(F)⊆ S2(F); S2 is not as effective as S1 if there is an F for which there are outputs S1(F) and S2(F) of S1 and S2, respectively, such that S1(F) ⊂ S2(F); and S1 is more effective than S2 if (i) S1 is at least as effective as S2, and (ii) S2 is not as effective as S1. This definition of relative effectiveness takes into account non-confluent elimination procedures, i.e., procedures that do not generally have a unique fixpoint and that may thus have more than one possible output for a given input. In fact, we show that out of the three covered clause elimination",Clause elimination procedures for CNF formulas | Blocked clause elimination | On a generalization of extended resolution,rejected,000
1011.5349.pdf.json,Distributed Graph Coloring: An Approach Based on the Calling Behavior of Japanese Tree Frogs,"Given an undirected graph G = (V,E), where V is the node set and E is the edge set, and a number k > 0 of colors, a valid k-coloring of the graph is the assignment of exactly one color to each node such that adjacent nodes (that is, nodes that are connected by an edge) do not share the same color. Formally, we say that a k-coloring of an undirected graph G = (V,E) is a function c : V → {1, 2, . . . , k} such that c(u) 6= c(v) for each edge (u, v) ∈ E. The optimization version of the graph coloring problem (GCP), which is NP -hard [22], consists in finding the minimum number k∗ of colors such that a valid k∗-coloring can be found. This number is called the chromatic number of graph G and is denoted by χ(G). The GCP is a quite generic problem. Practical applications originate especially from problems that can be modelled by networks and graphs, for example, communication networks. Several tasks in modern wireless ad-hoc networks, such as sensor networks, are related to graph coloring. Examples include TDMA slot assignment [20], detection of mobile objects and reduction of signaling actuators [38], distributed MAC layer management [18], energy-efficient coverage [9], delay efficient sleep scheduling [30] or wakeup scheduling [24]. Due to the distributed nature of these networks, algorithms for solving problems related to graph coloring are generally also required to be distributed [32]. Such algorithms make an exclusive use of local information for deciding the color of the nodes, that is, they are characterized by the absence of any central control mechanism. The goal of this paper is to device an algorithm for generating valid colorings in a distributed manner. The distributed conception of an algorithm is generally beneficial for its scalability. Moreover, in comparison to centralized approaches it is generally much easier to adapt a distributed algorithm to dynamic changes during execution. Unfortunately, the exclusive use of local information is often not sufficie","Mathematical modeling of frogs’ calling behavior and its possible application to artificial life and robotics | Modeling synchronized calling behavior of Japanese tree frogs | Optimal distributed algorithms for minimum weight spanning tree, counting, leader election, and related problems | A graph coloring heuristic using partial solutions and a reactive tabu scheme | Swarm Intelligence: Introduction and Applications | Metaheuristics in Combinatorial Optimization: Overview and Conceptual Comparison | Swarm Intelligence: From Natural to Artificial Systems | A distributed algorithm for constructing a minimum diameter spanning tree | Wireless sensor networks with energy efficient organization | Towards desynchronization of multi-hop topologies | Ant Colony Optimization | A faster distributed protocol for constructing a minimum spanning tree | An experimental analysis of simple, distributed vertex coloring algorithms | Distributed computing with advice: Information sensitivity of graph coloring | A distributed algorithm for minimumweight spanning trees | A sublinear time distributed algorithm for minimum-weight spanning trees | Low power distributed mac for ad hoc sensor radio networks | Distributed largest-first algorithm for graph coloring | A distributed TDMA slot assignment algorithm for wireless sensor networks | Variable space search for graph coloring | Reducibility among combinatorial problems | Particle swarm optimization | Wakeup scheduling in wireless sensor networks | On greedy graph coloring in the distributed model | On the complexity of distributed graph coloring | Firefly Inspired Distributed Graph Coloring Algorithms | k-Phase Oscillator Synchronization for Graph Coloring | Experiments in the dynamics of phase coupled oscillators when applied to graph coloring | Delay efficient sleep scheduling in wireless sensor networks | A memetic algorithm for graph coloring | Distributed Algorithms | A survey on vertex coloring problems | Coloring unstructured radio networks | Frog Call-Inspired Self-Organizing Anti- Phase Synchronization for Wireless Sensor Networks | A game theoretic approach for efficient graph coloring | The social behaviour of anuran amphibians | Distributed stochastic search and distributed breakout: properties, comparison and applications to constraint optimization problems in sensor networks",rejected,000
1011.5480.pdf.json,Bayesian Modeling Of An Human MMORPG Player,"With more and more CPU cores and more and more immersive gameplays, AI is becoming a key feature of video games. Non-player characters (NPC) acting against the player as well as by his side are required to behave realistically and interestingly. We model a massively multiplayer online role-playing game (MMORPG) player through Bayesian programming (Lebeltel, 2004). We bet that this model can learn to play as a given player he could observe and that it will yield a realistic robot, customized to the instructing player. A role playing game (RPG) consist in the incarnation by the human player of an avatar with a class (warrior, wizard, rogue, priest…) having different skills, spells, items, health points, stamina/energy/mana (magic energy) points. A MMORPG (e.g. World of Warcraft, AION or EVE Online) is a role-playing game in a persistent, multiplayer world. There are usually players-run factions fighting each other but we modeled a particular domain of multiplayer RPG called players versus environment (PVE). This is a cooperative task in which human players fight together against different NPC. And more specifically here, we modeled the ""druid"" class, which is complex because it can cast spells to deal damages or other negative effects as well as to heal allies or enhance their capacities (“buff” them). This model deals only with a sub-task of a global AI for autonomous NPC. The problem that we try to solve with the presented model is: how do we choose which skill to use and on which target in a PVE battle? Possible targets are all our allies and foes. Possible skills are all that we know, we aim to get a distribution over target and skills and pick the most probable combination that is as yet possible to achieve (enough energy/mana, no cooldown). For that, we first choose what should be the target given all surrounding variables: is an ally near death that he should be healed, which foe should we focus our attacks on? Once we have the distribution over possible target",An Architecture for Game Behavior AI: Behavior Multi-Queues | Bayesian Programming and Hierarchical Learning in Robotics | Handling complexity in the Halo 2 AI | It knows what you're going to do: adding anticipation to a Quakebot | Bayesian Robot Programming | Teaching Bayesian behaviours to video game characters | Probability Theory: The Logic of Science,rejected,000
1012.0322.pdf.json,A Bayesian Methodology for Estimating Uncertainty of Decisions in Safety-Critical Systems,,"Probability and Statistical Methods in Engineering Design | Multi-Objective optimization of safety related Systems: An application to short term conflict alert | Combining Pattern Classifiers: Methods and Algorithms | Classification and Regression Trees | Bayesian Methods for Nonlinear Classification and Regression | Bayesian CART model search | Bayesian averaging of classifiers and the overfitting problem, International Conference on Machine Learning | The Bayesian decision tree technique with a sweeping strategy | Bayesian inductively learned modules for safety critical systems | Reversible jump Markov Chain Monte Carlo computation and Bayesian model determination | Knowledge discovery via multiple models | Making sense of a forest of trees",rejected,000
1012.0830.pdf.json,Using ASP with recent extensions for causal explanations,"We examine a few difficulties encountered when trying to translate a logical formalism into a running answer set programming (ASP) program, showing how recent developments in ASP systems are of great help. We are not concerned here by complexity matters (also an important matter, for which exists a large literature). Rather, we deal with the ease for writing, and ∗Paper presented at ASPOCP10, Answer Set Programming and Other Computing Paradigms Workshop, associated with ICLP, Edinburgh, July 20, 2010. more importantly reading (thus modifying easily) programs in ASP for a given problem. Indeed, ASP is presented as (and is) a declarative formalism where it should be immediate to write a program from a logical formalization of a given problem. In practice, this is rarely as easy as claimed. We choose as an example a formalism that we have designed in collaboration with Philippe Besnard and Marie-Odile Cordier. This formalism aims at a logical formalization of explanations from causal and “is-a” statements. Given some information such as “fire causes smoke” and “grey smoke is a smoke”, if “grey smoke” is established, we want to infer that “fire” is a (tentative) explanation for this fact. The formalization [3, 4] is expressed in terms of rules such as “if α causes β and δ isa β, then α explains δ because {α, δ} is possible”. Here, α, ... may be first order atoms (without function symbols). Thus, we can express these rules in a “Datalog” formulation. When various explanations are possible, some of them can be subsumed by other ones, and the set of the solutions should be pruned. This concerns looking for paths in some graph and ASP is good for these tasks. There currently exist systems which are rather efficient, such as DLV1 [9] or gringo/clasp or claspD2. Transforming formal rules into an ASP program is easy. ASP should then be an interesting tool for researchers when designing a new theoretical formalization as the one examined here. An ASP program should help examini","Knowledge representation, reasoning and declarative problem solving | Macros, Macro Calls and Use of Ensembles in Modular Answer Set Programming, ICLP | Ontology-based inference for causal explanation, KSEM 2007, in LNAI 4798 | Ontology-based inference for causal explanation, Integrated Computer- Aided Engineering | Template programs for Disjunctive Logic Programming: An operational semantics | The Conflict-Driven Answer Set Solver clasp: Progress Report | Nonmonotonic Causal Theories | Causes and Explanations: A Structural-Model Approach - Part II: Explanations | The DLV System for Knowledge Representation and Reasoning | The Facts of Causation | An Experience of Using ASP for Toy Examples, ASP’07, in Advances in Theory and Implementation, publ | Causal Logic | A Language for Modular Answer Set Programming: Application to ACC Tournament Scheduling, ASP 05, M. De Vos and A Provetti (eds), Answer Set Programming, Advances in Theory and Implementation, CEUR-WS.org publ",rejected,000
1012.1615.pdf.json,Argudas: arguing with gene expression information,,"Scientific argumentation in pre-service biology teacher education | Analysis of large data sets using formal concept lattices | Anatomy ontologies for bioinformatics: principles and practise, chap | Argumentation in artificial intelligence | Information Technology & Lawyers: Advanced technology in the legal domain, from challenges to daily routine, chap | Sealife evaluation | Argumentation-based inference and decision making - a medical perspective | Capturing expert knowledge with argumentation: a case study in bioinformatics | aGEM: an integrative system for analyzing spatial-temporal gene-expression information | The data warehouse ETL toolkit: practical techniques for extracting, cleaning, conforming, and delivering data | Evaluation of a semantic web application for collaborative knowledge building in the dementia domain | Using argumentation to tackle inconsistency and incompleteness in online distributed life science resources | Towards the use of argumentation in bioinformatics: a gene expression case study | Using argumentation to resolve conflict in biological databases | The new rhetoric: a treatise on argumentation | Argument-based negotiation | Knowledge-driven enhancements for task composition in bioinformatics | Law, Ontologies and the Semantic Web, Channelling the Legal Information Flood, Frontiers in Artificial Intelligence and Applications, vol | Dialectical argumentation with argument schemes: an approach to legal logic | Argumentation Schemes | A little semantic web goes a long way in biology",rejected,000
1012.1619.pdf.json,Are SNOMED CT Browsers Ready for Institutions? Introducing MySNOM,"The Systematized Nomenclature of Medicine - Clinical Terms (SNOMED CT) has become a reference terminology [1] and an active research topic in both the healthcare and the Semantic Web communities [2] [3]. An effective way to advance research in ontologies for the life sciences in general, and in SNOMED CT in particular, is by providing appropriate software to researchers and practitioners. In particular, visualization and browsing tools can provide a better understanding of the structure and complexity of a biomedical terminology. There are lists of existing browsers, such as the ones provided by The National Library of Medicine of the United States1 and the United Kingdom’s National Health Service2, in order to provide researchers and practitioners with a reference. These lists, however, are not comprehensive, not up to date, and have not been fully ranked or evaluated. These lists can also be misleading for practitioners: as an example, Protégé3 is listed as a SNOMED CT browser. In 2008, Rogers [4] performed a study of existing SNOMED CT browsers and developed a general catalog of desirable browsing features. In this paper we present a SNOMED CT web-based browser called MySNOM, aiming at showing the structure of SNOMED, with support for rich diagrams. 1 www.nlm.nih.gov/research/umls/Snomed/snomed_browsers.html 2 www.connectingforhealth.nhs.uk/systemsandservices/data/snomed/browser 3 protege.stanford.edu ar X iv :1 01 2. 16 19 v1 [ cs .A I] 7 D ec 2 01 0","Survey of current terminologies and ontologies in biology and medicine: Elect | Examining SNOMED from the perspective of formal ontological principles: Some preliminary analysis and observations | Ontological analysis of SNOMED CT: BMC Medical Informatics and Decision Making vol | SNOMED CT: Browsing the Browsers | An Extension to HTTP : Digest Access Authentication | Drawing Graphs With Dot | Graphviz Open Source Graph Drawing Tools | Modular Ontologies: Concepts, Theories and Techniques for Knowledge Modularization: LNCS",rejected,000
1012.1635.pdf.json,,"The combination of Ontologies and Text Mining (TM) has been considered important within the life science research community, to keep track of knowledge reported in the increasing accumulation of scientific literature available online (e.g. [5]). Although most of them have not been developed for natural language analysis [3], ontological resources provide domain knowledge required by text mining systems. Ontologies can provide a structured and semantically richer representation for text mining systems. They will provide the capability of natural language processing (NLP) systems to run reasoning over natural language. Furthermore, they will provide the framework for a consistent semantic integration of the various resources used throughout a text mining system, and also the integration of knowledge extracted from text and from other different resources like databases. This is consistent with the vision of the Semantic Web. In this paper we dealt with one of the issues for the combination of the two technologies, comparing and linking lexical resources with domain knowledge provided by ontologies. Neither ontologies nor their interplay with the lexical resources have received much attention in the development of lexical resources for the bio-medicine domain, although in very beginning domain ontologies have been considered important resources. In this paper we explicitly linked the FrameNet [1] semantic frames with the concepts from the biological process ontology of the Gene Ontology (GO) The result shows the gaps between the linguistics-oriented and domain-specific semantics on the classification of events and the grouping of target words. It provides valuable information for the improvement of domain ontologies support for text mining systems. And also, it will result in benefits to language understanding technology. The Gene Ontology has been widely used as knowledge base for NLP systems in the domain. Among the three subontologies of terms, biological process ont",The Berkeley FrameNet project | BioFrameNet: a FrameNet extension to the domain of molecular biology | Selecting an Ontology for Biomedical Text Mining | Bridging the Gap between Domain-Oriented and Linguistically-Oriented Semantics | CJO: Ontology Design for Biomedical Text Mining. In Semantic Web: Revolutionizing Knowledge Discovery in the Life Sciences,rejected,000
1012.1643.pdf.json,Process Makna - A Semantic Wiki for Scientific Workflows,"Scientific Workflows underlie the large-scale complex e-science applications and infrastructures, e.g., lab experiments, simulations, complex knowledge-intensive research questions. Compared with business workflows, a scientific workflow has special features such as computation, data or transaction intensity, knowledge-intensive human expert interaction, and a large number of activities including management of virtual organisations such as research collaborations and research teams. The described emerging computing infrastructures with powerful computing and resource sharing capabilities present the potential for accommodating those special features. There are many industrial-strength Business Process Management (BPM) workflow tools available. However when it comes to knowledge-intensive scientific workflows, practical experiences have shown that the modelled scientific process representations are often not enacted correctly, consistently and homogenously. The reality of daily work of a researcher involves different science domains, different roles, and heterogeneous information and data objects. Moreover, the scientific processes are subject to frequent changes and exceptions which require flexible compensations and many human interactions. Traditional BPM approaches such as “Peoplelinks”, “Partnerlinks”, “Exceptions”, “Compensations” provide limited support for coordination, collaboration and integration in scientific workflows due to the lack of semantics and intuitive easy to use interfaces for human computer interactions. In this paper, we present a solution for this through the integration of our Process Makna Semantic Wiki with a BPM workflow system. While the Wiki makes it easy to collaboratively author and add the required input data at runtime at the user front-end, the BPM system running in the back-end executes and enforces the process workflow. The Semantic Web extension of the Wiki allows establishing an explicit domain model in the back-end which repr",The fungalweb ontology: Semantic web challenges in bioinformatics and genomics | Rule responder HCLS eScience | Semantic Wikipedia | Knowledge representation concepts for automated SLA management,rejected,000
1012.1646.pdf.json,Use of semantic technologies for the development of a dynamic trajectories generator in a Semantic Chemistry eLearning platform,"Learning is a very trying and individual process for any single user of an eLearning environment. Especially unskilled learners require either a human teacher/ tutor or a very intelligent, personalized artificial intelligence of the eLearning environment to be guided by an individual learning procedure and learning path. Also with more experienced learners the studying process of an individual can be optimized by personalized didactics, dynamic assembly of pages and units and in a strong way by an appropriate and distinct teaching path. To distinguish the results of personalized, individual didactics, composition of page content and path generation from traditional eLearning content and hardcoded paths we henceforth call the dynamically generated, individual teaching paths “Dynamic eLearning Trajectories” (DeLTs). To increase the acceptance of an educational platform this device should be able to large sets of user data available. The generation of user data based on traditional platform techniques requires a registration process with precise monitoring of knowledge, personal background, level of experience, performance, and additional personal skills. However, this monitoring process may cause rejection of users from certain user groups like business workers who might be afraid of surveillance by colleagues or by their company’s management. Any registration process poses a barrier for free participation and decreases the amount of users of a platform. Lower numbers of users weaken the market position of the platform. For a freely available eLearning platform there are only two ways to build up a DeLT system: Analyze session information or offer value added service in turn for registration. In the first approach the system compares background knowledge with information of a single user which has been collected over a short period of time during his/her current session. As a result of this semantic analysis the system might recommend paths and try to deliver content ",,rejected,000
1012.1648.pdf.json,Analysis of Cancer Omics Data In A Semantic Web Framework,"The Yale Specialized Program in Research Excellence (SPORE) in skin cancer is a large translational cancer project, which aims at rapidly moving biological insights from the “bench to bedside”. As part of the effort, the SPORE collects skin cancer samples from mostly malignant melanoma patients and performs a multitude of Omics studies, probing the melanoma genome, epigenome, transcriptome and proteome. The idea is to integrate this data with clinical outcome information to derive prognostic and predictive biomarkers, i.e. genomic markers that predict patient survival and drug therapy effectiveness, respectively. Conventionally, these markers are either derived statistically in an unbiased fashion [33], or by prior knowledge and candidate (gene) selection [17]. We are interested in combining these approaches, and are developing means for unbiased assessment of Omics data using existing knowledge on cellular processes that affect ar X iv :1 01 2. 16 48 v1 [ cs .A I] 8 D ec 2 01 drug effectiveness. In particular, we are employing Semantic Web technology to create RDF graphs that define the genomic state of cancer cells and the functional annotation of the cells’ molecular entities (i.e. genes or proteins). We use SPARQL to query these graphs to better understand the molecular basis of drug resistance and sensitivity. We start by retrieving quantitative data from a large relational database, a component of the Corvus architecture [19], storing melanoma Omics data. We do this by providing a new semantic component of Corvus, a SPARQL endpoint which relies upon Hibernate 1 for Object Relational Mapping (ORM). Through this endpoint, we can dynamically create RDF graphs of the data stored within. We then merge such graphs with SKOS-converted Gene Ontology (GO) [1] information to annotate genomic elements with functional data, such as their involvement in certain cellular processes. As a case study, we used the new Corvus SPARQL endpoint to create an RDF graph with data repr","Gene ontology: tool for the unification of biology | R2O, an extensible and semantically based database-to-ontology mapping language | Cooking the Semantic Web with the OWL API | Bio2RDF: Towards a mashup to build bioinformatics knowledge systems | D2RQ-treating non-RDF databases as virtual RDF graphs | RDF-based schema mediation for database grid | Exposing heterogeneous data sources as SPARQL endpoints through an object-oriented abstraction | The owl of biomedical investigations | caCORE: a common infrastructure for cancer informatics | The Sequence Ontology: a tool for the unification of genome annotations | BioBIKE: A Web-based, programmable, integrated biological knowledge base | The Cancer Biomedical Informatics Grid (caBIG¡ sup¿ TM¡/sup¿) | Integrative analysis of epigenetic modulation in melanoma cell response to decitabine: clinical implications | Cancer microarray informatics (caArray) data management and analysis tools at the National Cancer Institute (NCI) Center for Bioinformatics | Rewriting Queries by Means of Model Transformations from SPARQL to OQL and Vice-Versa | Evolution of decitabine development | Genome-wide screen of promoter methylation identifies novel markers in melanoma | BioLingua: a programmable knowledge environment for biologists | Semantic web data warehousing for caGrid | Provenance of High Throughput Biomedical Experiments | SKOS Core: Simple knowledge organisation for the web | A multigene assay to predict recurrence of tamoxifen-treated, node-negative breast cancer | MEDME: an experimental and analytical methodology for the estimation of DNA methylation levels based on microarray derived MeDIP-enrichment | HyBrow: a prototype system for computer-aided hypothesis evaluation | Genome-wide methylation and expression profiling identifies promoter characteristics affecting demethylation-induced gene up-regulation in melanoma | An ontology-driven semantic mashup of gene and biological pathway information: Application to the domain of nicotine dependence | A survey of current approaches for mapping of relational databases to RDF | Deductive biocomputing | Pellet: A practical owl-dl reasoner | The OBO Foundry: coordinated evolution of ontologies to support biomedical data integration | Relations in biomedical ontologies | Using Semantic Web Technologies to Annotate and Align Microarray Designs | Gene expression profiling predicts clinical outcome of breast cancer | The Dublin Core: a simple content description model for electronic resources",rejected,000
1012.1654.pdf.json,Using Semantic Wikis for Structured Argument in Medical Domain,,Laying the foundations for a world wide argument web | From the semantic web to social machines: A research challenge for AI on the World Wide Web | Semantic wikis: A comprehensible introduction with examples from health sciences | Tim: A semantic web application for the specification of metadata items in clinical research | The structure of argumentation in health product ads,rejected,000
1012.1658.pdf.json,Creating a new Ontology: a Modular Approach,"Ontologies in life sciences, in particular, members of the OBO Foundry [6], contain information about species, proteins, chemicals, genomes, pathways, diseases, etc. Information in these ontologies might overlap, and it is possible that a certain concept is defined in different ontologies from a different point of view and at different level of granularity. Therefore, the combination of information from different ontologies is useful to create a new ontology. Case Study The integration will be illustrated with a case study on Toll-like receptors. If we want to investigate what kind of information about Toll-like receptors is available in Molecule Role Ontology (MoleculeRoleOntlogy) [6], then we will see that Toll-like receptors are defined as pattern recognition receptors. In the Biological Process Ontology (GO) [6] the Toll-like receptors are described in the context of signaling pathway and are subsumed by the pattern recognition receptor signaling pathway. In the Protein [6] ontology a Toll-like receptor is just a protein. In the NCI Thesaurus [5] ontology Toll-like receptors are defined as Cell Surface Receptors. It follows from foregoing that multiple ontologies model different aspects of the same concept and the combination of the available information provides more knowledge about concepts where an ontology developer is interested in. We introduce an approach for generating a new ontology in which ontologies from OBO Foundry are reused. First, we extract modules from these ontologies, on the basis of the well defined modularity approach [2]. As a signature for the modules we are using the symbols that match the terms of interest as indicated by the user. In our case study we create an ontology about Toll-like receptors, therefore we use two seed terms (Toll, TLR). Subsequently, we create mappings between concepts in the modules. It has already been shown [1] that the simple similarity algorithms outperform structural similarity algorithms in biomedical ontolo","Creating mappings for ontologies in biomedicine: Simple methods work | Extracting modules from ontologies: A logic-based approach | Ontology mapping: The state of the art | Binary codes capable of correcting, deletions, insertions, and reversals | Pellet: A practical owl-dl reasoner",rejected,000
1012.1659.pdf.json,First steps in the logic-based assessment of post-composed phenotypic descriptions,"A phenotype is defined as a basic observable characteristic of an organism. Thus, a set of phenotypic descriptions may involve different domains and granularities ranging from molecular to organism level. Phenotypic descriptions have been recently described by means of terminological resources, with the Human Phenotype Ontology (HPO) [1] being a prominent example. The HPO ontology represents a so-called pre-composed description: it does not provide explicit links between the phenotypic descriptions (e.g. increased calcium concentration in blood) and the relevant entities associated to it, such as the chemical element involved (“calcium”), the way in which it is involved (“increased concentration”) and where it appears (“blood”). Post-composed phenotypic descriptions intend to provide a more formal representation to interoperate with involved entities [2] and to allow more powerful reasoning. Nevertheless, the formal representation of phenotypic descriptions is still a challenge [3, 4] owing to the complex nature of some phenotypes and the lack of consensus among clinicians to describe them in a standard way. Mungall et al. [3] and Hoehndorf et al. [4] have recently proposed automatic and semi-automatic methods to transform pre-composed phenotypic descriptions into a description logic (DL) based post-composed representation linked to domain ontologies. The integration of domain ontologies with post-composed phenotypic descriptions presents new challenges since most of the involved ontologies are developed independently and may perform a different conceptualization for the same entities. Therefore, this integration may not always lead to the expected and proper logical consequences [5, 6]. In this paper we present first steps towards the logic-based assessment of the integration of phenotypic descriptions with domain ontologies. ar X iv :1 01 2. 16 59 v1 [ cs .A I] 8 D ec",The Human Phenotype Ontology | Terminological mapping for high throughput comparative biology of phenotypes | Integrating phenotype ontologies across multiple species | Interoperability between phenotype and anatomy ontologies | Ontology integration using mappings: Towards getting the right logical consequences | Logic-based assessment of the compatibility of UMLS ontology sources. Accepted for publication | Using ontologies to describe mouse phenotypes | Symbolic modeling of structural relationships in the foundational model of anatomy | The OBO foundry: coordinated evolution of ontologies to support biomedical data integration. Nature biotechnology | Modular reuse of ontologies: Theory and practice | Relations as patterns: bridging the gap between OBO and OWL | Hypertableau Reasoning for Description Logics | The logical difference problem for description logic terminologies. In: IJCAR,rejected,000
1012.1661.pdf.json,Analysis and visualisation of RDF resources in Ondex,,"Advancing translational research with the Semantic Web, BMC Bioinformatics, 8 (Suppl | Graph-based analysis and visualization of experimental results with Ondex | Semantic Data Integration for Systems Biology Research, Technology Track at ISMB’09 | Ondex semantic definition, (Web document) http://ondex.svn.sourceforge.net/viewvc/ondex/trunk/doc/semantics",rejected,000
1012.1667.pdf.json,,"Contemporary research in the Life Sciences depends on the sophisticated integration of large amounts of data obtained by in-house experiments with reference databases available on the web. This is followed by analysis workflows that rely on highly specific algorithms, often available as web services. The amount of data produced and consumed by this process is prodigious; however, the sheer amount of available resources is a source of severe difficulties. Within this huge set of resources, one of the main problems to the user is finding the right web services for a given research task. The landscape of Life Sciences web services is large and complex: there are thousands of resources [1], most of them available in public repositories, i.e. BioCatalogue [3], but unfortunately only a few are described by adequate metadata, which is essentially textual in nature and this makes the discovery and the integration difficult. In addition, there are many versions of different services that apparently provide the same broad functionality, but not enough metainformation is available to decide which of these services is the most appropriate for a precise task. Given this context, it is a pressing question how to help researchers to discover the best possible mapping between their requirements and the available tools. We present a semi-automatic approach to assist the researcher in web service discovery, looking for web services that are appropriate to fulfill the information requirements in the Life Sciences domain. The whole process is driven by wellcaptured requirements, in order to avoid the high costs associated with nondisciplined, non-reusable, ad-hoc development of integration applications. The matching between the requirements and web services is based on a semantic normalization of both the requirements and the web services metadata.",Semantic annotation of biomedical texts through concept retrieval | BioCatalogue: a universal catalogue of web services for the life sciences | Requirements gathering in a model-based approach for the design of multi-similarity systems | A string metric for ontology alignment | Modelling Strategic Relationships for Process Reenginering,rejected,000
1012.1743.pdf.json,Scientific Collaborations: Principles of WikiBridge Design,"Collaborative environments for scientific knowledge are essential for scientists to formalize their ideas and to develop theories collaboratively. Large numerous corpuses created in a collaborative effort have emerged in recent years. For example the encyclopedia Wikipedia contains human-readable articles with texts, images which are grouped into categories and access with a full text search engine. Despite the power of wiki, it is difficult to answer a specific query because of the purely textual information stored. As a result, automated tools cannot understand knowledge and thus exploit it. Semantic wikis offer an open environment which allows to aggregate knowledge produced by different teams involved in different research fields. It also allows interoperability among corpuses in case of annotations defined using ontologies. Nevertheless, representing and managing life sciences data and related knowledge require a deep understanding of life sciences concepts. Chen and Carlis in [2] have identified four challenging characteristics that make difficult modeling in life sciences : 1) complexity of data (heterogeneous, incomplete, uncertain, inconsistent, multi-dimensional); 2) domain knowledge barrier; 3) evolving knowledge and 4) modeling skills of actors. Our main objective is to build a platform that allows: 1) to capture both free and controlled data; 2) to verify that annotations have meaning in relation to domain knowledge; 3) and to ensure a reasonable cost of developing and maintaining. The rest of the paper is organized as follow: section 2 describes the state of art of semantic wikis in Life Sciences, section 3 presents the design principles of WikiBridge. Finally, section 4 concludes the paper.","Semantic Wikis: A Comprehensible Introduction with Examples from the Health Sciences | Genomic data modeling | Creating and using Semantic Web information with Makna | Lab service Wiki: a wiki-based data management solution for laboratories production services | BOWiki: an Ontology-based Wiki for Annotation of data and Integration of Knowledge in Biology | OpenDrugWiki - Using a Semantic Wiki for Consolidating, Editing and Reviewing of Existing Heterogeneous Drug Data | Brede Wiki: a neuroinformatics Web service with structured information | Semantic annotation for knowledge management: Requirements and a survey of the state of the art",rejected,000
1012.1745.pdf.json,Populous: A tool for populating Templates for OWL ontologies,"Ontologies are being developed to provide controlled vocabularies for the annotation of life science data. Annotating data with ontologies adds semantics to the data that can facilitate data integration and enrich data analysis[18], [5], [3]. For ontologies to have a faithful representation of a domain, experts from that domain must have input to the authoring process. There are barriers that prevent domain experts engaging in an ontology’s development; in particular, the semantics of an ontology language, or the intricacies of the authoring tools. To address this issue we have developed Populous that allows users to contribute their knowledge by populating simple templates that are then transformed to statements in the underlying representation language. When designing an ontology it is often the case that repeating patterns occur in the modelling. These patterns can be abstracted from the ontology and used to specify simple templates that could be populated by domain experts [7,6,2]. As an example of a pattern, consider an ontology about cells; eukaryotic cells can be classified as being either anucleate, mono-nucleate, binucleate or multinucleate. ar X iv :1 01 2. 17 45 v1 [ cs .A I] 8 D ec 2 01 We can abstract over this pattern to say that every cell can be classified by its nucleation. This pattern is repeated for all cell types; the only variables are the cell name and the value for its nucleation. We can now use this pattern to build a simple template that could be populated by a cytologist, without him or her ever knowing about the underlying ontological representation. This type of pattern is common in ontology development where you have one set of entities being described in terms of another set of entities [17]. The tabular layout provides a simple and intuitive form fill-in style of user interface for a user to populate such templates. Typically, each row corresponds to a set of related entities and each column represents the type of relationship. The in",RDF123: From Spreadsheets to RDF | Ontology Design Patterns for bio-ontologies: a case study on the Cell Cycle Ontology | Gene ontology: tool for the unification of biology | An ontology for cell types | Ontologies and data integration in biomedicine: Success stories and challenging issues | Applying Ontology Design Patterns in Bio-ontologies | Ontology design patterns for semantic web content | Using ontologies to describe mouse phenotypes | The adult mouse anatomical dictionary: a tool for annotating and integrating data | The Manchester OWL syntax | Embedding knowledge patterns into owl | Developing a Kidney and Urinary Pathway Knowledge Base | Bioportal: ontologies and integrated data resources at the click of a mouse | M2: a Language for Mapping Spreadsheets to OWL. In OWL: Experiences and Directions (OWLED) | Mapping Master: a Spreadsheet to OWL Mapping Language | Overcoming the ontology enrichment bottleneck with quick term templates | Modularisation of domain ontologies implemented in description logics and related formalisms including owl | The obo foundry: coordinated evolution of ontologies to support biomedical data integration | Relations in biomedical ontologies | RightField: Rich Annotation of Experimental Biology Through Stealth Using Spreadsheets,rejected,000
1012.2148.pdf.json,Bisimulations for Fuzzy Transition Systems,,"Pattern recognition using temporal fuzzy automata | Exact performance equivalence: an equivalence relation for stochastic automata | Bisimulation relations for weighted automata | Fuzzy reasoning supported by Petri nets | Task sequence planning using fuzzy Petri nets | A fuzzy Petri-nets model for computing with words | Supervisory control of fuzzy discrete event systems | Retraction and generalized extension of computing with words | Fuzzy Petri net: an overview | A description of the dynamic behavior of fuzzy systems | Bisimulation for probabilistic transition systems: a coalgebraic approach | New directions in fuzzy automata | Theory of extended fuzzy discreteevent systems for handling ranges of knowledge uncertainties and subjectivity | Fuzzy Sets and Systems: Theory and Applications | A survey on analysis and design of model-based fuzzy control systems | Reactive, generative, and stratified models of probabilistic processes | Equivalence in knowledge representation: automata, recurrent neural networks, and dynamical fuzzy systems | Fuzzy Petri net | Fuzzy Switching and Automata: Theory and Applications | Formal verification of parallel programs | A limit theorem in some dynamic fuzzy systems | Bisimulation through probabilistic testing | Fuzzy Turing machines: variants and universality | Approximation and robustness of fuzzy finite automata | Modeling and control of fuzzy discrete event systems | An overview of probabilistic process algebras and their equivalences | Communication and Concurrency | Fuzzy Automata and Languages: Theory and Applications | Concurrency and automata on infinite sequences | Fuzzy Control and Fuzzy Systems | A generalized fuzzy Petri net model | Congruences and homomorphisms of fuzzy automata | Supervisory control of fuzzy discrete event systems: a formal approach | Fuzzy stochastic automata for intelligent vehicle control | Maxmin automata | Bisimulation relations for fuzzy finite automata | A lattice-theoretical fixpoint theorem and its applications | On generalizations of adaptive algorithm and application of the fuzzy sets concept to pattern classification, Ph.D | A formulation of fuzzy automata and its application as a model of learning systems | Models for concurrency | Fuzzy automata with fuzzy relief | Fuzzy sets and systems",rejected,000
1012.2162.pdf.json,Nondeterministic fuzzy automata,"Finite automata (also called finite-state automata or finite-state machines) are probably best known computational devices and are used to model operations of many systems in practice. Automata theory is closely related to formal language theory as the automata are often classified by the class of formal languages they are able to recognize [15]. A finite automaton gives a finite representation of a regular language that may be an infinite set. It is widely known that finite automata are significant in many different areas, including computer science, linguistics, mathematics, electrical engineering, philosophy, and biology. To deal with imprecision due to fuzziness in modeling some systems, fuzzy automata and fuzzy languages have been proposed as a reasonable extension of classical automata and formal language theory. The mathematical formulation of fuzzy automata was first proposed by Wee in 1967 [36]. The basic idea in the formulation is that, unlike the classical case, a fuzzy automaton can switch from one state to another one to a certain possibility degree, and thus it is capable of capturing the uncertainty appearing in states or state transitions of a system. A fuzzy language over an alphabet Σ, originally introduced in [18, 25], is defined as a fuzzy subset of Σ∗, where Σ∗ stands for the Kleene closure of Σ. In this sense, a fuzzy language L allows for strings in Σ∗ that are not completely in or out the language; rather each string s has a membership grade L(s), which measures its degree of membership in L. In the literature up to now, various variants of fuzzy automata have been proposed in different modeling situations (see, for example, [2, 6, 7, 8, 9, 10, 16, 17, 22, 23, 26, 27, 28, 33, 38]) and the notions of fuzzy automata and fuzzy languages have proved useful in many areas [1, 4, 11, 12, 13, 20, 21, 30, 31, 32, 34, 35, 37, 39]. In terms of fuzzy transition functions, fuzzy automata may be broadly classified into three types: The first type [1, 3, 6,",Fuzzy automata with -moves compute fuzzy measures between strings | A bibliography on fuzzy automata | Algebraic aspects of families of fuzzy languages | Pattern recognition using temporal fuzzy automata | Determinism and fuzzy automata | Supervisory control of fuzzy discrete event systems | Retraction and generalized extension of computing with words | New directions in fuzzy automata | Fuzzy Sets and Systems: Theory and Applications | Fuzzy tree automata | Parameter identification of recurrent fuzzy systems with fuzzy finite-state automata representation | Deformed fuzzy automata for correcting imperfect strings of fuzzy symbols | Encoding nondeterministic fuzzy tree automata into recursive neural networks | Communicating Sequential Processes | Introduction to Automata Theory | Fuzzy Switching and Automata: Theory and Applications | Fuzzy ω-automata | Note on fuzzy languages | Approximation and robustness of fuzzy finite automata | Fuzzy Turing machines: variants and universality | Fuzzy finite automata and fuzzy regular expressions with membership values in lattice-ordered monoids | The relationships among several types of fuzzy automata | Modeling and control of fuzzy discrete event systems | On fuzzy regular languages | Some considerations on fuzzy automata | Fuzzy Automata and Languages: Theory and Applications | Characterizations of fuzzy finite automata | Supervisory control of fuzzy discrete event systems: A formal approach | Finite automata and their decision problems | Fuzzy state automata and applications to mobile robot control | Fuzzy stochastic automata for intelligent vehicle control | Fault detection and isolation based on fuzzy automata | Fuzzy automata and languages | Clinical monitoring with fuzzy automata | Fuzzy automata with fuzzy relief | On generalizations of adaptive algorithm and application of the fuzzy sets concept to pattern classification | A formulation of fuzzy automata and its application as a model of learning systems | Fuzzy pushdown automata | A fuzzy discrete event system approach to determining optimal HIV/AIDS treatment regimens | Fuzzy sets,rejected,000
1012.2496.pdf.json,On the Implementation of GNU Prolog,"GNU Prolog’s roots go back to the start of the 1990s at the Logic Programming research team at INRIA Rocquencourt, in Paris. Philippe Codognet planned on implementing a low-level version of his intelligent backtracking techniques and opted to do so on the state-of-the art SICStus Prolog system, for which he obtained the source code. This task was handed down to Daniel Diaz, at that time an M.Sc. student. However, at the time SICStus Prolog was already a very large scale and ar X iv :1 01 2. 24 96 v2 [ complex system: version 2.1 had about 70,000 lines of highly tuned and optimized C and Prolog code: clearly not the easiest platform on which to carry out independent, low-level experiments. So we took it upon ourselves to develop yet another implementation of Prolog which would meet the following requirements: • The system ought to serve as the basis for several research-oriented extensions such as: intelligent backtracking, co-routining (freeze was a hot topic back then), concurrency, constraints, etc. • The system would be made available freely to all researchers. • The system would be portable by design, not tied to any particular architecture. • The core of the system must be simple and lightweight, unlike SICStus. • The base system performance should be good. The rationale being that a system designed to be extended needs to provide good base performance. We targeted performance close to that of SICStus Prolog native code. The last two points (simplicity and performance) were hard to reconcile. This was particularly true at a time where research on WAM optimization was a hot topic: choice points, backtracking, unification, indexing, register allocation, etc.: all aspects of the WAM were the object of published research on optimizations thereof. The goals we had set for ourselves seemed difficult to reach and rather ambitious: performance with a simple implementation, all done with little or no optimizations. At the time, most Prolog systems were based on byte-cod","Objective: In minimum context | Warren’s Abstract Machine: A Tutorial Reconstruction | Casting the WAM as an EAM | Design and Implementation of an Or-Parallel Prolog Engine | A portable and efficient implementation of kl1 | Wamcc: Compiling prolog to c | Compiling constraints in clp(fd) | The design of the yap compiler: An optimizing compiler for logic programming languages | A minimal extension of the wam for clp(fd) | Multiple specialization of wam code | jc: An Efficient and Portable Sequential Implementation of Janus | Turbo erlang: Approaching the speed of c | Native code compilation in sicstus prolog | Constraint logic programming | C--: A Portable Assembly Language | LLVM: a compilation framework for lifelong program analysis transformation | XSB: A system for efficiently computing well-founded semantics | YapTab: A tabling engine designed to support parallelism | On applying or-parallelism and tabling to logic programs | Foundations of Constraint Satisfaction | Parallel constraint satisfaction in logic programming: Preliminary results of chip within pepsys | Design, implementation, and evaluation of the constraint language cc(fd) | High-performance logic programming with the aquarius prolog compiler | An Abstract Prolog Instruction Set | Linear tabling strategies and optimizations",rejected,000
1012.2609.pdf.json,Inverse category frequency based supervised term weighting scheme for text categorization,,"LIBSVM: A Library for Support Vector Machines, http://www.csie.ntu.edu.tw/ cjlin/libsvm | A Statistical Interpretation of Term Specificity and Its Application in Retrieval | Text categorization with support vector machines – How to represent texts in input space | frequency approach and mutual information algorithm | Term-weighting approaches in automatic text retrieval | A re-examination of text categorization methods",rejected,000
1012.2713.pdf.json,Phase Transitions of Plan Modification in Conformant Planning,"Artificial Intelligence (AI) planning involves generating a series of operators leading from the initial world description to the goal world description[1]. Whenever a system needs to take into account operators and goals, AI planning is an important component. Therefore, AI planning techniques have been widely used in many engineering problems. For example, classical planning has successfully applied to autonomous controller for NASA’s Deep Space One spacecraft, scheduled to be launched in late 1998[2]. Off-the-shelf conformant planning tools are exploited to solve message-based Web Service Composition in a general form that involves powerful ontologies[3]. As an extension of classical planning, conformant planning is the problem of finding a sequence of operators for achieving a goal in the presence of uncertainty in the operators or initial state[4,5]. Since conformant planning is computationally harder than classical planning, researchers explore approaches of solving the problem and plan modification is one of them. Plan modification is formalized as a process of removing inconsistencies in the validation structure of a plan when it is being reused in a new or changed planning situation[6]. Without generating a plan from scratch, which is actually a process of resource and time consuming, plan modification has long been recognized as a valuable tool for the improvement of efficiency in planning systems. Recently, Nebel and Koehler in [7] discuss the relationship between plan modification and plan generation pointing out that sometimes modifying a plan is not computationally as easy as planning from scratch. In consequence, some most interesting questions are put forward. Under which circumstances it is worthwhile to adopt plan modification and under which circumstances it isn’t worthwhile to adopt plan modification. Whether there exists a rapid transition between almost all plan problems are solved with plan modification and almost all plan problems aren’t solv","STRIPS: A New Approach to the Application of Theorem Proving to Problem Solving | Message-Based Web Service Composition, Integrity Constraints, and Planning under Uncertainty: A New Connection | Expressive planning and explicit knowledge | Conformant graphplan | A Validation-Structure-Based Theory of Plan Modification and Reuse | Plan Modification versus Plan Generation: A Complexity-Theoretic Perspective | Conformant Planning via Model Checking | Planning with incomplete information as heuristic search in belief space | Conformant Planning via Heuristic Forward Search: A New Approach, | Compiling Uncertainty Away: Solving Conformant Planning Problems using a Classical Planner, | Conformant Planning Heuristics | Flexible Reuse of Plans via Annotation and Verification, | A Theory of Plan Modification, | Mackie,”Treatment plan modification using voxelbased weighting factors/dose prescription, | Flexible plan reuse in a formal framework | Solution reuse in dynamic constraint satisfaction problems, | Critical Behavior in the Satisfiability of Random Boolean Expressions, | The TSP phase transition, | Exact Phase Transitions in Random Constraint Satisfoperator Problems, | Random MAX SAT, random MAX CUT, and their phase transitions, | Beyond NP the QSAT phase transition, | Complexity of Planning with Partial Observability, | Cambridge, Massachusetts, “Introduction to Algorithms, | From conformant into classical planning: efficient translations that may be complete Too, | Planning Graph Heuristics for Belief Space Search, | Complexity of Planning with Partial Observability, | Constraint Partitioning in Penalty Formulations for Solving Temporal Planning Problems, | Decrease Observation Variables for Strong Planning under Partial Observation, | Phase transition in a random NK landscape model, | Task decomposition on abstract states, for planning under nondeterminism,",rejected,000
1012.3018.pdf.json,,"Temporal Logic Model Checking [20] is a verification method for discrete systems. In a nutshell, the system, often called the model, is described by the possible transitions of its components, while the properties to verify are encoded in a temporal modal logic. It is used, for example, for the verification of protocols and hardware circuits [5]. Many tools, called model checkers, have been developed to this aim. The most famous ones are SPIN [35] and SMV [43] (with its many incarnations: NuSMV [17], RuleBase [6]), VIS [8], and FormalCheck [34]. There are many languages to express the model; the most widespread ones are Promela and SMV. Two temporal logics are mainly used to define the specification: CTL [20] and LTL [45]. In this paper we focus on the latter. In many cases, the two inputs of the model checking problem (the model and the formula) can be processed in a different way. If we want to verify several properties of the same system, it makes sense to spend more time on the model alone, if the verification of the properties becomes faster. Many tools allow to build the model separately from checking the formula [16, 53, 36]. This way, one can reuse the same model, compiled into a data structure, in order to check several formulae. In the same way, we may wish to verify the same property on different systems: the property is this time the part we can spend more time on. Many tools allow populating a property database [16, 53, 36], i.e., a collection of temporal formulae which will be checked on the models. We imagine a situation in which we early establish the requirements that our system must satisfy, even before the system is actually designed. As a result, and we can fill a database of temporal formulae, but we do not yet describe the system. While the design/modeling of the system goes on, we can preprocess the formulae (without knowledge of the model, which is not yet known). Whenever the system is specified, we can then use the result of this preprocess","Symbolic reachability analisys based on SAT-solvers | Algebraic decision diagrams and their applications | The complexity of searching implicit graphs | The complexity of algorithmic problems on succinct instances, pages 351–377 | Methodology and system for pratical formal verification of reactive hardware | On the fly model checking for rctl formulas | Symbolic model checking without BDDs | VIS: a system for verification and syntesis | Verification of arithmetic circuits using binary moment diagrams | On the complexity of vlsi implementations and graph representations of boolean functions with application to integer multiplication | Symbolic model checking: 100 states and beyond | Complexity results for planning | Space efficency of propositional knowledge representation formalisms | The size of a revised knowledge base | Preprocessing of intractable problems | NuSMV 2.4 User’s Manual | NuSMV 2: An opensource tool for symbolic model checking | Multi terminal binary decision diagrams: An efficient data structure for matrix representation | Progress on the state explosion problem in model checking | Model Checking | Expressive power and succinctness of propositional languages for preference representation | A knowledge compilation | A parametric analysis of the state explosion problem in model checking | Parametrized Complexity | Binary decision diagrams in theory and practice | The complexity of problems on graphs represented as obdds | Model checking and preprocessing | Treewidth in verification: Local vs. global | Strips: a new approach to the application of theorem proving to problem solving | Succinct representations of graphs | Computers and Intractability: A Guide to the Theory of NP-Completeness | Simple on-the-fly automatic verification of linear temporal logic | Succinctness as a source of complexity in logical formalisms | The model checker spin | An automata theoretic approach to branching-time model checking | An Introduction to Kolmogorov Complexity and Its Applications | Monotonic reductions, representative equivalence, and compilation of intractable problems | On the complexity of case-based planning | The complexity of graph problems fore succinctly represented graphs | Temporal Verification of Reactive Systems - Safety | Symbolic Model Checking | A note on succinct representations of graphs | The temporal logic of programs | The complexity of temporal logic model checking | The complexity of propositional linear temporal logics | The polynomial-time hierarchy | Succinct representations of counting problems | Succinct representation and leaf languages | Languages represented by boolean formulas | Succinct representation, leaf languages, and projection reductions | VIS User’s Manual | Combining decision diagrams and SAT procedures for efficient symbolic model checking",rejected,000
1012.3148.pdf.json,,"Humans have always been fascinated by machines, so much so that Greek myths also have a mention of them. From the advent of the 20th century,1956 to be more precise, man has been intrigued by the very thought of creating something that can emulate him. Right from the coining of the term “Artificial Intelligence” by John McCarthy to the present day world, artificial intelligence is everywhere around us. Most of the work being done in industries is being done by them. They have become such an important part of our everyday lives that most of it is being controlled by them, and a failure on their part could be disastrous. However on close examination of the “jobs” that these machines carry out for us, we notice that most of these jobs don’t require much of abstract thought. These are well defined jobs with proper instruction which the machine can follow step by step to obtain the desirable results. So, why is it that these machines are replacing more and more engineers and not the artists, or the musicians from their jobs? The answer lies somewhere in the 1980’s when Hans Moravec, Rodney Brooks and Marvin Minsky devised something called the Moravec’s Paradox. This paradox deals with the often mistaken fact that it is the logical problems in the field of Artificial Intelligence that are the hardest to solve, and that simple day to day activities like facial recognition, and hand-eye coordination that are the easiest and can be easily implemented. In fact AI researchers in the 1960’s worked only on the logical aspect, assuming that the “easier” problems will solve themselves once the hard ones can be solved. Contrary to all the above opinions Moravec said that”it is comparatively easy to make computers exhibit adult level performance on intelligence tests or playing checkers, and difficult or impossible to give them the skills of a one-year-old when it comes to perception and mobility.” What he meant by the above statement is that day to day activities like speech percep",,rejected,000
1012.3280.pdf.json,TARGET TRACKING IN THE RECOMMENDER SPACE Toward a new recommender system based on Kalman filtering,"In Web-based services of dynamic content, recommender systems face the difficulty of identifying new pertinent items and providing pertinent and personalized recommendations for users. Personalized recommendation has become a mandatory feature of Web sites to improve customer satisfaction and customer retention. Recommendation involves a process of gathering information about site visitors, managing the content assets, analyzing current and past user interactive behaviour, and, based on the analysis, delivering the right content to each visitor. Recommendation methods can be distinguished into two main approaches: content based filtering (M Pazzani, D. Billsus, 2007) and collaborative filtering (D. Goldberg and al 1992). Collaborative filtering (CF) is one of the most successful and widely used technology to design recommender systems. CF analyzes users ratings to recognize similarities between users on the basis of their past ratings, and then generates new recommendations based on like-minded users’ preferences. This approach suffers from several drawbacks, such as cold start, latency, sparsity (M. Grcar, D. and al 2006), even if it gives interesting results. The main idea of this paper is to propose an alternative way for recommender systems. Our work is based on the following assumption: we consider Users and Web resources as a dynamic system described in a state space. This dynamic system can be modelled by techniques coming from control system methods. The obtained state space is defined by state variables that are related to the users. We consider that the states of the users (by states, we understand « what are the resources they want to see in the next step ») are measured by the grades given to one resource by the users. In this paper, we are going to present the effectiveness of Kalman filtering based approach for recommendation. We will detail the backgrounds of this approach i.e. state space description and Kalman filter. Then, we expose the applied met","Neuromancien. Collection J’ai | Discrete-time stochastic systems : estimation and control | Time series analysis : forecasting and control | Topology of communities for the collaborative recommendations to groups | Analysis of strategies for building group profiles. User Modeling, Adaptation and Personalization | Content-Based Recommendation Systems | Using Collaborative Filtering to Weave an Information Tapestry | Data Sparsity Issues in the Collaborative Filtering Framework | The book, The publishing company. London, 2 edition",rejected,000
1012.3312.pdf.json,,,"Knowledge creation and enhancement through collaborative information retrieval | Collaborative information retrieval among Economic Intelligence actors,“ In Proceedings of the 4 International conference on collaboration technologies, CollabTech 2008, Japan | Economic Intelligence. A guide for beginners and practionners, | Modelisation Du Problème Informationnel Du Veilleur | Considering users‟ behaviors in improving the responses of an information base,“ 1 International Conference on Multidisciplinary Information Sciences and Technologies, Merida | L‟Intelligence Économique et Les Système d‟Information : Problématiques et approches de solutions | Knowledge Management and Organizational Memories | Transition from Data to Information | Representation of knowledge resource in the context of Economic Intelligence systems | The knowledge-Creating Company: How Japanese Companies Create the Dynamics of Innovation | The Internet, Intranets and the AI Renaissance | ISMICK and Knowledge Management | Views of Knowledge are human views | Methods and Tools for Corporate Knowledge Management | Determinants of successful Knowledge Management Programs | Effects of age at entry, Knowledge Intensity and imitability on International growth | Working Knowledge: How Organizations manage what they know | The Capitalization of “purely Swiss” Vitamin C: Industry, University, and Government (ality)”, In 5th Triple Helix Conference, The Capitalization of Knowledge: cognitive, economic, social & cultural aspects | Une étude de cas, la mise en place d'un projet capitalisation de connaissances et de compétences | Knowledge Acquisition and modeling for corporate memory: lessons learnt from experience | A generic model of corporate memory: application to the industrial systems | A mix method of Knowledge Capitalization in maintenance | Application of Knowledge Management to System Development | Knowledge formalization in experience feedback processes: An ontology-based approach | Designing a Knowledge Management Approach for the CAMRA Community of Science | Application of “EQuA2te",rejected,000
1012.3336.pdf.json,Dynamic Knowledge Capitalization through Annotation among Economic Intelligence Actors in a Collaborative Environment,,"Considering users’ behaviours in improving the responses of an information | Developing a robust authoring annotation system for the Semantic Web | Efficient technique for adaptive hypermedia, intelligent hypertext: Advances techniques for the World Wide Web | Application of “EQuA2te” Architecture in Economic Intelligence. In Information and Communication Technologies applied to Economic Intelligence | Contribution to the understanding of explanatory factors for decision-maker problem within the framework of economic intelligence, SCI | Awareness and coordination in shared workspaces | Modelisation du Problème Informationnel du Veilleur | Economic intelligence. A guide for beginners and practitioners | Collaborative Information Retrieval among Economic Intelligence Actors, in the fourth International Conference on Collaboration Technologies (CollabTech | Collaborative knowledge creation and management in information retrieval, in the 5th international KMO conference KMO | AMTEA: Tool for Creating and Exploiting Annotations in the Context of Economic Intelligence (Competitive Intelligence) | Dynamic capitalization and visualization strategy in collaborative knowledge management system for EI process | Intelligence stratégique sur Internet, Paris, Dunod | L'annotation pour la recherche d'informations dans le contexte d'intelligence économique",rejected,000
1012.3410.pdf.json,Descriptive-complexity based distance for fuzzy sets,"The notion of distance between two objects is very general. Distance metrics and distances have now become an essential tool in many areas of mathematics and its applications including geometry, probability, statistics, coding/graph theory, data analysis, pattern recognition. For a comprehensive source on this subject see [4]. The notion of a fuzzy set was introduced by [8]. It is a class of objects with continuous values of membership and hence extends the classical definition of a set (to distinguish it from a fuzzy set we refer to it as a crisp set). Formally, a fuzzy set is a pair (E,m) where E is a set of objects and m is a membership function m : E → [0, 1]. Fuzzy set theory can be used in a wide range of domains in which information is incomplete or imprecise, such as pattern recognition, decision theory. The concept of distance and similarity is important in the area of fuzzy logic and sets. We now review some common ways of defining distances on fuzzy sets (see [9] and references therein). Classical distances measure how far two points are in Euclidean space. For instance, the Minkowski distance between two points x and y in Rn is defined as dr(x, y) := ( n∑ i=1 |xi − yi|r )1/r , r ≥ 1. (1) ∗Department of Information Technology, University of Miskolc, HUNGARY. H-3515. Miskolc-Egyetemvaros. Email : kovacs@iit.uni-miskolc.hu †Department of Electrical and Electronics Engineering, Ariel University Center of Samaria, Ariel 40700, ISRAEL. Email : ratsaby@ariel.ac.il. (Corresponding author). 1 ar X iv :1 01 2. 34 10 v1 [ cs .A I] 1 5 D ec 2 01 0 Let E be a finite set and let Φ(E) be the set of all fuzzy subsets of E. Consider A,B two fuzzy subsets A, B ∈ Φ(E) with membership functions mA,mB : E → [0, 1]. Then (1) can be extended to the following distance, dr(A,B) := (∑ x∈E |mA (x)−mB(x)|r )1/r , r ≥ 1. Based on (1) letting r = 2 we have the Hausdorff distance between two nonempty compact crisp sets U , V ⊂ R, q (U, V ) := max { sup v∈V inf u∈U d2 (u, v) , sup u∈U ",Modern Information Retrieval | A pattern recognition approach to the problem of linguistic approximation in system analysis | Elements of information theory | Encyclopedia of Distances | Information efficiency | Information width | Information set distance | Fuzzy sets | Measures of similarity among fuzzy concepts: A comparative analysis,rejected,000
1012.4776.pdf.json,Automatic Estimation of the Exposure to Lateral Collision in Signalized Intersections using Video Sensors,"Collisions at intersections make up a high proportion of total collisions all over the world, 39.7 % of all collisions and 21.8 % of fatal collisions in the US for instance (NHTSA, 2008). Traffic signals are installed at intersections according to warrants on traffic volumes and safety. Over the years, there has been considerable interest in improving signalized intersections to minimize delays and stops. It has become possible to develop traffic control strategies that can adapt to current traffic conditions in real-time thanks to the advancement of sensors. However not much is known about the impact on safety of traffic control strategies, particularly adaptive ones. The CRONOS strategy is a real-time adaptive traffic control strategy developed in the 1990s (Boillot et al., 2006). It relies on video sensors that provide queue lengths and spatial occupancy rates every second (Aubert et al., 1996). Its algorithm controls the traffic lights in order to minimize total delay over a short-range time horizon. The CRONOS strategy was compared to a standard time-plan based control strategy with vehicle-actuated ranges. During the real world experiment, the two strategies alternately controlled a real intersection in the suburbs of Paris over several months. The traffic databases recorded during the CRONOS strategy assessment enable us to obtain quantitative results in a real world setting and to compare the exposure between strategies and between traffic volume conditions. ∗École Polytechnique de Montréal, C.P. 6079, succ. Centre-Ville, Montréal Québec, Canada, H3C 3A7. Tel.: +1 (514) 340-4711 (ext. 4962). Fax: +1 (514) 340-3981. Email: nicolas.saunier@polymtl.ca. Website: http://nicolas.saunier.confins.net †Université Paris-Est, INRETS, GRETIA, 2 rue de la Butte Verte, 93166 Noisy-le-Grand cedex, France. Email: sophie.midenet@inrets.fr ar X iv :1 01 2. 47 76 v1 [ cs .A I] 2 1 D ec 2 01 0 An original model was developed to evaluate the exposure to lateral collision in",Methods for the Assessment and Prediction of Traffic Safety at Urban Intersections and their Application in Micro-simulation Modelling | Automatic vehicle queue measurement at intersections using image-processing | Pierrelée. The real-time urban traffic control system cronos: Algorithm and experiments | The concept of exposure | Cartes auto-organisatrices pour l’interprétation de mesures spatiales et la description du trafic au centre de carrefours | Exposure to lateral collision in signalized intersections with different traffic control strategies | Incidence de la rgulation d’un carrefour feux sur le risque des usagers. Apprentissage d’indicateurs par slection de donnes dans un flux | Creating ensemble classifiers through data selection and order; application to the online learning of road safety indicators | Automatic detection of vehicle interactions in a signalized intersection | Stream-based Learning through Data Selection in a Road Safety Application,rejected,000
1012.5705.pdf.json,Looking for plausibility,"Traditionally, uncertainty in propositions is handled through the concept of probability with its statistical interpretation. It is however, a bit strange when such an approach which is based on counting events, is applied to hypotheses, like explanatory propositions. For example, in the interpretation of experimental data, one is actually looking for plausible explanations to describe the observed data. Whilst probability may be seen to underlie data measurement, a statistical picture for explanations may be viable only in a multiple-world universe. We thus seek a measure for plausibility, with which we can compare different possible explanations. Furthermore, this measure of plausibility should allow appropriate combination when different explanations and/or sets of data are combined.",Fuzzy Sets as the Basis for a Theory of Possibility | Fuzzy sets | A Mathematical Theory of Evidence | Abduction | Probabilistic Inferences in Bayesian Networks | Biconditionality | Neural Network Logic | Logic Programming on a Neural Network | Neural networks and physical systems with emergent collective computational abilities | Neural” Computation of Decisions in Optimization Problems | The Logic of Neural Networks,rejected,000
1012.5754.pdf.json,Software Effort Estimation with Ridge Regression and Evolutionary Attribute Selection,"Software companies and other stakeholders, such as, customers, end-users, managers and researchers, have worked over the past decades on improving the accuracy and consistency of effort estimations for developing software systems. To achieve this, several techniques have been developed aiming on one hand to develop high quality software with the lowest possible costs and on the other hand to strive towards successful project completion [1]. Moreover, developing techniques to efficiently estimate the overall development costs, especially from the planning phases of a project, can offer a significant competitive advantage for software companies and project managers. This advantage can be used for reducing the risk of resource misallocation and enhancing the manager’s ability to deal with budgeting, planning and controlling of the project processes and assets. Software cost models proposed in literature are based on expert judgement or employ some mathematical or machine learning technique to reach to improved effort approximations. Models usually employ historical project data obtained from previous software developments and very rarely the suitability of this data is questioned. Moreover, for a software cost model to be regarded as practical the following requisites need to co-exist; firstly, the delivery of accurate, transparent and meaningful effort approximations and secondly, the utilisation of suitable, measurable and available information at the project initiation stages, where effort estimation is needed the most. Nevertheless, the majority of cost models found in the literature require project information that is available only after requirements specification and relate for instance to the size of the software, application type, function points and language type used. Experienced cost estimators or project managers need to manually perform evaluation, filtering and identification of the appropriate project parameters that should be used in each model as a pr","Applications of Fuzzy Logic to Software Metric Models for Development Effort Estimation | Reliable Confidence Intervals for Software Effort Estimation | A Constrained Regression Technique for COCOMO Calibration | Finding Causes of Software Failure Using Ridge Regression and Association Rule Generation Methods | Adaptive Ridge Regression System for Software Cost Estimating on Multi-Collinear Datasets | Software Metrics – A Rigorous and Practical Approach, PWS Publishing | A Systematic Review of Software Development Cost Estimation Studies | Finding the Right Data for Software Cost Modeling | Improving Analogy Software Effort Estimation using Fuzzy Feature Subset Selection Algorithm | Optimization of Analogy Weights by Genetic Algorithm for Software Effort Estimation | Quasi-optimal Case-selective Neural Network Model for Software Effort Estimation | Neural Network Approach for Software Cost Estimation | Can Neural Networks be Easily Interpreted in Software Cost Estimation | Identification of Fuzzy Models of Software Cost Estimation | Can Genetic Programming Improve Software Effort Estimation? A Comparative Evaluation | On the Problem of the Software Cost Function | Combining Techniques to Optimize Effort Predictions in Software Project Management | Reliable Predictive Intervals for the Critical Frequency of the F2 Ionospheric Layer | Application of Ridge Regression to Quantify Marginal Effects of Collinear Soil Properties on Phytotoxicity of Arsenic, Cadmium, Lead, and Zinc | Local Ridge Regression for Face Recognition | Transduction with Confidence and Credibility",rejected,000
1012.5755.pdf.json,DD-EbA: An algorithm for determining the number of neighbors in cost estimation by analogy using distance distributions,"The last few years we observe a continuous technological orgasm, which has to do with the importance software has taken in our every day life. As human activity becomes more and more complicated, the need of even more exigent systems seems vital. A demanding system however has demanding requirements regarding the development procedure. A project manager is the one who has to confront the issue in many perspectives, either has it to do with risk management matters, defect prediction etc or effort and time requirements. Effort requirements in means of effort estimation is a task known as Software Cost estimation, which is essential in the early stages of the development and may be performed in any stage of the life cycle of the under estimation project. To cope with this important task, a plethora of methods has been proposed (Jorgensen and Shepperd, 2007). These estimation methods fall in three main categories. • Expert judgment, in which the calculation of effort is based on human judgment. Although the technique is easy to apply and gives direct evaluation, because of the fact that it relies on instinctive processes is difficult to be in full analyzed (Berger, 1985; Silverman, 1985; Hammond, 1996 and Hogarth, 2005). • Estimation by analogy (EbA), a form of Case Based Reasoning (Mukhopadhyay et al., 1992). Main aspect of the technique is to use historical projects, the effort of which is known, to estimate a new one. • Algorithmic cost estimation, i.e. COCOMO (Boehm, 1981) and Function Points (Albrecht and Gaffney, 1983). These methods require the application of a cost model, via one or more mathematical equations calculated through statistical data analysis. These approaches, if used correctly and calibrated with historical data, seem to be very useful. As discussed in Shepperd and Schofield (1997) there are certain advantages that appoint EbA the more attractive in respect with the other systems. In fact, users are more willing to accept solutions from analogy bas","Statistical Decision Theory and Bayesian Analysis | Finding Groups in Data: An Introduction to Cluster | LSEbA: least squares regression and estimation by analogy | semi-parametric model for software cost estimation | reasoning model for software effort estimation."" MIS Quarterly | Effort estimation using analogy",rejected,000
1012.5815.pdf.json,,,,rejected,000
1012.5960.pdf.json,Extending Binary Qualitative Direction Calculi with a Granular Distance Concept: Hidden Feature Attachment,"A qualitative representation provides mechanisms which characterize central essential properties of objects or configurations. A quantitative representation establishes a measure in relation to a unit of measurement which has to be generally available. Qualitative spatial calculi usually deal with elementary objects (e.g., positions, directions, regions) and qualitative relations between them (e.g., ”adjacent”, ”on the left of”, ”included in”). The constant general availability of common measures is now self evident. However, one needs only remember the example of the history of technologies of measurement of length to see that the more local relative measures, which are qualitatively represented, (for example, ”one piece of material is longer than another” versus ”this thing is two meters long”) can be managed by biological/epigenetic cognitive systems much more easily as absolute quantitative representations. Typically, in Qualitative Spatial Reasoning relatively coarse distinctions between configurations are made only. The two main trends in Qualitative Spatial Reasoning are topological reasoning about regions [11, 13, 2] and positional reasoning about point configurations [4, 3, 6, 7, 12]. Applications exist in which finer qualitative acceptance areas are helpful. The possibility to use finer qualitative distinctions can be viewed as a stepwise transition to quantitative knowledge. The idea of using context dependant direction and distance intervals for the representation of spatial knowledge can be traced back to Clementini, di Felice, and Hernandez [1]. However, only special cases of reasoning were considered in their work. Here, we will propose calculi that make direct use of general purpose constraint propagation. In this paper we introduce a method for extending binary qualitative direction calculi with adjustable granularity like OPRAm[7] or the star calculus [12] with a granular distance concept. This method is similar to the concept of extending points w",Qualitative Represenation of Positional Information | Point-Set Topological Spatial Relations | Qualitative Spatial Reasoning with Cardinal Directions | Using orientation information for qualitative spatial reasoning | The Ecological Approach to Visual Perception | Reasoning about cardinal directions | Representing relative direction as a binary relation of oriented points | Oriented straight line segment algebra: Qualitative spatial reasoning about oriented objects | Qualitative spatial reasoning about line segments | Qualitative reasoning about relative direction on adjustable levels of granularity | A spatial logic based on regions and connection | Qualitative direction calculi with arbitrary granularity | On the complexity of qualitative spatial reasoning: A maximal tractable fragment of the region connection calculus | The finest of its class: The natural point-based ternary calculus for qualitative spatial reasoning,rejected,000
1012.6018.pdf.json,,"One of the major goals of video games is to make the user feel like he/she really is in the game environment. To achieve this, it is possible to use complex devices to increase immersion like surround sound systems and stereoscopic screens. Another way is to make rich environments to increase presence. The latter can be done by, among other things, having characters with believable behaviours (Bates 1994). To generate those behaviours, models from artificial intelligence are used in the game industry. For those models to perceive the environment, game designers have to create a simplified representation of the environment, which is often defined a priori. Defining by hand every new environment’s representation is a time-consuming work. We propose that our characters will be able to learn those representations, for them to be autonomous. This learning will be unsupervised and online: the character will learn while it plays without the judgement of a human. To be able to achieve the best believability, we want the computercontrolled characters to do like human-controlled char- acters. Indeed, there are no better example of what a believable behaviour is than a human behaviour itself. It is this kind of learning, by example (Del Bimbo A., Vicario E. 1995) or by imitation (Gorman and Humphrys 2007; Bauckhage et al. 2007) we want to use to learn a representation of the environment. This article first presents the growing neural gas model which is used to learn the representation of the environment. Then the characteristics and qualities of the learned representations are assessed by different measures. To conclude, some enhancements are proposed for the growing neural gas to give more information to the character’s model.","The Role of Emotion in Believable Agents | Learning Human Behavior from Analyzing Activities in Virtual Environments MMI-Interaktiv | Specification by-Example of Virtual Agents Behavior | A growing neural gas network learns topologies in ‘Advances in Neural Information Processing Systems 7 | Imitative learning of combat behaviours in first-person computer games in ‘Proceedings of CGAMES 2007, the 11th International Conference on Computer Games: AI, Animation, Mobile, Educational & Serious Games | Learning human-like movement behavior for computer games in ‘Proceedings of the 8th International Conference on the Simulation of Adaptive Behavior (SAB’04)",rejected,000
1101.2301.pdf.json,A Factorial Experiment on Scalability of Search Based Software Testing,"Software testing is one of the most critical and at the same time most time and cost consuming activity in software development process [1]. In order to cut this costs as much as possible we need to employ effective techniques to automate this process. What actually needs to be automated is generating the test data which is a demanding process [2]. Automation of generating test data helps to have fast, cheap and error free process [2]. If we can optimize the test cases generation process, then we save a lot of time and money. Among optimization techniques, search based optimization is the one which has been applied to different areas of Software Engineering applications [2]. Software testing was not an exception in Software Engineering area and the term “Search Based Software Testing (SBST)“ proves it. The recent years show a dramatic rise of interest in Search Based Testing (SBT) [2]. SBT has been applied to different testing areas such as structural, functional, non-functional, mutation, regression and so on [2]. The term ”Search Based Testing” in general means using some sort of search alogorithms to generate test cases for testing a software. ar X iv :1 10 1. 23 01 v1 [ cs .S E ] 1 2 Ja n 20 11 2 There are many Search Based techniques and each of them uses a different algorithm to optimize the search and the results. The three popular ones which are in use for testing purpose are Neighborhood Search, Simulated annealing and Genetic algorithms (GA). And of course there are simple techniques as well such as random testing which does not use any optimization and search technique. [3]. According to [3] flexibility and strength of these heuristic optimization techniques help a lot in finding the optimal solutions in large and complex search spaces. This study focuses on using the SBT techniques or as we said heuristic optimization techniques for software testing, when we have different programs regarding to complexity. We will apply the technique which is called Gene",A Novel Approach To Automated Testing To Increase Software Reliability | Automated Test Data Generation using Search Based Software Engineering | A Search-Based Automated Test-Data Generation Framework for Safety-Critical Software | Genetic algorithms for dynamic test data generation | Applying particle swarm soptimization to software testing | Genetic algorithm based software testing | Observations in using parallel and sequential evolutionary algorithms for automatic software testing | Search-based test case generation for object-oriented java software using strongly-typed genetic programming | The Automatic Generation of Software Test Data Using Genetic Algorithms | Effective Black-Box Testing with Genetic Algorithms | Selection in factorial experiments | GEVA: grammatical evolution in Java | A BNF-based automatic test program generator for compatible microprocessor verification ACM Trans | Automatic test generation for functional verification of microprocessors | Experimental assessment of random testing for object-oriented software | Generating Software Test Data by Evolution | Genetic Programming with simple loops | Designing and Prototyping a Functor Language Using Denotational Semantics | Towards a simpler method of operational semantics for language definition | Genetic Algorithm Fitness Function for Mutation Testing,rejected,000
1101.2378.pdf.json,Extracting Features from Ratings: The Role of Factor Models,"Recommender systems [1, 17] are one of the most prominent applications of preference handling technology [6] and a highly active area of research. In particular, fueled by the Netflix competition and its one million dollar prize money [2], research on collaborative recommendation techniques [21] has recently made significant advances, most notably through the introduction of factor models [16, 22]. In collaborative recommender systems, users repeatedly express their preferences for items, which usually is done by giving explicit ratings on some predefined numerical scale. This data can be modeled using a rating matrix, whose rows correspond to items, columns to users, and entries to ratings. Typically, ratings matrices are very sparse, that is, only a small fraction of all possible ratings have actually been observed. Personalized recommendations are generated by predicting unobserved ratings from the available data and, for each user, selecting those items considered to be most appealing. Most state-of-the-art collaborative recommendation methods— including the winner of the Netflix Prize—are based on factor models, which are known to yield much more accurate predictions than traditional neighborhood-based methods [14, 15, 22, 23, 24]. In factor models, each user and each item is represented by a vector in some shared real coordinate space. The vectors are chosen such that each observed rating is closely approximated by the dot product of the corresponding item and user vectors. The selection of coordinates usually is formalized as an optimization problem. Predictions for unobserved ratings are generated by computing the respective scalar products. Equivalently, this approach can be seen as a factorization of the rating matrix into the product of an item matrix (whose rows 1 Institut für Informationssysteme, Technische Universität Braunschweig, Germany are the item vectors) and a user matrix (whose columns are the user vectors). The success of factor models is usua","Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions | The million dollar programming prize | Scalable collaborative filtering with jointly derived neighborhood interpolation weights | Preference elicitation with subjective features | Preference handling: An introductory tutorial | Accurate computation of the product-induced singular value decomposition with applications | Towards a comprehensive survey of the semantic gap in visual image retrieval | Large margin rank boundaries for ordinal regression | Evaluating collaborative filtering recommender systems | A survey of top-k query processing techniques in relational database systems | Factorization meets the neighborhood: A multifaceted collaborative filtering model | Collaborative filtering with temporal dynamics | Factor in the neighbors: Scalable and accurate collaborative filtering | Matrix factorization techniques for recommender systems | Just for you | Interview with Simon Funk | Principal component analysis for large scale problems with lots of missing values | Collaborative filtering recommender systems’, in The Adaptive Web: Meth-  ods and Strategies of Web Personalization, volume | A unified view of matrix factorization models | Scalable collaborative filtering approaches for large recommender systems | Improving maximum margin matrix factorization",rejected,000
1101.3465.pdf.json,,,"The cemetery"", South African",rejected,000
1101.4101.pdf.json,Context Capture in Software Development,"The term context has an intuitive meaning for humans, but due to this intuitive connotation it remains vague and generalist. Furthermore, the interest in the many roles of context comes from different fields such as literature, philosophy, linguistics and computer science, with each field proposing its own view of context [1]. The term context typically refers to the set of circumstances and facts that surround the center of interest, providing additional information and increasing understanding. The context-aware computing concept was first introduced by Schilit and Theimer [2], where they refer to context as “location of use, the collection of nearby people and objects, as well as the changes to those objects over time”. In a similar way, Brown et al. [3] define context as location, identities of the people around the user, the time of day, season, temperature, etc. In a more generic definition, Dey and Abowd [4] define context as “any information that can be used to characterize the situation of an entity. An entity is a person, ? Supported by FCT grant SFRH/BD/43336/2008. ar X iv :1 10 1. 41 01 v1 [ cs .S E ] 2 1 Ja n 20 11 place, or object that is considered relevant to the interaction between a user and an application, including the user and applications themselves”. In software development, the context of a developer can be viewed as a rich and complex network of elements across different dimensions that are not limited to the work developed on an IDE (Integrated Development Environment). Due to the difficulty on approaching such challenge, there is not a unique notion of what it really covers and how it can be truly exploited. With the increasing dimension of software systems, software development projects have grown in complexity and size, as well as in the number of functionalities and technologies involved. During their work, software developers need to cope with a large amount of contextual information that is typically not captured and processed in orde",Context-aware computing: A guide for the pervasive computing community | Disseminating active map information to mobile hosts | Context-aware applications: From the laboratory to the marketplace | Towards a better understanding of context and contextawareness | Ontology: Its transformation from philosophy to information systems | The semantic web | A context model for personal knowledge management applications | Rdf vocabulary description language 1.0: Rdf schema (2004) Published: W3C Recommendation | Using task context to improve programmer productivity | Building usage contexts during program comprehension | Supporting collaborative software development by context-aware information retrieval facilities | Rdf primer (2004) Published: W3C Recommendation,rejected,000
1101.5460.pdf.json,,"As envisioned by Mark Weiser in [1], ubiquitous information access for people requires the computing technology to become as simple as older technologies like printing. After almost two decades of research and tremendous amount of work on technology enhancements in mobile computing, still a large gap exists between today’s computing technologies and the user’s environment, requirements and expectations in utilizing such technologies. The number of available mobile devices was almost equal to half of the world population by the end of 2008. Such rapid prevalence of mobile devices is shaping our new lifestyles, and more human-centric approaches will be required to support our daily activities and future mobile working environments [2]. Context-awareness plays a key role in adapting the information systems to real needs of the user. The idea has a rather long history. The artificial intelligence society was * Corresponding author criticized in 1980’s for ignoring the differences in situations where software was used [3]. In the last decade, a large body of research on context-awareness has been performed. Two recent literature reviews and classifications are done by Hong, et al in [4] and by Balduf, et al in [5]. To the best knowledge of us, most approaches have one of the following shortcomings. First, current approaches lack a sound theoretical and architectural basis to fulfil the need for establishing an extensible and platform-independent framework. Second, most approaches are weak in terms of accommodating human-centric, uncertainty-aware design requirements for adapting to real-world applications. Even ontological approaches which are suggested for context-awareness as well as other application areas have a major problem namely symbol grounding (ref to Gardenfors). More details about some important challenges of context- awareness is given in Section 0. To solve the first problem, we suggest using the theory of Language Action Perspective (LAP) to define the pos","The computer for the 21st century | The Future of Work: What Does Online Community Have to Do with It | Two Decades of the Language-Action Perspective | Context-aware systems: A literature review and classification | A survey on context-aware systems | Architectures for Context | A language/action perspective on the design of cooperative work | Towards A Theoretical Foundation for Web Services - The Language-Action Perspective (LAP) Approach | A theoretical investigation of the emerging standards for web services | Towards a LAP-based Information Paradigm | Fuzzy logic = computing with words | From Search Engines to Question Answering Systems - The Problems of World Knowledge, Relevance, Deduction and Precisiation | Characteristics of geographic information needs | TR-86-03- How human needs are expressed in queries - a study of real search data | Service discovery in pervasive computing environments | Context-Aware Middleware for Anytime, Anywhere Social Networks | What we talk about when we talk about context | Collaborative context recognition for handheld devices | Supporting Group-Oriented Mobile Services Transactions | Approaches to Uncertainty in Spatial Data | From PIM to GIM: personal information management in group contexts | Advances in type-2 fuzzy sets and systems | Qualitative representation of positional information | A Context-Aware Service Discovery Framework Based on Human Needs Model | Relationship management vs business transactions: Business interaction as design of business interaction | Sharing hierarchical context for mobile web services | Type-2 Fuzzy Sets, A Tribal Parody [Discussion Forum | Fuzzy Aided Application Layer Semantic Intrusion Detection System - FASIDS (IJNSA) | Computing with Words: Zadeh, Turing, Popper and Occam | Supporting uncertainty in moving objects in network databases | Communicating Spatial Uncertainty using Geographical Reasoning | Reasoning about uncertain contexts in pervasive computing environments | Modeling uncertainty in context-aware computing | Reasoning about vague topological information | Fuzzy Logic - A New Direction, The Concept of f-Validity | A Culturally Context-Aware Architecture for Mobile Profile Matching | Alderfer, Existence, relatedness, and growth | Perceptual Reasoning: A New Computing with Words Engine | Inferring intentions in generic context-aware systems | Exploiting real world knowledge in ubiquitous applications | Designing a new foundation for design | Type-2 Fuzzy Sets and Systems: An Overview [corrected reprint | Computing with words and its relationships with fuzzistics | Encoding Words into Interval Type-2 Fuzzy Sets Using an Interval Approach | Location Approximation for Local Search Services using Natural Language Hints | Fuzzifying Allen's Temporal Interval Relations | A Security Framework for SOA Applications in Mobile Environment | Data Security in Mobile Devices by GEO Locking  | Dynamic Multi-Layer Signature Based Intrusion Detection System Using Mobile Agents | An analysis of services for the mobile tourist | Understanding and Using Context | The Java Context Awareness Framework (JCAF) – A Service Infrastructure and Programming Framework for Context-Aware Applications | A framework for context information management | A mobile computing middleware for location- and context-aware internet data services | Toward an OSGi-based infrastructure for context-aware applications",rejected,000
1101.5632.pdf.json,Active Markov Information-Theoretic Path Planning for Robotic Environmental Sensing,"Research in multi-robot exploration and mapping has recently progressed from building occupancy grids [14] to sampling spatially varying environmental phenomena [6, 7], in particular, environmental fields (e.g., plankton density, pollutant concentration, temperature fields) that are characterized by continuous-valued, spatially correlated measurements (see Fig. 1). Exploration strategies for building occupancy grid maps usually operate under the assumptions of (a) discrete, (b) independent cell occupancies, which impose, respectively, the following limitations for learning environmental field maps: these strategies (a) cannot be fully informed by the continuous field measurements and (b) cannot exploit the spatial correlation structure of an environmental field for selecting observation paths. As a result, occupancy grid mapping strategies are not capable of selecting the most informative observation paths for learning an environmental field map. Furthermore, occupancy grid mapping strategies typically assume that range sensing is available. In contrast, many in situ environmental and ecological sensing applications (e.g., monitoring of ocean phenomena, forest ecosystems, or pollution) permit only point-based sensing, thus making a highresolution sampling of the entire field impractical in terms of resource costs (e.g., energy consumption, mission time). In practice, the resource cost constraints restrict the spatial coverage of the observation paths. Fortunately, the spatial correlation structure of an environmental field enables a map of the field (in particular, its unobserved areas) to be learned using the point-based observations taken along the resourceconstrained paths. To learn this map, a commonly-used approach in spatial statistics [15] is to assume that the environmental field is realized from a probabilistic model called the Gaussian process (GP) (Section 3.2). More importantly, the GP model allows an environmental field to be formally characterized and ",,rejected,000
1102.0714.pdf.json,Una arquitectura para la evaluación de sistemas inteligentes,,,rejected,000
1102.1803.pdf.json,Proposing LT based Search in PDM Systems for Better Information Retrieval,"In early 1970s there was no such system to automate the process of data management, then in 1980s Computer Integrated Manufacturing was introduced but seemed not to be successful in product data management. With emergence of CAD technologies PDM Systems are introduced and used to manage engineering data, activities and processes through better control of engineering data, activities, changes and product configurations. PDM products mainly manage information about design and manufacturing of products including technical operations and running projects. PDM is also renowned as Engineering Data Management and Engineering Document Management Systems because it provides better management and control over engineering data, activities, and changes related to design and manufacture of product. Product Lifecycle Management (PLM) is another acronym for PDM to manage the entire development life cycle of the product by integrating people, data, processes and business systems. PDM provides a backbone for the controlled flow of engineering information throughout the product life cycle by using engineering data, such as CAD, ERP and field service. Moreover PDM also supports product teams and techniques by providing Concurrent Engineering in improving engineering workflow. PDM systems address issues such as control, quality, reuse, security and availability of engineering data. PDM performs five main functions to integrate and manage all applications, information, and processes during the associated product life cycle i.e., Data vault and document management, Workflow and process management, Product structure management, Parts management and Program management [8]. The major objectives of PDM are to reduce the cost of engineering, reduce effort in product development life cycle, reduce time in change handling and new product development, improve the quality and services of the product, deliver and support products at the given time, improve team coordination, increase customization",,rejected,000
1102.2174.pdf.json,,"Linear Temporal Logic (LTL) is a very well-known logic introduced in [Pnu77] for verifying computer programs. It is widely used to reason on finite state transition systems. On the other hand, propositional schemata have been introduced in [ACP09]. They extend the language of propositional logic with indexed propositions (such as pn, p1 or pi+1) and iterated connectives of the form ∨n i=0 φ or∧n i=0 φ. Notice that n denotes a parameter, which must be interpreted as a natural number. If arbitrary expressions for indices and iterations are allowed in the schema, then the satisfiability problem is undecidable, but we have identified in [ACP09,ACP10a,ACP11] some subclasses for which this problem is decidable. The simplest of these classes is called regular : it is defined by restricting both the indices of the propositions, that must be of the form k or n+ k where k ∈ Z and n is a variable, and iterations, that must be non-nested and of the form ∧n+l i=k φ where n is a variable and k, l ∈ Z. Decision procedures are designed in [ACP09,ACP10a] and an implementation is available [ACP10c]. LTL and propositional schemata share many common features and trying to compare them precisely is a rather natural and, hopefully, fruitful idea. In both logics, interpretations can be viewed as arrays of propositional functions and the formulae relate the values of these functions at different states. The indices of the propositions in the schematic case may be viewed as the time in LTL. Thus comparing the expressing powers and complexities of those two logics, and, if possible, defining translations from one logic to the other is a natural and potentially rewarding issue. Notice that there already exist several results relating ⋆ This work has been partly funded by the project ASAP of the French Agence Nationale de la Recherche (ANR-09-BLAN-04-07-01) LTL to other formalisms like monadic second order logic via Büchi automata [WVS83], monadic first order logic over natural numbers [GPSS80","A Schemata Calculus for Propositional Logic, TABLEAUX | A Resolution Calculus for Propositional Schemata | Bounded model checking | LTL Goal Specifications Revisited, ECAI (Amsterdam) | The complexity of propositional linear temporal logics | Star-free regular sets of ω-sequences | Temporal Logics for Specification and Verification, Proceedings of the European Summer School in Logic, Language and Information (ESSLI’09) | The tableau method for temporal logic: an overview | Reasoning about infinite computation paths",rejected,000
1102.2670.pdf.json,Online Least Squares Estimation with Self-Normalized Processes: An Application to Bandit Problems∗,"The least squares method forms a cornerstone of statistics and machine learning. It is used as the main component of many stochastic sequential decision problems, such as multi-armed bandit, linear bandits, and other linear control problems. However, the analysis of least squares in these online settings is non-trivial because of the correlations between data points. Fortunately, there is a connection between online least squares estimation and the area of self-normalized processes. Study of self-normalized processes has a long history that goes back to Student and is treated in detail in recent book by de la Peña et al. (2009). Using these tools we provide a proof of a bound on the deviation for vector-valued martingales. A less general version of the bound can be found already in de la Peña et al. (2004, 2009). Additionally our proof, based on the method of mixtures, is new, simpler and self-contained. The bound improves the previous bound of Rusmevichientong and Tsitsiklis (2010) and it is applicable to virtually any online least squares problem. The bound that we derive, gives immediately rise to tight confidence sets for the online least squares estimate that can replace the confidence sets in existing algorithms. In particular, the confidence sets can be used in the UCB algorithm for the multi-armed bandit problem, the ConfidenceBall algorithm of Dani et al. (2008) for the linear bandit problem, and LinRel algorithm of Auer (2003) for the associative reinforcement learning problem. We show that this leads to improved performance of these algorithms. Our hope is that the new confidence sets can be used to improve the performance of other similar linear decision problems. The multi-armed bandit problem, introduced by Robbins (1952), is a game between the learner and the environment. At each time step, the learner chooses one of K actions and receives a reward which is generated independently at random from a fixed distribution associated with the chosen arm. T",Active learning in heteroscedastic noise | Online optimization in X-armed bandits | Stochastic linear optimization under bandit feedback | Self-normalized processes: Limit theory and Statistical Applications | Asymptotically efficient adaptive allocation rules | Strong consistency of least squares estimates in multiple regression,rejected,000
1102.2748.pdf.json,Feature Selection via Sparse Approximation for Face Recognition,"W ITHIN the last several decades, facerecognition has received extensive attention due to its wide range of application from identity authentication, access control and surveillance to human-computer interaction and numerous novel face recognition algorithms have been proposed [43], [28]. One of the key issue to successful face recognition systems is the development of effective face representation, namely how to extract and select the discriminative features to represent face image. According to the region from which features are derived, face representation methods can be generally divided into two categories: holistic representation and local representation. The holistic representation extract features from the whole face image while the local representation calculating the features from the local faical regions. After the introduction of the well-known Eigenfaces [33], the holistic representation meth- • The authors are with the Institute of Information Science and Engineering, Central South University, Changsha, Hunan, 410083, China. E-mail: {yxliang, wanglei, yxiang, bjzou}@mail.csu.edu.cn ods were extensively studied [4], [24], [3], [13], [37], [34]. However, local areas are often more descriptive and more appropriate for dealing with those facial variations due to expression, partial occlusion and illumination, since most variations in appearance only affect a small part of the face region. Local feature analysis (LFA) [25] pioneers the study of local representation for face recognition. Recently, local representation approaches have received more attention and have shown more promising results [36], [14], [16], [5], [1], [39], [2], [23], [17], [38], [6]. A lots of local feature descriptors, such as Haar-like features [16], SIFT features [5], histograms of oriented gradient (HOG) [2], edge orientation histograms (EOH) [39], Gabor features [36], [18], local binary patterns (LBP) [1], [18], [22], Bio-inspired features [23], learned descriptor [6] etc., have be","Face recognition using HOG-EBGM, | Face recognition by independent component analysis, | Eigenfaces vs. Fisherfaces: Recognition using class specific linear projection, | On the use of SIFT features for face authentication, | Face Recognition with Learning-based Descriptor,”,Proc | LIBSVM: a library for support vector machines | A regularized framework for feature selection in face detection and authentication | Optimal Gabor filters for texture segmentation, | The CAS-PEAL large-scale chinese face database and baseline evaluations, | An introduction to variable and feature selection, | Face recognition using laplacianfaces, | Face recognition: Component-based versus global approaches, | Labeled faces in the wild: A database for studying face recognition in unconstrained environments, | Face recognition using boosted local features, | Volterrafaces: Discriminant analysis using volterra kernels, | Gabor volume based local binary pattern for face representation and recognition, | Illumination invariant face recognition using near-infrared images, | Matching pursuits with timefrequency dictionaries, | On the recent use of local binary patterns for face authentication, | Using biologically inspired features for face processing, | Beyond Eigenfaces: Probabilistic matching for face recognition, | Local feature analysis: A general statistical theory for object representation, | AdaBoost Gabor Fisher classifier for face recognition, | Adaboost Gabor feature selection for classification, | Recognition of faces in unconstrained environments: A comparative study, | Regression shrinkage and selection via the lasso, | Greed is good: Algorithmic results for sparse approximation, | Topics in sparse approximation, | Signal recovery from random measurements via orthogonal matching pursuit, | Eigenfaces for recognition, | Towards a practical face recognition system: Robust registration and illumination by sparse Representation, | Boosted multi-task learning for face verification with applications to web images and video search, | Face recognition by elastic bunch graph matching, | Robust face recognition via sparse representation, | Implicit elastic matching with random projections for pose-variant face recognition, | Exploring feature descriptors for face recognition, | Face recognition using Ada-boosted Gabor features, | Boosting local binary pattern (LBP)-based face recognition, | P.Phillips, and A.Rosenfeld, ”Face recognition: A literature survey,",rejected,000
1102.2749.pdf.json,MULTI-TASK GLOH FEATURE SELECTION FOR HUMAN AGE ESTIMATION,"Within the past decade, automatic age estimation has become an active research topic due to its emerging new applications from human-computer interaction to security control, surveillance monitoring, biometrics, etc. For example, in automatic human computer interaction (HCI) applications if computers can determine the age of the user, both the content of computer and the type of interaction can be adjusted according to the age of the user. In security control and surveillance monitoring, the automatic age estimation system can prevent minors from drinking wine or purchasing tobacco. Aging is a very complicated process and is determined by both innate factors and environmental factors such as heredity, gender, health, and lifestyle, which make the automatic age estimation very challenging. Much works on age estimation problem has been undertaken in recent years. Two keys to these methods are face representation and age estimation [1]. Existing face representation techniques for age estimation often include the anthropometric models [2], active appearance models [3, 4, 5], aging pattern subspace [6], age manifold [7, 1, 8], local features such as local binary patterns (LBP) features [9], Gabor features [10], spatially fexible patch (SFP) [11], bio-inspired features (BIF) [12], etc. and the combination of them [13, 14]. Based on these face representation, the age estimation can be performed by considering it as a classification problem [2, 3, 4, 6, 9, 14] or a regression problem [11, 12, 13, 3, 4, 5] or a hybrid of two [1]. It is well known that aging process shares a global trend but is specific to a given individual. Most of existing methods concern the building of global age estimator [10, 12, 11] due to the lack of training data for each individual. There are also a few works care on the person specific age estimation [3, 4, 6, 5]. In this paper we propose a novel method based GLOH representation [15] and MTL feature selection [16] along with ridge regression for g","Age synthesis and estimation via faces: A survey | Age classification from facial images | Toward automatic simulation of aging effects on face images | Comparing different classifiers for automatic age estimation | Multi-task warped gaussian process for personalized age estimation | Automatic age estimation based on facial aging patterns | Human age estimation with regression on discriminative aging manifold | Discriminant feature manifold for facial aging estimation | Demographic classification with local binary patterns | Face age classification on consumer images with gabor feature and fuzzy lda method | Ranking with uncertain labels | Human age estimation using bio-inspired features | A study on automatic age estimation using a large database | Age categorization via ecoc with fused gabor and lbp features | A performance evaluation of local descriptors | Joint covariate selection and joint subspace selection for multiple classification problems | Multi-task feature learning via efficient l2,1-norm minimization",rejected,000
1102.3868.pdf.json,,"Given a set V of Boolean variables and a set of disjunctive clauses on literals from V (i.e., variables or their negations), MAX-SAT asks for a truth assignment to the variables that maximizes the number of clauses that are satisfied (i.e., made true by that assignment). MAX-SAT is NP-hard [8] but can be approximated in polynomial time, though not as close to the optimum as one wishes (cf. [2] and references therein, as well as [5] for the restricted case of three-literal clauses). MAX-SAT has enjoyed a paradigmatic status over the years, not only because of its close relation to SAT, the first decision problem to be proven NP-complete, but also because of its importance to other areas (e.g., constraint satisfaction in artificial intelligence [6]). Since NP-hardness is a property of worst-case scenarios, the difficulty of actually solving a specific instance of an NP-hard problem varies widely with both the instance’s size and internal structure. In fact, in recent years it has become ∗Corresponding author (valmir@cos.ufrj.br). increasingly clear that small changes in either can lead to significant variation in an algorithm’s performance, possibly even to a divide between the instance’s being solvable or unsolvable by that algorithm given the computational resources at hand and the time one is willing to spend [13]. Following some early groundwork [25], several attempts have been made at providing theoretical foundations or practical guidelines for automatically selecting which method to use given the instance [26, 23, 7, 12, 17, 19, 31]. Here we investigate a different, though related, approach to method selection in the case of MAX-SAT instances. Since all MAX-SAT heuristics require an initial truth assignment to the variables, and considering that this is invariably chosen at random, a natural question seems to be whether it is worth spending some additional effort to determine an initial assignment that is better suited to the instance at hand. Once we adopt thi",Third Max-SAT evaluation | Complexity and Approximation: Combinatorial Optimization Problems and their Approximability Properties | Massively Parallel Models of Computation | A distributed implementation of simulated annealing | MAX SAT approximation beyond the limits of polynomial-time approximation | Constraint Processing | How to solve it automatically: Selection among problem-solving methods | Computers and Intractability: A Guide to the Theory of NP-Completeness | Stochastic relaxation | Towards an understanding of hill-climbing procedures for SAT | Unsatisfied variables in local search | Algorithm portfolios | Phase Transitions in Combinatorial Optimization Problems: Basics | An adaptive noise mechanism for WalkSAT | Scaling and probabilistic smoothing: Efficient dynamic local search for SAT | Optimization by simulated annealing | Selecting the right algorithm | The SAT 2004 competition | Boosting as a metaphor for algorithm design | Algorithms for weighted Boolean optimization | Tabu search for SAT | Evidence for invariants in local search | Automatically configuring constraint satisfaction programs: A case study | An Introduction to Genetic Algorithms | The algorithm selection problem | Provably bounded-optimal agents | Domain-independant extensions to GSAT: Solving large structured variables | A new method for solving hard satisfiability problems | Warped landscapes and random acts of SAT solving | UBCSAT: An implementation and experimentation environment for SLS algorithms for SAT and MAX-SAT | Confronting hardness using a hybrid approach,rejected,000
1102.4922.pdf.json,Counting Solutions of Constraint Satisfiability Problems: Exact Phase Transitions and Approximate Algorithm,,Generating Satisfiable Problem Instances | The Good Old Davis-Putnam Procedure Helps Counting Models | A new upper bound for 3-SAT | Beyond NP: the QSAT phase transition | Counting CSP Solutions Using Generalized XOR Constraints | Hard and easy distributions of sat problems | Combining Component Caching and Clause Learning for Effective Model Counting | Exact Phase Transitions in Random Constraint Satisfaction Problems,rejected,000
1102.4924.pdf.json,New Worst-Case Upper Bound for #XSAT,"Tremendous efforts have been made on analyzing algorithms for difficult problems, such as propositional satisfiability (SAT) or model counting (#SAT). If P ≠ NP, these problems are all super-polynomial. When constructing the super-polynomial algorithms, improvements in the exponential time bounds are crucial in determining the size of these problems that can be solved, for even a slight improvement from O(c k ) to O((c-) k ) may significantly increase the size of these problems being tractable. Take the 3-SAT problem for example. The currently fastest deterministic algorithm for solving 3-SAT (Kutzkov et al. 2010) ran in O(1.439 n ), which is a meaningful advance over O(2 n ). And the 3-SAT instances with 65 variables can be solved by the algorithm in approximately 10 10 steps, instead of 10 19 (which may not be tractable). Therefore, it is significant to improve the upper bounds on the worst-case running time for problems with high computational complexity. #XSAT is one of hard problems whose computational complexity is further up the polynomial hierarchy. Valiant (1979) has proved that #XSAT is #P-complete. This is a problem of computing the number of models for a given formula in Conjunction Normal Form (CNF), i.e., the number of distinct complete truth assignments to variables such that exactly one literal in each clause evaluates to true. In fact, the problem is a vital variant of the well-known #SAT problem, which has a wide range of applications, such as various probabilistic inference problems can be translated into #SAT problem (cf. Park 2002; Sang et al. 2005). Recently, most of the efforts in algorithm construction have been dedicated to algorithms for #XSAT problem. For example, based on an algorithm for counting all maximum weight independent sets in a simple graph, Dahllof and Jonsson (2002) presented an upper time bound for #XSAT (O(1.7548 n ), where n is the number of the variables). Further improved algorithm in (Porschen 2005) proposed a new upper ",New algorithms for Exact Satisfiability | Using CSP to improve deterministic 3-SAT. arXiv:1007.1166v2 | 16254n ) for exact 3-satisfiability: a simpler proof | MAP complexity results and approximation methods | The complexity of computing the permanent,rejected,000
1102.4925.pdf.json,"Worst-Case Upper Bound for (1, 2)-QSAT","Quantified Boolean Formulas (QBF) can be viewed as a generalization version of the Boolean satisfiability (SAT) with existential or universal quantifiers to every variable in propositional formulas. This problem permits both universal and existential quantifiers over Boolean variables. Deciding whether a QBF is satisfiable is the prototypical problem for PSPACE-complete problems, and is also one of the most important issues in artificial intelligence field. Many practical problems can be transformed into QBF, such as intelligent planning problems, non-monotonic reasoning problems and reasoning about knowledge problems. Based on the fact that there is no polynomial time algorithm exists for SAT problems, assuming P≠NP stands, developing fast exact algorithm for testing satisfiability of propositional formulas are crucial in determining the scale of the problems that can be solved. Because a slight improvement from O(c k ) to O((c-)k) may significantly increase the size of the problem being tractable, it is not surprising to view tremendous efforts made by researchers to designing exact algorithms providing better upper bound of SAT problems. Take 3-SAT problem for instance. The currently best upper bound for deterministic algorithm is O(1.439 n ) achieved by Kutzkov and Scheder [6], and that for local search algorithm is O(1.32216 n ) achieved by Rolf [7]. When it comes to QBF problem, the best upper bound of QBF problem in 3CNF (conjunctive normal form) is O(1.619 m ) where m is the number of clauses, as can be seen in ([8]. However, this upper bound is achieved under the restriction that the number of clauses should be equal to the number of variables. Moreover, Williams pointed out that when the clause-to-variable ratio approaches 2, the bound approaches 2 n . In this paper, we focus on a subclass of closed quantified Boolean formulas, (1, 2)- QSAT, which was first introduced in [2]. (1, 2)-QSAT-formulas are in the form of ( , )X Y X Y  , where X has 1n variables,","A linear-time algorithm fortesting thetruth of certain quantified Boolean formulas, Information Processing | New results on the phase transition for random quantified Boolean formulas | 1, 2)-QSAT: A Good Candidate for Understanding Phase Transitions Mechanisms | Improved Algorithms for 3-Coloring, 3-Edge-Coloring, and Constraint Satisfaction | A | Using CSP to improve deterministic 3-SAT | Improved bound for the PPSZ/Schoning-algorithm for 3-SAT | Algorithms for quantified Boolean formulas | New Worst-Case Upper Bound for #2-SAT and #3-SAT with the Number of Clauses as the Parameter",rejected,000
1102.4926.pdf.json,New Worst-Case Upper Bound for X3SAT,"Exact satisfiability problem, abbreviated XSAT, is a problem of deciding whether there is a truth assignment satisfying exactly one literal in each clause. The exact 3- satisfiability (X3SAT) is the version in which each clause contains at most three literals. The X3SAT problem is an important variant of the well-known NP-complete problem of propositional satisfiability (SAT), which has played a key role in complexity theory as well as in automated planning. In fact, X3SAT is also a NPcomplete problem even when restricted to all variables occurring only unnegated [1]. If P ≠ NP, it means that we can’t solve the problem in polynomial time. Therefore, Improvements in the exponential time bounds are crucial in determining the size of NP-complete class problem that can be solved. Even a slight improvement from O(c k ) to O((c-) k ) may significantly increase the size of the problem being tractable. Recently, tremendous efforts have been made on analyzing of algorithms for X3SAT problems. Based on a recursive partitioning of the problem domain and a careful elimination of some branches, Drori and Peleg presented an algorithm running in O(1.1545 n ) for X3SAT, where n is the number of the variables [2]. By adapting and improving branching techniques, Porschen et al. proposed an algorithm for solving X3SAT running in O(1.1487 n ) [3]. According to exploit a perfect matching reduction and present a more involved deterministic case analysis, Porschen et al. prove a new upper bound for X3SAT (O(1.1926 n )) [4]. By providing a new transformation rule, Kulikov [5] simplified the proof of the bound for X3SAT (O(1.1926 n )) presented by Porschen et al. [4]. Based on combining various techniques including matching and reduction, Dahllöf et al. addressed an algorithm running in O(1.1120 n ) for X3SAT [6]. Further improved algorithms in [7] presented a new upper time bound for the X3SAT (O(1.1004 n )), which is the best upper bound so far. Different from complexity analyses regardin",The Complexity of Satisfiability Problems | Faster Exact Solutions for Some NP-hard Problems | X3SAT is Decidable in time O(2) | Exact 3-Satisfiability is Decidable in time O(2) | An Upper Bound O(2) for Exact 3-Satisfiability: a Simpler Proof | Algorithms for Four Variants of the Exact Satisfiability Problem | New Algorithms for Exact Satisfiability | Exact Algorithms for Variants of Satisfiability and Colouring Problems | An Algorithm for Exact Satisfiability Analysed with the Number of Clauses as Parameter | New Worst-Case Upper Bounds for SAT | Upper Bounds for Covering Problems | New Worst-Case Upper Bound for #2-SAT and #3-SAT with the Number of Clauses as the Parameter,rejected,000
1102.5185.pdf.json,,"Traditionally higher-order logic representation of natural language semantics (Thomason, 1974) had to be combined with an additional formalism to describe a syntactic structure of a language and a mapping between the two. This two-component architecture of a language model has not essentially changed with the invention and further rapid development of type-logical grammar (Lambek, 1958; Blackburn et al., 1997), i.e. a parallel logical formalism to describe a syntactic structure: in spite of the very close and deep correspondence between the two logics, their internal languages and semantics remain different. Several theoretical, methodological and technological issues are rooted in the two-component architecture of a language model, out of which it is important to mention here the following. 1. A language in such a model cannot express anything about another language of the same model nor, of course, about itself. This kind of expressiveness is, however, one of the characteristic capabilities of a natural language. 2. Lack of lexical robustness. As the semantic interpretation of a sentence in the two-component language model can be composed only from semantic interpretations of all its constituents, such a model fails to interpret an entire sentence if it contains even a single unrecognized (new) word. Some ad hoc add-ins to the formalism are the only known solution of the issue. 3. Lack of structural (syntactic) robustness. Unlike the semantic logic, which may be universally applicable for a wide variety of languages, the syntactic logic often requires special extensions in order to cover different languages and even specific structures in the same language. Capturing the semantic categories and their relationships in the very formalism (rather than in a concrete language model) makes it principally incapable of modeling language self-learning, that is derivation of new grammar rules from text samples. These, along with some other issues and needs motivated researc","An Introduction to Mathematical Logic and Type Theory: To Truth Through Proof | Logical Aspects of Computational Linguistics: an Introduction (In Retoré, C. (Ed.), LACL’96 | Unification and matching modulo type isomorphism | Situations and individuals. Current Studies in Linguistics | WordNet: An electronic lexical database | Intensional and Higher-Order Modal Logic with Applications to Montague Semantics | A multi-level, higher-order unification approach to ellipsis | Reference and generality: An examination of some medieval and modern theories | A note on Higher Order Grammar. Corr, abs/0910.0537 | Method and system for processing, storing, retrieving and presenting information with an extendable interface for natural and artificial languages. US Patent 6,999,934 | Dynamic montague grammar. Pages 3–48 of: Papers from the second symposium on logic and language. Akademiai Kiadoo | Dynamic predicate logic | The semantics of definite and indefinite noun phrases | File change semantics and the familiarity theory of definiteness | Haskell 98 language and libraries: The revised report | A theory of truth and semantic representation. Pages 277–321 | A logical semantics for feature structures. Pages 257–266 of: Acl proceedings, 24th annual meeting | A Logical Formalism for Head-Driven Phrase Structure Grammar | The mathematics of sentence structure | Higher-order categorical grammar | Hyperintensional semantics in a higher order logic with definable subtypes. Pages 32–45 of: Proceedings of the second workshop on lambda calculus, type theory, and natural language, king’s college london | Higher order grammar (introductory course, language and logic section). In: The 18th European Summer School in Logic, Language and Information | Ambiguity, neutrality, and coordination in higher order grammar | A mathematical formalism for linguistic theories with an application in head-driven phrase structure grammar. Phil | The formal relationship between direct and continuation-passing style optimizing compilers: a synthesis of two paradigms | Formal philosophy: Selected Papers of Richard Montague. New Haven (Conn.) (etc.): Yale | The essence of functional programming. Pages 1–14 of: Popl ’92: Proceedings of the 19th acm sigplan-sigact symposium on principles of programming languages",rejected,000
1102.5385.pdf.json,,,"Strongly equivalent logic programs | Equivalence of logic programs under updates | REVISE: Logic programming and diagnosis | Dynamic updates of non-monotonic knowledge bases | On properties of update sequences based on causal rejection | An abductive framework for computing knowledge base updates | Logic program-based updates | The refined extension principle for semantics of dynamic logic programming | A preference-based framework for updating logic programs | Belief revision of logic programs under answer set semantics | A Program-Level Approach to Revising Logic Programs under the Answer Set Semantics | Belief Revision, chapter Belief Revision: An Introduction, pages 1–28 | On semantic update operators for answer-set programs | Towards a theory of declarative knowledge | A classification theory of semantics of normal logic programs: II | Die Logik und das Grundlagenproblem | A new logical characterisation of stable models and answer sets | Strong equivalence made easy: nested expressions and weight constraints | The stable model semantics for logic programming | Negation as failure in the head | Minimal logic programs | Introduction to Lattices and Order",rejected,000
1102.5451.pdf.json,,"Unlike deterministic finite automata (DFA), whose efficient minimization is possible, the state minimization problem for non-deterministic finite automata (NFA) is computationally hard (PSPACE-complete, [41, 77]) and known algorithms like in [16, 42, 55, 56, 76] cannot be used in practice. For that reason, many researchers aimed their attention to NFA state reduction methods which do not necessarily give a minimal one, but they give ”reasonably” smallNFAs that can be constructed efficiently. The basic idea of reducing the number of states of NFAs by computing and merging indistinguishable states resembles the minimization algorithm for DFAs, but is more complicated. That led to the concept of a right invariant equivalence on an NFA, studied by Ilie andYu [36, 37], who showed that they can be used to construct smallNFAs from regular expressions. In particular, both the partial derivative automaton and the follow automaton of a given regular expression are factor automata of the position automaton with respect to the right invariant equivalences (cf. [19, 20, 35, 37, 38]). Right invariant equivalenceshave beenalso studied in [10, 11, 18, 37, 39, 40].Moreover, the same conceptwas studiedunder thename”bisimulation equivalence” inmanyareas of computer science and mathematics, such as modal logic, concurrency theory, set theory, formal verification, model checking, etc., and numerous algorithms have been proposed to compute the greatest bisimulation equivalence on a given labeled graph or a labeled transition system (cf. [52, 57, 58, 59, 62, 73, 75]). The faster algorithms are based on the crucial equivalence between the greatest bisimulation equivalence and the relational coarsest partition problem (see [28, 29, 43, 72, 61]). ✩Research supported by Ministry of Science and Technological Development, Republic of Serbia, Grant No. 174013 ∗Corresponding author. Tel.: +38118224492; fax: +38118533014. Email addresses: aca@pmf.ni.ac.rs (Aleksandar Stamenković), mciric@pmf.ni.a",Fuzzy relational products as a tool for analysis and synthesis of the behaviour of complex natural and artificial systems | On quotient machines of a fuzzy automaton and the minimal machine | Fuzzy Relational Systems: Foundations and Principles | Fuzzy Equational Logic | A similarity-based generalization of fuzzy orderings preserving the classical axioms | A compendium of fuzzy weak orders: Representations and constructions | A formal study of linearity axioms for fuzzy orderings | A Course in Universal Algebra | Finite nondeterministic automata: Simulation and minimality | Mergible states in large NFA | Supervisory control of fuzzy discrete event systems | Observability and decentralized control of fuzzy discrete-event systems | State-based control of fuzzy discrete-event systems | Introduction to Discrete Event Systems | Theoretical study and implementation of the canonical automaton | NFA reduction algorithms by means of regular inequalities | NFA reduction algorithms by means of regular inequalities | New finite automaton constructions based on canonical derivatives | Computing the equation automaton of a regular expression in O (s2) space and time | Minimization algorithm of fuzzy finite automata | Fuzzy equivalence relations and their equivalence classes | Uniform fuzzy relations and fuzzymappings | Factorization of fuzzy automata | Fuzzy relation equations and reduction of fuzzy automata | The cutting of compositions | Fuzzy modifiers based on fuzzy relations | An efficient algorithm for computing bisimulation equivalence | Frombisimulation to simulation: coarsest partition problems | Commutative | Modeling and control of discrete-event dynamical systems: with Petri nets and other tools | Determinization of fuzzy automatawithmembership values in complete residuated lattices | Fuzzy homomorphisms of algebras | Myhill-Nerode type theory for fuzzy languages and automata | Constructing NFAs by optimal use of positions in regular expressions | Algorithms for computing small NFAs | Reducing NFAs by invariant equivalences | Follow automata | On NFA reductions | Reducing the size of NFAs by using equivalences and preorders | Minimal NFA problems are hard | On the state minimization of nondeterministic finite automata | CCS expressions | Diagnosability of fuzzy discrete event systems | Fuzzy Sets and Fuzzy Logic | Minimization of states in automata theory based on finite lattice-ordered monoids | Fuzzy finite automata and fuzzy regular expressions with membership values in lattice ordered monoids | Fuzzy discrete event systems and their observability | Modeling and control of fuzzy discrete event systems | Decision making in fuzzy discrete event systems | The relationship of controllability between classical and fuzzy discrete-event systems | Forward and backward simulations: Part I | Minimization of fuzzy finite automata | Fair testing revisited: A process-algebraic characterisation of conflicts | A new algorithm of the state-minimization for the nondeterministic finite automata | Once more about the state-minimization of the nondeterministic finite automata | A calculus of communicating systems | Communication and Concurrency | Communicating and Mobile Systems: the π-Calculus | Fuzzy Automata and Languages: Theory and Applications | Three partition refinement algorithms | Concurrency and automata on infinite sequences | Fuzzy function as an approximate solution to a system of fuzzy relation equations | Solvability and approximate solvability of fuzzy relation equations | System of fuzzy relation equations as a continuous model of IF-THEN rules | Congruences and homomorphisms of fuzzy automata | Automata theory based on completed residuated lattice-valued logic (I) | Automata theory based on completed residuated lattice-valued logic (II) | Supervisory control of fuzzy discrete event systems: a formal approach | Pumping lemma in automata theory based on complete residuated lattice-valued logic: A note | Fuzzy discrete-event systems under fuzzy observability and a test algorithm | Generalizing the PaigeTarjan algorithm by abstract interpretation | Towards a unified view of bisimulation: a comparative study | Resolution of composite fuzzy relation equations | On the origins of bisimulation | Minimization of nondeterministic finite automata | Regular languages | Toward a generalized theory of uncertainty (GTU) – an outline | Is there a need for fuzzy logic,rejected,000
1102.5452.pdf.json,Bisimulations for fuzzy automata,"Study of fuzzy automata and languages was initiated in 1960s by Santos [95–97], Wee [103], Wee and Fu [104], and Lee and Zadeh [58]. From late 1960s until early 2000smainly fuzzy automata and languages with membership values in the Gödel structure have been considered (see for example [25, 33, 74]). The idea of studying fuzzy automatawithmembership values in some structured abstract set comes back toW.Wechler [102], and in recent years researcher’s attention has been aimedmostly to fuzzy automata withmembership values in complete residuated lattices, lattice-orderedmoinoids, and other kinds of lattices. Fuzzy automata taking membership values in a complete residuated lattice were first studied by D.W. Qiu in [83, 84], where some basic concepts were discussed, and later, D. W. Qiu and his coworkers have carried out extensive research of these fuzzy automata (cf. [85, 87, 105–109]). From a different point of view, fuzzy automata with membership values in a complete residuated latticewere studied by J. Ignjatović, M. Ćirić and their coworkers in [20, 21, 39–41, 43, 100]. Fuzzy automata with membership values in a lattice-ordered monoid were investigated by Y. M. Li and others [59, 60, 62, 64], fuzzy automata over other types of lattices were the subject of [30, 54, 57, 61, 63, 77–80], and automatawhich generalize fuzzy automata over any type of lattices, as well as weighted automata over semirings, have been studied recently in [17, 29, 48]. Notably, fuzzy ✩Research supported by Ministry of Science and Technological Development, Republic of Serbia, Grant No. 174013 ∗Corresponding author. Tel.: +38118224492; fax: +38118533014. Email addresses: miroslav.ciric@pmf.edu.rs (Miroslav Ćirić), jelena.ignjatovic@pmf.edu.rs (Jelena Ignjatović), nada@tfc.kg.ac.rs (Nada Damljanović), basic_milan@yahoo.com (Milan Bašić) Preprint submitted to May 9, 2011 automata have been used to simulate discrete event systems (see [65, 86, 89]). In the present paper, we will study bisim","Reactive Systems: Modelling | On the general theory of relational morphisms | On quotient machines of a fuzzy automaton and the minimal machine | On the equivalence of Z-automata | Conjugacy and equivalence of weighted automata and functional transducers | On the generating sequences of regular languages on k symbols | Fuzzy Relational Systems: Foundations and Principles | Determinism and fuzzy automata | Fuzzy Equational Logic | Iteration Theories: The Equational Logic of Iterative Processes | Bisimulation relations for weighted automata | Finite nondeterministic automata: Simulation and minimality | NFA reduction algorithms by means of regular inequalities | Minimization algorithm of fuzzy finite automata | Decompositions of T-generalized transformation semigroups | Determinization of weighted finite automata over strong bimonoids | Fuzzy equivalence relations and their equivalence classes | Uniform fuzzy relations and fuzzy functions | Factorization of fuzzy automata | Fuzzy relation equations and reduction of fuzzy automata | Fuzzy functions and their applications | Foundations of fuzzy functions and vague algebra based on many-valued equivalence relations | A theory of vague lattices based on many-valued equivalence relations – I: general representation results | Fuzzy Sets and Systems: Theory and Applications | A generalization of Kozen’s axiomatization of the equational theory of the regular sets, in: Words, semigroups, and transductions, World Scientific, River | Simulation vs | An efficient algorithm for computing bisimulation equivalence | Weighted finite automata over strong bimonoids | Kleene and Büchi results for weighted automata and multi-valued logics over arbitrary bounded lattices | Automata | From bisimulation to simulation: coarsest partition problems | Fuzzy Automata and Decision Processes | Mathematics of fuzzy logic | P | Backward and forward bisimulation minimisation of tree automata | Commutative | Formal power series and regular operations on fuzzy languages | Determinization of fuzzy automata with membership values in complete residuated lattices | Fuzzy homomorphisms of algebras | On the greatest solutions to certain systems of fuzzy relation inequalities and equations | Myhill-Nerode type theory for fuzzy languages and automata | Algorithms for computing small NFAs | Reducing NFAs by invariant equivalences | On NFA reductions | Reducing the size of NFAs by using equivalences and preorders | An improved algorithm for determinization of weighted and fuzzy automata | CCS expressions | Generalized morphisms | Products of T-generalized state machines and T-generalized transformation semigroups | Fuzzy points | Fuzzy Sets and Fuzzy Logic | Fuzzification of rational and recognizable sets | Automata and Computability | On covering of products of fuzzy finite state machines | Lattice automata | Note on fuzzy languages | Minimization of states in automata theory based on finite lattice-ordered monoids | Algebraic properties of LA-languages | Finite automata theory with membership values in lattices | Fuzzy finite automata and fuzzy regular expressions with membership values in lattice ordered monoids | Minimization of lattice finite automata and its application to the decomposition of lattice languages | The relationships among several types of fuzzy automata | Modeling and control of fuzzy discrete event systems | On the construction of reversible automata for reversible languages | Derivatives of rational expressions with multiplicity | Forward and backward simulations: Part I | Products of fuzzy finite state machines | Minimization of fuzzy finite automata | A calculus of communicating systems | Communication and Concurrency | Communicating and Mobile Systems: the π-Calculus | Fuzzy Automata and Languages: Theory and Applications | Three partition refinement algorithms | Concurrency and automata on infinite sequences | Finite L-fuzzy acceptors | Finite L-fuzzy machines | Fuzzy Relational Calculus: Theory | Computing behavior of finite fuzzy machines – Algorithm and its application to reduction and minimization | Congruences and homomorphisms of fuzzy automata | Syntactic semigroups | Automata theory based on completed residuated lattice-valued logic (I) | Automata theory based on completed residuated lattice-valued logic (II) | Characterizations of fuzzy finite automata | Supervisory control of fuzzy discrete event systems: a formal approach | Pumping lemma in automata theory based on complete residuated lattice-valued logic: A note | A note on Trillas’ CHC models | Fuzzy discrete-event systems under fuzzy observability and a test algorithm | Generalizing the Paige-Tarjan algorithm by abstract interpretation | Towards a unified view of bisimulation: a comparative study | Automata and coinduction (an exercise in coalgebra) | Elements of Automata Theory | On the origins of bisimulation and coinduction | Maximin automata | On reduction of maxmin machines | Fuzzy automata and languages | Homomorphism and isomorphism theorems generalized from a relational perspective | The Algorithm Design Manual | Categories of relational structures | The Concept of Fuzziness in Automata and Language Theory | On generalizations of adaptive algorithm and application of the fuzzy sets concept to pattern classification, Ph.D | A formulation of fuzzy automata and its application as a model of learning systems | Automata theory based on complete residuated lattice-valued logic: Reduction and minimization | Pumping lemma in context-free grammar theory based on complete residuated lattice-valued logic | Automata theory based on complete residuated lattice-valued logic: A categorical approach | Automata theory based on complete residuated lattice-valued logic: Pushdown automata | Equivalence in automata theory based on complete residuated lattice-valued logic | On relational homomorphisms of automata | Toward an algebraic theory of fuzzy relational systems, Technical Report: CS-TR-73-25",rejected,000
1102.5635.pdf.json,Practical inventory routing: A problem definition and an optimization method,"Many logistic activities are concerned with linking material flows among companies and processes. In such applications, we find a combination of quantity decisions, e. g. the amount of goods shipped (Inventory Management), and routing decisions as tackled in the area of Vehicle Routing. Clearly, both areas intersect to a considerable degree, complicating the solution of such problems. Recently, intensive research has been conducted in this context which is commonly refereed to as Inventory Routing Problems [2, 3] (IRP). Several variants of the IRP can be found, ranging from deterministic demand cases to stochastic models. From the practical point of view of the companies, reality is much more complex than a know demand and much more uncertain than a stochastic law. In fact, companies often have a partial knowledge of the demand over the planning horizon. Our observation of this phenomenon can be transformed in a new type of data, which we propose for further experimental investigations. We here assume that demand of the current period is known at the beginning of the period. Besides, we have an approximate overview of the demand over the 5 next periods, the 20 next periods and the 60 next periods. This overview is rather good (e.g. it does not differ from reality by more that ±10%) but of course, we cannot predict with certainty what will happen the next periods. The global objective of this work is to provide practical optimization methods to companies involved in inventory routing problems, taking into account this new type of data. Also, companies are sometimes not able to deal with changing plans every period and would like to adopt regular structures for serving customers. As our work is a long term project, we are gradually going to develop our solution approach. In a first phase, we will focus on the Inventory Routing problem with a single product, deterministic known demand over a finite horizon. Contrary to [1], we assume that the routing costs and the inve","A hybrid heuristic for an inventory-routing problem | Dynamic routing-and-inventory problems: A review | The Vehicle Routing Problem: Latest Advances and New Challenges, chapter Inventory Routing, pages 49–72 | Combinatorial optimization, chapter The vehicle routing problem, pages 315–338 | A record-to-record travel algorithm for solving the heterogeneous fleet vehicle routing problem | Inventory routing and on-line inventory routing file format",rejected,000
1103.0632.pdf.json,AN AGENT BASED ARCHITECTURE (USING PLANNING) FOR DYNAMIC,"The great success of Web services, due especially to their richness of application made possible by open common standards, has led to their wide proliferation and a tremendous variety of Web services (WS) are now available. However, this proliferation has rendered the discovery, search and use of an appropriate Web services arduous. These tasks are increasingly complicated, especially while dealing with composite Web service to response to an ostensible long-term complex user’s goal. The automatic Web service composition task consists of finding an appropriate combination of existing Web services to achieve a global goal. Solving this problem involves mixing and matching component Web services according to certain features. These features can be divided into two main groups [1]: - Features related to the user, including the user’s constraints and preferences. - Features related to Web services and which can be divided into two subgroups, internal and external features. Internal features include quality of service (QoS) attributes, and external features include existing restrictions on the connection of Web services, (e.g., a hotel room should be reserved for a conference usually after booking the flight). External features are specified in the Web service ontology language, OWL-S [2], through a set of control constructs such as, Sequence, Unordered, Choice, etc. In the field of Web services, the Semantic Web Services (SWS) approach [3] is a step toward dynamic service discovery and composition [4, 5] where intelligent systems try to build service compositions from abstract user requirements without a manual selection of services. SWS build on knowledge representation techniques, with ontologies describing a domain in a formal manner, and AI planning methods to make composition systems more autonomous. An agent possesses the ability to understand and interact with its environment. Because of being context- aware, autonomous and able to interpret semantics with the he","A Constraint-based Approach to Horizontal Web Service Composition | DAML-S: Web Service Description for the Semantic Web | Automated discovery, interaction and composition of semantic web services | Agents Negotiating with Semantic Web Services | Adapting Golog for Composition of Semantic Web Services”, KR | J.Xie, H.Guo & H.Wang,(2005) “Solving Qos-driven Web Service Dynamic Composition as Fuzzy Constraint Satisfaction | Planning and MonitoringWeb Service Composition | Automated Composition of Web Services by Planning at the Knowledge Level | Automated Composition of Web Services by Planning in Asynchronous Domains | Un modèle de composition automatique et distribué de services Web par planification“, RSTI - RIA - 23/2009 | Semantic Web Services | A Planner for Composing Services Described in DAML-S | Computation Orchestration: A Basis for Wide-area Computing | Semi-automatic composition of web services using semantic descriptions”, In Proceedings Web Services: Modeling, Architecture and Infrastructure. Workshop in Conjunction with ICEIS2003 | Towards a Semantic Composition of ebXML Business Processes | Ontologies in Agent Infrastructure | A coordination algorithm for multi-agent planning | Vers une architecture à base d’agents pour une composition sémantique et dynamique des services web dans un contexte d’ebXML | Multi-data source fusion approach in Peer-to-Peer systems | OWL Web Ontology Language Overview",rejected,000
1103.0697.pdf.json,"A Wiki for Business Rules in Open Vocabulary, Executable English","The well known ""layer cake"" diagram (Berners-Lee 2004) outlines a high level agenda for work on the Semantic Web. 2 There is much current work in progress under the heading of ""Semantics"", as in the interleaving of metadata with data in RDF or OWL, stemming from (Berners-Lee et al, 2001). Such work fits into the layers from XML to Ontology in Figure 1. It may be useful to think of this as ""data semantics"", or ""Semantics1"". In the diagram, there are boxes labeled Rule, Unifying Logic, Proof and Trust, User Interface and Applications. This paper describes one way of meeting some of the requirements indicated by those boxes, with an online system that combines Semantics1 with two further kinds of meaning. Semantics2 specifies what conclusions a reasoning engine should be able to infer from any set of rules and facts (Walker 1993), using a logical model theory (Apt et al 1988) that takes into account the semantics under which databases are used in practice. Semantics3 concerns the meaning of English concepts at the author- and user-interface. The design of the system described here rests on making Semantics1, 2, and 3 work together. Adding and integrating these semantic dimensions has the potential not only to support aspects of the Semantic Web, but also to ease some significant problems in commercial IT. According to (Forrester 2005) : Aligning IT strategy with business strategy has been one of the top three issues confronting IT and business executives for more than 20 years. Polling of CIOs and business executives conducted in 2004 revealed that aligning IT and business goals remains their No. 1 or 2 priority. As one way of addressing the problem, this paper shows how to support the writing and running of applications as rules in open vocabulary, executable English. The system that does this takes a lightweight approach to English, backed by an inference engine that assigns a highly declarative meaning to a set of rules. The system accepts rules in English, and smal","Towards a theory of declarative knowledge | www.w3.org/2004/Talks/0412-RDF-functions/slide4-0.html. See also update at http://www.w3.org/2007/03/layerCake.png | The Semantic Web | A Comparison of RDF Query Languages | Oil Industry Supply Chain Management Using English Business Rules Over SQL | Semantic Resolution for E-Commerce | Relations in Biomedical Ontologies | Backchain Iteration: Towards a Practical Inference Method that is Simple Enough to be Proved Terminating, Sound and Complete",rejected,000
1103.2091.pdf.json,An Artificial Immune System Model for Multi Agents Resource Sharing in Distributed Environments,"In recent years there has been considerable interest in exploring and exploiting the potential of biological systems for applications in computer science and engineering. These systems are inspired by various aspects of the immune systems of mammals. Artificial immune system imitates the natural immune system that has sophisticated methodologies and capabilities to build computational algorithms that solves engineering problems efficiently [2]. The main goal of the human immune system is to protect the internal components of the human body by fighting against the foreign elements such as the fungi, virus and bacteria [1]. Moreover, research into natural immune systems suggests the existence of learning properties which may be used to advantage in machine learning systems [5]. Similarly, if there is an environment which is divided into sub environment then each sub environment is traversed by a single bot. Every bot is assigned to do a set job in its environment. Considering an environment being divided into n sub environment with m Bots, each working on one environment, the complete environment may be obtained by summing up all the individual bot and the sub-environment The objective of this research is to demonstrate the utility of multi-robot deployed using a unique First Come First Serve (FCFS) charging where only a single charger is used by multiple bots in an environment such that none of the bots are allowed to stop functioning by complete discharge of the battery power. To achieve this unique goal a new computational technique called the Artificial Immune System is applied which presumes the discharge of power of the battery as an external attack to malign the operation of the robot in the environment and uses natural immune concepts to make the robot immune to such failure.",An Artificial Immune System Model for Multi Agents based Resource Discovery in Distributed Environment | Principles of a Computer Immune System | Adaptation in Natural and Artificial Systems | Hive - Distributed Agents for Networking | An Artificial Immune System for a MultiAgent Robotics System,rejected,000
1103.3123.pdf.json,Reduced Ordered Binary Decision Diagram with Implied Literals: A New knowledge Compilation Approach,"Reasoning problems in their general form are intractable and knowledge compilation has been emerging as a key direction of research for dealing with such kind of intractability [1-5]. The basic idea of knowledge compilation is to split the reasoning process into two phases: an off-line compilation phase, in which the propositional theory is compiled into some tractable target language, and an on-line query-answering phase, in which the compiled target is used to efficiently answer the queries. And the compiling time in off-line phase can be amortized by a (potentially) exponential number of on-line queries. The target language is one of key aspects for any compilation approach. There have existed dozens of target languages so far, such as Horn theories [1], prime implicates/implicants [6, 7], reduced ordered binary decision diagram (ROBDD) [8, 9], free binary decision diagram (FBDD) [5, 10], decomposable negation normal form (DNNF, three subsets d-DNNF, DNNFT and d-DNNFT) [3, 11, 12], EPCCL theory [4, 13] and so on. Therefore, it is important to choose an appropriate target language in practical applications. Darwiche and Marquis argue that the choice of a target language must be based on two key aspects: the succinctness of the target compilation language, and the class of queries and transformations that the language supports in polytime [5]. Moreover, they propose the classic knowledge compilation map, which analyzes many existing target compilation languages according to the above aspects. On this basis, some researchers extend the knowledge compilation map [12, 14, 15]. ROBDD is one of the most tractable target languages which satisfy all of querying requirements involved in the knowledge compilation map (as far as we know, the compilation languages meeting these requirements include ROBDD, MODS, d-DNNFT and EPCCL theory [5, 12, 13]) and has been quite influential in many communities such as model checking [16], AI planning [17], abductive inference [18], termi","Knowledge compilation and theory approximation | A survey on knowledge compilation | Decomposable negation normal form | Knowledge Compilation Using Extension Rule | A knowledge compilation map | Compilation for critically constrained knowledge bases | Knowledge compilation using theory prime implicates | Graph-based algorithms for Boolean function manipulation | An introduction to binary decision diagrams | Efficient analysis and manipulation of OBDDs can be extended to FBDDs | On the tractability of counting theory models and its application to truth maintenance and belief revision | New compilation languages based on structured decomposability | Extending the knowledge compilation map: Krom, Horn, Affine and Beyond | Extending the knowledge compilation map: Closure principles | Model Checking | Conformant planning via symbolic model checking | Terminological reasoning in SHIQ with ordered binary decision diagrams | Evaluating abductive hypotheses using an EM algorithm on BDDs | The language of search | Semantical and computational aspects of Horn approximations | An Extensible SAT-solver | Lingeling, Plingeling, PicoSAT and PrecoSAT at SAT Race | Extending SAT Solvers to Cryptographic Problems | A computing procedure for quantification theory | Algorithms for propositional KB approximation | New advances in compiling CNF to decomposable negation normal form | Model counting and planning using extension rule",rejected,000
1103.3223.pdf.json,Using Soft Computer Techniques on Smart Devices for Monitoring Chronic Diseases: the CHRONIOUS case,,Chronic kidney disease and endstage renal diseasea review produced to contribute to the report the status of health in the european union: towards a healthier europe | Tele-assistance in chronic respiratory failure patients: a randomised clinical trial | Individually adaptable automatic qt detector | A real-time QRS detection algorithm. | Wavelet transforms and the ecg: a review | An introduction to support vector machines and other kernel based learning methods | Random forests | Neural Networks and Learning Machines (3rd Edition) | Learning decision tree classifiers | Bayesian network classifiers | Generating accurate rule sets without global optimization | Innovations in Bayesian Networks Theory and Applications,rejected,000
1103.3240.pdf.json,Decentralized Constraint Satisfaction,,"Distributed channel assignment and routing in multiradio multichannel multihop wireless networks | Self organization of interfering 802.11 wireless access networks | Protocols and architectures for channel assignment in wireless mesh networks | Minimum interference channel assignment in multiradio wireless mesh networks | A self-managed distributed channel selection algorithm for WLANs | Complexity analysis of a decentralised graph colouring algorithm | Local search strategies for satisfiability testing | Survey propagation: An algorithm for satisfiability | An algebraic approach to network coding | Network coding for wireless applications: A brief tutorial | XORs in the air: practical wireless network coding | Network coding-aware routing in wireless networks | An evolutionary approach to inter-session network coding | Towards a collision-free WLAN: Dynamic parameter adjustment in CSMA/E2CA | Decentralised learning MACs for collision-free access in WLANs | A computing procedure for quantification theory | A machine program for theorem-proving | ManySAT: a parallel SAT solver | How good are branching rules in DPLL | Reverend Bayes on inference engines: a distributed hierarchical approach | Random k-satisfiability problem: From an analytic solution to an efficient algorithm | On selecting a satisfying truth assignment | A probabilistic algorithm for k-SAT and constraint satisfaction problems | Rigorous location of phase transitions in hard optimization problems | The threshold for random k-SAT is 2k log 2-O(k) | The probabilistic analysis of a greedy satisfiability algorithm | Analysis of two simple heuristics on a random instance of k-SAT | Threshold values of random k-SAT from the cavity method | Gibbs states and the set of solutions of random constraint satisfaction problems | Comparing beliefs, surveys and random walks | Analytic and algorithmic solution of random satisfiability problems | Clustering of solutions in the random satisfiability problem | Circumspect descent prevails in solving random constraint satisfaction problems | Linear upper bounds for random walk on small density 3-CNFs | Invariant measures for Markov processes arising from iterated function systems  with place-dependent probabilities",rejected,000
1103.4487.pdf.json,Handwritten Digit Recognition with a Committee of Deep Neural Nets on GPUs,"Current automatic handwriting recognition algorithms are already pretty good at learning to recognize handwritten digits. More than a decade ago, Multilayer Perceptrons or MLPs (Werbos, 1974; LeCun, 1985; Rumelhart et al., 1986) were among the first classifiers tested on the now famous MNIST handwritten digit recognition benchmark. Most had few layers or few artificial neurons (units) per layer (LeCun et al., 1998), but apparently back then these were the biggest feasible MLPs, trained when CPU cores were at least 20 times slower than today. A more recent MLP with a single hidden layer of 800 units achieved 0.70% error (Simard et al., 2003). The latest substantial improvement by others occurred in 2003 (Simard et al., 2003) (error rate 0.4%). It was obtained with a convolutional neural network (CNN), using then novel elastic training image deformations. Ranzato et al. (2006, 2007) pre-trained each hidden CNN layer one by one in unsupervised fashion (this seems promising especially for small training sets), then used supervised learning to achieve 0.39% error rate. Recently we were able to significantly improve this result, obtaining an error rate of 0.35% using graphics cards (GPUs) to greatly speed up training of plain but deep MLPs (Ciresan et al., 2010). Deformations proved essential to prevent MLPs with up to 12 million free parameters from overfitting. To let the deformation process keep up with network training speed we had to port it onto the GPU as well. At some stage in the classifier design process one usually has collected a set of possible classifiers. Often one of them yields best performance. Intriguingly, however, the sets of patterns misclassified by the different classifiers do not necessarily overlap. This information could be harnessed in a committee. In the context of handwritten recognition, Chellapilla et al. (2006) already showed how a combination of various classifiers can be trained more quickly than a single classifier yielding the same err","Pattern Recognition and Machine Learning | Combining multiple classifiers for faster optical character recognition. In Document Analysis Systems VII, pages 358–367 | Deep big simple neural nets for handwritten digit recognition | Une procédure d’apprentissage pour réseau a seuil asymmetrique (a learning scheme for asymmetric threshold networks) | Gradient-based learning applied to document recognition | Efficient learning of sparse representations with an energy-based model | Unsupervised learning of invariant feature hierarchies with applications to object recognition | Learning internal representations by error propagation | Best practices for convolutional neural networks applied to visual document analysis",rejected,000
1103.4558.pdf.json,Representing First-Order Causal Theories by Logic Programs,"Propositional nonmonotonic causal logic (McCain and Turner 1997) and its generalizations became a basis for the semantics of several expressive action languages (Giunchiglia and Lifschitz 1998; Giunchiglia et al. 2004; Lifschitz and Ren 2006; Lifschitz and Ren 2007; Ren 2009). The Causal Calculator (CCalc)1 is a partial 1 http://www.cs.utexas.edu/users/tag/ccalc/ implementation of this logic that allows us to automate some kinds of reasoning and planning in action domains described in such languages. It has been used to solve several challenging commonsense reasoning problems, including problems of nontrivial size (Akman et al. 2004), to provide a group of robots with high-level reasoning (Caldiran et al. 2009), to give executable specifications of norm-governed computational societies (Artikis et al. 2009), and to automate the analysis of business processes under authorization constraints (Armando et al. 2009). An important theorem due to Norman McCain (McCain 1997, Proposition 6.7) shows how to embed a fragment of propositional causal logic into the language of logic programming under the answer set semantics (Gelfond and Lifschitz 1991). This result, reviewed below, paved the way to the development of an attractive alternative to CCalc—the software system coala (Gebser et al. 2010) that uses answer set programming (Marek and Truszczyński 1999; Niemelä 1999; Lifschitz 2008) for answering queries about actions described in causal logic. A causal theory in the sense of (McCain and Turner 1997) is a set of “causal rules” of the form F ⇐ G, where F and G are propositional formulas (the head and the body of the rule). The rule reads “F is caused if G is true.” Distinguishing between being true and having a cause turned out to be essential for the study of commonsense reasoning. The assertion “if the light is on at time 0 and you toggle the switch then the light will be off at time 1” can be written as an implication: on0 ∧ toggle → ¬on1· In causal logic, on the other",Representing the Zoo World and the Traffic World in the language of the Causal Calculator | Formal specification and automatic analysis of business processes under authorization constraints: an actionbased approach | Specifying norm-governed computational societies | Bridging the gap between high-level reasoning and low-level control | Answer sets for propositional theories | Stable models and circumscription | Symmetric splitting in the general theory of stable models | Coala: a compiler from action languages to ASP | The stable model semantics for logic programming | Classical negation in logic programs and disjunctive databases | Nonmonotonic causal theories | An action language based on causal explanation: Preliminary report | Representing synonymity in causal logic and in logic programming | System F2LP — computing answer sets of first-order formulas | Circumscription | On the logic of causal explanation | The semantics of variables in action descriptions | Translating first-order causal theories into answer set programming | Stable models and an alternative logic programming paradigm | Causal theories of action and change | Applications of circumscription to formalizing common sense knowledge | Logic programs with stable model semantics as a constraint programming paradigm | Solving the Frame Problem: A Mathematical Investigation of the Common Sense Law of Inertia,rejected,000
1103.4601.pdf.json,Doubly Robust Policy Evaluation and Learning,"We study decision making in environments where we receive feedback only for chosen actions. For example, in Internet advertising, we find only whether a user clicked Appearing in Proceedings of the 28 th International Conference on Machine Learning, Bellevue, WA, USA, 2011. Copyright 2011 by the author(s)/owner(s). on some of the presented ads, but receive no information about the ads that were not presented. In health care, we only find out success rates for patients who received the treatments, but not for the alternatives. Both of these problems are instances of contextual bandits (Auer et al., 2002; Langford & Zhang, 2008). The context refers to additional information about the user or patient. Here, we focus on the offline version: we assume access to historic data, but no ability to gather new data (Langford et al., 2008; Strehl et al., 2011). Two kinds of approaches address offline learning in contextual bandits. The first, which we call the direct method (DM), estimates the reward function from given data and uses this estimate in place of actual reward to evaluate the policy value on a set of contexts. The second kind, called inverse propensity score (IPS) (Horvitz & Thompson, 1952), uses importance weighting to correct for the incorrect proportions of actions in the historic data. The first approach requires an accurate model of rewards, whereas the second approach requires an accurate model of the past policy. In general, it might be difficult to accurately model rewards, so the first assumption can be too restrictive. On the other hand, it is usually possible to model the past policy quite well. However, the second kind of approach often suffers from large variance especially when the past policy differs significantly from the policy being evaluated. In this paper, we propose to use the technique of doubly robust (DR) estimation to overcome problems with the two existing approaches. Doubly robust (or doubly protected) estimation (Cassel et al., 1976; Rob","The nonstochastic multiarmed bandit problem | The offset tree for learning with partial labels | Multiclass classification with filter-trees | Some results on generalized difference estimation and generalized regression estimation for finite populations | Evaluating online ad campaigns in a pipeline: causal models at scale | Dataset shift in machine learning. In Covariate Shift and Local Learning by Distribution Matching, pp. 131–160 | The WEKA data mining software: An update | Better algorithms for benign bandits | A generalization of sampling without replacement from a finite universe | Demystifying double robustness: a comparison of alternative strategies for estimating a population mean from incomplete data | More bang for their bucks: assessing new features for online advertisers | The epoch-greedy algorithm for contextual multi-armed bandits | Exploration scavenging | Stratification and weighting via the propensity score in estimation of causal treatment effects: A comparative study | Direct loss minimization for structured prediction | Semiparametric efficiency in multivariate regression models with missing data | Estimation of regression coefficients when some regressors are not always observed | Learning from logged implicit exploration data",rejected,000
1103.4778.pdf.json,A Formal and Computational Properties of the Confidence Boost of Association Rules,"As the now well-known task of association rule mining was defined, the problems faced were twofold. First, the quantity of candidate itemsets for antecedent X and consequent Y of association rules X → Y grows exponentially with the often already large universe of items. The introduction of a support threshold parameter was a key advance that allowed for the design of efficient frequent set miners and for the computation of association rules in large datasets: there, exploration is limited to those itemsets that appear “often enough” as subsets of the transactions, that is, their relative frequency exceeds a certain ratio of the transactions; see [Agrawal et al. 1996] and the references there. Then, the second problem is that, often, the set of rules provided as output is too large, specially if we consider that its purpose is to be read, and understood, by a human. We consider that this problem warrants further research, and we attempt at providing here yet one more approach to it. Address at the time of submission: Departmento de Matemáticas, Estad́ıstica y Computación, Av Los Castros s/n, Santander 39005, Spain (joseluis.balcazar@unican.es). This work has been partially supported by project TIN2007-66523 (FORMALISM) of Programa Nacional de Investigación, Ministerio de Ciencia e Innovación (MICINN), Spain, and by the Pascal-2 Network of the European Union. Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior specific permission and/or a fee","A new approach to online generation of association rules | Fast discovery of association rules | Yet a faster algorithm for building the Hasse diagram of a concept lattice | Two measures of objective novelty in association rule mining | Closure-based confidence boost in association rules | Objective novelty of association rules: Measuring the confidence boost | Redundancy, deduction schemes, and minimum-size bases for association rules | Parameter-free association rule mining with yacaree | Closed-set-based discovery of representative association rules revisited | Mining educational data for patterns with negations and high confidence boost | Filtering association rules with negations on the basis of their confidence boost | Constraint-based rule mining in large, dense databases | Free-sets: A condensed representation of boolean data for the approximation of frequency queries | Neogene of the old world database of fossil mammals (NOW) | Mini: Mining informative non-redundant itemsets | Interestingness measures for data mining: A survey | Familles minimales d’implications informatives résultant d’un tableau de données binaires | Pruning redundant association rules using maximum entropy principle | Actes de Extraction et gestion des connaissances (EGC) | Fast discovery of representative association rules | Representative association rules | Representative association rules and minimum condition maximum consequence association rules | Closed set based discovery of representative association rules | Concise representations of association rules | On selecting interestingness measures for association rules: User oriented description and multiple criteria decision aid | Pruning and summarizing the discovered associations | Implications partielles dans un contexte | Discovering predictive association rules | Small is beautiful: discovering the minimal set of unexpected patterns | Generating a condensed representation for association rules | The representative basis for association rules | Discovery, analysis, and presentation of strong rules | Finding association rules that trade support optimally against confidence | Interestingness and pruning of mined patterns | Beyond market baskets: Generalizing association rules to dependence rules | Autonomous discovery of reliable exception rules | Discovery of surprising exception rules based on intensity of implication | Selecting the right objective measure for association analysis | Pruning and grouping discovered association rules | Discovering significant patterns | Data Mining: Practical Machine Learning Tools and Techniques (2ed) | Mining non-redundant association rules | Efficient algorithms for mining closed itemsets and their lattice structure | Principles of Data Mining and Knowledge Discovery, Second European Symposium, PKDD ’98, Nantes, France, September 23-26, 1998, Proceedings",rejected,000
1103.5034.pdf.json,On Understanding and Machine Understanding,,,rejected,000
1104.0128.pdf.json,Towards an automated query modification assistant,"Users of search engines often enter a number of queries in succession before they find everything they need or before they are convinced that the collection in which they search does not contain answers to their information needs. Query suggestions can help users in the formulation of their queries (e.g. [7, 17]). In addition to query suggestions, users can potentially be helped by higher level feedback on their search strategy. Such feedback can warn users earlier on when the current line of search is not going to be effective and help them to formulate a more effective strategy. For instance, suppose a users is looking for pictures of impressionist paintings. She successively enters the queries Monet and impressionism, but none of the search results are of her liking. Query suggestions may include the names of contemporaries of Monet and the titles of paintings by Monet. This can be useful suggestions, but do not tell the user why her own modified query (impressionism) was unsuccessful. 2. The suggested search strategies can be reused for comparable information needs (e.g. finding cubist paintings), preventing the user from making the same ‘mistake’ twice. In this paper we explore the potential of an automatic search assistant that provides feedback on the ways users modify their queries. We present a methodology to use search interactions of previous users collected in search logs to determine which types of query modification have and have not been effective in the past. These observations can form the basis for the assistant’s feedback. In addition, we identify opportunities where the assistant may improve the search: query modification strategies that are commonly used, but do not usually lead to results that users find relevant. We analyze query modifications in two ways: by a traditional term-based approach (e.g. [5, 8, 10, 12, 13, 16, 18, 25]) and by a semantic approach that we developed for this purpose [11]. Both approaches are applied to query logs of th","Linked data the story so far | From ‘dango’ to ‘japanese cakes’: Query reformulation models and patterns | RDF vocabulary description language 1.0 | Context-aware query suggestion by mining click-through and session data | Hyponymy extraction and web search behavior analysis based on query reformulation | WordNet: an electronic lexical database | Combining evidence for automatic web session identification | Semantic search log analysis: A methodology and a study on professional image search | Analyzing and evaluating query reformulation strategies in web search logs | Patterns of query reformulation during web searching | The effect of specialized multimedia collections on web searching | Query word deletion prediction | Image querying by image professionals | A comparison of query and term suggestion features for interactive searching | Özmutlu. Markovian analysis for automatic new topic identification in search engine transaction logs | An algorithm for suffix stripping | Analysis of multiple query reformulations on the web: The interactive information retrieval context | The art and architecture thesaurus (AAT) | The thesaurus of geographical names (TGN) | RDF/OWL representation of WordNet, W3C working draft 19 june | Integrating lexical units, synsets and ontology in the cornetto database | Data mining of search engine logs",rejected,000
1104.0843.pdf.json,Phase Transitions in Knowledge Compilation: an Experimental Study,"Phase transitions, as a kind of well-known phenomenon in artificial intelligence, have attracted a great mount of attention since the paper [1]. They claimed that all NP-complete problems have a critical point that separates overconstrained and underconstrained regions, and soluble-to-insoluble phase transition occurs at this point. Successive studies have shown that phase transitions widely exist in complex combinational (optimization) problems [2-8]. Some representative problems are random k-SAT, whose phase transition point is measured by the ratio of the number of clauses to that of variables, and random Constraint Satisfaction Problems (CSPs), where in the RB model [2] an exact transition point was proved whose instances are hard to solve. Furthermore, recent investigations on more complex problems have demonstrated that there are phase transitions in QBF [5,6] and planning [7] which are PSPACE-complete, and even in problems that are EXPSPACE-complete [8]. In addition, some real-world problems, such as TSP [9] and manipulation problem [10], have been shown to have phase transition phenomena. In fact, it is worth mentioning that soluble-to-insoluble phase transition studied most widely is only one an example Bailey et al. [11] have addressed phase transitions in #SAT, of which the decision problem is PP-complete. As second example phase transitions of backtrack-free instances have been studied [12]. The phase transitions mentioned above are always accompanied with the transitions of CPU runtimes. Namely, algorithms will suffer an easy-hard-easy pattern when solving those problems. Instances around the soluble-to-insoluble transition points are hard to solve by both systematic search algorithms and local search algorithms with other instances easy to solve. However, we will show that easy-hard-easy patterns are not only expressed in terms of the time, but also in terms of the space. That is phase transitions in knowledge compilation. Knowledge compilation [13] is","Where the Really Hard Problems Are | Exact Phase Transitions in Random Constraint Satisfaction Problems | Rigorous location of phase transitions in hard optimization problems | Phase Transition Behavior: from Decision to Optimization, In: proc | Beyond NP: the QSAT phase transition | New Results on the Phase Transition for Random Quantified Boolean Formulas | Phase Transitions in Classical Planning: An Experimental Study | Phase Transitions of EXPSPACE-Complete Problems | The TSP Phase Transition | Where Are the Really Hard Manipulation Problems? The Phase Transition in Manipulating the Veto Rule | Phase Transitions of PP-Complete Satisfiability Problems | Exact phase transition of backtrack-free search with implications on the power of greedy algorithms | A survey on knowledge compilation | Constraint and Variable Ordering Heuristics for Compiling Configuration Problems | Knowledge Compilation and Theory Approximation | A Compiler for Deterministic, Decomposable Negation Normal Form | Consistency restoration and explanations in dynamic CSPs Application to configuration | AND/OR Multi-Valued Decision Diagrams (AOMDDs) for Graphical Models | A Knowledge Compilation Map | Hard and Easy Distributions of SAT Problems | Towards Industrial-Like Random SAT Instances.In | The Good Old Davis-Putnam Procedure Helps Counting Models | Counting Models Using Connected Components | proc | Eliminating Interchangeable Values in Constraint Satisfaction Problems",rejected,000
1104.1677.pdf.json,Automatic Vehicle Checking Agent (VCA),,"Maybury(editor), Intelligent Multimedia Interfaces | Designing Autonomous Agents | Artificial life meets entertainment: Life like autonomous agents | a multi-agent approach to self-organizing vision systems | An agent-based architecture in knowledge discovery and data mining | Multiagent based approach for information retrieval in the WWW | An architecture for information retrieval agents | Agents as mediators in electronic commerce",rejected,000
1104.1678.pdf.json,"A PROPOSED DECISION SUPPORT SYSTEM/EXPERT SYSTEM FOR GUIDING FRESH STUDENTS IN SELECTING A FACULTY IN GOMAL UNIVERSITY, PAKISTAN",,"Computational Intelligence for Decision Support, 1999, University of Nebraska, Omaha | A proposed expert system for selecting exploratory factor analysis procedures | Artificial Intelligence: A Modern Approach, Prentice Hall, Second Edition",rejected,000
1104.3250.pdf.json,Adding noise to the input of a model trained with a regularized objective,"Regularization is a well studied problem in the context of neural networks. It is usually used to improve the generalization performance when the number of input samples is relatively small or heavily contaminated with noise. The regularization of a parametric model can be achieved in different manners some of which are early stopping (Morgan and Bourlard, 1990), weight decay or output smoothing, and are used to avoid overfitting during the training of the considered model. From a Bayesian point of view, many regularization techniques correspond to imposing certain prior distributions on model parameters (Krogh and Hertz, 1991). In this paper we propose a novel approach to achieve regularization that combines noise in the input and explicit output smoothing by regularizing the L2-norm of the Jacobian’s mapping function with respect to the input. Bishop (1995) has proved that the ar X iv :1 10 4. 32 50 v1 [ cs .A I] 1 6 A pr 2 two approaches are essentially equivalent under some assumptions using a Taylor approximation up to the second order of the noisy objective function. Using his theoretical analysis, we derive the approximation of our cost function in the weak noise limit and show the advantage of our technique from the theoretical and empirical point of view. In particular, we show that we achieve a better smoothing of the output of the considered model with a little computational overhead.",The effects of adding noise during backpropagation training on a generalization performance | Training with noise is equivalent to Tikhonov regularization | Calculation of the smoothing spline with weighted roughness measure | Why does unsupervised pre-training help deep learning | Deep sparse rectifier neural networks. Deep Learning and Unsupervised Feature Learning Workshop — NIPS ’10 | Nonparametric Regression and Generalized Linear Models | A simple weight decay can improve generalization | Gradient-based learning applied to document recognition | Generalization and parameter estimation in feedforward | Rectified linear units improve restricted boltzmann machines,rejected,000
1104.4053.pdf.json,On the evolution of the instance level of DL-Lite knowledge bases,"Description Logics (DLs) [3] are logics for expressing knowledge bases (KBs) constituted by two components, namely, the TBox, asserting general properties of concepts and roles (binary relations), and the ABox, which is a set of assertions about individuals that are instances of concepts and roles. It is widely accepted that such logics are well-suited for expressing ontologies, with the TBox capturing the intensional knowledge about the domain of interest, and the ABox expressing the knowledge about the instance level of the predicates defined in the TBox. Following this idea, several Knowledge Representation Systems, called DL systems, have been recently built, providing methods and tools for managing ontologies expressed in DLs 1. Notice that numerous DLs have been studied in the last decades, with the goal of analyzing the impact of the expressive power of the DL language to the complexity of reasoning. Consequently, each DL system is tailored towards managing KB expressed in a specific DL. By referring to the so-called functional view of knowledge representation [13], DL systems should be able to perform two kinds of operations, called ASK and TELL. ASK operations, such as subsumption checking, or query answering, are 1 http://www.cs.man.ac.uk/ sattler/reasoners.html used to extract information from the KB, whereas TELL operations aim at changing the KB according to new knowledge acquired over the domain. In other words, TELL operations should be able to cope with the evolution of the KB. There are two types of evolution operators, corresponding to inserting, and deleting chunks of knowledge, respectively. In the case of insertion, the aim is to incorporate new knowledge into the KB, and the corresponding operator should be defined in such a way to compute a consistent KB that supports the new knowledge. In the case of deletion, the aim is to come up with a consistent KB where the retracted knowledge is not valid. In both cases, the crucial aspect to take into ","Consistent query answers in inconsistent databases | The DL-Lite family and relations | The Description Logic Handbook: Theory, Implementation and Applications | Tractable reasoning and efficient query answering in description logics: The DL-Lite family | Path-based identification constraints in description logics | Evolution of DL-Lite knowledge bases | On instance-level update and erasure in description logic ontologies | On the semantics of updates in databases | Ontology change: Classification and survey | Reasoning about action I: A possible worlds approach | On the difference between updating a knowledge base and revising it | The INFOMIX system for advanced integration of incomplete and inconsistent data | Foundations of a functional approach to knowledge representation | Updating description logic ABoxes | A new approach to knowledge base revision in DL-Lite | Updating Logical Databases",rejected,000
1104.4153.pdf.json,Learning invariant features through local space contraction,"A recent topic of interest1 in the machine learning community is the development of algorithms for unsupervised learning of a useful representation. This automatic discovery and extraction of features is often used in building a deep hierarchy of features, within the contexts of supervised, semi-supervised, or unsupervised modeling. See Bengio (2009) for a recent review of Deep Learning algorithms. Most of these methods exploit as basic building block algorithms for learning one level of feature extraction: the representation learned at one level is used as input for learning the next level, etc. The objective is that these representations become better as depth is increased, but what defines a good representation? It is fairly well understood what PCA or ICA do, but much 1see NIPS’2010 Workshop on Deep Learning and Unsupervised Feature Learning ar X iv :1 10 4. 41 53 v1 [ cs .A I] 2 1 A remains to be done to understand the characteristics and theoretical advantages of the representations learned by a Restricted Boltzmann Machine Hinton et al. (2006), an auto-encoder Bengio et al. (2007), sparse coding Olshausen and Field (1997); Ranzato et al. (2007); Kavukcuoglu et al. (2009); Zeiler et al. (2010), or semi-supervised embedding Weston et al. (2008). All of these produce a non-linear representation which, unlike that of PCA or ICA, can be stacked (composed) to yield deeper levels of representation. It has also been observed empirically Lee et al. (2009) that the deeper levels often capture more abstract features (such as parts of objects) defined in terms of less abstract ones (such as sub-parts of objects or low-level visual features like edges), and that these features are generally more invariant Goodfellow et al. (2009) to changes in the known factors of variation in the data (such as geometric transformations in the case of images). A simple approach, used here, to empirically verify that the learned representations are useful, is to use them to initialize a cl",Neural networks and principal component analysis: Learning from examples without local minima | Learning deep architectures for AI | Greedy layerwise training of deep networks | Training with noise is equivalent to Tikhonov regularization | Measuring invariances in deep networks | A fast learning algorithm for deep belief nets | Estimation of non-normalized statistical models using score matching | Nonlinear autoassociation is not equivalent to PCA | What is the best multi-stage architecture for object recognition? In Proc | Fast inference in sparse coding algorithms with applications to object recognition | Learning invariant features through topographic filter maps | Regularized estimation of image statistics by score matching | Learning multiple layers of features from tiny images | An empirical evaluation of deep architectures on problems with many factors of variation | Sparse deep belief net model for visual area V2 | Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations | Sparse coding with an overcomplete basis set: a strategy employed by V1 | Efficient learning of sparse representations with an energy-based model | Learning representations by back-propagating errors | Extracting and composing robust features with denoising autoencoders | Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion | Deep learning via semisupervised embedding | Deconvolutional networks,rejected,000
1104.4290.pdf.json,,"The study of arguments as abstract entities and their interaction as introduced by Dung [12] has become one of the most active research branches within Artificial Intelligence and Reasoning, see, e.g., [3, 6, 24]. Argumentation handles possible conflicts between arguments in form of attacks. The arguments may either originate from a dialogue between several agents or from the pieces of information at the disposal of a single agent, this information may even contain contradictions. A main issue for any argumentation system is the selection of acceptable sets of arguments, where an acceptable set of arguments must be in some sense coherent and be able to defend itself against all attacking arguments. Abstract argumentation provides suitable concepts and formalisms to study, represent, and process various reasoning problems most prominently in defeasible reasoning (see, e.g., [23], [8]) and agent interaction (see, e.g., [22]). Extending Dung’s concept, Bench-Capon [4] introduced value-based argumentation systems that allow to compare arguments with respect to their relative strength such that an argument cannot successfully attack another argument that is considered of a higher rank. The ranking is specified by the combination of an assignment of values to arguments and an ordering of the values; the latter is called an audience [5]. As laid out by BenchCapon, the role of arguments in this setting is to persuade rather than to prove, demonstrate or refute. Whether an argument can be accepted with respect to all possible or at least one audience allows to formalize the notions of objective acceptance and subjective acceptance, respectively. ∗Ordyniak and Szeider’s research was supported by the European Research Council, grant reference 239962. Kim’s research was partially supported by the EPSRC, grant reference EP/E034985/1. †A preliminary and shortened version of this paper appeared in COMMA 2010. An important limitation for using value-based argumentation systems in r","Digraphs: Theory, Algorithms, Applications | Semantics of abstract argument systems | Argumentation in artificial intelligence | Persuasion in practical argument using value-based argumentation frameworks | Audiences in argumentation frameworks | Elements of Argumentation | A tourist guide through treewidth | An abstract, argumentation-theoretic approach to default reasoning | Recognizability and second-order definability for sets of finite graphs | Recursive conditioning | Bucket elimination: a unifying framework for reasoning | On the acceptability of arguments and its fundamental role in nonmonotonic reasoning, logic programming and n-person games | Computational properties of argument systems satisfying graph-theoretic constraints | Tractability in value-based argumentation | Complexity in value-based argument systems | Towards fixed-parameter tractable algorithms for argumentation | Parameterized Complexity Theory, volume XIV of Texts in Theoretical Computer Science. An EATCS Series | A sufficient condition for backtrack-bounded search | Computers and Intractability | Bounded treewidth as a key to tractability of knowledge representation and reasoning | Algorithms and complexity results for persuasive argumentation | Properties and complexity of some formal interagent dialogues | How to reason defeasibly",rejected,000
1104.4910.pdf.json,Hybrid Tractable Classes of Binary Quantied Constraint Sa ,,,rejected,000
1104.4966.pdf.json,Combining Ontology Development Methodologies and Semantic Web Platforms for E-government Domain Ontology Development,"In the past ten years, e-government has been a subject of interest of governments around the world. Governments worldwide are expecting e-government to improve their internal processes and provide Internet and ICT-based service delivery to citizens, businesses and organizations. This requires the design, implementation and launch of web-based systems that present government structures and services online, provide mechanisms for online interaction of government with citizens, and facilitate online citizen participation to government processes and decision making. These mandates of e-government can only be achieved if a large range of government’s services and processes are delivered seamlessly to citizens and stakeholders through a single web portal [1], [2]. This raises the issue of developing heterogonous web-based e-government systems of government departments and agencies that can interoperate and be easily integrated. Although the state-of-the-art software engineering techniques including objectoriented and agile methods provide appropriate solutions to the aforementioned engineering problems of services integration and interoperability in e-government [1], [3], [4], it has been demonstrated that they have certain limitations [3], [4], [5], [6]. Therefore, during the past six years, Semantic Web technologies have emerged as promising solutions to these problems [3], [4], [7], [8], [16]. Semantic-based e-government consists of describing existing entities, concepts, processes, laws and regulations governing a government service domain, into a conceptual model namely domain ontology. This domain ontology is initially represented in a human readable form. Then, to make it processable by computers, ontology editing and implementing platforms should be used by egovernment developers to develop the domain ontology in Semantic Web machine processable syntaxes such as XML, RDF, and OWL. In light of the above, practicing semantic development in e-government could be chal","XML Schema Design and Management for E-government Data Interoperability | Integrated Service Modelling for Online One-Stop Government | Achieving Interoperability in E-government Services with two Modes of Semantic Bridging: SRS and SWRL | A Methodology Framework for E-government Service Delivery Integration,  | Practical Artificial Intelligence Programming with Java,  | Efficient RDF Storage and Retrieval in Jena2 | Configuring E-government Services Using Ontologies | An Ontology for E-government Knowledge Modelling and Interoperability | Using Knowledge Management and Business Process in E-government | Multilevel Life-event Abstraction Framework for E-government Service Integration | Semantic Service Oriented Architectures for E-government Platforms,  | Research Knowledge Sharing of E-government Based on Automatic Ontology Mapping,  | A Conceptual Model for Semantically-Based Egovernment Portal,  | Towards Building a Semantic Grid for E-government Applications,  | Barthes, “Towards a Semantic Interoperability in an E-government Application,  | Knowledge-based Platform for Egovernment Agents: A Web-based Solution Using Semantic Technologies | Towards a Methodology for Building Ontologies | The Semantic Web | Building Web Service Ontologies,  | Debugging and Repair of OWL Ontologies,  | A Comparative Study Ontology Building Tools for Semantic Web Applications | Comparing Ontology Development Tools Based on an Online Survey | The Protégé OWL Plugin: An Open Development Environment for Semantic Web Applications | Toward Principles for the Design of Ontologies used for Knowledge Sharing | Overview of Methodologies for Building Ontologies,  | Overview of Approach, Methodologies, Standards, and Tools for Ontologies | Ontologies for Software Engineering and Software Technology,  | Investigating E-government Knowledge Base ontology Supporting Development Project Monitoring in Sub Saharan Africa,  | Evaluation of Ontologies and DL Reasoners | A Semantically-Rich, Graphical Environment for Collaborative Ontology Development in Agentcities,  | A Practical Guide to Building OWL Ontologies Using the Protégé-OWL Plugin and CO-ODE Tools Edition 1.0 | Constructing Ontologies in OWL Using Protégé-2000,  | Jena Tutorial",rejected,000
1104.4993.pdf.json,,,"On the power of k-consistency | Affine systems of equations and counting infinitary logic | Clause-learning algorithms with many restarts and bounded-width resolution | Constraint propagation as a proof system | Decidable relationships between consistency notions for constraint satisfaction problems | Constraint satisfaction problems of bounded width | Theoretical analysis of singleton arc consistency and its extensions | Peek arc consistency | Results on the algebraic approach to the csp | Combinatorial problems raised from 2-semilattices | Optimal implementation of conjunctive queries in relational data bases | Smart) look-ahead arc consistency and the pursuit of CSP tractability | Linear datalog and bounded path duality of relational structures | Majority constraints have bounded pathwidth duality | Closure functions and width 1 problems | Some practicable filtering techniques for the constraint satisfaction problem | On 2-sat and renamable horn | The computational structure of monotone monadic SNP and constraint satisfaction: A study through Datalog and group theory | Tractability and learnability arising from algebras with few subpowers | Constraints, consistency and closure | Universal algebra and hardness results for constraint satisfaction problems | Bounded width problems and algebras | Clones in Universal Algebra, volume 99 of Seminaires de Mathematiques Superieures",rejected,000
1104.5069.pdf.json,Synthesizing Robust Plans under Incomplete Domain Models,"In the past several years, significant strides have been made in scaling up plan synthesis techniques. We now have technology to routinely generate plans with hundreds of actions. All this work, however, makes a crucial assumption–that a complete model of the domain is specified in advance. While there are domains where knowledge-engineering such detailed models is necessary and feasible (e.g., mission planning domains in NASA and factory-floor planning), it is increasingly recognized (c.f. (Hoffmann, Weber, and Kraft 2010; Kambhampati 2007)) that there are also many scenarios where insistence on correct and complete models renders the current planning technology unusable. What we need to handle such cases is a planning technology that can get by with partially specified domain models, and yet generate plans that are “robust” in the sense that they are likely to execute successfully in the real world. This paper addresses the problem of formalizing the notion of plan robustness with respect to an incomplete domain model, and connects the problem of generating a robust plan under such model to conformant probabilistic planning (Kushmerick, Hanks, and Weld 1995; Hyafil and Bacchus 2003; Bryce, Kambhampati, and Smith 2006; Domshlak and Hoffmann 2007). Following Garland & Lesh (2002), we shall assume that although the domain modelers cannot provide complete models, often they are able to provide annotations on the partial model circumscribing the places where it is incomplete. In our framework, these annotations consist of allowing actions to have possible preconditions and effects (in addition to the standard necessary preconditions and effects). As an example, consider a variation of the Gripper domain, a well-known planning benchmark domain. The robot has one gripper that can be used to pick up balls, which are of two types light and heavy, from one room and move them to another room. The modeler suspects that the gripper may have an internal problem, but this cannot",Sequential monte carlo in probabilistic planning reachability heuristics | Probabilistic planning via heuristic forward search and weighted model counting | Exploration of the robustness of plans | Plan evaluation with incomplete action descriptions | Conformant probabilistic planning via CSPs | Fault tolerant planning: Toward probabilistic uncertainty models in symbolic non-deterministic planning | An algorithm for probabilistic planning | Reachability heuristics for planning in incomplete domains. In ICAPS’09 Workshop on Heuristics for Domain Independent Planning,rejected,000
1104.5566.pdf.json,Limits of Preprocessing∗,"Many important computational problems that arise in various areas of AI are intractable. Nevertheless, AI research was very successful in developing and implementing heuristic solvers that work well on realworld instances. An important component of virtually every solver is a powerful polynomial-time preprocessing procedure that reduces the problem input. For instance, preprocessing techniques for the propositional satisfiability problem are based on Boolean Constraint Propagation (see, e.g., Eén and Biere, 2005), CSP solvers make use of various local consistency algorithms that filter the domains of variables (see, e.g., Bessière, 2006); similar preprocessing methods are used by solvers for Nonmonotonic and Bayesian reasoning problems (see, e.g., Gebser et al., 2008, Bolt and van der Gaag, 2006, respectively). Until recently, no provable performance guarantees for polynomial-time preprocessing methods have been obtained, and so preprocessing was only subject of empirical studies. A possible reason for the lack of theoretical results is a certain inadequacy of the P vs NP framework for such an analysis: if we could reduce in polynomial time an instance of an NP-hard problem just by one bit, then we can solve the entire problem in polynomial time by repeating the reduction step a polynomial number of times, and P = NP follows. With the advent of parameterized complexity (Downey, Fellows, and Stege, 1999), a new theoretical framework became available that provides suitable tools to analyze the power of preprocessing. Parameterized complexity considers a problem in a two-dimensional setting, where in addition to the input size n, a problem parameter k is taken into consideration. This parameter can encode a structural aspect of the problem instance. A problem is called fixed-parameter tractable (FPT) if it can be solved in time f(k)p(n) where f is a function of the parameter k and p is a polynomial of the input size n. Thus, for FPT problems, the combinatorial explos","The complexity of global constraints | The parameterized complexity of global constraints | Range and roots: Two common patterns for specifying and propagating counting and occurrence constraints. Artificial Intelligence 173(11):1054–1078 | and Dechter | M | A | and van der Gaag | F | S | G | and Pearl | M | and Biere | F | and Szeider | and Santhanam | and Szeider | Advanced preprocessing for answer set solving | and Lifschitz | C | Fixed-parameter complexity in AI and nonmonotonic reasoning | and Niedermeier | and Truszczyński | and Truszczyński | Detecting backdoor sets with respect to Horn and binary clauses | C | and Szeider | On the connections between backdoors, restarts, and heavy-tailedness in combinatorial search",rejected,000
1104.5601.pdf.json,Mean-Variance Optimization in Markov Decision Processes,,Constrained Markov decision processes | Bandit processes and dynamic allocation indices | Robust dynamic programming | Robust Markov decision processes with uncertain transition matrices | On the approximability of trade-offs and optimal access | Dynamic coherent risk measures | Reinforcement learning: An introduction | Approximation of dynamic programs – II,rejected,000
1105.0650.pdf.json,,"A fundamental reasoning task for propositional logic is to compute models of propositional formulas or determine that no models exist. Programs developed for this task are commonly called model generators or satisfiability (SAT) solvers. In the paper we show that transition systems introduced by Nieuwenhuis et al. (2006) to model and analyze SAT solvers can be adapted for the analysis and comparison of solvers developed for other propositional formalisms. The two formalisms we focus on are logic programming with the answer-set semantics and the logic PC(ID). Davis-Putnam-Logemann-Loveland (DPLL) procedure is a well-known method that exhaustively explores interpretations to generate models of a propositional formula. Most modern SAT solvers are based on variations of the DPLL procedure. Usually these variations are specified by pseudocode. Nieuwenhuis et al. (2006) proposed an alternative approach based on the notion of a transition system that describes “states of computation” and allowed transitions between them. In this way, it defines a directed graph such that every execution of the DPLL procedure corresponds to a path in the graph. This abstract way of presenting DPLL-based algorithms simplifies the analysis of their correctness and facilitates studies of their properties — instead of reasoning about pseudocode constructs, we reason about properties of a graph. For instance, by proving that the graph corresponding to a DPLL-based algorithm is finite and acyclic we show that the algorithm always terminates. Answer-set programming (ASP) (Marek and Truszczyński 1999; Niemelä 1999) is a declarative programming formalism based on the answer-set semantics of logic programs (Gelfond and Lifschitz 1988). Generating answer sets of propositional programs is the key step in computation with ASP. The logic FO(ID), introduced by Denecker (2000) is another formalism for declarative programming and knowledge representation. As in the case of ASP, most automated reasoning ta","Towards understanding and harnessing | The relative efficiency of propositional proof systems | A machine program for theorem proving | A deductive system for non-monotonic reasoning | Weight constraints as nested expressions | Conflict-driven answer set solving | Tableau calculi for answer set programming | The stable model semantics for logic programming | On the relation among answer set solvers | On the relation between answer set and SAT procedures (or, between smodels and cmodels) | A model-theoretic counterpart of loop formulas | Disjunctive stable models: Unfounded sets, fixpoint semantics, and computation | Sat-based answer set programming | Abstract answer set solvers with backjumping and learning | Nested expressions in logic programs | ASSAT: Computing answer sets of a logic program by SAT solvers | Stable models and an alternative logic programming | Model generation for ID-logic | On the relation between ID-logic and answer set programming | SAT(ID): Satisfiability of propositional logic extended with inductive definitions | Logic programs with stable model semantics as a constraint programming paradigm | Extending the Smodels system with cardinality and weight constraints | Solving SAT and SAT modulo theories: From an abstract Davis-Putnam-Logemann-Loveland procedure to DPLL(T) | Modular equivalence for normal logic programs | The well-founded semantics for general logic programs",rejected,000
1105.0707.pdf.json,Parameterized Complexity of Problems in Coalitional Resource Games,,Complexity of constructing solutions in the core based on synergies among coalitions | Parameterized complexity for the skeptic | Parameterized Complexity Theory (Texts in Theoretical Computer Science | D | Easy and hard coalition resource game formation problems: a parameterized complexity analysis | An Introduction to Multiagent Systems | On the computational complexity of qualitative coalitional games | On the computational complexity of coalitional resource games,rejected,000
1105.0974.pdf.json,GANC: Greedy Agglomerative Normalized Cut,"Clustering or partitioning of nodes in networks or graphs is an important task that has many applications in a diverse range of fields. It has been used for many years to study social networks [1] and continues to be employed in the field of sociology to explore social interactions. More recently it has been employed in the study of biochemical networks [2, 3], biological neural networks [4, 5], and transport and communication networks. There are three components to the clustering task: (i) choosing the number of clusters; (ii) selecting a criterion that measures the merit of each candidate cluster allocation; and (iii) identifying an algorithm that searches for the optimal clustering. Some performance criteria can be used both to select the number of clusters and choose the clustering, e.g., modularity [6] or information-theoretic criteria based on the minimum description length [7]. There is no universally-accepted performance criterion and indeed the most appropriate criterion can vary depending on the application domain and the goal of the clustering. Modularity, for example, focuses on network structure and places primary value on direct 1Corresponding author. Tel.: +1 514 677 0056; fax: +1 514 398 4470; E-mail: seyed.s.tabatabaei@mail.mcgill.ca. 2E-mail: mark.coates@mcgill.ca 3E-mail: michael.rabbat@mcgill.ca connections between nodes. On the other hand, clustering algorithms based on Markov random walks [7, 8] also value indirect connections and network flow. In this paper we select the normalized cut criterion [9], which simultaneously encourages intra-cluster similarity while penalizing inter-cluster similarities. Methods based on this criterion have been employed successfully in a wide range of applications [5, 8–12]. The normalized cut criterion is related to the conductance of the underlying graph [13]. Furthermore an implicit duality between normalized cut and normalized association exists; the former encourages clusters that are less connected to each ",Social network analysis: Methods and applications | Functional cartography of complex metabolic networks | Efficient algorithms for accurate hierarchical clustering of huge datasets: tackling the entire protein space | Revealing modular architecture of human brain structural networks by using cortical thickness from MRI | Spectral Clustering and Label Fusion For 3D Tissue Classification: Sensitivity and Consistency Analysis | Community structure in social and biological networks | Maps of random walks on complex networks reveal community structure | Diffusion maps and coarse-graining: a unified framework for dimensionality reduction | Normalized cuts and image segmentation | Spectral grouping using the Nyström method | Weighted graph cuts without eigenvectors: a multilevel approach | Network community discovery: solving modularity clustering via normalized cut | Approximate counting | Algorithms for partitioning of graphs and computer logic based on eigenvectors of connection matrices | Partitioning sparse matrices with eigenvectors of graphs | A multilevel algorithm for partitioning graphs | A fast and high quality multilevel scheme for partitioning irregular graphs | A random walks view of spectral segmentation | On spectral clustering: Analysis and an algorithm | Fast approximate spectral clustering | Fast multiscale image segmentation | A min-max cut algorithm for graph partitioning and data clustering | Segmentation and boundary detection using multiscale intensity measurements | An integrated segmentation and classification approach applied to multiple sclerosis analysis | Efficient multilevel brain tumor segmentation with integrated bayesian model classification | An examination of procedures for determining the number of clusters in a data set | On clustering validation techniques | A dendrite method for cluster analysis | A general statistical framework for assessing categorical clustering in free recall | Measuring the power of hierarchical cluster analysis | Cubic Clustering Criterion | Estimating the number of clusters in a data set via the gap statistic | Graph clustering using distance-k cliques | Interpreting and assessing the results of cluster analyses | A criterion for determining the number of groups in a data set using sum-of-squares clustering | Automatic cluster stopping with criterion functions and the gap statistic | A test for clusters | Estimating the dimension of a model | A new look at the statistical model identification | Pattern clustering by multivariate mixture analysis | X-means: Extending K-means with Effcient Estimation of the Number of Clusters | Uncovering latent structure in valued graphs: a variational approach | Bayesian methods for graph clustering | Bayesian methods for graph clustering | Stochastic image segmentation by typical cuts | On clustering using random walks | Spectral methods for automatic multiscale data clustering | Self-tuning spectral clustering | A stability based method for discovering structure in clustered data | Stability-based validation of clustering solutions | A sober look at clustering stability | Cluster stability scores for microarray data in cancer studies | Fitting a graph to vector data | Influence of graph construction on graph-based clustering measures | Fast unfolding of communities in large networks | Finding community structure in very large networks | C++ Standard Template Library | Performance of modularity maximization in practical contexts | Benchmarks for testing community detection algorithms on directed and weighted graphs with overlapping communities | Algorithms for graph partitioning on the planted partition model | Grooming | Comparing classifications: an evaluation of several coefficients of partition agreement | An information flow model for conflict and fission in small groups | Mapping the structural core of human cerebral cortex | The structure of scientific collaboration networks | The dynamics of viral marketing | Graphs over time: densification laws | A connectivity based clustering algorithm with application to VLSI circuit partitioning | Clustering by weighted cuts in directed graphs,rejected,000
1105.1247.pdf.json,Machine-Part cell formation through visual decipherable clustering of Self Organizing Map,"Cell formation has been emerged as a production strategy in implementing cellular manufacturing and consists of decomposing the shop in distinct manufacturing cells, each one dedicated to the processing of a family of similar part types. Group Technology (GT) as defined by Burbidge (1979) is the management philosophy that believes similar activities should be done similarly. Cellular Manufacturing (CM) is the application of GT. A manufacturing cell is a cluster of dissimilar machines placed in close proximity and dedicated to the manufacture of a family of parts. In the design of a CM system, similar parts are grouped into families and associated machines into groups as cell formation problem(CF), so that one or more part families can be processed within a single machine group. CM has been proven as a methodology to lower work in process levels, reducing production lead-time while retaining flexibility for new products. The potential benefits include reductions in material handling, setup times, lot sizes, work-inprocess inventories and lead times and increase in throughput, productivity and quality (Wemmerlov and Hyer, 1989). In CF, a binary machine/part matrix of pm dimension is usually provided. The m rows indicate m machines and the p columns represent p parts. Each binary element in the pm matrix indicates a relationship between parts and machines where ‘‘1’’ or ‘‘0’’ represents that the pth part should be worked on the mth machine or otherwise. The matrix also displays all similarities in parts and machines. The objective is to group parts and machines in a cell based on their similarities. If there are no ‘‘1’’ outside the diagonal block and no ‘‘0’’ inside the diagonal block then it is called as perfect result. That is, the two cells are completely independent where each part family will be processed only within a machine group. On the other hand, if in the machine/part matrix there is ‘‘1’’ outside the diagonal block then this is called an ‘‘exceptional par","A cost-based heuristic for group technology | Manufacturing cell formation using similarity coefficients and a parallel genetic TSP algorithm formulation and comparison | 1993.Covering technique-based algorithm for machine grouping to form manufacturing | Giraudel and S.Lek(2001) Utilisation of non-supervised neural netwroks and principle component analysis to study fish assemblages | Group Technology in Engineering Industry. London: Mechanical Engineering Publications | A massively parallel architecture for a selforganizing neural pattern recognition machine | Numerical taxonomy applied to group technology and plant | Direct clustering algorithm for group formation in cellular manufacture | MODROC: An extension of rank order clustering for group technology | Groupability: Analysis of the properties of binary data matrices for group technology | Application of Self Organizing Map in MachinePart Cell Formation | A comparison of three array-based clustering techniques for manufacturing cell formation | On the use of self-organising maps for clustering and visualization | 2004.An evolutionary algorithm for manufacturing cell formation | Manufacturing cell formation using a new self-organizing neural network | Artificial Neural Networks: a tutorial | Tabu search procedures for the cell formation problem with intracell transfer costs as a function of cell size | Ant colony recognition systems for part clustering problems, International | Data exploration using Self-Organizing Maps. Acta Polytechnica Scandinavica: Mathematics, computing and management in engineering, Series | Tips for processing and color-coding of self-organising maps. In Visual Explorations in Finance with Self-Organizing Maps, G.Deboeck and T | SOM-based exploratory analysis of gene expression data. In Advances in Self-Organising Maps, N.Allinson, H.Yin, L.Allinson and J.Slack (eds) Springer-Verlag, London | Extending the Kohonen Self Organising Mao networks for clusterung analysis | Integrated cellular manufacturing systems design with production planning and dynamic system reconfiguration | Grouping efficacy: a quantitative criterion for goodness of block diagonal forms of binary matrices in group technology | An improved fuzzy clustering method for cellular manufacturing ,International | Using simulated annealing to schedule a flowshop manufacturing cell with sequence-dependent family setup times, International | Neural network-based design of cellular manufacturing systems | Clustering of grapevine (Vitis vinivera L.) genotypes with Kohonen neural networks, VITIS | Weighted similarity measure heuristics for the group technology machine clustering problem | Heuristic approaches for part assignment in cell formation | A note on 'Modified Hamiltonian chain: a graph theoretic approach to group technology | Optimization and implementation of cellular manufacturing system in a pump industry using three cell formation algorithms. International Journal of Advanced Manufacturing Technology | A robust cellular manufacturing system design for dynamic part population using a genetic algorithm, International | Single linkage versus average linkage clustering in machine cells formation applications | Cellular Manufacturing Systems: Design,Planning and Control | Machine clustering for economic production | Sequence-dependent clustering of parts and machines, a Fuzzy ART neural network approach | A new approach for the cellular manufacturing problem in fuzzy dynamic conditions by a genetic algorithm | Evolving dispatching rules using genetic programming for solving multi-objective flexible job-shop problems Computers | Fractional cell formation in group technology using modified ART1 neural networks, The International Journal of Advanced Manufacturing | AN 2006b Complete and fractional cell formation using Kohonen selforganizing map networks in a cellular manufacturing | Machine-cell formation through neural network models | Somtoolbox for matlab 5 | Machine-component cell formation in group technology: MACE | Solving group technology problems via clique partitioning | Cellular Manufacturing in the US: A survey of users.IOnternational | Machine-part cell formation in group technology using a modified ART1 method",rejected,000
1105.1929.pdf.json,"The Hidden Web, XML and the Semantic Web: Scientific Data Management Perspectives",,"DBpedia: A nucleus for a web of open data | XQuery 1.0: An XML Query Language | Mathematical Markup Language (MathML) | Propagating XML Constraints to Relations | The Latest MML (Medical Markup Language) —XML based Standard for Medical Data Exchange / Storage | Frequent Pattern Mining on XML documents | Online mining of frequent query trees over XML data streams | Fast and Effective Clustering of XML Data Utilizing their Structural Information | Indexing the invisible Web: A Survey | Mining Association Rules from XML Documents | Automatic Wrapper Induction from Hidden- Web Sources with Domain Knowledge | YAGO: A Core of Semantic Knowledge | Mining Association rules from XML data mining query | XML Based Markup Languages for Specific Domains | Knowledge Discovery over Deep Web, Semantic Web and XML In: DAFSAA",rejected,000
1105.3486.pdf.json,Xapagy: a cognitive architecture for narrative reasoning,II-A External look: the pidgin language . . . . . . 2 II-B From words to concepts and verbs . . . . . . 3 II-C Instances . . . . . . . . . . . . . . . . . . . . 4 II-D The focus . . . . . . . . . . . . . . . . . . . . 4 II-E Shadows . . . . . . . . . . . . . . . . . . . . 4,"An integrated theory of the mind | The atomic components of thought | The Newell test for a theory of cognition | Integrating cognition, perception and action through mental simulation in robots | Unsupervised learning of narrative event chains | Unsupervised learning of narrative schemas and their participants | Repeated encounters of a similar kind: Effects of familiarity on children’s autobiographic memory | SAL: An explicitly pluralistic cognitive architecture | An overview of the EPIC architecture for cognition and performance with application to human-computer interaction | Extending the Soar cognitive architecture | Soar: An architecture for general intelligence | Toward a Computational Model of Narrative | A unified cognitive architecture for physical agents | Towards a computational theory of human daydreaming | What is it like to be a bat | KARMA: Knowledge-based active representations for metaphor and aspect | John Dean’s memory: A case study | Unified theories of cognition | Stanford encyclopedia of philosophy: Identity | Stanford encyclopedia of philosophy: Personal identity | Learnability and cognition: the acquisition of argument structure | Boyes-Braem. Basic objects in natural categories | Dynamic memory: A theory of reminding and learning in computers and people | Scripts, plans, goals and understanding: An inquiry into human knowledge structures, volume 2 | Contact languages: Pidgins and creoles | Anatomy and physiology for speech, language, and hearing | The CLARION cognitive architecture: Extending cognitive modeling to social simulation. Cognition and multi-agent interaction: From cognitive modeling to social simulation, pages | Episodic and semantic memory | Using anytime algorithms in intelligent systems",rejected,000
1105.4224.pdf.json,On A Semi-Automatic Method for Generating Composition Tables,"Since Allen’s seminal work of Interval Algebra (IA) [1,2], qualitative calculi have been widely used to represent and reason about temporal and spatial knowledge. In the past decades, dozens of qualitative calculi have been proposed in the artificial intelligence area “Qualitative Spatial & Temporal Reasoning” and Geographic Information Science. Except IA, other well known binary qualitative calculi include the Point Algebra [3], the Region Connection Calculi RCC-5 and RCC-8 [4], the INDU calculus [5], the Oriented Point Relation Algebras OPRA [6], and the Cardinal Direction Calculus (CDC) [7], etc. Relations in each particular qualitative calculus are used to represent temporal or spatial information at a certain granularity. For example, The Netherlands is west of Germany, The Alps partially overlaps Italy, I have today an appointment with my doctor followed by a check-up. Given a set of qualitative knowledge, new knowledge can be derived by using constraint propagation. Consider an example in RCC-5. Given that The Alps partially overlaps Italy and Switzerland, and Italy is a proper part of the European Union (EU), and Switzerland is discrete from the EU, we may infer that The Alps partially overlaps the EU. The above inference can be obtained by using composition-based reasoning. The composition-based reasoning technique has been extensively used in qualitative ar X iv :1 10 5. 42 24 v1 [ cs .A I] 2 1 M ay 2 01 1 2 spatial and temporal reasoning, and, when combined with backtracking methods, has been shown to be complete in determining the consistency problem for several important qualitative calculi, including IA, Point Algebra, Rectangle Algebra, RCC-5, and RCC-8. Moreover, qualitative constraint solvers have been developed to facilitate composition-based reasoning [8,9]. We here give a short introduction of the composition-based reasoning technique. SupposeM is a qualitative calculus, and Γ = {viγijvj}ni,j=1 is a constraint network overM. The composition-based",An interval-based representation of temporal knowledge | Maintaining knowledge about temporal intervals | Constraint propagation algorithms for temporal reasoning | A spatial logic based on regions and connection | INDU: An interval and duration network | Representing relative direction as a binary relation of oriented points | Similarity assessment for cardinal directions between extended spatial objects | Qualitative spatial representation and reasoning in the sparq-toolbox | GQR: A fast solver for binary qualitative constraint networks | Region connection calculus: Its models and composition table | Weak composition for qualitative spatial and temporal reasoning | The challenge of qualitative spatial reasoning | Composition  inOPRAm | Qualitative reasoning about relative direction on adjustable levels of granularity | Composing cardinal direction relations | Reasoning about cardinal directions between extended objects | What is a qualitative calculus? a general framework | Some observations and puzzles about composing spatial and temporal relations | On the consistency problem for the INDU calculus | Deriving the composition of binary topological relations | Qualitative spatial reasoning and representation | A reasoning system of ternary projective relations,rejected,000
1105.4318.pdf.json,,1.1 Language Modeling . . . . . . . . . . . . . . . . . . . . . . . . 2 1.2 Decoding in Machine Translation . . . . . . . . . . . . . . . . 3,"Computational models of the brain: from structure to function | Foundations of Sttistical Natural Language Processing | An empirical study of smoothing techniques for language modeling | The mathematic of statistical machine translation: Parameter estimation | Minimum error rate training in statistical machine translation | Statistical phrasebased translation | Greedy decoding for statistical machine translation in almost linear time | Pharaoh: A beam search decoder for phrase-based statistical machine translation models | Generation of word graphs in statistical machine translation | A decoder for syntax-based statistical mt | Hierarchical phrase based translation | Techniques for automatically correcting words in text | Finding approximate matches in large lexicons | Hierarchically coded lexicon with variants | Error-tolerant finite-state recognition with applications to morphological analysis and spelling correction | The string-to-string correction problem | Fast string correction with levenshtein | Binary codes capable of correcting deletions, insertions, and reversals | Language independent text correction using finite state automata | Applying winnow to contextsensitive spelling correction | Automatic rule acquisition for spelling correction | Proceedings of the Twelfth National Conference on Artificial Intelligense | A comparison of merging strategies for translation of german compounds | Using a grammar checker for evaluation and postprocessing of statistical machine translation | Improving a statistical mt system with automatically learned rewrite patterns | Statistical machine translation with scarce resources using morpho-syntactic information | Clause restructuring for statistical machine translation | Chinese syntactic reordering for statistical machine translation | Using statistical techniques and web search to correct esl errors | From spelling correction to text cleaning - using context information | Speech and Language Processing (2nd Edition) (Prentice Hall Series in Artificial Intelligence) | Bleu: a method for automatic evaluation of machine translation | Error analysis of the written english essays of secondary school students in malaysia: A case | A systematic comparison of various statistical alignment models | Srilm – an extensible language modeling toolkit | Open source toolkit for statistical machine translation | Programming languages and their compilers: Preliminary notes | Recognition and parsing of context-free languages in time n | Wordnet: A lexical database for english",rejected,000
1105.4394.pdf.json,Integrating Testing and Interactive Theorem Proving,"Users of interactive theorem provers such as ACL2 spend most of their time and effort challenging the theorem prover to find proofs of conjectures. They may start with a high-level theorem, only to find that a very long sequence of other theorems must be proven before the theorem prover is convinced that the original conjecture is in fact a theorem. During this process users invariably challenge the theorem prover with conjectures that are false. For example, an intermediate lemma may be missing some non-obvious hypotheses. In such cases, users routinely have a difficult time determining whether the theorem prover failed because the conjecture is not true or because the theorem prover cannot find a proof without further user assistance. Lightweight methods for quickly and automatically identifying false conjectures have the potential to dramatically simplify the interactions between users and theorem provers. In this paper we explore the obvious, well-studied idea of using random testing to try to find concrete counterexamples to conjectures. A naive approach to random testing is unlikely to find counterexamples in all but the simplest of cases. One reason is that it is highly unlikely that random assignments will satisfy even relatively simple hypotheses. This is especially true in a theorem prover for an untyped logic, like ACL2, where all variables can take on any value. We use a general data definition framework that is integrated with our testing framework. Together, they enable us to infer type information automatically from hypotheses. Unfortunately, hypotheses are often much more complex than a sequence of type restrictions. Our first contribution shows how to overcome this problem by using the full power of ACL2 to simplify conjectures for better testing. While previous work has suggested that subgoals generated during the proof process can be tested independently, as far as we know, no one has ever described or designed a system that does this automaticall","Random Testing in Isabelle/HOL | Nitpick: A Counterexample Generator for Higher- Order Logic Based on a Relational Model Finder | A Computational Logic | Symbolic Test Case Generation for Primitive Recursive Functions | Functional Testing in the Focal Environment | Formal Program Testing | QuickCheck: a lightweight tool for random testing of Haskell programs | Automating the Generation and Sequencing of Test Cases from Model- Based Specifications | ACL2s: ”The ACL2 Sedan | Combining Testing and Proving in Dependent Type Theory | Backtracking and Induction in ACL2 | Using ACL2 Arrays to Formalize Matrix Algebra. In: Fourth International Workshop on the ACL2 Theorem Prover and Its Applications (ACL2 ’03) | Testing Can Be Formal, Too | A SAT-based procedure for verifying finite state machines in ACL2 | Computer-Aided Reasoning: An Approach | Verification of executable pipelined machines with bit-level interfaces | A Framework for Verifying Bit-Level Pipelined Machines Based on Automated Deduction and Decision Procedures | Termination Analysis with Calling Context Graphs | Automatic generation of counterexamples for ACL2 using Alloy | Checking ACL2 Theorems via SAT Checking | SAT-Based Finite Model Generation for Higher-Order Logic",rejected,000
1105.5440.pdf.json,,,Manipulation Planning for Redundant | Using Genetic Algorithms | A Monte Carlo Algorithm for Path Planning | Solving the Find-Path Problem by Good Representation of the Free | The Complexity of Robot Motion Planning | Analogous Crossover | Robust Path Planning in the Plane | A Genetic Algorithm for Job Shop | A Genetic Algorithm for Bin Packing and Line | A Local Based Approach for Path Planning | Contribution a la Plani cation de Trajectoires | Motion Planning for Re-Orientation Using Finger Tracking: Landmarks | An Overview of KALI: A System | Adaptation in Natural and Arti cial Systems | Evolutionary Navigator for a Mobile Robot | A Simple Motion-Planning Algorithm for General Robot Manip | Incremental Roadmaps and Global Path Planning | A Random Approach to Motion Planning | Parallel Implementation of Genetic Algorithms in a Classi er System | Continuous-Curvature Path Planning for Car-Like | Allocation de Processus sur les Architectures | A Parallel Genetic Algorithm Applied to the Mapping | Parallel Genetic Algorithm for a Hypercube | Evolutionary Planner/Navigator: Operator,rejected,000
1105.5441.pdf.json,,,"Finding least constrained plans and optimal parallel executions | Executing parallel plans faster by adding actions | Expressive equivalence of planning formalisms | Parallel non-binary planning in polynomial time | Fast planning through planning graph analysis | Planning for conjunctive goals | Completeness in approximation classes | O-Plan: The open planning architecture | Zero knowledge and the chromatic number | A threshold of lnn for approximating set cover (preliminary version) | Formalizing plan justi cations | Computers and Intractability: A Guide to the Theory | Combining the expressivity of UCPOP with the e ciency | Representation and control in IxTeT, a temporal | State-variable planning under structural restrictions | Multi-contributor causal structures for planning: A formalization | A uni ed framework for explanation-based | Tractable planning for an assembly line | E cient planning for a miniature assembly | Generating parallel execution plans with a partial-order planner | Extending planning graphs | On the hardness of approximating minimization | On the computational complexity of temporal projec | Formulating multiagent, dynamic-world problems in the classical | Complete determination of parallel actions and temporal | A new method for solving hard satis  | Styrning av LEGO-bilfabrik. Andra omarbetade upplagan | Interacting goals and their use | Planning in time: Windows and durations for activities and goals | Practical Planning",rejected,000
1105.5442.pdf.json,,,,rejected,000
1105.5443.pdf.json,,,"Fast probabilistic algorithms for Hamiltonian circuits | Intelligent Backtracking on Constraint Satisfaction Problems | Using csp look-back techniques to solve exception | An algorithm for nding Hamilton | Camou aging independent sets in quasi | Finding hidden Hamiltonian cycles | Where the really hard problems are | Exploring the k{colorable landscape with iterated | Asymptotic and nite size parameters for phase | Phase transitions in the properties of random graphs | Finding Hamilton cycles in sparse random graphs | Boosting combinatorial search through | Which search problems are random | The hardest constraint problems: A double phase | Approximation algorithms for combinatorial problems | Cliques, Coloring, and Satis ability | GSAT and local consistency | An extension of the multi-path algorithm for nding Hamilton cycles | Limit distribution for the existence of a Hamilton | Systematic and nonsystematic search strategies | Algorithm 595: An enumerative algorithm for nding Hamiltonian | On various algorithms for estimating the chromatic number of a graph | Randomized Algorithms | Welsh-Powell opposition graphs. Information Processing | Graphical Evolution: an introduction to the theory of random graphs | Hamiltonian circuits in random graphs | Almost all regular graphs are Hamiltonian | A new method for solving hard satis ability | Generating Hamiltonian circuits without backtrack | Worst case analysis of a graph coloring algorithm | Finding Hamiltonian cycles: Algorithms, graphs and performance | Generating random regular graphs",rejected,000
1105.5444.pdf.json,Semantic Similarity in a Taxonomy: An Information-Based Measure and its Application to Problems of Ambiguity in Natural Language,,A simple but useful approach to conjunct | An occurrence-based model of word categorization | Discovering the lexical features of a language | A rule-based approach to prepositional phrase attachment | Introduction to the special issue | Coping with syntactic ambiguity or how to put | A spreading activation theory of semantic processing | Prepositional phrase attachment through a backed-o | Lexical disambiguation using simulated anneal | Large-Scale Dictionary Construction for Foreign Language Tutoring | WordNet: An Electronic Lexical Database | Frequency Analysis of English Usage: Lexicon | Similarity | Use of syntactic context to produce term association lists for text | Explorations in Automatic Thesaurus Discovery | Relevance feedback revisited | Noun homograph disambiguation using local context in large corpora | Structural ambiguity and lexical relations | Combining a Chinese thesaurus with a Chinese | Estimation of probabilities from sparse data for the language model | Mathematical Foundations of Information Theory | Dictionaries and Corpora: Combining Corpus | Analysis of Japanese compound nouns | Lexical ambiguity and information retrieval | Dynamic programming method for analyzing conjunc | Conceptual association for compound noun analysis | Designing Statistical Language Learners: Experiments on | Filling in a sparse training space for word sense | Similarity-based approaches to natural language processing | Automatic sense disambiguation using machine readable dictionaries | Generalizing case frames using a thesaurus and the MDL principle | Using syntactic dependency as local context to resolve word sense ambigu | An information-theoretic de nition of similarity | Building a large annotated | Augmenting lexicons automatically | Respects for similarity | WordNet: An on-line lexical database | Contextual correlates of semantic similarity | Distributional clustering of English words | Semantic memory | Ranking documents with a thesaurus. JASIS | Development and application | A maximum entropy model for prepositional phrase | Selection and Information: A Class-Based Approach to | Semantic classes and syntactic ambiguity | Using information content to evaluate semantic similarity in a taxonomy | Selectional constraints: An information-theoretic model and its compu | Disambiguating noun groupings with respect to Wordnet senses | WordNet and class-based probabilities | A perspective on word sense disambiguation methods | Distinguishing systems and distinguishing senses | A First Course in Probability | Contextual correlates of synonymy | Automatic Text Processing | Word sense disambiguation for free-text indexing using a massive | Features of similarity | Using WordNet to disambiguate word senses for text retrieval | Query expansion using lexical-semantic relations | Special issue on EuroWordNet | Empirical study of predictive powers | The grammar of sense: Is word-sense tagging | Verb Semantics and Lexical Selection,rejected,000
1105.5446.pdf.json,,,"Temporal reasoning and planning | Actions and events in interval temporal logic | Homogeneous concepts in a temporal | A computational account for a description logic | Hierarchical plans in a description logic of time | Terminological knowledge representation: a proposal | Terminological logics with modal operator | Temporal Extensions of Terminological Languages | Time dependent concepts: Representation and reasoning using temporal | Fine grained theories of time | Decidable reasoning in terminological | A uni ed framework for class-based | Computing least common subsumers | Tbox and abox reasoning in expressive description | What's in an aggregate | Hierarchical planning involving deadlines, travel | Plan-based terminological reasoning | Taxonomic plan reasoning | The complexity of concept | Deduction in concept | STRIPS: a new approach to the application of theorem | The integration of temporal operators into a terminological | On point-based temporal disjointness | A guide to the modal logic of knowledge and belief | A propositional modal logic of time intervals | RAT: representation | Subsumption algorithms for concept | A formal theory of plan recognition and its implementation | On the semantics of strips | Some philosophical problems from the standpoint | Terminological reasoning is inherently intractable | Terminological cycles: Semantics and computational properties | Inferences for temporal object descriptions in a terminological | Temporal Reasoning in the Situation Calculus | Natural actions, concurrency and continuous time in the situation calculs | On the complexity of qualitative spatial reasoning: a maximal | Features and Fluents. The Representation of Knowledge about | Non-monotonic temporal reasoning | Reasoning with individuals in concept languages | A correspondence theory for terminological logics: Preliminary report | Combining terminological logics with tense logic | Attributive concept descriptions with comple | A temporal terminological logic | Feature constraint logics for uni cation grammar | Generating project networks | Interval situation calculus | Exact and approximate reasoning about temporal | The design and experimental analysis of algorithms | Expressiveness and completeness of an interval tense logic | Closed Terminologies and Temporal reasoning in Descriptions for Plan | Terminological reasoning with constraint networks | Subsumption and recognition of heterogeneous constraint | Practical planning",rejected,000
1105.5447.pdf.json,,,A randomized parallel branch and | Parallel branch-and-bound algorithms on the hyper | Partial order planning: evaluating possible e ciency gains | An architecture for active | Estimating probabilities: a crucial task in machine learning | Parallel search algorithms for robot motion | The CN2 induction algorithm | Maximizing the bene ts of parallel search | A hybrid approach to improving the performance of parallel search | Parallel search using transformation-ordering | Massively parallel IDA* search | Introduction to robotics | PRA*: massively parallel heuristic | Studying overheads in massively | Inference bear: designing interactive | A multi-level load balancing scheme | Parallel state-space search for a rst solution with | Unstructured tree search on SIMD parallel computers | Scalable parallel formulations of depth- rst search | Integrating user interface agents with conventional applications | SIMD parallel heuristic search | New anticipatory load balancing strategies for parallel | Automatically con guring constraint satisfaction programs: a case study | Depth- rst heuristic search on a SIMD | Single-agent parallel window search | C4.5: programs for machine learning | Induction of decision trees | Parallel heuristic search algorithms for message passing | A parallel implementation | AIDA* - asynchronous parallel IDA | Parallel distributed processing: exploration | A distributed and adaptive dynamic load balancing scheme | Darwin: resource management | Static partitioning with slackness | An architecture for improving the performance of parallel search,rejected,000
1105.5449.pdf.json,,,"Neuronlike adaptive elements | Trails and U-turns in the selection | Dynamic Programming | On a routing problem | Dynamic Programming and Optimal Control | The case for chaotic adaptive routing | Packet routing in dinamically changing networks: A rein | TCP vegas: New techniques | Shortest paths algorithms: Theory | Predictive Q-routing: A memory-based reinforcement | Distributed optimization by ant colonies | Ants can colour graphs | A framework for QoS-based | An evaluation of TCP Vegas by live emulation | Two ant colony algorithms for best-e ort routing | A note on two problems in connection with graphs | Optimization, Learning and Natural Algorithms (in Italian) | Ant algorithms for distributed | Ant colony system: A cooperative learning | Positive feedback as a search strategy | The ant system: Optimization by a colony | Self-organized shortcuts | La reconstruction du nid et les coordinations interindividuelles | Reinforcement learning algorithm | Reinforcement learning: A survey | The revised ARPANET routing metric | Reinforcement learning with selective perception and hidden state | The new routing algorithm | A failsafe distributed routing protocol | OSPF Anatomy of an Internet Routing Protocol | On the behavior of a learning | Nonstationary models of learning automata | Probability, Random Variables and Stochastic Process (Third edition) | Computer Networks: A System | Simulation and the Monte Carlo Method | QoS routing (qosr) working group report | Ant-like agents for load balancing | Reinforcement learning with replacing eligibility | Learning without state estimation | Multiagent systems: A survey from a machine learning | Variance reduction algorithms for parallel replicated | Ants and reinforcement learning: A | High-performance Communication Networks | Analysis of shortest-path routing algorithms in a dynamic | A Simulation Laboratory for Evaluation of Dynamic Tra c Manage",rejected,000
1105.5450.pdf.json,,,"Lectures on Functional Equations and Their Applications | On Measures of Information and Their Characterizations | A summary of a new normative theory of probabilistic logic | An inquiry into computer understanding | Probability, frequency, and reasonable expectation | The logical view of conditioning and its application | On a recurrent misuse of a classical functional equation result | Theories of Probability | Plausibility measures: a user's manual | Plausibility measures and default reasoning | Modeling belief in dynamic systems. part I: foun | An axiomatic framework for belief updates | A framework for comparing alter | Where do we stand on maximum entropy | Probability Theory|The Logic of Science | The Uncertain Reasoner's Companion | The Theory of Probability | Foundations of Statistics | Rational Descriptions, Decisions, and Designs",rejected,000
1105.5452.pdf.json,,,,rejected,000
1105.5453.pdf.json,,"Nonmonotonic logics and related systems for nonmonotonic and default reasoning (Reiter, 1980; Moore, 1985; McCarthy, 1980) were developed for representing knowledge and forms of reasoning that are not conveniently expressible in monotonic logics, like the rst-order predicate logic or propositional logics. In nonmonotonic logics inferences can be made on the basis of what cannot be inferred from a set of facts. When extending this set, some of the inferences may become invalid, and hence the set of inferable facts does not monotonically increase. For example, in the kind of reasoning expressed as inheritance networks (Horty, 1994), one network link may say that priests imbibe non-alcoholic beverages only. This is, in the absence of contrary information, a su cient reason to conclude that a certain priest will not drink vodka. Without contradiction, information stating that the priest does drink vodka can be added, which retracts the previous conclusion. The need to incorporate priority information to nonmonotonic logics (Lifschitz, 1985; Brewka, 1989; Ge ner & Pearl, 1992; Ryan, 1992; Brewka, 1994; Baader & Hollunder, 1995) stems from the possibility that two default rules are in con ict. One source of such priority information is the speci city of defaults. When one rule says that priests usually do not drink and another says that men usually do, inferences concerning male priests should be based on the rst one because it is more speci c, as male priests are a small subset of men. Speci city as a basis for resolving con icts between defaults has been investigated in the framework of path-based inheritance theories (Horty, 1994). In general, however, priorities may come from di erent sources, and therefore it is justi ed to investigate nonmonotonic reasoning with an abstract notion of priorities as orderings on defaults. In this c 1998 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved. setting the problem is to de ne what are the correct infere",Structural Complexity I | Default reasoning using classical logic | Preferred subtheories: an extended logical framework for default reasoning | Adding priorities and speci city to default logic | Preferred answer sets for extended logic programs | Disjunctive ordered logic: semantics and expressiveness | Compiling reasoning with and about preferences into default logic | Linear-time algorithms for testing the satis ability of propositional Horn formulae | Formalizing nonmonotonic reasoning systems | On the complexity of timetable and multicommodity ow problems | Conditional entailment: bridging two approaches to default reasoning | Complexity results for nonmonotonic logics | Some direct theories of nonmonotonic inheritance | Hard problems for simple default theories | Generalizations of Opt P to the polynomial hierarchy | Computing circumscription | Nonmonotonic Logic: Context-Dependent Reasoning | Circumscription { a form of non-monotonic reasoning | E cient implementation of the well-founded and stable model semantics | A logic for default reasoning | Prioritized autoepistemic logic | Lexicographic priorities in default logic | Representing defaults as sentences with reduced priority | It is not my default: the complexity of reasoning in default logic | Constructive default logic and the control of defeasible reasoning,rejected,000
1105.5454.pdf.json,,,"Abstract local search | An approach to resource constrained project scheduling | Exploring the k{colorable landscape with iterated | Greedy randomized adaptive search procedures | Computers and Intractability: A Guide | Coloring by tabu branch and bound | Boosting combinatorial search through | Cliques, Coloring, and Satis ability | Squeaky wheel"" optimization | Experiments with parallel graph coloring heuristics | Distributed coloration neighborhood search | Tuning local search for satis ability testing | Using tabu search for solving the resource | Local search strategies for satis ability | Generation of schedules using a genetic procedure",rejected,000
1105.5455.pdf.json,,,A learning algorithm for Boltzmann | A new method to optimize the satellite | Ensemble learning in Bayesian neural networks | Tractable variational structures for approximating | Neural Networks for Pattern Recognition | Evidence for massless modes in the `solvable model | Bucket elimination: A unifying framework for probabilistic inference | The limitations of deterministic Boltzmann machine learning | Probability and Random Processes | Variational Methods for Inference and Estimation | Improving the mean eld approximation via | Boltzmann machine learning using mean eld | E cient learning in Boltzmann machines | Mixture representations for infer | Probable networks and plausible predictions - a review | Probabilistic inference using Markov chain Monte Carlo methods | TAP free energy structure of SK spin glasses | Statistical Field Theory | Probabilistic Reasoning in Intelligent Systems | A mean eld theory learning algorithm for neural | Convergence condition of the TAP equation for the in nite-ranged | E cient inference and learning ig decimatable boltzmann machines | Learning in Boltzmann trees | Mean eld theory for sigmoid belief | Calculus | Solution of `solvable model | Mean eld theory based on belief networks,rejected,000
1105.5457.pdf.json,,,Fast Planning through Planning Graph Analysis | The Automatic Inference of State Invariants in TIM | EBL and DDB for Graphplan | On the Relations Between Intelligent Backtracking and Explana | Extending Planning Graphs to an ADL | Incremental Graphplan,rejected,000
1105.5458.pdf.json,,,,rejected,000
1105.5459.pdf.json,,,"Conditional quantum dynamics and logic | Quantum mechanical hamiltonian models of Turing machines | The fundamental physical limits of computation | Quantum complexity theory | The stabilization of quantum compu | Experimental quantum teleportation | Tight bounds on quantum search | Quantum counting | Monte Carlo simulation of quantum computation | Nested quantum search and NP | Quantum computers and intractable (NP-complete) computing problems | Where the really hard problems | Quantum computations with cold trapped ions | Nuclear magnetic resonance spectroscopy | Quantum theory, the Church-Turing principle and the universal quan | Quantum computational networks | The Principles of Quantum Mechanics (4th edition) | Quantum computation | Quantum mechanical computers | QED: The Strange Theory of Light and Matter | Feynman Lectures on Computation | Computers and Intractability: A Guide | On the stupid algorithm for satis ability | Bulk quantum computation | Quantum computers can search arbitrarily large databases | Quantum mechanics helps in searching for a needle in a haystack | Quantum computing: Dream or nightmare | Quantum computing and phase transitions in combinatorial search | A framework for structured quantum search | Highly structured searches with quantum computers | Phase transitions and the search | The hardest constraint problems: A double phase | Local search methods for quantum computers | E cient quantum transforms | Critical behavior in the satis ability of random | Quantum measurements and the Abelian stabilizer problem | Resilient quantum computation | Is quantum mechanically coherent computation useful | A potentially realizable quantum computer | Constraint satisfaction | Minimizing con icts: A | The entropy of the k-satis ability problem | Future of quantum computing proves to be debatable | Combinatorial Algorithms for Computers and Calcula | Graphical Evolution: An Introduction to the Theory of Random | A new method for solving hard satis ability | Scheme for reducing decoherence in quantum computer memory | Algorithms for quantum computation: Discrete logarithms and fac | Realizable universal quantum logic gates | Single quantum querying of a database | Maintaining coherence in quantum computers | Incomplete thoughts about incomplete satis ability | Exploiting the deep structure of constraint problems",rejected,000
1105.5460.pdf.json,,,"Optimal control of Markov decision processes with incomplete state | Structured solution methods for non | Using temporal logic to control search | Making forward chaining relevant | Algebraic decision diagrams and their applications | Nonmonotonic reasoning in the framework of the situation calculus | Learning to act using real-time dynamic | Dynamic Programming | Adaptive aggregation for in nite horizon | Dynamic Programming | Discrete dynamic programming | Fast planning through graph analysis | Learning sorting and decision trees with POMDPs | A robust and fast action selection mechanism | Correlated action e ects in decision theoretic regression | Prioritized goal decomposition | Structured reachability analysis | Using abstractions for decision-theoretic planning | Approximating value trees in structured dynamic | Exploiting structure in policy | Stochastic dynamic programming | The frame problem and Bayesian network action | Computing optimal policies for partially observable | Process-oriented planning and average-reward | A heuristic variable-grid solution method for POMDPs | Graph-based algorithms for boolean function manipulation | The computational complexity of propositional STRIPS planning | Linear stochastic systems | Acting optimally in partially | Incremental pruning: A | Planning for conjunctive goals | Input generalization in delayed reinforcement | Decomposition principle for dynamic programs | Model minimization in Markov decision processes | Solving planning problems with large state and | Model reduction techniques for computing | Planning with deadlines | Planning under time | A model for reasoning about persistence and causation | Decomposition techniques for planning in stochastic do | Planning and Control | Integrating planning and execution in stochastic | Abstraction and approximate decision theoretic plan | Bucket elimination: A unifying framework for probabilistic inference | Mini-buckets: A general scheme for generating approximations | Sur un probl | Explanation-based learning and reinforcement | A probabilistic model of action | Probabilistic planning with information | Learning and executing generalized robot plans | STRIPS: A new approach to the application of theorem | Exploiting Constraints in Design Synthesis | Algorithm 97 (shortest path) | An algorithm for identifying the ergodic subchains and | Decision Theory | Advances in probabilistic reasoning | Model minimization, regression, and propositional STRIPS | Bounded-parameter Markov decision processes | Representing uncertainty in simple planners | Abstracting probabilistic actions | Utility Models for Goal-Directed Decision-Theoretic | Decision-theoretic re nement planning using inheri | Projecting plans for uncertain worlds | Modeling a dynamic and uncertain world I: Symbolic | Decision Theoretic Planning | Heuristic search in cyclic AND/OR graphs | A heuristic variable-grid solution method for POMDPs | Planning and Control in Stochastic Domains with Imperfect | SPUDD: Stochastic planning | Dynamic Programming and Markov Processes | Re nement planning as a unifying framework for plan synthesis | A sparse sampling algorithm for near | Decisions with Multiple Objectives: Preferences | A computational scheme for reasoning in dynamic probabilistic net | Generating Abstraction Hierarchies: An Automated Approach | Characterizing abstraction hier | Optimal probabilistic and decision-theoretic planning using Markovian | Real-time search in nondeterministic domains | Macro-operators: A weak method for learning | Real-time heuristic search | An Algorithm for Probabilistic Planning | Decomposition of systems governed by Markov | Online minimization of transition systems | State constraints revisited | Exploiting Structure for Planning and Control | Generating optimal policies for high-level plans | Probabilistic propositional planning: Representations and complex | On the complexity of solving | Algorithms for sequential decision making | Computationally feasible bounds for partially observed | A survey of algorithmic methods for partially observed | Introduction to Linear and Nonlinear Programming | Introduction to Dynamic Systems: Theory, Models and Applica | On the undecidability of probabilistic planning | To discount or not to discount in reinforcement learning: A case | Systematic nonlinear planning | Instance-based utile distinctions for reinforcement learning | Some philosophical problems from the standpoint | The parti-game algorithm for variable resolution | The complexity of Markov chain decision | Flexible decomposition algorithms for weakly coupled Markov decision | Approximating optimal policies for partially observable | Reinforcement learning with hierarchies of machines | Probabilistic Reasoning in Intelligent Systems: Networks of Plausible | ADL: Exploring the middle ground between STRIPS and the situa | UCPOP: A sound, complete, partial order planner | Conditional Nonlinear Planning | Control knowledge to improve plan quality | Exploiting the rule structure for decision making within the independent | The independent choice logic for modelling multiple agents under | Probabilistic partial evaluation: Exploiting rule structure in probabilistic | Context-speci c approximation in probabilistic inference | Theoretical results on reinforcement learning | CASSANDRA: Planning for contingencies | Markov Decision Processes | Modi ed policy iteration algorithms for discounted | Multichain Markov decision processes with a | Planning in a hierarchy of abstraction spaces | The nonlinear nature of plans | Universal plans for reactive robots in unpredictable environments | A reinforcement learning method for maximizing undiscounted | Evaluating in uence diagrams | The role of relevance in explanation I: Irrelevance | Probabilistic robot navigation in partially observable | How to dynamically merge Markov decision processes | Reinforcement learning with soft state | The optimal control of partially observable | Postponing threats in partial-order planning | The optimal control of partially observable Markov processes over | Team-partitioned, opaque-transition reinforcement learning | TD models: Modeling the world at a mixture of time scales | Reinforcement Learning: An Introduction | Control strategies for a stochastic planner | Dynamic programming and in uence diagrams | TD-Gammon, a self-teaching backgammon program, achieves master | A probabilistic approach to concurrent mapping | Finding structure in reinforcement learning | Generating conditional plans and programs | An introduction to least commitment planning | Solutions procedures for partially observed | A value-directed approach to planning | Optimal planning with a goal-directed utility model | Arti cial Intelligence, Third Edition | Intelligent Planning : A Decomposition and Abstraction Based Approach | A model approximation scheme for planning | Exploiting causal independence in Bayesian network",rejected,000
1105.5461.pdf.json,,,"The Logic of Conditionals, Vol | Constraint propagation with imprecise | Representing and Reasoning with Probabilistic Knowledge: A Logical | Logical Foundations of Probability | Coherent numerical and ordinal probabilistic assessments | On fuzzy syllogisms | Qualitative reasoning with | Inference with imprecise numerical quanti | A logic for reasoning about probabilities | Anytime deduction for probabilistic logic | Computers and Intractability: A Guide | Conditional events in probability assessment and revi | An analysis of rst-order logics of probability | Probabilistic description logics | Column generation methods | A linear programming approach to reasoning | Precision of Probabilistic Deduction under Taxonomic Knowledge | E cient global probabilistic deduction from taxonomic and prob | Magic inference rules for probabilistic deduction under taxonomic | Many-valued rst-order logics with probabilistic semantics | Probabilistic deduction with conditional constraints over basic | Probabilistic logic programming | Local probabilistic deduction from taxonomic and probabilistic | Probabilistic and truth-functional many-valued logic program | Computation of best bounds | A semantical framework for supporting subjective | Stable semantics for probabilistic deductive | Probabilistic logic | Probabilistic logic revisited | Probabilistic Logic | Combinatorial Optimization, Algorithms | Probabilistic Reasoning in Intelligent Systems: Networks of Plausible | Anytime decision making with imprecise probabilities | Theory of Linear and Integer Programming | Precise Conclusion under Uncertainty and Incompleteness in Deductive | On cautious probabilistic inference and | Computing probability intervals under independency constraints | Statistical Reasoning with Imprecise Probabilities",rejected,000
1105.5462.pdf.json,,,Incremental probabilistic inference | Symbolic probabilistic inference in large BN20 networks | NESTOR: A computer-based medical diagnostic aid that integrates | The computational complexity of probabilistic inference using Bayesian | Reformulating inference problems through selective | A Bayesian analysis of simulation algorithms for inference | Approximate probabilistic reasoning in Bayesian belief | Mini-buckets: A general scheme of generating approximations in auto | Bucket elimination: A unifying framework for probabilistic inference | Maximum likelihood from incomplete data | Localized partial evaluation of belief networks | Weighting and integrating evidence for stochastic sim | Sampling-based approaches to calculating marginal Den | A tractable inference algorithm for diagnosing multiple diseases | Search-based methods to bound diagnostic probabilities in very large | Bounded conditioning: Flexible inference | Variational methods for inference and learning in graphical models | Recursive algorithms for approximating probabilities | Blocking-Gibbs sampling in very large | Introduction to Bayesian networks | Local computations with probabilities on | Introduction to Monte Carlo methods | Probabilistic Reasoning in Intelligent Systems | A probabilistic causal model for diagnostic problem solving | Probabilistic partial evaluation: Exploiting rule structure in probabilistic | Convex Analysis | Simulation approaches to general probabilistic inference | Valuation-based systems for Bayesian decision analysis | An empirical analysis of likelihood { weighting simulation,rejected,000
1105.5463.pdf.json,Extensible Knowledge Representation: the Case of Description Reasoners,"Description Logics (DLs) are a family of object-centered formalisms for representing knowledge about and reasoning with individuals grouped into classes (here called concepts) and related by binary relations (here called roles). Descriptions usually have a term-like notation that uses concept constructors and identifiers to build definitions of more complex concepts from simpler ones. For example, the description in Figure 1 is supposed to capture the noun phrase “A collection of objects that are books and that are written by two or more authors, who are all Venusians”. This is accomplished by using the concept constructor and to conjoin terms that represent component notions: c©1999 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved. BOOK: objects that are books — a concept declared elsewhere, probably as a primitive; at-least(2,authoredBy): objects that are related to at least 2 other objects by the authoredBy role; the concept constructor is at-least here; all(authoredBy, VENUSIAN): objects that are related by the authoredBy role only to objects that are in the concept VENUSIAN; the concept constructor here is all. The concept VENUSIAN might itself be defined as a being whose address includes the planet value Venus: and(BEING, all(address, fills(planet, Venus))). (Note that descriptions can be nested.) A more precise introduction to DLs is presented in Section 2. Description logics reason both about intensional notions such as concepts, and about extensional aspects having to do with individuals that can be ascribed descriptions and participate in specific relationships. DLs have found a variety of applications in areas such as data management (Borgida, 1995), software engineering (Devanbu & Jones, 1997), configuration management (Wright et al., 1993), as well as general AI. A particular description language is characterized, among others, by the choice of term constructors in it, and the significant features of DLs are clear, precise semant","A formal definition for the expressive power of terminological knowledge representation languages | A scheme for integrating concrete domains into concept languages | An empirical analysis of optimization techniques for terminological representation systems - or making kris get a move on | From type systems to knowledge representation: Natural semantics specifications for description logics | Towards the systematic development of terminological reasoners: clasp reconstructed | Description logics in data management | On the relative expressiveness of description logics and predicate logics | classic: A structural data model for objects | Reasoning with black boxes: Handling test concepts in Classic | Asking queries about frames | A semantics and complete algorithm for subsumption in the classic description logic | Uniqueness constraints in description logics | Implementing and testing expressive description logics: a preliminary report | Computing least common subsumers in description logics | Software Information Systems | The use of description logics in kbse systems | Taxonomic plan reasoning | An epistemic operator for description logics | Two theses of knowledge representation: language restrictions, taxonomic classification, and the utility of representation services | A class library implementation of a principled open architecture | Building Large Knowledge-Based Systems | The Complexity of Decision Problems in Automata Theory and | The anatomy of the back",rejected,000
1105.5464.pdf.json,,,,rejected,000
1105.5465.pdf.json,,,"Complexity results for SAS+ planning | Structural Complexity I | Fast planning through planning graph analysis | Symbolic Boolean manipulation with ordered binary decision | The computational complexity of propositional STRIPS planning | An algorithm to evaluate quanti ed | Automatic OBDD-based generation | A machine program for theorem proving | Improvements to Propositional Satis ability Search Algorithms | Inferring state constraints for domain-independent | Application of theorem-proving to problem solving | Planning as satis ability | Pushing the envelope: planning, propositional logic | Heuristics based on unit propagation for satis ability | Systematic nonlinear planning | Conditional nonlinear planning | Planning for contingencies: A decision-based approach | A planning algorithm not based on directional search | Improvements to the evaluation of quanti ed Boolean formulae | Plan synthesis: A logical perspective | Conformant Graphplan",rejected,000
1105.5466.pdf.json,,,"Instance-Based Learning Algorithms | UCI Repository of machine learning databases | Stacked Regressions | Bagging Predictors | Bias, Variance, and Arcing Classi ers | Estimating Probabilities: A Crucial Task in Machine Learning | A Comparative Evaluation of Voting and Meta-learning | A Weighted Nearest Neighbor Algorithm for Learning | A Comparative Evaluation of Combiner | Neural Network Ensembles | Decision Combination in Multiple Classi er | Methods of Combining Experts' Probability Assessments | Hierachical Mixtures of Experts and the EM | Error Estimation by Series Association for Neural Network | Neural Network Ensembles, Cross Validation, and Active | Multiple Decision Trees | Combining Estimates in Regression and Classi | On Voting Ensembles of Classi ers (extended abstract) | Generalized Linear Models | Dynamic Learning Bias Selection | On Pruning and Averaging Decision Trees | When Networks Disagree: Ensemble Methods | Program for machine learning | The Strength of Weak Learnability | Boosting the margin: A new | Stacked Density Estimation | The Characterisation of Predictive Accuracy and Decision Combina | Stacking Bagged and Dagged Models | Computer Systems That Learns | Stacked Generalization | Hybrid System for Protein Secondary",rejected,000
1105.5516.pdf.json,Ontology Alignment at the Instance and Schema Level,"Motivation. An ontology is a formal collection of world knowledge. In this paper, we use the word ontology in a very general sense, to mean both the schema (classes and relations), and the instances with their assertions. In recent years, the success of Wikipedia and algorithmic advances in information extraction have facilitated the automated construction of large general-purpose ontologies. Notable endeavors of this kind include DBpedia [1], KnowItAll [8], WikiTaxonomy [24], and yago [28], as well as commercial services such as freebase.com, trueknowledge.com, and wolframalpha.com. These ontologies are accompanied by a growing number of knowledge bases1 in a wide variety of domains including: music2, movies3, geographical data4, publications5, medical and biological data6, or government data7. Many of these ontologies contain complementing data. For instance, a general ontology may know who discovered a certain enzyme, whereas a biological database may know its function and properties. However, since the ontologies generally use different terms (identifiers) for an entity, their information cannot be easily brought together. In this respect, the ontologies by themselves can be seen as isolated islands of knowledge. The goal of the Semantic Web vision is to interlink them, thereby creating one large body of universal ontological knowledge [3, 4]. This goal may be seen as a much scaled-up version of record linking, with challenges coming from different dimensions: (i) unlike in record linkage, both instances and schemas should be reconciled; (ii) the semantics of the ontologies have to be respected; (iii) the ontologies are typically quite large and complex. Moreover, we are interested in performing the alignment in a fully automatic manner, and avoid tedious tuning or parameter settings. A number of recent research have investigated this problem. There have been many works on entity resolution (i.e., considering the A-Box only) [10, 23, 25, 26, 29, 15, 16]. In anot",DBpedia: A Nucleus for a Web of Open Data | Schema and ontology matching with COMA++ | Web of linked data | Linked data on the Web | Data fusion | SameAs networks and beyond: Analyzing deployment status and implications of owl:sameAs in linked data | Duplicate record detection: A survey | Web-scale information extraction in KnowItAll (preliminary results) | Results of the ontology alignment evaluation initiative | Automatic identity recognition in the semantic web | Managing co-reference on the semantic Web | Large scale integration of senses for the semantic Web | When owl:sameAs isn’t the same: An analysis of identity in linked data | Performing object consolidation on the semantic Web data graph | Some entities are more equal than others: statistical methods to consolidate linked data | A self-training approach for resolving object coreference on the semantic Web | How matchable are four thousand ontologies on the semantic Web | An empirical study of instance-based ontology matching | Ontology matching with semantic verification | Rimom: A dynamic multistrategy ontology alignment framework | An introduction to the syntax and content of Cyc | Towards a standard upper ontology | Leveraging terminological structure for object reconciliation | Deriving a large-scale taxonomy from Wikipedia | L2R: A logical method for reference reconciliation | Combining a logical and a numerical method for data reconciliation | Combining linguistic and statistical analysis to extract relations from Web documents | YAGO: A core of semantic knowledge | Sig.ma: live views on the web of data | Leveraging data and structure in ontology integration | Discovering and maintaining links on the Web of data | Learning concept mappings from instance similarity,rejected,000
1105.5667.pdf.json,Complexity of and Algorithms for Borda Manipulation,"Voting is a simple mechanism to combine preferences in multi-agent systems. Unfortunately, results like those of Gibbrard-Sattertwhaite prove that most voting rules are manipulable. That is, it may pay for agents to mis-report their preferences. One appealing escape from manipulation is computational complexity (Bartholdi, Tovey, & Trick 1989). Whilst a manipulation may exist, perhaps it is computationally too difficult to find? Unfortunately, few voting rules in common use are NP-hard to manipulate with the addition of weights to votes. The small set of voting rules that are NP-hard to manipulate with unweighted votes includes single transferable voting, 2nd order Copeland, ranked pairs (all with a single manipulator), and maximin (with two manipulators) (Bartholdi & Orlin 1991; Bartholdi, Tovey, & Trick 1989; Xia et al. 2009). Borda is probably the only commonly used voting rule where the computational complexity of unweighted manipulation remains open. Xia, Conitzer, & Procaccia (2010) observe that: “The exact complexity of the problem [manipulation by a coalition with unweighted votes] is now known with respect to almost all of the prominent voting rules, with the glaring exception of Borda” Copyright c© 2011, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. It is known that computing a manipulation of Borda is NP-hard when votes are weighted (Conitzer, Sandholm, & Lang 2007), and polynomial when votes are unweighted and there is just a single manipulator (Bartholdi, Tovey, & Trick 1989). With a coalition of manipulators and unweighted votes, it has been conjectured that the problem is NP-hard (Zuckerman, Procaccia, & Rosenschein 2008). One of our most important contributions is to close this question. We prove that computing a manipulation of Borda with just two manipulators is NP-hard. As a consequence, we treat computing a manipulation as an approximation problem in which we try to minimize the number of manipula",Single transferable vote resists strategic voting. Social Choice and Welfare 8(4):341–354 | The computational difficulty of manipulating an election | On the reconstruction of binary and permutation matrices under (binary) tomographic constraints | When are elections with few candidates hard to manipulate | An empirical study of Borda manipulation | Analysis of several task-scheduling algorithms for a model of multiprogramming computer systems. JACM 22(4):522–550 | An empirical study of the manipulability of single transferable voting | Complexity of unweighted coalitional manipulation under some common voting rules | A scheduling approach to coalitional manipulation | Minimizing Makespan in a TwoMachine Flow Shop with Delays and Unit-Time Operations is NP-Hard | Algorithms for the coalitional manipulation problem,rejected,000
1105.6124.pdf.json,Reasoning on Interval and Point-based Disjunctive Metric Constraints in Temporal Contexts,"Two main lines of research are commonly recognized in the temporal reasoning area. The first approach deals with reasoning about temporal constraints on time-dependent entities. The goal is to determine what consequences (T) follow from a set of temporal constraints, ""{TemporalConstraints}|=T?"", or to determine whether a set of temporal constraints is consistent, with no assumptions about properties of temporal facts. The second approach deals with reasoning about change, events, actions and causality. Here, the goal is to obtain the consequent state from a set of actions or events which are performed on an initial state: ""[Si, {A1, A2, ..., An}]|= Sj?"". Both these approaches constitute active fields of research with applications in several artificial intelligence areas such as reasoning about change, scheduling, temporal planning, knowledge-based systems, natural language understanding, etc. In these areas, time plays a crucial role, problems have a dynamic behavior, and it is necessary to represent and reason about the temporal dimension of information. In this paper, we deal with the first of these approaches. Our goal is reasoning on qualitative and quantitative constraints between intervals or time-points in temporal contexts. Moreover, special cases of non-binary constraints are also managed. These tasks are pending issues in the temporal reasoning area, as well as important features to facilitate modeling of relevant problems in this area (including planning, scheduling, causal or hypothetical reasoning, etc.). Several temporal reasoning models have been defined in the literature, with a clear trade-off between representation expressiveness and complexity of reasoning algorithms. Qualitative Point Algebra (PA) (Vilain, Kautz & Van Beek, 1986) is a limited subset of interval-based models. Interval Algebra (IA) introduced by Allen (1983) represents symbolic (qualitative) constraints between intervals but metric information, such as 'interval1 starts 2 seconds b","Maintaining knowledge about temporal intervals | Hybrid Temporal Reasoning for Planning and Scheduling | A metric time-point and duration-based temporal model | Temporal reasoning in Reakt: An environment for real-time knowledge-based systems. AICommunications | Later: Managing temporal information efficiently | Tractable disjunctive constraints | An optimal k-consistency algorithm | Temporal data base management | Temporal constraint networks | From local to global consistency | Situation Recognition: Representation and Algorithms | Eight maximal tractable subclasses of Allen's algebra with metric time | Synthesizing constraint expressions | A sufficient condition for backtrack-free search | Hierarchisation of the Seach Space in Temporal Planning | A model for planning and scheduling integration | Efficient algorithms for qualitative reasoning about time | Constraints, consistency and closure | How to determine the expressive power of constraints | A linear-programming approach to temporal reasoning | A unifying approach to temporal constraint reasoning | Computational complexity of relating time | Integrating metric and qualitative temporal reasoning | Consistency in networks of relations | Networks of constraints: fundamental properties and applications to picture processing | Qualitative temporal reasoning with points and durations | Reasoning about temporal relations: a maximal tractable subclass of Allen's interval algebra | A new framework for reasoning about Points | Distance constraint arrays: A model for reasoning on intervals with qualitative and quantitative distances | Efficient planning through separate resource scheduling | Tractable disjunctions of Linear Constraints | Bactracking algorithms for disjunctions of temporal constraints | 1991).Temporal query processing with indefinite information | On the minimality and global consistency of row convex networks | Constraint tightness and looseness versus local and global | Constraint propagation algorithm for temporal reasoning | Temporal representation with qualitative and quantitative information about points and durations | Performance of temporal reasoning systems, ACM Sigart",rejected,000
1105.6148.pdf.json,Overcoming Misleads In Logic Programs by Redefining Negation,"Negation as failure and incomplete information in logic programs have been studied by many researchers, mainly because of their role in the foundations of declarative reading of logic programming. This paper gives a review of some of the definitions of the concepts related to of the declarative reading of logic programming. Then, the paper provides a framework to overcome misleads and to solve a misleading case study. The paper begins with reviewing the relevant work of contributions to logic programming emphasizing many concepts such as negation as failure, closed world assumption, incomplete information, and their consequences (Section 2). Then we comment on the standard definitions of the relevant logic programming concepts such as: compound terms, substitution, common instance, facts, rules, reduction, variables quantification, unifier, Most General Unifier (MGU), computation, and structured data (Section 3). Then we briefly discuss the semantics of logic programming. A logic program can have many semantics according the point of view. The common semantics are operational, denotational, and declarative (Section 4). Then we present our framework for overcoming misleads in logic programs using negation as invalid (Section 5). Then we investigate the features of the presented framework in the next section.","A logical foundation for logic programming, I and II, Journal of Logic Programming, pages 151–194 | A Causal Logic of Logic Programming | ""On Skolemization in constrained logics | Negation as failure | Prolog in 10 Figures | The birth of Prolog"", dans History of Programming Languages, edited by Thomas | A note on the Declarative reading of Logic Programming |  What’s in a Model? Epistemological Analysis of Logic Programming | Teaching students to solve insight problems. Evidence for domain specificity in training | Logic Programming and Reasoning with Incomplete Information' | From Logic Programming to Prolog | Sequent forms of Herbrand theorem and their applications | On indenite data bases and the closed world assumption | On closed world data bases | Minimal belief and negation as failure in multi-agent systems | Artificial Intelligence A Modern Approach"" 2 Ed, page 273 | Selected Works in Logic"", edited by Fenstad | The Art of Prolog",rejected,000
1105.6314.pdf.json,Activity-Based Search for Black-Box Contraint-Programming Solvers,"Historically, the constraint-programming (CP) community has focused on developing open, extensible optimization tools, where the modeling and the search procedure can be specialized to the problem at hand. This focus stems partially from the roots of CP in programming languages and partly from the rich modeling language typically found in CP systems. While this flexibility is appealing for experts in the field, it places significant burden on practitioners, reducing its acceptance across the wide spectrum of potential users. In recent years however, the constraint-programming community devoted increasing attention to the development of black-box constraint solvers. This new focus was motivated by the success of Mixed-Integer Programming (MIP) and SAT solvers on a variety of problem classes. MIP and SAT solvers are typically black-box systems with automatic model reformulations and general-purpose search procedures. As such, they allow practitioners to focus on modeling aspects and may reduce the time to solution significantly. This research is concerned with one important aspect of black-box solvers: the implementation of a robust search procedure. In recent years, various proposals have addressed this issue. Impact-based search (Ibs) [10] is motivated by concepts found in MIP solvers such as strong branching and pseudo costs. Subsequent work about solution counting can be seen as an alternative to impacts [8] that exploits the structure of CP constraints. The weighted-degree heuristic (wdeg) [1] is a direct adaptation of the SAT heuristic Vsids[5] to CSPs that relies on information collected from failures to define the variable ordering. This paper proposes Activity-Based Search (Abs), a search heuristic that recognizes the central role of constraint propagation in constraint-programming ar X iv :1 10 5. 63 14 v1 [ cs .A I] 3 1 M ay 2 systems. Its key idea is to associate with each variable a counter which measures the activity of a variable during propagation. Thi",Boosting systematic search by weighting constraints | The cycle-cutset method for improving search performance in ai applications | Comet v2.1 user manual | Chaff: engineering an efficient sat solver | Minizinc: Towards a standard cp modelling language | Counting and estimating lattice points: Special polytopes for branching heuristics in constraint programming | Singleton consistencies | Impact-based search strategies for constraint programming | Scalable load balancing in nurse to patient assignment problems | The Progressive Party Problem: Integer Linear Programming and Constraint Programming Compared | A dynamic programming approach for consistency and propagation for knapsack constraints | Backdoors to typical case complexity,rejected,000
1106.0171.pdf.json,Proposal of Pattern Recognition as a necessary and sufficient principle to Cognitive Science,"Are there any scientific principle, system, property, or technique that can explain the overall cognitive phenomena? The Computational Theory of Mind and the Connectionist Model are the most successful cognitive science modeling principles, but there is still many unsolved questions about the nature of mind. This article proposes the concept of Pattern Recognition to be a formal answer to most of those questions, and build a solid Cognitive Science theory taking pattern recognition as a necessary and sufficient principle. With derived concepts as pattern processing and pattern learning, a complete explanatory model of the mind functioning will be proposed. This article proposes a set of definitions and explanations as physical phenomenon, of some ill-defined concepts in pattern recognition and cognitive science, actually viewed as abstract principles. The derived explanations and solutions given here is a very ambitious and new scientific proposal. This paper starts arguing the necessity of the underestimated concept of pattern recognition as a cognitive science principle and the proposal to also be a sufficient principle. Then, a more fundamental description of the pattern recognition concept and it's mechanisms is discussed, allowing a formal physical description and a related cognitive description. This gives a better foundation for the modeling of any cognitive function as a physical pattern recognition mechanism, and explanations to some key biological cognitive processes. This is a totally new perspective to the pattern recognition concept, and consequently a totally new candidate to be a theoretical solution to some fundamental problems of cognitive science. The pattern recognition description of some primitive cognitive concepts like instinct, action, reaction, processing and learning are presented. This is important to describe the overall cognitive phenomena in full explanatory level. Also a general unsupervised learning model is proposed, where the only l",Some general remarks about pattern recognition | Pattern Recognition: An overview | A logical calculus of the ideas immanent in nervous activity,rejected,000
1106.0357.pdf.json,Learning Hierarchical Sparse Representations using Iterative Dictionary Learning and Dimension Reduction,,Emergence of simple cell receptive field properties by learning a sparse code for natural | Computer Science and Artificial Intelligence Laboratory Technical Report Generalization and Properties of the Neural Response Generalization and Properties of the Neural Response | What and where: A Bayesian inference theory of attention | An integrated model of visual attention using shape-based features | On the Prospects for Building a Working Model of the Visual Cortex | Hierarchical models in the brain | Reinforcement learning or active inference | Action and behavior: a free-energy formulation | Action understanding and active inference | Towards a mathematical theory of cortical micro-circuits | Sparse Recovery Using Sparse Matrices | Hierarchical Bayesian inference in the visual cortex | Perceptual Neuroscience: The Cerebral Cortex | Sparse coding with an overcomplete basis set: a strategy employed by V1 | Hierarchical models of object recognition in cortex | A quantitative theory of immediate visual recognition | A feedforward architecture accounts for rapid categorization | Robust object recognition with cortex-like mechanisms,rejected,000
1106.0566.pdf.json,,"Evolutionary Algorithms (EAs) are stochastic search algorithms, which have been used to solve many optimization problems in real-world applications [34, 47, 51]. As one of the primary operators in the framework of EAs, the mutation operator has significant influence on the performance of an EA. During the past decades, various strategies ∗Corresponding author: Ke Tang (E-mail: ketang@ustc.edu.cn. Telephone: +86 551 360 0754) of controlling the parameters of the mutation operator have been developed to promote the performance of EAs. Some of them were concerned with the mutation operators for binary search space (e.g., [3, 20, 21, 29, 43, 45, 48]), while some were dedicated to continuous search space [1, 23, 42, 50]. In this paper, we restrict our investigation to the former. As the most commonly used mutation operator for binary search space, the so-called bitwise mutation operator flips each bit of an individual (solution) with a uniform probability Pm, where Pm is called the mutation rate. Early investigations often employed a fixed mutation rate over the whole optimization process [20], but further studies have revealed that a time-variable mutation rate scheme might be better than a fixed mutation rate. According to Bäck [5], Hinterding et al. [27] and Thierens [48], there are three classes of time-variable mutation rate schemes : dynamic mutation rate schemes, adaptive mutation rate schemes and self-adaptive mutation schemes. During the past decades, a large number of empirical investigations have been dedicated to show the advantages of various time-variable mutation rate schemes. Holland [28] proposed a time-variable mutation rate scheme for Genetic Algorithm (GA). After fourteen years, Fogarty [21] designed a number of dynamic mutation rate schemes with which the performance of GAs was significantly improved on some static optimization problems. Inspired by Evolution Strategies (ES), Bäck [2] proposed a self-adaptive mutation scheme for GAs for the continu",,rejected,000
1106.0664.pdf.json,,,"Temporal Constraint Networks in Nonlinear | Satis ability in Nonlinear Time: Algorithms | Spatial reasoning with propositional logic | Carving Up Space: Existential Axioms for a Formal Theory of Spatial | A Calculus of Individuals Based on \Connection | The complexity of theorem-proving procedures | Morphological Spatial Reasoning: Preliminary Report | Using interval logic for order assembly | Twenty-one large tractable subclasses of Allen's | Reasoning about binary topological relations | Point-Set Topological Spatial Relations | A Mathematical Framework for the De nition | Topological Spatial Relations Based on | How Far Can We \C""? de ning a \Doughnut"" Using Connection | A Connection Based Approach | A Complete Classi cation of Tractability in the Spa | Computational complexity of relating | On Binary Constraint Problems | Semantical Foundations of Spatial Logics | The complexity of some polynomial network | Sviluppo ed Analisi di Algoritmi per il Ragionamento Spaziale Quali | Computational properties of qualitative spatial reasoning: First results | Observations on the complexity of reasoning in constraint algebras | Reasoning about temporal relations: A maximal | Modelling topological and metrical properties | A spatial logic based on regions | Maximal Tractable Fragments of the Region Connection Calculus: A | On the complexity of qualitative spatial reasoning: A maximal | Intuitionistic logic is polynomial-space complete | Measuring without Measures: The -Calculus",rejected,000
1106.0666.pdf.json,"Experiments with Infinite-Horizon, Policy-Gradient Estimation","Function approximation is necessary to avoid the curse of dimensionality associated with largescale dynamic programming and reinforcement learning problems. The dominant paradigm is to use the function to approximate the state (or state and action) values. Most algorithms then seek to minimize some form of error between the approximate value function and the true value function, usually by simulation (Sutton & Barto, 1998; Bertsekas & Tsitsiklis, 1996). While there have been a multitude of empirical successes for this approach (for example, Samuel, 1959; Tesauro, 1992, 1994; Baxter, Tridgell, & Weaver, 2000; Zhang & Dietterich, 1995; Singh & Bertsekas, 1997), there are only weak theoretical guarantees on the performance of the policy generated by the approximate value function. In particular, there is no guarantee that the policy will improve as the approximate value function is trained; in fact performance can degrade even when the function class contains an approximate value function whose corresponding greedy policy is optimal (see Baxter & Bartlett, 2001, Appendix A, for a simple two-state example). An alternative technique that has received increased attention recently is the “policy-gradient” approach in which the parameters of a stochastic policy are adjusted in the direction of the gradient of some performance criterion (typically either expected discounted reward or average reward). The c 2001 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved. key problem is how to compute the performance gradient under conditions of partial observability when an explicit model of the system is not available. This question has been addressed in a large body of previous work (Barto, Sutton, & Anderson, 1983; Williams, 1992; Glynn, 1986; Cao & Chen, 1997; Cao & Wan, 1998; Fu & Hu, 1994; Singh, Jaakkola, & Jordan, 1994, 1995; Marbach & Tsitsiklis, 1998; Marbach, 1998; Baird & Moore, 1999; Rubinstein & Melamed, 1998; Kimura, Yamamura, & Kobayashi, 1995; K","Policy-gradient learning of controllers with internal state | Gradient descent for general reinforcement learning | Hebbian synaptic modifications in spiking neurons that learn | Estimation and approximation bounds for gradient-based reinforcement learning | Stochastic optimization of controlled partially observable markov decision processes | Neuronlike adaptive elements that can solve difficult learning control problems | Reinforcement learning in POMDPs via direct gradient ascent | Infinite-horizon policy-gradient estimation | Learning to play chess using temporal-differences | Perturbation Realization, Potentials, and Sensitivity Analysis of Markov Processes | Algorithms for Sensitivity Analysis of Markov Chains Through Potentials and Perturbation Realization | Feedforward Neural Network Methodology | Smooth Perturbation Derivative Estimation for Markov Chains | Stochastic approximation for monte-carlo optimization | An analysis of actor/critic algorithms using eligibility traces: Reinforcement learning with imperfect value functions | Reinforcement learning in POMDPs with function approximation | Reinforcement learning by stochastic hill climbing on discounted reward | Actor-Critic Algorithms | Simulation-Based Methods for Markov Decision Processes | Simulation-Based Optimization of Markov Reward Processes | Some Studies in Machine Learning Using the Game of Checkers | Learning Without State-Estimation in Partially Observable Markovian Decision Processes | Reinforcement learning for dynamic channel allocation in cellular telephone systems | Reinforcement learning with soft state aggregation | Learning to Predict by the Method of Temporal Differences | Reinforcement Learning: An Introduction | Policy Gradient Methods for Reinforcement Learning with Function Approximation | A multi-agent, policy-gradient approach to network routing | Practical Issues in Temporal Difference Learning | TD-Gammon, a self-teaching backgammon program, achieves master-level play | Reinforcement learning from state and temporal differences | Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning | A reinforcement learning approach to job-shop scheduling",rejected,000
1106.0667.pdf.json,Reasoning within Fuzzy Description Logics,,"KRIS: Knowledge representation and inference system, system description | A terminological knowledge representation system with complete inference algorithm | Representing and Reasoning with Probabilistic Knowledge | On the analytic formalism of the theory of fuzzy sets | reducing” CLASSIC to practice: Knowledge representation meets reality | Decidable reasoning in terminological knowledge representation systems | Decidable reasoning in terminological knowledge representation systems | A sound and complete fuzzy logic system using Zadeh’s implication operator | A system of knowledge representation based on formulae of predicate calculus whose variables are annotated by expressions of a fuzzy terminological logic | Deduction in concept languages: From subsumption to instance checking | Fuzzy Sets and Systems | Can we enforce full compositionality in uncertainty calculi | Approximate and commonsense reasoning: From theory to practice | An analysis of first-order logics of probability | Probabilistic description logics | An alternative proof method for possibilistic logic and its application to terminological logics | Using an expressive description logic: Fact or fiction | Probabilistic reasoning in terminological logics | P-CLASSIC: A tractable probabilistic description logic | Uncertainty and Vagueness in Knowledge Based Systems | Fuzzy logic and the resolution principle | Modelling the retrieval of structured documents containing texts and images | Mirlog: A logic for multimedia information retrieval | A relevance terminological logic for information retrieval | Computational complexity of terminological reasoning in BACK | Reasoning and revision in hybrid representation systems | Combinatorial Optimization: Algorithms and Complexity | Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference | The BACK system – an overview | On the hardness of approximate reasoning | Attributive concept descriptions with complements | A probabilistic terminological logic for modelling information retrieval | A fuzzy description logic | A note on the relationship between fuzzy logic and four-valued logic | Reasoning and experimenting within Zadeh’s fuzzy propositional logic | A description logic for vague knowledge | The rationality and decidability of fuzzy implications | Generalizing term subsumption languages to fuzzy logic | Fuzzy sets",rejected,000
1106.0668.pdf.json,,,,rejected,000
1106.0669.pdf.json,,,,rejected,000
1106.0671.pdf.json,,"There are more and more applications in arti cial intelligence that use constraint networks (CNs) to solve combinatorial problems, ranging from design to diagnosis, resource allocation to car sequencing, natural language understanding to machine vision. Finding a solution in a constraint network involves looking for a set of value assignments, one for each variable, so that all the constraints are simultaneously satis ed (Meseguer, 1989; Tsang, 1993). This task is NP-hard and many exponential time algorithms have been proposed to solve this problem. These algorithms, which make a systematic exploration of the search space, all have backtracking as a basis. As long as the unassigned variables have values consistent with the partial instantiation, they extend it by assigning values to variables. Otherwise, a dead-end is reached and some previous assignments have to be changed before going on with the partial instantiation extension. The explicit constraints of the network together induce some implicit constraints. Since basic search algorithms do not record these implicit constraints, they waste time by repeatedly detecting the local inconsistencies caused by them. Filtering techniques are essential to reduce the size of the search space and so to improve the e ciency of search algorithms. They can be used during a preprocessing step to remove once and for all some local inconsistencies that otherwise would have been repeatedly found during search (Dechter & Meiri, 1994). They can also be maintained during search. c 2001 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved. Debruyne & Bessi ere Search algorithms di er in the kind of local consistency they achieve after each choice of a value for a variable. Most of them enforce partial arc consistency, going from forward checking (FC,Golomb & Baumert, 1965; Haralick & Elliott, 1980), which only removes the values directly arc inconsistent with the last assignment, to really full look-ahead (RFL, Ga","Maintaining Knowledge about Temporal Intervals | Dynamic variable ordering in csps | Radio link frequency assignment | Where the really hard problems are | Two new constraint propagation algorithms requiring small space complexity | A strong local consistency for constraint satisfaction | A property of path inverse consistency leading to an optimal algorithm | From restricted path consistency to max-restricted path consistency | Some practicable ltering techniques for the constraint satisfaction problem | Experimental evaluation of preprocessing algorithms for constraint satisfaction problems | Network-based heuristics for constraint-satisfaction problems | A su cient condition for backtrack-free search | A su cient condition for backtrack-bounded search | Completable representations of constraint satisfaction problems | Neighborhood inverse consistency preprocessing | Random uniform csp generators. In http://www.ics.uci.edu/~ frost/csp/generatotr.html | Look-ahead value ordering for constraint satisfaction problems | A constraint satisfaction method for inference making | The phase transition behaviour of maintaining arc consis | Increasing tree search e ciency for constraint satisfaction | Random constraint satisfaction | Hybrid algorithms for the constraint satisfaction problem | Contradicting conventional wisdom in constraint satisfac | Lazy arc consistency | Path consistency revisited | How to Solve the Zebra Problem, or Path Consistency the Easy Way | Foundations of Constraint Satisfaction",rejected,000
1106.0672.pdf.json,,,,rejected,000
1106.0675.pdf.json,,,"Conditional e ects in Graphplan | Subset of PDDL for the AIPS2000 Planning Competition | Fast planning through planning graph analysis | Fast planning through planning graph analysis | HSP: Heuristic search planner | Planning as heuristic search: New results | Planning as heuristic search | A robust and fast action selection | The computational complexity of propositional STRIPS planning | Ordering problem subgoals | Goal ordering in partially ordered plans | Heuristic search planning with BDDs. In ECAI-Workshop: PuK | NP-completeness of several arrangement problems | STRIPS: A new approach to the application of theorem | The automatic inference of state invariants in tim | Hybrid STAN: Identifying and managing combinatorial op | When gravity fails: Local search topology | Combining the expressiveness of UCPOP with | A heuristic for domain independent planning and its use | Local search topology in planning benchmarks: An empirical analysis | Solving the entailment problem in the uent calculus | Subgoal ordering and goal augmentation for heuristic | Planning - a randomized approach | A theoretical analysis of conjunctive-goal problems | Understanding and extending | Unifying SAT-based and graph-based planning | Pushing the envelope: Planning, propositional logic | Solving complex planning tasks through extraction of subproblems | On reasonable and forced goal orderings and their use | On the instantiation of ADL operators involving | Extending planning graphs | Elevator control as a planning problem | E cient implementation of the plan graph in stan | Systematic nonlinear planning | A heuristic estimator for means-ends analysis in planning | The PDDL Planning Domain De nition Language | Using regression-match graphs to control search in planning | Hard and easy distributions of SAT | On the compilability and expressive power of propositional planning | Ignoring irrelevant facts and operators | ADL: Exploring the middle ground between STRIPS and the | GRT: a domain independent heuristic for STRIPS | Exploiting state constraints in heuristic state-space | Nonparametric Statistics for the Behavioral Sciences | Blocks world revisited",rejected,000
1106.0676.pdf.json,,,,rejected,000
1106.0678.pdf.json,,"The rst Trading Agent Competition (TAC) was held from June 22nd to July 8th, 2000, organized by a group of researchers and developers led by Michael Wellman of the University of Michigan and Peter Wurman of North Carolina State University (Wellman, Wurman, O'Malley, Bangera, Lin, Reeves, & Walsh, 2001). Their goals included providing a benchmark problem in the complex and rapidly advancing domain of e-marketplaces (Eisenberg, 2000) and motivating researchers to apply unique approaches to a common task. A key feature of TAC is that it required autonomous bidding agents to buy and sell multiple interacting goods in auctions of di erent types. Another key feature of TAC was that participating agents competed against each other in a preliminary round and many practice games leading up to the nals. Thus, developers changed strategies in response to each others' agents in a sort of escalating arms race. Leading into the competition day, a wide variety of scenarios were possible. A successful agent needed to be able to perform well in any of these possible circumstances. This article describes ATTac-2000, the rst-place nisher in TAC. ATTac-2000 uses a principled bidding strategy, which includes several elements of adaptivity . In addition to the success at the competition, isolated empirical results are presented indicating the robustness and e ectiveness of ATTac-2000's adaptive strategy. The remainder of the article is organized as follows. Section 2 presents the details of the TAC domain. Section 3 introduces ATTac-2000, including the mechanisms behind its adaptivity. Section 4 describes the competition results and the results of controlled experiments testing ATTac-2000's adaptive components. Section 5 compares ATTac-2000 c 2001 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved. with some of the other TAC participants. Section 6 presents possible directions for future research and concludes.","The FCC spectrum auctions: An early assessment | FAucS: An FCC spectrum auction simulator for autonomous bidding agents | In online auctions of the future, it'll be bot vs. bot vs. bot | Computers and Intractability: A Guide to the Theory of NP-completeness | Designing bidding strategies for trading agents in electronic auctions | Bidding algorithms for simultaneous auctions | Shopbots and pricebots | Autonomous bidding agents in the trading agent competition | Biddingbot: a multiagent support system for cooperative bidding in multiple auctions | Auction theory: A guide to the literature | Markov games as a framework for multi-agent reinforcement learning | Algorithm design for agents which participate in multiple simultaneous auctions | Towards a test-bed for trading agents in electronic auction markets. AI Communications | Nash convergence of gradient dynamics in general sum games | Layered Learning in Multiagent Systems: A Winning Approach to Robotic Soccer | Making more from less: Strategic demand reduction in the FCC spectrum auctions | A trading agent competition",rejected,000
1106.0679.pdf.json,,,,rejected,000
1106.0680.pdf.json,,,"On the computational complexity of approximating distri | Learning regular sets from queries and counterexamples | Map building for a mobile robot from sensory data | Estimation in a bidirectional mixture of von Mises distributions | Learning dynamics: System | A maximization technique occurring | Probability and Statistics (2nd edition) | Maximum likelihood from incomplete | Unsupervised Learning and Clustering, chap | Using occupancy grids for mobile robot perception and navigation | Error correction in mobile robot map learning | Complexity of automaton identi cation from given data | Introduction to Automata | Maximum likelihood estimation for mixture multivariate stochastic obser | A probabilistic distance measure for | Passive distance learning for robot navigation | Unsupervised learning of probabilistic models for robot | A robot exploration and mapping strategy based on | On information and su ciency | Dynamic map building for an au | A computationally e cient method for large-scale | Maximum likelihood estimation for multivariate observations | Statistics of Directional Data | A distributed model for mobile robot environment-learning and naviga | The EM Algorithm and Extensions | Sensor fusion in certainty grids for mobile robots | High resolution maps from wide angle sonar | Dervish: An o ce-navigating | Map learning with uninterpreted sensors and e ectors | A tutorial on hidden Markov models and selected applications in speech | Diversity based inference of nite automata | Inference of nite automata using homing sequences | Learning probabilistic automata with variable | On the learnability and usage of acyclic probabilistic | On the learnability and usage of acyclic probabilistic | Learning Models for Robot Navigation | Learning topological maps with weak local odometric | Heading in the right direction | Probabilistic navigation in partially observable environ | A stochastic map for uncertain spatial | Learning metric-topological maps for indoor mobile robot | Integrating grid-based and topological maps for mobile robot | Learning maps for indoor mobile robot navigation | A probabilistic approach to concurrent map acqui | The Nature of Statistical Learning",rejected,000
1106.0681.pdf.json,Accelerating Reinforcement Learning through Implicit Imitation,"The application of reinforcement learning to multiagent systems offers unique opportunities and challenges. When agents are viewed as independently trying to achieve their own ends, interesting issues in the interaction of agent policies (Littman, 1994) must be resolved (e.g., by appeal to equilibrium concepts). However, the fact that agents may share information for mutual gain (Tan, 1993) or distribute their search for optimal policies and communicate reinforcement signals to one another (Mataric, 1998) offers intriguing possibilities for accelerating reinforcement learning and enhancing agent performance. Another way in which individual agent performance can be improved is by having a novice agent learn reasonable behavior from an expert mentor. This type of learning can be brought about through explicit teaching or demonstration (Atkeson & Schaal, 1997; Lin, 1992; Whitehead, 1991a), by sharing of privileged information (Mataric, 1998), or through an explicit cognitive representation of imitation (Bakker & Kuniyoshi, 1996). In imitation, the agent’s own exploration is used to ground its observations of other agents’ c©2003 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved. behaviors in its own capabilities and resolve any ambiguities in observations arising from partial observability and noise. A common thread in all of this work is the use of a mentor to guide the exploration of the observer. Typically, guidance is achieved through some form of explicit communication between mentor and observer. A less direct form of teaching involves an observer extracting information from a mentor without the mentor making an explicit attempt to demonstrate a specific behavior of interest (Mitchell, Mahadevan, & Steinberg, 1985). In this paper we develop an imitation model we call implicit imitation that allows an agent to accelerate the reinforcement learning process through the observation of an expert mentor (or mentors). The agent observes the state ","Learning how to do things with imitation | Robot learning from demonstration | Locally weighted learning for control | Robot see, robot do: An overview of robot imitation | Dynamic Programming | Dynamic Programming: Deterministic and Stochastic Models | Learning to communicate through imitation in autonomous robots | Drama, a connectionist architecturefor control and learning in autonomous robots | Imitation skills as a means to enhance learning of a synthetic proto-language in an autonomous robot | Sequential optimality and coordination in multiagent systems | Decision theoretic planning: Structural assumptions and computational leverage | Rational and convergent learning in stochastic games | Imitation as social exchange between humans and robot | Learning by imitation: a hierarchical approach | Imitating human performances to automatically generate expressive jazz ballads | Acting optimally in partially observable stochastic domains | Intelligent social learning | Elevator group control using multiple reinforcement learning | Model minimization in Markov decision processes | Abstraction and approximate decision theoretic planning | Model-based bayesian exploration | Probability and statistics | Do robots ape | Active and passive routes to imitation | Observational learning in octopus vulgaris | Practical reinforcement learning in continuous domains | Robot programming by demonstration (RPD): Support the induction by human interaction | Algebraic Structure Theory of Sequential Machines. PrenticeHall, Englewood Cliffs | Multiagent reinforcement learning: Theoretical framework and an algorithm | Learning in Embedded Systems | Reinforcement learning: A survey | Near-optimal reinforcement learning in polynomial time | Learning by watching: Extracting reusable task knowledge from visual observation of human performance | Online miminization of transition systems | Mondrian: A teachable graphical editor | Self-improvement based on reinforcement learning, planning and teaching | Self-improving reactive agents based on reinforcement learning, planning and teaching | Markov games as a framework for multi-agent reinforcement learning | A survey of algorithmic methods for partially observed Markov decision processes | Using communication to reduce locality in distributed multi-agent learning | Behaviour-based primitives for articulated control | Exploration of multi-state environments: Local mesures and back-propagation of uncertainty | A comparison of the Bonferroni and Scheffé bounds | Knowledge, learning and machine intelligence | LEAP: A learning apprentice for VLSI design | Prioritized sweeping: Reinforcement learning with less data and less real time | Game Theory: Analysis of Conflict | Mapping between dissimilar bodies: Affordances and the algebraic foundations of imitation | Algorithms for inverse reinforcement learning | Is it really imitation? a review of simple mechanisms in social information gathering | Cultural transmission of communications systems: Comparing observational and reinforcement learning models | A Bayesian approach to imitation in reinforcement learning | Markov Decision Processes: Discrete Stochastic Dynamic Programming | Imitation in free-ranging rehabilitant orangutans (pongopygmaeus) | Learning to fly | Knowing what to imitate and knowing when you succeed | Why experimentation can be better than perfect guidance | Multivariate Observations | Stochastic games | Reinforcement learning for dynamic channel allocation in cellular telephone systems | The optimal control of partially observable Markov processes over a finite horizon | Skill reconstruction as induction of LQ controllers with subgoals | Learning to predict by the method of temporal differences | Reinforcement Learning: An Introduction | Multi-agent reinforcement learning: Independent vs | Reconstruction human skill with machine learning | Two kinds of training information for evaluation function learning | Learning hierarchical performance knowledge by observation | Do monkeys ape | Complexity analysis of cooperative mechanisms in reinforcement learning | Complexity and cooperation in q-learning",rejected,000
1106.0707.pdf.json,Efficient Reinforcement Learning Using Recursive Least-Squares Methods,"In recent years, reinforcement learning (RL) has been an active research area not only in machine learning but also in control engineering, operations research and robotics (Kaelbling et al.,1996; Bertsekas, et al.,1996; Sutton and Barto,1998; Lin,1992). It is a computational approach to understand and automate goal-directed learning and decision-making, without relying on exemplary supervision or complete models of the environment. In RL, an agent is placed in an initial unknown environment and only receives evaluative feedback from the environment. The feedback is called reward or reinforcement signal. The ultimate goal of RL is to learn a strategy for selecting actions such that the expected sum of discounted rewards is maximized. Since lots of problems in the real world are sequential decision processes with delayed evaluative feedback, the research in RL has been focused on theory and algorithms of learning to solve the optimal control problem of Markov decision processes (MDPs) which provide an elegant mathematical model for sequential decision-making. In operations research, many results have been presented to solve the optimal control problem of MDPs with model information. However, in reinforcement learning, the model information is assumed to be unknown, which is different from the methods studied in operations research such as dynamic programming. In dynamic programming, there are two elemental processes, which are the policy evaluation process and the policy improvement process, respectively. In RL, there are two similar processes. One is called learning prediction and the other is called learning control. The goal of learning control is to estimate the optimal policy or optimal value function of an MDP without knowing its model. Learning prediction aims to solve the policy evaluation problem of a stationary-policy MDP without any prior model and it can be regarded as a sub-problem of learning control. Furthermore, in RL, learning prediction is different","Neurodynamic Programming. Belmont, Mass.: Athena Scientific | The convergence of TD | Convergence of the RLS and LMS adaptive filters | On the convergence of stochastic iterative dynamic programming algorithms | Self-improving reactive agents based reinforcement learning, planning and teaching | Analysis of recursive stochastic algorithm | Study of the transient phase of the forgetting factor RLS | Convergence results for singlestep on-policy reinforcement-learning algorithms | Asynchronous stochastic approximation and Q-learning | An analysis of temporal difference learning with function approximation",rejected,000
1106.0776.pdf.json,,"Answer Set Programming (ASP) is one of the most successful logic programming approaches in Non-monotonic Reasoning and Artificial Intelligence applications (Baral 2003; Gelfond 2008). In (Nicolas et al. 2006), a possibilistic framework for reasoning under uncertainty was proposed. This framework is a combination between ASP and possibilistic logic (Dubois et al. 1994). Possibilistic Logic is based on possibilistic theory in which, at the mathematical level, degrees of possibility and necessity are closely related to fuzzy sets (Dubois et al. 1994). Due to the natural properties of possibilistic logic and ASP, Nicolas et al.’s approach allows us to deal with reasoning that is at the same time non-monotonic and uncertain. Nicolas et al.’s approach is based on the concept of possibilistic stable model which defines a semantics for possibilistic normal logic programs. An important property of possibilistic logic is that it is axiomatizable in the necessityvalued case (Dubois et al. 1994). This means that there is a formal system (a set of axioms and inferences rules) such that from any set of possibilistic fomulæ F and for any possibilistic formula Φ, Φ is a logical consequence of F if and only if Φ is derivable from F in this formal system. A result of this property is that the inference in possibilistic logic can be managed by both a syntactic approach (axioms and inference rules) and a possibilistic model theory approach (interpretations and possibilistic distributions). Equally important to consider is that the answer set semantics inference can also be characterized as a logic inference in terms of the proof theory of intuitionistic logic and intermediate logics (Pearce 1999; Osorio et al. 2004). This property suggests that one can explore extensions of the answer set semantics by considering the inference of different logics. Since in (Dubois et al. 1994) an axiomatization of possibilistic logic has been defined, in this paper we explore the characterization of a ","A logic programming framework for possibilistic argumentation: Formalization and logical properties | A Complete Calculus for Possibilistic Logic Programming with Fuzzy Propositional Variables | Towards an automated deduction system for first-order possibilistic logic programming with fuzzy constants | Evidential support logic programming | Knowledge Representation, Reasoning and Declarative Problem Solving | Probabilistic reasoning with answer sets | Characterizations of the disjunctive stable semantics by partial evaluation | Characterizations of the disjunctive well-founded semantics: Confluent calculi and iterated gcwa | Semantics of (Disjunctive) Logic Programs Based on Partial Evaluation | Knowledge and Inquiry : Essays on the Pragmatism of Isaac Levi | Possibilistic semantics for logic programs with ordered disjunction | Introduction to Lattices and Order, Second ed | A classification theory of semantics of normal logic programs: I | A classification theory of semantics of normal logic programs: II | A general theory of confluent rewriting systems for logic programming and its applications | Vienna University of Technology | Towards possibilistic logic programming | Possibilistic logic | Possibilistic logic: a retrospective and prospective view | Bilattices and the semantics of logic programming | Safe and Sound: Artificial Intelligence in Hazardous Applications | From arguments to decisions: Extending the Toulmin view | Handbook of Knowledge Representation | The Stable Model Semantics for Logic Programming | Classical Negation in Logic Programs and Disjunctive Databases | Temporal disjunctive logic programming | Combining probabilistic logic programming with the power of maximum entropy | Theory of generalized annotated logic programming and its applications | An epistemic foundation for logic programming with uncertainty | Extended criteria for organ acceptance: Strategies for achieving organ safety and for increasing organ pool | Professional characteristics of the transplant coordinator | Probabilistic logic programming | Fixpoint characterizations for many-valued disjunctive logic programs with probabilistic semantics | Quantitative disjunctive logic programming: Semantics and computation | Probabilistic logic programming | Possibilistic Uncertainty Handling for Answer Set Programming | Semantics for possibilistic disjunctive programs | Semantics for possibilistic disjunctive programs | Reasoning about actions under uncertainty: A possibilistic approach | Applications of Intuitionistic Logic in Answer Set Programming | Stable Inference as Intuitionistic Validity | Quantitative Logic Programming revisited | A lattice-theoretical fixpoint theorem and its applications | Judgment under uncertainty:Heuristics and biases | Logic and structure, 3rd., aumented edition ed | Quantitative deduction and its fixpoint theory | An introduction to fuzzy answer set programming | coincide. Then the proof is reduced to possibilistic definite programs",rejected,000
1106.0987.pdf.json,Nearest Prime Simplicial Complex for Object Recognition,"The structure representation is important to understanding the underlying mechanism of generating data. To capture such structures, manifold learning algorithms [1,2] assume that data are generated from an underlying low-dimensional manifold. However, it is not easy to discover and preserve the topological structure hidden in the manifold. For example, [3] pointed out that the view and style-independent action manifolds, which are used to describe human activities, can be assumed to lie in a torus. Persistent homology can effectively discover the topological invariants such as holes, which cannot be easily available by other means such as manifold learning algorithms [4]. The method first incrementally constructs nested families of simplicial complexes from point cloud data (PCD), and then computes the lifecycle of each possible topological invariant by placing the complexes within an evolutionary growth process. Finally, it extracts those truly topological invariants or ? Junping Zhang, Ziyu Xie, Email: jpzhang@fudan.edu.cn, ziyu.ryan@gmail.com ?? Stan Z. Li, Email:szli@nlpr.ia.ac.cn ar X iv :1 10 6. 09 87 v1 [ cs .L G ] 6 J un 2 features with longer lifecycle and removes topological noises [5]. However, how to employ it for practical applications (e.g., object recognition) remains unsolvable. In this paper, we propose a novel method, called nearest prime simplicial complex approaches (NSC), to obtain a structure-preserving representation and achieve higher performance in object recognition. Specifically, we generate a nested family of simplicial complexes per class, and estimate a prime simplicial complex per class by weighting the lifecycles of alive topological structures. Then we classify objects based on the nearest projection distances from each object to simplices in these simplicial complexes. Furthermore, we also utilize a projection constraint term to enhance the extrapolation ability of NSC and prevent incorrect projection. The main contribution is that ",Nonlinear dimensionality reduction by locally linear embedding | A global geometric framework for nonlinear dimensionality reduction | View and style-independent action manifolds for human activity recognition | Topological estimation using witness complexes | Topological persistence and simplification | Elements of Algebraic Topology | On the local behavior of spaces of natural images | Geodesic delaunay triangulations in bounded planar domains | Algebraic Topology | Computing persistent homology | A barcode shape descriptors for curve point cloud data | Coverage in sensor networks via persistent homology | Analyzing Stratified Spaces Using Persistent Versions of Intersection and Local Homology | Towards stratification learning through homology inference | Persistent homology for random fields and complexes | UCI machine learning repository | Columbia object image library (COIL-20) | Columbia object image library (COIL-100) | Evaluating colour-based object recognition algorithms using the SOIL-47 database | Face recognition: From theory to applications | Parameterisation of a stochastic model for human face identification | SVM and kernel methods matlab toolbox | Shape contexts enable efficient retrieval of similar shapes,rejected,000
1106.1510.pdf.json,,"Petrology, a branch of geology studying rocks and their formation, plays an important role in describing Earth’s crust structure, which is essential for revealing patterns in distribution of mineral resources. Similar to other natural sciences, a wealth of knowledge requiring a proper management (especially with regard to consistency) and integration has been accumulated in petrology. These tasks could be approached more efficiently, if the knowledge had been machine processable, in particular, if a formal theory of petrology (i.e. a system of axioms, definitions and theorems [11], p.33) had been available. Ontologies, especially OWL ontologies, are well suited for playing the role of a cornerstone of such theory, as they have been remarkably successful in other sciences, e.g., bioinformatics, chemistry, and health care. This paper describes our steps towards developing a formal theory of petrology. We focus on identifying basic terms, providing definitions to other commonly 2 used terms i.e., terms used in industrial standards, and namely, rock types such as rhyolite or harzburgite, and formalizing the basic set of axioms. We use OWL as a main formalization tool enabling us, in particular, to automatically check our representation for consistency. It is only natural to start developing a theory by identifying the important terms to be later used for representing facts, e.g., knowledge about specific rock samples. Such facts are typically stored in relational databases in modern petrology, so relational databases can be used as a source of terms. We describe the conversion of one such database, namely Proba [5] (Sample in Russian), to a collection of OWL ontologies containing facts expressed using an initial set of currently undefined terms in the 2 section. Once the terms have been identified, we proceed to their formalization, i.e., writing their definitions in OWL. First, it is essential to define the basic terms, which can be used to define all other terms. Curr","Representations of commonsense knowledge | Attempto controlled english (ace) language manual, version 3.0 | Bgs rock classification scheme, volume 1, classification of igneous rocks | Petrographic code of Russia | Controlled English for Knowledge Representation | ed.): Igneous Rocks: A Classification and Glossary of Terms | Introduction to Mathematical Logic | Petrographic dictionary | Ontology of scientific dictionary | Algorithm to classify igneous rock sample and formal definition of igneous rock type | Definitions, Dictionaries, and Meanings",rejected,000
1106.1796.pdf.json,,,,rejected,000
1106.1797.pdf.json,,"Parameter learning is common in various elds from neural networks to reinforcement learning to statistics. It is used to tune up systems for their best performance, be they classi ers or statistical models. Unlike these numerical systems described by mathematical formulas however, symbolic systems, typically programs, do not seem amenable to any kind of parameter learning. Actually there has been little literature on parameter learning of programs. This paper is an attempt to incorporate parameter learning into computer programs. The reason is twofold. Theoretically we wish to add the ability of learning to computer programs, which the authors believe is a necessary step toward building intelligent systems. Practically it broadens the class of probability distributions, beyond traditionally used numerical ones, which are available for modeling complex phenomena such as gene inheritance, consumer behavior, natural language processing and so on. c 2001 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved. The type of learning we consider here is statistical parameter learning applied to logic programs. 1 We assume that facts (unit clauses) in a program are probabilistically true and have a parameterized distribution. 2 Other clauses, non-unit de nite clauses, are always true as they encode laws such as \if one has a pair of blood type genes a and b, one's blood type is AB"". We call logic programs of this type a parameterized logic program and use for statistical modeling in which ground atoms 3 provable from the program represent our observations such as \one's blood type is AB"" and the parameters of the program are inferred by performing ML (maximum likelihood) estimation on the observed atoms. The probabilistic rst-order framework sketched above is termed statistical abduction (Sato & Kameya, 2000) as it is an amalgamation of statistical inference and abduction where probabilistic facts play the role of abducibles, i.e. primitive hypotheses. 4 St",Stochastic attribute-value grammars | Learning acyclic rst-order horn sentences from entailment | From statistical knowledge bases to degrees of belief | Trainable grammars for speech recognition | Valence induction with a head-lexicalized PCFG | Probability Theory (3rd ed.) | Introduction to Algorithms | Maximum likelihood from incomplete | From Logic to Logic Programming | A probabilistic parsing | Abductive logic programming | Learning and Representation of Symbolic-Statistical Knowledge (in Japanese) | E cient EM learning for parameterized logic programs | Probabilistic Language Models (in Japanese) | E ective Bayesian inference for stochastic programs | Learning probabilities for noisy rst-order rules | Uncertainty logics | A derivation of the Inside-Outside Algorithm from the EM algorithm | Probabilistic deductive databases | The estimation of stochastic context-free grammars using the Inside-Outside algorithm | E cient inference in Bayes networks as a combinatorial optimization problem | Foundations of Logic Programming | Probabilistic deduction with conditional constraints over basic events | Foundations of Statistical Natural Language Processing | The EM Algorithm and Extensions | Stochastic logic programs | Probabilistic logic programming | Answering queries from context-sensitive probabilistic knowledge bases | Probabilistic logic | Probabilistic Reasoning in Intelligent Systems | Inside-Outside reestimation from partially bracketed corpora | De nite clause grammars for language analysis | a survey of the formalism and a comparison with augmented transition networks | Semantics and inference for recursive probability models | Probabilistic Horn abduction and Bayesian networks | Generalized queries on probabilistic context-free grammars | A tutorial on hidden markov models and selected applications in speech recognition | Foundations of Speech Recognition | E cient tabling mechanisms for logic programs | Learning rst-order acyclic horn programs from entailment | Probabilistic Constraint Logic Programming | Inference and missing data | XSB as an e cient deductive database engine | A statistical learning method for logic programs with distribution semantics | Modeling scienti c theories as PRISM programs | Minimum likelihood estimation from negative examples in statistical abduction | PRISM: a language for symbolic-statistical modeling | A Viterbi-like algorithm and EM learning for statistical abduction | Fast EM learning of a family of PCFGs | Linear tabulated resolution based on Prolog control strategy | The Art of Prolog | An e cient probabilistic context-free parsing algorithm that computes pre x probabilities | Unfold/fold transformation of logic programs | OLD resolution with tabulation | Japanese grammar for speech recognition considering the MSLR method | ATR integrated speech and language database | Memoing for logic programs | Probabilistic languages: a review and some open questions | An Anatomy of Kinship | Exploiting causal independence in Bayesian network inference,rejected,000
1106.1799.pdf.json,,,,rejected,000
1106.1800.pdf.json,,,,rejected,000
1106.1802.pdf.json,,,,rejected,000
1106.1804.pdf.json,,,,rejected,000
1106.1813.pdf.json,SMOTE: Synthetic Minority Over-sampling Technique,"A dataset is imbalanced if the classes are not approximately equally represented. Imbalance on the order of 100 to 1 is prevalent in fraud detection and imbalance of up to 100,000 to c©2002 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved. 1 has been reported in other applications (Provost & Fawcett, 2001). There have been attempts to deal with imbalanced datasets in domains such as fraudulent telephone calls (Fawcett & Provost, 1996), telecommunications management (Ezawa, Singh, & Norton, 1996), text classification (Lewis & Catlett, 1994; Dumais, Platt, Heckerman, & Sahami, 1998; Mladenić & Grobelnik, 1999; Lewis & Ringuette, 1994; Cohen, 1995a) and detection of oil spills in satellite images (Kubat, Holte, & Matwin, 1998). The performance of machine learning algorithms is typically evaluated using predictive accuracy. However, this is not appropriate when the data is imbalanced and/or the costs of different errors vary markedly. As an example, consider the classification of pixels in mammogram images as possibly cancerous (Woods, Doss, Bowyer, Solka, Priebe, & Kegelmeyer, 1993). A typical mammography dataset might contain 98% normal pixels and 2% abnormal pixels. A simple default strategy of guessing the majority class would give a predictive accuracy of 98%. However, the nature of the application requires a fairly high rate of correct detection in the minority class and allows for a small error rate in the majority class in order to achieve this. Simple predictive accuracy is clearly not appropriate in such situations. The Receiver Operating Characteristic (ROC) curve is a standard technique for summarizing classifier performance over a range of tradeoffs between true positive and false positive error rates (Swets, 1988). The Area Under the Curve (AUC) is an accepted traditional performance metric for a ROC curve (Duda, Hart, & Stork, 2001; Bradley, 1997; Lee, 2000). The ROC convex hull can also be used as a robust method of identifying p","UCI Repository of Machine Learning Databases http://www.ics.uci.edu/∼mlearn/∼MLRepository.html | The Use of the Area Under the ROC Curve in the Evaluation of Machine Learning Algorithms | SMOTE: Synthetic Minority Over-sampling TEchnique | Modifying MUSTAFA to capture salient data | Learning to Classify English Text with ILP Methods | Fast Effective Rule Induction | Context-sensitive Learning Methods for Text Categorization | A Weighted Nearest Neighbor Algorithm for Learning with Symbolic Features | Neural Network Training on Unequally Represented Classes | Metacost: A General Method for Making Classifiers Cost-sensitive | Explicitly Representing Expected Cost: An Alternative to ROC Representation | Inductive Learning Algorithms and Representations for Text Categorization | Learning Goal Oriented Bayesian Networks for Telecommunications Risk Management | Combining Data Mining and Machine Learning for Effective User Profile | Off-line, Handwritten Numeral Recognition by Perturbation Method | The Electrotopological State: Structure Information at the Atomic Level for Molecular Graphs | The Class Imbalance Problem: Significance and Strategies | Machine Learning for the Detection of Oil Spills in Satellite Radar Images | Addressing the Curse of Imbalanced Training Sets: One Sided Selection | Noisy Replication in Skewed Binary Classification | Heterogeneous Uncertainity Sampling for Supervised Learning | A Comparison of Two Learning Algorithms for Text Categorization | Data Mining for Direct Marketing Problems and Solutions | Feature Selection for Unbalanced Class Distribution and Naive Bayes | Computational Geometry in C | Reducing Misclassification Costs | Robust Classification for Imprecise Environments | The Case Against Accuracy Estimation for Comparing Induction Algorithms | A Large-Scale Evaluation of Features for Automatic Detection of Oil Spills in ERS SAR Images | Toward Memory-based Reasoning | Measuring the Accuracy of Diagnostic Systems | Two Modifications of CNN | Cost Sensitive Bibliography | The Selection of Good Search Terms | Comparative Evaluation of Pattern Recognition Techniques for Detection of Microcalcifications in Mammography",rejected,000
1106.1814.pdf.json,When do Numbers Really Matter?,"A belief network is a compact representation of a probability distribution (Pearl, 1988; Jensen, 2001). It consists of two parts, one qualitative and the other quantitative. The qualitative part of a belief network (called its structure) is a directed acyclic graph in which nodes represent domain variables and edges represent direct influences between these variables. The quantitative part of a belief network is a set of conditional probability tables (CPTs) that quantify our beliefs in such influences. Figure 1 depicts the structure of a belief network and Figure 2 depicts its CPTs.1 Automated reasoning systems based on belief networks have become quite popular recently as they have enjoyed much success in a number of real-world applications. Central to the development of such systems is the construction of a belief network (hence, a probability distribution) that faithfully represents the domain of interest. Although the automatic synthesis of belief networks—based on design information in certain applications and based on learning techniques in others—has been drawing a lot of attention recently, mainstream methods for constructing such networks continue to be based on traditional knowledge engineering (KE) sessions involving domain experts. One of the central issues that arise in such KE sessions is the assessment of impact that changes in network parameters may have on probabilistic queries of interest. Consider for example the following common method for constructing belief networks in medical diagnosis applications (Coupé, Peek, Ottenkamp, & Habbema, 1999). First, the 1. This specific network and its CPTs are distributed with the evaluation version of the commercial HUGIN system at http://www.hugin.com/. c©2002 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved. network structure is developed. Next, parameters are estimated by non-experts using a combination of statistical data and qualitative influences available from textbook material",Sensitivity analysis in discrete Bayesian networks | A distance measure for bounding probabilistic belief change | Using sensitivity analysis for efficient quantification of a belief network | A differential approach to inference in Bayesian networks | Learning Bayesian nets that perform well | Bayesian updating in recursive graphical models by local computation | Gradient descent training of bayesian networks | Bayesian Networks and Decision Graphs | Making sensitivity analysis computationally efficient | Sensitivity analysis for probability assessments in Bayesian networks | Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference | Context-specific approximation in probabilistic inference | The sensitivity of belief networks to imprecise probabilities: an experimental investigation | Local learning in probabilistic networks with hidden variables | Analysing sensitivity data from probabilistic networks,rejected,000
1106.1816.pdf.json,,,,rejected,000
1106.1817.pdf.json,,,Construct algebra: An analytical method for dialog | Megainduction: A test ight | Vector-based natural language call routing | Fast e ective rule induction | Learning trees and rules with set-valued features | Knowledge collection for natural language spoken | Incremental reduced error pruning | How May I Help You | Prosodic cues to recognition | Generalizing prosodic prediction | Detecting misrecognitions and cor | Identifying user corrections | A comparison of classi cation techniques for the automatic detection | Problem spotting | Prosodic correlates | Characterizing and recognizing spoken corrections in human-computer | Predicting automatic speech | Predicting and adapting to poor speech recognition | Automatic detection of poor speech | Spoken language adaptation over time and state | Human-machine problem solving using spo | Corrections in spoken dialogue | Learning optimal dialogue | Towards developing general models | PARADISE: A general | Using natural language processing | Computer Systems That Learn: Classi cation | Modelling Prosodic and Dialogue Information for Automatic Speech,rejected,000
1106.1818.pdf.json,,,,rejected,000
1106.1819.pdf.json,A Knowledge Compilation Map,"Knowledge compilation has emerged recently as a key direction of research for dealing with the computational intractability of general propositional reasoning (Darwiche, 1999; Cadoli & Donini, 1997; Boufkhad, Grégoire, Marquis, Mazure, & Säıs, 1997; Khardon & Roth, 1997; Selman & Kautz, 1996; Schrag, 1996; Marquis, 1995; del Val, 1994; Dechter & Rish, 1994; Reiter & de Kleer, 1987). According to this direction, a propositional theory is compiled off-line into a target language, which is then used on-line to answer a large number of queries in polytime. The key motivation behind knowledge compilation is to push as much of the computational overhead into the off-line phase, which is amortized over all on-line queries. But knowledge compilation can serve other important purposes as well. For example, target compilation languages and their associated algorithms can be very simple, allowing one to develop on-line reasoning systems for simple software and hardware platforms. Moreover, the simplicity of algorithms that operate on compiled languages help in streamlining the effort of algorithmic design into a single task: that of generating the smallest compiled representations possible, as that turns out to be the main computational bottleneck in compilation approaches. There are three key aspects of any knowledge compilation approach: the succinctness of the target language into which the propositional theory is compiled; the class of queries that can be answered in polytime based on the compiled representation; and the class of transformations that can be applied to the representation in polytime. The AI literature has thus far focused mostly on target compilation languages which are variations on DNF and CNF formulas, such as Horn theories and prime implicates. Moreover, it has focused mostly on clausal entailment queries, with very little discussion of tractable transformations on compiled theories. The goal of this paper is to provide a broad perspective on knowledg","Planning via model checking: a decision procedure for AR | Equivalence of free Boolean graphs can be decided probabilistically in polynomial time | An investigation of the laws of thought | Tractable cover compilations | Graph-based algorithms for Boolean function manipulation | Symbolic Boolean manipulation with ordered binary decision diagrams | A survey on knowledge compilation | Comparing space efficiency of propositional knowledge representation formalisms | On the number of prime implicants | Compiling knowledge into decomposable negation normal form | Decomposable negation normal form | On the tractability of counting theory models and its application to belief revision and truth maintenance | Testing equivalence probabilistically | An improved incremental algorithm for generating prime implicates | Directional resolution: the Davis-Putnam procedure, revisited | Tractable databases: How to make propositional unit resolution complete through compilation | Efficient analysis and manipulation of obdds can be extended to fbdds | On the complexity of analysis and manipulation of Boolean functions in terms of decision diagrams | The comparative linguistics of knowledge representation | Propositional belief base update and minimal change | Some connections between non-uniform and uniform complexity classes | Learning to reason | Propositional independence—Part I: formula–variable independence and forgetting | A new method to compute prime and essential prime implicants of boolean functions | Consequence finding algorithms, Vol | Knowledge compilation using theory prime implicates | Algorithms and Data Structures in VLSI Design: OBDD Foundations and Applications | Computational complexity | A way to simplify truth functions | On cores and prime implicants of truth functions | Foundations of assumption-based truth maintenance systems: Preliminary report | On the hardness of approximate reasoning | Knowledge compilation and theory approximation | The complexity of boolean functions",rejected,000
1106.1820.pdf.json,Inferring Strategies for Sentence Ordering in Multidocument News Summarization,"Multidocument summarization poses a number of new challenges over single document summarization. Researchers have already investigated issues such as identifying repetitions or contradictions across input documents and determining which information is salient enough to include in the summary (Barzilay, McKeown, & Elhadad, 1999; Carbonell & Goldstein, 1998; Elhadad & McKeown, 2001; Mani & Bloedorn, 1997; McKeown, Klavans, Hatzivassiloglou, Barzilay, & Eskin, 1999; Radev & McKeown, 1998; White, Korelsky, Cardie, Ng, Pierce, & Wagstaff, 2001). One issue that has received little attention is how to organize the selected information so that the output summary is coherent. Once all the relevant pieces of information have been selected across the input documents, the summarizer has to decide in which order to present them so that the whole text makes sense. In single document summarization, one possible ordering of the extracted information is provided by the input document itself. However, Jing (1998) observed that, in single document summaries written by professional summarizers, extracted sentences do not always retain their precedence orders in the summary. Moreover, in the case of multiple input documents, this does not provide a useful solution: information may be drawn from different documents and therefore, no single document can provide an ordering. Furthermore, the order between two pieces of information can change significantly from one document to another. In this paper, we provide a corpus based methodology for studying ordering. Our goal was to develop a good ordering strategy in the context of multidocument summarization c©2002 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved. targeted for the news genre. The first question we addressed is the importance of ordering. We conducted experiments which show that ordering significantly affects the reader’s comprehension of a text. Our experiments also show that although there is no single i","Information fusion in the context of multi-document summarization | Can text structure be incompatible with rhetorical structure | The use of mmr, diversity-based reranking for reordering documents and producing summaries | Learning to order things | Generating Referring Expressions: Constructing Descriptions in a Domain of Objects and Processes | Empirically estimating order constraints for content planning in generation | Generating patient specific summaries of medical articles | Assigning time-stamps to event-clauses | Cyclic ordering is np-complete | Reading Comprehension, chap. Coherence and Cohesive Harmony | Detecting text similarity over short passages: Exploring linguistic feature combinations via machine learning | Multi-paragraph segmentation of expository text | Automated discourse generation using discourse structure relations | Summary generation through intelligent cutting and pasting of the input document | Linear segmentation and segment relevence | Neats: A multidocument summarizer | Multi-document summarization by graph search and matching | Robust temporal processing of news | Focus of attention: Constraining what can be said next | Text Generation: Using Discourse Strategies and Focus Constraints to Generate Natural Language Text | Columbia multi-document summarization: Approach and evaluation | Towards multidocument summarization by reformulatin: Progress and prospects | The generation of high-level structure for extended explanations | Planning text for advisory dialogues: Capturing intentional and rhetorical information | Centroid-based summarization of multiple documents: sentence extraction, utility-based evaluation, and user studies | Generating natural language summaries from multiple on-line sources | Experiments in multidocument summarization | Non-Parametric statistics for the behavioural sciences | Multidocument summarization via information extraction | An empirical approach to temporal reference resolution",rejected,000
1106.1821.pdf.json,,,,rejected,000
1106.1822.pdf.json,Efficient Solution Algorithms for Factored MDPs,"Over the last few years, Markov Decision Processes (MDPs) have been used as the basic semantics for optimal planning for decision theoretic agents in stochastic environments. In the MDP framework, the system is modeled via a set of states which evolve stochastically. The main problem with this representation is that, in virtually any real-life domain, the state space is quite large. However, many large MDPs have significant internal structure, and can be modeled compactly if the structure is exploited in the representation. Factored MDPs (Boutilier, Dearden, & Goldszmidt, 2000) are one approach to representing large, structured MDPs compactly. In this framework, a state is implicitly described by an assignment to some set of state variables. A dynamic Bayesian network (DBN) (Dean & Kanazawa, 1989) can then allow a compact representation of the transition model, by exploiting the fact that the transition of a variable often depends only on a small number c©2003 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved. of other variables. Furthermore, the momentary rewards can often also be decomposed as a sum of rewards related to individual variables or small clusters of variables. There are two main types of structure that can simultaneously be exploited in factored MDPs: additive and context-specific structure. Additive structure captures the fact that typical large-scale systems can often be decomposed into a combination of locally interacting components. For example, consider the management of a large factory with many production cells. Of course, in the long run, if a cell positioned early in the production line generates faulty parts, then the whole factory may be affected. However, the quality of the parts a cell generates depends directly only on the state of this cell and the quality of the parts it receives from neighboring cells. Such additive structure can also be present in the reward function. For example, the cost of running the factor","Complexity of finding embeddings in a K-tree | A sufficiently fast algorithm for finding close to optimal clique trees | Polynomial approximation – a new computational technique in dynamic programming | Dynamic Programming | Nonserial Dynamic Programming | Decision theoretic planning: Structural assumptions and computational leverage | Approximating value trees in structured dynamic programming | Exploiting structure in policy construction | Stochastic dynamic programming with factored representations | Approximation Theory (2nd edition) | The linear programming approach to approximate dynamic programming | On constraint sampling for the linear programming approach to approximate dynamic programming | Planning with deadlines in stochastic domains | A model for reasoning about persistence and causation | Model minimization in Markov decision processes | Abstraction and approximate decision theoretic planning | Bucket elimination: A unifying framework for reasoning | Stable function approximation in dynamic programming | Max-norm projections for factored MDPs | Multiagent planning with factored MDPs | Solving factored POMDPs with linear value functions | Context specific multiagent coordination and planning with factored MDPs | SPUDD: Stochastic planning using decision diagrams | Stochastic planning using decision diagrams – C implementation. http://www.cs.ubc.ca/spider/staubin/Spudd | Influence diagrams | Decisions with Multiple Objectives: Preferences and Value Tradeoffs | Solving factored Mdps using non-homogeneous partitioning | Triangulation of graphs – algorithms giving small total state space | Computing factored value functions for policies in structured MDPs | Policy iteration for factored MDPs | Solving very large weakly-coupled Markov decision processes | Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference | Markov decision processes: Discrete stochastic dynamic programming | Finding approximate separators and computing tree-width quickly | Direct value-approximation for factored MDPs | Generalized polynomial approximations in Markovian decision processes | The Sciences of the Artificial (second edition) | How to dynamically merge Markov decision processes | APRICODD: Approximate policy construction using decision diagrams | Note on Jordan elimination, linear programming and Tchebycheff approximation | Learning to predict by the methods of temporal differences | Scaling up average reward reinforcmeent learning by approximating the domain models and the value function | Dynamic programming and influence diagrams | Feature-based methods for large scale dynamic programming | An analysis of temporal-difference learning with function approximation | Learning and Value Function Approximation in Complex Decision Processes | Tight performance bounds on greedy policies based on imperfect value functions | Generalized belief propagation | On the role of context-specific independence in probabilistic reasoning",rejected,000
1106.1853.pdf.json,"פ Algorithm: its past present, futue present and comments",,A relative deviation detection for time series | On classification from the view of outlier,rejected,000
1106.2489.pdf.json,Eliciting Forecasts from Self-interested Experts: Scoring Rules for Decision Makers,"Eliciting predictions of uncertain events from experts or other knowledgeable agents—or relevant information pertaining to events— is a fundamental problem of study in statistics, economics, operations research, artificial intelligence and a variety of other areas [16, 5]. Increasingly, robust mechanisms for prediction are being developed, proposed and/or applied in real-world domains ranging from elections and sporting events, to events of public interest (e.g., disease spread or terrorist action), to corporate decision making. Indeed, the very idea of crowd-sourcing and information (or prediction) markets is predicated on the existence of practical mechanisms for information elicitation and aggregation. A key element in any prediction mechanism involves providing an expert agent with the appropriate incentives to reveal a forecast they believe to be accurate. Many forms of “outcome-based” scoring rules, either individual or market-based, provide experts with incentives to (a) provide sincere forecasts; (b) invest effort to improve the accuracy of their personal forecasts; and (c) participate Working Paper in the mechanism if they believe they can improve the quality of the principal’s forecast. However, with just a few exceptions (see, e.g., [15, 13, 3, 7], most work fails to account for the ultimate use to which the forecast will be put. Furthermore, even these models assume that the experts who provide their forecasts derive no utility from the final forecast, or how it will be used, except insofar as they will be rewarded by the prediction mechanism itself. In many real-world uses of prediction mechanisms, this assumption is patently false. Setting aside purely informational and entertainment uses of information markets, the principal is often interested in exploiting the elicited forecast in order to make a decision [10, 13, 3]. In corporate prediction markets, the principal may base strategic business decisions on internal predictions of uncertain events. In ",Convex Optimization | Verification of forecasts expressed in terms of probability | Information elicitation for decision making | A utility framework for bounded-loss market makers | Prediction markets | Prediction markets | Non-myopic strategies in prediction markets | Strictly proper scoring rules | Combinatorial information market design | Decision markets | Logarithmic market scoring rules for modular combinatorial information aggregation | Measures of the value of information | Decision rules and decision markets | Elicitation of personal probabilities and expectations | Prediction mechanisms that do not incentivize undesirable actions | Prediction markets,rejected,000
1106.2647.pdf.json,From Causal Models To Counterfactual Structures,"Counterfactual reasoning arises in broad array of fields, from statistics to economics to law. Not surprisingly, there has been a great deal of work on giving semantics to counterfactuals. Perhaps the best-known approach is due to Lewis [1973] and Stalnaker [1968], and involves possible worlds. The idea is that a counterfactual of the form “if A were the case then B would be the case”, typically written A B, is true at a world w if B is true at all the worlds closest to w where A is true. Of course, making this precise requires having some notion of “closeness” among worlds. More recently, Pearl [2000] proposed the use of causal models based on structural equations for reasoning about causality. In causal models, we can examine the effect of interventions, and answer questions of the form “if random variable X were set to x, what would the value of random variable Y be”. This suggests that causal models can also provide semantics for (at least some) counterfactuals. The relationship between the semantics of counterfactuals in causal models and in counterfactual structures (i.e., possible-worlds structures where the semantics of counterfactuals is given in terms of ∗A preliminary version of this paper appears in the Proceedings of the Twelfth International Conference on Principles of Knowledge Representation and Reasoning (KR 2010), 2010. †Supported in part by NSF grants IIS-0534064, IIS-0812045, and IIS-0911036, and by AFOSR grants FA9550-08-1-0438 and FA9550-09-1-0266, and ARO grant W911NF-09-1-0281. closest worlds) was studied by Galles and Pearl [1998]. They argue that the relationship between the two approaches depends in part on whether we consider recursive (i.e., acyclic) models (those without feedback—see Section 2 for details). They reach the following conclusion [Pearl 2000, p. 242].1 In sum, for recursive models, the causal model framework does not add any restrictions to counterfactuals beyond those imposed by Lewis’s framework; the very general concept ","The logic of nonmonotonicity | Quick completeness proofs for some logics of conditionals | Basic conditional logic | On the complexity of conditional logics | An axiomatic characterization of causal counterfactuals | Updates and counterfactuals | Axiomatizing causal reasoning | Causes and explanations: A structural-model approach | A unified view of consequence relation, belief revision and conditional logic | Nonmonotonic reasoning, preferential models and cumulative logics | Completeness and decidability of three logics of counterfactual conditionals | Counterfactuals | Intensional logics without iterative axioms | Causality: Models, Reasoning, and Inference | A semantic analysis of conditional logic | A Lewisian logic of causal counterfactuals | A peculiarity in Pearl’s logic of interventionist counterfactuals",rejected,000
1106.2652.pdf.json,,"In The Graduate, Benjamin Braddock (Dustin Hoffman) is told that the future can be summed up in one word: “Plastics”. One of us (Halpern) recalls that in roughly 1990, Judea Pearl told him that the future was in causality. Pearl’s own research was largely focused on causality in the years after that; his seminal contributions are widely known. We were among the many influenced by his work. We discuss one aspect of it, actual causation, in this article, although a number of our comments apply to causal modeling more generally. Pearl introduced a novel account of actual causation in Chapter 10 of Causality, which was later revised in collaboration with one of us [Halpern and Pearl 2005]. In some ways, Pearl’s approach to actual causation can be seen as a contribution to the philosophical project of trying to analyze actual causation in terms of counterfactuals, a project associated most strongly with David Lewis [1973a]. But Pearl’s account was novel in at least two important ways. The first was his use of structural equations as a tool for modeling causality. In the philosophical literature, causal structures were often represented using so-called neuron diagrams, but these are not (and were never intended to be) all-purpose representational tools. (See [Hitchcock 2007b] for a detailed discussion of the limitations of neuron diagrams.) We believe that the lack of a more adequate representational tool had been a serious obstacle to progress. Second, while the philosophical literature on causality has focused almost exclusively on actual causality, for Pearl, actual causation was a rather specialized topic within the study of causation, peripheral to many issues involving causal reasoning and inference. Thus, Pearl’s work placed the study of actual causation within a much broader context. The use of structural equations as a model for causal relationships was well known long before Pearl came on the scene; it seems to go back to the work of Sewall Wright in the 1920s (","The Logic of Conditionals | Culpable causation | Event causation: the counterfactual analysis | The role of moral judgment in causal and intentional attribution: What we say or how we think? | Moral appraisals affect doing/allowing judgments | Causal relations | Actual causes and thought experiments | Structural equation methods in the social sciences | Two concepts of causation | Structural equations and causation | Defaults and normality in causal structures | Causes and explanations: A structural-model approach | Patterns of Discovery | Causation in the Law (second ed.) | Causal powers | The intransitivity of causation revealed in equations and graphs | Prevention, preemption, and the principle of sufficient reason | What’s wrong with neuron diagrams? In J | Trumping and contrastive causation | Cause and norm | A Treatise of Human Nature | An Enquiry Concerning Human Understanding | Norm theory: comparing reality to its alternatives | The simulation heuristic | Causes, nomic subsumption, and the concept of event | Causal judgment and moral judgment: two experiments | Nonmonotonic reasoning, preferential models and cumulative logics | Causation | Causation | Events | Counterfactuals | The Psychology of Counterfactual Thinking | Causality: Models, Reasoning, and Inference | Counterfactual thinking | Trumping preemption | Dependency equilibria and the causal structure of decision and game situations | A survey of ranking theory | Making Things Happen: A Theory of Causal Explanation",rejected,000
1106.2662.pdf.json,Learning Equilibria with Partial Information in Decentralized Wireless Networks,,"The Theory of Learning in Games, ser | Strategic learning and its limits (arne ryde memorial lectures sereis) | Game theory | Methodologies for analyzing equilibria in wireless games | How can ignorant but patient cognitive terminals learn their strategy and utility? | Game Theory and the Flat-Fading Gaussian Interference Channel: Analyzing Resource Conflicts in Wireless Networks | Game theory and the frequency selective interference channel - a tutorial | Optimal linear precoding strategies for wideband non-cooperative systems based on game theory – part II: Algorithms | Decentralized learning of Nash equilibria in multi-person stochastic games with incomplete information",rejected,000
1106.2692.pdf.json,Generating Schemata of Resolution Proofs,,A schemata calculus for propositional logic | A Decidable Class of Nested Iterated Schemata | Decidability and undecidability results for propositional schemata | Cut-elimination and Redundancy-elimination by Resolution | Towards understanding and harnessing the potential of clause learning | A simple and flexible way of computing small unsatisfiable cores in SAT modulo theories | The resolution calculus | Automatic abstraction without counterexamples | Proof theory in the USSR 1925-1969 | First-Order Logic | Optimization and translation of tableau-proofs into resolution | Validating SAT Solvers Using an Independent Resolution- Based Checker: Practical Implementations and Other Applications,rejected,000
1106.3457.pdf.json,,"The two most prominent declarative paradigms, namely logic and functional programming, differ radically in an important aspect: logic programming is traditionally first-order while functional programming encourages and promotes the use of higher-order functions and constructs. One problem is that even second-order logic fails in terms of vital properties such as completeness and compactness. It would seem, on the face of it, that there would be no hope of finding a complete resolution proof procedure for higher-order logic programming. The initial attitude of logic programmers towards higher-order logic programming was somewhat skeptical: it was often argued (see for example [War82]) that there exist ways of encoding or simulating higher-order programming inside Prolog itself. However ease of use is a primary criterion for a programming language, and the fact that higher-order features can be simulated or encoded does not mean that it is practical to do so. ∗An early version of this paper appears in: A. Charalambidis, K. Handjopoulos, P. Rondogiannis, W. W. Wadge. Extensional Higher-Order Logic Programming. Proceedings of the 12th European Conference on Logics in Artificial Intelligence (JELIA). LNCS 6341, Springer, pages 91-103, 2010. †The research of A. Charalambidis has been co-financed by the European Union (European Social Fund - ESF) and Greek national funds through the Operational Program “Education and Lifelong Learning” of the National Strategic Reference Framework (NSRF) - Research Funding Program: Heracleitus II. Investing in knowledge society through the European Social Fund. Eventually extensions with genuine higher-order capabilities were introduced - roughly speaking, extensions which allow predicates to be applied but also passed as parameters. The two most prominent such languages are λProlog [MN86, Nad87] and HiLog [CKW89, CKW93]. These two systems share a common idea, namely they are both intensional. Intuitively speaking, an intensional language ",Domain theory | Logic Programming | The Lambda Calculus: Its Syntax and Semantics | Extensionality of Simply Typed Logic Programs | An Improved Extensionality Criterion for Higher-Order Logic Programs | Lattice Theory | HiLog as a Platform for Database Languages | HILOG: A Foundation for Higher-Order Logic Programming | Predicate Logic as a Computational Formalism | Functional Programming | General Lattice Theory | LUSH-Resolution and its Completeness | Introduction to Combinators and λ-calculus | Extensional Higher-Order Datalog | Foundations of Logic Programming | Higher Order Logic Programming | A Higher-Order Logic as the Basis for Logic Programming | Higher-Order Horn Clauses | Higher-Order Logic Programming | Minimum Model Semantics for Logic Programs with Negation-as-Failure | Denotational Semantics: the Scott-Strachey Approach to Programming Language Theory | Semantics of Programming Languages | Higher-Order Horn Logic Programming | Higher-Order Extensions to Prolog: are they needed? Machine Intelligence,rejected,000
1106.3498.pdf.json,On the expressive power of unit resolution,"Unit resolution is a key feature of state of the art sat solvers [13] [7] [5], where it speeds up the search for solutions and inconsistencies. It is well known that different cnf representations of a given problem do not always allow unit resolution to deduce the same information. For example, the cnf encoding for pseudo Boolean constraints proposed in [3] allows unit resolution to restore generalized arc consistency. This is not the case with the encoding proposed in [16], which does not allow unit resolution to deduce as much information as the former encoding does. As a manner of speaking, the expressive power of unit resolution is best exploited using the encoding proposed in [3], with notable consequences on the resolution time. Two important related questions are ""What information can be deduced by unit resolution?"" and ""Which clauses are required in order to allow this information to be deduced?"" These questions are strongly connected to the characterization of the application field of sat solvers: ""Which problems can be solved as efficiently using a sat solver as using a specialized solver?"" and ""How to encode these problems into cnf formulae for optimal resolution time?"" In this paper, we are interested in the functions that can be calculated by means of unit resolution. Studying the expressive power of unit resolution requires characterizing these functions, which will be called propagatable functions, and specifying the size of the formulae required to compute them. Section 2 presents the three main research directions related to the expressive power of unit resolution. Section 3 introduces the concept of propagators and propagatable functions as a formal framework where unit resolution is a computing model. This section also presents theoretical results that will be used in section 4, where the expressive power of unit resolution is compared to the one of monotone Boolean circuits. Section 5 ends the paper with a synthesis of the results, which highligh",GAC via unit propagation | Efficient cnf encoding of boolean cardinality constraints | A translation of pseudo boolean constraints to sat | New encodings of pseudo-boolean constraints into cnf | An extensible sat-solver | Arc consistency in sat | Berkmin: A fast and robust sat solver | The monotone and planar circuit value problems are log space complete for p | Unit refutations and horn sets | Complete problems for deterministic polynomial time | Look-ahead versus look-back for satisfiability problems | Towards robust cnf encodings of cardinality constraints | Chaff: Engineering an efficient sat solver | Towards an optimal cnf encoding of boolean cardinality constraints | The gap between the monotone and non monotone circuit complexity is exponential | A linear-time transformation of linear inequalities into conjunctive normal form,rejected,000
1106.3876.pdf.json,Uncertainty in Ontologies: Dempster-Shafer Theory for Data Fusion Applications,,"Introduction to the Semantic Web and Semantic Web Services | Use Cases for Ontologies in Information Fusion, Information Fusion | Ontologies and Probabilities: Working Together for Effective Multi-INT Fusion, International Ontology for the Intelligence | Jena: A Semantic Web Toolkit | BayesOWL: Uncertainty Modelling in Semantic Web Ontologies, book | Pronto: a Non-Monotonic Probabilistic Description Logic Reasoner | Probabilistic Ontologies for Knowledge Fusion, Information | FiRE: A Fuzzy Reasoning Engine for Imprecise Knowledge, K-Space | fuzzyDL: An Expressive Fuzzy Description Logic Reasoner | A Mathematical Theory of Evidence | Fusion adaptée d’informations conflictuelles dans le cadre de la théorie de l’évidence, thesis presented at the Institut | Modélisation comportementale en fusion de données | Uncertain Reasoning for Creating Ontology | BeliefOWL: An Evidential Representation in OWL Ontology, pages 77-80 | SWRL: A semantic web rule language combining OWL and RuleML | Rule Interchange Format: The Framework",rejected,000
1106.3932.pdf.json,Coincidences and the Encounter Problem: A Formal Account,,"The base-rate fallacy in probability judgments | On the intelligibility of the universe and the notions of simplicity, complexity and irreducibility | The search for simplicity: A fundamental cognitive principle | Simplicity: a unifying principle in cognitive science | Men talk | Analogie, principe d'économie et complexité algorithmique | A structural model of intuitive probability | Methods for studying coincidences | Judgment of coincidences: Mine versus yours | How surprising is a simple pattern? Quantifying 'Eureka! | Randomness and coincidences: Reconciling intuition and probability theory | Probability, algorithmic complexity, and subjective randomness | Subjective probability: A judgement of representativeness | Using the list of creepy coincidences as an educational opportunity | An introduction to Kolmogorov complexity and its applications | A mathematical theory of communication | Complexity and the representation of patterned sequences of symbols | Complexity-based induction systems: Comparisons and convergence theorems | The discovery of algorithmic probability | Availability: A heuristic for judging frequency and probability | Support theory: A nonextensional representation of subjective probability | Modern news reporting | Probability, rarity, interest, and surprise",rejected,000
1106.3967.pdf.json,,"The actual panorama of distribution of information through the Web depicts a clear situation: there is an incredible amount of data delivered under the form of Web data sources and a corresponding need of capability of mining this information in a reliable and efficient way. Mining information from Web sources is a task which can obviously be useful in several different area of the knowledge. Moreover, this topic interests both the academia and the enterprises. For example, consider the following scenarios: i) a research group which needs to acquire a dataset of information delivered through online services, say for example an online database publishing, day by day, information about the mapping of some genes; ii) a company for which it is essential, for marketing and product placement, to monitor the trends of pricing of services offered by its competitors, provided through the Web. Both the two actors need to extract, possibly, a huge amount of data during an extend period of time (e.g., months), at regular intervals (say, each day). One important aspect in both the cases is the reliability and the quality of data extracted. It is utterly important that acquired information is correct, because the research group can not accept corrupted data and the comparison with competitors would fail in case of bad product data. These two examples highlight common requirements in the panorama of Web data mining, and depict different related problems. Although in literature some techniques to design systems for the extraction of data from Web sources have been presented, there is a lack of work in the area of their maintenance. An ample number of questions and problems related to the possibility of automatizing the process of maintenance are still uncovered. This work tries to focus on some aspects related to the maintenance of these systems. We first introduce the theoretical background required to create intelligent procedures of Web data extraction. Then, we explain how to f","Web data extraction system | Scalable web data extraction for online market intelligence | A survey on tree edit distance and related problems | Automatic repairing of web wrappers by combining redundant views | A machine learning approach to web mining | Automatic wrapper adaptation by tree edit distance matching | Design of automatically adaptable web wrappers | Web data extraction, application and techniques: A survey | Web information extraction by HTML tree edit distance matching | Wrapper verification | Finite-state approaches toWeb information extraction | Regression testing for wrapper maintenance | A brief survey of web data extraction tools | Wrapper maintenance: A machine learning approach | Schema-guided wrapper maintenance for web-data extraction | Automatically generating labeled examples for web wrapper maintenance | Information extraction | The tree-to-tree editing problem | Identifying syntactic differences between two programs",rejected,000
1106.4083.pdf.json,Symmetry-Based Search Space Reduction For Grid Maps,"Pathfinding on uniform-cost undirected grid maps is a problem commonly appearing in the literature: for example in application areas such as robotics [7] artificial intelligence [12] and video games [3, 11]. In such contexts it is often the case that queries sent to the pathfinding system need to be solved as quickly as possible. Traditionally, this requirement is met through the application of hierarchical decomposition techniques that transform the search space into a much smaller approximate representation [2, 11]. Such methods are very fast, particularly when compared to the classical A* algorithm, but have the disadvantage that solutions found in the abstract state space are often not optimal when mapped back to the original grid. An alternative speedup method is to develop better heuristics to guide the search [1, 10, 5]. Though usually fast, optimal and more effective than the popular Manhattan or Octile heuristic (both analogous to Euclidean distance but optimised to 4 and 8-connected grids), they have the disadvantage of requiring significant memory overhead. In this paper we present Rectangular Symmetry Reduction (RSR): a graph pruning algorithm for undirected uniform-cost grid maps which is fast, memory efficient, optimality preserving and which can, in some cases, eliminate entirely the need to search. 1 ar X iv :1 10 6. 40 83 v1 [ cs .A I] 2 2 The central idea that we will explore involves the identification and elimination of path symmetries from the search space. To deal with path symmetries RSR makes use of an off-line empty rectangle decomposition [6] that converts an arbitrary undirected uniform-cost grid map into an equivalent one where only nodes from the perimeter of each empty rectangle need to be explored during search. We extend this approach in several directions: (i) we generalise the method from 4-connected grid maps to the 8-connected case where the increase in branching factor makes effective symmetry elimination more challenging; (ii) w",Improved heuristics for optimal path-finding on game | Near optimal hierarchical path-finding | Warp speed: Path planning for Star Trek Armada | Contraction hierarchies: Faster and simpler hierarchical routing in road networks. In: WEA | Portal-based truedistance heuristics for path finding | Breaking path symmetries in 4-connected grid maps | A coarse-to-fine approach for fast path finding for mobile robots | Search space reduction using swamp hierarchies | Handbook of Constraint Programming | Memory-based heuristics for explicit state spaces | A comparison of high-level approaches for speeding pathfinding | Tractable multi-agent path planning on grid maps,rejected,000
1106.4090.pdf.json,,"By allowing a developer to incrementally introduce design details, refinement provides a powerful mechanism for mastering the complexities that arise when formally modelling systems. This benefit comes with proof obligations (POs) – the task of proving the correctness of each refinement step. Discharging such proof obligations typically requires a developer to supply properties – properties that relate to their design decisions. Ideally automation should be provided to support the discovery of such properties, allowing the developer to focus on design decisions rather than analysing failed proof obligations. With this goal in mind, we have developed a heuristic approach for the automatic discovery of invariants in order to support the formal modelling of systems. Our approach, shown in Figure 1, involves three components: • a simulation component that generates system traces, • an Automatic Theory Formation (ATF) component that generates conjectures from the analysis of the traces and, • a formal modelling component that supports proof and proof failure analysis. Crucially, proof and proof failure analysis is used to tailor the theory formation component. From a modelling perspective we have focused on Event-B [1] and the Rodin tool-set [2], in particular we have used the ProB animator plug-in [14] for the simulation component. In terms of ATF, we have used a general-purpose system called HR [4]. Generating invariants from the analysis of ProB animation traces is an approach analogous to that of the Daikon system [9]; however, while Daikon is tailored for programming languages here we focus on formal models. We come back to this in §6. ∗The research reported in this paper is supported by EPSRC grants EP/F037058 and EP/F035594. †Maria Teresa Llano is partially funded by a BAE Systems studentship. Our investigation involved a series of experiments, drawing upon examples which include Abrial’s “Cars on a Bridge” [1] and the Mondex case study by Butler et al. [3] . Our ","Modeling in Event-B - System and Software Engineering | Rodin: an open toolset for modelling and reasoning in Event-B | An incremental development of the Mondex system in Event-B | Automated Theory Formation in Pure Mathematics | Constraint Generation via Automated Theory Formation | The Daikon system for dynamic detection of likely invariants | Reasoned Modelling Critics: Turning Failed Proofs into Modelling Guidance | Case-Analysis for Rippling and Inductive Proof | AM: An Artificial Intelligence approach to discovery in mathematics | Eurisko: A program which learns new heuristics and domain concepts | ProB: A Model Checker for B | Automatic Guidance for Refinement Based Formal Methods. 5th workshop on Automated Formal Methods (AFM‘10), a satellite workshop of the 22nd International Conference on Computer Aided Verification (CAV‘10) | Refinement and Term Synthesis in Loop Invariant Generation. In: 2nd International Workshop on Invariant Generation (WING’09), a satellite workshop of ETAPS’09 | Automated Discovery of Inductive Theorems. In: From Insight to Proof: Festschrift in Honour of Andrzej Trybulec, Studies in Logic, Grammar and Rhetoric | Employing Theory Formation to Guide Proof Planning. In: AISC/Calculemus’02 | Scheme-Based Synthesis of Inductive Theories | Applying Lakatos-style reasoning to AI problems. In: Thinking Machines and the philosophy of computer science: Concepts and principles | AM: a case study in methodology | UML-B: Formal modeling and design aided by UML",rejected,000
1106.4218.pdf.json,Rooting opinions in the minds: a cognitive model and a formal account of opinions and their dynamics,"The studies about opinions, persuasion and social influence are foundational and pressing issues in social psychology; however, within this discipline, the dynamics of opinions at the level of population has been underestimated. There are also other disciplines that have shown a great interest regarding such an issue, ranging from political science ([17]) passing through socio-physics ([7]) up to complexity science ([18]). Understanding opinions, describing how they are generated and revised, and how fare opinions travel over the social space both as a consequence of social influence and as one of the main means through which social influence unfolds, is crucial for grasping a deeper understanding of human social cognition and behaviors. Investigating opinions requires to take into account two levels of explanation: the individual and the social level. Social psychology has been mainly interested in explaining this first level, trying to describe the complex interplay of affective, cognitive and behavioral aspects that make opinions emerge. On the other hand, scholars from computer science and physics have tried to explain how different opinions can coexist or how they are modified through social interactions, treating opinions as objects that are exchanged and revised according to certain mechanisms that are quite far from the reality of cognitive and social processes. In both cases there is a reductionist fallacy that works in apparently different ways but it affects both 1 Department of Cognitive Science, Central European University, Budapest, Hungary, email: GiardiniF@ceu.hu 2 University of Siena, Italy, email: walter.quattrociocchi@unisi.it 3 ISTC-CNR, Rome, Italy, email:rosaria.conte@istc.cnr.it these approaches, leading them to treat opinions either as a set of unrelated specific elements or as a unidimensional object that has nothing in common with a cognitive representation. We claim that opinions are highly dynamical representations resulting from the inte","Situating social influence processes: Dynamic, multidirectional flows of influence within social networks | From private attitude to public opinion: A dynamic theory of social impact | Readings in attitude theory and measurement, chapter Attitude, pages 1–13 | Multicolored dynamos on toroidal meshes | Dynamic monopolies in colored tori | Bugie, finzioni e sotterfugi. Per una scienza dell’inganno | Statistical physics of social dynamics | Timevarying graphs and dynamic networks | The public opinion process | Mixing beliefs among interacting agents | Social Pressures in Informal Groups: A Study of Human Factors in Housing | Attitude: The history of a concept | A cognitive-social theory of public opinion: Dynamic impact and cognitive structure | Discrete opinion dynamics on networks based on social influence | Attitudes and attitude change | The psychology of social impact | Public opinion | Continuous opinion dynamics of multidimensional allocation problems under bounded confidence: More dimensions lead to better chances for consensus | The vicissitudes of attitudes and similar representational constructs in twentieth century psychology | Belief, Attitude, Intention, and Behavior: An Introduction to Theory and Research | Communication concepts 4: Public opinion | Emergence through selection: The evolution of a scientific challenge | Selection in scientific networks | Simulating opinion dynamics in heterogeneous communication systems | Attitudes and attitude change | Time varying graphs and social network analysis: Temporal indicators and metrics",rejected,000
1106.4221.pdf.json,,"Opinions represent a conspicuous part of our mental representations. A large part of our social time is spent in exchanging, evaluating, revising and comparing our opinions. We also say, about many different issues, that we have opinions and we try to convince others about the groundedness of our own opinions. Since the beginning of the last century, social psychologists have been interested in understanding the specificity of opinions, as compared to other kinds of mental representations, by focusing their attention on the multiplicity of dimensions, including attitudes, beliefs ∗Central European University, Hungary email: GiardiniF@ceu.hu †University of Siena, Italy email: walter.quattriocchi@unisi.it ‡Labss-ISTC-CNR, Italy email: rosaria.conte@istc.cnr.it 1 and evaluations, that take part within this phenomenon. Also political science has always been very attentive to what is considered as a way to measure people’s preferences and beliefs about publicly relevant issues. Many of these contributions have been directed towards understanding the so-called public opinion and the processes through which it is possible to influence it, manipulating people’s awareness and tendencies ([18]). More recently, other disciplines have shown a great interest regarding such an issue, ranging from computer science passing through socio-physics ([7, 13]) up to complexity science ([19]). Despite the large amount of studies on opinions, the term itself and the underlying concept are poorly specified and too general, since there are at least two classes of mental representations that can be termed opinions but they differ with regard to important aspects. Moreover, relevant contributions coming from social psychology and computer science try to model distinct issues, thus making the analysis of opinions quite difficult. This lack of sound theoretical contributions is often compensated by giving more preeminence to transmission and communication processes, thus partially putting aside ","Situating social influence processes: Dynamic, multidirectional flows of influence within social networks | From private attitude to public opinion: A dynamic theory of social impact | Readings in attitude theory and measurement, chapter Attitude, pages 1–13 | Multicolored dynamos on toroidal meshes | Dynamic monopolies in colored tori | Bugie, finzioni e sotterfugi. Per una scienza dell’inganno | Statistical physics of social dynamics | Time-varying graphs and dynamic networks | The public opinion process | Mixing beliefs among interacting agents | Social Pressures in Informal Groups: A Study of Human Factors in Housing | Attitude: The history of a concept | Sociophysics: A review of galam models | A cognitive-social theory of public opinion: Dynamic impact and cognitive structure | Discrete opinion dynamics on networks based on social influence | Attitudes and attitude change | The psychology of social impact | Public opinion | Continuous opinion dynamics of multidimensional allocation problems under bounded confidence: More dimensions lead to better chances for consensus | The vicissitudes of attitudes and similar representational constructs in twentieth century psychology | Belief, Attitude, Intention, and Behavior: An Introduction to Theory and Research | Communication concepts 4: Public opinion | Emergence through selection: The evolution of a scientific challenge | Selection in scientific networks | Simulating opinion dynamics in heterogeneous communication systems | Attitudes and attitude change | Time varying graphs and social network analysis: Temporal indicators and metrics. SNA- MAS",rejected,000
1106.4557.pdf.json,Learning When Training Data are Costly: The Effect of Class Distribution on Tree Induction,"In many real-world situations the number of training examples must be limited because obtaining examples in a form suitable for learning may be costly and/or learning from these examples may be costly. These costs include the cost of obtaining the raw data, cleaning the data, storing the data, and transforming the data into a representation suitable for learning, as well as the cost of computer hardware, the cost associated with the time it takes to learn from the data, and the “opportunity cost” associated with suboptimal learning from extremely large data sets due to limited computational resources (Turney, 2000). When these costs make it necessary to limit the amount of training data, an important question is: in what proportion should the classes be represented in the training data? In answering this question, this article makes two main contributions. It addresses (for classification-tree induction) the practical problem of how to select the class distribution of the training data when the amount of training data must be limited, and, by providing a detailed empirical study of the effect of class distribution on classifier performance, it provides a better understanding of the role of class distribution in learning. Some practitioners believe that the naturally occurring marginal class distribution should be used for learning, so that new examples will be classified using a model built from the same underlying distribution. Other practitioners believe that the training set should contain an increased percentage of minority-class examples, because otherwise the induced classifier will not classify minority-class examples well. This latter viewpoint is expressed by the statement, “if the sample size is fixed, a balanced sample will usually produce more accurate predictions than an unbalanced 5%/95% split” (SAS, 2001). However, we are aware of no thorough prior empirical study of the relationship between the class distribution of the training data and classifier p","An empirical comparison of voting classification algorithms: bagging, boosting, and variants | Classification and Regression Trees | UCI Repository of Machine Learning Databases, (http://www.ics.uci.edu/~mlearn/MLRepository.html), Department of Computer Science, University of California | The use of the area under the ROC curve in the evaluation of machine learning algorithms | Pruning decision trees with misclassification costs | Megainduction: machine learning on very large databases | Toward scalable learning with non-uniform class and cost distributions: a case study in credit card fraud detection | SMOTE: synthetic minority over-sampling technique | A simple, fast, and effective rule learner | Improved generalization with active learning | Exploiting the cost (in)sensitivity of decision tree splitting criteria | The foundations of cost-sensitive learning | A Mixture-of-Experts Framework for ConceptLearning from Imbalanced Data Sets | Adaptive Fraud Detection | The Estimation of Probabilities | Construction and Assessment of Classification Rules | Concept learning and the problem of small disjuncts | The Class Imbalance Problem: A Systematic Study | In Papers from the AAAI Workshop on Learning from Imbalanced Data Sets | Multiple comparisons in induction algorithms | Static versus dynamic sampling for data mining | Addressing the curse of imbalanced training sets: one-sided selection | Heterogeneous uncertainty sampling for supervised learning | The case against accuracy estimation for comparing classifiers | Efficient progressive sampling | Robust classification for imprecise environments | Well-trained PETs: improving probability estimation trees | C4.5: Programs for Machine Learning | Active learning for class probability estimation and ranking | Active Sampling for Class Probability Estimation and Ranking | Getting Started With SAS Enterprise Miner | Adjusting the outputs of a classifier to new a priori probabilities: a simple procedure | Better decisions through science | Types of cost in inductive learning | When small disjuncts abound, try lazy learning: a case study | A quantitative study of small disjuncts | The effect of class distribution on classifier learning: an empirical study | Learning and making decisions when costs and probabilities are both unknown",rejected,000
1106.4561.pdf.json,pddl2.1 : An Extension to pddl for Expressing Temporal Planning Domains,"In 1998 Drew McDermott released a Planning Domain Description Language, pddl (McDermott, 2000; McDermott & the AIPS-98 Planning Competition Committee, 1998), which has since become a community standard for the representation and exchange of planning domain models. Despite some dissatisfaction in the community with some of the features of pddl the language has enabled considerable progress to be made in planning research because of the ease with which systems sharing the standard can be compared and the enormous increase in availability of shared planning resources. The introduction of pddl has facilitated the scientific development of planning. Since 1998 there has been a decisive movement in the research community towards application of planning technology to realistic problems. The propositional puzzle domains of old are no longer considered adequate for demonstrating the utility of a planning system — modern planners must be able to reason about time and numeric quantities. Although several members of the community have been working on applications of planning to real domains of this nature for some time (Laborie & Ghallab, 1995; Ghallab & Laruelle, 1994; Muscettola, 1994; Drabble & Tate, 1994; Wilkins, 1988) there has always been a gap c©2003 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved. between the modelling requirements of such domains and what can be expressed in pddl. Application-driven planners come equipped with their own modelling conventions and black arts and, as a consequence, it is difficult to reproduce their results and to make empirical comparisons with other approaches, both of which are essential for scientific progress to be made. The pddl language provides the foundation on which an expressive standard can be constructed, enabling the domain models of the applications-driven community to be shared and motivating the development of the planning field towards realistic application. The third International Planning Comp",,rejected,000
1106.4569.pdf.json,,,,rejected,000
1106.4570.pdf.json,Competitive Safety Analysis: Robust Decision-Making in Multi-Agent Systems,"Deriving solution concepts for multi-agent encounters is a major challenge for researchers in various disciplines. The most famous and popular solution concept in the economics literature is the Nash equilibrium. Although Nash equilibrium and its extensions and modifications are powerful descriptive tools, and have been widely used in the AI literature (Rosenschein & Zlotkin, 1994; Kraus, 1997; Sandholm & Lesser, 1995), their appeal from a normative AI perspective is somewhat less satisfactory.1 We wish to equip an agent with an action that guarantees some desired outcome, or expected utility, without relying on other agents’ rationality.2 This paper shows that, surprisingly, the desire for obtaining a guaranteed expected payoff, where this payoff is of the order of the value obtained in a 1. If we restrict ourselves to cases where there exists an equilibrium in dominant strategies, as is done in some of the CS literature (Nisan & Ronen, 1999), then the corresponding equilibrium is appealing from a normative perspective. However, such cases rarely exist. 2. Maximizing expected payoff when facing a set of possible environment behaviors is fundamental to AI. In particular, it is discussed in the context of game trees, in the context of planning with incomplete information, where we need to obtain a desired goal regardless of the initial configuration, as well as in the context of reinforcement learning, where we wish to maximize expected payoff when the actual model (selected from a set of possible models in adversarial way) is initially unknown. (Russell & Norvig, 1995). c©2002 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved. Nash equilibrium, is achievable in various classical computer science settings. Our results are inspired by several interesting examples for counter-intuitive behaviors obtained by following Nash equilibria and other solution concepts (Roth, 1980; Aumann, 1985). One of the most interesting and challenging examples has be",On the non-transferable utility value: A comment on the Roth-Shaper | On-Line Computation and Competitive Analysis | Worst-Case Equilibria. In STACS | Negotiation and cooperation in multi-agent environments | Algorithmic mechanism design | Rules of Encounter | Values for games without side payments: Some difficulties with current concepts | Artificial Intelligence: A Modern Approach | Rational Competitive Analysis,rejected,000
1106.4573.pdf.json,,,,rejected,000
1106.4575.pdf.json,,,,rejected,000
1106.4576.pdf.json,,,,rejected,000
1106.4577.pdf.json,Interactive Execution Monitoring of Agent Teams,"As automation and reliable, high-bandwidth communication networks become more common, humans are increasingly responsible for monitoring and controlling the activity of distributed teams of cooperating agents, both human and machine. Such control decisions in many realistic domains are complex, and require human experience and judgment. Our vision is that human decision makers will be able to perform more important tasks than continuously monitoring incoming information by relying on an automated execution aid to alert them when significant new information warrants their attention. We are primarily interested in domains requiring human control and will describe two such domains. However, the majority of our techniques and analysis also apply to completely automated execution monitoring. In fact, in one of our domains we both interact with a human controller and autonomously adjust robot behavior and plans. To rapidly make effective control decisions for distributed agent teams, the human needs automated support, for several reasons. First, inexpensive sensors and reliable, high-bandwidth communication networks provide large volumes of pertinent data arriving from sensors, team members, c©2003 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved. and other sources. Without automated support, the human cannot cope with the volume of incoming information. Second, plans that coordinate the activity of several team members, as many as several hundred in our first domain, can become too complex to monitor without automated help. Third, we are addressing domains that are dynamic, sometimes requiring responses in a few seconds or less. Fourth, the automated team members (robots) are complex, with different failure modes and recovery procedures, and automated support for controlling them is often essential. All these challenges are magnified as the tempo of the decision cycle increases or the user becomes stressed. Thus, domains with the above properties ",,rejected,000
1106.4578.pdf.json,,,,rejected,000
1106.4632.pdf.json,Inferring 3D Articulated Models for Box Packaging Robot,,"Learning to Manipulate Articulated Objects in Unstructured Environments using a Grounded Relational Representation | Extracting Planar Kinematic Models using Interactive Perception | 3D Pose Estimation, Tracking and Model Learning of Articulated Objects from Dense Depth Video using Projected Texture Stereo | Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography | Efficient RANSAC for Point-Cloud Shape Detection | Generalizing the Hough Transform to Detect Arbitrary Shapes | Towards 3D Point Cloud Based Object Maps for Household Environments | Beyond Trees: Common Factor Models for 2D Human Pose Recovery | Spatial Priors for Part-based Recognition using Statistical Models | Learning Compact 3D Models of Indoor and Outdoor Environments with a Mobile Robot | Efficient Grasping from RGBD Images: Learning using a New Rectangle Representation | Learning Grasp Strategies with Partial Shape Information | Learning to Place New Objects | Human activity detection from rgbd images | The Elements of Statistical Learning: Data Mining, Inference, and Prediction | Openrave: A Planning Architecture for Autonomous Robotics",rejected,000
1106.5312.pdf.json,Manipulation of Nanson’s and Baldwin’s Rules,"Computational social choice studies computational aspects of voting. For example, how does a coalition of agents compute a manipulation? Can we compile these votes into a more compact form? How do we decide if we have elicited enough votes from the agents to be able to declare the result? Whilst there has been a very active research community studying these sort of questions for well known voting rules like plurality and Borda, there are other less well known rules that might deserve attention. In particular, we put forward two historical voting rules due to Nanson and Baldwin which are related to Borda voting. There are several reasons to consider these two rules. Firstly, they have features that might appeal to the two opposing camps that support Borda and Condorcet. In particular, both rules are Condorcet consistent as they elect the candidate who beats all others in pairwise elections. Secondly, both rules are elimination style procedures where candidates are successively removed. Other elimination procedures like STV and plurality with runoff are computationally hard to manipulate (in the case of STV, with or without weights on the votes, whilst in the case of plurality with runoff, only in the case of weighted votes). We might therefore expect Nanson’s and Baldwin’s rules to be computationally hard to manipulate. Thirdly, statistical analysis sug- Copyright c© 2013, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. gest that, whilst the Borda rule is vulnerable to manipulation (Chamberlin 1985), Nanson’s rule is particularly resistant (Favardin & Lepelley 2006). We might expect Baldwin to be similarly resistant. Finally, the two rules have been used in real elections in the Universitiy of Melbourne (between 1926 and 1982), the University of Adelaide (since 1968), and the State of Michigan (in the 1920s). It is perhaps therefore somewhat surprising that neither rule has received much attention till now in the comput",,rejected,000
1106.5316.pdf.json,Online cake cutting,"Congratulations. Today is your birthday so you take a cake into the office to share with your colleagues. At tea time, people slowly start to arrive. However, as some people have to leave early, you cannot wait for everyone to arrive before you start sharing the cake. How do you proceed fairly? This is an example of an online cake cutting problem. Most previous studies of fair division assume that all agents are available at the time of the division [Brams and Taylor, 1996]. Here, agents arrive and depart as the cake is being divided. Online cake cutting provides an abstract model for a range of practical problems besides birthday parties. Consider, for instance, allocating time on a large telescope. Astronomers will have different preferences for when to use the telescope depending on what objects are visible, the position of the sun, etc. How do we design a web-based reservation system so that astronomers can asynchronously choose observation times that is fair to all? As a second example, consider allocating space at an exhibition. Exhibitors will have different preferences for space depending on the size, location, cost, etc. How do allocate space when not all exhibitors arrive at the same time but those who have arrived want to start setting up immediately? Online cake cutting poses some interesting new challenges. On the one hand, the online aspect of such problems makes fair division more difficult than in the offline case. How can we ensure that agents do not envy cake already given to other agents? On the other hand, the online aspect of such problems may make fair division easier than in the offline case. Perhaps agents do not envy cake that has already been eaten before they arrive? ar X iv :1 10 6. 53 16 v1 [ cs .A I] 2 7 Ju n 20 11","Fair Division: From cake-cutting to dispute resolution | Better ways to cut a cake | Truth, justice, and cake cutting | Distributed fair allocation of indivisible goods | Two-player envy-free multi-cake division | How to cut a cake fairly | How Not to Do it. Research Report 97.27 | Random constraint satisfaction: Theory meets practice | Incompleteness and incomparability in preference aggregation | Dealing with incomplete agents’ preferences and an uncertain agenda in group decision making via sequential majority voting | The fair division of a fixed supply among a growing population | Uncertainty in preference elicitation and aggregation",rejected,000
1106.5427.pdf.json,,"State space search is a fundamental and pervasive approach to artificial intelligence in general and planning in particular. It is among the most successful approaches to planning. A major concern with state space search is that it has a high time and space cost since the state space that needs to be explored is usually very large. Much research on classical planning has focused on the design of better heuristic functions. For example, new heuristic functions have recently been developed by analyzing the domain transition graphs (DTGs) and causal graphs on top of the SAS+ formalism [Briel et al. 2007; Helmert and Röger 2008]. Despite the suc- ACM Journal Name, Vol. V, No. N, Month 20YY, Pages 1–0??. 2 · cess of using domain-independent heuristics for classic planning, heuristic planners still face scalability challenges for large-scale problems. As shown by recent work, search even with almost perfect heuristic guidance may still lead to very high search cost [Helmert and Röger 2008]. Therefore, it is important to improve other components of the search algorithm that are orthogonal to the development of heuristics. Recently, partial order based reduction (POR), a new way to reduce the search cost from an orthogonal perspective, has been studied for classical planning [Chen et al. 2009; Chen and Yao 2009]. POR as a method to reduce search space has been extensively studied in model checking with solid theoretical investigation. However, the theoretical properties of POR in planning have still not been fully investigated. There are three key questions. 1) POR algorithms have been extensively studied in model checking. In fact, POR is an enabling technique for modeling checking, which will not be practical without POR due to its high time complexity. Extensive research has been developed for the theory of POR in model checking. What are the relationships between the previous POR methods designed for model checking and existing work for planning? Understanding these r","Factored planning | Planning as heuristic search | Factored planning: How, when, and when not | An lp-based heuristic for optimal planning | Fast planning by search in domain transition graphs | Stratified planning | Completeness and optimality preserving reduction for planning | Long distance mutual exclusion for planning | Model Checking | The detection and exploitation of symmetry in planning problems | The Fast Downward planning system | Landmarks, critical paths and abstractions: What’s the difference anyway? In Proc | Flexible abstraction heuristics for optimal sequential planning | How good is almost perfect | The FF planning system: Fast plan generation through heuristic search | The model checker spin | State-variable planning under structural restrictions: Algorithms and complexity | Cost-optimal planning with landmarks | Factored planning using decomposition trees | Landmarks revisited | State space generation: Efficiency and practicality | Stubborn sets for reduced state space generation | A stubborn attack on state explosion | Stubborn sets of coloured petri nets | On-the-fly verification with stubborn sets | The state explosion problem | An LP-based heuristic for optimal planning | On stubborn sets in the verification of linear time temporal properties",rejected,000
1106.5448.pdf.json,Dominating Manipulations in Voting with Partial Information,"In computational social choice, one appealing escape from the Gibbard-Satterthwaite theorem (Gibbard 1973; Satterthwaite 1975) was proposed in (Bartholdi, Tovey, and Trick 1989). Whilst manipulation may always be possible, perhaps it is computationally too difficult to find? Many results have subsequently been proven showing that various voting rules are NP-hard to manipulate (Bartholdi and Orlin 1991; Conitzer and Sandholm 2003; Elkind and Lipmaa 2005; Conitzer, Sandholm, and Lang 2007; Faliszewski, Hemaspaandra, and Schnoor 2008; Xia et al. 2009; Faliszewski, Hemaspaandra, and Schnoor 2010) in various senses. However, recent results suggest that computing a manipulation is easy on average or in many cases. Therefore, computational complexity seems to be a weak barrier against manipulation. See (Faliszewski, Hemaspaandra, and Hemaspaandra 2010; Faliszewski and Procaccia 2010) for some surveys of this recent research. It is normally assumed that the manipulator has full information about the votes of the non-manipulators. The argument often given is that if it is NP-hard with full infor- Copyright c© 2014, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. mation, then it only can be at least as computationally difficult with partial information. However, when there is only one manipulator, computing a manipulation is polynomial for most common voting rules, including all positional scoring rules, Copeland, maximin, and voting trees. The only known exceptions are STV (Bartholdi and Orlin 1991) and ranked pairs (Xia et al. 2009). Therefore, it is not clear whether a single manipulator has incentive to lie when the manipulator only has partial information. In this paper, we study the problem of how one manipulator computes a manipulation based on partial information about the other votes. For example, the manipulator may know that some voters prefer one alternative to another, but might not be able to know all pairwise comp",Single transferable vote resists strategic voting | The computational difficulty of manipulating an election | Towards a dichotomy for the possible winner problem in elections based on scoring rules. JCSS 76(8):812–836 | A multivariate complexity analysis of determining possible winners given incomplete votes | Universal voting protocol tweaks to make manipulation hard | When are elections with few candidates hard to manipulate? JACM 54(3):1–33 | Hybrid voting protocols and hardness of manipulation | AI’s war on manipulation: Are we winning? AI Magazine 31(4):53–64 | Using complexity to protect elections | Manipulation of copeland elections | Voting procedures with incomplete preferences | Determining possible and necessary winners under common voting rules given partial orders. To appear in JAIR | Complexity of unweighted coalitional manipulation under some common voting rules | Algorithms for the coalitional manipulation problem,rejected,000
1106.5829.pdf.json,Active Classification: Theory and Application to Underwater Inspection,"Consider the following scenario, which occurs when observing an environment with an underwater vehicle: given a playback of imaging sonar data from the vehicle, the task is to determine which frames contain objects of interest (e.g., mines [19], explosives, ship wreckage, enemy submarines, marine life [16], etc.). We will refer to these problems as underwater inspection, since an object is being inspected to determine its nature. We are interested in utilizing sensor data, such as depth map Geoffrey A. Hollinger and Gaurav S. Sukhatme Computer Science Department, Viterbi School of Engineering, University of Southern California, Los Angeles, CA 90089, e-mail: {gahollin,gaurav}@usc.edu Urbashi Mitra Electrical Engineering Department, Viterbi School of Engineering, University of Southern California, Los Angeles, CA 90089, e-mail: ubli@usc.edu 1 information, to determine the nature of a potential object of interest. Such problems are typically formulated as passive classification, where some data are given, and the goal is to determine the nature of this data. While passive classification problems are challenging in themselves, what is often overlooked is that robotic applications allow for active decision making. In other words, an autonomous vehicle performing a classification task has control over how it views the environment. The vehicle could change its position, modify parameters on its sensor, or even manipulate the environment to improve its view. For instance, it may be difficult to determine the nature of an object when viewed from the top (due to lack of training data, lack of salient features, occlusions, etc.), but the same object may be easy to identify when viewed from the side. As an example, Figure 1 shows an explosive device placed on a ship’s hull viewed from two different angles with imaging sonar. The explosive is easier to identify when viewed from the side (left image) versus from above (right image) due to the reflective qualities of its material",SURF: Speeded up robust features | Learning OpenCV: Computer Vision with the OpenCV Library | A Bayesian approach to optimal sensor placement | Approximating the stochastic knapsack: the benefit of adaptivity | Information theoretic sensor data selection for active object recognition and state estimation | Fusion of multiple quadratic penalty function support vector machines (QPFSVM) for automated sea mine detection and classification | Adaptive submodularity: A new approach to active learning with stochastic optimization | Near-optimal Bayesian active learning with noisy observations | Efficient multi-robot search for a moving target | Near-optimal nonmyopic value of information in graphical models | Dynamic sensor planning with stereo for model identification on a mobile platform | Active M-ary sequential hypothesis testing | Transinformation for active object recognition | Efficient informative sensing using multiple robots | Feature space trajectory methods for active computer vision | Towards autonomous habitat classification using Gaussian mixture models | Probabilistic Robotics | Sequential tests of statistical hypotheses | Bayesian data fusion of multiview synthetic aperture sonar imagery for seabed classification | On optimal AUV track-spacing for underwater mine detection | Conditional feature sensitivity: A unifying view on active recognition and feature selection,rejected,000
1106.5890.pdf.json,A Comparison of Lex Bounds for Multiset Variables in Constraint Programming,"In constraint programming, we often need to model multisets (or bags) of objects. For example, in the template design problem (prob002 in CSPLib (Gent and Walsh 1999)), we need to construct printing templates, which are multisets of different designs. Multisets, unlike sets, can contain repetition of elements. For popular designs, we may have multiple copies on the same template. Surprisingly, whilst there has been significant progress on developing representations for sets, relatively little research has been done on how best to represent multisets. Sadler and Gervet (2004) proposed representing set variables with subset, lexicographic, and cardinality bounds. Indeed, they suggested that such a representation could also be used for multisets (2008). However, little detail is provided about how to do this exactly. To compare two multisets, they lexicographically compare their occurrence vectors written Copyright c© 2014, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. in decreasing order. For instance, {3, 3, 2, 1, 1} {4} {4, 4}. Gervet and Van Hentenryck (2006) proposed representing set variables using length-lex bounds, arguing that it provides comparable pruning to the aforementioned hybrid domains at a fraction of the computational cost. It is therefore promising to consider length-lex and related bounds for multiset variables. However, as a number of different orderings are possible, we have undertaken a theoretical and empirical comparison of the most promising options. As multisets permit repeated elements, we can incorporate information about the variety (number of distinct elements) (Law, Lee, and Woo 2009) in addition to the cardinality and position in the lexicographic ordering. As a result, we introduce eight different representations for multiset variables in which we maintain bounds according to one of eight different orderings: length-(co)lex (LL/LC), variety(co)lex (VL/VC), length-variety-(co)lex (LVL/L","Extended (2, 4)-designs | CSPLib: A benchmark library for constraints | Length-lex ordering for set CSPs | Extended triple systems. Aequat | Variety reasoning for multiset constraint propagation | Construction of extended Steiner systems for information retrieval | Hybrid set domains to strengthen constraint propagation and reduce symmetries | Enhancing set constraint solvers with lexicographic bounds | Bound consistency for binary length-lex set constraints | Consistency and propagation with multiset constraints: A formal viewpoint | Exponential propagation for set variables",rejected,000
1106.5917.pdf.json,Implementing Human-like Intuition Mechanism in Artificial Intelligence,,"A Perspective on Judgment and Choice | INTERACTIONS BETWEEN PHILOSOPHY AND ARTIFICIAL INTELLIGENCE: The Role of Intuition and Non-Logical Reasoning in Intelligence | IBSEAD: - A Self-Evolving Self-Obsessed Learning Algorithm for Machine Learning. IJCSET (URL: - http://ijcset.excelingtech.co.uk/) | Law of Connectivity in Machine Learning. International Journal of Simulation- Systems, Science and Technology - IJSSST (URL: - http://www.ijssst.info/) | How can computers get common sense | The Society of Mind | The Emotion Machine: Commonsense Thinking, Artificial Intelligence, and the Future of the Human Mind | Herbert Simon: Artificial intelligence as a framework for understanding intuition | Making management decisions: The role of intuition and emotion | Explaining the Ineffable; AI on the Topics of Intuition, Insight and Inspiration | Learning and knowledge | Intuition as Instinctive Dialogue. Computing with Instinct | What is and what will be: Integrating spirituality and science",rejected,000
1106.5998.pdf.json,The 3rd International Planning Competition: Results and Analysis,"Beginning in 1998 the international planning community has held a biennial event to support the direct comparison of planning systems on a changing collection of benchmark planning problems. The benefits of this series of events have been significant: over five years, planning systems have been developed that are capable of solving large and complex problems, using richly expressive domain models and meeting advanced demands on the structure and quality of solutions. The competition series has inspired many advances in the planning research community as well as an increasingly empirical methodology and a growing interest in the application of planners to real problems. In this paper we describe the structure, objectives and outcomes of the third competition, which took place in Toulouse in 2002. The competition was colocated with the AI Planning and Scheduling (AIPS) conference. At that conference a brief report was presented of some of the results achieved by the participating planners. We begin by presenting an overview of the main results as presented at the conference, showing the number of problems attempted and solved by each planner and identifying the competition prize-winners. As in previous years the competition resulted in the collection of a large data set comprising data points for several different domains. A certain comparative understanding can be obtained by examining the data for the individual domains, but conclusions drawn on this basis cannot be generalised across domains. One of the goals of this paper is to try to reveal some insights that cross the boundaries of the domains and allow some general questions to be answered. These include: which planners reveal the most consistent, stable performance c©2003 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved. across domains? What benefit is obtained by exploiting hand-coded control knowledge? Is there any general agreement over what makes a planning problem hard? Are particu","The AIPS’00 planning competition | Planning with resources and concurrency: A forward chaining approach | Using temporal logic to express search control knowledge for planning | Fast Planning through Plan-graph Analysis | A robust and fast action selection mechanism for planning | Sapa: A scalable, multi-objective, heuristic, metric, temporal planner | Taming numbers and durations in the model-checking integrated planning system | pddl2.1: An extension to pddl for expressing temporal planning domains | Temporal planning with PDDL2.1 | Time-optimal planning in temporal problems | Planning through stochastic local search and temporal action graphs in LPG | Representation and control in IxTeT, a temporal planner | Heuristic planning with time and resources | The Metric-FF planning system: Translating “ignoring delete lists” to numerical state variables | Where ignoring delete-lists works: local search topology in planning benchmarks | The FF planning system: Fast plan generation through heuristic search | A critical assessment of benchmark comparison in planning | 100 Statistical Tests | Talplanner in the 3rd international planning competition: Extensions and control rules | Planning with sharable resource constraints. In Proceedings of IJCAI-95 | The AIPS’98 Planning Competition: Competitors’ perspective | The 1998 AI planning systems competition | PDDL–the planning domain definition language | A heuristic estimator for means ends analysis in planning | SHOP2: An HTN planning environment | SimPlanner: an executionmonitoring system for replanning in dynamic worlds | Making graphplan goal-directed | Temporal planning with continuous change | On the extraction, ordering, and usage of landmarks in planning | SteLLa: An optimal sequential and parallel planner | Temporal planning with mutual exclusion reasoning | um-translog-2: a planning domain designed for AIPS-02 | vhpop: Versatile heuristic partial order planner",rejected,000
1106.6022.pdf.json,Use of Markov Chains to Design an Agent Bidding Strategy for Continuous Double Auctions,"Electronic commerce at present is mostly driven by human interactions (humans decide what to buy, where to buy from, and how much they are willing to pay), but automated trading agents are increasingly being developed and deployed (Eriksson & Janson, 2002; Greenwald, 2003; Arunachalam et al., 2003). To a large extent, automated agents have been restricted to simpler types of e-commerce problems, where decisions about buying and selling, and about prices at which to buy and sell, are relatively formulaic (see for example, http://www.ebay.com). The construction of particular types of auctions and other mechanisms designed for e-commerce systems can also simplify agent decision problems by making it irrational, for example, for an agent to offer a bid price that is different from its true valuation for the object being exchanged (Vickrey, 1961). However, there are many types of trading problems in e-commerce where decisions that an agent must make are much less formulaic. An example of such problems, which has recently been the focus of considerable research in the research community (Wellman, 2003; Greenwald, 2003; He at al. 2002; Tesauro & Das, 2001), is the problem of bidding in a continuous double auction (CDA). The CDA is an auction variant (Friedman, 1993, page 8) in which buyers and sellers post their buy and sell offers asynchronously, and the auction will match a buy and a sell offer at any moment as long as the buy bid is higher than or equal to the sell offer. The CDA supports timely transactions and achieves high market efficiency, which is why most real-world markets for trading equities and commodities use the CDA. The dynamics of the CDA (such as entry and exit of agents’ offers and continuous matching in auctions), however, adds additional complexity to the design of optimally profitable bidding agents. Although there has been research on developing bidding agents for CDAs (He et al., 2002; Tesauro & Das, 2001; He & Jennings, 2003; Vetsikas & Selman, 20",,rejected,000
1106.6341.pdf.json,Pose and Motion from Omnidirectional Optical Flow and a Digital Terrain Map€,,"Statistical image analysis for pose estimation without point correspondences | Softposit: Simultaneous pose and correspondence determination | Recursive estimation of time-varying motion and structure parameters | Comparison of approaches to egomotion computation | MFm: 3-D motion from 2-D motion causally integrated over time | Robust recovery of ego-motion | Integrated position estimation using aerial image sequences | A critique of structure-from-motion algorithms | Error analysis for a navigation algorithm based on optical-flow and a digital terrain map | Epipolar geometry for panoramic cameras | Epipolar geometry for central catadioptric cameras | Estimation of omnidirectional camera model from epipolar geometry | A unifying theory for central panoramic systems | Para-catadioptric camera auto-calibration from epipolar geometry. Research Report CTU-CMP-2003-18, CMP K13133 | Epipolar geometry for panoramic cameras | Epipolar geometry for panoramic cameras | Catadioptric self-calibration | Omnidirectional camera model and epipolar geometry estimation by ransac with bucketing | Robust wide baseline stereo from maximally stable extremal regions | A theory of catadioptric image formation | Pose and motion recovery from feature correspondences and a digital terrain map | An iterative image registration technique with an application to stereo vision | Pyramidal implementation of the lucas kanade feature tracker, description of the algorithm",rejected,000
1107.0018.pdf.json,,,,rejected,000
1107.0019.pdf.json,,,,rejected,000
1107.0020.pdf.json,Learning to Order BDD Variables in Verification,"The size and complexity of software and hardware systems have significantly increased in the past years. As a result, it is harder to guarantee their correct behavior. Thus, formal methods, preferably computerized, are needed for this task. One of the most successful methods for automated verification of finite-state systems is temporal logic model checking (Clarke, Emerson, & Sistla, 1986; Queille & Sifakis, 1981). Temporal logics are suitable formalisms for describing the behavior of a program over time. A model checking procedure receives a finite-state model of the system and a specification c©2003 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved. written as a temporal logic formula. It returns “yes” if the model satisfies the formula (meaning that the system behaves according to the specification). Otherwise, it returns “no”, along with a counter example that demonstrates a bad behavior. Model checking has been very successful in finding subtle errors in various systems. It is currently recognized by the hardware industry as an important component of the development phase of new designs. However, model checking procedures often suffer from high space requirements, needed for holding the transition relation and the intermediate results. One of the most promising solutions to this problem is the use of binary decision diagrams (BDDs) (Akers, 1978; Bryant, 1986) as the basic data structure in model checking. BDDs are canonical representations of boolean functions and are often very concise in size. Their conciseness also yields efficiency in computation time. Since it is straightforward to represent the transition relation and the intermediate results as boolean functions, BDDs are particularly suitable for model checking. Today, existing industrial BDD-based verifiers, such as IBM’s RuleBase (Beer, Ben-David, Eisner, & Landver, 1996) and Motorola’s Verdict (Kaufmann & Pixley, 1997) are used by many companies in their development infrastruc",Binary decision diagrams | BDD variable ordering for interacting finite state machines | RuleBase: An industry-oriented formal verification tool | Efficient OBDD-based boolean manipulation in CAD beyond current limits | Simulated annealing to improve variable orderings for OBDDs | Improving the variable ordering of OBDDs is NP-complete | Classification and Regression Trees | Combinational profiles of sequential benchmark circuits | Compositional instance-based learning | Graph-based algorithms for boolean function manipulation | Heuristics to compute variable orderings for efficient manipulation of ordered binary decision diagrams | Parallel logic simulation of VLSI systems | Efficient variable ordering heuristics for shared ROBDD | Automatic verification of finite state concurrent systems using temporal logic specifications | Learning to order things | Nearest neighbor pattern classification | Genetic algorithm for variable ordering of OBDDs | Fast exact minimization of BDDs | Pattern Classification and Scene Analysis | Approximating minimum feedback sets and multi-cuts in directed graphs | A recursive partitioning decision rule for nonparametric classification | Finding the optimal variable ordering for binary decision diagrams | Interleaving based variable ordering methods for ordered binary decision diagrams | Evaluation and improvements of boolean comparison method based on binary decision diagrams | Variable ordering algorithms for ordered binary decision diagrams and their evaluation | BDD minimization by truth table permutations | Experiments in Induction | Minimization of binary decision diagrams based on exchanges of variables | FIRE: A fault-independent combinational redundancy identification algorithm | Sampling schemes for computing variable orderings | Reducibility among combinatorial problems | Intertwined development and formal verification of a 60x bus model | Explorations of sequential atpg using boolean satisfiability | Selective sampling for nearest neighbor classifiers | Identifying sequentially untestable faults using illegal states | Logic verification using binary decision diagrams in a logic synthesis environment | Symbolic Model Checking: An Approach to the State Explosion Problem | Speeding up variable ordering of OBDDs | Sample method for minimization of OBDDs | Linear sifting of decison diagrams | Functional approaches to generating orderings for efficient symbolic representations | Shared binary decision diagrams with attributed edges for efficient boolean function manipulation | Waiting false path analysis of sequential logic circuits for performance optimization | Who are the variables in your neighbourhood | Symmetry detection and dynamic variable ordering of decision diagrams | Learning logic | Specification and verification of concurrent systems in cesar | Discovering rules by induction from large collections of examples | Induction of decision trees | Dynamic variable ordering for ordered binary decision diagrams | Parallel distibuted processing: Exploration in the microstructure of cognition | Implicit state enumeration of finite state machines using BDDs | Two kinds of training information for evaluation function learning | Learning a preference predicate | Design error diagnosis in sequential circuits | Adaptive switching circuits | Improved variable ordering of BDDs with novel genetic algorithm,rejected,000
1107.0021.pdf.json,Decentralized Supply Chain Formation: A Market Protocol and Competitive Equilibrium Analysis,"Electronic commerce technology can provide significant improvements in existing modes of commercial interaction, through increased speed, convenience, quality, and reduced costs. Yet some have proposed more radical visions of how business may be transformed. Exponential increases in communications bandwidth and computational ability have the potential to qualitatively decrease the friction in business interactions. With this as a premise, Malone and Laubaucher’s treatise on the emerging “E-Lance Economy” (1998) puts forth the view that, in the not-too-distant future, business relationships will lose much of their current persistent character. Indeed, Malone and Laubaucher propose that large companies as we know them will cease to exist, and rather be dynamically formed by “electronically connected freelancers” (e-lancers) for the purpose of producing particular goods and services, and then dissolved when projects are completed. Others employ the evocative term “virtual corporation” (Davidow, 1992) to describe groups of agile organizations forming temporary confederations for ad hoc purposes. c©2003 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved. Whether or not one accepts the full extent of this vision of virtual corporations, several business trends provide evidence that we are moving in this direction. Software companies are time-shifting development between the U.S. and India, and Sun Microsystems now allows freelance programmers to bid to fix customers’ software problems (Borenstein & Saloner, 2001). Large, traditional manufacturing companies, exemplified by major automotive manufacturers, increasingly outsource the production of various components. Ford and General Motors (GM) have spun off parts manufacturing into separate companies (Lucking-Reily & Spulber, 2001). Start-ups and other small companies form partnerships to compete with larger, more established companies. Application service providers supplant in-house provision of stand",,rejected,000
1107.0022.pdf.json,,"The design and analysis of interactions of self-interested parties are central to the theory and application of multi-agent systems. In particular, the theory of economic mechanism design or, more generally, implementation theory (Maskin, 1999; Maskin & Sjostrom, 2002) has become a standard tool for researchers in the areas of multi-agent systems and e-commerce (Rosenschein & Zlotkin, 1994; Nisan & Ronen, 1999; Shoham & Tennenholtz, 2001; Feigenbuam & S, 2002; Tennenholtz, 1999; Papadimitriou, 2001). In classical mechanism design1 a center defines an interaction for self-motivated parties that will allow it to obtain some desired goal (such as maximizing revenue or social welfare) taking the agents’ incentives 1. See e.g., Fudenberg and Tirole (1991), Chapter 7, or Mas-Colell, Whinston, and Green (1995), Chapter 23. c©2004 AI Access Foundation. All rights reserved. into account. This perspective has been largely motivated by the view of the center as a government or a seller that can define and control the rules of interaction. However, in many distributed systems and multi-agent interactions, interested parties cannot control the rules of interactions. A network manager for example cannot simply change the communication protocols in a given distributed systems in order to lead to desired behaviors, and a broker cannot change the rules in which goods are sold by an agency auctioneer to the public. The focus of this paper is on how a reliable interested party, which cannot change the rules of interaction, and cannot enforce behavior, can obtain its desired goals (in service of the community or for its own benefits). The reliable party has only one source of power: its reliability. It can commit to payments to the different agents, when certain observable outcomes will be reached, and the agents can be sure that they will be paid appropriately. In our work we introduce the study of implementation of desired behaviors by interested party as above.2 There are two major ","Subjectivity and correlation in randomized strategies | Multipart pricing of public goods | Adoption externalities as public goods | Algorithms and Methods for Mobile Computing and Communications | Minimality and Simplicity | Bundling Equilib | Characterization of ex post equilibrium in the VCG | Worst-Case Equilibria. In STACS | Extensive games and the problem of information | Nash equilibrium and welfare optimality | Implementation theory | Privacy Preserving Auctions and Mechanism Design | Equilibrium points in n-person games | Bidding and allocation in combinatorial auctions | Algorithmic mechanism design | Algorithms,Games,and the Internet | ibundle: An efficient ascending price bundle auction | Rules of Encounter | A class of games possessing pure-strategy nash equilibria | The price of anarchy is independent of the network topology | How bad in selfish routing | Cabob: A fast optimal algorithm for combinatorial auctions | Contracting with externalities | Social Laws for Artificial Agent Societies: Off-line Design | On rational computability and communication complexity | Extracting intercation-created surplus | Electronic commerce: From game-theoretic and economic models to working protocols | Competive Safety Analyis: robust decision-making in multi-agent systems | Counterspeculations, auctions, and competitive sealed tenders",rejected,000
1107.0023.pdf.json,CP-nets: A Tool for Representing and Reasoning with Conditional Ceteris Paribus Preference Statements,"Extracting preference information from users is generally an arduous process, and human decision analysts have developed sophisticated techniques to help elicit this information (Howard & Matheson, 1984). A key goal in the study of computer-based decision support is the construction of tools that allow the preference elicitation process to be automated, either partially or fully. Methods for extracting, representing and reasoning about the preferences of naive users are particularly important in AI applications, ranging from collaborative c©2004 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved. filtering (Lashkari, Metral, & Maes, 1994) and recommender systems (Nguyen & Haddawy, 1998) to product configuration (D’Ambrosio & Birmingham, 1995) and medical decision making (Chajewska, Getoor, Norman, & Shahar, 1998). In many of these applications users cannot be expected to have the patience (or sometimes the ability) to provide detailed preference relations or utility functions. Typical users may not be able to provide much more than qualitative rankings of fairly circumscribed outcomes. In this paper we describe a novel graphical representation, CP-nets, that can be used for specifying preference relations in a relatively compact, intuitive, and structured manner using conditional ceteris paribus (all else being equal) preference statements. CP-nets can be used to specify different types of preference relations, such as a preference ordering over potential decision outcomes or a likelihood ordering over possible states of the world, for example, as in Shoham’s (1987) preference semantics. However, it is mainly the first type—preferences over the outcomes of decisions—that motivates the development of CPnets. The inference techniques for CP-nets described in this paper focus on two important, related questions: how to perform preferential comparison between outcomes, and how to find the optimal outcome given a partial assignment to the problem at","Graphical models for preference and utility | Utility independence in qualitative decision theory | Towards a possibilistic logic handling of preferences | Toward a logic for qualitative decision theory | UCP-Networks: A directed graphical representation of conditional utilities | A constraint-based approach to preference elicitation and decision making | CP-networks for preference-based CSP | Introducing variable importance tradeoffs into CPnets | Structure and complexity in planning with unary operators | A new look at the semantics and optimization methods of CP-networks | The computational complexity of propositional STRIPS planning | Review of Halldén “On the Logic of ‘Better’ | Utility elicitation as a classification problem | Introduction to Algorithms | Preference-directed design | Modeling and Reasoning about Preferences with CP-nets | On recursively directed hypercubes | CP-nets - reasoning and consistency testing | Structure and complexity in planning with unary operators | Preference-based configuration of web page content | Reasoning about soft constraints and conditional preferences: Complexity results and approximation techniques | Efficient probabilistic reasoning in bayes nets with mutual exclusion and context specific independence | A logic of relative desire (preliminary report) | Representing preferences as ceteris paribus comparatives | Logical representation and computation of optimal decisions in a qualitative setting | Making decision in a qualitative setting: From decision under uncertainty to case-based decision | A possibilistic logic machinery for qualitative decision | Interactive goal programming | Decision Theory | Modeling and generating tradeoffs for constraintbased configuration | Remote conferencing with multimedia objects | Toward case-based preference elicitation: Similarity measures on preference structures | Sales configuration in business processes | On the Logic of ‘Better | What is ceteris paribus preference | Linear Programming in Single and Multiple Objective Systems | A cumulative-model semantics for dynamic preferences on assumptions | Preference programming for configuration | Decisions with Multiple Objectives: Preferences and Value Trade-offs | Automatically generating abstractions for planning | Expected utility networks | Collaborative interface agents | The decision-theoretic video advisor | Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference | Product conguration frameworks - a survey | Complexity of probabilistic reasoning in (directedpath) singly connected (not polytree!) Bayes networks. submitted for publication | A semantical approach to nonmonotonic logics | Conditional utility, utility independence, and utility networks | Formalizing configuration knowledge using rules with choices | Specification and evaluation of preferences for planning under uncertainty | Utility theory and preference logic | The Logic of Preference: An Essay | The logic of preference reconsidered | Philosophical logic: Philosophical Papers, Volume II | Preferential semantics for goals",rejected,000
1107.0024.pdf.json,Complexity Results and Approximation Strategies for MAP Explanations,"The task of computing the Maximum a Posteriori Hypothesis (MAP) is to find the most likely configuration of a set of variables given partial evidence about the complement of that set. The focus of this paper is on the complexity of computing MAP in Bayesian networks, and on a class of best effort methods for approximating MAP. One specialization of MAP which has received a lot of attention is the Most Probable Explanation (MPE). MPE is the problem of finding the most likely configuration of a set of variables given complete evidence about the complement of that set. The primary reason for this attention is that MPE seems to be a much simpler problem than its MAP generalization. Unfortunately, MPE is not always suitable for the task of providing explanations. Consider for example the problem of system diagnosis, where each component has an associated variable representing its health. Given some evidence about the system behavior, one is usually interested in computing the most probable configuration of health variables. This is a MAP problem since the available evidence does not usually specify the value of each c©2004 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved. non–health variable. It is common to approximate this problem using MPE, in which case one is finding the most likely configuration of every unknown variable, including health variables and some other variables of no particular interest, such as the inputs and outputs of system components. However, the projection of an MPE solution on health variables is usually not a most likely configuration. Neither is the configuration obtained by choosing the most likely state of each health variable separately. MAP turns out to be a very difficult problem, even when compared to the MPE problem, or to the Pr problem for computing the probability of evidence. Specifically, we provide in Section 2 some complexity results which indicate that neither exact nor approximate solutions can be guaran",An optimal approximation algorithm for Bayesian inference | Recursive conditioning | A differential approach to inference in Bayesian networks | Partial abductive inference in Bayesian belief networks using a genetic algorithm | Mini-buckets: A general scheme for approximate inference | Bucket elimination: A unifying framework for probabilistic inference | Inference in belief networks: A procedural guide | Bayesian updating in recursive graphical models by local computation | Stochastic local search for Bayesian networks | Triangulation of graphs—algorithms giving small total state space | Local computations with probabilities on graphical structures and their application to expert systems | Stochastic boolean satisfiability | Initial experiments in stochastic satisfiability | The computational complexity of probabilistic planning | The turbo decision algorithm | Stochastic greedy search: Efficiently computing a most probable explanation in Bayesian networks | Loopy belief propagation for approximate inference: an emperical study | The complexity of Markov decision processes | A differential semantics for jointree algorithms | Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference | On the hardness of approximate reasoning | Propagating belief functions with local computations | Finding MAPs for belief networks is NP–hard | PP is as hard as the polynomial-time hierarchy | Generalized belief propagation,rejected,000
1107.0025.pdf.json,Taming Numbers and Durations in the Model Checking Integrated Planning System,"Practical action planning and model checking appear to be closely related. The MIPS project targets the integration of model checking techniques into a domain-independent action planner. With the HSF-Spin experimental model checker (Edelkamp, Leue, & LluchLafuente, 2003) we are looking towards the integration of planning technology into an c©2003 AI Access Foundation. All rights reserved. existing model checker. Additional synergies are exploited in the automated compilation of protocol software model checking problems into planner inputs (Edelkamp, 2003). Model checking (Clarke, Grumberg, & Peled, 1999) is the automated process to verify if a formal model of a system satisfies a specified temporal property or not. As an illustrative example, take an elevator control system together with a correctness property that requires an elevator to eventually stop on every call of a passenger or that guarantees that the door is closed, while the elevator is moving. Although the success in checking correctness is limited, model checkers have found many errors in current hardware and software designs. Models often consist of many concurrent sub-systems. Their combination is either synchronous, as often seen in hardware design verification, or asynchronous, as frequently given in communication and security protocols, or in multi-threaded programming languages like Java. Model checking requires the exploration of very large state spaces containing all reachable system states. This problem is known as the state explosion problem and occurs even when the sets of generated states is much smaller than the set of all reachable states. An error that shows a safety property violation, like a deadlock or a failed assertion, corresponds to one of a set of target nodes in the state space graph. Roughly speaking, something bad has occured. A liveness property violation refers to a (seeded) cycle in the graph. Roughly speaking, something good will never occur. For the case of the elevator ex","Planning with resources and concurrency: A forward chaning approach | Using temporal logics to express search control knowledge for planning | Computational aspects of reordering plans | Improving heuristics for planning as search in belief space | Heuristic search symbolic model checking = efficient conformant planning | Planning in nondeterministic domains under partial observability via symbolic model checking | μcke - efficient μ-calculus model checking | Symbolic guided search for CTL model checking | Fast planning through planning graph analysis | Planning as heuristic search | Symbolic boolean manipulation with ordered binary-decision diagrams | Planning via model checking: A decision procedure for AR | Automatic OBDD-based generation of universal plans in non-deterministic domains | Symbolic model checking: 1020 states and beyond | Introduction to Algorithms | Shortest-path forest with topological ordering | Sapa: a domain-independent heuristic metric temporal planner | Datenstrukturen und Lernverfahren in der Zustandsraumsuche | Directed symbolic exploration and its application to AI-planning | First solutions to PDDL+ planning problems | Planning with pattern databases | Mixed propositional and numerical planning in the model checking integrated planning system | Symbolic pattern databases in heuristic search planning | Promela planning | Exhibiting knowledge in planning problems to minimize state encoding length | On the implementation of MIPS | The model checking integrated planning system MIPS | Directed explicit-state model checking in the validation of communication | Theory and practice of time-space trade-offs in memory limited search | OBDDs in heuristic search | Deterministic state space planning with BDDs | Deterministic state space planning with BDDs | Implementing HEAPSORT with n log n − 0.9n and QUICKSORT with n log n + 0.2n comparisons | Symbolic heuristic search for factored markov decision processes | Strips: A new approach to the application of theorem proving to problem solving | Propositional planning | The automatic inference of state invariants in TIM | The detection and exploration of symmetry in planning problems | Extending the exploitation of symmetries in planning | PDDL2.1: An extension to PDDL for expressing temporal planning domains | Fast planning through greedy action graphs | LPG: a planner based on local search for planning graphs with action costs | Planning as model checking | Model checking Java programs using structural heuristics | One action is enough to plan | LAO*: A heuristic search algorithm that finds solutions with loops | Symbolic heuristic search using decision diagrams | A formal basis for heuristic determination of minimum path cost | Heuristic planning with time and resources | On the complexity of planning in transportation domains | Decidability and undecidability results for planning with numerical state variables | Verteilte Visualisierung von Geometrischen Algorithmen | A heuristic for domain independent planning and its use in an enforced hill climbing algorithm | Extending FF to numerical state variables | Local search topology in planning benchmarks: A theoretical analysis | Fast plan generation through heuristic search | Solving the entailment problem in the fluent calculus using binary decision diagrams | SetA*: An efficient BDD-based heuristic search algorithm | OBDD-based universal planning for synchronized agents in non-deterministic domains | Planning control rules for reactive agents | Pushing the envelope: Planning, propositional logic, and stochastic search | State-space planning by integer optimization | Generating parallel execution plans with a partial order planner | Elevator control as a planning problem | On reasonable and forced goal orderings and their use in an agenda-driven planning algorithm | Extending planning graphs to an ADL subset | Depth-first iterative-deepening: An optimal admissible tree search | Divide-and-conquer frontier search applied to optimal sequence alignment | Planning with sharable resources constraints | Planning with a language for extended goals | Buddy: Binary decision diagram package, release 1.7 | Symmetry reduction and heuristic search for error detection in model checking | Efficient implementation of the plan graph in STAN | Encoding temporal planning domains and validating temporal plans. In Workshop of the UK Planning and Scheduling Special Interest Group (PlanSIG) | The 1998 AI Planning Competition | Symbolic Model Checking | HSTS: integrating planning and scheduling | Heuristics | Formulating multiagend, dynamic-world problems in the classical framework | ADL: Exploring the middleground between Strips and situation calculus | Modelling and Verification of Real-Time Systems Using Timed Automata: Theory and Practice | Planning as model checking for extended goals in nondeterministic domains | Practical and theoretical considerations in heuristic search algorithms | Heuristic planning with ressources | Error detection with directed symbolic model checking | Détermination du parallélisme maximal et optimisation temporelle dans les plans d’actions linéaires | Enhanced iterative-deepening search | Symmetry reduction for SAT representations of transition systems | Numeric state variables in constraint-based planning | Optimal scheduling using branch and bound with SPIN 4.0 | Discrete Optimization Algorithms with Pascal Programs | Nonlinear planning with parallel resource allocation | Planen mit einem Modellprüfer im μ-Kalkül | Validation with guided search of the state space | A* with partial expansion for large branching factor problems | Sparse-memory graph search",rejected,000
1107.0026.pdf.json,,,,rejected,000
1107.0027.pdf.json,Effective Dimensions of Hierarchical Latent Class Models,"Hierarchical latent class (HLC) models (Zhang, 2002) are tree-structured Bayesian networks (BNs) where leaf nodes are observed while internal nodes are latent. They generalize latent class models (Lazarsfeld and Henry, 1968) and were first identified as a potentially useful class of Bayesian networks by Pearl (1988). We are concerned with learning HLC models from data. A fundamental question is how to select among competing models. The BIC score (Schwarz, 1978) is a popular metric that researchers use to select among Bayesian network models. It consists of a loglikelihood term that measures the fitness to data and a penalty term that depends linearly upon standard model dimension, i.e. the number of linearly independent standard model parameters. When all variables are observed, the BIC score is an asymptotic approximation of (the logarithm) of the marginal likelihood (Schwarz, 1978). It is also consistent in the sense that, given sufficient data, the BIC score of the generative model — the model from which data were sampled — is larger than those of any other models that are not equivalent to the generative model. When latent variables are present, the BIC score is no longer an asymptotic approximation of the marginal likelihood (Geiger et al., 1996). This can be remedied, to some extent, using the concept of effective model dimension. In fact if we replace standard model dimension with effective model dimension in the BIC score, the resulting scoring function, called the BICe score, is an asymptotic approximation of the marginal likelihood almost everywhere except for some singular points (Rusakov and Geiger, 2002). c©2004 AI Access Foundation. All rights reserved. Neither BIC nor BICe have been proved to be consistent for latent variable models. As a matter of fact, it has not even been defined what it means for a model selection criterion to be consistent for latent variable models. Empirical studies suggest that the BIC score is well-behaved in practice for the","A new look at the statistical model identification | Latent variable models and factor analysis, 2nd edition | Bayesian classification (AutoClass): Theory and results | Efficient Approximations for the Marginal Likelihood of Bayesian Networks with Hidden variables | Probabilistic networks and expert | Dimension correction for hierarchical latent class models | Asymptotic model selection for directed networks with hidden variables | Exploratory latent structure analysis using both identifiable and unidentifiable | Latent structure analysis | Asymptotic model selection for Naive Bayesian networks. UAI-02 | Automated analytic asymptotic evaluation of marginal likelihood for latent models. UAI-03 | Estimating the dimension of a model | On the geometry of Bayesian graphical models with hidden variables | Geometry, moments and Bayesian networks with hidden variables | Hierarchical latent class models for cluster analysis | Learning hierarchical latent class models | Structural EM for Hierarchical Latent Class Models | Hierarchical latent class models for cluster analysis",rejected,000
1107.0029.pdf.json,A Personalized System for Conversational Recommendations,"Recommendation systems help users find and select items (e.g., books, movies, restaurants) from the huge number available on the web or in other electronic information sources (Burke, 1999; Resnick & Varian, 1997; Burke, Hammond, & Young, 1996). Given a large set of items and a description of the user’s needs, they present to the user a small set of the items that are well suited to the description. Recent work in recommendation systems includes intelligent aides for filtering and choosing web sites (Eliassi-Rad & Shavlik, 2001), news stories (Ardissono, Goy, Console, & Torre, 2001), TV listings (Cotter & Smyth, 2000), and other information. The users of such systems often have diverse, conflicting needs. Differences in personal preferences, social and educational backgrounds, and private or professional interests are pervasive. As a result, it seems desirable to have personalized intelligent systems that c©2004 AI Access Foundation. All rights reserved. process, filter, and display available information in a manner that suits each individual using them. The need for personalization has led to the development of systems that adapt themselves by changing their behavior based on the inferred characteristics of the user interacting with them (Ardissono & Goy, 2000; Ferrario, Waters, & Smyth, 2000; Fiechter & Rogers, 2000; Langley, 1999; Rich, 1979). The ability of computers to converse with users in natural language would arguably increase their usefulness and flexibility even further. Research in practical dialogue systems, while still in its infancy, has matured tremendously in recent years (Allen, Byron, Dzikovska, Ferguson, Galescu, & Stent, 2001; Dybkjær, Hasida, & Traum, 2000; Maier, Mast, & Luperfoy, 1996). Today’s dialogue systems typically focus on helping users complete a specific task, such as planning, information search, event management, or diagnosis. In this paper, we describe a personalized conversational recommendation system designed to help users cho","Case-based reasoning: Foundational issues, methodological variations, and system approaches | Development principles for dialog-based interfaces | Mining association rules between sets of items in large databases | Refining conversational case libraries | Conversational case-based reasoning | Mixed-initiative interaction | Towards conversational human-computer interaction | The TRAINS project: A case study in building a conversational planning agent | Natural language understanding (second edition) | Tailoring the interaction with users in web stores | An adaptive system for the personalized access to news | Learning collaborative information filters | Gus, a frame driven dialog system | Using introspective learning to improve retrieval in CBR: A case study in air traffic control | Introduction to special section on the adaptive web | The Wasabi personal shopper: A case-based recommender system | Knowledge-based navigation of complex information spaces | Plan recognition in natural language dialogue | Constructing and utilizing a model of user preferences in collaborative consultation dialogues | KNOME: Modeling what the user knows in UC | MIMIC: An adaptive mixed initiative spoken dialogue system for information queries | Elements of a plan-based theory of speech acts | Learning to order things | PTV: Intelligent personalized TV guides | Interactive constraint satisfaction | Gemini: A natural language system for spoken-language understanding | Constraint-based agents: Assistance, cooperation, compromise | A system for building intelligent agents that learn to retrieve and extract information | Dialog management for an adaptive database assistant | On abstract task models and conversation policies | Collaborative maintenance in ULYSSES | Learning subjective functions with large margins | A form-based dialogue manager for spoken language applications | Learning users’ interests by unobtrusively observing their normal behavior | The development and utilization of the case-based help-desk support system HOMER | Personalized, conversational case-based recommendation | Preface to the special issue computational models of mixedinitiative interaction | Harnessing models of users’ goals to mediate clarification dialog in spoken language systems | Cooperating to be noncooperative: The dialog system PRACMA | Leveraging data about users in general in the learning of individual user models | Speech and language processing | The Berkeley restaurant project | Building a user model implicitly from a cooperative advisory dialog | Personal usability based upon a scrutable, dynamic, individual user model | User models in dialog systems | Grouplens: Applying collaborative filtering to usenet news | Algorithms for constraint-satisfaction problems: A survey | NewsWeeder: Learning to filter netnews | User modeling in adaptive interfaces | A stochastic model of human-machine interaction for learning dialog strategies | Interactive assessment of user preference models: The automated travel assistant | Designing and evaluating an adaptive spoken dialogue system | Proceedings of the ECAI’96 workshop on Dialogue processing in spoken language systems, Budapest, Hungary | Dynamic user level and utility measurement for adaptive dialog in a help-desk system | Interfaces for eliciting new user preferences in recommender systems | Content-boosted collaborative filtering for improved recommendations | Syskill & Webert: Identifying interesting web sites | AMICA: The AT&T mixed initiative conversational architecture | A constraint-based model for cooperative response generation in information dialogues | Personalized retrieval for online recruitment services | Generating queries and replies during informationseeking interactions | User modeling via stereotypes | An adaptive interactive agent for route advice | ARTIMIS: Natural dialogue meets rational agency | Mailcat: An intelligent assistant for organizing e-mail | Galaxy-II: A reference architecture for conversational system development | Organization, communication, and control in the Galaxy-II conversational system | Social information filtering: Algorithms for automating ‘word of mouth | Intelligent profiling by example | Optimizing dialogue management with reinforcement learning: Experiments with the NJFun system | Spoken natural language dialog systems: A practical approach | Surfing the digital wave, generating personalized TV listings using collaborative, case-based recommendation | The CommandTalk spoken dialogue system | Dialog act modeling for automatic tagging and recognition of conversational speech | What can I say?: Evaluating a spoken language interface to email | Evaluation for DARPA communicator spoken dialogue systems | Recent improvements in the CMU spoken language understanding system | Weighting features | Understanding computers and cognition: A new foundation for design | Towards lifetime maintenance of case base indexes for continual case based reasoning | Natural language processing and user modeling: Synergies and limitations",rejected,000
1107.0030.pdf.json,Coherent Integration of Databases by Abductive Logic Programming,"Complex reasoning tasks often have to integrate information that is coming from different sources. One of the major challenges with this respect is to compose contradicting sources of information such that what is obtained would properly reflect the combination of the datasources on one hand1, and would still be coherent (in terms of consistency) on the other hand. There are a number of different issues involved in this process, the most important of which are the following: 1. Unification of the different ontologies and/or database schemas, in order to get a fixed (global) schema, and a translation of the integrity constraints2 of each database to the new ontology. 2. Unification of translated integrity constraints in a single global set of integrity constraints. This means, in particular, elimination of contradictions among the translated 1. This property is sometimes called compositionality (Verbaeten, Denecker, & De Schreye, 1997, 2000). 2. I.e., the rules that represent intentional truths of a database domain. c©2004 AI Access Foundation. All rights reserved. integrity constraints, and inclusion of any global integrity constraint that is imposed on the integration process. 3. Integration of databases w.r.t. the unified set of integrity constraints, computed according to the previous item. Each one of the issues mentioned above has its own difficulties and challenges. For instance, the first issue is considered, e.g., by Ullman (2000) and Lenzerini (2001, 2002), where questions such as how to express the relations between the ‘global database schema’ and the source (local) schemas, and how this influences query processing with respect to the global schema (Bertossi, Chomicki, Cortés, & Gutierrez, 2002), are dealt with3. The second issue above is concerned with the construction of a single, classically consistent, set of integrity constraints, applied on the integrated data. In database context, it is common to assume that such a set is pre-defined, and consists",,rejected,000
1107.0031.pdf.json,Grounded Semantic Composition for Visual Scenes,"We introduce a visually-grounded language understanding model based on a study of how people describe objects in visual scenes of the kind shown in Figure 1. We designed the study to elicit descriptions that would naturally occur in a joint reference setting and that are easy to produce and understand by a human listener. A typical referring expression for Figure 1 might be, ”the far back purple cone that’s behind a row of green ones”. Speakers construct expressions to guide listeners’ attention to intended objects. Such referring expressions succeed in communication because speakers and listeners find similar features of the visual scene to be salient, and share an understanding of how language is grounded in terms of these features. This work is a step towards our longer term goals to develop a conversational robot (Hsiao, Mavridis, & Roy, 2003) that can fluidly connect language to perception and action. To study the use of descriptive spatial language in a task similar to one our robots perform, we collected several hundred referring expressions based on scenes similar to Figure 1. We analysed the descriptions by cataloguing the visual features that they referred to within a scene, and the range of linguistic devices (words or grammatical patterns) that they used to refer to those features. The combination of a visual feature and corresponding linguistic device is referred to as a descriptive strategy. The example sentence above contains several descriptive strategies that make use of colour, spatial relations, and spatial grouping. These descriptive strategies are used in composition by the speaker to make reference to a unique object. We propose a set of computational mechanisms that correspond to the most commonly used descriptive strategies from our study. The resulting model has been implemented as a set of visual feature extraction algorithms, a lexicon that is grounded in terms of these visual c©2004 AI Access Foundation. All rights reserved. features, a r","Part-of-speech tagging and partial parsing | Natural Language Understanding, chap | When push comes to shove: A computational model of the role of motor control in the acquisition of action verbs | The dynamics of vagueness | Blender 3D graphics creation suite | SAM: A perceptive spoken languageunderstanding robot | Reference resolution in the wild | Risk-taking and recovery in task-oriented dialogue | A grouping principle and four applications | A computational model to connect gestalt perception and natural language | Design considerations for generic grouping in vision | The agreement process: An empirical investigation of human-human computer-mediated collaborative dialogues | Augmenting user interfaces with adaptive speech commands | What the eyes say about speaking | Computational models of incremental semantic interpretation | Coupling perception and simulation: Steps towards conversational robotics | What’s in the lexicon | Fitting words: vague words in context | A computational model of color perception and color naming | what” and “where” in spatial language and spatial cognition | Language and Perception | Ubiquitous talker: Spoken language interaction with real world objects | KARMA: Knowledge-based Action Representations for Metaphor and Aspect | Lexical semantics and compositionality | Incremental speech production and referential overspecification | The Generative Lexicon | The Human Semantic Potential | Grounding spatial language in perception: An empirical and computational investigation | Learning visually-grounded words and syntax for a scene description task | A trainable spoken language understanding system | Learning words from sights and sounds: A computational model | Using model-theoretic semantic interpretation to guide statistical parsing and word recognition in a spoken language interface | Normalized cuts and image segmentation | Grounding the lexical semantics of verbs in visual perception using force dynamics and event logic | Laws of organization in perceptual forms | Procedures as a representation for data in a computer program for understanding natural language | Utterance segmenation for spontaneous speech recognition",rejected,000
1107.0034.pdf.json,Price Prediction in a Trading Agent Competition,"Many market decision problems involve some anticipation or forecast of future prices. Price prediction is particularly important, for example, in committing to a binding offer to purchase a good that has complements to be purchased at a later date. This sort of scenario arises whenever there are sequential or overlapping auctions for related goods. Although market forecasting techniques are in widespread use over a broad range of applications, we are unaware of studies exploring the problem in a context reminiscent of multi-auction environments. The annual Trading Agent Competition (TAC) (Wellman et al., 2003) provides a convenient medium for studying approaches to price prediction. As an open-invitation tournament, it has attracted a diverse community of researchers interested in many aspects of trading agent strategy. Price prediction has turned out to be a pivotal issue in the TAC market game,1 and an interesting array of approaches has emerged from agent designers’ efforts over three years of competition. Since TAC defines a controlled, regular, repeatable, and transparent environment for observing trading agent behavior, it is also uncommonly amenable to analysis. 1. We refer to the original (“classic”) TAC game, a scenario in the domain of travel shopping. Sadeh et al. (2003) introduced a second game (“TAC/SCM”), in the domain of supply chain management, and we expect that further domains will be the subject of trading competitions in coming years. c 2004 AI Access Foundation. All rights reserved.","Fast approximations for sums of distances, clustering and the Fermat-Weber problem | Bid determination in simultaneous auctions: An agent architecture | Walverine: A Walrasian trading agent | Agent-oriented software engineering for successful TAC participation | The 2002 trading agent competition: An overview of agent strategies | Bidding under uncertainty in simultaneous auctions. In IJCAI-03 Workshop on Trading Agent Design and Analysis, Acapulco | SouthamptonTAC: An adaptive autonomous trading agent | The Walrasian Vision of the Microeconomy | kavayaH: A trading agent developed for TAC-02 | TAC-03: A supply-chain trading competition | Multiagent competitions and research: Lessons from RoboCup and TAC | The first international trading agent competition: Autonomous bidding agents | Decision-theoretic bidding based on learned density models in simultaneous, interacting auctions | A principled study of the design tradeoffs for autonomous trading agents",rejected,000
1107.0035.pdf.json,Compositional Model Repositories via Dynamic Constraint Satisfaction with Order-of-Magnitude Preferences,"Mathematical models form an important aid in understanding complex systems. They also help problem solvers to capture and reason about the essential features and dynamics of such systems. Constructing mathematical models is not an easy task, however, and many disciplines have contributed approaches to automate it. Compositional modelling (Falkenhainer & Forbus, 1991; Keppens & Shen, 2001b) is an important class of approaches to automated model construction. It uses predominantly knowledge-based techniques to translate a high level scenario into a mathematical model. The knowledge base usually consists of generic fragments of models that provide one of the possible mathematical representation of a process that occurs in one or more components. The inference mechanisms instantiate this knowledge base, search for the most appropriate selection of model fragments, and compose them into a mathematical model. Compositional modelling has been successfully applied to a variety of application domains ranging from simple physics, over various engineering problems to biological systems. The present work aims at a compositional modelling approach for building model repositories of ecological systems. In the ecological modelling literature, a range of models have been devised to formally characterise the various phenomena that occur in ecological systems. For example, the logistic growth (Verhulst, 1838) and the Holling predation (Holling, 1959) models describe the changes in the size of a population. The former expresses changes due to births and deaths and the latter changes due to one population feeding on another. A compositional model repository aims c©2004 AI Access Foundation. All rights reserved. KEPPENS & SHEN to make such (partial) models more generally usable by providing a mechanism to instantiate and compose them into larger models for more complex systems involving many interacting phenomena. Thus, the input to a compositional model repository is a scenario describ","Microeconomics with Calculus | Semiring-based constraint satisfaction and optimization | A compositional modeling language | Reasoning about nonlinear system identification | Numeric reasoning with relative orders of magnitude | Symbolic reasoning with relative orders of magnitude | An assumption-based TMS | A general labeling algorithm for assumption-based truth maintenance | Generalized physical networks for automated model building | Compositional modeling: finding the right model for the job | Modeling the Environment - An Introduction to System Dynamics Modeling of Environmental Systems | Principles of Systems | A formal basis for the heuristic determination of minimal cost paths | Diagnosis and therapy recognition for ecosystems - usage of modelbased diagnosis techniques | Transformation of qualitative dynamic models - application in hydroecology | Some characteristics of simple types of predation and parasitism | System Dynamics: A United Approach (Second Edition edition) | Compositional Ecological Modelling via Dynamic Constraint Satisfaction with Order-of-Magnitude Preferences | Disaggregation in compositional modelling of ecological systems via dynamic constraint satisfaction | On compositional modelling | On supporting dynamic constraint satisfaction with order of magnitude preferences | Inducing process models from continuous data | Modelling vegetation dynamics in mediterranean ecosystems: Issues of scale | Automated model selection for simulation based on relevance reasoning | Elements of physical biology | An essay on the principle of population | Hard, flexible and dynamic constraint satisfaction | Solution techniques for constraint satisfaction problems: Advanced approaches | Solution techniques for constraint satisfaction problems: Foundations | Minimizing conflicts: A heuristic repair method for constraint satisfaction and scheduling problems | Dynamic constraint satisfaction problems | Efficient compositional modeling for generating causal explanations | The balance of animal populations | A* algorithm | Automated modeling of complex systems to answer prediction questions | Random search and insect population models | Valued constraint satisfaction problems: Hard and easy problems | On the relative value of parasites and predators in the biological control of insect pests | Declarative bias in equation discovery | Using domain knowledge on population dynamics modeling for equation discovery | Foundations of Constraint Satisfaction | Solution reuse in dynamic constraint satisfaction problems | Recherches mathématiques sur la loi d’accroissement de la population | Fluctuations in the abundance of a species considered mathematically",rejected,000
1107.0037.pdf.json,,,,rejected,000
1107.0038.pdf.json,,,,rejected,000
1107.0040.pdf.json,,,,rejected,000
1107.0041.pdf.json,,,"Utility-based on-line exploration | Interleaved vs. a priori exploration | The Quickhull algorithm for convex | On a routing problem | Learning in navigation: Goal | Generalized best- rst search strategies and the optimality | A note on two problems in connexion with graphs | KBFS: K-best rst search | PHA*: Performing A* in unknown physical | Random distances within a rectangle and between two rectangles | A formal basis for the heuristic determina | Reinforcement learning: A survey | Searching for an optimal path in a tree with random costs | Organizational strategies for multi | Are many reactive agents better than a few deliberative ones | Incremental A | Depth- rst iterative-deepening: An optimal admissible tree search | Real-time heuristic search | Linear-space best- rst search | Finding optimal solutions to Rubik's Cube using pattern databases | Sliding-tile puzzles and Rubik's Cube in AI research | Spatial Tessellations, Concepts, and Applica | Studies in semi-admissible heursitics | Roadmap-A*: An algorithm for minimizing travel e ort | Optimal and e cient path planning for partially-known environments | Optimal Path Search in Unknown Physical Enviroments | Pruning duplicate nodes in depth- rst search | Vertex-ant-walk: A robust method",rejected,000
1107.0042.pdf.json,Restricted Value Iteration: Theory and Algorithms,"Partially Observable Markov Decision Processes (POMDPs) provide a general framework for sequential decision-making tasks where the effects of an agent’s actions are nondeterministic and the states of the world or environment are not known with certainty. Due to the model generality, POMDPs have found a variety of potential applications in reality (Monahan, 1982; Cassandra, 1998b). However, solving POMDPs is computationally intractable. Extensive efforts have been devoted to developing efficient algorithms for finding solutions to POMDPs (Parr & Russell, 1995; Cassandra, Littman, & Zhang, 1997; Cassandra, 1998a; Hansen, 1998; Zhang, 2001). Value iteration is a popular algorithm for solving POMDPs. Two central concepts in value iteration are belief state and value function. A belief state, a probability distribution over the state space, measures the probability that the environment is in each state. All possible belief states constitute a belief space. A value function specifies a payoff or cost for each belief state in the belief space. Value iteration proceeds in an iterative fashion. Each iteration, referred to as a dynamic programming (DP) update, computes a new value function from the current one. When the algorithm terminates, the final value function is used for the agent’s action selection. Value iteration is computationally expensive because, at each iteration, it updates the current value function over the entire belief space, which necessitates the solution of a large number of linear programs. One generic strategy to accelerate value iteration is to restrict value iteration, that is, DP updates, to a subset of the belief space. For simplicity, a subset of the belief space is referred to as belief subset. Existing value iteration algorithms working with belief subsets include a family of grid-based algorithms where DP updates calculate values for a finite grid (Lovejoy, c©2005 AI Access Foundation. All rights reserved. 1991; Hauskrecht, 1997; Zhou & Hansen","Optimal control of Markov decision processes with incomplete state estimation | Learning to act using real-time dynamic programming | Dynamic Programming | Planning with incomplete information as heuristic search in belief space | Structured reachability analysis for Markov decision processes | Computing optimal policies for partially observable decision processes using compact representations | On the complexity of partially observed Markov decision processes | Exact and approximate algorithms for partially observable Markov decision processes | A survey of POMDP applications | Incremental pruning: a simple, fast, exact method for partially observable Markov decision processes | An environment model for nonstationary reinforcement learning | Solving planning problems with large state and action spaces | Planning with deadlines in stochastic domains | Decomposition techniques for planning in stochastic domains | Anytime synthetic projection: maximizing the probability of goal satisfaction | Solving large POMDPs using real time dynamic programming | Finite memory control of partially observable systems | Heuristic search in cyclic AND/OR graphs | Incremental methods for computing bounds in partially observable Markov decision processes | Value-function approximations for partially observable Markov decision processes | Modeling treatment of ischemic heart disease with partially observable Markov decision processes | Planning and acting in partially observable stochastic domains | Policy iteration for factored MDPs | Efficient dynamic programming updates in partially observable Markov decision processes | The computational complexity of probabilistic planning | Computationally feasible bounds for partially observed Markov decision processes | On the undecidability of probabilistic planning and infinite horizon partially observable Markov decision problems | A survey of partially observable Markov decision processes: theory, models, and algorithms | The complexity of Markov decision processes | Flexible decomposition algorithms for weakly coupled Markov decision problems | Approximating optimal policies for partially observable stochastic domains | Point-based value iteration: an anytime algorithm for POMDPs | Value-directed compresseion of POMDPs | Markov decision processes: discrete stochastic dynamic programming | Exponential family PCA for belief compression in POMDPs | The optimal control of partially observable Markov processes over a finite horizon | The optimal control of partially observable decision processes | BI-POMDP: Bounded, incremental partially-observable Markovmodel planning | A model approximation scheme for planning in partially observable stochastic domains | Space-progressive value iteration: an anytime algorithm for a class of POMDPs | Speeding up the convergence of value iteration in partially observable Markov decision processes | Algorithms for partially observable Markov decision processes | Solving informative partially observable Markov decision processes | An improved grid-based approximation algorithm for POMDPs | A POMDP approximation algorithm that anticipates the need to observe",rejected,000
1107.0043.pdf.json,,,,rejected,000
1107.0045.pdf.json,Graduality in Argumentation,"As shown by Dung (1995), argumentation frameworks provide a unifying and powerful tool for the study of several formal systems developed for common-sense reasoning, as well as for giving a semantics to logic programs. Argumentation is based on the exchange and valuation of interacting arguments which support opinions and assertions. It can be applied, among others, in the legal domain, for collective decision support systems or for negotiation support. The fundamental characteristic of an argumentation system is the interaction between arguments. In particular, a relation of attack may exist between arguments. For example, if the argument takes the form of a logical proof, arguments for a proposition and arguments against this proposition can be advanced. In that case, the attack relation relies on logical inconsistency. The argumentation process is usually divided in two steps: a valuation of the relative strength of the arguments, followed by the selection of the most acceptable arguments. In the valuation step, it is usual to distinguish two different types of valuations: intrinsic valuation: here, the value of an argument is independent of its interactions with the other arguments. This enables to simply express to what extent an argument increases the confidence in the statement it supports (see Pollock, 1992; Krause, Ambler, Elvang, & Fox, 1995; Parsons, 1997; Prakken & Sartor, 1997; Amgoud & Cayrol, 1998; Kohlas, Haenni, & Berzati, 2000; Pollock, 2001). c©2005 AI Access Foundation. All rights reserved. For example, in the work of Krause et al. (1995), using the following knowledge base, composed of (formula, probability) pairs {(φ1, 0.8), (φ2, 0.8), (φ3, 0.8), ((φ1 ∧ φ2 → φ4), 1), ((φ1 ∧ φ3 → φ4), 1)}, two arguments can be produced1: A1 =< {φ1, φ2, (φ1 ∧ φ2 → φ4)}, φ4 > and A2 =< {φ1, φ3, (φ1 ∧ φ3 → φ4)}, φ4 >. Both arguments have the same weight 0.8 × 0.8 × 1 = 0.64, and the formula φ4 has the weight 0.64 + 0.64− 0.512 = 0.7682. interaction-based valuation: ","On the acceptability of arguments in preference-based argumentation | Inferring from inconsistency in preference-based argumentation frameworks | Value based argumentation frameworks | A logic-based theory of deductive arguments | Critique et amélioration de l’évaluation graduelle par tuples pour le traitement des circuits | Gradual acceptability in argumentation systems | Gradual handling of contradiction in argumentation frameworks | Autour de la sémantique préférée des systèmes d’argumentation | On the acceptability of arguments and its fundamental role in nonmonotonic reasoning, logic programming and n-person games | Coherence in finite argument systems | Coherence in finite argument system | Dialectic reasoning with inconsistent information | Robust semantics for argumentation frameworks | Computer supported argumentation and collaborative decision making: the hermes system | Probabilistic argumentation systems and abduction | A logic of argumentation for reasoning under uncertainty | Argument systems - a uniform basis for non-monotonic reasoning | Normative argumentation and qualitative probability | Reasoning from inconsistency: A taxonomy of principles for resolving conflict | How to reason defeasibly | Defeasible reasoning with variable degrees of justification | Argument-based extended logic programming with defeasible priorities | A mathematical treatment of defeasible reasoning and its implementation | On the existence and multiplicity of extension in dialectical argumentation | Abstract argumentation systems | Mathématiques discrètes et informatique",rejected,000
1107.0046.pdf.json,Explicit Learning Curves for Transduction and Application to Clustering and Compression Algorithms,"The bulk of work in Statistical Learning Theory has dealt with the inductive approach to learning. Here one is given a finite set of labeled training examples, from which a rule is inferred. This rule is then used to label new examples. As pointed out by Vapnik (1998) in many realistic situations one actually faces an easier problem where one is given a training set of labeled examples, together with an unlabeled set of points which needs to be labeled. In this transductive setting, one is not interested in inferring a general rule, but rather only in labeling this unlabeled set as accurately as possible. One solution is of course to infer a rule as in the inductive setting, and then use it to label the required points. However, as argued by Vapnik (1982, 1998), it makes little sense to solve what appears to be an easier c©2004 AI Access Foundation. All rights reserved. problem by ‘reducing’ it to a more difficult one. While there are currently no formal results stating that transduction is indeed easier than induction1 it is plausible that the relevant information carried by the test points can be incorporated into an algorithm, potentially leading to superior performance. Since in many practical situations we are interested in evaluating a function only at some points of interest, a major open problem in statistical learning theory is to determine precise relations between induction and transduction. In this paper we present several general error bounds for transductive learning.2 We also present a general technique for establishing error bounds for transductive learning algorithms based on compression and clustering. Our bounds can be viewed as extensions of McAllester’s PAC-Bayesian framework (McAllester, 1999, 2003a, 2003b) to transductive learning. The main advantage of using the PAC-Bayesian approach in transduction, as opposed to induction, is that here prior beliefs on hypotheses can be formed based on the unlabeled test data. This flexibility allows for th",,rejected,000
1107.0047.pdf.json,Decentralized Control of Cooperative Systems: Categorization and Complexity Analysis,"Markov decision processes have been widely studied as a mathematical framework for sequential decision-making in stochastic domains. In particular, single-agent planning problems in stochastic domains were modeled as partially observable Markov decision processes (POMDPs) or fully-observable MDPs (Dean, Kaelbling, Kirman, & Nicholson, 1995; Kaelbling, Littman, & Cassandra, 1998; Boutilier, Dearden, & Goldszmidt, 1995). Borrowing from Operations Research techniques, optimal plans can be computed for these planning problems by solving the corresponding Markov decision problem. There has been a vast amount of progress in solving individual MDPs by exploiting domain structure (e.g., Boutilier et al., 1995; Feng & Hansen, 2002). Approximations of MDPs have also been studied, for example, by Guestrin et al. (2003), assuming that the reward function can be decomposed into local reward functions each depending on only a small set of variables. We are interested in a single Markov decision process that is collaboratively controlled by multiple decision-makers. The group of agents cooperate in the sense that they all want to maximize a single global objective (or minimize the cost of achieving it). Nevertheless, the decision-makers do not have full observability of the whole system at the time of execution. These processes can be found in many application domains such as multi-robot problems, flexible manufacturing and information gathering. For example, consider a group of space c©2004 AI Access Foundation. All rights reserved. exploration rovers, like those sent by NASA to Mars.1 These rovers could be assigned a set of experiments to perform on the planet before they need to meet. They may have a limited amount of time to perform these experiments. Then, the robots need to decide what experiments to perform and how much time they should invest in each one given the available battery power and remaining time. Decentralized cooperative problems also include information gather","Communication in reactive multiagent robotic systems | Transition-independent decentralized Markov decision processes | The complexity of decentralized control of Markov decision processes | Communication-proof equilibria in cheap-talk games | Sequential optimality and coordination in multiagent systems | Exploiting structure in policy construction | The dynamics of reinforcement learning in cooperative multiagent systems | Planning under time constraints in stochastic domains | Generalizing the partial global planning algorithm | Coordination of Distributed Problem Solvers | Symbolic heuristic search for factored Markov decision processes | KQML as an agent communication language | Decentralized language learning through acting | Optimizing information exchange in cooperative multi-agent systems | Goal-oriented Dec-MDPs with direct communication | Collaborative plans for complex group action | Distributed planning in hierarchical factored MDPs | Multiagent planning with factored MDPs | Efficient solution algorithms for factored MDPs | Dynamic programming for partially observable stochastic games | Planning and acting in partially observable stochastic domains | Games and Decisions | Taming decentralized POMDPs: Towards efficient policy computation for multiagent settings | On the complexity of designing distributed protocols | Intractable problems in control theory | The complexity of Markov decision processes | Probabilistic Reasoning in Intelligent Systems | Learning to cooperate via policy search | The communicative multiagent team decision problem: Analyzing teamwork theories and models | The complexity of multiagent systems: The price of silence | A real-time world model for multi-robot teams with high-latency communication | Principles of metareasoning | Distributed value functions | The optimal control of partially observable Markov processes over a finite horizon | The contract net protocol: High level communication and control in a distributed problem solver | Cheap talk, coordination, and evolutionary stability | General principles of learning-based multi-agent systems | Communication decisions in multi-agent cooperation: Model and experiments",rejected,000
1107.0048.pdf.json,Reinforcement Learning for Agents with Many Sensors and Actuators Acting in Categorizable Environments,"The division between knowledge-based and behavior-based artificial intelligence has been fundamental to achieving successful applications within the field of autonomous robots (Arkin, 1998). However, up to now, this division has had few repercussions for reinforcement learning. Within artificial intelligence, reinforcement learning has been formalized in a very general way borrowing ideas from the dynamic programming and decision-theory fields. Within this formalization, the objective of reinforcement-learning methods is to establish a correct mapping from a set of abstract observations (formalized as states) to a set of high level actions, without being worried about how these sets of states and actions are defined (for an introduction to reinforcement learning you can check Kaelbling, Littman, & Moore, 1996; Sutton & Barto, 1998, among many others). Algorithms developed within this general framework can be used in different fields without any modification. For each c©2005 AI Access Foundation. All rights reserved. particular application, the definition of the sets of states and actions is the responsibility of the programmer and is not supposed to be part of the reinforcement-learning problem. However, as clearly pointed by Brooks (1991), in autonomous robots the major hurdles are those related with perception and action representations. For this reason, in a robotic task, what traditional reinforcement-learning research assumes to be the major problem (connecting states and actions) is simpler than what it assumes as given (the definition of states and actions). The consequence is that existing reinforcement-learning methods are best suited for problems that fall into the symbolic artificial intelligence domain than for those that belong to robotics. Due to the generality of existing reinforcement-learning algorithms, a robotic problem can be analyzed and re-formulated so that it can be tackled with the available reinforcement-learning tools but, in many cases, t","Behavior-Based Robotics. Intelligent Robotics and Autonomous Agents | Dynamic Programming | Decision-theoretic planning: Structural assumptions and computational leverage | Intelligence without representation | C-XCS: An implementation of the XCS in C. (http://www.cs.bath.ac.uk/ amb/LCSWEB/computer.htm) | Control of a six-legged robot walking on abrupt terrain | A control structure for the locomotion of a legged robot on difficult terrain | Input generalization in delayed reinforcement learning: An algorithm and performance comparisons | The dynamics of reinforcement learning in cooperative multiagent systems | Accelerating reinforcement learning by composing solutions of automatically identified subtasks | Neuronal Darwinism | Parallel Distributed Processing: Explorations in the Microstructure of Cognition. Volume 1: Foundations, chap. Distributed Representations | Hybrid learning architecture based on neural networks for adaptive control of a walking machine | Learning in Embedded Systems. A Bradford Book | Reinforcement learning: A survey | Sparse Distributed Memory | Q-learning of complex behaviors on a six-legged walking machine | Evolution and development of modular control architectures for 1-d locomotion in six-legged animats | Learning to coordinate behaviors | Automatic programming of behavior-based robots using reinforcement learning | Reinforcement Learning with Selective Perception and Hidden State | Co-evolving model parameters for anytime learning in evolutionary robotics | C-trace: A new algorithm for reinforcement learning of robotic control | Regularization algorithms for learning that are equivalent to multilayer networks | The speed prior: A new simplicity measure yielding near-optimal computable predictions | Learning to coordinate without sharing information | Reinforcement learning architectures for animats | Reinforcement Learning: An Introduction | Online learning with random representations | Generalization in reinforcement learning: Successful examples using sparse coarse coding | Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning | Multi-agent reinforcement learning: Independent vs. cooperative agents | A distributed genetic programming architecture for the evolution of robust insect locomotion controllers | Apprentissage Adaptatif et Apprentissage Supervisé par Algorithme Génétique | Adaptive switching circuits | Classifier fitness based on accuracy | Explore/exploit strategies in autonomy. In From Animals to Animats",rejected,000
1107.0050.pdf.json,,,An improved xed-parameter | Results and open problems on the Tower of Hanoi | Vertex cover: further observations and further | Parameterized computational feasibility | Parameterized complexity: A framework | Editorial note concerning advanced problem 3918 | Improving search techniques and using them on di erent environments | Compressing pattern databases | Solution to advanced problem 3918 | Computers and Intractability: A Guide to the Theory | Harnessing computational resources for e cient exhastive search | Criticizing solutions to relaxed models yields | A formal basis for the heuristic determination | The tower of Hanoi | Reducibility among combinatorial problems | Depth- rst iterative-deepening: An optimal admissible tree search | Macro-operators: A weak method for learning | Finding optimal solutions to Rubik's cube using pattern databases | Divide-and-conquer bidirectional search: First results | Best- rst frontier search with delayed duplicate detection | Disjoint pattern database heuristics | Time complexity of iterative-deepening-A | Finding optimal solutions to the twenty-four puzzle | Divide-and-conquer frontier search applied to optimal | ZRAM: a library of parallel search algorithms and its use in enu | Upper bounds for vertex cover further improved | Combinatorial Optimization: Algorithms | Heuristics | Solution to advanced problem 3918 | An iterative algorithm for the Reve's puzzle,rejected,000
1107.0051.pdf.json,On Prediction Using Variable Order Markov Models,"Learning of sequential data continues to be a fundamental task and a challenge in pattern recognition and machine learning. Applications involving sequential data may require prediction of new events, generation of new sequences, or decision making such as classification of sequences or sub-sequences. The classic application of discrete sequence prediction algorithms is lossless compression (Bell et al., 1990), but there are numerous other applications involving sequential data, which can be directly solved based on effective prediction of discrete sequences. Examples of such applications are biological sequence analysis (Bejerano & Yona, 2001), speech and language modeling (Schütze & Singer, 1994; Rabiner & Juang, 1993), text analysis and extraction (McCallum et al., 2000) music generation and classification (Pachet, 2002; Dubnov et al., 2003), hand-writing recognition (Singer & Tishby, 1994) and behaviormetric identification (Clarkson & Pentland, 2001; Nisenson et al., 2003).1 1. Besides such applications, which directly concern sequences, there are other, less apparent applications, such as image and texture analysis and synthesis that can be solved based on discrete sequence prediction algorithms; see, e.g., (Bar-Joseph et al., 2001). c©2004 AI Access Foundation. All rights reserved. The literature on prediction algorithms for discrete sequences is rather extensive and offers various approaches to analyze and predict sequences over finite alphabets. Perhaps the most commonly used techniques are based on Hidden Markov Models (HMMs) (Rabiner, 1989). HMMs provide flexible structures that can model complex sources of sequential data. However, dealing with HMMs typically requires considerable understanding of and insight into the problem domain in order to restrict possible model architectures. Also, due to their flexibility, successful training of HMMs usually requires very large training samples (see hardness results of Abe & Warmuth, 1992, for learning HMMs). In ","On the computational complexity of approximating probability distributions by probabilistic automata | Text compression by context tree weighting | A new method for analyzing protein sequence relationships based on sammon maps | A corpus for the evaluation of lossless compression algorithms | Texture mixing and texture movie synthesis using statistical learning | Variations on probabilistic suffix trees: Statistical modeling and the prediction of protein | Solving problems of context modeling | Semantically motivated improvements for PPM variants | A block-sorting lossless data compression algorithm | Protein structure prediction center | Compressing XML with multiplexed hierarchical PPM models | Predicting daily behavior via wearable sensors | Unbounded length contexts for PPM | Data compression using adaptive coding and partial string matching | A convergent gambling estimate of the entropy of English | Elements of Information Theory | The origin and evolution of protein superfamilies | Universal lossless data compression algorithms | Multi-class protein fold recognition using support vector machines and neural | PPMexe: PPM for compressing software | Using machine-learning methods for musical style modeling | Relations between entropy and error probability | Parser for protein folding | The design and analysis of efficient lossless data compression systems | Using the Fisher kernel method to detect remote protein homologies | Prediction of protein structural classes by a new measure of information discrepancy | On-line algorithms for combining language models | Improved smoothing for probabilistic suffix trees seen as variable order Markov chains | The performance of universal encoding | Structural class prediction: An application of residue distribution along the sequence | A note on the Ziv-Lempel model for compressing individual sequences | Folding units in globular proteins | Mismatch string kernels for discriminative protein | Structural patterns in globular proteins | An analysis of the burrows-wheeler transform | Concentration inequalities for the missing mass and for histogram rule error | Maximum entropy Markov models for information extraction and segmentation | What are the baselines for protein fold recognition | A strong version of the redundancy-capacity theorem of universal coding | On loss functions which minimize to conditional expected values and posterior probabilities | Implementing the PPM data compression scheme | SCOP: A structural classification of proteins database for the investigation of sequences and structures | The Data Compression Book (2nd ed.). MIS:Press | Protein is incompressible | Towards behaviometric security systems: Learning to identify a typist | Always Good Turing: Asymptotically optimal probability estimation | Playing with virtual musicians: The continuator in practice | Sequence comparisons using multiple sequences detect three times as many remote homologues as pairwise methods | A tutorial on hidden Markov models and selected applications in speech recognition | Fundamentals of Speech Recognition | A universal data compression system | Universal coding, information, prediction, and estimation | The power of amnesia: Learning probabilistic automata with variable memory length | Hierarchic organization of domains in globular proteins | Implementing the context tree weighting method for text compression | Redundancy of the Lempel-Ziv incremental parsing rule | Part-of-speech tagging using a variable memory Markov model | PPM: One step to practicality | Adaptive mixtures of probabilistic transducers | Dynamical encoding of cursive handwriting | Pfam: A comprehensive database of protein domain families based on seed | A genomic perspective on protein families | Using compression based language models for text categorization | Using compression for source based classification of text | A context-tree weighting method for text generating sources | Implementing the context-tree weighting method: Arithmetic coding | Weighting Techniques in Data Compression Theory and Algorithms | The context-tree weighting method: Extensions | The context-tree weighting method: Basic properties | The zero-frequency problem: Estimating the probabilities of novel events in adaptive text compression | Text mining: A new frontier for lossless compression | Within the twilight zone: A sensitive profile-profile comparison tool based on information theory | Protomap: Automatic classification of protein sequences, a hierarchy of protein families, and local maps of the protein | Compression of individual sequences via variable-rate coding",rejected,000
1107.0052.pdf.json,,,,rejected,000
1107.0053.pdf.json,Finding Approximate POMDP Solutions Through Belief Compression,"Decision making is one of the central problems of artificial intelligence and robotics. Most robots are deployed into the world to accomplish specific tasks, but the real world is a difficult place in which to act—actions can have serious consequences. Figure 1(a) depicts a mobile robot, Pearl, designed to operate in the environment shown in Figure 1(b), the Longwood retirement facility in Pittsburgh. Real world environments such as Longwood are characterized by uncertainty; sensors such as cameras and range finders are noisy and the entire world is not always observable. A large number of state estimation techniques explicitly recognize the impossibility of correctly identifying the true state of the world (Gutmann, Burgard, Fox, & Konolige, 1998; Olson, 2000; Gutmann & Fox, 2002; Kanazawa, c©2005 AI Access Foundation. All rights reserved. Koller, & Russell, 1995; Isard & Blake, 1998) by using probabilistic techniques to track the location of the robot. Such state estimators as the Kalman filter (Leonard & DurrantWhyte, 1991) or Markov localization (Fox, Burgard, & Thrun, 1999; Thrun, Fox, Burgard, & Dellaert, 2000) provide a (possibly factored, Boyen & Koller, 1998) distribution over possible states of the world instead of a single (possibly incorrect) state estimate. In contrast, controllers such as motion planners, dialogue systems, etc. rarely model the same notions of uncertainty. If the state estimate is a full probability distribution, then the controller often uses a heuristic to extract a single “best” state, such as the distribution’s mean or mode. Some planners compensate for the inevitable estimation errors through robust control (Chen, 2000; Bagnell & Schneider, 2001), but few deployed systems incorporate a full probabilistic state estimate into planning. Although the most-likely-state method is simple and has been used successfully by some real applications (Nourbakhsh, Powers, & Birchfield, 1995), substantial control errors can result when the distri","Autonomous helicopter control using reinforcement learning policy search methods | GTM: the generative topographic mapping | Computing optimal policies for partially observable Markov decision processes using compact representations | Tractable inference for complex stochastic processes | A heuristic variable grid solution method for POMDPs | Acting under uncertainty: Discrete Bayesian models for mobile-robot navigation | Robust and H-∞ Control | Algorithms for Partially Observable Markov Decision Processes | A generalization of principal components analysis to the exponential family | Multidimensional Scaling | Markov localization for mobile robots in dynamic environments | Singular value decomposition and least squares solutions | Stable function approximation in dynamic programming | An experimental comparison of localization methods | An experimental comparison of localization methods continued | Dynamic programming for POMDPs using a factored state representation | Solving POMDPs by searching in policy space | Value-function approximations for partially observable Markov decision processes | Stochastic neighbor embedding | Dynamic Programming and Markov Processes | CONDENSATION – conditional density propagation for visual tracking | Principal Component Analysis | Stochastic simulation algorithms for dynamic probabilistic networks | Self-organized formation of topologically correct feature maps | Learning the parts of objects by non-negative matrix factorization | Mobile robot localization by tracking geometric beacons | Computationally feasible bounds for partially observable Markov decison processes | Directional Statistics (2nd edition) | Generalized Linear Models (2nd edition) | Learning finite-state controllers for partially observable environments | Variable resolution discretization for high-accuracy solutions of optimal control problems | Variable resolution discretization in optimal control | DERVISH an office-navigating robot | Probabilistic self-localization for mobile robots | Point-based value iteration: An anytime algorithm for POMDPs | Policy-contingent abstraction for robust robot control | Value-directed compression of POMDPs | Convex Analysis | Nonlinear dimensionality reduction by locally linear embedding | Global coordination of local linear models | Coastal navigation with mobile robots | Artificial Intelligence: A Modern Approach | Learning geometrically-constrained hidden markov models for robot navigation: Bridging the geometrical-topological gap | A global geometric framework for nonlinear dimensionality reduction | Robust Monte Carlo localization for mobile robots | BI-POMDP: Bounded, incremental partially-observable Markovmodel planning | Speeding up the convergence of value iteration in partially observable Markov decision processes | An improved grid-based approximation algorithm for POMDPs",rejected,000
1107.0054.pdf.json,A Comprehensive Trainable Error Model for Sung Music Queries,"Many approaches have been proposed for the identification of viable targets for a query in a music database. Query-by-humming systems attempt to address the needs of the nonexpert user, for whom a natural query format – for the purposes of finding a tune, hook or melody of unknown providence – is to sing it. Our goal is to demonstrate a unifying model, expressive enough to account for the complete range of modifications observed in the performance and transcription of sung musical queries. Given a complete model for singer error, we can accurately determine the likelihood that, given a particular target (or song in a database), the singer would produce some query. These likelihoods offer a useful measure of similarity, allowing a query-by-humming (QBH) system to identify strong matches to return to the user. Given the rate at which new musical works are recorded, and given the size of multimedia databases currently deployed, it is generally not feasible to learn a separate model for each target in a multimedia database. Similarly, it may not be possible to customize an error model for every individual user. As such, a QBH matcher must perform robustly across a broad range of songs and singers. We develop a method for training our error model that functions well across singers with a broad range of abilities, and successfully generalizes to works for which no training examples have been given (see Section 11). Our approach (described in Section 9) is an extension of a standard re-estimation algorithm (Baum & c©2004 AI Access Foundation. All rights reserved. Eagon, 1970), and a special case of Expectation Maximization (EM) (Dempster, Laird, & Jain, 1977). It is applicable to hidden Markov models (HMM) with the same dependency structure, and is demonstrated to be convergent (see Appendix A).","Gapped BLAST and PSI-BLAST: A New Generation of Protein Database Search Programs | To catch a chorus: Using chroma-based representations for audio thumbnailing | A maximization technique occurring in the statistical analysis of probabilistic functions of markov chains | Musart: Music retrieval via aural queries | The musart music-retrieval system: An overview | Accurate short-term analysis of the fundamental frequency and the harmonics-to-noise ratio of a sampled sound | Melody retrieval on the web | A Metric Index for Approximate String Matching | Maximum likelihood from incomplete data via the em algorithm | Evaluating a simple approach to music information retrieval: conceiving melodic n-grams as text | Biological Sequence Analysis | Melody spotting using hidden markov models | Algorithms on strings, trees, and sequences | Spoken language processing, chap. Large-vocabulary search algorithms, pp | An Efficient Index Structure for String Databases | String matching techniques for music retrieval | Melody matching directly from audio | Towards the digital music library: Tune retrieval from acoustic input | The new zealand digital library MELody inDEX | Johnny can’t sing: A comprehensive error model for sung music queries | Oasis: An online and accurate technique for localalignment searches on biological sequences | Comparison of musical sequences | Timing information for musical query matching | Algorithms for chordal analysis | Cubyhum: a fully functional, “query by humming” system | Flexible sequence similarity searching with the fasta3 program package | An audio front end for query-by-humming systems | A tutorial on hidden markov models and selected applications in speech recognition | Hmm-based musical query retrieval | Sensitivity and Selectivity in Protein Similarity Searches: A Comparison of Smith-Waterman in Hardware to BLAST and FASTA | Melodic resolution in music retrieval | Recognition of musical key: Exploratory study | Content-based retrieval for music collections | Overview of the fifth text retrieval conference | Sia(m)ese: An algorithm for transposition invariant, polyphonic content-based music retrieval | Warping indexes with envelope transforms for query by humming",rejected,000
1107.0055.pdf.json,Phase Transitions and Backbones of the Asymmetric Traveling Salesman Problem,"Phase transitions of combinatorial problems and thrashing behavior similar to phase transitions in combinatorial algorithms have drawn much attention in recent years (Gomes, Hogg, Walsh, & Zhang, 2001; Hogg, Huberman, & Williams, 1996; Martin, Monasson, & Zecchina, 2001). Having been extensively studied in the so-called spin glass theory (Mézard, Parsi, & Virasoro, 1987) in physics, phase transition refers to a phenomenon when some system properties change rapidly and dramatically when a control parameter undergoes a slight change around a critical value. Such transitions appear only in large systems. A larger system usually exhibits sharper and more abrupt phase transitions, leading to a phenomenon of crossover of the trajectories of phase transitions from systems of the same type but with different sizes. A daily-life example of phase transitions is water changing from ice (solid phase) to water (liquid phase) to steam (gas phase) when temperature increases. It has been shown that many combinatorial decision problems have phase transitions, including Boolean satisfiability (Cheeseman, Kanefsky, & Taylor, 1991; Mitchell, Selman, & Levesque, 1992; Hogg, 1995; Selman & Kirkpatrick, 1996; Monasson, Zecchina, Kirkpatrick, Selman, & Troyansky, 1999), graph coloring (Cheeseman et al., 1991), and the symmetric Traveling Salesman Problem (deciding the existence of a complete tour of vising a given set of cities with a cost less than a specified value) (Cheeseman et al., 1991; Gent & Walsh, 1996a). Phase transitions can be used to characterize typical-case c 2004 AI Access Foundation. All rights reserved. properties of difficult combinatorial problems (Gomes et al., 2001; Martin et al., 2001). The hardest problem instances of most decision problems appear very often at the points of phase transitions. Therefore, phase transitions have been used to help generate the hardest problem instances for testing and comparing algorithms for decision problems (Achlioptas, Gomes, Kaut","Generating satisfiable instances | The (2) limit in the random assignment problem | Branch and bound methods | Finite-size scaling | Pathology of traveling-salesman subtour-elimination algorithms | Phase transition and finite-size scaling for the integer partitioning problem | Exact solution of large-scale, asymmetric Traveling Salesman Problems | Some new branching and bounding criteria for the asymmetric traveling salesman problem | Where the really hard problems are | The asymmetric traveling salesman problem: Algorithms, instance generators, and tests | Searching for backbones and fat: A limit-crossing approach with applications | Constructive bounds and exact expectations for the random assignment problem | Frozen development in graph coloring | On a linear programming, combinatorial approach to the traveling salesman problem | Generalized best-first search strategies and the optimality of A | Asymptotic and finite size parameters for phase transitions: Hamiltonian circuit as a case study | When is the assignment bound asymptotically tight for the asymmetric traveling-salesman problem | The probabilistic relationship between the assignment and asymmetric traveling salesman problems | Computers and Intractability: A Guide to the Theory of NP-Completeness | The scaling of search cost | The TSP phase transition | Phase transitions and annealed theories: Number partitioning as a case study | Analysis of heuristics for number partitioning | IJCAI-2001 tutorial: Phase transitions and structure in combinatorial problems. http://www.cs.wustl.edu/ zhang/links/ijcai-phasetransitions.html | The Traveling Salesman Problem and Its Variations | Exploiting problem structure as a search heuristic | Phase transitions and the search problem | The Traveling Salesman Problem and its Variations, chap. Experimental Analysis of Heuristics for the ATSP | Reducibility among combinatorial problems | A patching algorithm for the nonsymmetric traveling-salesman problem | An upper bound on the expected cost of an optimal assignment | Searching for an optimal path in a tree with random costs | Probabilistic analysis of heuristics. In The Traveling Salesman Problem, pp. 181–205 | Optimization by simulated annealing | Critical behavior in the satisfiability of random boolean expressions | Configuration space analysis of traveling salesman problems | The Traveling Salesman Problem | An effective heuristic algorithm for the Traveling Salesman Problem | An algorithm for the traveling salesman problem | Linear assignment problems | Statistical mechanics methods and phase transitions in optimization problems | Probabilistic analysis of tree search | An expected-cost analysis of backtracking and non-backtracking algorithms | On the solution of the random link matching problem | Hard and easy distributions of SAT problems | Determining computational complexity from characteristic ’phase transitions | The travelling salesman problem with distances one and two | Clustering at the phase transitions | Heuristics: Intelligent Search Strategies for Computer Problem Solving | Critical behavior in the computational cost of satisfiability testing | Backbones in optimization and approximation | Computational performance of three subtour elimination algorithms for solving asymmetric traveling salesman problems | The gn,m phase transition is not hard for the hamiltonian cycle problem | On the expected value of a random assignment problem | Problems in physics with many scales of length | State-space Search: Algorithms, Complexity, Extensions, and Applications | Phase transitions and backbones of 3-SAT and maximum 3-SAT | Phase transitions of the asymmetric traveling salesman | Performance of linear-space search algorithms | A study of complexity transitions on the asymmetric Traveling Salesman Problem",rejected,000
1107.0089.pdf.json,Towards a Reliable Framework of Uncertainty-based Group Decision Support System,,"Analysis of Production as an Effect Combination of Activities | Nonlinear programming | Management Models and Industrial Applications of Linear Programming | Multiple Criteria Decision Making | Lexicographic orders, utilities and decision rules: A survey | Methods for quantifying subjective probabilities and multi-attribute utilities | Raiffa, Decisions With Multiple Objective: Preferences and Value Tradeoffs | Classement et choix en presence de point de vue multiples: Le methode electre | How to select and how to rank projects: The PROMETHEE method | The SIR method: A superiority and inferiority ranking method for multiple criteria decision making | Assessing a set of additive utility functions for multicriteria decision-making: the UTA Methods | Business failure prediction using UTADIS multicriteria analysis | Building additive utilities for multi-group hierarchical discrimination: the M.H.DIS method | A novel multicriteria group decision making approach with intuitionistic fuzzy SIR method | Exposition of a new theory on the measurement of risk | Statistical Decision Functions | Theory of Games and Statistical Decisions | The Foundations of Statistics | Decision analysis: Applied decision theory | Fuzzy Sets | Intuitionistic fuzzy sets | Interval-valued intuitionistic fuzzy sets | Operators over interval-valued intuitionistic fuzzy sets | Intuitionistic preference relations and their application in group decision making | Rough set | Rough Sets: Theoretical Aspects of Reasoning about Data, Dordrecht | Intelligent Decision Support: Handbook of Applications and Advances of Rough Sets theory, Dordrecht | Rough sets theory for multicriteria decision analysis | An ontology-driven framework for supporting complex decision process | Exploring Primary Activities of the Knowledge Chain",rejected,000
1107.0098.pdf.json,A Probabilistic Attack on NP-complete Problems,"Non-deterministic polynomial time complete (NP-complete) problems are of considerable theoretical and practical interest and play a central role in the theory of computational complexity in modern computer science. Currently, more than three thousand vital computational tasks in operations research, machine learning, hardware design, software verification, computational biology, and other fields have been shown to be NP-complete. The ‘completeness’ designates the property that, if an efficient (= polynomial-time) algorithm for solving any one of NP-complete problems could be found, then we would immediately have (as a minimum) an efficient algorithm for all problems in this class [1-4]. Despite persistent efforts by many talented researchers throughout several decades, it is not currently known whether NP-complete problems can be efficiently solved. An unproven conjecture broadly spread among complexity theorists is that such polynomial-time algorithm cannot exist. It is also a general belief that either proof or disproof of this conjecture can only be obtained through development of some new mathematical techniques. In the present paper, a novel approach to tackling NP-complete problems is proposed bringing a fresh perspective on the subject matter. More specifically, our approach takes the problem from the realm of discrete mathematics and reformulates it in the realm of continuous mathematics, where it is then treated using tools of mathematical analysis and probability theory. The main idea of the proposed method stems from recognizing that, owing to exponentially large solution space for whichever NP-complete problem, any prospective approach to solving it by examining solution candidates sequentially, one by one, is predestined to fail in yielding an efficient algorithm, regardless of how smart and sophisticated this approach is. Assume for a moment that an efficient algorithm for solving NP-complete problems does exist. Then we can only hope to discover it if","The complexity of theorem-proving procedures | Reducibility among combinatorial problems, in Complexity of Computer Computations | Computers and Intractability: A Guide to the Theory of NP- Completeness | Combinatorial Optimization: Algorithms and Complexity | The complexity of satisfiability problems | Bonferroni-Type Inequalities with Applications, New York: Springer-Verlag | Probability, Random Variables, and Stochastic Processes, 2nd ed | An empirical study of phase transitions in binary constraint satisfaction problems | Determining computational complexity from characteristic ‘phase transitions | Exact Phase Transitions in Random Constraint Satisfaction Problems | The phase transition in Exact Cover, Chicago",rejected,000
1107.0134.pdf.json,The Influence of Global Constraints on Similarity Measures for Time-Series Databases,"In many scientific fields, a time series consists of a sequence of values or events obtained over repeated measurements of time [2]. Time-series analysis is comprised of methods that attempt to understand time series, to explain the underlying context of the data points (where did they come from? what generated them?), or to make forecasts. Time-series databases are popular in many applications, such as stock market analysis, economic and sales forecasting, budgetary analysis, utility studies, inventory studies, yield projections, workload projections, process and quality control, observation of natural phenomena, scientific and engineering experiments, medical treatments, etc. As a consequence, in the last decade there has occurred an increasing amount of interest in querying and mining such data, which resulted in a large amount of work introducing new methodologies for different task types including: indexing, classification, clustering, prediction, segmentation, anomaly detection, etc. [1, 2, 3, 4]. One of the most important aspects of time-series analysis is the choice of appropriate similarity/distance measure – the measure which tells in what extent two time series are similar. Similarity-based retrieval is explicitly or implicitly used in all above-mentioned task types of time-series analysis. However, unlike data types in traditional databases where the similarity/distance definition is straightforward, the distance between time series needs to be carefully defined in order to reflect the underlying (dis)similarity of these specific data, which is usually based on shapes and patterns. As expected, there exists a large number of measures for expressing (dis)similarity of time series data proposed in the literature, e.g., Euclidean distance (ED) [1], Dynamic Time Warping (DTW) [5], distance based on Longest Common Subsequence (LCS) [6], Edit Distance with Real Penalty (ERP) [7], Edit Distance on Real sequence (EDR) [8], Sequence Weighted Alignment model (Swal","Fast Subsequence Matching in TimeSeries Databases | Data Mining: Concepts and Techniques | A Decade of Progress in Indexing and Mining Large Time Series Databases | Querying and Mining of Time Series Data: Experimental Comparison of Representations and Distance Measures | Exact indexing of dynamic time warping | Discovering similar multidimensional trajectories | On the marriage of lp-norms and edit distance | Robust and fast similarity search for moving object trajectories | An efficient and accurate method for evaluating time series similarity | Three Myths about Dynamic Time Warping | A framework for time-series analysis. In Proceedings of the 14th international conference on Artificial intelligence: methodology, systems, and applications (AIMSA'10) | The UCR Time Series Classification/Clustering Homepage: http://www.cs.ucr.edu/~eamonn/time_series_data | Fast similarity search in the presence of noise, scaling, and translation in times-series databases | Haar wavelets for efficient similarity search of time-series: with and without time warping | Dimensionality reduction for fast similarity search in large time series databases | Locally adaptive dimensionality reduction for indexing large time series databases | Exact indexing of dynamic time warping | Fast time series classification using numerosity reduction | Using dynamic time warping to find patterns in time series | Discovering Similar Multidimensional Trajectories | Dynamic programming algorithm optimization for spoken word recognition | Minimum prediction residual principle applied to speech recognition | Time-series classification in many intrinsic dimensions",rejected,000
1107.0194.pdf.json,J. Dundas: LAW OF CONNECTIVITY IN MACHINE LEARNING Law of Connectivity in Machine Learning,,"Neural Networks for Pattern Recognition | An Introduction to Neural Networks | The Algebraic Mind: Integrating Connectionism and Cognitive Science (Learning, Development, and Conceptual Change) | Statistical Decision Theory and Bayesian Analysis. Springer Series in Statistics (II Ed) | Hidden Markov processes | A Learning Algorithm for Boltzmann Machines | Bretthorst, “Bayesian Spectrum Analysis and Parameter Estimation | Information Theory, Inference, and Learning Algorithms | Case based Reasoning: Foundation Issues, Methodological Variations, and System Approaches | Supervised Machine Learning: A Review of Classification Techniques | Introduction to Data Mining | Learning to predict by the methods of temporal differences | Self-organizing maps"". Neural networks - A comprehensive foundation (2nd Ed.), Prentice-Hall, ISBN 0-13-908385-5 | Fast algorithms for mining association rules in large databases | http://www.cs.huji.ac.il/labs/learning/Papers/allerton.pdf “The Information Bottleneck method | IBSEAD: - A self-evolving self-obsessed learning algorithm for machine learning | GPS: a case study in generality and problem solving | The History of Western Philosophy | Embodiments of Mind | In Search of Memory: the Emergence of a New Science of Mind | Hegel: A Reinterpretation",rejected,000
1107.0268.pdf.json,,"Solving time for a SAT instance can significantly vary for different solvers. Therefore, for many SAT instances, availability of different solvers may be beneficial. This observation leads to algorithm portfolios which, among several available solvers, select one that is expected to perform best on a given instance. This selection is based on data about the performance of available solvers on a large training set of instances. The problem of algorithm portfolio is not limited only M. Nikolić Faculty of Mathematics, University of Blegrade, Belgrade, Serbia E-mail: nikolic@matf.bg.ac.rs Tel.: +381648650064 F. Marić Faculty of Mathematics, University of Blegrade, Belgrade, Serbia E-mail: filip@matf.bg.ac.rs P. Janičić Faculty of Mathematics, University of Blegrade, Belgrade, Serbia E-mail: janicic@matf.bg.ac.rs to the SAT problem, but can be considered in general (Huberman, Lukose, & Hogg, 1997; Gomes & Selman, 2001; Horvitz, Ruan, Gomes, Kautz, Selman, & Chickering, 2001). There are a number of approaches to algorithm portfolios for SAT, the most successful one being SATzilla (Xu, Hutter, Hoos, & Leyton-Brown, 2008) that regularly wins in various categories of SAT Competitions1. SATzilla is very successful, but is a rather complex machinery not easy to understand, reimplement or modify. In this paper we present an algorithm portfolio system, based on the k-nearest neighbors method, that is conceptually significantly simpler and more efficient than SATzilla. It derives from our earlier research on solver policy selection (Nikolić, Marić, & Janičić, 2009). The rest of the paper is organized as follows. In Section 2, some of the existing algorithm portfolios are described. In Section 3, the proposed technique is described and in Section 4 the experimental results are presented. The conclusions are drawn in Section 5.",A gender-based genetic algorithm for the automatic configuration of algorithms | Pattern Classification (2nd Edition). WileyInterscience | A bayesian approach to tackling hard computational problems | An economic approach to hard computational problems | Paramils: An automatic algorithm configuration framework | Isac – instancespecific algorithm configuration | Learning to select branching rules in the dpll procedure for satisfiability | Non-modelbased algorithm portfolios for SAT | Formalization and implementation of modern sat solvers | Instance-based selection of policies for sat solvers | Understanding Random SAT: Beyond the Clauses-to-Variables Ratio | Learning to Solve QBF | Latent Class Models for Algorithm Portfolio Methods | n-Gram-Based Classification and Unsupervised Hierarchical Clustering of Genome Sequences | SATzilla: Portfoliobased Algorithm Selection for SAT | SATzilla2009: an Automatic Algorithm Portfolio for SAT,rejected,000
1107.4985.pdf.json,Variational Gaussian Process Dynamical Systems,"Nonlinear probabilistic modeling of high dimensional time series data is a key challenge for the machine learning community. A standard approach is to simultaneously apply a nonlinear dimensionality reduction to the data whilst governing the latent space with a nonlinear temporal prior. The key difficulty for such approaches is that analytic marginalization of the latent space is typically intractable. Markov chain Monte Carlo approaches can also be problematic as latent trajectories are strongly correlated making efficient sampling a challenge. One promising approach to these time series has been to extend the Gaussian process latent variable model [1, 2] with a dynamical prior for the latent space and seek a maximum a posteriori (MAP) solution for the latent points [3, 4, 5]. Ko and Fox [6] further extend these models for fully Bayesian filtering in a robotics setting. We refer to this class of dynamical models based on the GP-LVM as Gaussian process dynamical systems (GPDS). However, the use of a MAP approximation for training these models presents key problems. Firstly, since the latent variables are not marginalised, the parameters of the dynamical prior cannot be optimized without the risk of overfitting. Further, the dimensionality of the latent space cannot be determined by the model: adding further dimensions always increases the likelihood of the data. In this paper we build on recent developments in variational approximations for Gaussian processes [7, 8] to introduce a variational Gaussian process dynamical system (VGPDS) where latent variables are approximately marginalized through optimization of a rigorous lower bound on the marginal likelihood. As well as providing a principled approach to handling uncertainty in the latent space, this allows both the parameters of the latent dynamical process and the dimensionality of the latent space to be determined. The approximation enables the application of our model to time series containing millions of dimen",Probabilistic non-linear principal component analysis with Gaussian process latent variable models | Gaussian process latent variable models for visualisation of high dimensional data | Gaussian process dynamical models | Gaussian process dynamical models for human motion | Hierarchical Gaussian process latent variable models | GP-BayesFilters: Bayesian filtering using Gaussian process prediction and observation models | Variational learning of inducing variables in sparse Gaussian processes | Bayesian Gaussian process latent variable model | Gaussian Processes for Machine Learning | Introduction to Gaussian processes | Pattern Recognition and Machine Learning (Information | The variational Gaussian approximation revisited | Gaussian process priors with uncertain inputs - application to multiple-step ahead time series forecasting | Modeling human motion using binary latent variables,rejected,000
1108.2989.pdf.json,A Theory of Multiclass Boosting,,"Optimal stragies and minimax lower bounds for online convex games | Reducing multiclass to binary: A unifying approach for margin classifiers | AdaBoost is consistent | Convexity, classification, and risk bounds | Error-correcting tournaments | Solving multiclass learning problems via errorcorrecting output codes | Multiclass boosting for weak classifiers | An adaptive version of the boost by majority algorithm | Boosting a weak learning algorithm by majority | Continuous drifting games | Experiments with a new boosting algorithm | Game theory, on-line prediction and boosting | A decision-theoretic generalization of on-line learning and an application to boosting | Classification by pairwise coupling | The rate of convergence | The strength of weak learnability | Improved boosting algorithms using confidence-rated | Boosting the margin | On the Consistency of Multiclass Classification | Statistical behavior and consistency of classification methods based on convex | Multi-class AdaBoost",rejected,000
1109.0820.pdf.json,ShareBoost: Efficient Multiclass Learning with Feature Sharing,"Learning to classify an object into a relevant target class surfaces in many domains such as document categorization, object recognition in computer vision, and web advertisement. In multiclass learning problems we use training examples to learn a classifier which will later be used for accurately classifying new objects. Typically, the classifier first calculates several features from the input object and then classifies the A short version of this manuscript will be presented at NIPS, Dec. 2011. Part of this work was funded by ISF 519/09. A.S. is on sabbatical from the Hebrew University. object based on those features. In many cases, it is important that the runtime of the learned classifier will be small. In particular, this requires that the learned classifier will only rely on the value of few features. We start with predictors that are based on linear combinations of features. Later, in Section 4, we show how our framework enables learning highly non-linear predictors by embedding non-linearity in the construction of the features. Requiring the classifier to depend on few features is therefore equivalent to sparseness of the linear weights of features. In recent years, the problem of learning sparse vectors for linear classification or regression has been given significant attention. While, in general, finding the most accurate sparse predictor is known to be NP hard (Natarajan, 1995; Davis et al., 1997), two main approaches have been proposed for overcoming the hardness result. The first approach uses `1 norm as a surrogate for sparsity (e.g. the Lasso algorithm (Tibshirani, 1996) and the compressed sensing literature (Candes & Tao, 2005; Donoho, 2006)). The second approach relies on forward greedy selection of features (e.g. Boosting (Freund & Schapire, 1999) in the machine learning literature and orthogonal matching pursuit in the signal processing community (Tropp & Gilbert, 2007)). A popular model for multiclass predictors maintains a weight vector for ea","Uncovering shared structures in multiclass classification | Multi-task feature learning | Consistency of the group lasso and multiple kernel learning | Shape matching and object recognition using shape contexts | Label embedding trees for large multi-class tasks | Decoding by linear programming | Deep big simple neural nets excel on handwritten digit recognition | Ultraconservative online algorithms for multiclass problems | Multiclass learnability and the erm principle | Greedy adaptive approximation | Training invariant support vector machines | Compressed sensing | Boosting with structural sparsity | Online multiclass learning by interclass hypothesis sharing | A short introduction to boosting | A decision-theoretic generalization of on-line learning and an application to boosting | Generalized additive models | Multi-label prediction via compressed sensing | The benefit of group sparsity | Learning with structured sparsity | Learning the kernel matrix with semidefinite programming | Gradient-based learning applied to document recognition | Fast group sparse classification | Sparse approximate solutions to linear systems | Introductory lectures on convex optimization: A basic course, volume 87 | Transfer learning for image classification with sparse prototype representations | An efficient projection for l 1,infinity regularization | Improved boosting algorithms using confidence-rated predictions | Trading accuracy for sparsity in optimization problems with sparsity constraints | Best practices for convolutional neural networks applied to visual document analysis | Max-margin markov networks | Learning to learn: Introduction | Regression shrinkage and selection via the lasso | Sharing visual features for multiclass and multiview object detection | Signal recovery from random measurements via orthogonal matching pursuit | Distance metric learning, with application to clustering with side-information | Class-size independent generalization analysis of some discriminative multi-category classification | Image classification using super-vector coding of local image descriptors",rejected,000
1109.1498.pdf.json,Structured Knowledge Representation for Image Retrieval,"Image retrieval is the problem of selecting, from a repository of images, those images fulfilling to the maximum extent some criterion specified by an end user. In this paper, we concentrate on content-based image retrieval, in which criteria express properties of the appearance of the image itself, i.e., on its pictorial characteristics. Most of the research in this field has till now concentrated in devising suitable techniques for extracting relevant cues with the aid of image analysis algorithms. Current systems result effective when the specified properties are so-called low-level characteristics, such as color distribution, or texture. For example, systems such as IBM’s QBIC1 can easily retrieve, among others, stamps containing the picture of a brown horse in a green field, when asked to retrieve images of stamps with brown central area over a greenish background. Nevertheless, present systems fail at treating correctly high-level characteristics of an image — such as, “retrieve stamps with a galloping horse”. First of all, most systems cannot even allow the user to specify such queries, because they lack a language for expressing highlevel features. Usually, this is overcome with the help of examples: “retrieve images similar to this one”. However, examples are quite ambiguous to interpret: which are the features 1. See e.g., http://wwwqbic.almaden.ibm.com/cgi-bin/stamps-demo c©2002 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved. in the example that should appear in retrieved images? This ambiguity produces a lot of “false positives”, as any one can experience. Even if relevant features are pointed out in the example, the system cannot tell whether what is pointed out is the color distribution, or its interpretation — after all, a galloping brown horse produces a color distribution which is more similar to a running brown fox than to a galloping white horse. In this aspect, image retrieval faces the same problems of object recognitio","Computing spatial similarity by games | Hybrid computation and reasoning for artificial vision | A schema for integrating concrete domains into concept languages | The Virage image search engine: an open framework for image management | A constraint-based approach to shape management in multimedia databases | The LIVEProject-Retrieval experiments based on evaluation viewpoints | Symbolic reasoning among 3-D models and 2-D images | Description logics for conceptual data modeling | Pattern matching for spatial point sets | Blobworld: A system for region-based image indexing and retrieval | Features integration and relevance feedback analysis in image similarity evaluation | Computable queries for relational databases | Iconic indexing by 2D strings | Geometric pattern matching under euclidean motion | The bayesian image retrieval system, PicHunter | A Description logic for image retrieval | Query by sketch and relevance feedback for contentbased image retrieval over the web | Reasoning in description logics | Representation and Recognition in Vision | Content-based retrieval by spatial similarity in image databases | Query by image and video content: The QBIC system | DOLORES: A system for logic-based retrieval of multimedia objects | Pictoseek: Combining color and shape invariant features for image retrieval | θR-string: A geometry-based representation for efficient and effective retrieval of images by spatial similarity | Design and evaluation of algorithms for image retrieval by spatial similarity | Foundations of spatioterminological reasoning with description logics | Representing and reasoning on conceptual queries over image databases | The VRML 2.0 Handbook | Query by visual example | Fast multiresolution image querying | Handbook of Computer Vision and Applications | NETRA: A toolbox for navigating large image database | Vision | A model of multimedia information retrieval | Towards computer vision with description logics: some recent progress | Reasoning and Revision in Hybrid Representation Systems | The QBIC project: Querying images by content using color, texture, and shape | A content-based search engine for VRML databases | Finding similar patterns in large image databases | An approach to perception in theory of actions: part 1 | Texture classification by a two-level hybrid scheme | Digital Image Processing | A logical framework for depiction and image interpretation | Equality and domain closure in first-order databases | Content-based image retrieval with relevance feedback in MARS | Modified Fourier descriptors for shape representation - a practical approach | A distance measure between attributed relational graphs for pattern recognition | VisualSEEK: a fully automated content-based image query system | Reasoning within fuzzy description logics | Arrangement: A spatial relation between parts for evaluating similarity of tomographic section | Principles of Database and Knowledge Base Systems, Vol | The KL-ONE family | Generalizing term subsumption languages to Fuzzy logic | Fuzzy sets",rejected,000
1109.6841.pdf.json,Learning Dependency-Based Compositional Semantics,"One of the major challenges in NLP is building systems that both handle complex linguistic phenomena and require minimal human effort. The difficulty of achieving both criteria is particularly evident in training semantic parsers, where annotating linguistic expressions with their associated logical forms is expensive but seemingly unavoidable. In this article, we overcome these limitations by developing new techniques that can learn rich semantic representations from weak supervision. What is the total population of the ten largest cities in California? city San Francisco Chicago Boston · · · loc Mount Shasta California San Francisco California Boston Massachusetts · · · · · · > 7 3 5 0 18 2 · · · · · · state Alabama Alaska Arizona · · · population Los Angeles 3.8 million San Francisco 805,000 Boston 617,000 · · · · · · count {} 0 {1,4} 2 {2,5,6} 3 · · · · · · System ? Figure 1: The concrete objective: a system that answers natural language questions given a structured database of facts. An example is shown in the domain of US geography. We demonstrate our techniques on the concrete task of building a system to answer questions given a structured database of facts–see Figure 1 for an example in the domain of US geography. The problem of ar X iv :1 10 9. 68 41 v1 [ cs .A I] 3 0 Se p 20 11 building natural language interfaces to databases (NLIDBs) has a long history in NLP, starting from the early days of AI with systems such as Lunar (Woods et al., 1972), Chat-80 (Warren and Pereira, 1982), and many others (see Androutsopoulos et al. (1995) for an overview). While quite successful in their respective limited domains, because these systems were constructed from manually-built rules, they became difficult to scale up, both to other domains and to more complex utterances. In response, against the backdrop of a statistical revolution in NLP during the 1990s, researchers began to build systems that could learn from examples, with the hope of overcoming the limitations of","Deterministic statistical mapping of sentences to underspecified semantics | Natural language interfaces to databases an introduction | Bootstrapping semantic parsers from conversations | A controlled fragment of DRT | Reinforcement learning for mapping instructions to actions | Reading between the lines: Learning to map high-level instructions to commands. In Association for Computational Linguistics (ACL) | Learning to win by reading manuals in a Monte-Carlo framework. In Association for Computational Linguistics (ACL) | Type-Logical Semantics | Learning to sportscast: A test of grounded language acquisition | Learning to interpret natural language navigation instructions from observations | Driving semantic parsing from the world’s response | Head-Driven Statistical Models for Natural Language Parsing | Abstract interpretation: a unified lattice model for static analysis of programs by construction or approximation of fixpoints | Search-based structured prediction | Constraint Processing | Reading to learn: Constructing features from semantic abstracts | A statistical semantic parser that integrates syntax and semantics | Semantic mapping between natural language questions and SQL queries via syntactic pairing | Learning from natural instructions | Confidence driven unsupervised semantic parsing. In Association for Computational Linguistics (ACL) | Question-bank: creating a corpus of parse-annotated questions | From Discourse to Logic: An Introduction to the Model-theoretic Semantics of Natural Language, Formal Logic and Discourse | Discourse representation theory | Using string-kernels for learning semantic parsers | Learning language semantics from ambiguous supervision | Learning to transform natural to formal languages | Inducing probabilistic CCG grammars from logical form with higher-order unification | Lexical generalization in CCG grammar induction for semantic parsing | Learning Dependency-Based Compositional Semantics | Online EM for unsupervised models. In North American Association for Computational Linguistics (NAACL) | Learning semantic correspondences with less supervision | Learning programs: A hierarchical Bayesian approach | Learning dependency-based compositional semantics. In Association for Computational Linguistics (ACL) | A generative model for parsing natural language to meaning representations | Building a large annotated corpus of English: the Penn Treebank | A fully statistical approach to natural language interfaces. In Association for Computational Linguistics (ACL) | The proper treatment of quantification in ordinary English | Updating quasi-newton matrices with limited storage | Learning accurate, compact, and interpretable tree annotation. In International Conference on Computational Linguistics and Association for Computational Linguistics (COLING/ACL), pages 433–440 | A Bayesian model of the acquisition of compositional semantics | Towards a theory of natural language interfaces to databases | An algorithm for suffix stripping | A stochastic approximation method | Using model-theoretic semantic interpretation to guide statistical parsing and word recognition in a spoken language interface. In Association for Computational Linguistics (ACL) | The Syntactic Process | Using multiple clause constructors in inductive logic programming for semantic parsing | Learning to follow navigational directions | Graphical models, exponential families, and variational inference | An efficient easily adaptable system for interpreting natural language queries | Learning for semantic parsing with statistical machine translation | Learning synchronous grammars for semantic parsing with lambda calculus. In Association for Computational Linguistics (ACL), pages 960–967 | The lunar sciences natural language information system: Final report | Learning to parse database queries using inductive logic proramming | Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars | Online learning of relaxed CCG grammars for parsing to logical form",rejected,000
1110.1394.pdf.json,Learning Sentence-internal Temporal Relations,"The computational treatment of temporal information has recently attracted much attention, in part because of its increasing importance for potential applications. In multidocument summarisation, for example, information that is to be included in the summary must be extracted from various documents and synthesised into a meaningful text. Knowledge about the temporal order of events is important for determining what content should be communicated (interpretation) and for correctly merging and presenting information in the summary (generation). Indeed, ignoring temporal relations in either the information extraction phase or the summary generation phase potentially results in a summary which is misleading with respect to the temporal information in the original documents. In question answering, one often seeks information about the temporal properties of events (e.g., When did X resign? ) or how events relate to each other (e.g., Did X resign before Y? ). An important first step towards the automatic handling of temporal phenomena is the analysis and identification of time expressions. Such expressions include absolute date or time specifications (e.g., October 19th, 2000 ), descriptions of intervals (e.g., thirty years), indexical expressions (e.g., last week ), etc. It is therefore not surprising that much previous work has focused on the recognition, interpretation, and normalisation of time expressions1 (Wilson, Mani, Sundheim, & Ferro, 1. See also the Time Expression Recognition and Normalisation (TERN) evaluation exercise (http://timex2.mitre. org/tern.html). c 2005 AI Access Foundation. All rights reserved. LAPATA & LASCARIDES 2001; Schilder & Habel, 2001; Wiebe, O’Hara, Öhrström Sandgren, & McKeever, 1998). Reasoning with time, however, goes beyond temporal expressions; it involves interpretation of the order of events in discourse, analysis of their temporal relations, and generally the ability to draw inferences over time elements. An additional challenge ","Natural Language Understanding | Logics of Conversation | Probabilistic head-driven parsing for discourse structure | Information Fusion for Multi-Document Summarization: Praphrasing and Generation | Timeml-compliant text analysis for temporal reasoning | Bagging predictors | Stacked regressions | Building a discourse-tagged corpus in the framework of rhetorical structure theory | Estimating probabilities: a crucial task in machine learning | A maximum-entropy-inspired parser | Human expert-level performance on a scientific image analysis task by a system using combined artificial neural networks | Supersense tagging of unknown words in wordnet | Machine learning research: Four current directions | Selecting tnese aspect and connective words in language generation | The effects of aspectual class on the temporal sturcture of discourse: Semantics or pragmatics | WordNet: An Electronic Database | Tides temporal annotation guidelines | Experiments with a new boosting algorithm | A framework for resolution of time in natural language | Neural network ensembles | Algorithms for analyzing the temporal structure of discourse | Interpretation as abduction | Tense trees as the finite structure of discourse | From Discourse to the Lexicon: Introduction to Modeltheoretic Semantics of Natural Language, Formal Logic and Discourse Representation Theory | From Discourse to Logic: Introduction to Modeltheoretic Semantics of Natural Language, Formal Logic and Discourse Representation Theory. Kluwer, Dordrecht | The annotation of temporal information in natural language sentences | Coherence, Reference and the Theory of Grammar | Using subcategorisation to resolve verb class ambiguity | Temporal interpretation, discourse relations and commonsense entailment | English Verb Classes and Alternations | Temporally anchoring and ordering events in news | Inferring temporal ordering of events in news | A formal and computational synthesis of grosz and sidner’s and mann and thompson’s theories | An unsupervised approach to recognizing discourse relations | Temporal ontology and temporal reference | The specification of timeml | Arda summer workshop on graphical annotation toolkit for timeml | A Comprehensive Grammar of the English Language | From temporal expressions to temporal information: Smeantic tagging of news messages | A pilot study on annotating temporal relations in text | Non Parametric Statistics for the Behavioral Sciences | Sentence level discourse parsing using syntactic and lexical information | Exploiting linguistic cues to classify rhetorical relations | Improving accuracy in wordclass tagging through combination of machine learning systems | An empirical approach to temporal reference resolution | A multilingual approach to annotating and extracting temporal information | Stacked generalization | Line has cut 1,900 jobs since it acquired the core assets of the Mulwaukee Road trail line",rejected,000
1110.3907.pdf.json,AOSO-LogitBoost: Adaptive One-Vs-One LogitBoost for Multi-Class Problem,"Boosting is successful for both binary and multi-class classification (Freund & Schapire, 1995; Schapire & Singer, 1999). Among those popular variants, we are particularly focusing on LogitBoost (Friedman et al., 1998) in this paper. Originally, LogitBoost is motivated by statistical view (Friedman et al., 1998), where boosting algorithms consists of three key components: the loss, the function model, and the optimization algorithm. In the case of LogitBoost, these are the Logit loss, the use of additive tree models, and a stage-wise optimization, respectively. There are two important factors in the LogitBoost setting. Firstly, the posterior class probability estimate must be normalised so as to sum to one in order to use the Logit loss. This leads to a coupled classifier output, i.e., the sum-to-zero classifier output. Secondly, a dense Hessian matrix arises when deriving the tree node split gain and node value fitting. It is challenging to design a tractable optimization algorithm that fully handles both these factors. Consequently, some simplification and/or approximation is needed. Friedman et al. (1998) proposes a “one scalar regression tree for one class” strategy. This breaks the coupling in the classifier output so that at each boosting iteration the model updating collapses to K independent regression tree fittings, where K denotes the number of classes. In this way, the sum-to-zero constraint is dropped and the Hessian is approximated diagonally. Unfortunately, Friedman’s prescription turns out to have some drawbacks. A later improvement, ABCLogitBoost, is shown to outperform LogitBoost in terms of both classification accuracy and conver- gence rate (Li, 2008; 2010a). This is due to ABCLogitBoost’s careful handling of the above key problems of the LogitBoost setting. At each iteration, the sum-to-zero constraint is enforced so that only K − 1 scalar trees are fitted for K−1 classes. The remaining class – called the base class – is selected adaptively per i","Support vector machine solvers | A desicion-theoretic generalization of on-line learning and an application to boosting | Greedy function approximation: a gradient boosting machine | Additive logistic regression: a statistical view of boosting | Boosting products of base classifiers | Adaptive base class boost for multi-class classification | Abc-logitboost for multi-class classification | Robust logitboost and adaptive base class (abc) logitboost | An empirical evaluation of four algorithms for multiclass classification: Mart, abc-mart, robust logitboost, and abc-logitboost | Fast abc-boost for multi-class classification | Improved boosting algorithms using confidence-rated predictions | New multicategory boosting algorithms based on multicategory fisher-consistent losses",rejected,000
1110.5102.pdf.json,Towards Holistic Scene Understanding: Feedback Enabled Cascaded Classification Models,"O NE of the primary goals in computer vision is holisticscene understanding, which involves many sub-tasks, such as depth estimation, scene categorization, saliency detection, object detection, event categorization, etc. (See Figure 1.) Each of these tasks explains some aspect of a particular scene and in order to fully understand a scene, we would need to solve for each of these sub-tasks. Several independent efforts have resulted in good classifiers for each of these sub-tasks. In practice, we see that the subtasks are coupled—for example, if we know that the scene is an indoor scene, it would help us estimate depth from that single image more accurately. In another example in the robotic grasping domain, if we know what kind of object we are trying to grasp, then it is easier for a robot to figure out how to pick it up. In this paper, we propose a unified model that jointly optimizes for all the sub-tasks, allowing them to share information and guide the classifiers towards a joint optimal. We show that this can be seamlessly applied across different applications. Recently, several approaches have tried to combine these different classifiers for related tasks in vision [1–10]; however, most of them tend to be ad-hoc (i.e., a hardcoded rule is used) and often an intimate knowledge of the inner workings of the individual classifiers is required. • Congcong Li, Adarsh Kowdle and Tsuhan Chen are with the School of Electrical and Computer Engineering, Cornell University, Ithaca, NY, 14853. E-mail: {cl758, apk64}@cornell.edu, tsuhan@ece.cornell.edu • Ashutosh Saxena is with the Department of Computer Science, Cornell University, Ithaca, NY, 14853. E-mail: asaxena@cs.cornell.edu Even beyond vision, in many other domains, state-of-the-art classifiers already exist for many sub-tasks. However, these carefully engineered models are often tricky to modify, or even to simply re-implement from the available descriptions. Heitz et. al. [11] recently developed a framework for s","A hierarchical field framework for unified context-based classification | Make3d: Learning 3d scene structure from a single still image | Closing the loop on scene interpretation | Towards total scene understanding: Classification, annotation and segmentation in an automatic framework | Depth from familiar objects: A hierarchical model for 3d scenes | Joint parsing and semantic role labeling | From appearance to contextbased recognition: Dense labeling in small images | Object detection via boundary structure segmentation | Monocular human motion capture with a mixture of regressors | Depth estimation using monocular and stereo cues | Cascaded classification models: Combining models for holistic scene understanding. | Neural network ensembles | Cascaded neural networks based image classifier | A unified architecture for natural language processing: Deep neural networks with multitask learning | A decision-theoretic generalization of on-line learning and an application to boosting | On the design of cascades of boosted ensembles for face detection | Robust real-time face detection | Mutual boosting for contextual inference | Contextual models for object detection using boosted random fields | Auto-context and its application to high-level vision tasks | Feedback enabled cascaded classication models for scene understanding | A generic model to compose vision modules for holistic scene understanding | On combining classifiers | θ-mrf:capturing spatial and semantic structure in the parameters for scene understanding | A framework for learning predictive structures from multiple tasks and unlabeled data | Support vector machine learning for interdependent and structured output spaces | Max-margin markov networks | Semantic labeling of 3d point clouds for indoor scenes | Conditional random fields for object recognition | Learning structural svms with latent variables | Contextual priming for object detection | Depth estimation from image structure | Putting objects in perspective | Multiresolution models for object detection | Learning spatial context: Using stuff to find things | Context by region ancestry | A hierarchical field framework for unified  14 context-based classification | Object detection with discriminatively trained part based models | Objects in context | From appearance to contextbased recognition: Dense labeling in small images | Discriminative models for multi-class object layout | Modeling mutual context of object and human pose in human-object interaction activities | Multiclass object localization by combining local contextual interactions | An empirical study of context in object detection | Object localization with global and local context kernels | What, where and who? classifying event by scene and object recognition | Scaling learning algorithms towards ai | Multitask learning | Efficient backprop | Measuring invariances in deep networks | A fast learning algorithm for deep belief nets | Deconvolutional networks | Maximum likelihood from incomplete data via the em algorithm | A view of the EM algorithm that justifies incremental, sparse, and other variants | Variational gaussian process classifiers | Discriminative sparse image models for class-specific edge detection and image interpretation | Modeling the shape of the scene: A holistic representation of the spatial envelope | MIT outdoor scene dataset | 3-d depth reconstruction from a single still image | Learning depth from single monocular images | Contextual guidance of eye movements and attention in real-world scenes: the role of global features in object search. | Frequencytuned Salient Region Detection | The PASCAL VOC2006 Results. | Discriminatively trained deformable part models, release 3 | Histograms of oriented gradients for human detection | Robotic grasping of novel objects | Robotic grasping of novel objects using vision | A bayesian hierarchical model for learning natural scene categories | Recovering the spatial layout of cluttered rooms | The PASCAL Visual Object Classes  Challenge 2007 (VOC2007) Results",rejected,000
1112.1489.pdf.json,Multi-granular Perspectives on Covering,"The ability to conceptualize the world at different granularities and to switch among these granularities is fundamental to human intelligence and flexibility [9][19]. To simulate such an ability of human problem solving, Granular Computing (GrC) was proposed. In fact, there have existed many concrete models of granular computing, such as computing with words [17][18], rough set theory [12], formal concept analysis [8], quotient space theory [19], etc. Granulation [18][10], grouping some elements of the domain into granules, is a fundamental step towards granular computing. Idealized granulation should yield pairwise disjoint granules such as equivalence classes or partition blocks. However, incompleteness and impreciseness of information, as well as variant similarity of individuals, always result in overlapping among granules. Consequently, granular worlds are always formalized as a set equipped with a family of nonempty subsets whose union equals to the universe, which is precisely the covering model [10]. For any given covering, both union and intersection of covering blocks containing the given element can be viewed as induced granules, which form two new coverings representing granular worlds at different abstraction levels. Consequently, transformations among these three covering are important and interesting in that they simulate the process of switching among granularities, which are precisely our respect of discussion. Pawlak’s roughs set provides a concrete framework performing granular computing based on partition or equivalence relation, however, absolute disjointness among granules restrict applications of classical rough set theory, so generalized rough set models based on covering are extensively researched, and many results such as axiomization and reduction theory are obtained (see, for example, in [20][21][22][23] for details). In these researches, union and intersection of covering blocks containing the given element were always called the friend",On the Coverings by Tolerance Classes | Extentions and Intentions in the Rough Set Theory | Topological Spaces | Generalized Rough Set Model Based on Compatibility Relation | Compatibility Relation and Compatibility Kernel | The ABC of Order and Topology | A Generalized Topological View of Motion in Discrete Space | Formal Concept Analysis – Mathematical Foundations | Granularity | Granular Computing I: the Concept of Granulation and Its Formal Model | A Comparison of Two Types of Rough Sets Induced by Covering | Rough Sets: Theoretical Aspects of Reasoning about Data | On Covering Rough Sets | Expanding Tolerance RST Models Based Cores of Maximal Compatible Blocks | Properties of Covering Rough Set Model | Relational Interpretations of Neighborhood Ooperators and Rough Set Approximation Operators | Fuzzy Logic = Computing with Words | Towards a Theory of Fuzzy Information Granulation and Its Centrality in Human Reasoning and Fuzzy Logic | Theory and Application of Problem Solving | On Axiomatic Characterizations of Three Pairs of Covering Based Approximate Operators | Reduction and Axiomization of Covering Generalized Rough Sets | Topological Approaches to Covering Rough Sets | Relationship between Generalized Rough Sets based on Binary Relation and Covering,rejected,000
1112.1670.pdf.json,Data Mining Session-Based Patient Reported Outcomes (PROs) in a Mental Health Setting: Toward Data-Driven Clinical Decision Support and Personalized Treatment,,"Patient-reported outcome measures: Use in evaluation of treatment for aphasia | Patient-reported outcomes in schizophrenia | Validation of two generic patient-reported outcome measures in patients with type 2 diabetes | Systematic use of patient-rated depression severity monitoring: is it helpful and feasible in clinical psychiatry | The prognostic significance of patient-reported outcomes in cancer clinical trials | The impact of measuring patient-reported outcomes in clinical practice: a systematic review of the literature | Measuring patientreported outcomes: moving from clinical trials into clinical practice | Using formal client feedback to improve retention and outcome: Making ongoing, real-time assessment feasible | The reliability and validity of the Outcome Rating Scale: A replication study of a brief clinical measure | Outcome Rating Scale and Session Rating Scale in psychological practice: Clinical utility of ultra-brief measures | The Session Rating Scale: Preliminary Psychometric Properties of a ‘Working’ Alliance Measure | Using client feedback to improve couple therapy outcomes: a randomized clinical trial in a naturalistic setting | Data mining and electronic health records: Selecting optimal clinical treatments in practice | Clinical productivity system: A decision support model. | The twin questions of personalized medicine: who are you and whom do you most resemble | Predicting the prognosis of breast cancer by integrating clinical and microarray data with Bayesian networks | Improved breast cancer prognosis through the combination of clinical and genetic markers | Microarray-based classification and clinical predictors: on combined classifiers and additional predictive value | The use of outcome measures by psychologists in clinical practice | A measurement feedback system (MFS) is necessary to improve mental health outcomes | The theory of planned behavior | Improving clinical practice using clinical decision support systems: a systematic review of trials to identify features critical to success | Implementation matters: a review of research on the influence of implementation on program outcomes and the factors affecting implementation | Grand challenges in clinical decision support | The dissemination and implementation of evidence-based psychological treatments. A review of current efforts | Factors influencing the implementation of clinical guidelines for health care professionals: A systematic meta-review | Why don't physicians adhere to guideline recommendations  in practice? An analysis of barriers among Dutch general practitioners | KNIME: The Konstanz Information Miner | Principles of data mining | Data Mining: Practical Machine Learning Tools and Techniques, Second Edition, 2nd ed | CAIM Discretization Algorithm | Hidden naive Bayes | Not so naive bayes: Aggregating one-dependence estimators | Random Forests | 5: programs for machine learning | Instance-Based Learning Algorithms | Ensemble selection from libraries of models | ROC graphs: Notes and practical considerations for researchers | Measuring classifier performance: a coherent alternative to the area under the ROC curve | Classifier Technology and the Illusion of Progress | Critical review of published microarray studies for cancer outcome and guidelines on statistical analysis and reporting | A review of feature selection techniques in bioinformatics | Wrappers for feature subset selection | Early change in patient-reported health during lung cancer chemotherapy predicts clinical outcomes beyond those predicted by baseline report: results from Eastern Cooperative Oncology Group Study 5592 | Applying theory-driven approaches to understanding and modifying clinicians' behavior: what do we know | The technology acceptance model: its past and its future in health care | Optimized Antidepressant Therapy and Pain Self- Management in Primary Care Patients with Depression and Musculoskeletal Pain: A Randomized Controlled Trial",rejected,000
1112.5370.pdf.json,Enhancing Support for Knowledge Works: A relatively unexplored vista of computing research,,"A mind so rare: The evolution of human consciousness | Cognition Distributed: How Cognitive Technology Extends Our Minds, chapter Offloading cognition onto cognitive technology, pages 1–23 | Asap: a resource for annotating, curating, comparing, and disseminating genomic data | Acting with Technology | On the issues of building information warehouses | A design theory for systems that support emergent knowledge processes | Beyond ontologies: Toward situated representations of scientific knowledge | Dilemmas in a general theory of planning | Artificial Intelligence: A Modern Approach",rejected,000
1112.5381.pdf.json,Improving the Efficiency of Approximate Inference for Probabilistic Logical Models by means of Program Specialization,"In the field of artificial intelligence there is a large interest in probabilistic logical models, namely probabilistic extensions of logic programs as well as first-order logical extensions of probabilistic models such as Bayesian networks [3,5,11]. Probabilistic inference with such a model is the task of answering various questions about the probability distribution specified by the model, usually conditioned on certain observations (the evidence). While a variety of inference algorithms is being used, many of them are based on sampling [1,2,9,13]. The idea is to draw samples from the considered probability distribution conditioned on the evidence, and use these samples to compute an approximate answer to the inference questions of interest. It is important that the process of sampling is efficient because the more samples can be drawn per time-unit, the more accurate the answer will be (i.e., the closer to the correct answer). In this paper we use logic programs to represent probabilistic logical models and we use Prolog as the programming environment in which we implement sampling-based inference. From an implementation perspective, sampling boils down to repeatedly calling the same queries on a knowledge base composed of a static part (the evidence) and a highly dynamic part that changes at runtime because of the sampling. The more evidence, the larger the static part of the knowledge base, so the more redundancy there is in these repeated calls. Since it is important that the sampling process is efficient, this redundancy needs to be reduced as much as possible. In this paper we show how to do this by applying logic program specialization: we specialize the definitions of the querypredicates with respect to the static part of the knowledge base. While a lot of work about logic program specialization is about exploiting static information about the input arguments of queries (partial deduction [6]), we instead exploit static information about the knowledge base",Cutset sampling for Bayesian networks | Pattern Recognition and Machine Learning | Probabilistic Inductive Logic Programming | Improving the efficiency of gibbs sampling for probabilistic logical models by means of program specialization | Learning directed probabilistic logical models: Ordering-search versus structure-search | Logic program specialisation through partial deduction: Control issues | Specialising interpreters using offline partial deduction | Structure learning of probabilistic relational models from incomplete relational data | Learning Bayesian Networks | Transformation of logic programs: Foundations and techniques | First-order probabilistic inference | Sound and efficient inference with probabilistic and deterministic dependencies | On the implementation of the CLP(BN) language | andW | Improving the efficiency of inductive logic programming in the context of relational data mining,rejected,000
1112.6219.pdf.json,Document Clustering based on Topic Maps,"Clustering as an unsupervised data mining approach is widely used in variety of situations. It automatically groups a collection into meaningful sub-groups; the word meaningful is rather relative. The challenging part is to extract the meaningfulness and to control the objective of the “best” clustering sense. Document clustering, is a specialized data clustering problem, where the objects are in the form of documents. The objective of the clustering process is to group the documents which are similar in some sense like: type of document, contents of document, etc into a single group (cluster). The difficult part is to learn from a data set, actually how many classes of such groups exist in the collection. Document Clustering aims to discover natural grouping among documents in such a way that documents with in a cluster are similar (high intra cluster similarity) to one another and are dissimilar to documents in other clusters (low inter cluster similarity). Exploring, analyzing and correctly classifying the unknown natures of data in a document without supervision is the major requirement of document clustering method. Traditionally, document clustering algorithms mainly uses features like: words, phrases, and sequences from the documents to perform cluster. These algorithms generally apply simple features extraction techniques that mainly based on feature counting and frequency distribution of the features to decide about the relatedness among documents. All these approaches thus, do not able to cater the meaning behind the text (words). These techniques simply perform clustering independent of the context. Document written in human language contains a context and the usage of words are largely depends on the context of the written text. Recently, few researchers have suggested some different model for document representation that captures the inherit semantics of the words. Like Phrase-based and common sequence of word based approaches. These have reported outst","Data Clustering: a review | The Role of Clustering in Search Computing | Scatter/Gather: A Cluster-based Approach to Browsing Large Document Collections | Reexamining the cluster hypothesis: scatter/gather on retrieval results | Efficient Phrase-Based Document Indexing for Web Document Clustering | Efficient Phrase-Based Document Similarity for Clustering | Hierarchical document clustering using frequent Itemsets | Text document clustering based on frequent word meaning sequences | Topic Maps | XML Topic Maps (XTM | Scaling Topic Maps | A comparison of document clustering techniques | M.,“Acomparison of two suffix tree-based document clustering algorithms",rejected,000
1112.6222.pdf.json,A comparison of two suffix tree-based document clustering algorithms,,Data Clutering: a review | The Role of Clustering in Search Computing | Scatter/Gather: A Cluster-based Approach to Browsing Large Document Collections | Reexamining the cluster hypothesis: scatter/gather on retrieval results | Similarity Search-The Metric Space Approach. | Finding Groups in Data: An Introduction to Cluster Analysis. | Fast and effective text mining using linear time document clustering | A comparison of document clustering techniques | Efficient Phrase- Based Document Indexing for Web Document Clustering | Efficient Phrase-Based Document Similarity for Clustering | Text document clustering based on frequent word meaning sequences,rejected,000
1201.0216.pdf.json,Building Smart Communities with Cyber-Physical Systems,"Last decades have witnessed the exponential increase in the number of various computers of everyday use. Modern computers are becoming smaller and smaller, while equipped with higher and higher performance in terms of e.g. computational speed and memory size, as promised by Moore’s law. As a consequence, computers are transforming into a lot of new forms. Some examples of new forms of computers include mobile phones, smart sensors, and even ordinary physical things, such as a lamp, a table and a cup. In other words, many physical things will possess computing and communication capabilities of different levels, which are provided by small and (possibly) invisible computers embedded therein. This integration of networked computing and physical dynamics has lead to the emergence of cyber-physical systems (CPS), which have become very hot in recent years. Generally speaking, CPS features tight integrations of computation, networking, and physical objects, in which various devices are networked to sense, monitor and control the physical world. Although there is no unified definition of this notion, some defining characteristics of CPS include cyber capability in physical objects, networking at multiple and extreme scales, complexity at both temporal and spatial scales, high degrees of automation, and dependable even certifiable operations. Many researchers and practitioners have pointed out that CPS will transform how we interact with the physical world [3,13]. Another recent trend in IT is the rapid growth of social networking services, one of the most impactful concepts in the last decade. Human beings are social animals. Consequently it is unsurprising that social networks have been popular since the beginning of civilization [5]. Over decades they have been playing a significant role in the development of human society. In a social network, a group of individuals are linked through diverse social relationships, such as family, friendships, business partners, and clas",Integrating Sensors and Social Networks | Understanding individual human mobility patterns | Social life networks | Towards a Smart World and Ubiquitous Intelligence: A Walkthrough from Smart Things to Smart Hyperspaces and UbicKids | FriendSensing: Recommending Friends Using Mobile Phones | Augmenting Context Awareness by Combining Body Sensor Networks and Social Networks | The Emergence of Intelligent Enterprises: From CPS to CPSS | Cyber-I: Vision of the Individual’s Counterpart on Cyberspace | Cyber-Physical Handshake | Network QoS Management in Cyber-Physical Systems,rejected,000
1201.0414.pdf.json,CONTINUITY IN INFORMATION ALGEBRAS: A SURVEY ON THE RELATIONSHIP BETWEEN TWO TYPES OF INFORMATION ALGEBRAS,"Inference under uncertainty is a common problem in the real world. Thus, for pieces of information from different sources, there always exist two fundamental aspects that to combine information and to exact information on a designated domain. Based on the above consideration, the valuation-based system (VBS) was first introduced by Shenoy. 1 Kohlas, in Ref. 2, has exactly introduced the concept of information algebra. We can see that information algebra is an algebraic structure links up with local computation and inference for treating uncertainty or, more ∗Work Address: College of Mathematic Science, Xuzhou Normal University, Xuzhou, 221116, China. 1 generally, information and knowledge. It gives a basic mathematical model for describing the modes of information processing. Recent studies 2 3 4 showed that the framework of information algebra covers many instances from constraint systems, Bayesian networks, Dempster-Shafer belief functions to relational algebra, logic and etc. In view of the feasibility of computer processing information, Kohlas gave the notions of domain-free compact information algebra and labeled compact information algebra successively in the study of representation of information algebras. In the light of the previous conclusions, we know that there exists a correspondence between domain-free information algebra and labeled information algebra, that is, from a domain-free information algebra, we can construct its associated labeled information algebra, and vice versa. But, labeled compact information algebras introduced in Ref. 3 do not necessarily lead to domain-free compact information algebras, as we have seen in the example of cofinite sets.3 It naturally raises a question that whether we can present an improved definition of labeled compact information algebra such that its associated domain-free information algebra is compact and strong compact respectively. Accordingly, in this paper, we redefine the notions of labeled continuous infor","A valuation-based language for expert systems, Int | Algorithms for Uncertainty and Defeasible Reasoning, in Handbook of Defeasible Reasoning and Uncertainty Managment Systems, eds | Abstracting soft constraints: Framework, properties, examples | Soft set theory-First | Continuous Lattices and Domains:Encyclopedia of Mathematics and its Applications, (Cambridge | Continuous lattices, in Lecture Notes in Mathematics: Toposes",rejected,000
1201.0478.pdf.json,,,,rejected,000
1201.0564.pdf.json,The RegularGcc Matrix Constraint,"Global constraints can be used to model and reason about commonly found substructures. Many such models contain matrices of decision variables [1–3]. Matrix constraints are global constraints that apply to such matrices [4]. For example, the RegularGcc matrix constraint can be used to model rostering problems. It ensures each row of the matrix satisfies a Regular constraint (representing the shift rules) and each column satisfies a Gcc constraint (representing the required capacities for each shift). We prove here that propagating the RegularGcc constraint is costly, even under very severe restrictions. Therefore, as in [5], we look for partial methods that only enforce a limited level of consistency. These methods are based on necessary conditions that improve propagation over the decomposition into separate Regular constraints on the rows and separate Gcc constraints on the columns. These necessary conditions depend on extracting several string properties from the rows. We enforce these necessary conditions by constraining the rows with additional automaton constraints. Unfortunately, when the number of columns increases, these automata increase in size quite drastically. By using weighted automata, we show that we can limit the increase in size. Finally, we show that this approach can be used in a more general setting where we have a matrix with multicostRegular and Gcc constraints.","Matrix modelling | Matrix modelling: Exploiting common patterns in constraint programming | The Cardinality Matrix Constraint | Global matrix constraints | On matrices, automata, and double counting | Sequencing and Counting with the multicost-regular Constraint | On the characterization and generation of nurse scheduling problem instances | Global grammar constraints",rejected,000
1201.2241.pdf.json,Distance-Based Bias in Model-Directed Optimization of Additively Decomposable Problems,"Even for optimization problems that are extremely difficult to solve, it may be straightforward to extract information about important dependencies between variables and other problem regularities directly from the problem definition (Baluja, 2006; Drezner & Salhi, 2002; Hauschild & Pelikan, 2010; Stonedahl, Rand, & Wilensky, 2008; Schwarz & Ocenasek, 2000). Furthermore, when solving many problem instances of similar type, it may be possible to gather information about variable interactions and other problem features by examining previous runs of the optimization algorithm, and to use this information to bias optimization of future problem instances to increase its speed, accuracy and reliability (Hauschild & Pelikan, 2008; Hauschild, Pelikan, Sastry, & Goldberg, 2011). The use of information from previous runs to introduce bias into future runs of an evolutionary algorithm is often referred to as learning from experience (Hauschild & Pelikan, 2008; Hauschild, Pelikan, Sastry, & Goldberg, 2011; Pelikan, 2002). The use of bias based on the results of other learning tasks in the same problem domain is also commonplace in machine learning where it is referred to as inductive transfer or transfer learning (Pratt, Mostow, Kamm, & Kamm, 1991; Caruana, 1997). Numerous studies have shown that using prior knowledge and learning from experience promise improved efficiency and problem solving capabilities (Baluja, 2006; Drezner & Salhi, 2002; Hauschild & Pelikan, 2010; Hauschild, Pelikan, Sastry, & Goldberg, 2011; Rothlauf, 2006; Stonedahl, Rand, & Wilensky, 2008; Schwarz & Ocenasek, 2000). However, most prior work in this area was based on hand-crafted search operators, model restrictions, or representations. This paper describes an approach that combines prior problem-specific knowledge with learning from experience. The basic idea of the proposed approach comprises of (1) defining a problemspecific distance metric, (2) analyzing previous EDA models to quantify the likelihoo","Population-based incremental learning: A method for integrating genetic search based function optimization and competitive learning (Tech | Incorporating a priori knowledge in probabilistic-model based optimization | Multitask learning | A Bayesian approach to learning Bayesian networks with local structure (Technical Report MSR-TR-97-07) | A Bayesian method for the induction of probabilistic networks from data | Using hybrid metaheuristics for the one-way and two-way network design problem | Learning Bayesian networks with local structure | Linkage learning via probabilistic modeling in the ECGA (IlliGAL Report No | Finding multimodal solutions using restricted tournament selection | Enhancing efficiency of hierarchical BOA via distancebased model restrictions. Parallel Problem Solving from Nature, 417–427 | Intelligent bias of network structures in the hierarchical BOA | Network crossover performance on NK landscapes and deceptive problems | An introduction and survey of estimation of distribution algorithms | Using previous models to bias structural learning in the hierarchical BOA | Analyzing probabilistic models in hierarchical BOA | Learning Bayesian networks: The combination of knowledge and statistical data (Technical Report MSR-TR-94-09) | Adaptation on rugged fitness landscapes | Estimation of distribution algorithms: A new tool for evolutionary computation | Towards a new evolutionary computation: Advances on estimation of distribution | Evolutionary optimization and the estimation of search distributions with applications to graph bipartitioning | Bayesian optimization algorithm: From single level to hierarchy | Hierarchical Bayesian optimization algorithm: Toward a new generation of evolutionary algorithms | NK landscapes, problem difficulty, and hybrid evolutionary algorithms | Escaping hierarchical traps with competent genetic algorithms | A hierarchy machine: Learning to optimize from nature and humans | A survey of optimization by building and using probabilistic models | Searching for ground states of Ising spin glasses with hierarchical BOA and cluster exact approximation | Scalable optimization via probabilistic modeling: From algorithms to applications | Direct transfer of learned information among neural networks | Representations for genetic and evolutionary algorithms | Evaluation-relaxation schemes for genetic and evolutionary algorithms | A problem-knowledge based evolutionary algorithm KBOA for hypergraph partitioning | Crossnet: a framework for crossover with",rejected,000
1201.2430.pdf.json,A Well-typed Lightweight Situation Calculus∗,"Introduced by John McCarthy in 1963 [10], situation calculus has been widely applied in Artificial Intelligence related research areas and other fields. This formalism is considered as a dialect of logic programming language and mostly used in dynamic domain modeling. Based on First Order Logic (FOL) [1] and Basic Action Theory [9], situation calculus can be used for reasoning efficiently by virtue of dynamic elements, such as actions and fluents. Basic concepts of situation calculus are fundamentals of First Order Logic and Set Theory in Mathematical Logic, which greatly facilitate the process of action-based reasoning in situation calculus. In order to make programs sound and correct in semantics, people have proposed type systems [12] to ensure such significant properties. A well-typed programming language is determined by two semantic properties: preservation and progress. The first property makes sure that types are invariant under the evaluation and typing rules. And the progress property says a well-typed program never gets stuck. Nevertheless, little attention has been put on equipping formal languages good at dynamic modeling and reasoning, like situation calculus, with strong typing mechanisms. Indeed, situation Calculus is a typed second-order formal language, but from the viewpoint of type checking, it is not enough to finish smoothly. For instance, in situation calculus, only typed quantifiers are introduced for basic variables, while as for other logical expressions consisting of variables and connectives, fluents and predicates, current situation calculus emphasizes little on how to type check whether they are well-typed, how to type them thoroughly. Therefore, equipping other elements in current version of situation calculus with types is greatly needed for a complete and robust programming language with its type system, which is definitely feasible according to our investigation. In this paper, in addition to the handy available typed variables, we ","An introduction to first-order logic. In: Handbook of Mathematical Logic, Studies in Logic and the Foundations of Mathematics | A Formulation of the Simple Theory of Types | A Situation-Calculus Semantics for an Expressive Fragment of PDDL | A Semantics for ADL as Progression in the Situation Calculus | Representing Knowledge within the Situation Calculus using Interval-valued Epistemic Fluents | PDDL—the planning domain definition language. In: Yale Center for Computational Vision and Control Technical Report CVC TR-98-003/DCS TR-1165 | Decidable Reasoning in a Modified Situation Calculus | Semantics for a useful fragment of the situation calculus | Situations, actions and causal laws | ADL: Exploring the middle ground between STRIPS and the Situation Calculus | Types and Programming Languages | Knowledge in Action: Logical Foundations for Specifying and Implementing Dynamical Systems",rejected,000
1201.2630.pdf.json,Hybrid GPS-GSM Localization of Automobile Tracking System,"The ability to accurately detect a vehicle’s location and its status is the main goal of automobile trajectory monitoring systems. These systems are implemented using several hybrid techniques that include: wireless communication, geographical positioning and embedded applications. The vehicle tracking systems are designed to assist corporations with large number of automobiles and several usage purposes. A Fleet management system can minimize the cost and effort of employees to finish road assignments within a minimal time. Besides, assignments can be scheduled in advanced based on current automobiles location. Therefore, central fleet management is essential to large enterprises to meet the varying requirements of customers and to improve the productivity [1].","Al-Saber,“ Remote monitoring of Automobile diagnostics and location using a smart box with Global Positioning System and General Packet Radio Service, | A GPS enhanced in-Automobile extensible data collection unit | Design of Automobile Position Tracking System Using Short Message Services And Its Implementation on FPGA | CCSMOMS:A Composite Communication Scheme for Mobile Object Management System | The Optimal Location Update Strategy of Cellular Network Based Traffic Information System | A Mobile Automobile Tracking System with GPS/GSM Technology | A New Approach of Automobile Localization System Using GPS and GSM/GPRS Transmission | Automobile Tracking Using a Reliable Embedded Data Acquisition Sysytem With GPS and GSM | The GPRS-based location system for the long-distance freight | Development of On-Line Diagnostics and Real Time Early Warning System for Automobiles | A Real Time GPRS Surveillance System using the Embedded System | A Study on Remote On-Line Diagnostic System for Automobiles by Integrating the Technology of OBD, GPS, and 3G | NMEA 0183 Standard For Interfacing Marine Electronic Devices | Multipath error detection using different GPS receiver's antenna | GPS Signal Availability in an Urban Area- Receiver Performance Analysis | Analysis of Multiple GPS Antennas for Multipath Mitigation in Vehicular Navigation”, Institute of Navigation National Technical Meeting/Anaheim, CA/January | Effects of differential correction on accuracy of a GPS animal location system | MuraliKrishna I.V and LalKishore K (Jan 2007) “Kalman filter for GPS Datum conversion | Multi-rate sensor fusion for GPS navigation using Kalman filtering, PhD Thesis, Dpt of electrical engineering, Virginia | Vehicle positioning by database comparison using the Box-Cox metric and Kalman filtering | Introduction to Random Signals and Applied Kalman Filtering”, 3 ed | Navstar GPS User Equipment Introduction",rejected,000
1201.2711.pdf.json,"Ultrametric Model of Mind, I: Review","Before introducing and then discussing in detail Matte Blanco’s work in section 3, in section 2 we deal with alternative models of mental processes – the geometry or the topology of mental processes. These are neural model centered. Therefore they can be taken as influenced by physical models of the brain. They provide a useful starting point for us because they also avail of ultrametric topological representations and processing frameworks. It will become clearer later that our primary motivation is not with a physical (and hence, let’s assume, observable through physico-chemical and biological processes) view of the brain. Instead our motivation is to have a processing framework to model human reasoning that is, as reasoning, based on data such as text or dialog data, or other behavioral or expressive signals. In section 3 we survey Matte Blanco’s “logico-mathematical”, albeit largely descriptive, theory of psychoanalysis. ar X iv :1 20 1. 27 11 v3 [ cs .A I] 1 In section 4 we look at how ultrametrics can provide an appropriate framework for understanding Matte Blanco. In section 5 we tie the ultrametric topology strongly to input data. In section 6 we note how the unconscious can be vastly more efficient – quicker in reasoning – compared to the conscious mind. An implication of this is why unconscious thought processes are of interest, as well as conscious reasoning, for computation and for decision making. In general we address through our mathematical – topological and, at times when metric, geometric – modeling how the unconscious differs from the conscious. Modeling for us consists of formulating and defining heuristic data structures, with the intention of allowing us to explore how the unconscious can be expressed in terms of measured data.","The flow of thought and the flow of language | Discourse, Consciousness, and Time: The Flow and Displacement of Conscious Experience in Speaking and Writing | Looking through newly to the amazing irrationals | Introduction to Lattices and Order | Nordgren, “A theory of unconscious thought | Terentyeva, “Indications of a possible symmetry and its breaking in a many-agent model obeying quantum statistics | Physiologically inspired neural model for the encoding of face spaces | A review of hierarchical classification | Hierarchic agglomerative clustering methods for automatic document classification | Non-Archimedean Analysis, Quantum Paradoxes | Information Dynamics in Cognitive, Psychological | Khrennikov, “Toward an adequate mathematical model of mental space: Conscious/Unconscious dynamics on m-adic trees | Khrennikov, “Modelling of psychological behavior on the basis of ultrametric mental space: Encoding of categories by balls”, p-Adic Numbers, Ultrametric Analysis, and Applications | Nombres semi-réels et espaces ultramétriques”, Comptes | Generalized ultrametric spaces in quantitative domain theory | Dubes, Algorithms For Clustering Data Prentice-Hall | Data clustering: a review | Ordinal and Relational Clustering | The unconscious as an ultrametric set | Norm-based face encoding by single neurons in the monkey inferotemporal cortex | Techniques for structuring database records | The Unconscious as Infinite Sets: An Essay in Bi-Logic, With a New Foreword by Eric Rayner, Karnac | Story – Substance, Structure, Style, and The Principles of Screenwriting | Mathematical Classification and Clustering | On ultrametricity, data coding, and computation | Correspondence Analysis and Data Coding with R and Java | Identifying the ultrametricity of time series | Symmetry in data mining and analysis: A unifying view based on hierarchy | The structure of narrative: the case of film scripts | The correspondence analysis platform for uncovering deep structure in data and information | On ultrametric algorithmic information | Ultrametric model of mind, II: Application to text content analysis | Ribenboim, “Logic programming and ultrametric spaces | Virasoro, “Ultrametricity for physicists | Unconscious Logic: An Introduction to Matte Blanco’s Bi-Logic and Its Uses | Ultrametric Calculus | Generalized ultrametrics, domains and an application to computational logic | Generalized distance functions in the theory of computation | The Sciences of the Artificial | Non-Archimedean Functional Analysis",rejected,000
1201.3107.pdf.json,Tacit knowledge mining algorithm based on linguistic truth-valued concept lattice,"In our living environment, tacit konwledge (as opposed to formal or explicit knowledge) is everywhere, which is usually difficult to transfer to another person by means of writing it down or verbalising it. With tacit knowledge, people are often aware of the knowledge they possess or how it can be valuable to others and effective transfer of tacit knowledge generally requires extensive personal contact and trust. According to Parsaye [1], there are three major approaches to capture the tacit knowledge from groups and individuals: (i) Interviewing experts: structured interviewing of experts in a particular subject is the most commonly used technique to capture pertinent, tacit knowledge; (ii) Learning by being told: this can be done by interviewing or by task analysis. And task analysis is the process of determining the actual task or policy by breaking it down and analyzing what needs to be done to complete the task; (iii) Learning by observation: this can be done by presenting the expert with a sample problem, scenario, or case study and then observing the process used to solve the problem. However, the above methods are more complicated to use and lack of rigorous mathematical foundation. In this paper, we select the concept lattice model to capture tacit knowledge through depicting and analyzing explicit knowledge. Concept lattice (also called Corresponding author: School of Mathematics and Information Science, North China University of Water Resources and Electric Power, Zhengzhou 450045, Henan, PR China E-mail addresses: yangli6672@sina.com formal concept analysis FCA) was proposed by Wille [2-4] in 1982，and its ideological core is constructing the binary relation between objects and attributes based on bivalent logic. Facing the massive fuzzy information existed in reality, fuzzy concept lattice has appeared [5-8], which is used to describe the fuzzy relation between objects and attributes. As a conceptual clustering method, concept lattices have been proved t","Expert systems for experts | Lattice Theory | Restructuring lattice theory: An approach based on hierarchies of concepts. I: Rival I, ed.Ordered Sets | Formal Concept Analysis: Mathematical Foundations | Crisply generated fuzzy concepts | Rough Set and Concept Lattice, Xi’an Jiaotong University Press, Xi’an | Set approximations in fuzzy formal concept analysis | Fuzzy Formal Concept Analysis and Fuzzy Concept Lattices, Journal of Northeastern University (Natural Science | Y | Study of fuzzy concept lattice based on lattice-valued logic | Approach of concept lattice to multiple attribute decision making with linguistic information | Decision making with uncertainty information based on lattice-valued fuzzy concept lattice | A decision method based on uncertainty reasoning of linguistic truth-valued concept lattice | Lattice implication algebras | Lattice-Valued Logic-An Alternative Approach to Treat Fuzziness and Incomparability | Linguistic truth-valued lattice implication algebra and its properties | Reduction method for concept lattices based on rough set theory and its application | Relations of attribute reduction between object and property oriented concept lattices | On fuzzy approximation operators in attribute reduction with fuzzy rough sets, Information Sciences",rejected,000
1201.3117.pdf.json,Design of Emergent and Adaptive Virtual Players in a War RTS Game,"In an era in which computing power has boosted the graphical quality of videogames, players have turned their attention to other aspects of the game. In particular, they mostly request opponents exhibiting intelligent behavior. However, intelligence does not generally equate to playing proficiency but rather to interesting behaviors [1]. This issue is specifically relevant in real-time strategy (RTS) games that often employ two kinds of artificial intelligence (AI) [2]: one represented by a virtual player (VP, or non-player character – NPC) making decisions on a set of units (i.e., warriors, machines, etc.), and another one corresponding to the small units (usually with little or no intelligence). The design of these AIs is a complex task, and the reality in the industry is that in most of the RTS games, the NPC is basically controlled by a fixed script that has been previously programmed based on the experience of the designer/programmer. This script often comprises hundreds of rules, in the form if the game is in state S then Unit U should execute action A, to control the behavior of the components (i.e., units) under its control. This arises known problems: for instance, for players, the opponent behavior guided by fixed scripts can become predictable for the experienced player. Also, for AI programmers, the design of ar X iv :1 20 1. 31 17 v1 [ cs .N E ] 1 5 Ja n virtual players (VPs) can be frustrating because the games are becoming more and more complex with hundreds of different situations/states and therefore it is not easy to predict all the possible situations that could potentially happen and even more difficult to decide which is the most appropriate actions to take in such situations. As consequence, many RTS games contain ’holes’ in the sense that the game stagnates or behaves incorrectly under very specific conditions (these problems rely on the category of ’artificial stupidity’ [1]). Thus the reality of the simulation is drastically reduced and so t",Artificial stupidity: The art of intentional mistakes | Game Artificial Intelligence | Call for AI research in RTS games | Steps toward building of a good ai for complex wargame-type simulation games | How qualitative spatial reasoning can improve strategy game ais | Playing to learn: case-injected genetic algorithms for learning to play computer games | Real-time neuroevolution in the nero video game | Coevolution in hierarchical ai for strategy games | Co-evolving real-time strategy game playing influence map trees with genetic algorithms | Evolving teams of cooperating agents for real-time strategy game | Intelligent anti-grouping in real-time strategy games | Evolving robust strategies for an abstract realtime strategy game | A multi-agent potential field-based bot for a full RTS game scenario | Emergence in Games,rejected,000
1201.3204.pdf.json,,"Parallel search is an important research area for two reasons. First, many search problems, including planning instances, continue to be difficult for sequential algorithms. Parallel search on state-of-the-art, parallel clusters has the potential to provide both the memory and the CPU resources required to solve challenging problem instances. Second, while multiprocessors were previously expensive and rare, multicore machines are now ubiquitous. Future generations of hardware are likely to continue to have an increasing number of processors, where the speed of each individual CPU core does not increase as rapidly as in past decades. Thus, exploiting parallelism is necessary to extract significant speedups from the hardware. Our work is primarily motivated by domain-independent planning. In classical planning, many problem instances continue to pose a challenge for state-of-the-art planning systems. Both the memory and the CPU requirements are main causes of performance bottlenecks. The problem is especially pressing in sequential optimal planning. Despite significant progress in recent years in developing domain-independent admissible heuristics [1, 2, 3], scaling up optimal planning remains a challenge. Multi-processor, parallel planning3 has the potential to provide both the memory and the CPU resources required to solve challenging problem instances. We introduce and evaluate Hash Distributed A* (HDA*), a parallelization of A* [4]. HDA* runs A* on every processor, where each processor has its own open and closed lists. A hash function assigns each state to a unique processor, so that every state has an “owner”. Whenever a state is generated, its owner processor is computed according to this hash function, and the state is sent to its owner. This simple mechanism simultaneously accomplishes load balancing as well as duplicate pruning. While the key idea of hashbased assignment of states to processors was initially proposed as part of the PRA* algorithm by Evett et",Admissible heuristics for optimal planning | Planning with pattern databases | Flexible abstraction heuristics for optimal sequential planning | A formal basis for the heuristic determination of minimum cost paths | PRA∗: Massively parallel heuristic search | Scalable global and local hashing strategies for duplicate pruning in parallel A* graph search | Large-scale parallel breadth-first search | Parallel structured duplicate detection | Best-first heuristic search for multi-core machines | MPI: the complete reference | Disjoint pattern database heuristics | Transposition table driven work scheduling in distributed search | A performance analysis of transposition-table-driven work scheduling in distributed search | Parallel depth-first search on multiprocessors part I: Implementation | Spielbaumsuche auf massiv parallelen systemen | The implementation of the Cilk-5 multithreaded language | Depth-first heuristic search on a SIMD machine | A SIMD approach to parallel heuristic search | Best-first frontier search with delayed duplicate detection | Structured duplicate detection in external-memory graph search | Cost-optimal external planning | Parallel best-first search of statespace graphs: A summary of results | A randomized parallel branch-and-bound procedure | Randomized parallel algorithms for backtrack search and branch-and-bound computation | Scalable load balancing strategies for parallel A* algorithms | Divide-and-conquer frontier search applied to optimal sequence alignment | Domain-independent structured duplicate detection | S | Efficient memory-bounded search methods | Evaluations of Hash Distributed A* in optimal sequence alignment | Distributed game-tree search using transposition table driven work scheduling | Solving Awari with Parallel Retrograde Analysis | Scalable distributed Monte-Carlo Tree Search | Scalable | Algorithms for distributed termination detection | A new hashing method with applications for game playing | Complexity results for SAS planning | Macro-FF: Improving AI planning with automatically learned Macro-operators | Sequential and parallel algorithms for frontier A* with delayed duplicate detection | Iterative resource allocation for memory intensive parallel search algorithms on clouds | On transposition tables for singleagent search and planning: Summary of results | Parallelizing the Murphi verifier | Parallelizing the Murphi verifier | Parallel and distributed model checking in Eddy | Distributed-memory model checking with SPIN | The design of a multicore extension of the SPIN model checker | Parallel state space construction for model-checking | Achieving scalability in parallel reachability analysis of very large circuits | Efficient large-scale model checking | Deep Blue | On the parallelization of UCT | Parallel planning via the distribution of operators | An economics approach to hard computational problems | Heavy-tailed phenomena in satisfiability and constraint satisfaction problems | ManySAT: a parallel SAT solver | Single-agent parallel window search | Adaptive k-parallel best-first search: A simple but efficient algorithm for multi-core domain-independent planning | Kbfs: K-best-first search | Adaptive parallel iterative deepening search | Best-first heuristic search for multicore machines,rejected,000
1201.3868.pdf.json,A Dichotomy for 2-Constraint Forbidden CSP Patterns,"In this paper we study the generic combinatorial problem known as the binary constraint satisfaction problem (CSP) in which the aim is to determine the existence of an assignment of values to n variables such that a set of constraints on pairs of variables are simultaneously satisfied. The generic nature of the CSP has led to diverse applications, notably in the fields of Artificial Intelligence and Operations Research. A fundamental research question in complexity theory is the identification of tractable subproblems of NP-complete problems. Classical approaches have consisted in identifying types of constraints which imply the existence of a polynomial-time algorithm. Among the most wellknown examples, we can cite linear constraints and Horn clauses. In an orthogonal approach, restrictions are placed solely on the (hyper)graphof constraint scopes. In some cases, dichotomies have even been proved characterising all tractable classes definable by placing restrictions either on the constraint relations [2, 3] or on the (hyper)graph of constraint scopes [12, 13, 14]. Recently, a new avenue of research has been investigated: the identification of tractable classes of CSP instances defined by forbidding a specific (set of) subproblems. Novel tractable classes have been discovered by forbidding simple 3-variable subproblems [8, 9]. This paper presents an essential first step towards the identification of all such tractable classes, namely a dichotomy for the special case of forbidden 2-constraint subproblems. We first define the notion of a CSP pattern. A pattern can be seen as a generalisation of a binary CSP instance; it represents a set of subproblems by leaving the consistency of some tuples undefined. We use the term point to denote an assignment of a value to a variable, i.e. a pair a = 〈v, d〉where d is in the domain of variable v. A pattern is a graph in which vertices correspond to points and both vertices and edges are labelled. The label of a vertex correspondi","An optimal coarse-grained arc consistency algorithm | Classifying the complexity of constraints using finite algebras | A dichotomy theorem for constraint satisfaction problems on a 3-element set | The Complexity of Theorem-Proving Procedures | Fundamental properties of neighbourhood substitution in constraint satisfaction problems | Hierarchically nested convex VCSP | Characterising tractable constraints, Artificial Intelligence | Generalizing constraint satisfaction on trees: Hybrid tractability and variable elimination | Hybrid tractability of valued constraint problems | Eliminating interchangeable values in constraint satisfaction problems | Computers and Intractability: A Guide to the Theory of NP- Completeness, W.H | The complexity of homomorphism and constraint satisfaction problems seen from the other side | Can You Beat Treewidth | Tractable hypergraph properties for constraint satisfaction and conjunctive queries, STOC ’10",rejected,000
1201.3880.pdf.json,Modelling and simulation of complex systems: an approach based on multi-level agents,"The main objective of our research over the last decade has been agent-based simulation and complex system (CS) modelling. After studying the agent-based systems (ABS) organizational context, to simulate the reorganization of flexible manufacturing and regulate an urban transport system, we focused on modelling agents with strong communication skills, which may be used as building elements for the design of assistance systems to CS users. Our thoughts on the interactional level were inspired by models from human-machine interfaces field, especially those of the ""cognitive engineering"" approach [6]. Then we suggested a first agent model and defined the communication model of these agents [10,11,29]. Next, we realized that the agent architecture could vary (multi-level architecture), so as to support the more or less cognitive tasks that agents perform. We then defined the different granularities of these agents by placing them on a scale of behaviours inspired by Ramussen’s three-level scale [31] to describe human operator behaviour. CS are ""made of many components with many interactions"" [34]. The CS design (cooperative systems, assistance systems, etc.) then includes a very specific modelling of interactional and communicational levels. Moreover, according to Morin [22], CS designer ""must have a method that allows to design the multiple points of view, and to move from one point of view to another."" In this sense, Wooldridge [37] and Jennings [19] have argued that agents are a new paradigm for CS engineering; they suggest a satisfactory response to three common techniques for reducing the software complexity: decomposition, abstraction and organization. Jennings [19] raises two hypotheses of adequacy and formation: (1) agent approach can significantly improve our ability to model, design and build complex and distributed software systems, (2) in addition to being able to design and build CS, agent approach is destined to become a major paradigm of software engineer","and J | A Computational Framework for Human/Agent Communication Using Argumentation | Methodologies and Software Engineering for Agent Systems | Towards an agent-oriented approach to conceptualization | Interaction et pragmatique | The Psychology of Human-Computer Interaction | Towards a new theory for design activity reasoning | Analysis of a theory for design activity reasoning through a multiagent approach | Modèles de coordination d’agents cognitifs | Model of cognitive agents to simulate complex information systems | Agents to cooperate in distributed design process | Agent-based micro-tools development for a co-operative design platform | Agent-Based μ-Tools Integrated into a Co-Design Platform | Fuzzy agents communities for product integrated configuration | A mediation system to facilitate cooperation in a Co-design platform | Ören, ""Towards Fuzzy Agents with Dynamic Personality for Human Behavior Simulation | A universal modular actor formalism for artificial intelligence | A Roadmap of Agent Research and Development | On agent-based software engineering | L’Évaluation creative | The structuring of Organization | La Méthode | Cognition and reality: principles and implications of cognitive psychology | Human problem solving | Fougères, ""Knowledge modelling for Mediation system based on co-operative task: an e-learning application | The mediator: an artificial actor integrated in a cooperative design system | Agent-based Mediation System to Facilitate Cooperation in Distributed Design | Optimization of Product Configuration Assisted by Fuzzy Agents | A fuzzy configuration multi-agent approach for product family modelling in conceptual design | Dynamic Shared Context Processing in an E- Collaborative Learning Environment | Skills | BDI agents: from theory to practice | Speech acts | The sciences of the artificial | N | Multiagent Systems: A Modern Approach to Distributed Artificial Intelligence | Agent-based Software Engineering | Organizational abstractions in the analysis and design of multi-agent systems",rejected,000
1201.3883.pdf.json,Dynamic Shared Context Processing in an E-Collaborative Learning Environment,"Everyone now recognizes that effective collaboration requires that each member of the collaboration receives relevant information on the activity of his partners. The support of this relevant information sharing consists of models for formalizing relevant information, processors for measuring relevance, and indicators for presenting relevant information. Various concepts and implementations of relevant information models have been presented in the areas of HCI and Ubiquitous Computing. System Engineering (SE) is the application field of our research activity. According to ISO/IEC 15288:2002 standard [1], designing a system-of-interest needs 25 processes which are grouped into technical process, project processes, etc. The system life cycle stages are described by 11 technical processes. The first ones are the Stakeholder Requirements Definition Process, the Requirements Analysis Process and the Architectural Design Process. They correspond to the left side of the well-known entity Vee cycle [2] which links the technical processes of the development stage with the project cycle (described by the ISO/IEC 26702:2007 standard [3]). The system architect plays a significant role during the system development. Despite description of different tasks he has to realize, there is a risk of lack of understanding of his activity and of supporting the results of his system architecture design, in a collaborative manner. Hence, to improve collaboration between system architects and other designers, we have defined two scientific objectives: 1) observing, studying and modeling the daily activity of system architect in order to produce new knowledge and to propose an activity model which describe his critical activity, and 2) facilitating cooperative activity of designers and system architects, in improving the sharing of their work context [4]. Regarding the second objective, we conducted two experiments in educational context (student projects for a course in digital factory): • F",The relationship of system engineering to the project cycle | An E- Collaborative Learning Environment Based on Dynamic Workflow System | and E | Using activity theory to model context awareness: a qualitative case study | Designs for collaborative learning environments: can specialization encourage knowledge integration? | Designing collaborative learning systems: current trends & future research agenda | Exploring foundations for computer supported collaborative learning | Computer supported collaborative learning in higher education: scripts for argumentative knowledge construction in distributed groups | Modelling shared contexts in cooperative environments: concept | La pertinence et ses origines cognitives | To share or not to share? | Information sharing and team performance: A meta-analysis | A practical approach for relevance measure of inter-sentence | Using probabilistic models of document retrieval without relevance information | Agents to cooperate in distributed design process | Agent-Based μ-Tools Integrated into a Co- Design Platform | Modeling contexts in collaborative environment: A new approach | Shared context for knowledge distribution: A case study of collaborative taggings | A conceptual framework and a toolkit for supporting the rapid prototyping of contextaware applications | Explaining for developing a shared context in collaborative design | and | TF-IDF uncovered: a study of theories and probabilities | Inverse document frequency (idf): A measure of deviation from poisson | Estimating the selectivity of tf-idf based cosine similarity predicates | Inferring intra-organizational collaboration from cosine similarity distributions in text documents | Ontology-Based Structured Cosine Similarity in Speech Document Summarization,rejected,000
1201.4080.pdf.json,,"As part of ongoing research in developing a fully data-driven acoustic-visual (AV) text-tospeech (TTS) synthesizer [16], we integrate a tongue model to increase visual intelligibility and naturalness. To extend the kinematic paradigm used for facial animation in the synthesizer to tongue animation, we adapt state-of-the-art techniques of animation with motion-capture data for use with electromagnetic articulography (EMA). Our AV synthesizer1 is based on a non-uniform unit-selection TTS system for French [4], concatenating bimodal units of acoustic and visual data, and extending the selection algorithm with visual target and join costs [13]. The result is an application whose graphical user interface (GUI) features a “talking head” (i.e. computer-generated face), which is animated synchronously with the synthesized acoustic output. This synthesizer depends on a speech corpus acquired by tracking marker points painted onto the face of a human speaker, using a stereoscopic high-speed camera array, with simultaneously recorded audio. While the acoustic data is used for waveform concatenation in a conventional unit-selection paradigm, the visual data is post-processed to obtain a dense, animated 3D point cloud representing the speaker’s face. The points are interpreted as the vertices of a mesh, which is then rendered as an animated surface to generate the face of the talking head using a standard vertex animation paradigm. Due to the nature of the acquisition setup, no intra-oral articulatory motion data can be simultaneously captured. At the very least, any invasive instrumentation, such as EMA wires or transducer coils, would have a negative effect on the speaker’s articulation and hence, the quality of the recorded audio; additional practical issues (e.g. coil detachment) would limit the length of the recording session, and by extension, the size of the speech corpus. As a consequence, the synthesizer’s talking head currently features neither tongue nor teeth, which ","LAPRIE: Registration of multimodal data for estimating the parameters of an articulatory model | POPOVIĆ: Automatic rigging and animation of 3D characters | GOLDSTEIN: Articulatory Phonology: An overview | BEAUFORT: Linguistic features weighting for a text-to-speech system without prosody model | Combining MRI, EMA & EPG measurements in a three-dimensional tongue model | PAYAN: 3D biomechanical tongue modeling to study speech production | Three-dimensional electromagnetic articulography: A measurement principle | PARENT: Creating speech-synchronized animation | SENDA: Difference in vocal tract shape between upright and supine postures: Observations by an open-type MRI scanner | HUNTER: From experiments to articulatory motion – a three dimensional talking head model | THALMANN: Human motion capture driven by orientation measurements | OUNI: Introducing visual target cost within an acoustic-visual unit-selection speech synthesizer | SEAH: Modeling and animating the human tongue during speech production | Measurement of temporal changes in vocal tract area function from 3D cine-MRI data | BERGER: Towards a true acoustic-visual speech synthesis | FELS: An efficient biomechanical tongue model for speech research",rejected,000
1201.4089.pdf.json,A Description Logic Primer,,"Pushing the EL envelope | The Description Logic Handbook: Theory, Implementation, and Applications | Tractable reasoning and efficient query answering in description logics: The DL-Lite family | OWL 2: The next step for OWL | Description logic programs: combining logic programs with description logic | OWL 2 Web Ontology Language: Primer | Foundations of Semantic Web Technologies | The even more irresistible SROIQ | Efficient rule-based inferencing for OWL EL | All elephants are bigger than all mice | Cheap Boolean role constructors for description logics",rejected,000
1201.5217.pdf.json,Unsupervised Classification Using Immune Algorithm,"Unsupervised classification which also known as data clustering is defined as the problem of classifying a collection of objects into a set of natural clusters without any a priori knowledge. Many clustering methods were proposed. These methods can be basically classified into two categories: hierarchical and partitional. In contrast to hierarchical clustering, which yields a successive level of clusters by iterative fusions or divisions, partitional clustering assigns a set of data points into K clusters without any hierarchical structure. This process usually accompanies the optimization of a criterion function [1]. One of the widely used partitional method is the K-means algorithm. It is an iterative hill-climbing algorithm. Many of stochastic optimization methods were used in clustering problem Such as genetic algorithms GAs [2-5], simulated annealing (SA) [6-8] and tabu search (TS) [9]. Artificial Immune Systems (AIS) is a field of study devoted to the development of computational models based on the principles of the biological immune system. It is an emerging area that explores and employs different immunological mechanisms to solve computational problems [10] A lot of immune algorithms were developed aiming to finding solutions to a broad class of complex problems. Applications of AIS have included the following areas: clustering and classification [11-15], anomaly detection [16-18], optimization [13, 19], control [20-21], computer security, learning, bio-informatics, image processing, robotics, virus detection and web mining [22]. Many of the immune algorithms use principles inspired by the clonal selection theory of acquired immunity. The clonal selection principle is used by the immune system to describe the basic features of an immune response to an antigenic stimulus. It establishes the idea that only those cells that recognize the antigens proliferate, thus being selected against those which do not. The process of proliferating called clonal expansion.","Clustering with evolution strategies, | Clustering with a genetically optimized approach, | Genetic algorithm-based clustering technique, | A genetic approach to the automatic clustering problem, | A practical application of simulated annealing to clustering, | Experiments in projection and clustering by simulated annealing, | Alsultan, ""A simulated annealing algorithm for the clustering problems, | A Tabu search approach to the clustering problem, | Immunological Computation Theory and Applications | An evolutionary immune network for data clustering, | The Clonal Selection Algorithm with Engineering Applications,"" presented at the Proceedings of GECCO | Learning and Optimization Using the Clonal Selection Principle, | aiNet: An Artificial Immune Network for Data Analysis,"" presented at the in Data Mining: A Heuristic Approach | Artificial Immune Recognition System (AIRS): An Immune-Inspired Supervised Learning Algorithm, | Novelty Detection in Time Series Data using Ideas from Immunology,"" presented at the | An Immunological Approach to Change Detection: Algorithms, Analisys and Implications,"" presented at the | Self-Nonself Discrimination in a Computer,"" presented at the IEEE Computer | An artificial immune network for multimodal function optimization,"" presented at the | Design of mixed control systems using algorithms inspired by the immune system, | Intelligent tuning of PID controller with disturbance function using immune | Application areas of AIS: The past, the present and the future, | Real coded clonal selection algorithm for unconstrained global optimization using a hybrid inversely proportional hypermutation | An Immune Algorithm for Protein Structure Prediction on Lattice Models, | Fast clonal algorithm, | The use of multiple measurements in taxonomic Problems, | Cancer diagnosis via linear programming,",rejected,000
1201.6511.pdf.json,Ontologies for the Integration of Air Quality Models and 3D City Models,"Sustainable development and urban planning One of the most often cited definitions of sustainability is the one created by the Brundtland Commission in its report (Brundtland, 1987) which defined sustainable development as development that ""meets the needs of the present without compromising the ability of future generations to meet their own needs."" The report highlighted three fundamental components to sustainable development: environmental protection, economic growth and social equity. Regardless of whether environmental issues are not the only aspects of sustainable planning and decision processes, they are impossible to circumvent. In urban areas, one of the most important environmental problems is air pollution, mostly induced by vehicle traffic. This pollution can cause severe damages on health and is particularly crucial because of the high density of population in cities. The improvement of air quality is therefore imperative and must be taken into account in a sustainable urban planning process. In fact a deep understanding and an accurate prediction of urban flow and pollutant dispersion in cities is required for a more proactive urban planning. In addition, the existing EU legal framework (Dir 96/62 and the associated “daughter” directives), dictate the use of air quality models as one of the ways to be applied for atmospheric quality assessment and related policy making.","A Numerical Study of Flow and Pollutant Dispersion Characteristics in Urban Street Canyons | Modeling reactive pollutant dispersion in an urban street canyon | Air pollution at street level in European cities | A two-dimensional air quality model in an urban street canyon: evaluation and sensitivity analysis | Study of Impact of Street Layout and Thermal Radiation on Air Quality by Numerical Simulation | Ontology mapping: the state of the art | Urban street-canyon flows with bottom heating | Effects of inflow turbulence intensity on flow and pollutant dispersion in an urban street canyon | A numerical study of the effects of ambient wind direction on flow and dispersion in urban street canyons using the RNG k–e turbulence model | CityGML - Interoperable Access to 3D City Models. In Geo-information for Disaster Management | CityGML - 3D City Models for Emergency Response. In Geoinformation-Technology for Emergency Response, ISPRS book series, Taylor & Francis | Influence of Geometry on the Mean Flow within Urban Street Canyons – A Comparison of Wind Tunnel Experiments and Numerical Simulations | A Laboratory Model for the Flow in Urban Street Canyons Induced by Bottom Heating | An Ontology-based System for Urban Planning Communication. In Ontologies for Urban Development: Interfacing Urban Information Systems, Geneva | A Graph-Oriented Model for Articulation of Ontology Interdependencies | Ambient air quality, pollutant dispersion and transport models. Report of the European Topic Centre on Air Quality, prepared under the supervision of G. Kielland, Project Manager, European Environment Agency, Copenhagen | Candidate OpenGIS CityGML Implementation Specification (City Geography Markup Language) | CFD simulation of airflow over a regular array of cubes. Part I: Three-dimensional simulation of the flow | wind-tunnel measurements. In Boundary-Layer Meteorology",rejected,000
1202.0837.pdf.json,On the influence of intelligence in (social) intelligence testing environments,"Dating back from the late nineties, but with a stronger momentum recently, we can find several works [1, 10, 3, 14, 8, 2] addressing the problem of measuring agent intelligence in a principled and general way. With the common thing of using notions taken from (algorithmic) information theory, MML and two-part compression, Kolmogorov complexity and Solomonoff priors (see [15] for proper definitions of all these notions), some of these works present definitions and tests to evaluate agent intelligence. One important feature in some of these tests is that the complexity of a problem, task or environment can be derived from its Kolmogorov complexity. This allows for the application of the setting to many different fields in artificial intelligence, including inductive or deductive tasks [4, 6]: given any task or problem, we can derive its intrinsic complexity and use it as a measure of difficulty. A prototype of the universal test introduced in [8] has been used to evaluate several agents, including humans and reinforcement learning agents. Some preliminary results of this evaluation [11, 12] show that the setting is able to compare and evaluate different kinds of agents, but it fails at placing them on the same scale, since humans usually get similar scores to other relatively simple agents. One possible explanation for these results is that it is not usual to find other agents in the test, so social intelligence is rarely measured. The question, however, is what agents should be introduced in the test. This is related to the question of evaluating intelligence with games (also suggested in [8]), where the difficulty is not only given by the complexity of the game, but from the opponent’s intelligence. Fig. 1 shows this situation. This leads to a circular problem: we need to know the opponent’s intelligence first in order to know the complexity of the problem. One recent proposal to overcome this problem is turning this circularity into a recursion. The Darwin-Wallace ",A computational extension to the Turing Test | IQ tests are not for machines | Beyond the Turing Test | Computational measures of information gain and reinforcement in inference processes | Constructive reinforcement learning | On the computational measurement of intelligence factors | A (hopefully) non-biased universal environment class for measuring intelligence of biological and artificial systems | Measuring universal intelligence: Towards an anytime intelligence test | On more realistic environment distributions for defining | A formal definition of intelligence based on an intensional variant of Kolmogorov complexity | Comparing humans and AI agents | Evaluating a reinforcement learning algorithm with a general intelligence test | Frequency adjusted multi-agent q-learning | Universal intelligence: A definition of machine intelligence | An introduction to Kolmogorov complexity and its applications (3rd ed.) | Evolution and the Theory of Games | Algorithmic game theory | On-line Q-learning using connectionist systems | If multi-agent learning is the answer | Reinforcement learning: An introduction | Q-learning | Evolutionary game theory | Qv (λ)-learning: A new on-policy reinforcement learning algorithm,rejected,000
1202.0984.pdf.json,OWL: Yet to arrive on the Web of Data?,"Under the initial impetus of the Linking Open Data project – and guided by the Linked Data principles [3] and associated bestpractices – a rich vein of openly-available structured data has been published on the Web using Semantic Web standards. Publishing RDF on the Web is no longer confined to academia and hobbyists: the current “Web of Data” now features exports from various corporate and commercial bodies (e.g., BBC, New York Times, Freebase, BestBuy), online communities (e.g., Wikipedia, Geonames), life-science corpora (e.g., DrugBank, Linked Clinical Trials) and governmental bodies (e.g., data.gov, data.gov.uk, EuroStat). The “Linked Open Data cloud” now depicts 295 interlinked datasets, which together consist of an estimated 31.6 billion RDF triples.1 Although RDF provides standard syntaxes and a common datamodel for disseminating structured information, it offers very little when it comes to giving semantics to the published data. RDF Schema (RDFS) and OWL were developed to address this by providing a vocabulary for describing schema data. The special vocabulary terms of RDFS and OWL – such as rdfs:subClassOf or owl:FunctionalProperty – have a well-defined semantics, which can be used to derive implicit consequences from the data. 1http://www4.wiwiss.fu-berlin.de/lodcloud/state/ This work has been funded in part by Science Foundation Ireland under Grant No. SFI/08/CE/I1380 (Líon-2) and by an IRCSET postgraduate grant. CoRR Copyright 2012. In terms of publishing, parts of the RDFS and OWL standards have been adopted on the Web of Data. Linked Data literature recommends use of owl:sameAs relations to denote when two URIs refer to the same resource [18, § 2.5.2]. Further, Linked Data guidelines recommend use of RDFS [18, § 4.4.2] for defining terms and interlinking vocabularies. As regards the broader OWL standard, current guidelines explicitly mention use of owl:equivalentClass, owl:equivalentProperty, owl:InverseFunctionalProperty and owl:inverseOf [18, § 4.4.","Semantic Web for the Working Ontologist: Effective Modeling in RDFS and OWL | Patching syntax in OWL ontologies | Linked Data | Implementing OWL 2 RL and OWL 2 QL rule-sets for OWLIM | Tractable reasoning and efficient query answering in description logics: The DL-Lite family | OWL 2 Web Ontology Language: Profiles | Characterizing knowledge on the Semantic Web with Watson | Characterizing the semantic web on the web | SameAs networks and beyond: Analyzing deployment status and implications of owl:sameAs in linked data | RDF literal data types in practice | Towards a scalable, pragmatic knowledge representation language for the web | Description logic programs: Combining logic programs with description logic | When owl:sameAs isn’t the same: An analysis of identity in linked data | Using naming authority to rank data and ontologies for web search | YARS2: A federated repository for querying graph structured data from the Web | RDF Semantics | Linked Data: Evolving the Web into a Global Data Space (1st Edition) | Exploiting RDFS and OWL for Integrating Heterogeneous, Large-Scale, Linked Data Corpora | Igniting the OWL 1.1 touch paper: The OWL API | Concurrent classification of EL ontologies | Optimizing enterprise-scale OWL 2 RL reasoning in a relational database system | Efficient rule-based inferencing for OWL EL | DLEJena: A practical forward-chaining OWL 2 RL reasoner combining Jena and Pellet | OWL 2 Web Ontology Language: Direct Semantics | OWL 2 Web Ontology Language: Structural Specification and Functional-Style Syntax | Simple and efficient minimal RDFS | The PageRank Citation Ranking: Bringing Order to the Web | OWL 2 Web Ontology Language: Mapping to RDF Graphs | Tractable query answering and rewriting under description logic constraints | Reasoning in the OWL 2 Full ontology language using first-order automated theorem proving | Consequence-based reasoning beyond Horn ontologies | OWL 2 Web Ontology Language: Conformance | Completeness, decidability and complexity of entailment for RDF Schema and a semantic extension involving the OWL vocabulary | QueryPIE: Backward reasoning for OWL Horst over very large knowledge bases | Web Ontology Reasoning with Logic Databases | A survey of the web ontology landscape",rejected,000
1202.1886.pdf.json,,"One of the problems for computer network’s intrusion detection system that passively monitor a network link is the ability of a skilled attacker to evade detection by exploiting ambiguities in the traffic stream as seen by the network intrusion detection system (NIDS). [1] [3] The NIDS may less capability complete analysis for the full range of behaviour allowed by a particular protocol. For instance, attacker may be evade a NIDS that fails to reassemble IP fragments by their attack traffic. The traffic normalization mechanisms belong to the wide set of tools that help the allocation, control of resources in TCP/IP networks, and base system of improve the reliability NIDS. [3] Many technique can be to classify network traffic. The more skilled method is neural network. However, one requirement of such system is normal traffic. Then a key problem is how to choose the attributes of the input training data. In this paper, we use a support vector machine algorithm based on the KDDCUP 99 dataset. This paper produces a support vector machine for network intrusion detection that can detect smurf attack in network with accuracy of 99.6%. Also this system can predict the percentage of smurf infection in the network with absolute error average from 0% to 5%. One of intrusion detection methods is misuse detection technique. The frequently utilize a rule-based approach. When applied to misuse detection, rules become scenarios for network attacks. This paper is structured as follows. In Section 2 we discuss related work. Section 3 is the problem statement of intrusion detection system. Section 4 introduces our solution and experiment of intrusion detection with support vector machine. This paper is ended with a conclusion and future work.","Insertion, Evasion, and Denial of Service: Eluding Network Intrusion Detection | Preventing Traffic Analysis for Real-Time Communication Networks | Transport and Application Protocol Sctubbing | The CoralReef Software Suite as a Tool for System and Network Administrators | Empirically derived analytic models of wide-area TCP connections | Implicit Traffic Classification for Service Differentiation",rejected,000
1202.1891.pdf.json,,"Today, because of being critical in education sectors, most of the university administrators are trying to get more enrolment of the student and they have to be very careful to increase in student’s stratifications. As a result, they are very careful to solve university problem. In fact, it represents the difficult optimization problem. As the difficulty of the problem, their importance in practice and inherent scientific challenge increases, they have been widely investigated across both the operational research and the artificial intelligence community. . It can be classified into exam timetabling problem and course timetabling problem. In this paper, exam timetabling problem (ETP) is used as the test bed for the proposed three HH methods. The exam timetabling problem is to assign a number of exams to a number of potential time periods or slots by taking into account to satisfy the several constraints. Several approaches have been conducted with various methodologies being applied to attempt to produce better quality exam timetables. There are a lot of researchers and their publications in the literature. For more detailed information about examination timetabling, it can be found in [2, 16, and 18]. There are also varieties of timetabling problem classes on which variety of approaches such as sequential method, cluster methods, constraint-based methods and meta-heuristics are used. Moreover, there are a large number of Meta heuristics for solving an examination timetabling problem. However, these methods have some issues such as parameter tuning and they are not capable of dealing with other different problems. As a result, the current methods being applied to exam timetabling are hyper heuristic (HH). Hyper Heuristic is an emerged search technique for the purpose to raise the generality [7]. Early research works on hyper heuristic focused on the development of advanced strategies for choosing the heuristics to be applied at different points of the search [3]. Li","An experimental study on hyper heuristic and exam timetabling | An Examination Scheduling Model to Maximize Students’ Study Time | An Extended Great Deluge Approach to the Examination Timetabling Problem |  Modified Great Deluge Algorithm based Auto Associated Neural Network for Bankruptcy Prediction in Banks"", International Journal of Computer Intelligence Reserach | A tabu-search hyper heuristic for timetabling and roistering | Solving Exam Timetabling Problems with Flex-Deluge Algorithm | Reinforcement Learning with EGD based Hyper Heuristic System for Exam Timetabling Problem | Development and application of hyper heuristic to personnel scheduling. | A new reinforcement learning algorithm”, STUDIA UNIV. BABES-BOLYAI, INFOMATICA, Volume XLVIII, Nubmer 1,2003 | Non-Linear Great Deluge with learning Mechanism for Solving the Course Timetabling Problem”, MIC-2009: The VIII Meta-heuristic International Conference | Reinforcement learning: A Survey | Great Deluge with Nonlinear Decay Rate for Solving Course Timetabling Problem | Recent Developments in Practical Exam Timetabling | Iterated Great Deluge for the Dynamic Facility Layout Problem",rejected,000
1202.1945.pdf.json,A FRAMEWORK: CLUSTER DETECTION AND MULTIDIMENSIONAL VISUALIZATION OF AUTOMATED DATA MINING USING INTELLIGENT AGENTS,"Past decades has seen a dramatic increase in the amount of information of data being stored in different electronic format. The problem is how to maintain these data and also extraction of required knowledge. Data mining techniques can be viewed as a result of the natural evaluation of information technology [4] [16]. The process of analyzing the observational data sets to find unsuspected relationships and to summarize the data in novel ways those are both understandable and useful to the data user called as data mining.[16] [12] It is the achievement of relevant knowledge that can allow you to make strategic decisions which will allow you to proceed further. The techniques used in data mining are more difficult to understand by general user [1]. A system which performs the process autonomously needs more user interaction by way of selecting the appropriate attribute. Automated data mining, minimizes this problem by selecting the attributes based on the user specified objective. It also chooses the best data mining technique for knowledge extraction [9]. The level of automation incorporated in this mining system is an important issue. Detecting the interesting patterns and finding out the appropriate knowledge from the output is also an interesting issue in data mining. This research work addresses this issue with the help of software agents. [7] The software agents help in detecting the clusters automatically. It also assists in viewing the cluster results graphically. Multidimensional visualization is used to view the results in a more meaningful way. 2.OBJECTIVE To develop a user friendly data mining system using intelligent agent through automated approach is the objective function of this research work. It mainly deals about, developing a neutral system by using well known data mining techniques. Intelligent agents are also used in the above mentioned techniques to implement the automated process [1]. The developed automated system gets the input values form t","SEYDIM “Intelligent Agents: A Data Mining Perspective | Multilevel Algorithms for Partitioning Power-Law Graphs, | Discovering structures through the Bernstein inequality | Mastering Data Mining: The Art and Science of customer | Constructing Cost-effective Anomaly Detection mputer | CIDS: An Agent- Based Intrusion Detection System | Intelligent Agents: The Right Information at the Right Time | Intelligent Agent-Based Monitoring Platform for Applications in Engineering, International | A Method for Decentralized Clustering in Large Multi-Agent Systems, AAMAS’03 | L | Data Mining | Methods for Visual Mining of Data in Virtual Reality | A multi-Dimensional Data Visualization Tools for Knowledge Discovery in Databases”, IEEE 0730-3157/1995 | Intelligent Agents as Data Mining Techniques used in Academic Environment, The 4 International Conference on Virtual Learning ICVL, pp | Data Clustering: a Review | Multi-Agent systems An Introduction to Distributed Artificial Intelligence | Automated trend analysis of proteomics data using an intelligent data mining architecture | Data Mining and Visualization | Execution Monitoring of Security-Critical Programs in Distributed Systems: A Specification-based Approach, | Finding Groups in Data: An Introduction to Cluster Analysis | Agent based Distributed Data Mining : The KDEC Scheme.”(2003), http://citeseer.ist.psu.edu | Distributed Intrusion Detection for Computer Systems | The design and implementation of MAIDS (mobile agent intrusion detection system) | shapcott, Data Mining Information Visualization Beyond Charts and Graphs | Agent-Based Knowledge Communities, International Journal of Computer Science and Applications @Technomathematics | Penetration State Transition Analysis: A Rule-Based Intrusion Detection Approach, | Survey of Clustering Algorithms, | K | Intelligent Agent Based Framework for Manufacturing Systems Control | Intrusion detection using autonomous agents | Visualising Data Mining Models”, Information Visualisation in Data Mining and Knowledge Discovery | Multi Agent-Based Distributed Data Mining: An Over View | Paugam-moisy, Cluster detection algorithm in neural networks | MamMoeT: An intelligent agent-based communication support platform for multimodal transport, Expert Systems with Applications",rejected,000
1202.2773.pdf.json,Decentralized Multi-agent Plan Repair in Dynamic Environments∗,,"On the complexity of plan adaptation by derivational analogy in a universal classical planning framework | From one to many: Planning for loosely coupled multi-agent systems | STRIPS: A new approach to the application of theorem proving to problem solving | Plan stability: Replanning versus plan repair | The FF planning system: Fast plan generation through heuristic search | Multi-agent plan repairing | Self-interested planning agents using plan repair | Monitoring the execution of partial-order plans via regression | Plan reuse versus plan generation: a theoretical and empirical analysis | A general, fully distributed multi-agent planning algorithm",rejected,000
1202.3046.pdf.json,Segmentation of Offline Handwritten Bengali Script,,A Survey of Methods and Strategies in Character Segmentation | Off-line Cursive Script Word Recognition | Offline General Handwritten Word Recognition Using an Approximate BEAM Matching Algorithm | Skew Angle Detection of Digitized Indian Script Documents | An Off-line Cursive Handwriting Recognition System | Off-line Handwritten Chinese Character Recognition as a Compound Bays Decision Problem | A Complete Printed Bangla OCR System | Off-Line Arabic Character Recognition: The State of the Art,rejected,000
1202.3538.pdf.json,,,"Non-Well-Founded Sets | Alternating-time temporal logic | Alternating refinement relations | 20 years of modal and mixed specifications | Rudiments of μ-calculus | Characterizing updates in dynamic epistemic logic | DEL-sequents for regression and epistemic planning | H | The logic of public announcements | Proof systems for the coalgebraic cover modality | M | The complexity of one-agent refinement modal logic | Characterizing Kripke structures in temporal logic | Design and Verification of Synchronization Skeletons using Branching Time Temporal Logic | Logical questions concerning the μ-calculus: Interpolation, Lyndon and Los-Tarski | An axiomatization of bisimulation quantifiers via the μ-calculus | A note on bisimulation quantifiers and fixed points over transitive frames | Extensions and Applications of Dynamic Epistemic Logic | Reasoning about Knowledge | Modal specifications for the control theory of discrete-event systems | Propositional quantifiers in modal logic | Bisimulation quantifiers for modal logic | Undecidability for arbitrary public announcement logic | Reasoning about information change | Refinement quantifiers for logics of belief and knowledge | Arbitrary action model logic and action model synthesis | Refinement quantified logics of knowledge | Refinement quantified logics of knowledge and belief for multiple agents | Dynamic Logic | Automata for the modal mu-calculus and related results | On the expressive completeness of the propositional mu-calculus with respect to monadic second order logic | Expressivity and completeness for public update logics via reduction axioms | Module checking | Completeness of the finitary moss logic | Memoryless determinacy of parity games. In Automata logics, and infinite games, pages 95–106 | Modal I/O automata for interface and product line theories | An algorithmic approach to knowledge evolution | Infinite games. Automata logics, and infinite games, pages 197–204 | The undecidability of iterated modal relativization | Programming from Specifications: Second Edition | Topology and epistemic logic | Logic for social software | Logics of public communications | Quotient de spécifications pour la réutilisation de composants | Residual for component specifications | Why are modalities good for interface theories | On the supervisory control of discrete event systems | Quantified mu-calculus for control synthesis | Agents and roles: Refinement in alternating-time temporal logic | The Complementation Problem for Buchi Automata with Appplications to Temporal Logic | On the control of discrete event dynamical systems | An essay on sabotage and obstruction | One is a lonely number: on the logic of communication | Quantifying notes | Simulation and information | Future event logic - axioms and complexity | Dynamic Epistemic Logic, volume 337 of Synthese Library | Lecture notes on the modal μ-calculus | Completeness of Kozen’s axiomatisation of the propositional mucalculus | An alternative logic for knowability | CTL is exponentially more succinct than CTL | Using Z — Specification",rejected,000
1202.3698.pdf.json,Extended Lifted Inference with Joint Formulas,"Probabilistic graphical models have been widely used over the last two decades in real-world and research applications. One of their sought after features is the ability to compactly represent a set of interdependencies among random variables, providing a platform for efficient inference methods for both exact [1] and approximate [16] inference. Probabilistic Relational Models (PRM) extend the propositional models by introducing the concept of domain entities, along with a richer language which depicts the properties of each entity and the various interactions which they exhibit. Naturally, it is desirable, and often much more efficient, to apply inference directly to the relational model, thus avoiding an explicit extraction of the propositional model. The act of exploiting the high level structure in relational models is called lifted inference. This task can be carried out by a family of exact lifted inference algorithms, which are based on the idea of First-Order Variable Elimination (FOVE) [12, 3, 9]. An important task which is closely related to probabilistic inference, is decision making under uncertainty. The tight connection between the two tasks is exemplified in the influence diagram model [7], a popular model for decision making. Influence diagrams extend probabilistic models by adding decision and utility components to probabilistic graphical models. The quality of a decision, a set of assignments to decision variables in the influence diagram, is measured by its Expected Utility (EU). Under this principle, the best decision is achieved by maximizing the expected utility, a task that has been studied for both exact resolution [5] and approximation [11]. In the relational models realm, the study of decision making in influence diagrams has focused mainly on first-order MDP [14]. The goal of this paper is to extend the applicability of FOVE in two directions. First, we enrich the set of operators used by FOVE, by (a) introducing a novel model conversion m","Nonserial Dynamic Programming | Relational preference rules for control | Lifted firstorder probabilistic inference | Mpe and partial inversion in lifted probabilistic variable elimination | A new perspective on algorithms for optimizing policies under uncertainty | Exploiting logical structure in lifted probabilistic inference | Influence diagrams | Lifted inference seen from the other side : The tractable features | Lifted probabilistic inference with counting formulas | A language for relational decision theory, in proceedings of the international workshop on statistical relational learning | Efficient belief propagation for utility maximization and repeated inference | First-order probabilistic inference | Markov logic networks | Practical solution techniques for first-order mdps | Lifted Probabilistic Inference by First-Order Knowledge Compilation | Generalized belief propagation",rejected,000
1202.3699.pdf.json,Learning is planning: near Bayes-optimal reinforcement learning via Monte-Carlo tree search,"In reinforcement learning (RL), a central issue is the exploration/exploitation tradeoff (Sutton & Barto, 1998). Simply put, this dilemma refers to the balance between acting optimally according to the information that you have (exploitation) and acting potentially sub-optimally so as to improve the quality of your information (exploration). The classical approach to this issue considers the “general” model, and makes its guarantees (if any exist) about an algorithm’s behavior on any possible model that satisfies some constraints. A maximum likelihood estimate (MLE) is used with a promise that, if the correct exploration steps are taken, the resulting model is close to the truth. This frequentist approach to optimal behavior is effective in many scenarios, and has the added benefit that the MLE is often easy to compute. However, providing guarantees for a “general” MDP can cause over-exploration beyond what is needed to ensure optimal or near-optimal behavior. An effective approach to limiting over-exploration is to constrain the model to a class that is easier to learn. For example, if we know that the model dynamics can be treated as a separate problem for any one of a number of state features, we can more efficiently do factor learning (Strehl et al., 2007). Or, if we know that certain groups of states have identical dynamics, we can learn the group dynamics by using relocatable action models (Leffler et al., 2007). The downside to this strategy is that, in most cases, an entirely new algorithm must be invented to take advantage of new constraints. The Bayesian approach to model estimation in RL (Wilson et al., 2007) introduces the use of model priors, and much of the innovation required moves from algorithm design to prior engineering and inference. While neither of these new issues are trivial, they extend beyond reinforcement learning and general Bayesian techniques from outside of the field will apply, broadening the palette of possible techniques that can be",A Bayesian sampling approach to exploration in reinforcement learning | Appendix (Technical Report DCS-tr-687) | Finite-time analysis of the multiarmed bandit problem | R-MAX—A general polynomial time algorithm for near-optimal reinforcement learning | Design for an optimal probe | Local bandit approximation for optimal learning problems | Achieving master level play in 9x9 computer go | On the sample complexity of reinforcement learning | A sparse sampling algorithm for near-optimal planning in large Markov decision processes | Bandit based Monte-Carlo planning | Near-Bayesian exploration in polynomial time | Efficient reinforcement learning with relocatable action models | A unifying framework for computational reinforcement learning theory (pp 78-79) | Estimating mixture of Dirichlet process models | Markov chain sampling methods for dirichlet process mixture models | An analytic solution to discrete Bayesian reinforcement learning | Markov decision processes—discrete stochastic dynamic programming | Artificial intelligence: A modern approach | Variance-based rewards for approximate Bayesian reinforcement learning | Efficient structure learning in factored-state MDPs | An analysis of modelbased interval estimation for Markov decision processes | A Bayesian framework for reinforcement learning | Reinforcement learning: An introduction | Integrating samplebased planning and model-based reinforcement learning | Exploring compact reinforcement-learning representations with linear regression | Bayesian sparse sampling for on-line reward optimization | Multi-task reinforcement learning: A hierarchical Bayesian approach,rejected,000
1202.3700.pdf.json,Solving Cooperative Reliability Games,"Consider a communication network connecting a source and target vertices, where each link is controlled by a self-interested agent. Any link may fail, and if such failures result in the elimination of all paths between the source and target, information cannot be sent between them. Consider a planner aiming to maximize the probability of allowing communication between the source and target. Each link has its own probability of failure, and together with the network structure they determine the probability of connectivity between the source and target. When the planner is only allowed to use a certain subset of the links, we may consider links outside this set as failed links. Given a reward for achieving such connectivity, what is a reasonable way of allocating this reward between the agents? Which links are the most critical? This domain can be modeled as a cooperative game, which we call the network reliability game. In this game we are uncertain which links would survive, but link failures are independent. The value of a link subset, called a coalition, is the probability of achieving connectivity using only these links. Game theoretic solutions find ways of allocating the reward between the agents, under considerations of fairness and stability. The most prominent solution aiming at fairness is the Shapley value [19], which is a measure of the criticality of each edge to achieving connectivity. The core [13] is the most common solution considering stability, and contains all allocations where no subset of agents is incentivized to defect and form an alternative network. Applying these solutions requires finding tractable algorithms for computing them . Unfortunately, even in domains where determining the value of a subset of agents is easy, computing these solutions may be hard. Further, the problem of computing the value of a coalition in the network reliability game is the famous network reliability problem, which is known to be computationally hard [16], maki","Power indices in spanning connectivity games | The cost of stability in coalitional games | Approximating power indices: theoretical and empirical analysis | Power in threshold network flow games | Power and stability in connectivity games | Cooperative Games on Combinatorial Structures | Prediction markets, mechanism design, and cooperative game theory | Complexity of determining nonemptiness of the core | Computing Shapley values, manipulating value division schemes, and checking core membership in multi-issue domains | On the complexity of cooperative solution concepts | A randomized method for the Shapley value for the voting game | Network formation with heterogeneous players | Some theorems on n-person games | Probability inequalities for sums of bounded random variables | A course in game theory | The complexity of counting cuts and of computing the probability that a graph is connected | The cost of stability in network flow games | Cores of convex games | A value for n-person games | Measuring inconsistency in probabilistic knowledge bases | On three Shapley-like solutions for cooperative games with random payoffs",rejected,000
1202.3705.pdf.json,Filtered Fictitious Play for Perturbed Observation Potential Games and Decentralised POMDPs,"Increasingly, complex real-world problems are being tackled by teams of autonomous agents. Now, in artificial intelligence, the problem of controlling these agents is often framed as a problem of distributed optimisation (e.g. [11]), and one general method of optimisation is for each agent to iteratively choose a better reply to the actions of the others, given its beliefs. This paper focuses on one particular iterative algorithm, fictitious play [5], and its application to controlling teams of agents in single state and sequential decision–making problems. However, a common feature of the domains that agent systems are deployed in is uncertainty about the actions of other team members, and this can prevent algorithms like fictitious play from converging. The specific type of uncertainty we consider in this paper is when agents cannot accurately infer (either via sensors or communication) the actions that were just taken by the others in the team. We call this scenario perturbed observations to reflect the fact that it is the players’ observations, not their actions, that are noisy. As such, it requires the players to incorporate the possibility of incorrect observations into their learning procedures. We envisage this model applying to situations in which the players have on– board payoff evaluation, which means that the joint action that was just played cannot be inferred from the payoff an agent receives. This feature arises in many scenarios, such as: (i) mobile multi–robotics where agents share position information using noisy odemetry — coordination is difficult when robots cannot share accurate positioning information, (ii) unmanned aerial vehicle (UAV) target tracking, in which individual UAVs need to estimate what the others are currently tracking — images of a target may be needed from many positions but a UAV can only approximately infer the viewing angle of others, and (iii) distributed sensor optimisation problems, where there are often significant cost",Optimizing fixed-size stochastic controllers for POMDPs and decentralized POMDPs | Multi-agent reinforcement learning in common interest and fixed sum stochastic games: An experimental study | Stochastic approximation and differential inclusions | The complexity of decentralized control of Markov decision processes | Iterative solution of games by fictitious play | The Theory of Learning in Games | Extensive games and the problem of information | Individual Q-learning in normal form games | Generalised weakened fictitious play | Value-function reinforcement learning in Markov games | Distributed welfare games with applications to sensor coverage | Potential games | p–dominance and belief potential | The complexity of Markov decision processes | On similarities between inference in game theory and machine learning | Reasoning about joint beliefs for execution–time communication decisions | Memory-bounded dynamic programming for DEC-POMDP | Reinforcement learning to play an optimal Nash equilibrium in team Markov games | Reward shaping for valuing communications during multi-agent coordination | Collective intelligence | Point–based policy generation for decentralized POMDPs,rejected,000
1202.3706.pdf.json,A Framework for Optimizing Paper Matching,"The assignment of papers to reviewers is one of the most important tasks facing the organizers of scientific conferences. Assigning submitted papers to their most suitable reviewers is essential to the success of any conference, indeed to the functioning of many scientific fields, since it is reviewer assessments that determine the conference program and, to some extent, the shape of a discipline. However, this is not a simple task: large conferences often receive well over 1000 submissions that must be assigned to many hundreds of reviewers in short amount of time. Apart from ensuring the suitability of assigned reviewers, constraints imposed by reviewer load limits, conflicts of interest, and other factors push this assignment problem beyond the reach of a single program chair, and generally prevent the process from being distributed in a fully satisfactory way. Many large conferences in computer science (CS), and especially artificial intelligence (AI), allow reviewers to bid on papers, basically providing their “preferences”—which we interpret as reflecting a reviewer’s suitability to review particular submitted papers—after which a centralized matching process takes place to find the most suitable assignment. Preferences collected this way are, unfortunately, inherently noisy for two key reasons: (a) it is difficult for reviewers to offer reasonable assessments of all but a small fraction of the papers, given the numbers involved; and (b) reviewers have access to limited information about each paper (e.g., only title and abstract). The latter factor fundamentally limits how well a reviewer can judge her own suitability, while the former means reviewers are, in some sense, semi-randomly choosing papers on which they express interest. One response to this problem is to associate simple features (keywords being most common) with both papers and reviewers, and use some measure of overlap as a reflection of suitability. Unfortunately, this simple method is crude at ",Formal models for expert finding in enterprise corpora | Recommending papers by mining the web. In Working Notes of the Workshop on Machine Learning for Information Filtering in the 16th International Joint Artificial Intelligence | Latent Dirichlet allocation | Recommender systems for the conference paper assignment problem | Automating the assignment of submitted manuscripts to reviewers | College admissions and the stability of marriage | Using collaborative filtering to weave an information tapestry | The AI conference paper assignment problem | Mining for proposal reviewers: lessons learned at the National Science Foundation | The efficient allocation of individuals to positions | Classification using discriminative restricted Boltzmann machines | Non-linear matrix factorization with Gaussian processes | Expertise modeling for matching papers with reviewers | An algorithm to determine peer-reviewers | The evolution of the labor market for medical interns and residents: A case study in game theory | Bayesian probabilistic matrix factorization using Markov chain Monte Carlo | Expertise matching via constraint-based optimization | On the optimal assignment of conference papers to reviewers | LDA-based document models for ad-hoc retrieval,rejected,000
1202.3707.pdf.json,A temporally abstracted Viterbi algorithm,"The Viterbi algorithm (Viterbi, 1967; Forney, 1973) finds the most likely sequence of hidden states, called the “Viterbi path,” conditioned on a sequence of observations in a hidden Markov model (HMM). If the HMM has N states and the sequence is of length T , there are NT possible state sequences, but, because it uses dynamic programming (DP), the Viterbi algorithm’s time complexity is just O(N2T ). It is one of the most important and basic algorithms in the entire field of information technology; its original application was in signal decoding but has since been used in numerous other applications including speech recognition (Rabiner, 1989), language parsing (Klein and Manning, 2003), and bioinformatics (Lytynoja and Milinkovitch, 2003). Finding a most-likely state sequence in an HMM is isomorphic to finding a minimum cost path through a state–time trellis graph (see Figure 1) whose link cost is the negative log probability of the corresponding transition–observation pair in the HMM. Thus, the cost of finding an optimal path can be reduced further using an admissible (lower bound) heuristic and A* graph search. Even with this improvement, the time and space cost can be prohibitive when N and T are very large; for example, with a state space defined by 30 Boolean variables, running Viterbi for a million time steps requires 1024 computations. One possible approach to handle such problems is to use a state abstraction: a mapping φ : S0 7→ S1 from the original state space S0 to a coarser state space S1. For stochastic models (such as an HMM), the parameters of the model in S1 are often chosen to be the maximum of the corresponding constituent parameters in S0. Although these parameters do not define a valid probability measure, they serve as admissible heuristics for an A* search. The same idea can be applied to produce a a hierarchy of abstractions S0, S1, . . . , SL. Coarse-to-fine dynamic programming or CFDP (Raphael, 2001) begins with SL and iteratively finds the ",Why are DBNs sparse | The generalized A* architecture | The Viterbi algorithm | Hierarchical A*: Searching Abstraction Hierarchies Efficiently | A* Parsing: Fast Exact Viterbi Parse Selection | A hidden markov model for progressive multiple | On spectral clustering: Analysis and an algorithm | Multiscale methods: Averaging and homogenization | A tutorial on hidden Markov models and selected applications in speech recognition | Coarse-to-Fine Dynamic Programming | Between MDPs and Semi-MDPs: A Framework for Temporal Abstraction in Reinforcement Learning | Error bounds for convolutional codes and an asymptotically optimum decoding algorithm,rejected,000
1202.3709.pdf.json,EDML: A Method for Learning Parameters in Bayesian Networks,"We consider in this paper the problem of learning Bayesian network parameters given incomplete data, while assuming that all network variables are binary. We propose a specific method, EDML,1 which has a similar structure and complexity to the EM algorithm (Dempster, Laird, & Rubin, 1977; Lauritzen, 1995). EDML assumes Beta priors on network parameters, allowing one to compute MAP parameters. When using uninformative priors, EDML reduces to computing maximum likelihood (ML) parameters. EDML originated from applying an approximate inference algorithm (Choi & Darwiche, 2006) to a meta network in which parameters are explicated as variables, and on which data is asserted as evidence. The update equations of EDML resemble the ones for EM, yet EDML appears to have different convergence properties which stem from its being an inference method as opposed to a local search method. For example, we will identify a class of incomplete datasets on which EDML is guaranteed to converge immediately to an 1EDML stands for Edge-Deletion MAP-Learning or Edge-Deletion Maximum-Likelihood as it is based on an edge-deletion approximate inference algorithm that can compute MAP or maximum likelihood parameters. optimal solution, by simply reasoning about the behavior of its underlying inference method. Even though EDML originates in a rather involved approximate inference scheme, its update equations can be intuitively justified independently. We therefore present EDML initially in Section 3 before delving into the details of how it was originally derived in Section 5. Intuitively, EDML can be thought of as relying on two key concepts. The first concept is that of estimating the parameters of a single random variable given soft observations, i.e., observations that provide soft evidence on the values of a random variable. The second key concept behind EDML is that of interpreting the examples of an incomplete data set as providing soft observations on the random variables of a Bayesian net",On the revision of probabilistic beliefs using uncertain evidence | An edge deletion semantics for belief propagation and its practical impact on approximation quality | Modeling and Reasoning with Bayesian Networks | Maximum likelihood from incomplete data via the EM algorithm | Learning hidden variable networks: The information bottleneck approach | Learning bounded treewidth | Data perturbation for escaping local maxima in learning | Probability and the Weighing of Evidence | A tutorial on learning with Bayesian networks | Probabilistic Graphical Models: Principles and Techniques | The EM algorithm for graphical association models with missing data | Expectation propagation for approximate Bayesian inference | Expectationpropogation for the generative aspect model | Optimization with EM and expectation-conjugategradient | Accelerating EM for large databases,rejected,000
1202.3710.pdf.json,Strictly Proper Mechanisms with Cooperating Players,"Decision makers need to understand and evaluate complex decision problems with considerable uncertainties. Those uncertainties are integrated into decision models as forecasts in the form of probability distributions, and the analysis is often quite sensitive to the distributions used. Statistical analysis can support this process when there is sufficient relevant historical data. However, in many cases, decision makers must rely instead on the judgment of experts to obtain useful probabilistic forecasts. In many applications of decision analysis, multiple individual judgments are engaged. Even when the decision maker has her own belief about the uncertainties, she can benefit by integrating the judgments of others. Incorporating diverse views from heterogeneous disciplines has been shown to improve assement accuracy (Clemen 1989, Hoffmann et al. 2007). Several approaches have been developed in the literature to find optimal combinations of multiple individuals’ judgements (Clemen and Winkler 1999, Stone 1961, Morris 1977). A strictly proper scoring rule measures the quality of a probabilistic forecast based on the observed outcome (Winkler 1996). It can be used, ex post, to evaluate the quality of forecasters (Brier 1950), or, ex ante, to encourage forecasters to articulate their best possible report (Savage 1971). In either case, a scoring rule captures the accuracy, calibration, knowledge, and expertise in assessment, encouraging a forecaster to be careful and honest. A decision maker who needs more knowledge about a particular uncertainty can retain a panel of experts. Each expert reports his forecast to her, and his payment can depend on the observed state, his report, and the other reports, too. Although her contract with the experts can provide a risk-free subsidy, it can also have incentives for superior forecasts (Clemen 2002). In recent years, prediction markets have been created and several market designs have been developed (Pennock 2004, Peters et al. 2","A Unified Framework for Dynamic Pari-Mutuel Information Market Design,Proceedings of the ACM Conference on Electronic Commerce (EC) | Prediction Markets as Decision Support Systems, Information Systems Frontiers | Verification of Forecasts Expressed in Terms of Probability | Strictly Proper Mechanisms with Cooperating Players, Doctoral thesis, Stanford University | Combining Forecasts: A review and annotated bibliography | Combining Probability Distributions from Experts in Risk Analysis, Risk Analysis | Incentive Contracts and Strictly Proper Scoring Rules | Auctions with Intermediaries | Group Consensus Probability Distributions: A Critical Survey | Collusive Bidder Behavior at Single-Object Second-Price and English Aucions | Combinatorial Information Market Design, Information | Elicitation from Large, Heterogeneous Expert Panels: Using Multiple Uncertainty Measures to Characterize Information Quality for Decision Analysis, Decision Analysis | The Parimutuel Kelly Probability Scoring Rule, Decision Analysis | A Characterization for the Spherical Scoring Rule, Theory and Decision | Elicitation of Probabilities Using Competitive Scoring Rules, Decision Analysis | Self-Financed Wagering Mechanisms for Forecasting | Interpreting the Predictions of Prediction Markets | Combining Expert Judgments: A Bayesian Approach | A Dynamic Pari-Mutuel Market for Hedging, Wagering, and Information Aggregation | A Convex Parimutuel Formulation for Contingent Claim Markets | Elicitation of Personal Probabilities and Expectations | Prediction Markets: Does Money Matter | The Opinion Pool | Scoring Rules and the Evaluation of Probabilities, Test | Prediction Markets",rejected,000
1202.3711.pdf.json,A Logical Characterization of Constraint-Based Causal Discovery,"Causal discovery remains at the heart of most scientic research to date. Understanding which variables in a causal system influence which other is crucial for predicting the effects of actions and policies. Learning such relations from observational data is challenging, especially when latent confounders (hidden common causes) and selection bias (affecting the chance of inclusion in the data set) can be present. With the introduction of the FCI algorithm in the seminal work of (Spirtes et al., 2000), it was shown that, under reasonable assumptions, it is indeed possible to infer valid causal information from observed probabilistic independencies in the large sample limit. Subsequent results and contributions from various researchers (Spirtes et al., 1999; Ali et al., 2005; Zhang, 2008a) have developed this into a method that produces a provably sound and complete output model that captures all identifiable causal information. Perhaps surprisingly, this does not mean that the problem of causal discovery from data is now considered ‘solved’ by the wider research community: the method has trouble handling large models, and worse, in practice the output is often seen as unreliable. Most current constraint-based approaches to causal discovery rely on a two step process: a structure identification phase from observed independencies, followed by a (graphical) orientation phase. In real-world data, the large sample limit does not apply, and if one or more incorrect independence decisions are made, then this can lead to a series of erroneous orientations. But this ambiguity is not apparent in the output, severely limiting the interpretability of the entire model, also because there is little or no accountability prospect for any of the causal relations found. Bayesian scorebased methods such as GES (Chickering, 2002) are better suited to deal with this kind of problem, as they can produce multiple output models (Heckerman et al., 1999). However, they have trouble accounting ","Towards characterizing markov equivalence classes for directed acyclic graphs with latent variables | Optimal structure identification with greedy search | Causal discovery in multiple models from different experiments | Proof supplement to ‘A logical characterization of constraint-based causal discovery | A simple constraint-based algorithm for efficiently mining observational databases for causal relationships | A Bayesian approach to causal discovery. In Computation, Causation, and Discovery, pages 141–166 | Probabilistic Graphical Models: Principles and Techniques | A theoretical study of Y structures for causal discovery | Probabilistic latent variable models for distinguishing between cause and effect | Causality: models, reasoning and inference | Adjacencyfaithfulness and conservative causal inference | Ancestral graph Markov models | A linear non-Gaussian acyclic model for causal discovery | An anytime algorithm for causal inference | An algorithm for causal inference in the presence of latent variables and selection bias. In Computation, Causation, and Discovery, pages 211–252 | Causation, Prediction, and Search | Learning causal structure from overlapping variable sets | On the completeness of orientation rules for causal discovery in the presence of latent confounders and selection bias | Causal reasoning with ancestral graphs | Detection of unfaithfulness and robust causal inference",rejected,000
1202.3713.pdf.json,Bayesian network learning with cutting planes,"A Bayesian network (BN) encodes conditional independence relations between random variables using an acyclic directed graph (DAG) whose vertices are the random variables. The DAG can be used to ‘read off’ conditional independence relations thus providing insight into the structure of the joint probability distribution represented by the BN. As a result BNs are a very popular probabilistic model and there is great interest in ‘learning’ BNs from data (i.e. doing statistical model selection where BNs are the model class). One standard approach to BN learning is ‘search and score’. A score is chosen to represent how well any candidate BN is supported by the observed data (and any prior knowledge) and then a search is conducted with the goal of finding a BN with maximal score. BN learning is therefore an optimisation problem. Unfortunately, as is well-known [3], this optimisation problem is NP-hard for any reasonable score, even if the number of parents for any vertex in the DAG is limited to two. Given this hardness result most BN learning work has concentrated on heuristic search where there is no guarantee that an optimal BN has been found. However, there is a growing body of work on exact BN structure learning. One approach is to use dynamic programming [10, 12, 5] which has successfully been used for exact learning up to around 30 vertices. In this paper integer programming (IP) is used for exact BN learning. IP has already been used by Cussens [7] for the special case of BN pedigree reconstruction (see Section 8) and by Jaakkola et al [9] for general BN learning with a limit on parent set size. As explained in Section 3 the work presented here is most closely related to that of Jaakkola et al. However here IP is effected in a more conventional manner than Jaakkola et al, using the SCIP (Solving Constraint Integer Programs) framework [2]. In addition a different approach is taken to searching for good cutting planes. This paper assumes a basic knowledge of what Bay",Constraint Integer Programming | SCIP: Solving constraint integer programs | Large-sample learning of Bayesian networks is NP-hard | Introduction to Algortithms | Efficient maximum likelihood pedigree reconstruction | Bayesian network learning by compiling to weighted MAX-SAT | Maximum likelihood pedigree reconstruction using integer programming | Structure learning of Bayesian networks using constraints | Learning Bayesian network structure using LP relaxations | Exact Bayesian structure discovery in Bayesian networks | On sensitivity of the MAP Bayesian network structure to the equivalent sample size parameter | A simple approach for finding the globally optimal Bayesian network structure,rejected,000
1202.3718.pdf.json,On the Complexity of Decision Making in Possibilistic Decision Trees,"For several years, there has been a growing interest in the Artificial Intelligence community towards the foundations and computational methods of decision making under uncertainty. This is especially relevant for applications to sequential decision making under uncertainty, where a suitable strategy is to be found, that associate a decision to each state of the world. Several formalisms can be used for sequential decision problems, such as decision trees, influence diagrams or Markov decision processes. A decision tree is an explicit representation of a sequential decision problem, while influence diagrams or Markov decision processes are compact representations. Even in the simple and explicit case of decision trees, the set of potential strategies increases exponentially with the tree size. A popular criterion to compare decisions under risk is the expected utility (EU ) model axiomatized by von Neumann and Morgenstern [12]. This model relies on a probabilistic representation of uncertainty: an elementary decision (i.e. a one-step decision problem) is modeled by a probabilistic lottery over its possible outcomes. The preferences of the decision maker are supposed to be captured by a utility function assigning a numerical value to each outcome. The evaluation of a lottery is then performed through the computation of its expected utility (the greater is the better). In sequential decision making, each possible strategy is viewed as compound lottery. It can be reduced to an equivalent simple lottery, and thus compared to the others according to its expected utility. Although the high combinatorial nature of the set of possible strategies, the selection of an optimal strategy can be performed in polynomial time (polytime) with the size of the decision tree: the EU model indeed satisfies a property of monotonicity that guarantees completeness of a polytime algorithm of dynamic programming. When the information about uncertainty cannot be quantified in a simple, probab",Qualitative decision theory with preference relations and comparative uncertainty: An axiomatic approach | Making decision in a qualitative setting: from decision under uncertainty to case-based decision | Possibility theory | Possibility theory as a basis for qualitative decision theory | Possibilistic influence diagrams | Qualitative models for decision under uncertainty without the commensurability assumption | A comparison of axiomatic approaches to qualitative decision making using possibility theory | Two axiomatic approaches to decision making using possibility theory | Conditional possibilities independence and non interaction | Rank-dependent probability weighting in sequential decision problems under uncertainty | Necessitybased choquet integrals for sequential decision making under uncertainty | Theory of games and economic behavior | From conditional oughts to qualitative decision theory | Algebraic markov decision processes | Decision making over necessity measures through the choquet integral criterion | A possibilistic model for qualitative sequential decision problems under uncertainty in partially observable environments | Towards qualitative approaches to multi-stage decision making | Subjective probability and expected utility without additivity | A general non-probabilistic theory of inductive reasoning | An order of magnitude calculus,rejected,000
1202.3719.pdf.json,Inference in Probabilistic Logic Programs using Weighted CNF’s,"There is a lot of interest in combining probability and logic for dealing with complex relational domains. This interest has resulted in the fields of Statistical Relational Learning (SRL) and Probabilistic Logic Programming (PLP) [3]. While the two approaches essentially study the same problem, there are differences in emphasis. SRL techniques have focussed on the extension of graphical models with logical and relational representations, while PLP has extended logic programming languages (such as Prolog) with probabilities. This has resulted in differences in representation and semantics between the two approaches but also, and more importantly, in differences in the inference tasks that have been considered. The most common inference tasks in the graphical model and the SRL communities are that of computing the marginal probability of a set of random variables w.r.t. the evidence (the MARG task) and finding the most likely joint state of the random variables given the evidence (the MAP task). In the PLP community one has focussed on computing the probability of a single random variable without evidence. This paper alleviates this situation by contributing general MARG and MAP inference techniques for probabilistic logic programs. The key contribution of this paper is a two-step approach for performing MARG and MAP inference in probabilistic logic programs. Our approach is similar to the work of Darwiche [2] and others [14, 12], who perform Bayesian network inference by conversion to weighted propositional formulae, in particular weighted CNFs. We do the same for probabilistic logic programs, a much more expressive representation framework (it extends a programming language, it allows for cycles, etc.) In the first step, the probabilistic logic program is converted to an equivalent weighted CNF. This conversion is based on well-known conversions from the knowledge representation literature. The MARG task then reduces to weighted model counting (WMC) on the resultin","New advances in compiling CNF into decomposable negation normal form | Modeling and Reasoning with Bayesian Networks | Probabilistic Inductive Logic Programming - Theory and Applications, volume 4911 | ProbLog: A probabilistic Prolog and its application in link discovery | Logic programming revisited: Logic programs as inductive definitions | Inference in probabilistic logic programs using weighted CNF’s | From sampling to model counting | Learning the parameters of probabilistic logic programs from interpretations | Representing normal programs with clauses | Dedicated tabling for a probabilistic setting | CP-logic theory inference with contextual variable elimination and comparison to BDD based inference methods | Using weighted MAX-SAT engines to solve MPE | Sound and efficient inference with probabilistic and deterministic dependencies | Solving Bayesian networks by Weighted Model Counting | The well-founded semantics for general logic programs",rejected,000
1202.3720.pdf.json,Efficient Inference in Markov Control Problems,,"Variational Methods for Reinforcement Learning | Trans-dimensional MCMC for Bayesian Policy Learning | An Expectation Maximization Algorithm for Continuous Markov Decision Processes with Arbitrary Rewards | Planning and Acting in Partially Observable Stochastic Domains | Nonlinear Systems | Policy search for motor primitives in robotics | Policy Gradient Methods for Robotics | Optimization with EM and Expectation-ConjugateGradient | Robot Modelling and Control | Policy Gradient Methods for Reinforcement Learning with Function Approximation | Reinforcement Learning: An Introduction | Pros and Cons of truncated Gaussian EP in the context of Approximate Inference Control | Probabilistic inference for solving (PO)MDPs | Bayesian Time Series Models, chapter Expectation-Maximization methods for solving (PO)MDPs and optimal control problems | Graphical Models, Exponential Families, and Variational Inference",rejected,000
1202.3721.pdf.json,Dynamic consistency and decision making under vacuous belief,"Ignorance as a state of knowledge is often characterized by the absence of relevant uncertainty information. Bayesian decision theory developed in the 1940s and 1950s, assuming the relevant risk is described by a probability function, ranks available actions by expected utility. The nature of the probability function can be objective (based on evidence) or subjective (based on personal preference). Almost immediately, many economists [19], [1] have been interested in the question how an individual should make decision if she can’t associate any probability distribution to possible consequences of each alternative because of lack of evidence or violation of Savage’s axioms. Following Savage’s axiomatic approach, the earlier studies describe rational preference under ignorance by its characteristic properties. The sustained interest in the problem is motivated by many real life circumstances in which ignorance arises naturally, for example, in competitive games where information about the opponent is scarce, unreliable, or even intentionally misleading. It is often a mistake to fill the void left by the lack of hard evidence with analytic and judgmental assumptions and then act upon those judgments as if they were facts. In their attempts to create artificial agents with intelligence, computer scientists encounter the problem of how to program the behavior of the agents in the face of lack of information. While borrowing heavily from economists and philosophers, computer scientists also have to be concerned with the question of how to represent the state of ignorance. For economists, ignorance means the absence of probability information, therefore it can be declared by simply leaving out the probability component. For artificial agents, it is desirable to have a method for uncertainty representation in which the ignorance is obtained at the limit when the amount of information an agent has approaches zero. I call this representation vacuous belief. (This term is used","An optimality criterion for decision making under ignorance | Ranking sets of objects | Representation of a preference ordering by a numberical function | Possibility theory, probability and fuzzy sets | Decisiontheoretic foundation of qualitative possibility theory | Two axiomatic approaches to decision making using possibility theory | A decision theory for partially consonant belief functions | Reasoning about Uncertainty | Information processing under imprecise risk with the Hurwicz criterion | Decision making with belief functions: Compatibility and incompatibility with the sure-thing principle | A characterization of optimality criteria for decision making under complete ignorance | Dynamic consistency and nonexpected utility models of choice under uncertainty | Decision-making under ignorance with implications for social choice | Rationality and dynamic choice | Continuous extensions of an order on a set to the power set | Choice under complete uncertainty when outcome spaces are state dependent | Dynamic choice and nonexpected utility | Subjective probability and expected utility without additivity | Expectations in economics | A Mathematical Theory of Evidence | The transferable belief model | Process fairness and dynamic consistency | Statistical Reasoning with Imprecise Probabilities | Inferences from multinomial data: Learning about a bag of marbles",rejected,000
1202.3723.pdf.json,Approximation by Quantization,"Many widely used approximate inference algorithms such as mini-bucket elimination (Dechter and Rish, 2003) and the generalized mean-field algorithm (Xing et al., 2003) are essentially scope-based approximations. The approximation is invoked when either the factors of the posterior distribution or intermediate functions generated during the execution of a variable elimination algorithm are too large to fit in memory or too time-consuming to compute. Since the time and memory cost of processing a function is exponential in its scope size (in this paper, we consider only discrete graphical models), these schemes reduce complexity by approximating a large-scope function by several small-scope functions. For instance, the generalized mean field algorithm approximates each component Pi of the posterior distribution by a tractable component Qi defined over a subset of the scope of Pi such that the KL divergence between Qi and Pi is minimized. The reasons for the popularity of the scope-based approach are obvious; it is a very natural and simple idea, it is easy to implement and its complexity can be easily controlled. In this paper, we propose a fundamentally different but complementary class of range-based approximations: the main idea is to quantize a function by mapping a number of distinct values in its range to a single value. When the number of distinct values in the range is reduced, the function becomes more compressible and the time required to manipulate it may decrease substantially. Unfortunately, if we represent functions using tables, namely if we store a real number for every possible configuration of all variables appearing in the function’s scope, quantization will be useless because we will not reduce the representation size. In other words, we need structured representations to take advantage of quantization. Many structured representations have been proposed in literature such as confactors (Poole and Zhang, 2003), sparse representations (Larkin and Dec","Algebraic decision diagrams and their applications | Context-specific independence in Bayesian networks | Compiling bayesian networks using variable elimination | On probabilistic inference by weighted model counting | A differential approach to inference in Bayesian networks | Results from the Probablistic Inference Evaluation of UAI’08 | Bucket elimination: A unifying framework for reasoning | Mini-buckets: A general scheme for bounded inference | Markov Logic: An Interface Layer for Artificial Intelligence | The 2010 UAI approximate inference challenge | Stochastic relaxations, Gibbs distributions and the Bayesian restoration of images | Formula-based probabilistic inference | Mini-bucket heuristics for improved search | Probabilistic Graphical Models: Principles and Techniques | Bayesian inference in presence of determinism | Local computation with probabilities on graphical structures and their application to expert systems | Approximate inference by compilation to arithmetic circuits | AND/OR multi-valued decision diagrams (AOMDDs) for graphical models | Joingraph propagation algorithms | Expectation Propagation for approximate Bayesian inference | Bounds on marginal probability distributions | Loopy belief propagation for approximate inference: An empirical study | Exploiting contextual independence in probabilistic inference | New mini-bucket partitioning heuristics for bounding the probability of evidence | Heuristics for fast exact model counting | Probabilistic diagnosis using a reformulation of the internist- 1/qmr knowledge base i | Cudd: CU decision diagram package release | Tree-reweighted belief propagation algorithms and approximate ml estimation by pseudo-moment matching | Inference in the promedas medical expert system | Optimal quantization by matrix searching | A generalized mean field algorithm for variational inference in exponential families | Constructing free energy approximations and generalized belief propagation algorithms",rejected,000
1202.3724.pdf.json,Probabilistic Theorem Proving,"Unifying first-order logic and probability enables uncertain reasoning over domains with complex relational structure, and is a long-standing goal of AI. Proposals go back to at least Nilsson [27], with substantial progress within the UAI community starting in the 1990s (e.g., [1, 19, 40]), and added impetus from the new field of statistical relational learning starting in the 2000s [16]. Many well-developed representations now exist (e.g., [9, 14, 23]), but the state of inference is less advanced. For the most part, inference is still carried out by converting models to propositional form (e.g., Bayesian networks) and then applying standard propositional algorithms. This typically incurs an exponen- tial blowup in the time and space cost of inference, and forgoes one of the chief attractions of first-order logic: the ability to perform lifted inference, i.e., reason over large domains in time independent of the number of objects they contain, using techniques like resolution theorem proving [32]. In recent years, progress in lifted probabilistic inference has picked up. An algorithm for lifted variable elimination was proposed by Poole [29] and extended by de Salvo Braz [10] and others. Lifted belief propagation was introduced by Singla and Domingos [38] and extended by others (e.g., [21, 36]). These algorithms often yield impressive efficiency gains compared to propositionalization, but still fall well short of the capabilities of first-order theorem proving, because they ignore logical structure, treating potentials as black boxes. This paper proposes the first full-blown probabilistic theorem prover, capable of exploiting both lifting and logical structure, and having standard theorem proving and standard graphical model inference as special cases. Our solution is obtained by reducing probabilistic theorem proving (PTP) to lifted weighted model counting. We first do the corresponding reduction for the propositional case, extending previous work by Darwiche [6] a",Representing and Reasoning with Probabilistic Knowledge | The model evolution calculus as a first-order DPLL method | Jr | On probabilistic inference by weighted model counting | Recursive conditioning | A logical approach to factoring belief networks | A machine program for theorem proving | A computing procedure for quantification theory | Problog: A probabilistic prolog and its application in link discovery | Lifted First-Order Probabilistic Inference | Bucket elimination: A unifying framework for reasoning | AND/OR search spaces for graphical models | Inducing features of random fields | Markov Logic: An Interface Layer for Artificial Intelligence | Logical Foundations of Artificial Intelligence | editors | Formula-based probabilistic inference | SampleSearch: Importance Sampling in presence of Determinism | An analysis of first-order logics of probability | Lifted inference from the other side: The tractable features | Counting Belief Propagation | Constraint processing in lifted probabilistic inference | BLOG: Probabilistic models with unknown objects | Lifted probabilistic inference with counting formulas | The Alchemy system for statistical relational AI | Probabilistic modelling | Probabilistic logic | Using weighted MAX-SAT engines to solve MPE | First-order probabilistic inference | Sound and efficient inference with probabilistic and deterministic dependencies | A general method for reducing the complexity of relational inference and its application to MCMC | A machine-oriented logic based on the resolution principle | Simulation and the Monte Carlo Method | Solving Bayesian networks by weighted model counting | Heuristics for fast exact model counting | Bisimulation-based approximate lifted inference | Discriminative training of Markov logic networks | Lifted first-order belief propagation | OLD resolution with tabulation | From knowledge bases to decision models,rejected,000
1202.3728.pdf.json,Reasoning about RoboCup Soccer Narratives,"Natural language understanding requires the ability to translate individual sentences into representations of the underlying entities, properties, relations, and actions. It further requires the ability to combine the representations of individual sentences into a coherent whole. For example, determining from a commentary of a soccer game who has possession of the ball at any given moment requires one to infer numerous events that may not have been explicitly mentioned such as unsuccessful passing, kicking the ball, or stealing the ball. This paper argues that the coherence of natural language text provides a strong bias that can be exploited when learning to understand language. One particularly simple form of coherence requires that events can only take place when their preconditions are met. For example, a soccer player cannot kick the ball unless he is currently in possession of the ball. We present an approach that incorporates such domain knowledge into the process of learning to understand sports commentaries without annotated data. We use human commentaries of four championship games in the RoboCup simulation league [6] and map each narrative to a sequence of events such as pass, kick, steal, offside along with their arguments. Soccer commentaries differ from more complex narratives in that they report a linear sequence of events that unfolds over time. In a soccer commentary, each sentence results in an incremental update of the overall representation, or discourse model [24, 11, 9], making it possible to reconstruct the original temporal sequence of events. In this paper we show how a small amount of domain knowledge and a bias towards coherent discourse models can be used to learn how to interpret narratives. The domain knowledge we exploit encodes the preconditions and effects of event types using a STRIPS-like framework [8]. The logical representation of knowledge allows structured modeling of event types rather than modeling propositional state transit","Reasoning about actions in a probabilistic setting | Pattern Recognition and Machine Learning | Reinforcement learning for mapping instructions to actions | A general model for online probabilistic plan recognition | A bayesian model of plan recognition | Training a multilingual sportscaster: Using perceptual context to learn language | Learning probabilistic relational dynamics for multiple tasks | STRIPS: a new approach to the application of theorem proving to problem solving | Attention, intention and the structure of discourse | Sampling first order logical particles | Mental Models | Learning language semantics from ambiguous supervision | A formal theory of plan recognition | Learning and inferring transportation routines | Rhetorical Structure Theory: Toward a functional theory of text | Learning a probabilistic model of event sequences from internet weblog stroeis | A tutorial on HMM and selected applications in speech recognition | Logical Foundations for Describing and Implementing Dynamical Systems | Advice generation from observed execution: Abstract markov decision process learning | Recognizing multiagent activities from gps data | Verbnet: a broad-coverage, comprehensive verb lexicon | MAXPLAN: A new approach to probabilistic planning | Learning to follow navigational directions | A Formal Approach to Discourse Anaphora | Learning context-dependent mappings from sentences to logical forms | Learning planning rules in noisy stochastic worlds",rejected,000
1202.3729.pdf.json,Suboptimality Bounds for Stochastic Shortest Path Problems,"A stochastic shortest path problem is a Markov decision process (MDP) where the objective is to find a minimumcost policy that reaches a goal or terminal state with probability 1 [4, 2]. It is an elegant model for many problems of planning under uncertainty, especially for goal-oriented decision-theoretic planning problems where policy execution terminates once a goal condition is achieved. Standard solution methods rely on dynamic programming or linear programming. The model is also used in the development and analysis of reinforcement learning and heuristic search algorithms for MDPs [15, 1, 6]. There are extensions of the stochastic shortest path problem for planning under partial observability [11], multi-agent planning [12, 8], and risksensitive planning [10]. For the stochastic shortest path problem, the expected total cost of policy execution is bounded, without discounting. Thus it is an important alternative to the discounted infinitehorizon MDP as a model for decision-theoretic planning. Although use of a discount factor sometimes has an economic justification, discounting is not well-motivated for many AI planning problems and has potential drawbacks. It can skew the relative values of policies and change the optimal policy. Discounting can also make it impossible to guarantee that dynamic programming finds a policy that reaches a goal state with probability 1. With discounting, a policy that cycles forever without reaching the goal state still has finite total cost, which could be less than the cost of the best policy that is guaranteed to reach the goal state. Despite potential drawbacks, the discounted infinitehorizon model is widely used. One reason for its appeal is that discounting is a simple way to ensure that algorithms for solving infinite-horizon MDPs have the desired convergence properties, since the dynamic programming operator is a contraction operator in this case, with the contraction rate equal to the discount factor. Although the converg","Learning to act using real-time dynamic programming | Dynamic Programming and Optimal Control, Volume I | Parallel and distributed computation: Numerical methods | Analysis of stochastic shortest path problems | Neuro-Dynamic Programming | Heuristic search for planning under uncertainty | On the undecidability of probabilistic planning and related stochastic optimization problems | Decentralized algorithms for netcentric force protection against antiship missiles | Approximating optimal policies for partially observable stochastic domains | On terminating Markov decision processes with a risk averse objective function | Partially observed stochastic shortest path problems with approximate solution by neurodynamic programming | Stochastic shortest path games | Artificial Intelligence: A Modern Approach | Heuristic search value iteration for POMDPs | Asynchronous stochastic approximation and Q-learning | Speeding up the convergence of value iteration in partially observable Markov decision processes",rejected,000
1202.3740.pdf.json,An Efficient Protocol for Negotiation over Combinatorial Domains with Incomplete Information,"Multi-issue negotiation is one of the most preferred approaches for resolving conflicts in agent society [4]. It is being increasingly used in different multi-agent domains including trading systems, resource allocation, service level agreement negotiations, etc. [4, 9]. When multiple issues are involved in negotiation simultaneously, the agents with divergent preferences can cooperate to reach agreements that are beneficial for each other. But when the preferences of the participating agents are not common knowledge, they often fail to explore win-win possibilities and end up with inefficient results. Therefore, there is a need for negotiation protocols which can lead rational agents to op- timal agreements. By optimal or efficient agreement, we refer to an agreement which is Pareto-optimal (or Pareto-efficient) [7]. An alternative or outcome is Pareto-optimal (or Pareto-efficient) if there exists no other alternative which is at least as good as this alternative for all agents and strictly better for at least one agent. In this paper, we focus on the negotiation problems where the space of alternatives has a combinatorial structure 1. For example, negotiations over multiple indivisible goods or resources (where the number of bundles an agent may obtain is exponential in the number of goods or resources). When the negotiating agents know about the preferences of each other, they can reach an efficient agreement using distributed protocols like one-step monotonic concession protocol or monotonic concession protocol [8], where each agent searches the entire space of possible agreements. Similar scenarios of multi-attribute decision-making with complete information have also been studied in the field of collective decision-making in combinatorial domains, i.e. voting theory and preference aggregation (for instance, [5], [7], [10] etc..), which determines either one, some, or all optimal alternatives from a given collection of the agents preferences according to a give",CP-nets: A tool for representing and reasoning with conditional ceteris paribus preference statements | The Win-Win Solution: Guaranteeing Fair Shares to Everybody | Raiffa. Decisions with Multiple Objectives: Preferences and Value Tradeoffs. Wiley series in probability and mathematical statistics | Strategic Negotiation in Multiagent Environments | Sequential composition of voting rules in multi-issue domains | Efficient heuristic approach to dominance testing in CP-nets | Voting and collective choice; some aspects of the theory of group decision-making | Rules of encounter: designing conventions for automated negotiation among computers | An effcient protocol for negotiation over multiple indivisible resources | Voting on multiattribute domains with cyclic preferential dependencies,rejected,000
1202.3741.pdf.json,Noisy Search with Comparative Feedback,"We investigate a form of noisy search that arises in information retrieval systems, e.g. content-based image retrieval [Cox et al., 2000]. Consider a system where a user can search for a target item (unknown to the system) by answering a sequence of “queries” generated by the system. As an example, consider a content-based image retrieval system. The system first presents k images to the user. The user then selects one that is the most similar to the target image. Based on the image chosen by the user, the system presents a new set of k images and the user answers by selecting one of these k images. This continues until the target is found by the system. We assume that the user response in each query is probabilistic and depends on the similarities between the presented images and the target image according to a comparative feedback model as proposed in [Cox et al., 2000] and [Auer and Leung, 2009]. The search process is inherently noisy due to the probabilistic nature of the user feedback. We are interested in the performance of such systems in terms of query complexity, i.e the expected number of queries needed before a target is found.","Exploration-exploitation trade-offs with delayed feedback | Relevance feedback models for contentbased image retrieval. Multimedia Analysis, Processing and Communications | The bayesian learner is optimal for noisy binary search (and pretty good for quantum as well) | The Bayesian image retrieval system, PicHunter: theory, implementation, and psychophysical experiments",rejected,000
1202.3743.pdf.json,Belief change with noisy sensing in the situation calculus,"Situation calculus, introduced by John McCarthy [14, 15], has been applied widely to model and reason about actions and changes in dynamic systems. It was reinterpreted in [17] as basic action theories which are comprised of a set of foundational axioms defining the space of situations, unique-name axioms for actions, action preconditions and effects axioms, and the initial situation axioms [8]. The well known frame problem is solved by a set of special action effects axioms called successor state axioms. Since actions carried out by agents cause constant changes of the agents’ beliefs, developing strategies of managing belief changes triggered by actions is an important issue. The problem of iterated belief change within the framework of situation calculus has been investigated widely, e.g., [19, 20, 22, 13]. In [22], a new framework exceeding previous approaches was proposed in which a plausibility value is attached to every situation. This way, the framework is able to deal with nested beliefs, belief introspection, mistaken beliefs, and it can also handle belief revision and belief update (two types of belief changes) together in a seamless way. Although this framework has many distinct advantages, it suffers from some drawbacks. In this framework, a set of initial situations which an agent considers possible are given, then every time the agent performs a sensing action, situations that do not match the sensing result (e.g., a sensing result shows the light is on, while it is considered off in the situation) are discarded. A key assumption of the framework is that all sensing actions must be accurate, an assumption that is too strong in real-world scenarios. When sensing actions are not accurate, situations that perfectly match the actual situation are in fact discarded. Discarding such situations results in inconsistency and makes subsequent reasoning unproceedable. Let us illustrate this with the following example. Example 1 (adapted from [22]) Assume that th","On the logic of theory change: Partial meet functions for contraction and revision | From statistical knowledge bases to degrees of belief | Reasoning about noisy sensors and effectors in the situation calculus | On the logic of iterated belief revision | Progression using regression and sensors | Representing beliefs in the fluent calculus | Propositional knowledge base revision and minimal change | A semantic characterization of a useful fragment of the situation calculus with knowledge | What is planning in the presence of sensing | Modeling belief change on epistemic states | A framework for managing uncertain inputs: an axiomization of rewarding | A belief revision framework for revising epistemic states with partial epistemic states | Handling sequential observations in intelligent surveillance | Situations, Actions and Causal Laws | Some philosophical problems from the standpoint of artificial intelligence | Semantic considerations on nonmonotonic logic | The frame problem in the situation calculus: A simple solution (sometimes) and a completeness result for goal regression | Extending DT- Golog to deal with POMDPs | The frame problem and knowledge-producing actions | Knowledge, action, and the frame problem | Belief change with noisy sensing and introspection | Iterated belief change in the situation calculus | Knowledge, belief, and noisy sensing in the situation calculus. In www.cs.jhu.edu/ psimari/publications/simari msc.pdf | Ordinal conditional functions: A dynamic theory of epistemic states. Causation in Decision",rejected,000
1202.3744.pdf.json,Improving the Scalability of Optimal Bayesian Network Learning with External-Memory Frontier Breadth-First Branch and Bound Search,"Bayesian networks are a common machine learning technique used to represent relationships among variables in data sets. When these relationships are not known a priori, the structure of the network must be learned. A common learning approach entails searching for a structure which optimizes a particular scoring function (Cooper and Herskovits 1992; Heckerman, Geiger, and Chickering 1995). Because of the difficulty of the problem, early approaches focused on approximation techniques to learn “good” networks (Cooper and Herskovits 1992; Heckerman, Geiger, and Chickering 1995; Heckerman 1998; Friedman, Nachman, and Peer 1999; Tsamardinos, Brown, and Aliferis 2006). Unfortunately, these algorithms are unable to guarantee anything about the quality of the learned networks. Exact dynamic programming algorithms have been developed to learn provably optimal Bayesian network struc- tures (Ott, Imoto, and Miyano 2004; Koivisto and Sood 2004; Singh and Moore 2005; Silander and Myllymaki 2006). These algorithms identify optimal small subnetworks and add optimal leaves to find large optimal networks until finding the optimal network including all variables. Unfortunately, all of these algorithms must store an exponential number of subnetworks and associated information in memory. Parviainen and Koivisto (2009) recently proposed a divide-and-conquer algorithm in which fewer subnetworks are stored in memory at once at the expense of longer running time. Theoretical results suggest that this algorithm is slower than dynamic programming when an exponential number of processors is not available. Yuan et al. (2011) developed an A* heuristic search formulation based on the dynamic programming recurrences to learn optimal network structures. The algorithm formulates the learning problem as a shortest-path finding problem in a search graph. Each path in the graph corresponds to an ordering of the variables, and each edge on the path has a cost that corresponds to the choice of an optimal","Learning Bayesian networks is NP-complete | A Bayesian method for the induction of probabilistic networks from data | Structure learning of Bayesian networks using constraints | Learning Bayesian network structure from massive datasets: The “sparse candidate” algorithm | Learning Bayesian networks: The combination of knowledge and statistical data | A tutorial on learning with Bayesian networks | Learning Bayesian network structure using LP relaxations | The Art of Computer Programming, Volume 4, Fascicles 0-4 | Exact Bayesian structure discovery in Bayesian networks | Frontier search | Linear-time disk-based implicit graph search | Memoryefficient dynamic programming for learning optimal Bayesian networks | Cached sufficient statistics for efficient machine learning with large datasets | Finding optimal models for small gene networks | Exact structure discovery in Bayesian networks with less space | Modeling by shortest data description | A simple approach for finding the globally optimal Bayesian network structure | Finding optimal Bayesian networks by dynamic programming | A branch-and-bound algorithm for MDL learning Bayesian networks | The max-min hill-climbing Bayesian network structure learning algorithm | Learning optimal Bayesian networks using A* search | Sweep A*: Space-efficient heuristic search in partially ordered graphs | Breadth-first heuristic search",rejected,000
1202.3745.pdf.json,Order-of-Magnitude Influence Diagrams,"Influence diagrams have been widely used for the past three decades as a graphical model to formulate and solve decision problems under uncertainty. The standard formulation of an influence diagram consists of two types of information: qualitative information that defines the structure of the problem eg, the set of (discrete) chance variables describing the set of possible world configurations, the set of available decisions, as well as the dependencies between the variables, and quantitative information (also known as the parametric structure) that, together with the qualitative information, defines the model. The parametric structure is composed of the conditional probability distributions as well as the utility functions describing the decision maker’s preferences. In general, the solution to an influence diagram depends on both types of information. Quite often, however, we may have precise knowledge of the qualitative information but only very rough (or imprecise) estimates of the quantitative parameters. In such cases, the standard solution techniques cannot be applied directly, unless the missing information is accounted for. In this paper, we propose a qualitative theory for influence ∗This work was supported in part by the Science Foundation Ireland under grant no. 08/PI/I1912 diagrams in which such partially specified sequential decision problems can be modeled and solved. In particular, we introduce the order-of-magnitude influence diagram model that uses an order-of-magnitude representation of the probabilities and utilities. The model allows the decision maker to specify partially ordered preferences via finite sets of utility values. In this case, there will typically not be a unique maximal value of the expected utility, but rather a set of them. To compute this set and also the corresponding decision policy we propose a dedicated variable elimination algorithm that performs efficient operations on sets of utility values. Numerical experiments on sele",Qualitative MDPs and POMDPs: an order-of-magnitude approximation | On the relation between kappa calculus and probabilistic reasoning | A new perspective on algorithms for optimizing policies under uncertainty | Complexity results and algorithms for possibilistic influence diagrams | From influence diagrams to junction trees | Sequential decision making with partially ordered preferences | Influence diagrams with super value nodes involving imprecise information | Sequential decision making problems - representation and solution | Decision analysis | Evaluating influence diagrams | Valuation-based systems for Bayesian decision analysis | Ordinal conditional functions: a dynamic theory of epistemic states | Dynamic programming and influence diagrams | An order of magnitude calculus | An axiomatic framework for influence diagram computation with partially ordered utilities,rejected,000
1202.3749.pdf.json,Compact Mathematical Programs For DEC-MDPs With Structured Agent Interactions,"Consider a robotic team dealing with a building on fire. One agent is in charge of putting out the fire, another locates and evacuates survivors and a third delivers first aid to the injured. Most of an agent’s actions affect only itself (e.g. the first agent’s exact approach to fire fighting and the kind of extinguisher it uses mainly affect its own progress). However, the decision-making problems of these agents are not completely independent. For example, the fire-fighting agent’s decision of when to secure a given area affects how easy it will be for the rescue agent to locate survivors in that area. ∗This work was done while the first author was a Ph.D. student at University of Massachusetts, Amherst. Decentralized Markov Decision Processes (DECMDPs) have been widely used to model situations like the above. However, DEC-MDPs obscure the structured agent interaction, thus missing the representational and computational savings that can be obtained due to the loose coupling among the agents. Several models have been proposed in an attempt to exploit structured interactions, with each model catering to a different kind of structure [11, 13, 12]. Settings like the above example, where agents are largely independent except for few actions that affect the transitions and/or rewards of other agents, can be modeled using Event-Driven Interactions with Complex Rewards (EDI-CR). EDI-CR is much more compact than DEC-MDPs [9] without sacrificing expressive power. Finding the optimal policy in decision-theoretic models can be formulated as a mathematical program. In this paper, we propose a compact formulation of EDICR as a Mixed Integer Linear Program (MILP). Starting with an existing non-linear formulation of general DEC-MDPs, we introduce new variables to linearize the program, but exploit structured interactions to minimize the number of variables introduced. We develop an exact formulation for the case of 2 agents and a relaxed formulation for the case of 3 or more agen",,rejected,000
1202.3751.pdf.json,Dynamic Mechanism Design for Markets with Strategic Resources,"Let us consider the example of an organization having multiple sales and production teams. The sales teams receive project contracts, which are to be executed by the production teams. The problem that the management of both teams faces is that of assigning the projects (tasks) to production teams (resources). If the efficiency levels of the production teams and the workloads of the projects are observable by the management (controller), this problem reduces to an MDP, which has been well studied in the literature (Bertsekas, 1995; Puterman, 2005). Let us call the efficiency levels and workloads together as states of the tasks and resources. However, the states are usually observed privately by the individual teams (agents), who are rational and intelligent. They, therefore, might strategically misreport to the controller to increase their net returns. Hence, the problem changes from a completely or partially observable MDP into a dynamic game among the agents. We will consider cases where the solution of the problem involves monetary transfer. Hence, the task owners pay the resources to execute their tasks. A socially efficient mechanism would demand truthfulness and voluntary participation of the agents in this setting. The reporting strategy of the agents and the decision problem of the controller is dynamic since the state of the system is varying with time. In addition, the above problem has two characteristics, namely, interdependent values : the task execution generates values to the task owners that depend on the efficiencies of the assigned resources, and exchange economy: a trade environment where both buyers (task owners) and sellers (resources) are present. An exchange economy is also referred to as a market. The above properties have been investigated separately in literature on dynamic mechanism design. Bergemann and Välimäki (2010) have proposed an efficient mechanism called the dynamic pivot mechanism, which is a generalization of the Vickrey-Clarke","An efficient dynamic mechanism. Working Paper, Stanford University, Earlier version circulated | Dynamic Programming and Optimal Control, volume I | Social Welfare Maximization in Dynamic Strategic Decision Problems | Optimal coordinated planning amongst self-interested agents with private state | Efficient Mechanisms with Dynamic Populations and Dynamic Types | Multipart Pricing of Public Goods | Incentives in Teams | Games with Incomplete Information Played by “Bayesian | Efficient Design with Interdependent Valuations | Multi-agent influence diagrams for representing and solving games | Mechanism Design with Interdependent Valuations: Efficiency | Mechanism design with interdependent valuations: surplus extraction | Game Theoretic Problems in Network Economics and Mechanism Design Solutions | Markov Decision Processes: Discrete Stochastic Dynamic Programming | Multiagent Systems: Algorithmic, Game-Theoretic, and Logical Foundations | Counterspeculation, Auctions, and Competitive Sealed Tenders | A New Complexity Result on Solving the Markov Decision Problem",rejected,000
1202.3754.pdf.json,A Geometric Traversal Algorithm for Reward-Uncertain MDPs,"Markov Decision Processes (MDPs) have been a popular model for stochastic sequential decision making problems (Puterman 1994). Once we obtain the MDP model of the problem, we can solve it efficiently using various methods such as value iteration, policy iteration, or linear programming (LP) solver. However, the specification of model parameters, the transition probabilities and the rewards, can be a difficult task. For example, since the transition probabilities are estimated from the data or specified by the domain expert, there inevitably exists uncertainty regarding the accuracy of the estimation, which affects the real performance of the optimal policy obtained from the model. The specification of rewards poses a greater challenge in the sense that the current practice involves manual specification by the domain expert, and estimating it from the data still remains as an emerging research area, e.g., inverse reinforcement learning (Ng and Russell 2000). Over the recent years, a significant body of research has dealt with finding the robust solution to MDPs with imprecisely specified parameters. While most of the work in the past uses the maximin criterion to address the uncertainty in the transition probabilities only (White and Eldeib 1994; Nilim and Ghaoui 2005) or both (White and Eldeib 1986; Givan et al. 1997), some recent approaches solely focus on the imprecise specification of rewards (Delage and Mannor 2009; Xu and Mannor 2009; Regan and Boutilier 2009; Regan and Boutilier 2010). This is not only because the rewards are more difficult to specify than the transition probabilities, but also the uncertainty in the rewards is an important subject for preference elicitation algorithms (Regan and Boutilier 2009). The minimax regret criterion was also proposed for computing the robust policy for MDPs with imprecise rewards (Xu and Mannor 2009; Regan and Boutilier 2009; Regan and Boutilier 2010). The challenge is in finding an effective algorithm to address the ","Introduction to Linear Optimization | Percentile Optimization for Markov Decision Processes with Parameter Uncertainty | Bounded Parameter Markov Decision Processes | Algorithms for Inverse Reinforcement Learning | Robust Control of Markov Decision Processes with Uncertain Transition Matrices. Operations Research 53(5):780-798 | Markov Decision Processes: Discrete Stochastic Dynamic Programming, Wiley, Newyork | Regret-based Reward Elicitation for Markov Decision Processes | Robust Policy Computation in Reward-uncertain MDPs using Nondominated Policies | Parameter Imprecision in Finite State, Finite Action Dynamic Programs | Markov Decision Processes with Imprecise Transition Probabilities | Parametric Regret in Uncertain Markov Decision Processes",rejected,000
1202.3756.pdf.json,Price Updating in Combinatorial Prediction Markets with Bayesian Networks,"In a predictionmarket, agents trade securities about the outcome of an uncertain event, for example, “if event E happens, this security pays off $1”. IfE does happen, the agent receives $1 for every share of the security owned; if E does not happen, the agent gets nothing. The price of a security reflects a collective value for “$1 if E”, or a group-wide or consensus probability of the eventE. The idea is to harness market efficiency and leverage agents’ incentives to earn money in order to price events that might not otherwise be traded. In a predictionmarket, the primary goal is price discovery and thus information aggregation, not finding gains ∗Part of this work was conducted at Yahoo! Research. from trade. The Iowa Electronic Market and Intrade are two examples of real-world prediction markets with a long history of tested results [1, 2]. See Chen and Pennock [7] for a recent survey of prediction mechanisms. In this paper, we focus on prediction market mechanisms that employ a central market maker that determines the prices of securities algorithmically based on a cost function [6]. At any time, an interested agent can query the market maker for the price of a security and can either “take it or leave it”: that is, decide to buy or sell some shares at the quoted price, or do nothing. After each (infinitesimal) trade, the market maker updates the prices of all securities. For example, suppose there is a prediction market on a Duke basketball game, and the current price for the security “Duke wins” is $ 0.8. If a risk-neutral agent believes that Duke will win with 0.9 probability, then she has an incentive to buy some shares of the security, because her expected profit for holding one share is 0.9 − 0.8 = 0.1. If she buys some shares of the security, then its price will go up; on the other hand, if she sells some shares of the security (in this case, equivalent to buying shares of Duke’s opponent), then its price will go down. See Section 2 for more details. So f",Results from a dozen years of election futures markets research | Prediction market accuracy in the long run | On probabilistic inference by weighted model counting | Complexity of combinatorial market makers | Pricing combinatorial markets for tournaments | A utility framework for bounded-loss market makers | Designing markets for prediction | A new understanding of prediction markets via no-regret learning | The computational complexity of probabilistic inference using Bayes belief networks | Modeling and Reasoning with Bayesian Networks | Betting Boolean-style: A framework for trading in securities based on logical formulas | Group consensus probability distributions: A critical survey | Combining probability distributions: A critique and an annotated bibliography | Agreeing to disagree: Leveraging consensus and divergence in bayesian belief aggregation | Combinatorial information market design | Logarithmic market scoring rules for modular combinatorial information aggregation | Aggregating learned probabilistic beliefs | Probabilistic reasoning in intelligent systems: Networks of plausible inference | Graphical models for groups: Belief aggregation and risk sharing | Performing Bayesian inference by weighted model counting,rejected,000
1202.3759.pdf.json,Compressed Inference for Probabilistic Sequential Models,"Assigning labels to sequential data is a common problem extensively studied in several application domains such as computer vision and computational linguistics (Rabiner (1989), Lafferty et al. (2001), Quattoni et al. (2004)). For instance, in part-of-speech tagging, the problem is to tag parts of speech by considering the grammatical structure of the language, e.g., (verb verb noun noun verb adjective) is a very unlikely sequence in English. Likewise, one can assign letters to a sequence of images of hand-written characters by again exploiting the structure enforced by the grammar of that language. In these examples, sequential patterns are important and they can be used to extract information from massive data sets. Two common models for solving such problems are hidden Markov models (HMMs), and conditional random fields (CRFs, often as a linear-chain). These models have been extended in various forms to adapt to different types of problems. For example, semi-Markovian CRFs are introduced as a solution to segmentation problem allowing non-Markovian transitions in segments and assigning direct labels not to individual samples but to overall segments (Sarawagi & Cohen (2004)). Fox et al. (2008) proposes a non-parametric prior for systems with state persistence to prevent unrealistically many transitions. This method not only provides state persistence, but also allows learning the transition probabilities in an infinite state space. In these examples, the inference algorithm estimates the state sequence. But in several applications, this is not the end goal; instead the goal is to compute some function of the state sequence. In particular, we consider a frequently occurring form of this problem, compressed inference, where the function compress just keeps track of the state transitions without keeping track of the dwell times at each state and exact transition points. A simple example is the detection of actions in the movement of a human subject where the exact tra","Investigating Loss Functions and Optimization Methods for Discriminative Learning of Label Sequences, in ‘Proc. EMNLP | Hybrid mobile robot localization using switching state-space models, in ‘ICRA | Shape matching and object recognition using shape contexts | Confidence estimation for information extraction, in ‘Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics (HLTNAACL) | A simple-transition model for relational sequences, in ‘IJCAI | Relational sequential inference with reliable observations, in ‘Proc. of the International Conference on Machine Learning | An hdp-hmm for systems with state persistence, in ‘Advances in Neural Information Processing Systems | Interactive information extraction with constrained conditional random fields, in ‘AAAI | Conditional random fields: Probabilistic models for segmenting and labeling sequence data, in ‘International Conference on Machine Learning | HCRF library: Discriminative models for sequence labeling | Vision based single stroke character recognition for wearable computing | Conditional random fields for object recognition, in ‘Advances in Neural Information Processing Systems | A tutorial on hidden markov models and selected applications in speech recognition, in ‘Proceedings of the IEEE | semi-CRF :a java implementation of conditional random fields for sequential labeling | Semi-markov conditional random fields for information extraction, in ‘Advances in Neural Information | Introduction to Conditional Random Fields for Relational Learning | Max-margin markov networks, in ‘Neural Information Processing Systems Conference",rejected,000
1202.3762.pdf.json,Symbolic Dynamic Programming for Discrete and Continuous State MDPs,"Many real-world stochastic planning problems involving resources, time, or spatial configurations naturally use continuous variables in their state representation. For example, in the MARS ROVER problem [6], a rover must manage bounded continuous resources of battery power and daylight time as it plans scientific discovery tasks for a set of landmarks on a given day. While problems such as the MARS ROVER are naturally modeled by discrete and continuous state Markov decision processes (DC-MDPs), little progress seems to have been made in recent years in developing exact solutions for DC-MDPs with multiple continuous state variables be- yond the subset of DC-MDPs which have an optimal hyperrectangular piecewise linear value function [8, 11]. Yet even simple DC-MDPs may require optimal value functions that are piecewise functions with non-rectangular boundaries; as an illustration, we consider KNAPSACK: Example 1.1 (KNAPSACK). We have three continuous state variables: k ∈ [0, 100] indicating knapsack weight, and two sources of knapsack contents: xi ∈ [0, 100] for i ∈ {1, 2}. We have two actions movei for i ∈ {1, 2} that can move all of a resource from xi to the knapsack if the knapsack weight remains below its capacity of 100. We get an immediate reward for any weight added to the knapsack. We can formalize the transition and reward for KNAPSACK action movei (i ∈ {1, 2}) using conditional equations, where (k, x1, x2) and (k′, x′1, x ′ 2) are respectively the preand post-action state and R is immediate reward: k′ = ( k + xi ≤ 100 : k + xi k + xi > 100 : k R = ( k + xi ≤ 100 : xi k + xi > 100 : 0 x′i = ( k + xi ≤ 100 : 0 k + xi > 100 : xi x′j = xj , (j 6= i) If our objective is to maximize the long-term value V (i.e., the sum of rewards received over an infinite horizon of actions), then we can write the optimal value achievable from a given state in KNAPSACK as a function of state variables: V = 8>>>><>>>>: x1 + k > 100 ∧ x2 + k > 100 : 0 x1 + k > 100 ∧ x2 + k ≤ 100 : x",Algebraic Decision Diagrams and their applications | Dynamic Programming | Decision-theoretic planning: Structural assumptions and computational leverage | Symbolic dynamic programming for first-order MDPs | Exact solutions to time-dependent MDPs | Planning under continuous time and resource uncertainty: A challenge for ai | A model for reasoning about persistence and causation | Dynamic programming for structured continuous markov decision problems | SPUDD: Stochastic planning using decision diagrams | Solving factored mdps with hybrid state and action variables | Lazy approximation for solving continuous finite-horizon mdps | A fast analytical algorithm for solving markov decision processes with real-valued resources | A heuristic search approach to planning with continuous resources in stochastic domains | Temporal planning with continuous change | Variable resolution discretization in optimal control | APRICODD: Approximate policy construction using decision diagrams | Exploiting causal independence in bayesian network inference,rejected,000
1202.3764.pdf.json,Adjustment Criteria in Causal Diagrams: An Algorithmic Perspective,"A notorious problem affecting probabilistic reasoning in causal structures is bias. For instance, we might study whether regular coffee drinking (C) increases the risk of suffering a heart attack (H). Such a study might be compromised by an unobserved genetic predisposition (U) that causes an increased preference for coffee drinking but also for smoking (S), which does increase the risk to suffer a heart attack. These causal influences can be modeled as a causal diagram G = C ← U → S → H, whose arrows indicate the directionality of causal relationships between the variables of interest [9]. The paths from U to both C and H in this diagram indicate that an observed relation between C and H will be confounded by U, which may obscure or artificially increase the putative causal ef- fect. This bias can be controlled by adjustment for S, e.g. by averaging separate effect estimates for smokers and non-smokers. We can represent adjustment in the diagram by labeling S: C ← U → S → H. This labeling blocks the biasing path from C to H. To avoid bias, it may seem advisable to adjust for all covariates in our study. Unfortunately, adjustment can also create bias. A folklore example is the following: If we ask Harvard students for their grades and their parents’ income, we may well find an inverse correlation between the two, which could lead us to the interesting hypothesis that rich people have dumber than average children. However, a more likely explanation is that having rich parents (R) or being smart (S) both increase the odds of getting to Harvard (H). This hypothesis corresponds to the diagram R→ H ← S, in which H is labeled because we implicitly adjusted for H by restricting our study to Harvard students only. Because H is a common descendant of R and S, this opens a biasing path between R and S, which leads to so-called Berksonian bias [2] – hence, our “interesting” observation is merely an artifact. A further example where confounding and Berksonian bias combine to so","An algorithm for finding minimum d-separating sets in belief networks | Limitations of the application of fourfold tables to hospital data | dagR: A suite of R functions for directed acyclic graphs | Finding common ancestors and disjoint paths in DAGs | Finding the k shortest paths | DAG program: identifying minimal sufficient adjustment sets | Commentator: A front-end userinterface module for graphical and structural equation modeling | Independence properties of directed markov fields | Causality | Modern Epidemiology | Bayes-ball: The rational pastime | On the validity of covariate adjustment for estimating causal effects | Space-optimal, backtracking algorithms to list the minimal vertex separators of a graph | DAGitty: A graphical tool for analyzing causal diagrams | Finding minimal dseparators",rejected,000
1202.3767.pdf.json,Distributed Anytime MAP Inference,"Undirected graphical models are powerful tools for modelling many real world problems. They have been successfully applied to a diverse set of problems such as: image processing [1], protein design [2], and text labelling [3]. One desirable operation on such models is to infer their most probable configuration; the maximum a posteriori (MAP) problem. For tree-structured graphs algorithms exist that are guaranteed to compute the globally optimal MAP solution in polynomial time (see for example: [4, 5]). Finding the MAP solution for arbitrary graphs has been proven to be NP-hard [6]. For such graphs ap- proximation algorithms are required to generate solutions in a feasible time-span. One particularly popular algorithm is based on Max-Product Belief Propagation due to Pearl [5]. Max-Product is exact for treestructured graphs. For arbitrary graphs the algorithm has been adapted such that it runs for a number of iterations and is known as Loopy Belief Propagation (LBP, see [7]). LBP has (at best) weak guarantees on convergence and optimality, i.e. local optimality or guarantees for specific types of loopy graphs. Despite this, the algorithm has been shown to generate good results for a large number of problems. In this paper we propose a novel algorithm for the MAP inference problem of graphical model G = (V,E). Starting from a quadratic formulation over the nodes, s ∈ V (analogous to [8]), the problem is transformed into an integer formulation over the edges, (s, t) ∈ E. It is subsequently relaxed into a Linear Program (LP). The transformation from quadratic to linear increases both the number of variables (O(|V |k) → O(|E|k2)) as well as constraints (O(|V |) → O(|E| +  s∈V (|N (s)|− 1)k)). Where for ease of notation each node has k states, while N (s) are the neighbours of node s. The resulting LP formulation is equivalent to the standard MAP LP formulation (see for example [9]). However, defining the LP over the edge variables has certain advantages as discussed next","Learning conditional random fields for stereo | Tightening lp relaxations for map using message-passing | Conditional random fields: Probabilistic models for segmenting and labeling sequence data | Exact maximum a posteriori estimation for binary images | Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference | Finding maps for belief networks is np-hard | Loopy belief propagation for approximate inference: An empirical study | Quadratic programming relaxations for metric labeling and markov random field map estimation | A linear programming approach to maxsum problem: A review | Linear Programming 2: Theory and Extensions. Springer Series in Operations Research and Financial Engineering | Exploring Artificial Intelligence in the New Millennium, chapter Understanding Belief Propagation and Its Generalizations | Map estimation via agreement on trees: Message passing and linear programming | Convergent tree-reweighted message passing for energy minimization | Linear programming relaxations and belief propagation – an empirical study | Fixing max-product: Convergent message passing algorithms for map lprelaxations | Clusters and coarse partitions in lp relaxations | Mrf optimization via dual decomposition: Message-passing revisited | An analysis of convex relaxations for map estimation of discrete mrfs | Map estimation for graphical models by likelihood maximization | Maximum likelihood from incomplete data via the em algorithm | Constraint Processing | New finite pivoting rules for the simplex method | Finite Mathematics: An Applied Approach (Eighth Edition) | Randomized rounding: a technique for provably good algorithms and algorithmic proofs | Convex relaxation methods for graphical models: Lagrangian and maximum entropy approaches | CRFmatching: Conditional random fields for feature-based scan matching",rejected,000
1202.3768.pdf.json,The Structure of Signals: Causal Interdependence Models for Games of Incomplete Information,"In a game of incomplete information, we commonly distinguish the information available to respective agents in terms of their epistemic types (henceforth just types). Agents are assumed to know their own private types, and have probabilistic beliefs about other-agent types. When other-agent types are strategically relevant, our analyses generally consider what agents can infer about others from their own types, a possibility that arises only when types are interdependent. Such interdependencies typically derive from the way that the respective agents’ information relates to some underlying state of the world, in which case we may refer to an agent’s type as a signal about that state. The treatment of signals is a central element of theoretical analysis for many classes of multiagent interactions. In particular, signals play a pivotal role in formal models of auctions, voting, and many other social mechanisms. Canonical theoretical results about these problems take the form of relating properties of the signal distributions to solutions (e.g., equilibria) of the Bayesian games induced. For example, celebrated theorems in the auction literature establish revenue comparisons (ascending open outcry greater than second-price sealed bid greater than first-price sealed bid) under the assumption that signals are affiliated (a form of monotone relation) [Milgrom and Weber, 1982]. Recent work by Hong and Page [2009] has shown that the implications of signals on interacting agents varies qualitatively depending on whether they are viewed as caused by payoff-relevant elements of the underlying state (generated) or as causal factors from a predictive model of the observer (interpreted). Although both represent common patterns of uncertain information, literature to date has tended to emphasize the generated view. We develop a graphical model framework for representing the structure of signals in games of incomplete information. We show that this representation can capture the ke","Single crossing properties and the existence of pure strategy equilibria in games of incomplete information | Gaming prediction markets: Equilibrium strategies with a market | Efficient reasoning in qualitative probabilistic networks | Networks of influence diagrams: A formalism for representing agents’ beliefs and decisionmaking processes | Combinatorial information market design | Games of incomplete information played by Bayesian players | Interpreted and generated signals | Probabilistic Graphical Models: Principles and Techniques | Multi-agent influence diagrams for representing and solving games | Incremental tradeoff resolution in qualitative probabilistic networks | Bayesian network modelling through qualitative patterns | Putting Auction Theory to Work | Good news and bad news: Representation theorems and applications | A theory of auctions and competitive bidding | Qualitative Methods for Reasoning under Uncertainty | Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference | Causality: Models, Reasoning, and Inference | Enhancing QPNs for tradeoff resolution | Context-specific sign-propagation in qualitative probabilistic networks | Properties of monotonic effects on directed acyclic graphs | Counterspeculation, auctions, and competitive sealed tenders | Fundamental concepts of qualitative probabilistic networks | Explaining “explaining away",rejected,000
1202.3773.pdf.json,Measuring the Hardness of Stochastic Sampling on Bayesian Networks with Deterministic Causalities: the k-Test,"A Bayesian network, belief network, or directed acyclic graphical model, is a probabilistic graph model [28] that has gained wide acceptance in several areas of artificial intelligence [31]. A Bayesian network represents a joint probability distribution (JPD) over a set of statistical variables and structurally models the (conditional) independence relationships between the variables as a directed acyclic graph (DAG). Efficient algorithms exist that perform probabilistic inference on Bayesian networks for reasoning with uncertainty and to solve decision problems with uncertain data. Exact and approximate probabilistic Bayesian inference is known to be NP-hard [11, 12]. No single Bayesian inference algorithm or a class of algorithms is known to generally outperform others. Approximate inference algorithms are popular due to their anytime property [17] to produce an approximate result, possibly in real time [23]. For this reason, stochastic sampling algorithms, especially importance sampling, are among the most widely-used approximate inference methods [31]. Examples are SIS [32], AIS-BN [7], DIS [27], RIS [34] and EPIS-BN [35]. Importance sampling algorithms mainly differ in the choice of importance function to sample the JPD. All sampling algorithms perform poorly on Bayesian networks that are known to be hard for approximate inference. When zero probabilities are permitted in the JPDs, sampling algorithms become inefficient due to sample rejection; samples with zero probability do not contribute to the sum estimate and are therefore effectively rejected. Consequently, the sampling algorithm’s performance is poor on Bayesian networks with deterministic causalities, i.e. networks that model JPDs with zero probabilities. The local variance bound (LVB) [13] metric demarcates the boundary between the class of Bayesian networks with tractable approximations and those with intractable approximations. In certain cases the LVB of a Bayesian network can be used as a quantita","Random k-SAT: Two moments suffice to cross a sharp threshold | Two theorems on random polynomial time | MUNIN — an expert EMG assistant | Computational Complexity: A Modern Approach | Evaluation of Probabilistic Inference System, 2006. http://ssli.ee.washington.edu/~bilmes/ uai06InferenceEvaluation | Probabilistic analysis of a generalization of the unit clause literal selection heuristic for the k-satisfiability problem | AIS-BN: An adaptive importance sampling algorithm for evidential reasoning in large Bayesian networks | Mick gets some (the odds are on his side) (satisfiability) | A better algorithm for random k-SAT | On-line student modeling for coached problem solving using Bayesian networks | The computational complexity of probabilistic inference using Bayesian belief networks | Approximating probabilistic inference in Bayesian belief networks is NP-hard | An optimal approximation algorithm for Bayesian inference | Mixtures of deterministic-probabilistic networks and their and/or search space | Probabilistic analysis of the Davis Putnam procedure for solving the satisfiability problem | Necessary and sufficient conditions for sharp thresholds of graph properties and k- SAT problem | A survey of research in deliberative real-time artificial intelligence | The log-support encoding of CSP into SAT | Approximate inference algorithms for hybrid Bayesian networks with discrete constraints | A new algorithm for sampling CSP solutions uniformly at random | Approximate counting by sampling the backtrack-free search space | SampleSearch: Importance sampling in presence of determinism | A survey on algorithms for real-time Bayesian network inference. In In the joint AAAI-02/KDD-02/UAI-02 workshop on Real-Time Decision Support and Diagnosis | Toward normative expert systems: Part I the pathfinder project | Turing machines that take advice | Mixed deterministic and probabilistic networks | Dynamic importance sampling in Bayesian networks based on probability trees | Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference | Knowledge engineering for large belief networks | Simulation and Monte Carlo Method | Artificial intelligence: A modern approach | Simulation approaches to general probabilistic inference on belief networks | Halting space-bounded computations | Refractor importance sampling | An importance sampling algorithm based on evidence prepropagation | Theoretical analysis and practical insights on importance sampling in Bayesian networks",rejected,000
1202.3777.pdf.json,Belief Propagation by Message Passing in Junction Trees: Computing Each Message Faster Using GPU Parallelization,"Bayesian networks (BNs) are an effective tool in a diverse range of applications that require representation and reasoning with uncertain knowledge and data. Inference over BNs can be either exact or approximate. Perhaps the most popular exact inference algorithm, belief propagation in junction trees, relies on the compilation of a BN into a junction tree. Exact belief updating (or marginalization) is then performed by message passing over the junction tree [6]. Each node of a ∗Email:lu.zheng, ole.mengsheol@sv.cmu.edu †Email:jike@berkeley.edu junction tree is a clique computed from the moralized graph based on the original BN. However, belief propagation over junction trees is known to be computationally hard. Computational difficulty increases dramatically with the density of the BN, the treewidth of the network, and the number of states of each network node [9]. In addition, some practical issues associated with the specific implementation platform also affect the computation performance [1]. In our work, we address the computational problem of belief propagation on both the analytical and implementation levels. Two fundamental issues, which may cause large cliques in junction trees, are: (i) the topology and connectedness of a BN [9] and (ii) the high cardinality of a significant set of discrete BN nodes [13]. Discrete BN nodes can have high cardinalities for several reasons: First, they may represent discrete parameters, for example categorical parameters, that inherently take a large number of values [13]. A second reason for highcardinality, discrete BN nodes is that they are used to represent continuous parameters. The number of states grows exponentially with the number of bits used when representing a quantized continuous parameter. Consequently, if a fine-grained discretization is used in BN nodes, the difficulty of computation may become a major challenge. The above issues may cause very large cliques to be formed in junction trees, and thus hinder the ap",Inference in belief networks: A procedural guide | Parallel exact inference on a CPU-GPGPU heterogenous system | BEEM: bucket elimination with external memory | A parallel Lauritzen-Spiegelhalter algorithm for probabilistic inference | The EM algorithm for graphical association models with missing data | Local computations with probabilities on graphical structures and their application to expert systems | Highthroughput Bayesian network learning using heterogeneous multicore computers | GraphLab: A new framework for parallel machine learning | Understanding the scalability of Bayesian network inference using clique tree growth curves | Scalable parallel implementation of exact inference in Bayesian networks | Efficient inference in large discrete domains | Efficient computation of sumproducts on GPUs through software-managed cache | Node level primitives for parallel exact inference,rejected,000
1202.3887.pdf.json,Extended Mixture of MLP Experts by Hybrid of Conjugate Gradient Method and Modified Cuckoo Search,"Combining classifier is one of the most popular approaches in pattern recognition, which leads to have a better classification. It increases the recognition rate and improves the reliability of the system. It is usually a good approach in complicated problems due to the small sample size, class overlapping, dimensionality, and substantial noise in the input samples. Previous experimental and theoretic results show that the combining classifiers with each other lead to higher performance when the base classifiers have small error rates, and their errors are different [1]; in other words, the base classifiers make uncorrelated decision in this case. Generally, classifier selection and classifier fusion are two types of combining classifiers [2]. One of the most popular methods of classifier selection is ME, originally proposed by Jacobs et al. [3]. The ME models the conditional probability density of the target output by mixing the outputs from a set of local experts, each of which separately derives a conditional probability density of the target output. The outputs of expert networks are combined by a gating network which is trained to select the expert(s) that is performing the best at solving the problem [4, 5, and 6]. In the basic form of ME [3], the expert and gating networks are linear classifiers, however, for more complex classification tasks, the expert and gating networks could be of more complicated types. For instance, Ebrahimpour et al. [7] proposes a face detection model, in which they used MultiLayer Perceptrons (MLPs) [8, 9, 10] to form the gating and expert networks in order to improve the face detection accuracy. The Back Propagation (BP) algorithm is the most commonly used technique for training neural networks. It is an approximation of the Least Mean Square (LMS) algorithm, which is based on the steepest descent method. While the BP technique follows a straightforward and wellestablished algorithm, there are some disadvantages associated with it.","and R | Combination of multiple classifiers using local accuracy estimates | Adaptive mixture of experts | A modified mixture of experts network structure for ECG beats classification with diverse features | A mixture of experts network structure construction algorithm for modelling and control | Improved learning algorithms for mixture of experts in multiclass classification | Face detection using mixture of MLP | Neural Networks- A Comprehensive Foundation | Learning internal representations by error backpropagation | Neural Networks for Pattern Recognition | Understanding Neural Networks and Fuzzy Logic | Modified cuckoo search: A new gradient free optimisation algorithm. Chaos, Solitons& Fractals.Volume | Cuckoo search via L vy flights | Hierarchies of adaptive experts”, In Proceedings of the advances in neural information processing systems | Hierarchical mixtures of experts and the EM algorithm | Convergence results for the EM approach to mixtures of experts architectures | Statistical mechanics of the mixture of experts | Bayesian methods for mixture of experts | Mixtures of experts estimate a posteriori probabilities. | Organization of face and object recognition in modular neural networks | An introduction to genetic algorithms.sixth ed | Defining a standard for particle swarm optimization | Differential evolution – a simple and efficient heuristic for global optimization over continuous spaces | Engineering optimisation by cuckoo search. International Journal of Mathematical Modelling and Numerical Optimisation 2010;1:330–43 | Cuckoo search via L ́evy flights | ́evy flights and superdiffusion in the context of biological encounters and random searches | A particle swarm optimization approach for hexahedral mesh smoothing. International Journal for Numerical Methods in Fluids 2009;60:5578 | Newman,”UCI Machine Learning Repository”,[http://www.ics.uci.edu/~mlearn/MLRepository.html | Handbook of pattern recognition and computer vision.3rd ed",rejected,000
1202.4828.pdf.json,Towards an Intelligent Tutor for Mathematical Proofs,"Computer-supported learning is an increasingly important form of study since it allows for independent learning and individualized instruction and has resulted in many tutoring systems for different domains. Mathematics is a key discipline in education and today, there exist strong systems to teach and tutor specific mathematical skills, such as mathematical computations, problem solving and geometry (see for instance, [49, 41, 46, 36, 14, 53, 33, 19] to name a few). However, teaching and tutoring support on the ability of how to do proofs is underdeveloped in state of the art e-learning systems. Notable exceptions are the tutoring systems for geometrical proofs [45, 42, 67], as well as for pure formal logic proofs (such as the CMU proof tutor [61], the NovaNet Proof Tutorial [13] or Proofweb [39]). The overall goal of the work presented in this paper is to provide e-learning support for classical textbook-style proofs, which is not fostered by the above approaches. Following Van Lehn (see [69]), intelligent tutoring systems (ITSs) can be characterized as having both an outer loop and an inner loop. The outer loop selects a relevant task (exercise) for the student to complete. The inner loop iterates over individual problem-solving steps, evaluates the steps and provides feedback to the student. Typically, this is achieved by providing the following services: (S1) minimal feedback on a step, (S2) error specific feedback on an incorrect step, (S3) hints on the next step, (S4) assessment of knowledge, and (S5) review of the solution. In this paper we focus on the inner loop and report on how we adapted the proof assistant system Ωmega to realize the services (S1), (S2), (S3) and a bit of (S5). The services are provided by two components, one for step analysis, and one for step generation. The step analyzer produces minimal feedback on a student’s proof step, such as whether the step is correct or not, together with additional information that might be used to provide ","Human-Readable Machine-Verifiable Proofs for Teaching Constructive Logic | Limitations of Student Control: Do Students Know when They Need Help | Transforming matings into natural deduction proofs | Teaching Case-Based Argumentation Concepts using Dialectic Arguments vs. Didactic Explanations | Tactics for Hierarchical Proofs | A Generic Modular Data Structure for Proof Attempts Alternating on Ideas and Granularity | A Tactic Language for Declarative Proofs | Textbook Proofs Meet Formal Logic - The Problem of Underspecification and Granularity | Structured derivations: a unified proof style for teaching mathematics | Toward Automatic Hint Generation for Logic Proof Tutoring Using Historical Student Data | Automatic Hint Generation for Logic Proof Tutoring Using Historical Data | Mathpert: Computer Support for Learning Algebra, Trig, and Calculus. In Andrei Voronkov, editor:  LPAR, Lecture Notes in Computer Science 624 | Deep Inference for Automated Proof Tutoring | A corpus of tutorial dialogs on theorem proving; the influence of the presentation of the study-material | DiaWOz-II - A tool for wizard-of-oz experiments in mathematics | Student Proof Exercises Using MathsTiles and Isabelle/HOL in an Intelligent Book | Repair theory: A generative theory of bugs in procedural skills | PDS – A Three-Dimensional Data Structure for Proof Plans | Cognitive Computer Tutors: Solving the Two-Sigma Problem | A Declarative Language for the Coq Proof Assistant | Hiproofs: A Hierarchical Notion of Proof Tree | On the Comparison of Proof Planning Systems: lambdaCLAM, OMEGA and IsaPlanner | Assertion Level Proof Planning with Compiled Strategies | Verification of Human-level Proof Steps in Mathematics Education | Integrating Structured Queries into a Tactic Language. JAL - Special issue on Programming Languages and Mechanized Mathematics Systems Available at http://dx. doi.org/10.1007/s10817-009-9138-5 | Recording HOL Proofs in a Structured Browsable Format. In Michael Johnson, editor:  Algebraic Methodology and Software Technology, 6th International Conference, AMAST ’97, Sydney, Australia | Web-Based Evaluations Showing Differential Learning for Tutorial Strategies Employed by the Ms | Reconstructing Proofs at the Assertion Level | Human Oriented Proof Presentation: A Reconstructive Approach | Teaching logic using a state-of-the-art proof assistant | An iterative design methodology for user-friendly natural language office information applications | Exploring the Assistance Dilemma in Experiments with Cognitive Tutors | Reifying implicit planning in geometry: Guidelines for model-based intelligent tutoring system design | How to write a proof | Artificial Intelligence in Education - Supporting Learning through Intelligent and Socially Informed Technology | Advanced Geometry Tutor: An intelligent tutor that teaches proofwriting with construction | When and how often should worked examples be given to students? New results and a summary of the current state of research | Effective Tutoring Techniques: A Comparison of Human Tutors and Intelligent Tutoring Systems | Expansion Tree Proofs and Their Conversion to Natural Deduction Proofs | Human Problem Solving | The Aplusix-Editor: A New Kind of Software for the Learning of Algebra | Learning from performance errors | The New Book of Prime Number Records | Formalizing a Hierarchical Structure of Practical Mathematical Reasoning | A comparative evaluation of socratic versus didactic tutoring | Granularity Analysis for Tutoring Mathematical Proofs | The AProS Project: Strategic Thinking & Computational Logic | Computer Environments for Proof Construction | How to read and do proofs | A Proof Environment for Teaching Mathematics | KERMIT: A Constraint-Based Tutor for Database Modeling | Three Tactic Theorem Proving | DECLARE: a prototype declarative proof system for higher order logic | Automatic analysis of proof in a computer-based environment | MENON - Automating a Socratic Teaching Model for Mathematical Proofs | The Behavior of Tutoring Systems. I | The Relative Effectiveness of Human Tutoring, Intelligent Tutoring Systems, and Other Tutoring Systems | Isar - A Generic Interpretative Approach to Readable Formal Proof Documents | Formal Proof Sketches | Linguistic Processing in a Mathematics Tutoring System: Cooperative Input Interpretation and Dialogue Modelling | Building intelligent interactive tutors: Student-centered strategies for revolutionizing e-learning",rejected,000
1202.4835.pdf.json,Isabelle/PIDE as Platform for Educational Tools,"“Isabelle’s user interface is no advance over LCF’s, which is widely condemned as ‘user-unfriendly’: hard to use, bewildering to beginners. Hence the interest in proof editors, where a proof can be constructed and modified rule-by-rule using windows, mouse, and menus. But Edinburgh LCF was invented because real proofs require millions of inferences. Sophisticated tools – rules, tactics and tacticals, the language ML, the logics themselves – are hard to learn, yet they are essential. We may demand a mouse, but we need better education and training.” (L.C. Paulson, in “Isabelle: The Next 700 Theorem Provers”, 1990)","User Interaction with the Matita Proof Assistant | Proof General: A Generic Tool for Proof Development | A Framework for Interactive Proof | A generic approach to building user interfaces for theorem provers | Context aware Calculation and Deduction — Ring Equalities via Gröbner Bases in Isabelle | Constructive Type Classes in Isabelle | Local theory specifications in Isabelle/Isar | Event-Based Programming without Inversion of Control | Teaching logic using a state-of-the-art proof assistant | Web interfaces for proof assistants | Efficient Parallel Programming in Poly/ML and Isabelle/ML | An Overview of the Scala Programming Language | Isabelle: The Next 700 Theorem Provers | A combination of a dynamic geometry software with a proof assistant for interactive formal proofs | A Wiki for Mizar: Motivation, Considerations, and Initial Prototype | PLATΩ: A Mediator between Text-Editors and Proof Assistance Systems | Isabelle as Document-oriented Proof Assistant | The Isabelle Framework. In: Theorem Proving in Higher Order Logics (TPHOLs | Parallel Proof Checking in Isabelle/Isar | Asynchronous Proof Processing with Isabelle/Scala and Isabelle/jEdit | SML with antiquotations embedded into Isabelle/Isar | Isar — a Generic Interpretative Approach to Readable Formal Proof Documents",rejected,000
1202.4905.pdf.json,A BI-DIRECTIONAL REFINEMENT ALGORITHM FOR THE CALCULUS OF (CO)INDUCTIVE CONSTRUCTIONS,"In this paper we are interested in describing one of the key ingredients in the implementation of Interactive Theorem Provers (ITP) based on type theory. The architecture of these tools is usually organized in layers and follows the so called de Bruijn principle: the correctness of the whole system solely depends on the innermost component called kernel. Nevertheless, from a user perspective, the most interesting layers are the external ones, the ones he directly interacts with. Among these, the refiner is the one in charge of giving a meaning to the terms and types he writes. The smarter the refiner is, the more freedom the user has in omitting pieces of information that can be reconstructed. The refiner is also the component generating the majority of error messages the user has to understand and react to in order to finish his proof or definition. This paper is devoted to the description of a refinement algorithm for the Calculus of (Co)Inductive Constructions, the type theory on which the Matita [6], Coq [12] and Lego [19] ITPs are based on. 1.1. Refinement. In this and in the previous paper [4] we are interested in the implementation of interactive theorem provers (ITP) for dependently typed languages that are heavily based on the Curry-Howard isomorphism. Proofs are represented using lambdaterms. Proofs in progress are represented using lambda-terms containing metavariables that are implicitly existentially quantified. Progression in the proof is represented by instantiation of metavariables with terms. Metavariables are also useful to represent missing or partial information, like untyped lambda-abstractions or instantiation of polymorphic functions to omitted type arguments. Agda [8] and Matita [6] are examples of systems implemented in this way. Arnaud Spiwack in his Ph.D. thesis [31] partially describes a forthcoming release of Coq 8.4 that will be implemented on the same principles. The software architecture of these systems is usually built in layers. Th","A page in number theory | About the formalization of some results by Chebyshev in number theory | Formal metatheory of programming languages in the Matita interactive theorem prover | A compact kernel for the Calculus of Inductive Constructions. Sadhana | Hints in unification | User interaction with the Matita proof assistant | Lambda Calculi with Types | A brief overview of Agda - a functional language with dependent types | Coherence checking of coercions in Plastic | Subtyping, Type Conversion and Transitivity Elimination | Formalizing Overlap Algebras in Matita | The Calculus of Constructions | Greedy bidirectional polymorphism | Tridirectional typechecking | Packaging mathematical structures | A unification algorithm for typed lambda-calculus | Coercive subtyping | A Calculus of Substitutions for Incomplete-Proof Representation in Type Theory | Towards a practical programming language based on dependent type theory | Définitions Inductives en Théorie des Types d’Ordre Supérieur | Local type inference | Dependently typed records in type theory | Mathematical Knowledge Management and Interactive Theorem Proving | Spurious disambiguation errors and how to get rid of them | Typing algorithm in type theory with inheritance | Subset coercions in Coq. In Types for Proofs and Programs, volume 4502/2007 of LNCS, pages 237–252 | First-class type classes | Verified Computing in Homological Algebra. A Journey Esploring the Power and Limits of Dependent Type Theory | Construction and Deduction in Type Theories | Type processing by constraint reasoning | Interactive Theorem Provers: issues faced as a user and tackled as a developer | Une Théorie des Constructions Inductives",rejected,000
1202.5284.pdf.json,Elitism Levels Traverse Mechanism For The Derivation of Upper Bounds on Unimodal Functions,,,rejected,000
1202.6009.pdf.json,,"Statistical disclosure control (SDC, [1, 4, 8, 3, 5]), a.k.a. data anonymization and sometimes as privacy-preserving data mining, aims at making possible the ∗This work was partly supported by the Government of Catalonia under grant 2009 SGR 1135, by the Spanish Government through projects TSI2007-65406-C03-01 “E-AEGIS” and CONSOLIDER INGENIO 2010 CSD2007-00004 “ARES”, and by the European Comission under FP7 project “DwB”. The author is partially supported as an ICREA Acadèmia researcher by the Government of Catalonia. publication of statistical data in such a way that the individual responses of specific users cannot be inferred from the published data and background knowledge available to intruders. If the data set being published consists of records corresponding to individuals, usual SDC methods operate by masking original data (via perturbation or detail reduction), by generating synthetic (simulated) data preserving some statistical features of the original data or by producing hybrid data obtained as a combination of original and synthetic data. Whatever the protection method chosen, the resulting data should still preserve enough analytical validity for their publication to be useful to potential users. A microdata set can be defined as a file with a number of records, where each record contains a number of attributes on an individual respondent. Attributes can be classified depending on their range and the operations that can be performed on them: 1. Numerical. An attribute is considered numerical if arithmetical operations can be performed on it. Examples are income and age. When designing methods to protect numerical data, one has the advantage that arithmetical operations are possible, and the drawback that every combination of numerical values in the original data set is likely to be unique, which leads to disclosure if no action is taken. 2. Categorical. An attribute is considered categorical when it takes values over a finite set and standard arithme",A survey of inference control methods for privacypreserving data mining | A measure of nominal variance for hierarchical nominal attributes | Salazar-González. Statistical Confidentiality: Principles and Practice | Handbook on Statistical Disclosure Control (version 1.2) | Methoden der Geheimhaltung wirtschaftsstatistischer Einzeldaten und ihre Schutzwirkung | Centrality measures in trees | Protecting respondents’ identities in microdata release | DeWaal. Elements of Statistical Disclosure Control,rejected,000
1202.6153.pdf.json,,,"Dynamic Programming | Statistical Decision Theory and Bayesian Analysis | The case for objective Bayesian analysis | Dynamic Programming and Optimal Control, volume I and II | Pattern Recognition and Machine Learning | The Conscious Mind | Philosophy of Mind: Classical and Contemporary Readings | Language and Mind | Clustering by compression | The infinite partially observable markov decision process | Bayes or Bust? A Critical Examination of Bayesian Confirmation Theory | Mesurer l’intelligence d’une machine | Universal reinforcement learning | Foundations of Computational Linguistics: Human-Computer Communication in Natural Language | On the computational measurement of intelligence factors | Measuring universal intelligence: Towards an anytime intelligence test | A formal definition of intelligence based on an intensional variant of kolmogorov complexity | The fastest and shortest algorithm for all well-defined problems | Self-optimizing and Pareto-optimal policies in general environments based on Bayes-mixtures | Universal Artificial Intelligence: Sequential Decisions based on Algorithmic Probability | Human knowledge compression prize | On universal prediction and Bayesian confirmation | Feature dynamic Bayesian networks | Feature reinforcement learning: Part I: Unstructured MDPs | Open problems in universal induction & intelligence | Universal learning theory | Can intelligence explode | Probability Theory: The Logic of Science | An Introduction to Biological Evolution | Three approaches to the quantitative definition of information | Bandit based Monte-Carlo planning | The Singularity Is Near | Machine Super Intelligence | Universal sequential search problems | A collection of definitions of intelligence. In Advances in Artificial General Intelligence: Concepts, Architectures and Algorithms, volume | Universal intelligence: A definition of machine intelligence | Asymptotically optimal agents | An Introduction to Kolmogorov Complexity and its Applications | An approximation of the universal intelligence measure | Reinforcement Learning with Selective Perception and Hidden State | Predictably Rational? In Search of Defenses for Rational Behavior in Economics | Feature reinforcement learning in practice | Self-modification and mortality in artificial agents | Optimality issues of universal greedy agents with static priors | A computational approximation to the AIXI model | Introducing Anthropology: An Integrated Approach | Shadows of the Mind, A Search for the Missing Science of Consciousness | Universal learning of repeated matrix games | A philosophical treatise of universal induction | Artificial Intelligence. A Modern Approach | Delusion, survival, and intelligent agents | Reinforcement Learning: An Introduction | Practical solution techniques for first-order MDPs | The speed prior: A new simplicity measure yielding near-optimal computable predictions | Optimal ordered problem solver | Simple algorithmic principles of discovery, subjective beauty, selective attention, curiosity & creativity | Efficient structure learning in factored-state MDPs | Mind: A Brief Introduction | Consistency of feature Markov processes | Axioms for rational reinforcement learning | Principles of Solomonoff induction and AIXI | A Bayesian approach to model learning in nonMarkovian environments | About Behaviorism | Multiagent Systems: Algorithmic, Game-Theoretic, and Logical Foundations | Learning predictive state representations | MacLin. Cognitive Psychology | A formal theory of inductive inference: Parts 1 and 2 | Complexity-based induction systems: Comparisons and convergence theorems | Soft Computing: Integrating Evolutionary | Computing machinery and intelligence | Logics for Artificial Intelligence | A Monte Carlo AIXI approximation | Reinforcement learning via AIXI approximation | Statistical and Inductive Inference by Minimum Message Length | Theoretical Foundations of Artificial General Intelligence | Non-)equivalence of universal priors | The context tree weighting method: Basic properties",rejected,000
1202.6386.pdf.json,Relational Reinforcement Learning in Infinite Mario,,"Extending the Soar Cognitive Architecture | Soar-RL, integrating reinforcement | Towards Real-time GOMS | Online Q-Learning Using",rejected,000
1202.6609.pdf.json,TOWARDS AN INTEGRATED VISUALIZATION OF SEMANTICALLY ENRICHED 3D CITY MODELS: AN ONTOLOGY OF 3D VISUALIZATION TECHNIQUES,"Since the 1960s, the term urban model has been usually related to simplifications and abstractions of real cities, in contrast to its earlier usage referring to ideal cities (Foot, 1981). Today, accurate models can be used to perform, for example, urban simulations (Waddell et al, 2008), building energy consumption (Jones et al, 2000), water quality calculation (Kianirad et al, 2006) or air quality estimation (Moussiopoulos et al 2006). Urban models are widely used by urban planners and designers to explore the city or to plan it prior to acting on it. By this way, urban models can be seen as decision-making tools. 3D city models are specific urban models related to the field of Geographic Information Systems (GIS). 3D city models represent geo-referenced data in three dimensions and under a common view, the virtual city. CityGML (OGC 2008) is the first standard related to 3D city models. CityGML attempts to provide a description of 3D elements like relief, buildings, traffic infrastructure, water bodies, vegetation or city furnitures with their geometry, topology (spatial properties), semantic properties and relevant attributes. The attributes cover classification, function and actual usage of an object. Those objects have been identified to be either required or important in many different application areas. CityGML is also extendable to adapt to the requirements of specific applications. Such extensions have been defined for different issues such as noise, with noise immissions added to buildings, roads or railways (OGC 2008), and for different purposes such as flood information service (Schulte & Coors 2008). We thus obtain enriched 3D city models containing more than mere geometrical elements. In the case described by Schulte and Coors, the basic water model of CityGML has been extended with hydro-numerical data sets, as preliminary step of integration in a Web 3D Service for dynamic 3D flood visualization in interactive 3D scenes. If visualization is effective","Abstract Information Visualization in Interactive 3D Virtual Environments: Conceptualization and Usability Evaluation | A Taxonomy of Visualization Techniques Using the Data State Reference Model | Operational Urban Models: An Introduction | Planning for a sustainable city: an energy and environmental prediction model | Review of Watershed Ecological Models | Automating the design of graphical presentations of relational information | An Enhanced Visualization Ontology for a Better Representation of the Visualization Process. In: ICT Innovation 2010, Communications in Computer and Information | Ambient air quality, pollutant dispersion and transport models. Report of the European Topic Centre on Air Quality, prepared under the supervision of G | 3D Visualization of Air Quality Data. In: Reliability and Statistics in Transportation and Communication Conference (RelStat`11) | Development of a CityGML ADE for dynamic 3D flood information | The eyes have it: A task by data type taxonomy for information visualization | Bringing semantics to visualization services | Référentiels Spatiaux des Tâches d’Interaction et Caractéristiques de l’Utilisateur influençant la Performance en Réalité Virtuelle | Enhancing the visibility of labels in 3D navigation maps | Context-aware recommendation of visualization components | Towards a Unifying Visualization Ontology | UrbanSim: An Evolving Planning Support System for Evolving Communities. In: Planning Support Systems for Cities and Regions, Richard Brail (Ed.), Cambridge, MA: Lincoln Institute for Land Policy",rejected,000
1203.0088.pdf.json,The Mind Grows Circuits,"Understanding mental phenomena has been an age old subject in various disciplines ranging from philosophy [1, 2], psychology [14], ethology [3] cognitive sciences [19] and linguistics [18]. It is also the subject matter of modern fields such as neuroscience [15] and artificial intelligence [13, 9]. Some of the early studies in psychology and philosophy approach the question looking at mental phenomena subjectively in terms of experiences and percepts. Others such as neurobiology or AI approach it from the other end in viewing the mind as a neural network [12] where each neuron is a primitive binary circuit. Simplicity theory [4, 5] (and other older works [11]) emphasizes the principle of ‘simplicity’ in cognition – using the notion of Kolmogorov Complexity [8], it demonstrates that several cognitive functions can be understood as giving simple descriptions of a certain sensory stimulus. In this paper, we also model the mind as a place where a circuit grows, starting as a collection of primitive components at birth and then grows incrementally bottom up. A new node is formed by a simple composition of prior nodes when we undergo a repeated experience that can be described by that composition. Unlike neural networks, however, these circuits take “concepts” or “percepts” as inputs and outputs. Thus the growing circuits can be likened to a growing collection of lambda expressions [16] that are built on top of one another.","The search for simplicity: A fundamental cognitive principle | Simplicity: a unifying principle in cognitive science | Soar: An Architecture for General Intelligence | The Analysis of Sensations and the Relation of the Physical to the Psychical | The Handbook of Brain Theory and Neural Networks | The Society of Mind | Neuroscience: Exploring the Brain (3rd ed.) | The Lambda Calculus: Its Syntax and Semantics, Studies in Logic and the Foundations of Mathematics, 103 (Revised ed.) | Learning RFT: An Introduction to Relational Frame Theory and Its Clinical Applications",rejected,000
1203.0220.pdf.json,,,"SCC-Recursiveness: A General Schema for Argumentation Semantics | cf2 Semantics Revisited | The handling of loops in Talmudic Logic, with application to odd and even loops in argumentation, Expanded Version | An Equational Approach to Argumentation Networks, Feb 2011, 104 pp, to appear in Argumentation and Computation | Logics for defeasible argumentation | Solving semantic problems with odd-length cycles in argumentation | The cf2 Argumentation Semantics Revisited | Fibring Argumentation Frames",rejected,000
1203.0876.pdf.json,An MLP based Approach for Recognition of Handwritten ‘Bangla’ Numerals,"Optical Character Recognition (OCR) systems appear to ease the interface between man and machine and help in office automation with huge saving of time and human effort. The OCR system allows desired manipulation of the scanned text as the output is coded with ASCII or some other character code of such system prepared from the paper based input text. Success of the commercially available OCR system is yet to be extended to handwritten text. It is mainly due to the fact that numerous variations in writing styles of individuals make recognition of handwritten characters difficult. For a specific language based on some alphabet and numerals, OCR techniques are either aimed at printed text or handwritten text. The present work is aimed at the latter. Proc. 2nd Indian International Conference on Artificial Intelligence, pp. 407-417, Dec. 2005, Pune. Broadly speaking, OCR systems ease the barrier of the keyboard interface between man and machine to a great extent, and help in office automation with huge saving of time and human effort. The systems have potential applications in extracting data from filled in forms, interpreting handwritten addresses from postal documents for automatic routing, automatic reading of bank cheques etc. Past work on OCR of handwritten alphabet and numerals has been mostly found to concentrate on Roman script [1] related to English and some European languages, and scripts related to Asian languages like Chinese [2], Korean, and Japanese. Among Indian scripts, Devnagri, Tamil, Oriya and Bangla have started to receive attention for OCR related research in the recent years. Majority of the past work e.g. [1], [6], [7], [8], related to offline handwritten character recognition, concentrated on the analysis of English scripts. One of the most notable early work on handwritten English cursive word recognition is that of Bozinovic and Srihari [1], in which a word image is transformed through a hierarchy of representation levels: points, contours, feat",Off-line Cursive Script Word Recognition | Off-line Handwritten Chinese Character Recognition as a Compound Bays Decision Problem,rejected,000
1203.0882.pdf.json,HANDWRITTEN ‘BANGLA’ ALPHABET RECOGNITION USING AN MLP BASED CLASSIFIER,"Optical Character Recognition (OCR) is still an active area of research, especially for handwritten text. Success of the commercially available OCR system is yet to be extended to handwritten text. It is mainly due to the fact that numerous variations in writing styles of individuals make recognition of handwritten characters difficult. Past work on OCR of handwritten alphabet and numerals has been mostly found to concentrate on Roman script [3], related to English and some European languages, and scripts related to Asian languages like Chinese [2], Korean, and Japanese. Among Indian scripts, Devnagri, Tamil, Oriya and Bangla have started to receive attention for OCR related research in the recent years. Out of these, Bangla is the second most popular script and language in the Indian subcontinent. As a script, it is used for Bangla, Ahamia and Manipuri languages. Bangla, which is also the national language of Bangladesh, is the fifth most popular language in the world. So is the importance of Bangla both as a script and as a language. But evidences of research on OCR of handwritten Bangla characters, as observed in the literature, are a few in numbers. Two of the important research contributions relating to OCR of Bangla characters involve a multistage approach developed by Rahman et al. [1] and an MLP classifier developed by Bhowmik et al. [4]. The major features used for the multistage approach include Matra, upper part of the character, disjoint section of the character, vertical line and double vertical line. And, for the MLP classifier, the feature set is constructed from the stroke feature of characters. The data set used for testing recognition performances of the multistage approach was not of considerable size as it included characters of 49 different classes collected from only 20 different writers. Compared to this, a moderately large size data set of 25,000 samples, collected from different sections of population, is used for testing performances of the",Recognition of Handwritten Bengali Characters: a Novel Multistage Approach | Off-line Handwritten Chinese Character Recognition as a Compound Bays Decision Problem | On-line and Off-line Handwriting Recognition: a Comprehensive Survey | Recognition of Bangla Handwritten Characters Using an MLP Classifier Based on Stroke Features,rejected,000
1203.1007.pdf.json,Agnostic System Identification for Model-Based Reinforcement Learning,"Model-based reinforcement learning (MBRL) and much of control rely on system identification: building a model of a system from observations that is useful for controller synthesis. While often treated as a typical statistical learning problem, system identification presents different fundamental challenges as the executed controller and data generating process are inextricably intertwined. Naively attempting to estimate a controlled system can lead to a model that makes small error on a training set, but exhibits poor controller performance. This problem arises as the policy resulting from controller synthesis is often very different from the “exploration” policy used to collect data. While we might expect the model to make good predictions at states frequented by the exploration policy, the learned Appearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s). Figure 1. Example train-test mismatch in a helicopter domain. Train: model is fit based on samples near the desired trajectory, e.g. from watching an expert. Test: learned policy ends up in new regions where model is bad, leading to poor control performance. policy usually induces a different state distribution, where the model may poorly capture system behavior (Fig. 1). This problem is fully appreciated in the system identification literature and has been attacked by considering “open loop” identification procedures and “persistent excitation” (Ljung, 1999; Abbeel & Ng, 2005) that attempt to sufficiently “cover” the state-action space. Unfortunately, such methods rely on the strong assumption that the true system lies in the class of models considered: e.g., for continuous systems, they may require the true system to be modeled in a class of linear models. With this assumption, they ensure that eventually the correct model is learned– e.g., by learning about every discrete state-action pair or all modes of the line",Exploration and apprenticeship learning in reinforcement learning | Robot learning from demonstration | Policy search by dynamic programming | Error limiting reductions between classification tasks | On the generalization ability of on-line learning algorithms | Logarithmic regret algorithms for online convex optimization | Approximately optimal approximate reinforcement learning | Mind the duality gap: Logarithmic regret algorithms for online optimization | Iterative linear quadratic regulator design for nonlinear biological movement systems | System Identification: Theory for the User | Helicopter learning nose-in funnel | A reduction of imitation learning and structured prediction to no-regret online learning | Reinforcement learning in finite MDPs: PAC analysis | Finite time bounds for sampling based fitted value iteration | Model-based reinforcement learning with nearly tight exploration complexity bounds | Agnostic kwik learning and efficient approximate reinforcement learning | Simple statistical gradient-following algorithms for connectionist reinforcement learning,rejected,000
1203.1021.pdf.json,"Development of an Ontology to Assist the Modeling of Accident Scenarii ""Application on Railroad Transport ""","egative impact, the terrible cost of accidents, the occurrence of future disasters despite the advances in technology are the basis for the establishment of a process of feedback (Rex) as an essential means to promote the necessary improvement in security. The concept of ""feedback"" on transportation security is defined differently by authors and fields. The part common to all definitions is the interest of learning from an experience to avoid reproduction. The Rex is a dynamic process of collection, storage, analysis and exploitation of data relating to breach security situations (accident or incident). It consists in an analytical study of different causal factors involved in the genesis of incidents or accidents. Rex allows a better understanding of the mechanisms leading to events of insecurity. Its purpose is to benefit from the lessons of past experience to improve the level of security by implementing preventive measures and correctives to prevent accidents and incidents [1]. The methods of acquiring knowledge, applied to the field of security analysis, have shown their interests to extract and formalize the historical knowledge of security analysis (mainly accident scenarii) and its limits in terms of extraction of gait analysis and expert evaluation of safety, especially based on intuition and imagination. Generally, current methods of acquiring knowledge have been developed for well-structured problems. They do not address the specifics of the multi-expertise and coexistence of diverse knowledge and do not allow access to the subjective and intuitive knowledge related to a highly scalable and field unbounded as is that of security and certification of rail transport systems. Indeed, the acquisition of knowledge has encountered the difficulty of extracting expertise raised at each stage of the process of analysis and safety assessment. This difficulty stems from the complexity of the expertise that naturally encourages the experts to give their expertise thr","Contribution of case based reasoning (CBR) in the exploitation of return of experience. “Application to accident scenarii in rail transport | Apprentissage automatique et acquisition des connaissances : deux approches complémentaires pour les systèmes à base de connaissances | Une démarche basée sur l’apprentissage automatique pour l’aide à l’évaluation et à la génération de scenarii d’accidents | System Based Knowledge for the Help in Exploitation of Field Data Feedback in Railroad Transport, EVER'2010, 5th International Conference and Exhibition on Ecological Vehicles and Renewable Energies | Vers Une ontologie pour le domaine de l’analyse de sécurité des systèmes de transport automatisés, Conférence | Sécurité ferroviaire : la fin de l’erreur humaine | Etudes sur la fiabilité humaine dans les métiers de sécurité ferroviaire à la RATP | L’erreur humaine en perspective, Risques erreurs et défaillances : approche interdisciplinaire (Amalberti R | Ingénierie des Connaissances, évolutions récentes et nouveaux défis, Paris : Eyrolles | Acquisition des connaissances d’adaptation et Traitement de l’hétérogénéité dans un système de RàPC basé sur une Ontologie ",rejected,000
1203.1095.pdf.json,,"Search heuristics often make all the difference between effectively solving a combinatorial problem and utter failure. Heuristics make a search algorithm efficient for a variety of reasons, e.g., incorporation of domain knowledge, or randomization to avoid heavy-tailed runtimes. Hence, the ability to swiftly design search heuristics that are tailored towards a problem domain is essential for performance. This article introduces search combinators, a versatile, modular, and efficiently implementable language for expressing search heuristics. 1.1 Status Quo In CP, much attention has been devoted to facilitating the modeling of combinatorial problems. A range of high-level modeling languages, such as Zinc [13], OPL [29] or Comet [27], enable quick development and exploration of problem models. However, we see very little support on the side of formulating accompanying search heuristics. Most languages and systems, e.g. MiniZinc [14], Comet [27], Gecode [23], or ECLiPSe [7] provide a small set of predefined heuristics “off the shelf”. Some systems also support user-defined search based on a general-purpose programming language (e.g., all of the above systems except MiniZinc). The former is clearly too confining, while the latter leaves to be desired in terms of productivity, since implementing a search heuristic quickly becomes a non-negligible effort. This also explains why the set of predefined heuristics is typically small: it takes a lot of time for CP system developers to implement heuristics, too – time they would much rather spend otherwise improving their system. 1.2 Contributions In this article we show how to resolve this stand-off between solver developers and users, by introducing a domain-specific modular search language based on combinators, as well as a modular, extensible implementation architecture. For the user, we provide a modeling language for expressing complex search heuristics based on an (extensible) set of primitive combinators. Even if the use","CP and IP approaches to cancer radiotherapy delivery optimization | Boosting systematic search by weighting constraints | Boosting systematic search by weighting constraints | A denotational semantics of inheritance | A core calculus for Scala type checking | Autonomous Search | Limited discrepancy search | Aspect-oriented programming | Depth-first iterative-deepening: an optimal admissible tree search | SALSA: A language for search algorithms | The design of the Zinc modelling language | MiniZinc: Towards a standard CP modelling language | Search procedures and parallelism in constraint programming | A C++ implementation of CLP | Adding search to zinc | Impact-based search strategies for constraint programming | Towards a lightweight standard search language | Monadic constraint programming | Search combinators | Programming constraint inference engines | Gecode, the generic constraint development environment | Dichotomic search protocols for constrained optimization | The Oz programming model | Constraint-Based Local Search | Nondeterministic control for hybrid search | Search and strategies in OPL",rejected,000
1203.1882.pdf.json,Multi source feedback based performance appraisal system using Fuzzy logic decision support system,"In recent years multi-source feedback systems (MSFS) also known as 360 Degree Appraisal became very popular. It became popular as it has been felt for long years that one person’s assessment of another individual cannot be free of biases. In addition, with the focus on customers (both internal and external) and emphasis on softer dimensions of performance (leadership, innovation, team work, initiative, emotional intelligence, entrepreneurship etc.) it has become necessary to get multiple assessments for a more objective assessment. 360 Degree Appraisal is Multi- Rater Appraisal and Feedback System. Almost every Fortune 500 Company is using this in some form or the other. In this system, the candidate is assessed periodically (once in a year and sometimes even half yearly) by a number of assessors including his boss, immediate subordinates, colleagues, internal customers and external customers. The assessment is made on a questionnaire specially designed to measure behaviors. Performance appraisal the latest mantra for career development is followed by many organizations across the world. “Get paid according to what you contribute” this is turning the focus of organization to performance management and individual performance. It helps to rate the employees and evaluate their contribution towards the organizational goals based on their performance. “Free Form method"" generally involves description of the performance of an employee by his superior. This is an evaluation of the performance of any individual based on the facts and often includes examples and evidences to support the information. This system has the inseparability of the bias of the evaluator as major drawback. To overcome this new form of feedback “360-degree feedback” is formed, it is also known as 'multi-rater feedback'. In this system the feedback is taken from all the sources which come in contact with the employee on his/her job. The various sources include co-workers, managers and supervisors, cust","An Implementation Case for the Performance Appraisal and Promotion Ranking | Fuzzy Logic Modeling for Performance Appraisal Systems – A Framework for Empirical Evaluation | Data-Driven Fuzzy Rule Generation and Its Application for Student Academic Performance Evaluation | Performance Appraisal Issues, Challenges &Prospects | Human Resource Management (8th Edition), NewJersey, Pearson Education, Inc | Performance Appraisals, ABA Labor and Employment Law Section, Equal Employment Opportunity Committee | Performance Appraisals, Loss Control Services, Texas Association of Counties | A Fuzzy-Based Military Officer Performance Appraisal System | Data Mining Concepts, Models, Methods, and Algorithms, Wiley- Interscience | Multifactorial Fuzzy Approach to the Sawability Classification of Building Stones”,Construction and Building Materials | Business Research Methods | Fuzzy Evaluation System of Traffic Safety in Highway Tunnel”http://lib.hpu.edu.cn/comp_meeting/PROGRESS%20IN%20SAFETY20SCIENCE%20AND %20TECHNOLOGY%20VOL.V1/1989.doc[Accessed on | Teacher Portfolio Assessment. Washington, DC, ERIC/AEDigest, The Catholic University of America, Department of Education | A simple computation of MIN and MAX operations for fuzzynumbers | 360 degree feedback: The whole Story.Training and development | Making 360 degree feedback work, Human Capital | Degree feedback, Competency Mapping and Assessment Centers, New Delhi",rejected,000
1203.2556.pdf.json,A Probabilistic Transmission Expansion Planning Methodology based on Roulette Wheel Selection and Social Welfare,,"Electricity libralisation in the European Union: A progress report | Transmission system planning: the old world meets the new | Investing in expansion: the many issues that could transmission planning | Transmission planning and investment under competitive electricity market environment, | Key transmission planning issues, | A | and M | et al | Transmission expansion planning from past to future, | Transmission expansion planning using contingency criteria | Power system capacity expansion planning using Monte Carlo simulation and Genetic Algorithm, | Reliability planning for composite electrical power systems | and A | A | A | d | Flexible transmisison planning with uncertainties in an electricity market | A reliability test system for educational purposes, | Planning electricity transmisison to accommodate renewables: Using two-stage programming to evaluate flexibility and the cost of disregarding uncertainty | M | and R | S | Y | Multi-zone transmission expansion planning using genetic algorithm",rejected,000
1203.3464.pdf.json,Gibbs Sampling in Open-Universe Stochastic Languages,"General purpose probabilistic modelling languages aim to facilitate the development of complex models while providing effective, general inference methods so that the model-builder need not write model-specific inference code for each application from scratch. For example, BUGS (Spiegelhalter et al., 1996) can represent directed graphical models over indexed sets of random variables and uses MCMC inference (in particular, Gibbs sampling where this is possible). As the expressive power of modelling languages increases, the range of representable problems also grows. The class of first-order, open-universe probabilistic languages, including BLOG (Milch et al., 2005a) and Church (Goodman et al., 2008), handles cases in which the number of objects (in BUGS, the index set) is unknown and perhaps unbounded, and object identity is uncertain. It is still possible to write a complete inference algorithm for BLOG, based on MCMC over partial worlds; each such world is constructed from the minimal self-supporting set of variables relevant to the evidence and query variables. Generality has a price, however: BLOG’s default Metropolis–Hastings inference engine samples each variable conditioned only on its parents (Milch & Russell, 2006). This approach leads to unacceptably slow mixing rates for many standard models, in which evidence from child variables is highly informative. Our goal is to remedy this situation, primarily by extending the range of situations in which Gibbs sampling from the full, conditional posterior can be used within BLOG. Section 2 of this paper introduces the terminology of contingent Bayesian networks (CBNs), which we will use as the propositional “abstract machine” for open-universe stochastic languages. Section 3 surveys previous work related to general purpose sampling of CBNs and describes its limitations. Section 4 then describes our novel Gibbs sampling algorithm for CBNs which addresses these limitations; its implementation for BLOG is described in","An introduction to MCMC for machine learning | The alarm monitoring system: A case study with two probabilistic inference techniques for belief networks | Challenge: Where is the impact of Bayesian networks in learning? IJCAI | Samplingbased approaches to calculating marginal densities | Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images | Church: a language for generative models. UAI | BLOG: Probabilistic models with unknown objects | Approximate inference for infinite contingent Bayesian networks | General-purpose MCMC inference over relational structures | Markov chain sampling methods for dirichlet process mixture models | BUGS: Bayesian inference using gibbs sampling, version | Introduction to radar target recognition. The Institution of Engineering and Technology, United Kingdom",rejected,000
1203.3465.pdf.json,Compiling Possibilistic Networks : Alternative Approaches to Possibilistic Inference,"In possibility theory there are two different ways to define the counterpart of Bayesian networks. This is due to the existence of two definitions of possibilistic conditioning: product-based and min-based conditioning (Dubois and Prade, 1988). When we use the product form of conditioning, we get a possibilistic network close to the probabilistic one sharing the same features and having the same theoretical and practical results. However, this is not the case with min-based networks. In this paper, we are interested in the inference problem in multiply connected networks, which is known as a hard problem (Cooper, 1990). More precisely, we propose three compilation methods for min-based possibilistic networks. The compilation of Bayesian networks is always considered as an important area. Recently, researchers have been interested in various kinds of exact and approximate Bayesian networks inference algorithms using compilation techniques (Darwiche, 2003) (Chavira and Darwiche, 2005) (Wachter and Haenni, 2007), etc. Despite the importance of possibility theory, there is no compilation that has been proposed for possibilistic networks. This paper analyzes this issue by first adapting well-known compilation-based probabilistic inference approaches, namely the arithmetic circuit method (Darwiche, 2003) and the logical compilation of Bayesian Networks (Wachter and Haenni, 2007). Both of them are based on a network’s encoding into a logical representation and a compilation into a target compilation language, namely Π-DNNF. From there, all possible queries are answered in polynomial time. The third method exploits results obtained on one hand in (Benferhat et al., 2002) that transforms a minbased possibilistic network into a possibilistic knowledge base, and on the other hand results obtained regarding compilation of possibilistic bases (Benferhat et al., 2007) in order to assure inference in polytime. This method that is purely possibilistic is flexible since it permits t","On the transformation between possibilistic logic bases and possibilistic causal networks | Possibilistic causal networks for handling interventions: A new propagation algorithm | On the compilation of stratified belief bases under linear and possibilistic logic policies | Compiling bayesian networks with local structure | The computational complexity of probabilistic inference using bayesian belief networks (research note) | Decomposable negation normal form | A differential approach to inference in bayesian networks | A knowledge compilation map | Possibilistic logic | Possibility theory:An approach to computerized, Processing of uncertainty | Conditional possibilities independence and non interaction | Causality: Models, reasonning and inference | Logical compilation of bayesian networks with discrete variables",rejected,000
1203.3466.pdf.json,Possibilistic Answer Set Programming Revisited,"Answer set programming (ASP) is a form of declarative programming based on the stable model semantics (Gelfond and Lifzchitz, 1988). ASP has proven successful as an elegant formalism for commonsense reasoning in discrete domains and to encode combinatorial problems in a purely declarative way. Possibilistic logic (PL), introduced in (Dubois et al., 1994), emanated from possibility theory (Zadeh, 1978) and offers a sound and complete logic system for representing (partial) ignorance or uncertainty in a nonprobabilistic way. Possibilistic answer set programming (PASP) (Nicolas et al., 2006) unites ASP and PL and provides a single ∗Funded by a joint FWO project. †Postdoctoral fellow of the FWO. ‡On leave from Universiteit Gent. framework that supports declarative programming under uncertainty. In PASP, a certainty value is attached to each rule of an ASP program. The certainty of a particular conclusion of that program is then given by the lowest certainty of the rules that were used, i.e. the strength of a conclusion is determined by the weakest piece of information involved. However, for programs containing negation-as-failure, the semantics proposed in (Nicolas et al., 2006) often lead to counterintuitive results. For example, consider the PASP program P1: 1: concertBooked ← (1) 1: longDrive ← concertBooked ,not canceled (2) 0.2: canceled ← . (3) This program encodes that we are certain that we booked a concert and we are certain that we have a long drive ahead of us, unless the concert is canceled. The last rule encodes that the concert is indeed cancelled, although this information comes from an unreliable source, hence a low certainty degree is attached to this rule. The approach from (Nicolas et al., 2006) consists of first determining the classical answer sets, ignoring the certainty values, and subsequently adding certainties to atoms in these answer sets based on which rules are needed to support them. The program above only has one classical answer set, name","Probabilistic reasoning with answer sets | Nonmonotonic reasoning, conditional objects and possibility theory | Pstable semantics for logic programs with possibilistic ordered disjunction | A classification and survey of preference handling approaches in nonmonotonic reasoning | Towards possibilistic logic programming | Possibilistic logic | The stable model semantics for logic programming | Twelve definitions of a stable model | Assat: computing answer sets of a logic program by sat solvers | Towards a fuzzy answer set semantics for residuated logic programs | Possibilistic uncertainty handling for answer set programming | Preferred answer sets for ordered logic programs | Semantics for possibilistic disjunctive programs | Logics with common weak completions | Belief logic programming | Fuzzy sets as a basis for a theory of possibility",rejected,000
1203.3467.pdf.json,Three new sensitivity analysis methods for influence diagrams,"Decision making under uncertainty presents several opportunities and challenges beyond those encountered in pure reasoning under uncertainty. An influence diagram [Howard and Matheson, 1984] is a graphical model that represents the relationships between the decisions, uncertainties and preferences of a decision maker (DM), and it can be evaluated to reveal the optimal strategy and the DM’s value for the decision situation. Decision circuits are graphical representations that not only enable efficient evaluation of influence diagrams [Bhattacharjya and Shachter, 2007; Shachter and Bhattacharjya, 2010], but also compute a wide array of sensitivity analysis results [Bhattacharjya and Shachter, 2008]. In this paper, we extend our previous work on sensitivity analysis and show how decision circuits can also be used to efficiently perform more sophisticated analysis such as strategy comparisons, sensitivity to risk aversion, and value of perfect hedging [Seyller, 2008] computations. Sensitivity analysis refers to observing how the outputs of a system are affected as the inputs are varied. In decision situations, such analysis can provide the DM with insights, a better understanding of the situation and clarity of action. Decision circuits extend the research in arithmetic circuits [Darwiche 2000; 2003] towards evaluating and analyzing decision situations, and they reap similar benefits in efficiency. For belief networks, efficient sensitivity analysis is feasible primarily due to the linear relationship between marginal probabilities and the parameters (see for instance Castillo et al [1997]; Kjaerulff and van der Gaag [2000]; van der Gaag and Renooij [2001]; Chan and Darwiche [2004]). On the other hand, there are unique challenges in sensitivity analysis for influence diagrams [Nielsen and Jensen, 2003; Bhattacharjya and Shachter, 2008] arising due to the non-linearities created by maximization operations for making decisions, as well as the non-linear utility function f","The theory of risk aversion, In Aspects of the Theory of Risk-Bearing, Lecture 2, Yrjo Jahnssonin Saatio: Helsinki | Evaluating influence diagrams with decision circuits | Sensitivity analysis in decision circuits | Decision circuits: A graphical representation for efficient decision analysis computation, Ph.D Thesis, Stanford University | Sensitivity analysis in discrete Bayesian networks | Sensitivity analysis in Bayesian networks: From single to multiple parameters | Beyond treewidth in probabilistic inference, Ph.D Thesis, University of California | A differential approach to inference in Bayesian networks | A differential approach to inference in Bayesian networks | Information value theory | The foundations of decision analysis | Making sensitivity analysis computationally efficient | Sensitivity analysis in influence diagrams | Risk aversion in the small and in the large, Econometrica | Decision Analysis: Introductory Lectures on Choices under Uncertainty, Addison-Wesley | The value of hedging | Dynamic programming in influence diagrams with decision circuits | A measure of decision flexibility | Analysing sensitivity data from probabilistic networks",rejected,000
1203.3470.pdf.json,ALARMS: Alerting and Reasoning Management System for Next Generation Aircraft Hazards,"Next Generation Air Transportation System technologies will introduce new, advanced sensor technologies into the ∗This author conducted this work while at Aptima, Inc. cockpit. With the introduction of such systems, the responsibilities of the pilot and the density of air traffic are both expected to dramatically increase (Joint Planning and Development Office, 2007). As a result, the number of potential hazards and relevant information that must be perceived and processed by the pilot will grow. This information is likely to come from a variety of sources, requiring the pilot to integrate this information in order to evaluate hazard potential. Evaluating hazard potential will depend on the consideration of, and differentiation between, immediate (current) hazards and situations requiring re-planning or coordination (future). It will also require reasoning under uncertainty, as the actual state of the world needs to be reasoned from the hazards, and also a plan needs to be constructed for the pilot and artificial aircraft intelligence to handle the hazards, despite uncertainty as to the effectiveness of each, and temporal uncertainty about the duration required to handle each hazard. To support these challenging responsibilities, the pilot has an unambiguous need for an Integrated Alerting and Notification (IAN) system that will continuously monitor multiple sources of interdependent information to evaluate hazard potentials, track multiple potential hazards, provide caution/warning/alerting (CWA) notifications and contextrelevant decision support to the pilot, and determine the best method of presenting this information to ensure that the information can be viewed and used efficiently and effectively. There are two broad challenges that need to be addressed before an IAN system can become operational. First, existing methods cannot reason under uncertainty about the proposed scale of information and hazards in such a time-critical environment (Proctor, 1998; Song a",MUNIN: A causal probabilistic network for interpretation of electromyographic findings | Automated decision-analytic diagnosis of thermal performance in gas turbines | Exact solutions to time | Monitoring and control | Investigating interruptions: implications | Lazy approximation for solving | A fast analytical | Adapting an MDP,rejected,000
1203.3473.pdf.json,Lifted Inference for Relational Continuous Models,"Many real world systems are described by continuous variables and relations among them. Such systems include measurements in environmental-sensors networks (Hill et al., 2009), localizations in robotics (Limketkai et al., 2005), and economic forecastings in finance (Niemira & Saaty, 2004). Once a relational model among variables is given, inference algorithms can solve value prediction problems and classification problems. At a ground level, inference with a large number of continuous variables is non-trivial. Typically, inference is the task of calculating a marginal over variables of interest. Suppose that a market index has a relationship with n variables, revenues of n banks. When marginalizing out the market index, the marginal is a function of n variables (revenues of banks), thus marginalizing out remaining variables becomes harder. When n grows, the computation becomes expensive. For example, when relations among variables follow Gaussian distributions, the computational complexity of the inference problem is O(|U|3) (U is a set of ground variables). Thus, the computation with such models is limited to moderate-size models, preventing its use in the many large, real-world applications. To address these issues, Relational Probabilistic Languages (RPLs) (Ng & Subrahmanian, 1992; Koller & Pfeffer, 1997; Pfeffer et al., 1999; Friedman et al., 1999; Poole, 2003; de Salvo Braz et al., 2005; Richardson & Domingos, 2006; Milch & Russell, 2007; Getoor & Taskar, 2007) describe probability distributions at a relational level with the purpose of capturing larger models. RPLs combine probability theory for handling uncertainty and relational models for representing system structures. Thus, they facilitate construction and learning of probabilistic models for large systems. Recently, (Poole, 2003; de Salvo Braz et al., 2005; Milch et al., 2008; Singla & Domingos, 2008) showed that such models enable more efficient inference than possible with propositional graphical model",Lifted firstorder probabilistic inference. IJCAI’05: Proceedings of the 19th international joint conference on Artificial intelligence (pp. 1319–1325) | Mpe and partial inversion in lifted probabilistic variable elimination. AAAI’06: proceedings of the 21st national conference on Artificial intelligence (pp. 1123–1130) | Learning probabilistic relational models. IJCAI’99: Proceedings of the 16th international joint conference on Artificial intelligence (pp. 1300–1307) | Introduction to statistical relational learning (adaptive computation and machine learning) | Real-time bayesian anomaly detection in streaming environmental data | Lifted aggregation in directed first-order probabilistic models. IJCAI’09 | Object-oriented bayesian networks | Continuous multivariate distributions | Inference in hybrid networks: Theoretical limits and practical algorithms | Relational object maps for mobile robots. IJCAI’05: Proceedings of the 19th international joint conference on Artificial intelligence (pp. 1471–1476) | Transfer learning from minimal target data by mapping across relational domains. IJCAI’09 | First-order probabilistic languages: Into the unknown. 10–24 | Lifted probabilistic inference with counting formulas | Probabilistic logic programming | An analytic network process model for financial-crisis forecasting | Thin junction tree filters for simultaneous localization and mapping | Spook: A system for probabilistic objectoriented knowledge representation | First-order probabilistic inference | A unifying review of linear gaussian models | Inference in hybrid bayesian networks using mixtures of gaussians,rejected,000
1203.3474.pdf.json,Distribution over Beliefs for Memory Bounded Dec-POMDP Planning,"The problem of the control of a team of cooperative agents in interaction with a stochastic environment has a large field of applications: packet routing in a network, robot coordination, control of sensor networks, zone surveillance etc. The Dec-POMDP (Decentralised Partially Observable Markov Decision Process) formal framework may be used to tackle this problem rigorously. We focus here on the particular case of planning: given the rules of the environment and a goal modelled as a reward function, we are searching for a policy to assign to each agent in order to maximise the rewards. The computation of an optimal joint policy is NEXP-complete in a finite horizon [Bernstein et al., 2000] when the horizon is smaller than the number of states. The exact computation is thus not usable except for very small problems (especially, with a small number of observations) and for small horizons. Several approaches have been proposed to solve Dec-POMDPs: bottom-up dynamic programming [Hansen et al., 2004], [Szer and Charpillet, 2006], topdown search [Szer et al., 2005] and mathematical programming [Aras et al., 2007]. The number of partial policies to consider in an exact dynamic programming approach is generally exponential in the planning horizon and the number of agents and doubly exponential in the number of observations [Hansen et al., 2004]. Some algorithms have been proposed to overcome this problem: MBDP (Memory Bounded Dynamic Programming) [Seuken and Zilberstein, 2007b], IMBDP (Improved MBDP) [Seuken and Zilberstein, 2007a], MBDP-OC (MBDP with Observation Compression) [Carlin and Zilberstein, 2008], PBIP (Point Based Incremental Pruning) [Dibangoye et al., 2009]. They use only a bounded number of partial plans at each planning step. By bounding the memory, they are able to solve problems with significantly longer horizons than previous algorithms: the complexity is linear with the horizon. By avoiding the exhaustive backup, some of them can solve problems with a high",Mixed integer linear programming for exact finite-horizon planning in decentralized POMDPs | The complexity of decentralized control of markov decision processes | Value-based observation compression for DEC-POMDPs | Point-based incremental pruning heuristic for solving finitehorizon dec-pomdps | Dynamic programming for partially observable stochastic games | Taming Decentralized POMDPs: Towards Efficient Policy Computation for Multiagent Settings | Optimal and approximate Q-value functions for decentralized POMDPs | Improved Memory-Bounded Dynamic Programming for Decentralized POMDPs | Memory-Bounded Dynamic Programming for DEC-POMDPs | Point-based dynamic programming for DEC-POMDPs | MAA*: A Heuristic Search Algorithm for Solving Decentralized POMDPs,rejected,000
1203.3477.pdf.json,A Scalable Method for Solving High-Dimensional Continuous POMDPs Using Local Approximation,"Partially-Observable Markov Decision Processes (POMDPs) offer a framework for studying decision making under uncertainty. The optimal behavior in a POMDP domain is expected to strike a balance between exploring the partially-observable world and acting in a goal-directed manner. Most of the POMDP literature is concerned with discrete domains, but in the past few years, as POMDP tools become more powerful, there is growing ∗ {etom,wds}@cse.wustl.edu interest in tackling continuous domains (Porta et al., 2006; Brooks, 2009). The standard approach to solving POMDPs is to find an approximate solution to the fully-observable belief -MDP, whose states are probability distributions over the state space of the original POMDP (Kaelbling et al., 1998). In the discrete case, the resulting belief space is continuous but finite-dimensional, and belief update can be carried out exactly. However, the belief space of a continuous POMDP is infinite-dimensional, and must be approximated (Thrun, 2000). The optimal value function of belief-MDPs is piecewiselinear and convex in the discrete case (Sondik, 1971), and this also holds for some cases of continuous state (Porta et al., 2006), as long as the observations and actions are discrete. This result was used to tackle domains with continuous hybrid-linear dynamics by Brunskill et al. (2008). Other combinations of the discrete and the continuous domains were also considered (Hoey & Poupart, 2005; Spaan & Vlassis, 2005). The richest domain tackled by continuous POMDPs is probably outdoor navigation (Brooks, 2009). However, in all the examples mentioned above, the belief domain is solved through global optimization. Since the volume of state space grows exponentially with the dimension of the state, it is unrealistic to seek a globally-optimal solution in domains above a certain size because of the curse of dimensionality. Some studies (e.g., Feng & Zilberstein, 2004) try to offset some of the computational burden by finding parts of bel",Exploration and apprenticeship learning in reinforcement learning | A POMDP formulation of preference elicitation problems | Parametric POMDPs | Continuous-state POMDPs with hybrid dynamics | Dictionary of Eye Terminology | Bipedal walking on rough terrain using manifold control | What does shaping mean for computational reinforcement learning | Coupling perception and action using minimax optimal control | Region-based incremental pruning for POMDPs | Solving POMDPs with continuous or large discrete observation spaces | Grasping POMDPs | Planning and acting in partially observable stochastic domains | A POMDP framework for coordinated guidance of autonomous uavs for multitarget tracking | Belief space planning assuming maximum likelihood observations | Point-based value iteration for continuous POMDPs | The belief roadmap: Efficient planning in belief space by factoring the covariance | Coastal navigation with mobile robots | The Optimal Control of Partially Observable Markov Processes | Planning with continuous actions in partially observable environments | Optimal Control and Estimation | Rigid-body dynamics with friction and impact | Policies based on trajectory libraries | Receding horizon differential dynamic programming | LQR-trees: Feedback motion planning on sparse randomized trees | Monte carlo POMDPs | Pros and cons of truncated gaussian ep in the context of approximate inference control,rejected,000
1203.3478.pdf.json,Playing games against nature: optimal policies for renewable resource allocation,"The problem of devising policies to optimally allocate resources over time is a fundamental decision theoretic problem with applications arising in many different fields. In fact, such decisions may involve a variety of different resources such as time, energy, natural and financial resources, in allocation problems arising in domains as diverse as natural resources management, crowdsourcing, supply chain management, QoS and routing in networks, vaccine distribution and pollution management. A particularly interesting class of such problems involves policies for the allocation of renewable resources. A key and unique aspect of such a resource type is the fact that, by definition, its stock is constantly replenished by an intrinsic growth process. The most common example are perhaps living resources, such as fish populations or forests, that increase constantly by natural growth and reproduction, but less conventional resources such as users in a social com- munity or in a crowdsourcing project share the same intrinsic growth feature due to social interactions. A common feature of the growth processes presented is that they are density dependent, in the sense that the growth rate depends on the amount of resource available. This fact creates a challenging management problem when the aim of the intervention is to optimally use the resource, for instance by harvesting a fish population or by requiring some effort from a crowdsourcing community, especially when economic aspects are factored in. We face a similar challenge in vaccine distribution problems, where the growth rate of infections is again density dependent and the objective is to reduce its spreading. This study, in particular, has been motivated by the alarming consideration that many natural resources are endangered due to over-exploitation and generally poorly managed. For instance, the Food and Agricultural Organization estimates in their most recent report that 7% of marine fish stocks are already deplet","Robust optimization– methodology and applications | Dynamic programming and optimal control | Robust discrete optimization and network flows | Mathematical bioeconomics: the optimal management of renewable resources | Resource economics | Sustainability of fisheries through marine reserves: a robust modeling analysis | Computational Sustainability Computational Methods for a Sustainable Environment,Economy, and Society | Wilen. A model of regulated open access resource use | Risk-sensitive Markov decision processes | Implementing the precautionary principle in fisheries management through marine reserves | Markov games as a framework for multi-agent reinforcement learning | Risk sensitive Markov decision processes | Game theory. Third Edition | A stochastic model for the economic management of a renewable animal resource | Optimal escapement levels in stochastic and deterministic harvesting models | The Optimality of (S, s) Policies in the Dynamic Inventory Problem. Stanford mathematical studies in the social sciences, page",rejected,000
1203.3480.pdf.json,Learning Game Representations from Data Using Rationality Constraints,"Game theory has been widely used to model strategic interactions of agents. A natural question is where do the game representations come from? Traditionally, games have usually been constructed by hand, but in that case they may only be theoretical abstractions of reality. Alternatively, one might have access to a simulator, for example, in the trading agent competition, but that is unusual. The problem is similar to that of developing a probabilistic model, and a common approach, which we take in this paper, is to learn the model from data. Consider for example the following situation. A farmer wants to begin selling fruits in a market. She has to decide where in the market to locate her store, which types of fruits to sell, and what prices to charge for the fruits. She does not know what the other farmers currently do nor what payoffs the other farmers are receiving for their decisions. This is a game and our new farmer would like to learn both the rules of the game and the strategies that the other players play from observing them. Moreover, she would like to learn these quickly with limited data. A naive approach to this learning problem is to use the maximum likelihood estimation to learn the strategy profiles and payoff values separately from observed data. However, this approach is prone to over-fitting since limited amount of data may not accurately reflect the actual strategies and payoffs. More importantly, this approach ignores the fact that agents might already be playing reasonably good strategies. It does not connect the strategies played by the agents to their payoffs while learning. Our main contribution is to make this connection, as illustrated in Figure 1. The naive approach makes the connection between the strategy and payoff variables with the observed data, but does not connect the strategy variables to the payoff variables. An alternative approach could learn the payoffs from data, and then connect the strategies to the payoffs by solving the ","Semiring-based constraint satisfaction and optimization | Toolbar: a state-of-the-art platform for WCSP. http://www.inra.fr/bia/t/degivry/toolbar.pdf | Behavioral game theory | Learning graphical game models | Learning and solving many-player games through a clusterbased representation | Graphical models for game theory | Gambit: Software tools for game theory, version 0.2007.01.30 | Quantal response equilibria for normal form games | Constraint satisfaction algorithms for graphical games | Learning payoff functions in infinite games",rejected,000
1203.3482.pdf.json,Formula-Based Probabilistic Inference,"The standard task in the field of automated reasoning is to determine whether a set of logical formulas (the knowledge base KB) entails a query formula Q. (The formulas could be propositional or first-order; in this paper we focus on the propositional case.) Logic’s lack of a representation for uncertainty severely hinders its ability to model real applications, and thus many methods for adding probability to it have been proposed. One of the earliest is Nilsson’s probabilistic logic (Nilsson, 1986), which attaches probabilities to the formulas in the KB and uses these to compute the probability of the query formula. One problem with this approach is that the formula probabilities may be inconsistent, yielding no solution, but consistency can be verified and enforced (Nilsson, 1986). Another problem is that in general a set of formula probabilities does not completely specify a distribution, but this is naturally solved by assuming the maximum entropy distribution consistent with the specified probabilities (Nilsson, 1986; Pietra et al., 1997). A more serious problem is the lack of efficient inference procedures for probabilistic logic. This contrasts with the large literature on inference for graphical models, which always specify unique and consistent distributions (Pearl, 1988). However, the representational flexibility and compactness of logic is highly desirable, particularly for modeling complex domains. This issue has gained prominence in the field of statistical relational learning (SRL) (Getoor and Taskar, 2007), which seeks to learn models with both logical and probabilistic aspects. For example, Markov logic represents knowledge as a set of weighted formulas, which define a log-linear model (Domingos and Lowd, 2009). Formulas with probabilities with the maximum entropy assumption and weighted formulas are equivalent; the problem of converting the former to the latter is equivalent to the problem of learning the maximum likelihood weights (Pietra et al., 1","Value Elimination: Bayesian Inference via Backtracking Search | Context-specific independence in Bayesian networks | Rao-Blackwellisation of sampling schemes | On probabilistic inference by weighted model counting | Recursive conditioning | New Advances in Compiling CNF into Decomposable Negation Normal Form | AND/OR search spaces for graphical models | Markov Logic: An Interface Layer for Artificial Intelligence | Stochastic relaxations, Gibbs distributions and the Bayesian restoration of images | Introduction to Statistical Relational Learning | Approximate inference algorithms for hybrid Bayesian networks with discrete constraints | SampleSearch: A scheme that Searches for Consistent Samples | Approximate counting by sampling the backtrack-free search space | AND/OR Importance Sampling | Streamlined constraint reasoning | From sampling to model counting | Local computation with probabilities on graphical structures and their application to expert systems | Using weighted max-sat engines to solve mpe | Probabilistic Reasoning in Intelligent Systems | Inducing features of random fields | Sound and efficient inference with probabilistic and deterministic dependencies | Counting models using connected components | Simulation and the Monte Carlo Method | Heuristics for fast exact model counting | Probabilistic diagnosis using a reformulation of the internist- 1/qmr knowledge base i. the probabilistic model and inference algorithms | Minisat v1.13-a SAT solver with conflict-clause minimization | A new approach to model counting | Constructing free energy approximations and generalized belief propagation algorithms | Importance sampling algorithms for Bayesian networks: Principles and performance",rejected,000
1203.3490.pdf.json,Anytime Planning for Decentralized POMDPs using Expectation Maximization,"Decentralized partially observable MDPs (DECPOMDPs) have emerged in recent years as an important framework for modeling sequential decision making by a team of agents [5]. Their expressive power makes it possible to tackle coordination problems in which agents must act based on different partial information about the environment and about each other to maximize a global reward function. Applications of DEC-POMDPs include coordinating the operation of planetary exploration rovers [3], coordinating firefighting robots [14], broadcast channel protocols [5] and target tracking by a team of sensor agents [13]. However, the rich model comes with a price–optimally solving a finite-horizon DEC-POMDP is NEXP-Complete [5]. In contrast, finite-horizon POMDPs are PSPACE-complete [12], a strictly lower complexity class that highlights the difficulty of solving DEC-POMDPs. Recently, a multitude of point-based approximate algorithms have been proposed for solving finite-horizon DEC-POMDPs [11, 8, 16]. However, unlike their point-based counterparts in POMDPs ([15, 17]), they cannot be easily adopted for the infinite-horizon case due to a variety of reasons. For example, POMDP algorithms represent the policy compactly as α-vectors, whereas all DEC-POMDP algorithms explicitly store the policy as a mapping from observation sequences to actions, making them unsuitable for the infinitehorizon case. In POMDPs, the Bellman equation forms the basis of most point-based solvers, but as Bernstein et. al. [4] highlight, no analogous equation exists for DEC-POMDPs. To alleviate such problems, most infinite-horizon algorithms represent agent policies as finite-state controllers [1, 4]. So far, only two algorithms have shown promise for effectively solving infinite-horizon DEC-POMDPs–decentralized bounded policy iteration (DEC-BPI) [4] and a non-linear programming based approach (NLP) [1]. However, both of these algorithms have significant drawbacks in terms of the representative class of problem",Optimizing fixed-size stochastic controllers for POMDPs and decentralized POMDPs | Planning by probabilistic inference | Solving transition independent decentralized markov decision processes | Policy iteration for decentralized control of Markov decision processes | The complexity of decentralized control of Markov decision processes | MapReduce: a flexible data processing | Maximum likelihood from incomplete data via the EM algorithm | Point-based incremental pruning heuristic for solving finite-horizon DEC-POMDPs | SNOPT: An SQP algorithm for large-scale constrained optimization. SIOPT | New inference strategies for solving Markov decision processes using reversible jump MCMC | Point based backup for decentralized POMDPs: Complexity and new algorithms | Complexity of finite-horizon Markov decision process problems | Networked distributed POMDPs: A synthesis of distributed constraint optimization and POMDPs | Optimal and approximate Q-value functions for decentralized POMDPs | Anytime pointbased approximations for large POMDPs | Memory-bounded dynamic programming for DEC-POMDPs | Heuristic search value iteration for POMDPs | Hierarchical POMDP controller optimization by likelihood maximization | Probabilistic inference for solving (PO)MDPs | Probabilistic inference for solving discrete and continuous state markov decision processes,rejected,000
1203.3493.pdf.json,Solving Hybrid Influence Diagrams with Deterministic Variables,"An influence diagram (ID) is a formal compact representation of a Bayesian decision-making problem. It consists of four parts: a sequence of decisions, a set of chance variables with a joint distribution represented by a hybrid Bayesian network (BN), the decision maker’s preferences for the uncertain outcomes represented by a joint utility function that factors additively, and information constraints that indicate which uncertainties are known (and which are unknown) when a decision has to be made. IDs were initially defined by [8]. Hybrid IDs are IDs containing a mix of discrete and continuous chance and decision variables. In practice, most decision problems are hybrid. However, solving a hybrid ID involves two main computational challenges. First, marginalizing a continuous chance variable involves integration of a product of density and utility functions. In some cases, such as the Gaussian density function, there may not exist a closed-form representation of the integral. We will refer to this problem as the integration problem. Second, marginalizing a decision variable involves maximizing a utility function. If the decision variable is continuous and has relevant continuous information predecessors, then we may be faced with the problem of finding a closed-form solution of the maximization problem. Not only do we have to find the maximum value of the decision variable (as a function of the states of its relevant information predecessors), we have also to find a closed-form expression of the maximum utility (as a function of the states of its relevant information predecessors). We will refer to this problem as the optimization problem. A traditional method for solving hybrid IDs is to approximate a hybrid ID with a discrete ID by discretizing the continuous chance and decision variables (see, e.g., [9]). If we discretize a continuous variable using a few bins, we may have an unacceptable approximation of the problem. On the other hand, if we use many bins, we i",Rı́os. Decision analysis by augmented probability simulation | Multi-stage Monte Carlo method for solving influence diagrams using local computation | Arc reversals in hybrid Bayesian networks with deterministic variables | Decision making with hybrid influence diagrams using mixtures of truncated exponentials | The physical interpretation of the quantum dynamics | Risk analysis in capital investment | Proximal decision analysis | Influence diagrams | Certainty equivalents for threepoint discrete-distribution approximations | Nonuniform dynamic discretization in hybrid networks | Representing and solving decision problems with limited information | Mixtures of truncated exponentials in hybrid Bayesian networks | Sampling methods for action selection in influence diagrams | Decision analysis with continuous and discrete variables: A mixture distribution approach | Evaluating influence diagrams | Gaussian influence diagrams | Valuation-based systems for Bayesian decision analysis | Axioms for probability and belief-function propagation | Inference in hybrid Bayesian networks using mixtures of polynomials | Inference in hybrid Bayesian networks with deterministic variables | Mixtures of polynomials in hybrid Bayesian networks with deterministic variables,rejected,000
1203.3498.pdf.json,Automated Planning in Repeated Adversarial Games,"Adversarial games2 have been studied since the birth of game theory. They abstract many real scenarios such as chess, checkers, poker, and even the cold war. Repeated interactions, on the other hand, model situations where two or more agents interact multiple times, building long–run relationships. Their solutions are often represented as a sequence of actions (or plans of actions). Repeated adversarial games are, therefore, a 1http://users.ecs.soton.ac.uk/acc/LSGT/home.html 2Adversarial games are also known as constant–sum games. natural framework to study sequential decision making in an adversarial setting. It is somewhat surprising, then, to find that artificial intelligence offers few insights on how to interact against heterogeneous agents in repeated adversarial games, particularly since the field is renowned for offering solutions under weaker assumptions than those imposed by game theory (e.g. regarding computation and memory power). Indeed, the problem is further exacerbated if the adversaries’ behaviour is unknown a priori to the planning agent and the latter needs to interact with its adversaries to learn how they behave. Against this background, we present a study on how an agent should plan a sequence of actions in a repeated adversarial game when the adversaries are unknown. Specifically, in these games, the capability of an agent to compute a good sequence of actions relies on its capacity to forecast the behaviour of its opponents, which may be a hard task against opponents that themselves adapt. The planner, therefore, needs to construct a plan while considering the uncertain effects of its actions on the decisions of its opponents. The repeated nature of the interaction allows us to frame this as a planning adversarial problem, where the unknown behaviour of the opponents is learnt by repeatedly interacting with them. The learning task however, requires a large number of repeated interactions to be effective, which in many scenarios is unacceptabl","Social reward shaping in the prisoner’s dilemma | Efficient learning of multistep best response | R-MAX - A general polynomial time algorithm for near-optimal reinforcement learning | Learning and solving many-player games through a cluster-based representation | Markov games as a framework for multi-agent reinforcement learning | Implicit negotiation in repeated games, 393–404 | Planning against fictitious players in repeated normal form games | Policy invariance under reward transformations: Theory and application to reward shaping | Markov decision processes— discrete stochastic dynamic programming | EA: The winning strategy for the inaugural lemonade stand game tournament | An algorithm for computing stochastically stable distributions with applications to multiagent learning in repeated games",rejected,000
1203.3499.pdf.json,A Delayed Column Generation Strategy for Exact k-Bounded MAP Inference in Markov Logic Networks,"Graph matching instances are at the core of many problems in areas such as computational biology, computer vision, and knowledge representation. The problem of aligning protein-protein interaction networks [13] and the problem of matching different heterogeneous ontologies [1] are only two of numerous instances. In several of these cases, the alignment can be derived by computing a MAP state in a probabilistic network whose variables model the potential correspondences [4]. Given an assignment to the observable variables, a (marginal) MAP query attempts to find an assignment to the set of non-evidence (hidden) variables whose score is maximal [3]. We are specifically concerned with computing MAP states in Markov logic networks [5] (MLN) a probabilistic logic which combines the ideas of Markov networks with those of first-order logic. Several scenarios make it necessary to perform exact inference, especially if only those solutions are acceptable that are consistent with respect to the hard formulae of the MLN. Unfortunately, exact MAP inference is NP-hard. In several scenarios, however, it is sufficient to compute a MAP state with at most k active ground atoms. For instance, consider a matching problem where one is interested in the top k consistent correspondences between the nodes of two or more graphs. In other cases, one might know a-priori that only a small fraction of the ground atoms of hidden predicates will be active in a MAP state. This is true for several matching problems where the final alignment is required to be one-to-one and functional. Motivated by these observations, this paper introduces k-bounded MAP inference. k-Bounded MAP states are MAP states with at most k active ground atoms of hidden predicates. Compare this to the different m-best MAP problem [2] which aims at finding the m most probable MAP states. We present a novel algorithm combining integer linear programming (ILP) with a form of delayed column generation. Similar to dynamic program",Ontology matching | An lp view of the m-best map problem | Probabilistic Graphical Models | A probabilistic-logical framework for ontology matching | Markov logic networks | Improving the accuracy and efficiency of map inference for markov logic | Integer linear programming inference for conditional random fields | Theory of Linear and Integer Programming | Speeding up inference in markov logic networks by preprocessing to reduce the size of the resulting grounded network | Pellet: a practical OWL-DL reasoner | Ontofarm: Towards an experimental collection of parallel ontologies | Learning Structured Prediction Models: A Large-Margin Approach | Global alignment of protein-protein interaction networks by graph matching methods,rejected,000
1203.3500.pdf.json,Comparative Analysis of Probabilistic Models for Activity Recognition with an Instrumented Walker,"Improving the quality of life of the ever increasing elderly population is one of the key concerns for health care provision. Limitations to independent mobility for these individuals have a significant impact on the quality of their life. Devices such as rollating walkers are often used to improve the independence and mobility of older adults. Our long-term goal is to improve the utility of these devices, by enabling them to perceive their environment and actively provide assistance to their users. We are collaborating with a multidisciplinary group that is studying the usage of rollating walkers. We have access to a walker [9] that has been instrumented with various sensors and cameras to monitor the user. We are developing automated techniques to recognize the activities performed by users with respect to their walker (e.g., walking, standing, turning, etc.) based on the non-video sensors. This problem is significant for Kinesiologists who are studying the usage of walkers by elderly people. Currently they have to hand label the data by looking at video feeds of the user, which is ∗Allan Caine is currently at Research in Motion, Waterloo not only time consuming but may not be accurate due to synchronization issues between various sensors. An automated activity recognition system would enable clinicians to gather statistics about the activity patterns of users, their level of mobility and the context in which falls are more likely to occur. This will also be useful for the development of smart walkers that can assist users with navigation and braking while taking into account their intended activity. In this paper we describe a comparative analysis of activity recognition techniques based on hidden Markov models (HMMs) and conditional random fields (CRFs) trained by supervised and unsupervised learning for rollating walkers instrumented with various sensors. Our contributions are: • the first fully automated system to automatically recognize activities performed b","Passive derivation of basic walker-assisted gait characteristics from measured forces and moments | Maximum likelihood from incomplete data with the em algorithm | Motion control of intelligent passive-type walker for fall prevention function based on estimation of user state | Conditional random fields: Probabilistic models for segmenting and labeling sequence data | Extracting places and activities from gps traces using hierarchical conditional random fields | Learning and inferring transportation | The collapsed Gibbs sampler in Bayesian computations with applications to a gene regulation problem | Introduction to Statistical Relational Learning, chapter An Introduction to Conditional Random Fields for Relational Learning | Frontal plane balance control with rollators: Perturbed stance and walking",rejected,000
1203.3502.pdf.json,The Cost of Troubleshooting Cost Clusters with Inside Information,"In decision theoretical troubleshooting we are faced with a problem that needs to be solved by applying solution actions and by posing questions that gather information about the problem. The premise is that after each action we can cost free observe whether the problem was solved. The domain is assumed to be uncertain, that is, solution actions may be imperfect and information might be non-conclusive. Given a model that describes the uncertainty and the cost of actions and questions, the goal is to compute a strategy for solving the problem with the lowest expected cost. If the model has the following assumptions: (a) the problem is due to a single fault, (b) different actions address different faults, (c) costs do not depend on the previous history, and (d) there are no questions, then the problem is solvable in O(n · lg n) time where n is the number of actions. This algorithm is the wellknown ”P-over-C” algorithm by (Kadane and Simon, 1977) which was first brought into a troubleshooting context by (Kalagnanam and Henrion, 1990). Furthermore, if any of the above assumptions are relaxed without restrictions, the problem becomes NP-hard (Vomlelová, 2003). If assumption (a) is replaced with an assumption about multiple independent faults, an O(n·lg n) P-over-C-like algorithm also exists (Srinivas, 1995). Troubleshooting without assumption (b) can also be somewhat simplified due to the dependency set algorithm of (Koca and Bilgic, 2004). (Langseth and Jensen, 2001) proposed to relax assumption (c) slightly by considering a model where the actions can be partitioned into a flat set of socalled cost clusters (see Figure 1). The idea is that in order to access an action in a bottom level cluster Ki, you need to pay an additional cost Coi and to close the cluster you have to pay an additional cost Cci . Thereby it is possible to model e.g. the repair of complex manmade devices where you need to take apart some of the equipment to perform certain actions. If we can determ",Decision-theoretic troubleshooting | The SACSO methodology for troubleshooting complex systems | Optimal strategies for a class of constrained sequential problems | A comparison of decision analysis and expert rules for sequential diagnosis | A troubleshooting approach with dependent actions | Heuristics for two extensions of basic troubleshooting | Complexity of decision-theoretic troubleshooting | Troubleshooting when action costs are dependent with application to a truck engine,rejected,000
1203.3508.pdf.json,Merging Knowledge Bases in Possibilistic Logic by Lexicographic Aggregation,"Logic-based belief merging is an important topic in Artificial Intelligence and has application in many com- puter science fields, such as multi-agent systems and requirements engineering. In a logical framework, each information source is often considered as a knowledge base, which is a set of logical formulas. Even though each knowledge base is consistent, putting them together may give rise to logical contradiction. Since an inconsistent knowledge base is useless due to the fact “ex falso quodlibet” (a false statement implies an arbitrary statement), we need to resolve inconsistency when we merge knowledge bases. Furthermore, in practice, information is often pervaded with uncertainty. This is because the truth of some propositions may remain unknown in the presence of incomplete or partial information. Possibilistic logic [6] provides a flexible framework to handle inconsistency and deal with uncertainty. At the syntactic level, it is a weighted logic which attaches to each formula with a weight belonging to a totally ordered scale, such as [0, 1], where the weight is interpreted as the certainty level of the formula. A possibilistic knowledge base is a set of weighted formulas. At the semantic level, it is based on the notion of a possibility distribution, which is a mapping from the set of interpretations Ω to interval [0,1]. For each possibilistic knowledge base, there is a unique possibility distribution associated with it. Many merging approaches have been proposed in possibilistic logic [3, 4, 2, 5, 17, 14, 16, 12]. In [4, 2], given several possibilistic knowledge bases, a semantic combination rule (or merging operator) is applied to aggregate the possibility distributions associated with them into a new possibility distribution. Then the syntactical counterpart of the semantic merging of the possibility distributions is a possibilistic knowledge base whose associated possibility distribution is the new possibility distribution [2]. Several approaches (suc","An argumentation framework for merging conflicting knowledge bases: The prioritized case | Possibilistic merging and distance-based fusion of propositional information | Some syntactic approaches to the handling of inconsistent knowledge bases: A comparative study part 2: The prioritized case | A practical approach to fusing prioritized knowledge bases | Fusion of possibilistic knowledge bases from a postulate point of view | Possibilistic logic. In Handbook of logic in Aritificial Intelligence and Logic Programming, Volume 3, pages 439–513 | Quota and gmin merging operators | Lexicographic orders, utilities and decision rules: A survey | On the difference between merging knowledge bases and combining them | On the logic of merging | Merging information under constraints: A logical framework | Adaptive merging of prioritized knowledge bases | Fusion of Uncertain Information In the Framework of Possibilistic Logic | A model-based approach for merging prioritized knowledge bases in possibilistic logic | Merging stratified knowledge bases under constraints | Combining multiple prioritized knowledge bases by negotiation | A split-combination method for merging inconsistent possibilistic knowledge bases",rejected,000
1203.3512.pdf.json,Exact and Approximate Inference in Associative Hierarchical Networks using Graph Cuts,"The last few decades have seen the emergence of Markov networks or random fields as the most widely used probabilistic model for formulating problems in machine learning and computer vision. This interest has led to a large amount of work on the problem of estimating the maximum a posteriori (map) solution of a random field (Szeliski et al., 2006). However, most of this research effort has focused on inference over pairwise Markov networks. Of particular interest are the families of associative pairwise potentials (Taskar et al., 2004), in which connected variables are assumed to be more likely than not to share the same label. Inference algorithms targeting these associative potentials, which include truncated convex costs (Kumar and Torr, 2008), metrics (Boykov et al., 2001), and semi metrics (Kumar and Koller, 2009), often carry bounds which guarantee the cost of the solution found must lie within a bound, specified as a fixed factor of n of the cost of the minimal solution. Although higher order Markov networks (i.e. those with a clique size greater than two) have been used to obtain impressive results for a number of challenging problems in computer vision (Roth and Black, 2005; Komodakis and Paragios, 2009; Vicente et al., 2009; Ladicky et al., 2010), the problem of bounded higher order inference has been largely ignored. In this paper, we address the problem of performing graph cut based inference in a new model: the Associative Hierarchical Networks (ahns) (Ladicky et al., 2009), which includes the higher order Associative Markov Networks (amns) (Taskar et al., 2004) or Pn potentials (Kohli et al., 2007) and the Robust Pn (Kohli et al., 2008) model as special cases, and derive a bound of 4. This family of ahns have been successfully applied to diverse problems such as object class recognition, document classification and texture based video segmentation, where they obtain state of the art results. Note that in our earlier work Ladicky et al. (2009), the prob","Fast approximate energy minimization via graph cuts | Alphabet soup: A framework for approximate energy minimization | Exact optimization for markov random fields with convex priors | Robust higher order potentials for enforcing label consistency, in ‘CVPR | Convergent tree-reweighted message passing for energy minimization. | Comparison of energy minimization algorithms for highly connected graphs | Beyond pairwise energies: Efficient optimization for higher-order mrfs, in ‘CVPR09 | Factor graphs and the sum-product algorithm | MAP estimation of semi-metric MRFs via hierarchical graph cuts, in ‘Proceedings of the Conference on Uncertainity in Artificial Intelligence | Improved moves for truncated convex models, in ‘Proceedings of Advances in Neural Information | Associative hierarchical crfs for object class image segmentation, in ‘International | What, where and how many? combining object detectors and crfs, in ‘ECCV | Efficient belief propagation with learned higher-order markov random fields., in ‘ECCV | Efficient belief propegation for higher order cliques using linear constraint nodes | Fields of experts: A framework for learning image priors., in ‘CVPR | TextonBoost: Joint appearance, shape and context modeling for multi-class object recognition and segmentation | Tightening lp relaxations for map using message passing, in ‘UAI | A comparative study of energy minimization methods for markov random fields | Hop-map: Efficient message passing with high order potentials, in ‘Artificial Intelligence and Statistics | Flexible priors for exemplarbased clustering, in ‘Uncertainty in Artificial Intelligence (UAI) | Learning associative markov networks, in ‘Proc | Graph cut based optimization for mrfs with truncated convex priors | Joint optimization of segmentation and appearance models, in ‘ICCV | Graphical Models, Exponential Families, and Variational Inference | On the optimality of solutions of the max-product belief-propagation algorithm in arbitrary graphs. | High-arity interactions, polyhedral relaxations, and cutting plane algorithm for soft constraint optimisation (map-mrf), in ‘CVPR",rejected,000
1203.3513.pdf.json,Dynamic programming in influence diagrams with decision circuits,"Influence diagrams [Howard and Matheson, 1984] are popular graphical models for representing, evaluating and analyzing a single rational decision maker’s decision problem. We can exploit any separable value functions in influence diagrams for more efficient evaluation [Tatman and Shachter, 1990; Luque and Diez, 2009]. Decision circuits are graphical representations for efficient evaluation and sensitivity analysis on influence diagrams with a single value node [Bhattacharjya and Shachter, 2007, 2008, 2010]. In this paper, we show how they can be applied to influence diagrams with multiple value functions using join tree methods [Shachter and Peot, 1992; Dittmer and Jensen, 1994]. Arithmetic circuits [Darwiche, 2003] are graphical representations for probabilistic inference and sensitivity analysis in Bayesian belief networks. Decision circuits are a natural extension to arithmetic circuits for evaluating sequential decision problems represented as influence diagrams. Global structure refers to the topology of the graph, the size and the treewidth for a given task. Techniques have been developed to exploit global structure in the construction of arithmetic circuits applying logic [Darwiche, 2002; Chavira and Darwiche, 2005; Chavira, 2007] and join trees [Park and Darwiche, 2004]. We apply join tree methods, as well, but the arithmetic circuit approaches do not deal with the additional vertex elimination order restrictions in decision problems and complex accounting for separable value functions. To address these issues, we introduce a “branching operator” for decision circuits, use directed chordal graphs to develop our join tree structure, and introduce decision circuit backbones as a compact representation for symmetric decision circuits. Local structure in belief networks refers to the specific numbers, particularly zeros, in the conditional probability tables (CPTs). Like arithmetic circuits, decision circuits are compiled so that subsequent evaluation and analys","Decision Circuits: A graphical representation for efficient decision analysis computation, Ph.D Thesis, Stanford University | Evaluating influence diagrams with decision circuits | Sensitivity analysis in decision circuits | Three new sensitivity analysis methods for influence diagrams | A comparison of graphical techniques for asymmetric decision problems | Beyond treewidth in probabilistic inference, Ph.D Thesis, University of California, Los Angeles | Compiling Bayesian networks with local structure | A differential approach to inference in Bayesian networks | A logical approach to factoring belief networks | A differential approach to inference in Bayesian networks | Myopic value of information in influence diagrams | Algorithmic Graph Theory and Perfect Graphs, Academic Press, London | Decisiontheoretic foundations for causal reasoning | From influence diagrams to junction trees | Variable elimination for influence diagrams with super value nodes, Intl | Well-defined decision scenarios | A differential semantics for jointree algorithms, AI | Decision Analysis, Addison-Wesley, Reading, MA | Bayes-ball: The rational pastime (for determining irrelevance and requisite information in belief networks and influence diagrams) | Efficient value of information computation | Directed reduction algorithms and decomposable graphs | Decision making using probabilistic inference | Structuring conditional relationships in influence diagrams | Simple lineartime algorithms to test chordality of graphs, test acyclicity of hypergraphs, and selectively reduce acyclic hypergraphs | Dynamic programming and influence diagrams",rejected,000
1203.3525.pdf.json,Learning Why Things Change: The Difference-Based Causality Learner,"In the past 20 years in AI, the practice of learning causal models from data has received considerable attention [cf., Pearl and Verma, 1991, Cooper and Herskovits, 1992, Spirtes et al., 2000]. Existing methods ∗Also Department of Biomedical Informatics, School of Medicine, University of Pittsburgh. † Also Faculty of Computer Science, Bia lystok University of Technology, Wiejska 45A, 15-351 Bia lystok, Poland. are based on the formalism of structural equation models (SEMs), which originated in the econometrics literature over 50 years ago [cf., Strotz and Wold, 1960], and Bayesian networks [Pearl, 1987] which started the paradigm shift of graphical models in AI and machine learning 20 years ago. These methods have predominately focused on the learning of equilibrium (static) causal structure, and have recently gained inroads into mainstream scientific research, especially in biology [cf., Sachs et al., 2005]. Despite the success of these static methods, many realworld systems are dynamic in nature and are accurately modeled by systems of simultaneous differential equations. Temporal causality, in general, has been studied extensively in econometrics over the past four decades: Granger causality and vector autoregression (VAR) methods have become very influential [cf., Granger, 1969, Engle and Granger, 1987, Sims, 1980]. In AI, there has been work on learning Dynamic Bayesian Networks (DBNs) [Friedman et al., 1998] and modified Granger causality [Eichler and Didelez, 2007]. None of these models explicitly take into account the fact that many dynamic systems are based on differential equations. This makes their representations overly general for such systems, allowing arbitrary causal relations across time. In this paper, we show that differential equations impose strict constraints on crosstemporal causal edges, and we present a method that is capable of exploiting that fact. This paper considers Difference-Based Causal Models (DBCMs), a class of discrete-time dynami","A Bayesian method for the induction of probabilistic networks from data | Caveats for Causal Reasoning with Equilibrium Models | Restructuring dynamic causal systems in equilibrium. In AIStats, pages 81–88 | Causal reasoning in graphical time series models | Cointegration and error-correction: Representation, estimation, and testing | The Bayesian structural EM algorithm | Learning the structure of dynamic probabilistic networks. In UAI, pages 139–147 | Learning Gaussian networks | Measuring directional coupling between EEG sources | Investigating causal relations by econometric models and cross-spectral methods | Causality and model abstraction | Causality: Models, Reasoning, and Inference | Evidential reasoning using stochastic simulation of causal models",rejected,000
1203.3528.pdf.json,Rollout Sampling Policy Iteration for Decentralized POMDPs,"Planing under uncertainty in multi-agent settings is a challenging computational problem, particularly when agents with imperfect sensors and actuators, such as autonomous rovers or rescue robots, must reason about a large space of possible outcomes and choose a plan based on their incomplete knowledge. The partially observable Markov decision process (POMDP) has proved useful in modeling and analyzing this type of uncertainty in single-agent domains. When multiple cooperative agents are present, each agent must also reason about the decisions of the other agents and how they may affect the environment. Since each agent can only obtain partial information about the environment and sharing all the local information among the agents is often impossible, each agent must act based solely on its local information. These problems can be modeled as decentralized POMDPs (DEC-POMDPs) [2]. When a complete model of the domain is available, DECPOMDPs can be solved using a wide range of optimal or approximate algorithms, particularly MBDP [18] and its descendants [1, 8, 17]. Unfortunately, these algorithms are quite limited in terms of the size of the problems they can tackle. This is not surprising given that finite-horizon DECPOMDPs are NEXP-complete [2]. Intuitively, the main reason is that it is hard to define a compact belief state and compute a value function for DEC-POMDPs, as is often done for POMDPs. The state and action spaces blow-up exponentially with the number of agents. Besides, it is very difficult to search over the large policy space and find the best action for every possible situation. Another key challenge is modeling the dynamics of the entire domain, which may include complex physical systems. Existing DEC-POMDP algorithms assume that a complete model of the domain is known. This assumption does not hold in some real-world applications such as robot soccer. Incomplete domain knowledge is often addressed by reinforcement learning algorithms [19]. However, m",Incremental policy generation for finite-horizon DEC- POMDPs | The complexity of decentralized control of Markov decision processes | Bounded policy iteration for decentralized POMDPs | Rollout algorithms for combinatorial optimization | Parallel rollout for online solution of Dec-POMDPs | A comprehensive survey of multiagent reinforcement learning | Parallel rollout for online solution of partially observable Markov decision processes | Point-based incremental pruning heuristic for solving finite-horizon DEC-POMDPs | Rollout sampling approximate policy iteration | Approximate policy iteration with a policy language bias | Dynamic programming for partially observable stochastic games | Reinforcement learning as classification: Leveraging modern classifiers | Exploiting locality of interactions using a policy-gradient approach in multiagent learning | Taming decentralized POMDPs: Towards efficient policy computation for multiagent settings | Learning to cooperate via policy search | Bounded finite state controllers | Improved memorybounded dynamic programming for decentralized POMDPs | Memory-bounded dynamic programming for DEC-POMDPs | Reinforcement Learning: An Introduction | Conditional random fields for multi-agent reinforcement learning,rejected,000
1203.3531.pdf.json,Solving Multistage Influence Diagrams using Branch-and-Bound Search,"An influence diagram [7] is a compact representation of the relations among random variables, decisions, and preferences in a domain that provides a framework for decision making under uncertainty. Many algorithms have been developed to solve influence diagrams [2, 3, 8, 15, 17, 18, 19, 21]. Most of these algorithms, whether they build a secondary structure or not, are based on the bottom-up dynamic programming approach. They start by solving small low-level decision problems and gradually build on these results to solve larger problems until the solution to the global-level decision problem is found. The drawback of these methods is that they can waste computation in solving decision scenarios that have zero probability or that are unreachable from any initial state by following an optimal decision policy. This drawback can be overcome by adopting a branch-andbound approach to solving an influence diagram that uses a search tree to represent all possible decision scenarios. This approach can use upper bounds on maximum utility to prune branches of the search tree that correspond to lowquality decisions that cannot be part of an optimal policy; it can also prune branches that have zero probability. A branch-and-bound approach to influence diagram evaluation appears to have been first suggested by Pearl [16]. He proposed it as an improvement over the classic method of unfolding an influence diagram into a decision tree and solving it using the rollback method, which itself is a form of dynamic programming [7]. In Pearl’s words: A hybrid method of evaluating influence diagrams naturally suggests itself. It is based on the realization that decision trees need not actually be generated and stored in their totality to produce the optimal policy. A decision tree can also be evaluated by traversing it in a depth-first, backtracking manner using a meager amount of storage space (proportional to the depth of the tree). Moreover, branch-and-bound techniques can be employed to",An algorithm for finding minimum d-separating sets in belief networks | Evaluating influence diagrams with decision circuits | A method for using belief networks as influence diagrams | An anytime approximation for optimizing policies under uncertainty | Maximal flow through a network | An anytime algorithm for decision making under uncertainty | Influence diagrams | From influence diagrams to junction trees | Unconstrained influence diagrams | Representing and solving decision problems with limited information | Local computations with probabilities on graphical structures and their application to expert systems | A new approach to influence diagram evaluation | Welldefined decision scenarios | Computing bounds on expected utilities for optimal policies based on limited information | On representing and solving decision problems | Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference | A new method for influence diagram evaluation | Evaluating influence diagrams | Valuation based systems for Bayesian decision analysis | Efficient computation of jointree bounds for systematic MAP search | Probabilistic inference in influence diagrams,rejected,000
1203.3535.pdf.json,Multi-Domain Collaborative Filtering,"The amount of information available on the Internet is increasing at an astonishing rate, making information search a more and more challenging task. As such, recommendation plays an important role to bring items of potential interest to our attention. Some popular examples include systems for product recommendation in Amazon.com, movie recommendation in Netflix and MovieLens, and reference recommendation in CiteULike. Collaborative filtering (CF) is an effective recommendation approach based on the intuitive idea that the preference of a user can be predicted by exploiting the information about other users which share similar interests. In particular, CF techniques exploit past activities of the users, such as their transaction history or product satisfaction expressed in ratings, to predict the future activities of the users. In recent years, CF-based recommendation systems have become increasingly popular because it is generally much easier to collect the past activities of users than their profiles, partially due to privacy considerations. According to a survey on CF [26], different CF techniques can be classified into three categories: memorybased methods, model-based methods, and hybrid methods. Similar to the idea of nearest neighbor classification, memory-based methods make rating prediction based on the rating behavior of other items and users with similar interests. Some representative methods are [10, 23, 16]. One limitation of memory-based methods is that they require the rating data to be dense so that the similarity values can be estimated accurately. Unfortunately, this requirement is not realistic in many applications. To achieve better prediction performance and overcome the shortcomings of memory-based CF methods, model-based CF methods have been proposed and actively studied. Model-based CF techniques use the rating data to learn a model and then use the learned model to make predictions. Many learning models have been used for CF, such as Bayesia",Recommendation as classification: Using social and content-based information in recommendation | Learning collaborative information filters | Active collaborative filtering | Empirical analysis of predictive algorithms for collaborative filtering | Collaborative prediction using ensembles of maximum margin matrix factorizations | A rank minimization heuristic with application to minimum order system approximation | Log-det heuristic for matrix rank minimization with applications to hankel and euclidean distance matrices | Matrix variate distributions | Dependency networks for collaborative filtering and data visualization | An algorithmic framework for performing collaborative filtering | Preference-based graphic models for collaborative filtering | A bayesian approach toward active learning for collaborative filtering | Factorization meets the neighborhood: a multifaceted collaborative filtering model | Non-linear matrix factorization with gaussian processes | Transfer learning for collaborative filtering via a rating-matrix generative model | A collaborative filtering algorithm and evaluation metric that accurately model the user experience | Contentboosted collaborative filtering for improved recommendations | Collaborative filtering by personality diagnosis: A hybrid memoryand model-based approach | Probabilistic models for unified collaborative and content-based recommendation in sparse-data environments | Fast maximum margin matrix factorization for collaborative prediction | Probabilistic matrix factorization | Bayesian probabilistic matrix factorization using Markov chain Monte Carlo | Itembased collaborative filtering recommendation algorithms | Relational learning via collective matrix factorization | Maximummargin matrix factorization | A survey of collaborative filtering techniques | Probabilistic principal component analysis | Ordinal boltzmann machines for collaborative filtering | Large-scale collaborative prediction using a nonparametric random effects model | Collaborative ensemble learning: Combining collaborative and content-based information filtering via hierarchical bayes | Probabilistic memory-based collaborative filtering | Fast nonparametric matrix factorization for large-scale collaborative filtering,rejected,000
1203.3538.pdf.json,RAPID: A Reachable Anytime Planner for Imprecisely-sensed Domains,"One of the key questions in artificial intelligence research is how to make good decisions in large, stochastic, partially observable environments. Though generic optimal planning for finite-horizon partially observable Markov decision processes (POMDPs) is known to be PSPACEcomplete (Papadimitriou & Tsitsiklis, 1987), fortunately, some important POMDP domains have highly structured models. This insight has been used by previous researchers to design more efficient POMDP algorithms that leverage different types of structure. Focussing on domains that exhibit factored structure has led to POMDP planners that solve some of the largest POMDP problems in the litera- ture, including a hand washing assistance program (Boger et al., 2005) and a RoboCup rescue task (Paquet et al., 2005). Other recent work (Dai & Goldsmith, 2007; Dibangoye et al., 2009) has focused on domains where the flat state dynamics model limits the possible backtracking to earlier states, and showed that planning can be performed more efficiently when this topological structure is present. In this paper we focus on problems exhibiting both factored structure and a form of topological structure, and demonstrate that we can leverage these properties to scale to very large domains. Such properties are common in a number of important applications ranging from tutoring to dialogue systems. For example, some prior education studies coarsely approximate a student’s knowledge as a factored set of binary variables, one for each skill, and infers a precondition graph structure among skills (known as a “learning hierarchy”) from student data: see for example Gagneé’s and Briggs (1974) and Close and Murtagh (1986). Despite this structure, automated tutor action selection remains challenging as the factored state space may consist of hundreds of skills. In addition, the student state is not directly observable, but can be probed through the use of drill exercises and other student responses. Modelling a fairly sm",A decision-theoretic approach to task assistance for persons with dementia | Stochastic dynamic programming with factored representations | Structure and complexity in planning with unary operators | An analysis of the relationships among computation-related skills using a hierarchicalclustering technique | Knowledge tracing: Modeling the acquisition of procedural knowledge | Introduction to algorithms | Topological value iteration algorithm for Markov decision processes | Planning under time constraints in stochastic domains | Topological order planner for POMDPs | Principles of instructional design | Envelope-based planning in relational MDPs | Intelligent tutoring goes to school in the big city | SARSOP: Efficient point-based POMDP planning by approximating optimally reachable belief spaces | Developed of a learning hierarchy for the computational skills of fractional number subtraction | The complexity of Markov decision processes | An online POMDP algorithm for complex multiagent environments. AAMAS | Symbolic heuristic search value iteration for factored pomdps | Point-based POMDP algorithms: Improved analysis and implementation. UAI | An intraconcept analysis of rational number addition: A validation study,rejected,000
1203.4011.pdf.json,Understanding Sampling Style Adversarial Search Methods,"The recent introduction of the Upper Confidence bounds applied to Trees (UCT) method for adversarial game playing significantly improved the standard of computer Go programs (Gelly and Silver, 2007, 2008). In fact, it now appears that we may reach human-level performance in Go within the next decade, which is substantially sooner than anyone had predicted just a few years ago. The current developments are especially surprising given that the traditional minimax game tree search, which has yielded world-class play in Chess and many other games, does not scale to the domain of Go. Two issues hamper the application of minimax search to Go: a very high branching factor and the lack of a high-quality board evaluation function. A good board evaluation function is key in game tree search when one cannot reach terminal states in the game tree. UCT provides an effective way to address both these issues. The UCT algorithm (Kocsis and Szepesvári, 2006) is derived from a highly effective approach to solving the multi-armed bandit problem called UCB1 (Auer et al., 2002). The UCT sampling strategy strikes a provably optimal balance between exploration of new game states and exploitation, where lines of play that appear promising are repeatedly searched to deeper levels. This novel approach means that UCT can reach regions of the search space that are much deeper than the conventional iterative deepening minimax search, which has been the “gold standard” for Chess and other games. When UCT encounters a non-terminal leaf node, a random (or weakly informed) playout is typically used to provide some indication of the value of the state. As the designers of UCT for Go have observed, it is somewhat counter-intuitive that there is any useful information to be gained from having two weak players play out the game to completion from some intermediate state. After all, any real game between competent players will follow a very different overall trajectory than one between weak players. In","Finite-time analysis of the multiarmed bandit problem | An adaptive sampling algorithm for solving Markov decision processes | Monte Carlo tree search techniques in the game of Kriegspiel | Bandit algorithms for tree search | Efficient selection and backup operators in Monte-Carlo tree search | Simulation-based approach to general game playing | Combining online and offline knowledge in UCT | GIB: Steps toward an expert-level bridgeplaying program | Bandit based Monte-Carlo planning | Pathology on game trees revisited, and an alternative to minimaxing | On the nature of pathology in game searching | On adversarial search spaces and sampling-based planning | World-championship-caliber Scrabble",rejected,000
1203.4855.pdf.json,Texture Classification Approach Based on Combination of Edge & Co-occurrence and Local Binary Pattern,,"Texture Classification Based on Random Threshold Vector Technique | Texture classification by statistical learning from morphological image processing: application to metallic surfaces | An Innovative Technique of Stone Texture Classification Based on Primitive Pattern Units | A New Color-Texture Approach for Industrial Products Inspection | A Combined Color, Texture and Edge Features Based Approach for Identification and Classification of Indian Medicinal Plants”, International Journal of Computer Applications | Textural Features for Image Classification | A comparative study of texture measures with classification based on feature distributions | Consistent Gradient Operators | Texture classification by using advanced local binary patterns and spatial distribution of dominant patterns | An Isotropic 3×3 Gradient Operator, Machine Vision for Three – Dimensional Scenes | Object Enhancemet And Extraction, Picture Processing and Psychopictorics | Machine Perception of Three-Dimensional Solids, in optical and Electro-Optical Information Processing | Edge Detection Techniques - An Overview",rejected,000
1203.5452.pdf.json,Modeling of Mixed Decision Making Process,,"On the Convergence of Knowledge Management and Groupware | Mapping Knowledge Into A Database Model | and D | Cultural Barriers in Knowledge Sharing. E+M Ekonomics and Management, Liberec, 6(special issue) | and L | Experience Management: Foundations | What’s your strategy for managing knowledge? ” Harvard Business Review | Knowledge management in engineering design | Groupware: Some Issues and Experience | De l'interaction individuelle aux systèmes multiutilisateurs | Construction of shared knowledge in collaborative problem solving | CSCW: Four characters in search of a scontext | A Framework for Collaboration and Knowledge Management | Conception de collecticiels pour la gestion cooperative des connaissances | A Model of Collaborative Knowledge-Building | The collaborative knowledge sharing framework | Facilitating Collaborative Knowledge Construction | The Analysis on Collaborative Knowledge Creation in Supply chains | The New science of management decision. Prentice hall, Englewood-Cliffs | Des Systèmes Interactifs d’Aide à la Décision Aux Systèmes Coopératifs d’Aide à la Décision : Contributions conceptuelles et fonctionnelles. | Shared data modeling with UML-G",rejected,000
1203.5532.pdf.json,On the Use of Non-Stationary Policies for Infinite-Horizon Discounted Markov Decision Processes,,Neuro-Dynamic Programming | On the Sample Complexity of Reinforcement Learning,rejected,000
1203.6534.pdf.json,Global Preferential Consistency for the Topological Sorting-Based Maximal Spanning Tree Problema,"Given an undirected graph G = (V, E) with V the vertices and E the edges, a spanning tree x of G is a connected and acyclic partial graph of G. x is then always composed with |V| − 1 edges. We denote by SST(G) the spanning trees set of G. For short, we write: e ∈ x, with e ∈ E, to say: e is an edge of the spanning tree x. More generally, we will assimilate x to its edges set. The classical problem of maximum spanning tree (⇔ ST/Σu/OPT) is defined as follow: ST/Σu/OPT: Given an undirected graph G = (V, E) and a utility u(e) associated with each edge e ∈ E, the result is a feasible spanning tree x of G, maximizing the sum of utilities of edges in x, if such a tree exists. Otherwise, the result is ‘no’. Several consistency problems have been recently investigated on spanning trees. On the one hand, we note the consistency problem associated with feasible spanning trees of a graph [25]. Other investigations pointed out consistency associated with weighted spanning trees [8], and maximum spanning tree [9]. On the other hand, numerous local consistency problems combining classical spanning tree problems with other constraints have been investigated. For example, the diameter constrained minimum spanning tree problem (DCMST) [16]. Within non-conventional preferences, the situation is radically different. Very few consistency spanning tree problems have been investigated in literature. We cite a local consistency problem processed for the robust spanning tree problem with interval data (RSTID) [1]. Yet, the most of combinatorial problems from the real practical world require the modeling of imprecision or uncertainty, multiple divergent viewpoints and conflicts management, to wholly assess the solutions and to identify the best compromise ones. These singularities require more complex modeling of preferences [27, 21]. For now some decades, the OR/CP community scrutinizes combinatorial problems enabling non-conventional global preferences. Thus, we attended to the flowering ","A Constraint Satisfaction Approach to the Robust Spanning Tree Problem with Interval Data | The Complexity of Reasoning with Global Constraints | Semiring-Based CSPs and Valued CSPs: Frameworks | Preference-Based Constrained Optimization with Cp-nets | The Complexity of Multi- Constrained Spanning Tree Problems | Introduction to Algorithms | Graph Constraints in Constraint Programming: Weighted spanning trees | The Minimum Spanning Tree Constraint | An Annotated Bibliography of Multiobjective Combinatorial Optimisation | Topics on Domination in Directed Graphs | On Spanning Tree Problems with Multiple Objectives | Decision-Support with Preference Constraints | Preference-Based Problem Solving for Constraint Programming | Human Problem Solving | Constraint Programming for the Diameter Constrained Minimum Spanning Tree Problem, Electronic Notes in Discrete Mathematics | Preference-Based Search in State Space Graphs | A Preference-Based Approach to Spanning Trees and Shortest Paths Problems | P | The Two-Sided Matching | Aide Multicritère à la Décision: Méthodes et cas | Combinatorial Optimization: Polyhedra and Efficiency | Collective Choice and Social Welfare | Choice Functions: Rationality Re-examined | Rooted Tree and Spanning Tree Constraints | Constraint Solving in Uncertain and Dynamic Environments: a Survey | Multicriteria Decision Aid | Linear and Combinatorial Optimization in Ordered Algebraic Structures",rejected,000
1203.6716.pdf.json,Creating Intelligent Linking for Information Threading in Knowledge Networks,,"Rough Fuzzy MLP: Knowledge Encoding and Classification | Approaching the Interconnection of Heterogeneous Knowledge Bases on a Knowledge Grid | Informledge System: A modified Knowledge Network with Autonomous Nodes using Multi-lateral Links, International Conference, International Conference on Knowledge Engineering and Ontology Development, KEOD | Exploring the knowledge landscape: four emerging views of knowledge | A translation approach to portable ontology specifications | Knowledge Representation with Ontologies: The Present and Future | Towards a Standard Upper Ontology | Ontology Development Pitfalls | Ontology-based Knowledge Retrieval | Tracking the Emergence of Conceptual Knowledge during Human Decision Making | High-accuracy neurite reconstruction for high-throughput neuroanatomy",rejected,000
1204.0479.pdf.json,,"A coalition of decision makers with private information that requires collaborative production planning is considered. Each of the decision makers, hereafter referred to as agents, is selfish and seeks to implement his or her local optimal production plan to minimize his or her local costs. However, the agents could improve their situation by coordinating their individual production plans. The cost savings due to a better global production plan could be allocated to the agents in order to overcompensate them for deviating from their local optimal production plans. From a more general point of view, the problem of finding an appropriate allocation of cooperative gains is dealt with by cooperative game theory. The special situation of joint planning of selfish agents in case of private information considered here is the subject of collaborative operations planning (Dudek and Stadtler, 2005). The state of the art in collaborative planning is discussed by Frayret (2009) and by Stadtler (2009). Overviews of automated negotiation approaches relevant to collaborative planning are given by Lomuscio et al. (2003) and Ströbel and Weinhardt (2003). Applications of collaborative planning to supply chains are discussed by Ertogral and Wu (2000), and Fink (2004, 2006), for example. The proposed collaborative planning approach is applied to a distributed variant of the well-known multi level uncapacitated lot sizing problem (MLULSP) introduced by Yelle (1979). The distributed ∗Corresponding author. Email: tobias.buer@uni-bremen.de MLULSP (DMLUSLSP) was presented by Homberger (2010) and assumes several local and selfish agents with private information instead of a single agent with full information. The DMLULSP covers some important features of real world problems. There are several final products, a multi level production structure, and a trade-off between inventory and setup costs. Coordination is difficult, because there are agents with private information and conflicting object","Computational complexity of uncapacitated multi-echelon | An improved heuristic for multilevel lot sizing in material | Multiagent-based supply chain management, Chapter Supply chain coordination by means of automated negotiation between autonomous agents, pp. 351–372 | Barwertorientierte projektplanung mit mehreren akteuren mittels eines verhandlungsbasierten koordinationsmechanismus | oct.). A multidisciplinary review of collaborative supply chain planning | A parallel genetic algorithm for the multi-level unconstrained lot-sizing problem | Decentralized multi-level uncapacitated lot-sizing by automated negotiation | A generic coordination mechanism for lot-sizing in supply chains | An ant colony optimization approach for the multi-level unconstrained lot-sizing problem | A pheromone-based negotiation mechanism for lot-sizing in supply chains | An ant colony optimization-based negotation approach for lot-sizing in supply chains | Meta-heuristics for dynamic lot sizing: A review and comparison of solution approaches | A production-distribution coordinating model for third party logistics partnership | Decentralized supply chain coordination through auction markets: dynamic lot-sizing in distribution networks | Multiagent system approach for dynamic lot-sizing in supply chains, Chapter Trends in supply chain design and management - part II, pp. 311–330 | A classification scheme for negotiation in electronic commerce | A max-min ant system for unconstrained multi-level lot-sizing problems | A theory of justice | Statistical search methods for lotsizing problems | A framework for collaborative planning and state-of-the-art | Optimal multi-level lot sizing for requirements planning systems | The montreal taxonomy for electronic negotiations | Max-min ant system | The performance of a simple incremental lot-sizing rule in a multilevel inventory environment | Introduction to computational optimization models for production planning in a supply chain (2nd ed.) | The stochastic economic lot scheduling problem: A survey | A reduced variable neighborhood search algorithm for uncapacitated multilevel lot-sizing problems | Neighborhood search techniques for solving uncapacitated multilevel lot-sizing problems | Materials requirements lot sizing: A multilevel approach | Hierarchical coordination mechanisms within the supply chain",rejected,000
1204.0731.pdf.json,,,"GAC via unit propagation | Efficient CNF encoding of boolean cardinality constraints | New encodings of pseudo-boolean constraints into CNF | Arc consistency in SAT | The monotone and planar circuit value problems are log space complete for p | Unit refutations and horn sets | Universal booleanization of constraint models | Complete problems for deterministic polynomial time | Constraint Networks, Techniques and Algorithms | New encodings of pseudo-boolean constraints into cnf | Generalized arc consistency for global cardinality constraint | Towards an optimal CNF encoding of boolean cardinality constraints | The unit preference strategy in theorem proving",rejected,000
1204.1231.pdf.json,How Many Vote Operations Are Needed to Manipulate a Voting System?,"Voting is a popular method used to aggregate voters’ preferences to make a joint decision. Recently, voting has been used in many fields of artificial intelligence, for example in multi-agent systems [15], recommender systems [21, 32], and web-search engines [12]. One of the most desired properties for voting rules is strategy-proofness, that is, no voter has incentive to misreport her preferences to obtain a better outcome of the election. Unfortunately, strategy-proofness is not compatible with some other desired properties, due to the celebrated Gibbard-Satterthwaite theorem [22, 36], which states that when there are at least three alternatives, no strategy-proof voting rule satisfies the following two natural properties: non-imposition (every alternative can win) and non-dictatorship (no voter is a dictator, whose top ranked alternative is always selected to be the winner). Even though manipulation is inevitable, researchers have set out to investigate whether computational complexity can serve as a barrier against various types of strategic behavior, including manipulation. The idea is, if we can prove that it is computationally too costly for a strategic individual to find a beneficial operation, she may give up doing so. Initiated by Bartholdi, Tovey, and Trick [2], a fair amount of work has been done to characterize the computational complexity of various types of strategic behavior1, including the following. •Manipulation: a voter or a coalition of voters cast false vote(s) to change the winner (and the new winner is more preferred). • Bribery: a strategic individual changes some votes by bribing the voters to make the winner preferable to her [16]. The bribery problem is closely related to the problem of computing the margin of victory [5, 25, 47]. • Control: a strategic individual adds or deletes votes to make the winner more preferable to her [3]. Most previous results studying “using computational complexity as a barrier against strategic behavior” cond",,rejected,000
1204.1277.pdf.json,Mouse Simulation Using Two Coloured Tapes,"One of the important challenges in Human Computer Interactions is to develop more intuitive and more natural interfaces. Computing environments presently are strongly tied to the availability of a high resolution pointing device with a single, discrete two dimensional cursor. Modern Graphical user interface (GUI), which is a current standard interface on personal computers (PCs), is well-defined, and it provides an efficient interface for a user to use various applications on a computer. GUIs (graphical user interfaces) combined with devices such as mice and track pads are extremely effective at reducing the richness and variety of human communication down to a single point. While the utility of such devices in today’s interfaces cannot be denied, there are many users who find that the capability of GUI is rather limited when they try to do some tasks by using gestures. There are opportunities to apply other kinds of sensors and techniques to enrich the user experience of such users. For example, video cameras and computer vision techniques may be used to capture many details of human shape and movement. The shape of the hand may be analyzed over time to manipulate an onscreen object in a way analogous to the hand’s manipulation of paper on a desk. Such an approach may lead to a faster, more natural, and more fluid style of interaction for certain tasks. Ubiquitous computing is devoted to changing the relationship between humans and the computers with which we interact, towards allowing computers to become invisible and recede into the periphery of people’s lives. Our project, Mouse Simulation Using Two Coloured Tapes is an attempt in ubiquitous computing. Here, we will be using two colour tapes on our fingers. One of the tapes will be used for controlling cursor movement while the relative distance between the two coloured tapes will be used for click events of the mouse. Thus, the system will provide a new experience for users in interacting with the computer.","A Method for Controlling Mouse Movement using a Real-Time Camera,2008 | Computer vision based mouse, A | Real-time Hand Tracking and Finger Tracking for Interaction | Virtual mouse vision based interface | Fast tracking of hands and fingertips in infrared images for augmented desk interface | Shadow gestures: 3D hand pose estimation using a single camera",rejected,000
1204.1581.pdf.json,A new approach of designing Multi-Agent Systems,,"D.Sanchez, A.Moreno, “Organizational structures supported by agent-oriented methodologies | A Model Design of Multi-Agent Systems | Intelligent Agents, Multi agent systems, In The MIT Press, “A modern Approach to Distributed Artificial Intelligence | An Introduction to Multi-Agent | A practical application of a method of designing multi-agent systems based on the AUML language and the MDA approach | Evaluation of modeling techniques for agentbases systems | On agent-based software engineering | Intelligent agent: Theory and practice | Segrounichi, Intelligents agents, Agents Intelligents | The Gaia methodology: basic concepts and extensions | The INGENIAS methodology and tools | Multi-agent system development based on organizations | The MaSE methodology | Design Diagrams for Multi-agents Systems | Trencansky, “Agent Modeling Language (AML): A Comprehensive Approach to Modeling MAS | ASPECS: An Agent-oriented Software Process for Engineering Complex Systems: How to design agent societies under a holonic perspective | Methodological development of a multi-agent system in the healthcare domain | MAS methodology for HMS | From agents to organizations: an organizational view of multi-agent systems | Re-use of interaction protocols and Career-oriented models for multi-agents development, Réutilisation des protocoles d‟interaction et Démarche orientée modèles pour le développement multi-agents | Getting Started with AndroMDA for Java | A Model Design of Multi-Agents Systems”, in the International Conference on Models of Information and Communication Systems MICS‟10",rejected,000
1204.1596.pdf.json,An Intelligent Location Management approaches in GSM Mobile Network,"Recent advances in communication technology have created the opportunity for mobile terminals to receive many services that were, until not long ago, only available to tethered terminals. This system to support large scale mobility was the advanced mobile phone system. A new digital system, personal Communication System (PCS) provides voice as well as data services to wireless users. PCS works in the GSM 800/1900 MHz spectrum. There are competitive standards for analog, digital, and PCS system throughout the world [1]. One of the challenging tasks in a PCS environment is to efficiently maintain the location of the PCS subscribers in GSM who move around freely with their wireless unit. In India TRAI (Telephonic Regulatory Authority of India) is used for managing location information of the subscribers and enabling them to send and receive calls and other services such as messaging and data service. The cells are established as we have shown in figure 1, using which mobile subscribers move between them and he make calls for transmitting voice/data. The network reference model of a Personal Communication System in GSM network is shown in figure 2 we refined for supporting and understanding of my work .It consists of the following components [2]. Home Location Register (HLR): Maintains the profiles of the entire subscribers that are registered with the home network. When a mobile subscriber roams to another area, it has to register with the Visitor Location Register (VLR) of that area. The HLR maintains a pointer to the VLR which currently serve the mobile. Visitor Location Register (VLR): Supports registration, authentication, and call routing to/from a mobile while it is away from its home area. Each MSC has a VLR to holds the data relevant for handling calls from and to the MSs that are currently located in its area. The relevant data is downloaded from the home HLR when the mobile subscriber switches on the mobile handset in the area of the visited MSC thereby initi","Mobile cellular Communications: Analog and Digital systems, McGraw-Hill, Inc., 2 edition | Bernhard’s, “An estimate of network database transaction volume to support personal communication service | Mobility Management Using Frequently Visited Location Database | An efficient call Delivery algorithm in Hierarchical Cellular Networks | Intelligent Location Management Using Soft Computing Technique | Artificial Intelligence Based Authentication Technique with Three Entities in 3-G Mobile Communications | Intelligent Paging Based Mobile User Tacking Using Fuzzy Logic”, International Conference on methods and models in science and Technology, ISBN: 978-0-7354-0879-1 | Adaptive, Distributed Location Management in Mobile | TRAI, Telephonic Regulatory authority of India",rejected,000
1204.1637.pdf.json,Characterization of Dynamic Bayesian Network The Dynamic Bayesian Network as temporal network,,"Speech Recognition with Dynamic Bayesian networks,Bayesian networks | Variational Infererence in Probabilistic Models | Markov chain monte carlo in practice | Probabilistic reasoning in intelligent systems: Networks of plausible inference | S.Mian: Modelling Gene Expression Data using Dynamic Bayesian Natwork | An Introduction to Bayesian Network Theory and Usage | Time series classi_cation using mixed-state ynamic Bayesian networks | Compositional Modelling With DPNs | Probabilistic Independence Networks for Hidden Markov Probability Models | Dynamic Bayesian Networks: Representation, Inference and Leaning | Event-coupled hidden Markov models | Réseaux Bayésiens Dynamiques pour la Vérification du Locuteur | Input-Output HMMs for sequence processing | New approach using Bayesian Network to improve content based image classification systems | Clustering and Bayesian Network to improve content based image classification systems | kalti “Software Comparison dealing with Bayesian networks",rejected,000
1204.1653.pdf.json,,,,rejected,000
1204.1679.pdf.json,Clustering and Bayesian network for image of faces classification,,"On certain integrals of Lipschitz-Hankel type involving products of Bessel functions, | A bayesian network approach to multi-feature based image retrieval | A.A.‖A bayesian network model combining color, shape and texture information to improve content based image retrieval systems | New approach using Bayesian Network to improve content based image classification systems | Textural features for image database retrieval | Indexation et appariement d’images par modèle de mélange  gaussien des couleurs  | bakan Tree augmented naïve baysian classifier with feature selection for FRMI | Learning bayesian network is NP-complete, In Learning from data: artificial intelligence and statistics V, pages 121-130 | Tractable bayesian learning of tree augmented naïve bayes classifiers | Computational complexity of probabilistic inference using bayesian belief networks | Les relations spatiales : de la moélisation à la mise en oeuvre | Building classifiers using bayesian networks | De l’identification de structure de réseaux bayésiens à la reconnaissance de formes à partir d’informations complètes ou incomplètes | Learning the tree augmented naïve bayes classifier from incomplete datasets, LITIS Lab | Y.Lee, S.Lin. 2D C-Tree Spatial Representation for Iconic Image | A Discriminative Representation for Symbolic Image Similarity Evaluation | Réseaux Bayésiens : apprentissage et modélisation de systèmes complexes, novembre | Augmented naive bayesian classifiers for mixed-mode | P.H.Wuillemin, P.Leray, O.Pourret, A.Becker | Design and evaluation of spatial similarity approaches for image retrieval | Algorithmique pour les réseaux Bayésiens et leurs extensions | Highspeed face recognition based on discrete cosine transform and RBF neural networks‖ | Eigenfaces for recognition | Face Recognition using Boosted Local Features | 2D and 3D Multimodal Hybrid Face Recognition | Face Recognition: A Literature Survey | Component-based Face Recognition with 3D Morphable Models | A Wavelet-based Framework for Face Recognition. Workshop on advances in facial image analysis and recognition technology, 5 European conference on computer vision,1998 | Face Recognition Using Eigenfaces | Face Recognition by Independent Component Analysis | Eigenfaces vs | and M | Comparison of MLP and GMM classifiers for face verification on XM2VTS | A GMM Parts Based Face Representation for Improved Verification through Relevance Adaptation | Face Authentication Using Adapted Local Binary Pattern Histograms | N | Hidden Markov Models for Face Recognition | User Authentication via Adapted Statistical Models of Face Images | Hybrid Face Recognition Method using Markov Random Fields | Système d’identification de personnes par vision numérique | Automatic Video Based Face Verification and Recognition by Support Vector Machines | Real-time face detection and recognition using hybrid information extracted from face space and facial features | Towards Robust Face Recognition from Video | N-feature neural network human face recognition | Abdulredha, ―Face Detection Using DCT Coefficients in MPEG Video  | Venkatesh,‖ An integrated automatic face detection and recognition system | A neural network face recognition system | Contentbased indexing of images and video using face detection and recognition methods | Face recognition: a new feature selection and classification technique | Face Recognition Using the Discrete Cosine Transform | A tutorial on learning with Bayesian networks | Transformation Invariance in Pattern Recognition — Tangent Distance and Tangent Propagation",rejected,000
1204.1811.pdf.json,SKIN-COLOR BASED VIDEOS CATEGORIZATION,"Locating and tracking patches of skin-colored pixels through an image is a tool used in many face recognition and gesture tracking systems [13][8]. Skin information contributes much to object recognition [18]. One of the usage of skin color based tracking, locating and categorization could be blocking unwanted video contents on World Wide Web. On dedicated websites, people can upload videos and share it with the rest of the world. There are uploaded adult videos, which may not be allowed by the service providers. Therefore, how to effectively categorize and block such videos has been arousing a serious concern for the service providers. The mostly used approach to contents blocking on the Internet is based on contextual keyword pattern matching technology that categorizes URLs by means of checking contexts of web pages or video names and then traps the websites [11][15]. This does not hold true for websites which allow uploading videos like Google Videos and YouTube, because the videos uploaded have different names from the contents they contain. Due to no automated process, the Google and YouTube rely on user’s community. Therefore, an automated method to detect and categorize videos based on skin color will help the service providers and can provide control over the videos contents. According to Smeulders et. al [14] color has been an active area of research in image retrieval, more than in any other branch of computer vision. The interest in color may be ascribed to the superior discriminating potentiality of a three dimensional domain compared to the single dimensional domain of gray-level images [14]. The goal of our system is to categorize videos based on skin color. Depending on the percentage of skin in videos, the videos are flagged as Large-Skin-Videos (LSKIN), PartialSkin-Videos (PSKIN) and No-Skin-Videos (NSKIN). The set of videos used in our experiments consists of 30 videos, collected and provided by video service provider. The service provider defines",Comparing bayesian network classifiers | Bayesian network classifiers | El-Hafeez. An approach to image extraction and accurate skin detection from web pages | Stö  ttinger. Weighted skin color segmentation and detection using graph cuts | Skin detection: A random forest approach | Augmentation of skin segmentation | Universal seed skin segmentation | Color based skin classification | An adaptive multiple model approach for fast contentbased skin detection in on-line videos | An elliptical boundary model for skin color detection | Naked image detection based on adaptive and extensible skin color model. PR | The naked image detection based on automatic white balance method | A robust skin color based face detection algorithm | Content-based image retrieval at the end of the early years | Skin paths for contextual flagging adult videos | A survey on pixel-based skin color detection techniques | Exploring content-based and image-based features for nude image detection | Skin color detection using multiple cues | Adult image detection using statistical model and neural network | Blocking adult images based on statistical skin,rejected,000
1204.1851.pdf.json,A Probabilistic Logic Programming Event Calculus,"Systems for event recognition — ‘event pattern matching’, in the terminology of (Luckham 2002) — accept as input streams of sensor data in order to identify composite events of interest, that is, collections of events that satisfy some pattern. Consider, for example, the recognition of attacks on nodes of a computer network given the TCP/IP messages, the recognition of suspicious trader behaviour given the transactions in a financial market, the recognition of whale songs given a stream of whale sounds, and the recognition of human activities given multimedia content from surveillance cameras. A common approach to event recognition separates low-level from high-level recognition. In the case of human activity recognition, the output of the former type of recognition is a set of activities taking place in a short period of time: ‘short-term activities’ (STA). The output of the latter type of recognition is a set of ‘long-term activities’ (LTA), which are temporal combinations of STA. We focus on high-level recognition. ar X iv :1 20 4. 18 51 v2 [ cs .A We define a set of LTA of interest, such as ‘fighting’ and ‘meeting’, as temporal combinations of STA such as ‘walking’, ‘running’, and ‘inactive’ (standing still) using a logic programming (Prolog) implementation of the Event Calculus (EC) (Kowalski and Sergot 1986). We employ EC to express the temporal constraints on a set of STA that, if satisfied, lead to the recognition of a LTA. In earlier work (Artikis, Sergot and Paliouras (2010)) we identified various types of uncertainty that exist in activity recognition, such as erroneous STA detection. To address this issue, we extend our work by presenting Prob-EC, an EC dialect suitable for probabilistic activity recognition. Prob-EC operates on the state-ofthe-art probabilistic logic programming framework ProbLog (Kimmig et al. 2011). Prob-EC, therefore, may operate in settings where STA occurrences are assigned a confidence value by the underlying low-level tracking sy","Maintaining knowledge about temporal intervals | A logic programming approach to activity recognition | Run-time composite event recognition | Logic-based event recognition | Recognizing activities with multiple cues | Coupled Hidden Markov Models for complex action recognition | Probabilistic event logic for intervalbased event recognition | ProbLog technology for inference in a probabilistic first order logic | Graph-based algorithms for boolean function manipulation | Processing flows of information: From data stream to complex event processing | Chronicle recognition improvement using temporal focusing and hierarchisation | Inference in probabilistic logic programs using weighted CNF’s | The ecological approach to visual perception | Bilattices and modal operators | Recognition of group activities using dynamic probabilistic networks | Learning, detection and representation of multi-agent events in videos | Recognizing interleaved and concurrent activities: A statistical-relational approach | Large-scale event detection using semi-Hidden Markov Models | Why did the person cross the road (there)? scene understanding using probabilistic logic models and common sense reasoning | On the implementation of the probabilistic logic programming language ProbLog | Human behaviour classification using multiple views | A logic-based calculus of events | Conditional random fields: Probabilistic models for segmenting and labeling sequence data | Hierarchical conditional random fields for GPS-based activity recognition | The Power of Events: An Introduction to Complex Event Processing in Distributed Enterprise Systems | Learning relational affordance models for robots in multi-object manipulation tasks | Multi-agent event recognition in structured scenarios | Dynamic bayesian networks: representation, inference and learning | Hierarchical multi-channel semi Hidden Markov Models | An introduction to Hidden Markov Models | Markov logic networks | Location-based reasoning about complex multi-agent behavior | PEL-CNF: Probabilistic event logic conjunctive normal form for video interpretation | VidMAP: video monitoring of activity with Prolog | Bilattice-based logical reasoning for human detection | Grounding the lexical semantics of verbs in visual perception using force dynamics and event logic | Probabilistic event calculus based on markov logic networks | Event modeling and recognition using markov logic networks | Conditional random fields for activity recognition | The complexity of enumeration and reliability problems | Hybrid Markov logic networks | Joint recognition of multiple concurrent activities using factorial conditional random fields",rejected,000
1204.2018.pdf.json,Applications of fuzzy logic to Case-Based Reasoning,"Broadly construed Case-Based Reasoning (CBR) is the process of solving new problems based on the solution of past problems. The CBR systems’ expertise is embodied in a collection (library) of past cases rather, than being encoded in classical rules. Each case typically contains a description of the problem plus a solution and/or the outcomes. When a problem is successfully solved, the experience is retained in order to solve similar problems in future. When an attempt to solve a problem fails, the reason for the failure is identified and remembered in order to avoid the same mistake in future. Thus CBR is a cyclic and integrated process of solving a problem, learning from this experience, solving a new problem, etc. A case-library can be a powerful corporate resource allowing everyone in an organization to tap in the corporate library, when Subbotin & Voskoglou handling a new problem. CBR allows the case-library to be developed incrementally, while its maintenance is relatively easy and can be carried out by domain experts. As an intelligent-systems’ method CBR enables information managers to increase efficiency and reduce cost by substantially automating processes such as diagnosis, scheduling and design. CBR has been formalized for purposes of computer and human reasoning as a four steps process. These steps involve: R1: Retrieve the most similar to the new problem past case. R2: Reuse the information and knowledge of the retrieved case for the solution of the new problem. R3: Revise the proposed solution. R4: Retain the part of this experience likely to be useful for future problemsolving. Riesbeck and Bain [11], Slade [12], Lei et al. [9], Aamodt and Plaza [1], Voskoglou ([17], [20]), etc have provided detailed flowcharts illustrating the steps of the CBR process.","Case-Based Reasoning: Foundational Issues, Methodological Variations, and System Approaches | Fuzzy Logic Inference Model for a Rule-Based System in Medical Diagnosis | Introduction to the Use of the Fuzzy Logic in the Assessment of Mathematics Teachers, Proceedings 1  st Mediterranean | Fuzzy logic and Control, Prentice-Hall | Fuzzy Sets, Uncertainty and Information, Prentice-Hall, London | Principles of Uncertainty: What are they? Why do we mean them | Applying case-based reasoning to cold forcing process planning | Mathematizing the Van Hiele Levels: A Fuzzy Set Approach | A Methodology for Implementing Case- Based Reasoning Systems, Technical Report, Lockheed | Case-Based Reasoning: A Research Paradigm | Application of Fuzzy Logic to Learning Assessment, Didactics of Mathematics: Problems and Investigations | Fuzzy Logic and Learning Assessment | Fast and accurate center of gravity defuzzification of fuzzy system outputs defined on trapezoidal fuzzy partitions | The Process of Learning Mathematics: A Fuzzy Set Approach, Heuristics and Didactics of Exact Sciences | Case-Based Reasoning: A recent theory for problemsolving and learning in computers and people | Fuzzy sets in Case-Based reasoning | Transition Across Levels in the Process of Learning, Journal of Mathematical Modelling and Application (University of Blumenau | Case-Based Reasoning: History, Methodology and Development Trends | Mathematizing the Case-Based Reasoning process | Stochastic and fuzzy models in Mathematics Education, Artificial Intelligence and Management, Lambert Academic Publishing, Saarbrucken, Germany ( look at http://amzn.com./3846528218 | Fuzzy Logic Simplifies Complex Control Problems",rejected,000
1204.2235.pdf.json,"Publishing Identifiable Experiment Code And Configuration Is Important, Good and Easy","A few months ago, a graduate student in another country called me (Vaughan) to ask for the source code of one of my multi-robot simulation experiments. The student had an idea for a modification that she thought would improve the system’s performance. By the standards of scientific practice this was a perfectly reasonable request and I felt obliged to give it to her. With our original code, the student could (i) re-run our experiments to verify that we reported the results correctly; (ii) inspect the code to make sure that it actually implements the algorithm described in our paper; (iii) change parameters and initial conditions to make sure our results were not a fluke of the particular experimental setting; (iv) modify the robot controllers and quantitatively compare her new method with our originals. It would cost me nothing to make her a copy of our code, and her methodology would be impeccable. Why then do we read so few papers using this methodology? It turned out to be impossible to identify exactly which code was used to perform the experiments in our years-old paper. We had not labeled the source code at that moment, and it had subsequently been modified. All the code was under version control, so we could obtain approximately the right code by looking at revision dates. But having only approximately the right code strictly invalidates the replication of the experiments. The user has no way of knowing what the differences are between the code she has and the code we used. So we were able to offer the requesting student some code that may or may not be that used in the paper. This was better than nothing, but not good enough, and we suspect this is quite typical in our community. This disappointing episode was a wake-up call for me, and our group has been discussing how we can make sure this doesn’t happen again. We propose to routinely publish the exact code for each experiment that we use to justify any claims at all. This paper explains why we think compl",Literate Programming | Sharing Publication-Related Data and Materials: Responsibilities of Authorship in the Life Sciences | What is a citation worth | Citation advantage of open access articles | Perspectives on standardization in mobile robot programming: The Carnegie Mellon navigation (CARMEN) toolkit | Most valuable player: A robot device server for distributed control | Responging to fraud | Reproducible research: moving toward research the public can really trust | Post-publication sharing of data and tools | Data sharing: Empty archives | Doing science in the open | Sharing detailed research data is associated with increased citation rate | RFC3174: US Secure Hash Algorithm 1 (SHA1) | Making scientific computations reproducible | How to break md5 and other hash functions,rejected,000
1204.2248.pdf.json,Robust Spatio-Temporal Signal Recovery from Noisy Counts in Social Media,"Many real-world phenomena of interest to science are spatio-temporal in nature. They can be characterized by a real-valued intensity function f ∈ R≥0, where the value fs,t quantifies the prevalence of the phenomenon at location s and time t. Examples include wildlife mortality, algal blooms, hail damage, and seismic intensity. Direct instrumental sensing of f is often difficult and expensive. Social media offers a unique sensing opportunity for such spatio-temporal signals, where users serve the role of “sensors” by posting their experiences of a target phenomenon. For instance, social media users readily post their encounters with dead animals: “I saw a dead crow on its back in the middle of the road.” There are at least three challenges faced when using human social media users as sensors: 1. Social media sources are not always reliable and consistent, due to factors including the vagaries of language and the psychology of users. This makes identifying topics of interest and labeling social media posts extremely challenging. 2. Social media users are not under our control. In most cases, users cannot be directed or focused or maneuvered as we wish. The distribution of human users (our sensors) depends on many factors unrelated to the sensing task at hand. ar X iv :1 20 4. 22 48 v1 [ cs .A I] 1 0 A pr 2 3. Location and time stamps associated with social media posts may be erroneous or missing. Most posts do not include GPS coordinates, and self-reported locations can be inaccurate or false. Furthermore, there can be random delays between an event of interest and the time of the social media post related to the event. Most prior work in social media event analysis has focused on the first challenge. Sophisticated natural language processing techniques have been used to identify social media posts relevant to a topic of interest [32, 3, 25] and advanced machine learning tools have been proposed to discover popular or emerging topics in social media [1, 18, 33]. We di","Topic Detection and Tracking: Event-Based Information Organization | Influence and correlation in social networks | Beyond trending topics: Real-world event identification on twitter | Latent dirichlet allocation | Emerging topic detection on twitter based on temporal and social terms evaluation | Event detection from flickr data through wavelet-based spatial analysis | Spectral graph theory, Regional Conference Series in Mathematics, No. 92 | Concentration inequalities of the cross-validation estimate for stable predictors | Feedback effects between similarity and social influence in online communities | Mark my words!: linguistic style accommodation in social media | Density estimation by wavelet thresholding | OMG earthquake! Can Twitter improve earthquake response | A latent variable model for geographic lexical variation | Finding scientific topics | Finding hierarchy in directed online social networks | Life in the network: the coming age of computational social science | Pet: a statistical model for popular events tracking in social communities | A probabilistic approach to spatiotemporal theme pattern mining on weblogs | Statistical inference and simulation for spatial point processes. Monographs on statistics and applied probability | Numerical optimization. Springer series in operations research | Digital distribution maps of the mammals of the western hemisphere, version 3.0 | Detecting controversial events from twitter | Extracting events and event descriptions from twitter | Mining blog stories using communitybased and temporal clustering | Earthquake shakes twitter users: realtime event detection by social sensors | Closing the Loop: Fast, Interactive Semi-Supervised Annotation With Queries on Features and Instances | Unified cross-validation methodology for selection among estimators and a general cross-validated adaptive epsilon-net estimator: Finite sample oracle inequalities and examples | A statistical model for positron emission tomography | Jasmine: a real-time local-event detection system based on geolocation information propagated to microblogs | Event detection in twitter | Multiscale poisson intensity and density estimation | A study of retrospective and on-line event detection | Geographical topic discovery and comparison",rejected,000
1204.2712.pdf.json,Learning to Rank Query Recommendations by Semantic Similarity,,Simrank++: query rewriting through link analysis of the click | Extracting semantic relations from query logs | Improving search engines by query clustering | Agglomerative clustering of a search engine query log | From ”dango” to ”japanese cakes”: Query reformulation models and patterns | Context-aware query suggestion by mining click-through and session data | Random walks on the click graph | A model to estimate intrinsic  document relevance from the clickthrough logs of a web search engine | Recommending Better Queries from Click-Through Data | Concept-based interactive query expansion | Greedy function approximation: A gradient boosting machine | Combining evidence for automatic web session identification | Patterns of query reformulation during web searching | Accurately interpreting clickthrough data as implicit feedback | Generating query substitutions | Searching heterogeneous collections on the web: behaviour of excite users | To personalize or not to personalize: modeling queries with variation in user intent | Optimizing web search using web click-through data,rejected,000
1204.2713.pdf.json,Enabling Semantic Analysis of User Browsing Patterns in the Web of Data,"Understanding of user behavior in accessing Web resources is a powerful tool for Web sites providers to improve their applications, the design and content of the Web sites, to analyze users’ navigation intentions and respectively improve search or build adaptive sites. Furthermore, it helps to build recommendation systems that suggest users future actions based on their past behavior. The benefits of analyzing usage behavior analysis has been driving continuous research in the realm of Web Usage Mining, which aims at discovering navigation patterns from the logs of HTTP requests of pages and Web resources from the visitors of the sites. Due to the primarily syntactical nature of such resources, the representation of users’ requests lacks a semantic formalization. This makes the comprehension of the mined patterns difficult. A useful step towards a better interpretation and analysis of the usage patterns is to formalize the semantics of Web resources and user browsing behavior. We focus on this problem and present in this paper an approach for the semantic formalization of user Web browsing activity. It lays the basis for effective techniques of querying expressive usage patterns, as well as more intelligent mining and recommendation methods. In our approach, we map the records of usage logs issued by human visitors to meaningful events of the application domain where they were triggered. Therefore, instead of a syntactic representation, we now provide a semantic, formal description of each log by mapping it to concepts of a vocabulary of the domain knowledge. Instead of using flat taxonomies to represent such vocabulary, we address the use of ontologies to structure domain concepts and relations, ensuring a rich semantic model of the Web site content. Nowadays there is an increasing number of semanticallyenabled Web sites, which provide an ontology for the representation of their content and belonging Web resources. In this work, we assume that the domain ontology i","A Goal Specification Language for Automated Discovery and Composition of Web Services | Making Web services tradable - A policy-based approach for specifying preferences on Web service properties | LTL over Description Logic Axioms | USEWOD2012 - 2nd International Workshop on Usage Analysis and The Web of Data | A Model of Web Site Browsing Behavior Estimated on Clickstream Data | Characterizing browsing strategies in the world-wide web | Models of searching and browsing: Languages, studies, and application | The even more irresistible SROIQ | Results on the propositional mu-calculus | Temporal description logics: A survey | Using domain ontology for semantic web usage mining and next page prediction | A framework for mining meaningful usage patterns within a semantically enhanced web portal | Identifying web browsing trends and patterns | Conceptual user tracking | Modeling browsing behavior at multiple websites | Usage mining for and on the semantic web | Ontology-based filtering mechanisms for web usage patterns retrieval | Using ontology and sequence information for extracting behavior patterns from web navigation logs",rejected,000
1204.2718.pdf.json,Leveraging Usage Data for Linked Data Movie Entity Summarization,"Linked Data, which connects different pieces of machinereadable information (resources) via machine-readable relationships (properties) has rapidly grown in the past years, changing the way data is published and consumed on the Web. Data referring to real-world entities is being linked resulting into vast network of structured, interlinked descriptions that can be used to infer new knowledge. The rapid growth of Linked Data (LD) introduces however a set of new challenges. One in particular becomes very important when it comes to characterizing real world entities: their LD descriptions need to be processed and understood quickly and effectively. The problem known as entity summarization [5] is concerned with identifying the most important features of lengthy LD or Linked Open Data (LOD)1 descriptions. Solutions to this problem help applications and users of LD to quickly and effectively understand and work with the vast amount of data from LOD cloud. In this paper we propose a novel approach that leverages usage data in order to summarize entities in the LOD space. More precisely, we perform data analysis on LD in order to identify features of entities that best characterize them. Our approach is simple and effective. We first measure similarities between entities and identify a set of nearest neighbors for each entity. For each feature of the entity we then count the number of entities having the same feature in the nearest neighbors group as well as in the set of all entities. Based on this we compute a weight for each entity, order the entities descending and select the top-n features as the summarization for each entity. To validate our approach we run a set of experiments using two datasets, namely the HetRec2011 MovieLens2k dataset [4] and data crawled from Freebase.2 Results obtained from these datasets show that our approach is capable to identify relevant features that are shared with similar entities and thus provide meaningful summarizations. The remainde",Toward the Next Generation of Recommender Systems: A Survey of the State-of-the-Art and Possible Extensions | Latent dirichlet allocation | The anatomy of a large-scale hypertextual Web search engine | 2nd Ws. on Information Heterogeneity and Fusion in Recommender Systems (HetRec 2011) | RE- LIN: relatedness and informativeness-based centrality for entity summarization | Using ontologies to discover domain-level web usage profiles | Hierarchical Link Analysis for Ranking Web Data | Accurate Methods for the Statistics of Surprise and Coincidence | A maximum entropy web recommendation system: combining collaborative and content features | Employing a domain ontology to gain insights into user behaviour | Feature-Weighted User Model for Recommender Systems,rejected,000
1204.2741.pdf.json,"Simultaneous Object Detection, Tracking, and Event Recognition","Many common approaches to event recognition (Siskind and Morris, 1996; Starner et al., 1998; Wang et al., 2009; Xu et al., 2002, 2005) classify events based on their motion profile. This requires detecting and tracking the event participants. Adaptive approaches to tracking (Yilmaz et al., 2006), e.g. Kalman filtering (Comaniciu et al., 2003), suffer from three difficulties that impact their utility for event recognition. First, they must be initialized. One cannot initialize on the basis of motion since many event participants move only for a portion of the event, and sometimes not at all. Second, they exhibit drift and often must be Additional images and videos as well as all code and datasets are available at http://engineering.purdue. edu/˜qobi/arxiv2012a. periodically reinitialized to compensate. Third, they have difficulty tracking small, deformable, or partially occluded objects as well as ones whose appearance changes dramatically. This is particularly of concern since many events, e.g. picking things up, involve humans interacting with objects that are sufficiently small for humans to grasp and where such interaction causes appearance change by out-of-plane rotation, occlusion, or deformation. Detection-based tracking is an alternate approach that attempts to address these issues. In detection-based tracking an object detector is applied to each frame of a video to yield a set of candidate detections which are composed into tracks by selecting a single candidate detection from each frame that maximizes temporal coherency of the track. However, current object detectors are far from perfect. On the PASCAL VOC Challenge, they typically achieve average precision scores of 40% to 50% (Everingham et al., 2010). Directly applying such detectors on a per-frame basis would be ill-suited to event recognition. Since the failure modes include both false positives and false negatives, interpolation does not suffice to address this shortcoming. A better approach is to co","An inequality and associated maximization technique in statistical estimation of probabilistic functions of a Markov process | Statistical inference for probabilistic functions of finite state Markov chains | A maximization technique occuring in the statistical analysis of probabilistic functions of Markov chains | Efficient algorithms for finding the K best paths through a trellis | Kernel-based object tracking | URL http://www.cse.buffalo. edu/ ̃jcorso/bigshare/mindseye_human_ annotation_may11_buffalo.tar.bz | The PASCAL Visual Object Classes (VOC) challenge | Distance transforms of sampled functions | Cascade object detection with deformable part models | Object detection with discriminatively trained part based models | Fast algorithms for large-state-space HMMs with applications to web usage analysis | Orientation histograms for hand gesture recognition | Objects in action: an approach for combining action understanding and object perception | A generic approach to simultaneous tracking and verification in video | Key object driven multi-category object recognition, localization, and tracking using spatiotemporal context | Exploting human actions and object context for recognition tasks | A threshold selection method from gray-level histograms | Combining image regions and human activity for indirect object recognition in indoor wide-angle views | Globally-optimal greedy algorithms for tracking a variable number of objects | URL https://s3.amazonaws.com/ Annotations/vaticlabels_C-D1_0819.tar.gz | Spatiotemporal contour grouping using abstract part models | Good features to track | A maximum-likelihood approach to visual event classification | Real-time American sign language recognition using desk and wearable computer based video | Detection and tracking of point features | Convolutional codes and their performance in communication systems | Event recognition with time varying hidden Markov model | Finding the best set of K paths through a trellis with application to multitarget tracking | Motion based event recognition using HMM | An HMM-based framework for video semantic analysis | Object tracking: A survey",rejected,000
1204.2742.pdf.json,Video In Sentences Out,"We present a system that produces sentential descriptions of short video clips. These sentences describe who did what to whom, and where and how they did it. This system not only describes the observed action as a verb, it also describes the participant objects as noun phrases, properties of those objects as adjectival modifiers in those noun phrases, the spatial relations between those participants as ∗Corresponding author. Email: andrei@0xab.com. Additional images and videos as well as all code and datasets are available at http://engineering.purdue. edu/˜qobi/arxiv2012b. coordination: and verbs: approached, arrived, attached, bounced, buried, carried, caught, chased, closed, collided, digging, dropped, entered, exchanged, exited, fell, fled, flew, followed, gave, got, had, handed, hauled, held, hit, jumped, kicked, left, lifted, moved, opened, passed, picked, pushed, put, raised, ran, received, replaced, snatched, stopped, threw, took, touched, turned, walked, went nouns: bag, ball, bench, bicycle, box, cage, car, cart, chair, dog, door, ladder, left, mailbox, microwave, motorcycle, object, person, right, skateboard, SUV, table, tripod, truck adjectives: big, black, blue, cardboard, crouched, green, narrow, other, pink, prone, red, short, small, tall, teal, toy, upright, white, wide, yellow prepositions: above, because, below, from, of, over, to, with lexical PPs: downward, leftward, rightward, upward determiners: an, some, that, the particles: away, down, up pronouns: itself, something, themselves adverbs: quickly, slowly auxiliary: was Table 1: The vocabulary used to generate sentential descriptions of video. prepositional phrases, and characteristics of the event as prepositional-phrase adjuncts and adverbial modifiers. It incorporates a vocabulary of 118 words: 1 coordination, 48 verbs, 24 nouns, 20 adjectives, 8 prepositions, 4 lexical prepositional phrases, 4 determiners, 3 particles, 3 pronouns, 2 adverbs, and 1 auxiliary, as illustrated in Table 1. Produc","AAAI Workshop on Language-Action Tools for Cognitive Artificial Agents: Integrating Vision | People-tracking-bydetection and people-detection-by-tracking | Actions as space-time shapes | Learning and recognizing human dynamics in video sequences | Describing objects by their attributes | Cascade object detection with deformable part models | Object detection with discriminatively trained part based models | Towards 3-d model-based tracking and recognition of human movement | Logic and conversation | Object, scene and actions: Combining multiple features for human action recognition | Semantics and Cognition | Baby talk: Understanding and generating simple image descriptions | Local velocity-adapted motion events for spatio-temporal recognition | Learning realistic human actions from movies | Recognizing realistic actions from videos “in the wild | Integration of Natural Language and Vision Processing, volume I–IV | Unsupervised learning of human action categories using spatial-temporal words | A threshold selection method from gray-level histograms | Learnability and Cognition | Action MACH: A spatio-temporal maximum average correlation height filter for action recognition | Recognizing human actions: A local SVM approach | A 3-dimensional SIFT descriptor and its application to action recognition | Good features to track | HumanEva: Synchronized video and motion capture dataset and baseline algorithm for evaluation of articulated human | A maximum-likelihood approach to visual event classification | Realtime American sign language recognition using desk and wearable computer based video | Detection and tracking of point features | Convolutional codes and their performance in communication systems | Human action recognition by semilatent topic models | Motion based event recognition using HMM | Articulated pose estimation using flexible mixtures of parts | I2t: Image parsing to text description",rejected,000
1204.2801.pdf.json,Seeing Unseeability to See the Unseeable,"[T]here are known knowns; there are things we know we know. We also know there are known unknowns; that is to say we know there are some things we do not know. But there are also unknown unknowns–the ones we don’t know we don’t know. Donald Rumsfeld (12 February 2002) Additional images and videos as well as all code and datasets are available at http://engineering.purdue. edu/˜qobi/arxiv2012c. People exhibit the uncanny ability to see the unseeable. The colloquial exhortation You have eyes in the back of your head! expresses the assessment that someone is making correct judgements as if they could see what is behind them, but obviously cannot. People regularly determine the properties of occluded portions of objects from observations of visible portions of those objects using general world knowledge about the consistency of object properties. Psychologists have demonstrated that the world knowledge that can influence perception can be high level, abstract, and symbolic, and not just related to low-level image properties such as object class, shape, color, motion, and texture. For example, Freyd et al. (1988) showed that physical forces, such as gravity, and whether such forces are in equilibrium, due to support and attachment relations, influences visual perception of object location in adults. Baillargeon (1986, 1987) showed that knowledge of substantiality, the fact that solid objects cannot interpenetrate, influences visual object perception in young infants. Streri and Spelke (1988) showed that knowledge about object rigidity influences both visual and haptic perception of those objects in young infants. Moreover, such influence is cross modal: observable haptic perception influences visual perception of unobservable properties and observable visual perception influences haptic perception of unobservable properties. Wynn (1998) showed that material properties of objects, such as whether they are countable or mass substances, along with abstract properties, such ","Learning grammatical models for object recognition. In Logic and Probability for Scene Interpretation, number 08091 in Dagstuhl Seminar | Representing the existence and the location of hidden objects: Object permanence in 6- and 8month-old infants | Active perception | An inequality and associated maximization technique in statistical estimation of probabilistic functions of a Markov process | A maximization technique occuring in the statistical analysis of probabilistic functions of Markov chains | Recognition-by-components: A theory of human image understanding | Geometric reasoning for single image structure recovery | A dynamic bayesian network model for autonomous 3d reconstruction from a single indoor image | Maximum likelihood from incomplete data via the EM algorithm (with discussion) | Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography | Representing statics as forces in equilibrium | Blocks world revisited: Image understanding using qualitative geometry and mechanics | Learning spatial context: Using stuff to find things | Recovering occlusion boundaries from an image | An automatic method of solving discrete programming | A language and a program for stating and solving combinatorial problems | Consistency in networks of relations | Using contours to detect and localize junctions in natural images | Occlusions as a guide for planning the next view | Active object recognition by view integration and reinforcement learning | Active recognition through next view planning: a survey | Grammar-based object representations in a scene parsing task | Learning 3-d scene structure from a single still image | Make3d: Learning 3d scene structure from a single still image | Normalized cuts and image segmentation | A visual language model for estimating object pose and structure in a generative visual domain | Haptic perception of objects in infancy | A survey of sensor planning in computer vision | Psychological foundations of number: Numerical competence in human infants | What can missing correspondences tell us about 3d structure and motion | A stochastic grammar of images",rejected,000
1204.3040.pdf.json,Tractable Answer-Set Programming with Weight Constraints: Bounded Treewidth is not Enough,"Answer-set programming (ASP) has evolved as a paradigm that allows for very elegant solutions to many combinatorial problems [14]. The basic idea is to describe a problem by a logic program in such a way that the stable models correspond to the solutions of the considered problem. By extending logic programs with cardinality or, more generally, weight constraints, an even larger class of problems is accessible to this method [16]. For instance, in the product configuration domain, we need to express cardinality, cost, and resource constraints, which are very difficult to capture using logic programs without weights. In this paper, we restrict ourselves to normal logic programs with cardinality constraints (PCCs, for short) or weight constraints (PWCs, for short). Clearly, all common algorithmic tasks related to PCCs and PWCs – like checking the consistency of a program – are intractable, since intractability even holds without such constraints. An interesting approach to dealing with intractable problems comes from parameterized complexity theory and is based on the following observation: Many hard problems become tractable if some parameter that represents a structural aspect of the problem instance is small. One important parameter is treewidth, which measures the “tree-likeness” of a graph or, more generally, of a structure. In the area of knowledge representation and reasoning (KR & R), many tractability results for instances of bounded treewidth have been recently proven [8]. The goal of this work is to obtain tractability results via bounded treewidth also for PCCs and PWCs. Hereby, the treewidth of a PCC or PWC is ∗To appear in Theory and Practice of Logic Programming (TPLP). A preliminary version appeared in the Proceedings of the Twelfth International Conference on Principles of Knowledge Representation and Reasoning (KR 2010). †Supported by the Austrian Science Fund (FWF): P20704-N18. ‡Supported by the European Research Council (ERC), project 239962. §Supp","A linear-time algorithm for finding tree-decompositions of small treewidth | Safe separators for treewidth | Combinatorial optimization on graphs of bounded treewidth | Recognizability and second-order definability for sets of finite graphs | Heuristic methods for hypertree decomposition | Parameterized Complexity | Parameterized Complexity Theory | Bounded treewidth as a key to tractability of knowledge representation and reasoning | Answer-set programming with bounded treewidth | Pushing the power of stochastic greedy ordering schemes for inference in graphical models | Treewidth, Computations and Approximations | Treewidth: Computational experiments | Level mapping induced loop formulas for weight constraint and aggregate programs | Stable models and an alternative logic programming paradigm | Invitation to Fixed-Parameter Algorithms | Stable model semantics of weight constraint rules | Not so easy problems for tree decomposable graphs. In Advances in discrete mathematics and applications: Mysore, 2008, volume | Monadic second order logic on graphs with local cardinality constraints | Safe reduction rules for weighted treewidth",rejected,000
1204.3255.pdf.json,Lower complexity bounds for lifted inference,"Probabilistic logic models (a.k.a. probabilistic or statistic relational models) provide high-level representation languages for probabilistic models of structured data (Breese 1992; Poole 1993; Sato 1995; Ngo et al. 1995; Jaeger 1997; Friedman et al. 1999; Kersting and Raedt 2001; Milch et al. 2005; Vennekens et al. 2006; Taskar et al. 2002; Richardson and Domingos 2006). While supporting model specifications at an abstract, first-order logic level, inference is typically performed at the level of concrete ground instances of the models, i.e., at the propositional level. This mismatch between model specification and inference methods has been noted early on (Jaeger 1997), and has given rise to numerous proposals for inference techniques that operate at the high level of the underlying model specifications (Poole 2003; de Salvo Braz et al. 2005; Milch et al. 2008; Kisyński and Poole 2009; Jha et al. 2010; Gogate and Domingos 2011; Van den Broeck et al. 2011; Van den Broeck 2011; Fierens et al. 2011). Inference methods of this nature have collectively become known as “lifted” inference techniques. The concept of lifted inference is mostly introduced on an informal level: “...lifted, that is, deals with groups of random variables at a first-order level” (de Salvo Braz et al. 2005); “The act of exploiting the high level structure in relational models is called lifted inference” (Apsel and Brafman 2011); “The idea behind lifted inference is to carry out as much inference as possible without propositionalizing (Kisyński and Poole 2009); “lifted inference, which deals with groups of indistinguishable variables, rather than individual ground atoms (Singla et al. 2010). While, thus, the term lifted inference emerges as a quite coherent algorithmic metaphor, it is not immediately obvious what its exact technical meaning should be. Since quite a variety of different algorithmic approaches are collected under the label “lifted”, and since most of them can degenerate for cert",Extended lifted inference with joint formulas | Construction of belief and decision networks | Lifted first-order probabilistic inference | A tractable first-order probabilistic logic | Probabilities on finite models | Inference in probabilistic logic programs using weighted cnf’s | Learning probabilistic relational models | Probabilistic theorem proving | Relational bayesian networks | On the complexity of inference about probabilistic relational models | Liftability of probabilistic inference: Upper and lower bounds | Lifted inference seen from the other side: The tractable features | A catalog of complexity classes | Turing machines and the spectra of first-order formulas with equality | Towards combining inductive logic programming with bayesian networks | Lifted aggregation in directed first-order probabilistic models | Blog: Probabilistic logic with unknown objects | Lifted probabilistic inference with counting formulas | A theoretical framework for contextsensitive temporal probability model construction with application to plan projection | Probabilistic horn abduction and Bayesian networks | First-order probabilistic inference | Markov logic networks | A statistical learning method for logic programs with distribution semantics | Approximate lifted belief propagation | Discriminative probabilistic models for relational data | On the completeness of first-order knowledge compilation for lifted probabilistic inference | Conditioning in first-order knowledge compilation and lifted probabilistic inference | Lifted probabilistic inference by first-order knowledge compilation | Representing causal information about a probabilistic process,rejected,000
1204.3348.pdf.json,Symmetry Breaking Constraints: Recent Results,"Symmetry occurs in many constraint satisfaction and optimisation problems (Gent, Petrie, and Puget 2006). For example, suppose we have a proper coloring of a graph, and we permute the colors then we will obtain another symmetric coloring. Symmetries are problematic as they increase the size of the search space. We will waste time visiting symmetric solutions. Worse still, we will waste even more time visiting the (many failing) parts of the search tree which are symmetric to already visited states. A common and effective method to deal with symmetry is to add constraints which eliminate some, but not all symmetric solutions (e.g. (Puget 1993; Crawford et al. 1996; Shlyakhter 2001; Aloul, Sakallah, and Markov 2003; Puget 2005c; Law and Lee 2006; Walsh 2006a)). In this paper, we survey recent results on symmetry breaking constraints. We hope that this survey is of wider interest as many of the results are likely to translate to other domains like planning, model checking and heuristic search. Symmetry breaking constraints have a number of good and bad properties. On the positive side, a few simple constraints can often eliminate most if not all symmetry in a problem quickly and easily. In addition, propagation between the problem and the symmetry breaking constraints can reduce search considerably. On the negative side, we pick out particular solutions in each symmetry class, and this may conflict with the direction of the ∗Toby Walsh is supported by the Australian Government’s Department of Broadband, Communications and the Digital Economy, the ARC and the Asian Office of Aerospace Research and Development through grant AOARD-104123 and 124056. This paper was invited as a ”What’s Hot” paper to the AAAI’12 Sub-Area Spotlights track. Copyright c© 2012, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. branching heuristic. An alternative to posting static symmetry breaking constraints is a more dynamic approach that modifies","Efficient symmetry breaking for Boolean satisfiability | Excluding symmetries in constraint-based search | Enhancing clause learning by symmetry in sat solvers | The alldifferent constraint with precedences | Symmetries and lazy clause generation | Symmetry definitions for constraint satisfaction problems | Symmetry breaking predicates for search problems | Symmetry breaking | Symmetry in matrix models. Technical Report APES-30-2001, APES group. Presented at SymCon’01 (Symmetry in Constraints), CP2001 post-conference workshop | Matrix modelling. Technical Report APES-36-2001, APES group. Presented at Formul’01 Workshop on Modelling and Problem Formulation, CP2001 post-conference workshop | Breaking row and column symmetry in matrix models | Static and dynamic structural symmetry breaking | Global constraints for lexicographic orderings | Multiset ordering constraints | Propagation algorithms for lexicographic ordering constraints. Artificial Intelligence 170(10):803–908 | Constraints for breaking more row and column symmetries | Symmetry breaking in constraint programming | CSPLib: a benchmark library for constraints | Symmetry in constraint programming | Snake lex: An alternative to double lex | Modelling equidistant frequency permutation arrays: An application of constraints to mathematics | Automatic generation of constraints for partial symmetry breaking | Symmetries of symmetry breaking constraints | Combining symmetry breaking and global constraints | On the complexity and completeness of static constraints for breaking row and column symmetry | Global constraints for integer and set value precedence | Symmetry Breaking Constraints for Value Symmetries in Constraint Satisfaction | Breaking symmetry of interchangeable variables and values | A novel approach for detecting symmetries in CSP models | Beyond lex leader: Breaking symmetry with other orderings | Automatic detection of variable and value symmetries | Breaking symmetries in all different problems | Global grammar constraints | Decomposing global grammar constraints | Structural symmetry breaking | Using auxiliary variables and implied | General symmetry breaking constraints | Symmetry breaking using value precedence | Breaking value symmetry | On the complexity of breaking symmetry | Symmetry breaking via LexLeader feasibility checkers",rejected,000
1204.3436.pdf.json,Explaining Adaptation in Genetic Algorithms With Uniform Crossover: The Hyperclimbing Hypothesis,"Over several decades of use in diverse scientific and engineering fields, evolutionary optimization has acquired a reputation for being a kind of universal acid—a general purpose approach that routinely procures useful solutions to optimization problems with rugged, dynamic, and stochastic cost functions over search spaces consisting of strings, vectors, trees, and instances of other kinds of data structures (Fogel, 2006). Remarkably, the means by which evolutionary algorithms work is still the subject of much debate. An abiding mystery of the field is the widely observed utility of genetic algorithms with uniform crossover (Syswerda, 1989; Rudnick et al., 1994; Pelikan, 2008; Huifang and Mo, 2010). The use of uniform crossover (Ackley, 1987; Syswerda, 1989) in genetic algorithms causes genetic loci to be unlinked, i.e. recombine freely. It is generally acknowledged that the adaptive capacity of genetic algorithms with this kind of crossover cannot be explained within the rubric of the building block hypothesis, the reigning explanation for adaptation in genetic algorithms with strong linkage between loci (Goldberg, 2002). Yet, no alternate, scientifically rigorous explanation for adaptation in genetic algorithms with uniform crossover (UGAs) has been proposed. The hyperclimbing hypothesis, presented in this paper, addresses this gap. This hypothesis holds that UGAs perform adaptation by implicitly and efficiently implementing a global search heuristic called hyperclimbing. If the hyperclimbing hypothesis is sound, then the UGA is in good company. Hyperclimbing belongs to a class of heuristics that perform global decimation. Global decimation, it turns out, is the state of the art approach to solving large, hard instances of SAT (Kroc ar X iv :1 20 4. 34 36 v1 [ cs .N E ] 1 6 A pr 2 01 2 et al., 2009). Conventional global decimation strategies—e.g. Survey Propagation (Mézard et al., 2002), Belief Propagation, Warning Propagation (Braunstein et al., 2002)—use messag","A connectionist machine for genetic hillclimbing | Adaptive selection methods for genetic algorithms | The interplay of optimization and machine learning research | Survey propagation: an algorithm for satisfiability | Sufficient conditions for coarse-graining evolutionary dynamics | Generative Fixation: A Unifed Explanation for the Adaptive Capacity of Simple Recombinative Genetic Algorithms | The Extended Phenotype | The Selfish Gene | Biases in the crossover landscape | Evolutionary Computation : Towards a New Philosophy of Machine Intelligence | Genetic Algorithms in Search, Optimization & Machine Learning | The Design Of Innovation | Adaptation in Natural and Artificial Systems: An Introductory Analysis with Applications to Biology, Control, and Artificial Intelligence | Building blocks, cohort genetic algorithms, and hyperplane-defined functions | Stochastic Local Search: Foundations and Applications | A new method of image compression based on quantum neural network | The Origins of Order: Self-Organization and Selection in Evolution | Message-passing and local heuristics as decimation strategies for satisfiability | Combining pixelization and dimensional stacking | Evolution and the Levels of Selection",rejected,000
1204.3516.pdf.json,WHEN MAJORITY VOTING FAILS: COMPARINGQUALITY ASSURANCE METHODS FOR NOISY HUMAN COMPUTATION ENVIRONMENT,"Human computation is a growing research field that holds promise of humans and computers working seamlessly together to implement powerful systems. Algorithmically aggregating outputs from human computation workers is the key to such an integrated human-computer system (Little & Sun 2011). The nature of a human computation system is for workers to self-select tasks to work on, thus results from such an open call are generally noisy with different levels of correctness and quality. Redundancy with majority voting (Bernstein et al. 2010) or independent output agreement (von Ahn & Dabbish 2004) is commonly adopted to address this issue. However, Sun et al (2011) and Law & von Ahn (2009) both identified that high quality results reside in a minority of the responses and are often not identified by majority voting. As pointed out in (Law & von Ahn 2011), the limitations of majority voting include 1) the workers can agree on an incorrect answer by chance, 2) workers may have different specialized skills, and 3) the difficulty of the task affects the quality of the responses. We propose two methods for selecting the best answer in human computation that are based on multi-way comparisons: tournament selection and elimination selection. We conduct proof-of-concept experiments using CrowdFlower.com. Experimental results show that majority voting often produces incorrect answers in situations where the selection methods identify the correct answer. We simulate these methods to benchmark their time complexity, error rates and the costs associated with their deployment, in terms of number of comparisons required, and compare them with selection based on Condorcet voting (Stern 1993). The main points of this paper are: 1) Both tournament selection and elimination selection produce the correct answer where majority voting fails. However elimination selection typically has a lower error rate when the same number of comparisons is made. 2) With the same cost, 4-way comparison selec","Human Computation, | Soylent: A Word Processor with a Crowd Inside, | Human OCR: Insights from a Complex Human Computation Process, | Labeling images with a computer game, | Beyond Independent Agreement: A Tournament Selection Approach for Quality Assurance of Human Computation Tasks, | Input-agreement: A new mechanism for data collection using human computation games, | CODA: Convergence Diagnosis and Output Analysis for MCMC, | Ensuring quality in crowdsourced search relevance evaluation: The effects of training question distribution, | Programmatic Gold: Targeted and Scalable Quality Assurance in Crowdsourcing, | User-Centered Design of a Social Game to Tag Music, | Online Word Games for Semantic Data Collection, | Analyzing and Modeling Rank Data, | Selection in the Presence of Noise: The Design of Playoff Systems | Discrete Choice Analysis, | The Rank Analysis of Incomplete Block Designs, “ I | Individual Choice Behavior, | A Comparative Analysis of Selection Schemes Used in Genetic Algorithms, | Genetic-Based Machine Learning for Rule Induction: Taxonomy, Experimental Study and State of the Art, | Probability Models on Rankings",rejected,000
1204.3529.pdf.json,Hardness Results for Approximate Pure Horn CNF Formulae Minimization,"Horn functions constitute a rich and important subclass of Boolean functions and have many applications in artificial intelligence, combinatorics, computer science, and operations research. Furthermore, they possess some nice structural and algorithmic properties. An example of this claim is found on the satisfiability problem (SAT) of formulae in conjunctive normal form (CNF): while it is one of the most famous NP-complete problems for general Boolean CNFs (Cook [11]; see also: Arora and Barak [1], Garey and Johnson [19]), it can be solved in linear time in the number of variables plus the length of the Horn CNF formula being considered (Dowling and Gallier [16], ∗To appear in the special issue of the Annals of Mathematics and Artificial Intelligence dedicated to ISAIM2012. The authors gratefully acknowledge the partial support by NSF grants IIS 0803444 and by CMMI 0856663. The second author also gratefully acknowledge the partial support by the joint CAPES (Brazil)/Fulbright (USA) fellowship process BEX-2387050/15061676. Itai and Makowsky [23], and Minoux [26]), where length in this context means the number of literal occurrences in the formula (i.e., multiplicities are taken into account). The problem of finding short Horn CNF representations of Horn functions specified through Horn CNFs has received some considerable attention in the literature since it has an intrinsic appeal stemming from both theoretical and practical standpoints. The same can be said about some special cases, including Horn 3-CNFs, i.e., the ones in which each clause has at most three literals. Two of the common measures considered are the number of clauses and the number of literal occurrences (henceforth, number of literals). The NP-hardness of minimizing the number of clauses in Horn CNFs was first proved in a slightly different context of directed hypergraphs by Ausiello et al. [6]. It was later shown to also hold for the case of pure Horn 3-CNFs by Boros et al. [8]. The NP-hardness of m","Computational Complexity: A modern approach | The hardness of approximate optima in lattices, codes, and systems of linear equations | Hardness of approximations. in Approximation Algorithms for NP-Hard | Proof verification and the hardness of approximation problems | Probabilistic checking of proofs: a new characterization of NP | Minimal representation of directed hypergraphs | On approximate Horn formula minimization | A decomposition method for CNF minimality proofs | Exclusive and essential sets of implicates of Boolean functions | Hardness results for approximate pure Horn CNF formulae minimization | The Complexity of Theorem-Proving Procedures | eds.): Boolean Functions: Theory, Algorithms, and Applications, Encyclopedia of Mathematics and its Applications, vol. 142 | Introduction to algorithms, third edition | Composition of low-error 2-query PCPs using decodable PCPs | On the hardness of approximating label-cover | Linear-time algorithms for testing the satisfiability of propositional Horn formulae | Interactive proofs and the hardness of approximating cliques | Two-prover one-round proof systems: Their power and their problems (extended abstract) | Computers and intractability | Horn functions and their DNFs | Optimal compression of propositional Horn knowledge bases: complexity and approximation | On the complexity of k-SAT | Unification as a complexity measure for logic programming | On the hardness of approximating spanners | Minimum covers in relational database model | Ltur: A simplified linear-time unit resolution algorithm for Horn formulae and computer implementation | Two-query PCP with subconstant error | Hardness of approximating  Σp2 minimization problems | The design of approximation algorithms",rejected,000
1204.3616.pdf.json,Large-Scale Automatic Labeling of Video Events with Verbs Based on Event-Participant Interaction,"People describe observed visual events using verbs. A common assumption in Linguistics (Jackendoff, 1983; Pinker, 1989) is that verbs typically characterize the interaction between event participants in terms of the gross changing motion of these participants. Object class and image characteristics of the participants are believed to be largely irrelevant to determining the appropriate verb label for an event. Participants simply fill roles (such as agent and patient) in the spatiotemporal structure of the event class described by a verb. For example, an event where one participant (the agent) picks up another participant (the patient) consists of a sequence of two subevents, where during the first subevent the agent moves towards the patient while the patient is at rest and during the second subevent the agent moves together with the patient away from the original location of the patient. It does not matter whether the agent is a human or a cat, or whether the patient is a ball or a cup. Moreover, the shapes, sizes, colors, textures, etc. of the participants are irrelevant. Additionally, only the gross motion characteristics are relevant; it is irrelevant whether the participants grow, shrink, bend, vibrate, etc. during a pick up event. The precise linear or angular velocities and accelerations are likewise irrelevant. The objective of this paper is to evaluate this Linguistic assumption and its relevance to the computer-vision task of labeling video events with verbs. In order to evaluate this hypothesis, we focus our attention on methods that classify events solely on the basis of the gross changing motion of the event participants. In doing do, we often expressly discard other sources of information such as object class, ar X iv :1 20 4. 36 16 v1 [ cs .C changing human body posture, and low-level image characteristics such as shape, size, color, and texture. We do this not because we believe that such information could not help event recognition but rather to al",Statistical inference for probabilistic functions of finite state Markov chains | Actions as space-time shapes | Dynamic time warp (DTW) in Matlab | Object detection with discriminatively trained part based models | Learning realistic human actions from movies | Semantics and Cognition | Recognizing realistic actions from videos “in the wild | A threshold selection method from gray-level histograms | A unified approach to the change of resolution: Space and gray-level | Learnability and Cognition | Action MACH: A spatio-temporal maximum average correlation height filter for action recognition | Dynamic programming algorithm optimization for spoken word recognition | Recognizing human actions: A local SVM approach | Good features to track | A maximum-likelihood approach to visual event classification | Detection and tracking of point features | Convolutional codes and their performance in communication systems | Human action recognition by semilatent topic models,rejected,000
1204.3820.pdf.json,Distance Optimal Formation Control on Graphs with a Tight Convergence Time Guarantee,,"Distributed memoryless point convergence algorithm for mobile robots with limited visibility | Behavior-based formation control for multirobot teams | Robust rendezvous for mobile autonomous agents via proximity graphs in arbitrary dimensions | On multiple moving objects | Information flow and cooperative control of vehicle formations | Stability of a discrete-time asynchronous swarm with timedependent communication links | Complexity, Oracles, and Numerical Computation | A distributed and optimal motion planning approach for multiple mobile robots | Coordination of groups of mobile autonomous agents using nearest neighbor rules | Towards efficient trajectory planning: The path velocity decomposition | Path planning for permutation-invariant multirobot formations | Combinatorial optimization - networks and matroids | The multi-agent rendezvous problem. part 1: The synchronous case | The multi-agent rendezvous problem. part 2: The asynchronous case | Local control strategies for groups of mobile autonomous agents | A discrete grid abstraction for formation control in the presence of obstacles | Stability of multiagent systems with time-dependent communication links | Deadlock-free and collisionfree coordination of two robot manipulators | Coordinating multiple robots with kinodynamic constraints along specified paths | Consensus seeking in multi-agent systems under dynamically changing interaction topologies | Switching rules for decentralized control with simple control laws | Path coordination for multiple mobile robots: A resolution complete algorithm | Automatic generation of persistent formations for multi-agent networks under range constraints | Curve shortening and the rendezvous problem for mobile autonomous robots | Leader-to-formation stability | Prioritized motion planning for multiple robots | Centralized path planning for multiple robots: Optimal decoupling into sequential plans | Coordinated path planning for multiple robots | Multi-agent path planning and network flow | Rendezvous without coordinates | Graph-theoretic connectivity control of mobile robot networks",rejected,000
1204.3844.pdf.json,On how percolation threshold affects PSO performance,"Percolation theory appears in very different random structures, including spread of diseases, fire propagation in forests, phase transition in solids, diffusion in disordered media, etc. There are number of good reviews of the percolation theory [10,11]. This theory is particularly well adapted to describe global physical properties, such as the connectivity and conductivity behaviour of geometrically complex systems. This work analyzes the role of percolation threshold, a universal measure of connectivity in graphs, to analyze the convergence of swarms algorithms as a function of the expected number of neighbors at initial step. And therefore, to develop a framework to compare the performance of hybrid PSO algorithms. The analysis of the performance of different hybrid PSO algorithms has been addressed in different works [4,7,3]. However, in this work, we focus on the concept of percolation threshold as a useful tool to define the parameter space for which the performance of the basic PSO algorithm is enhanced. The basic model of PSO by Eberhart, Kennedy and Shi [8,6] is an stochastic optimization method for D -dimensional functions. Given a population of P individuals i, 1 ≤ i ≤ P , uniformly distributed on an D -dimensional hypercube of size S in points xi = (xi1, . . . , xid, . . . , xiD), each individual moves to next position according to a velocity vector vi = (vi1, . . . , vid, . . . , viD) both calculated according to (1): vid = w ∗ vid + c1 ∗ rand (1.0) ∗ (pid − xid) + c2 ∗ Rand (1.0) ∗ (pgid − xid) xid = xid + vi (1) where values rand(1.0) and Rand(1.0) are drawn at random according to a uniform distribution in the interval [0, 1]. Velocity vi (t+ 1) is a randomized linear combination of three forces: (i) inertia, weighted by parameter w ∈ [0, 1], (ii) the personal attraction c1 to the position pi where the minimum value of a function f (pi) was found, and (iii) the social attraction to the position pgi of the best goal remembered by the neighbors of indi","Percolation | The particle swarm explosion, stability, and convergence in a multidimensional complex space | Hybrid intelligent algorithms and applications | Editorial: New trends and applications on hybrid artificial intelligence systems | Comparing inertia weights and constriction factors in particle swarm optimization | Particle swarm optimization: Developments, applications and resources | Advanced nonparametric tests for multiple comparisons in the design of experiments in computational intelligence and data mining: Experimental analysis of power | Particle swarm: Social adaptation of knowledge | Logic-oriented neural networks for fuzzy neurocomputing | Applications of Percolation Theory | Introduction to Percolation Theory | A statistical study of the effects of neighborhood topologies in particle swarm optimization | The particle swarm optimization algorithm: Convergence analysis and parameter selection | Particle swarm optimization with highly-clustered scale-free neighborhood model",rejected,000
1204.3918.pdf.json,Eliminating the Weakest Link: Making Manipulation Intractable?,"Voting is a general mechanism for combining the preferences together of multiple agents. Voting is, however, not without its problems. One such problem is that agents may vote strategically, mis-reporting their true preferences in order to improve the outcome for them. For instance, in each round of a popular TV game show, players vote on which other player to eliminate. The host, Anne Robinson then tells the unlucky player, “You are the weakest link, goodbye!”. Players have an interesting strategic decision to make. On the one hand, they should vote to eliminate weak players (as weak players will tend to reduce the size of the jackpot). On the other hand, they should vote to eliminate strong players (as the overall winner takes the final jackpot and everyone else walks away empty-handed). Similarly, when the International Olympic Committee (IOC) meets to select a site for the next Olympics, there is an election in which the weakest city is successively eliminated. Strategic voting often appears to take place. For example, in the vote for the site of the 2012 Olympics, New York had 19 votes in the first round but only 16 in the second as several IOC members switched allegiances. In this paper, we study the computational resistance of elimination style voting rules to such strategic voting. Results like those of Gibbard-Satterthwaite prove that most voting rules are manipulable. That is, it may pay for agents to mis-report their preferences. One potentially appealing escape from manipulation is computational com- Copyright c© 2013, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. plexity (Bartholdi, Tovey, and Trick 1989). Whilst manipulations might exist, what if they are too hard to find? Unfortunately, only a few voting rules used in practice are known to be NP-hard to manipulate with unweighted votes and a single manipulator: single transferable voting (STV) (Bartholdi and Orlin 1991), a variant of the Copeland rule ","Multi-stage voting, sequential elimination and condorcet consistency | Single transferable vote resists strategic voting. Social Choice and Welfare 8(4):341–354 | The computational difficulty of manipulating an election | Unweighted coalitional manipulation under the Borda rule is NP-hard | On the complexity of manipulating elections | Universal voting protocol tweaks to make manipulation hard | Complexity of and algorithms for Borda manipulation | Hybrid voting protocols and hardness of manipulation | Elections can be manipulated often | Manipulation of Nanson’s and Baldwin’s rules | Incompleteness and incomparability in preference aggregation | Uncertainty in preference elicitation and aggregation | Complexity of terminating preference elicitation | Where are the really hard manipulation problems? The phase transition in manipulating the veto rule | An empirical study of the manipulability of single transferable voting | Generalized scoring rules and the frequency of coalitional manipulability | A sufficient condition for voting rules to be frequently manipulable | Complexity of unweighted coalitional manipulation under some common voting rules",rejected,000
1204.4051.pdf.json,Solution Representations and Local Search for the bi-objective Inventory Routing Problem,"The solution of the biobjective IRP is rather challenging, even for metaheuristics. We are still lacking a profound understanding of appropriate solution representations and effective neighborhood structures. Clearly, both the delivery volumes and the routing aspects of the alternatives need to be reflected in an encoding, and must be modified when searching by means of local search. Our work contributes to the better understanding of such solution representations. On the basis of an experimental investigation, the advantages and drawbacks of two encodings are studied and compared.",Heuristic approaches for the inventoryrouting problem with backlogging | Delivery volume optimization | A fast and elitist multiobjective genetic algorithm: NSGA-II | The biobjective inventory routing problem - problem solution and decision support | On the use of reference points for the bi-objective inventory routing problem | Replenishment routing problems between a single supplier and multiple retailers with direct delivery | Inventory routing problems: a logistical overview | A practical solution approach for the cyclic inventory routing problem,rejected,000
1204.4294.pdf.json,,"Statistical data analysis and learning in Riemannian orbifolds is motivated by applications, where the data we want to learn on are naturally represented by finite combinatorial structures such as point patterns, trees, and graphs. Examples from structural pattern recognition that learn on structured data include estimating central points of a distribution on graphs such as the mean and median [9, 16, 15, 21], central clustering of graphs [10, 12, 13, 14, 19, 15, 23], learning graph quantization [17], and multilayer perceptrons for graphs [20]. In retrospect, the structure space framework proposed by [18] theoretically justifies the above approaches in the sense that they actually minimize an empirical risk function on structures. Since minimizing an empirical risk function is usually computationally intractable, the ultimate challenge consists in constructing efficient algorithms which are capable to return optimal or at least suboptimal solutions. From the point of view of statistical pattern recognition, however, the ultimate goal is not to determine a good solution of an empirical risk function, but rather to discover the true but unknown structure of the data with respect to its distribution. According to this perspective, we may regard the solutions of empirical risk functions as estimators of the true but unknown population parameter. One gap between statistical and structural pattern recognition is the lack of consistency results of existing estimators for the population parameters. As a consequence most methods from structural pattern recognition that directly operate in the domain of graphs still have no statistical justification. The first contribution of this paper establishes sufficient conditions for consistency of estimators defined by empirical risk functions on attributed graphs. For this we regard graphs as points of some structure space [18]. A structure space is the quotient of a Euclidean space by some permutation group. The benefit of the struc",A linear programming approach for the weighted graph matching problem | editors | Riemannian geometry of orbifolds | Stochastic learning | On a relation between graph edit distance and maximum common subgraph | L | Balanced graph matching | Stochastic generalized gradient method for nonconvex nonsmooth stochastic optimization | Theory and algorithms on the median graph | I | A graduated assignment algorithm for graph matching | Learning with preknowledge: Clustering with point and graph matching distance measures | Self-organizing map for clustering in the graph domain | Median graph computation for graph clustering | On the sample mean of graphs | Algorithms for the sample mean of graphs | Graph quantization | Structure spaces | Central clustering of attributed graphs | Structural perceptrons for attributed graphs | An median graphs: properties | Stochastic generalized-differentiable functions in the problem of nonconvex nonsmooth stochastic optimization | Clustering of web documents using graph representations | An eigendecomposition approach to weighted graph matching problems | A rkhs interpolator-based graph matching algorithm | Adaptive switching circuits,rejected,000
1204.4541.pdf.json,Automatic Sampling of Geographic objects,"Many geographical processes require the use of data sample. The method used to choose the geographical object has to be considered. In this paper, we propose approach dedicated to the selection of a sample of geographic objects. Section 2 presents the context of this work. In section 3, the sampling method we propose is described. Section 4 is dedicated to the evaluation of our method.","Integrating multi-agent, objectoriented, and algorithmic techniques for improved automated map generalization | Maximum likelihood from incomplete data via the em algorithm (with discussion) | Unsupervised Feature Selection Using Feature Similarity | Cartographic generalization of roads in a local and adaptative approach: a knowledge acquisition | Knowledge revision in systems based on an informed tree search strategy: application to cartographic generalisation",rejected,000
1204.4989.pdf.json,Using Belief Theory to Diagnose Control Knowledge Quality,,"Probabilité et incertitude en fusion de données multisenseurs | Integrating multi-agent | J | Introduction aux méthiodes multicritères d'aide à la décision | A review and conceptual framework of automated map generalization | Creative Cartography based on Dialogue | Upper and lower probabilities induced by multivalued mapping | The art of artificial intelligence 1: Themes and case studies of knowledge engineering. | An interactive approach for multicriterion optimisation with an application to the operation of an academic department | A method based on samples to capture user needs for generalisation | A review of goal programming: a tool for multi objective analysis | Automated learning multi-criteria classifiers for FLIR ship imagery classification | Assessing a set of additive utility functions for multicriteria decision making | A statistical theory of target detection by pulsed radar | Data matching-a matter of belief | A new approach for impacts assessment of urban mobility | A missing link in OR-AD: Robustness analysis | The outranking approach and the foundations of ELECTRE methods | A Prototype Generalisation System Based on the Multi-Agent Paradigm | A mathematical theory of evidence | A bibliography of outranking approaches | Constructing the pignistic probability function in a context of uncertainty | The transferable belief model | Signal detection and recognition by human observers | Knowledge diagnosis in systems based on an informed tree search strategy: application to cartographic generalisation | Knowledge revision in systems based on an informed tree search strategy: application to cartographic generalisation | Aide multicritère à la décision dans le cadre de la problématique du tri : Concepts, méthodes et applications",rejected,000
1204.4990.pdf.json,,,"OXYGENE: An open framework for the deployment of geographic web services | Quality Assessment of Cartographic Generalisation | Integrating multi-agent | A review and conceptual framework of automated map generalization | Creative Cartography based on Dialogue | Applications of Machine Learning to Cognitive Radio Networks, Wireless Communications | Fast effective rule induction | Ant Colony Optimization | Role of urban patterns for building generalisation: An application of AGENT | Induction of Ripple-Down Rules Applied to Modeling Large Databases | Tabu search | Adaptation in Natural and Artificial Systems | A method based on samples to capture user needs for generalisation | An alternative objective function for Markovian fields | Optimization by Simulated Annealing | C4.5: programs for machine | Modèle de généralisation de données géographiques à base de contraintes et d’autonomie | A Prototype Generalisation System Based on the Multi-Agent Paradigm | Norvig, informed search and exploration, chapter 4 of artificial intelligence, a modern approach, second edition | Knowledge revision in systems based on an informed tree search strategy: application to cartographic generalisation, in CSTST | Learning local objective functions for robust face model fitting | Data Mining: Practical Machine Learning Tools and Techniques (San Francisco",rejected,000
1204.5213.pdf.json,"Solving Weighted Voting Game Design Problems Optimally: Representations, Synthesis, and Enumeration","In many real-world problems that involve multiple agents, for instance elections, there is a need for fair decision making protocols in which different agents have different amounts of influence in the outcome of a decision. Weighted voting games are often used in these decision making protocols. In a weighted voting game, a quota is given, and each agent (or also: player) in the game has a certain weight. If the total weight of a coalition of agents exceeds the quota, then that coalition is said to be winning, and losing otherwise. Weighted voting games arise in various settings, such as political decision making (decision making among larger and smaller political parties), stockholder companies (where people with different numbers of shares are supposed to have a different amount of influence), and elections (e.g., in the US Presidential Election, where each state can be regarded as a player who has a weight equal to its number of electors). The weight that a player has in a weighted voting game turns out not to be equal to his actual influence on the outcome of the decisions that are made using the weighted voting game. Consider for example a weighted voting game in which the quota is equal to the sum of the weights of all players. In such a game, a player’s influence is equal to the influence of any other player, no matter what weight he has. Throughout the literature, various power indices have been proposed: ways to measure a player’s influence (or (a priori) power) in a voting game. However, computing a power index turns out to be a challenge in many cases. In this paper, instead of analyzing the power of each agent in a voting game, we investigate the problem that has been referred to as the “inverse problem” and the “generalized apportionment problem”. We will call this problem the power index voting game design problem. In the power index voting game design problem we are given a target power index for each of the agents, and we study how to design a weigh","Computing power indices in weighted multiple majority games | The inverse Banzhaf problem | Voting power and power index website: a voting power WWWresource including powerslave voting body analyser | Complexity of comparison of influence of players in simple games | Efficient algorithm for designing weighted voting games | Approximating power indices | Computing the Banzhaf power index in network flow games | Power and stability in connectivity games | Generating functions for computing power indices efficiently | Power and size: a new paradox | Nearly optimal solutions for the chow parameters problem and low-weight approximation of halfspaces | The inverse shapley value problem | On the design and synthesis of voting games : exact solutions for the inverse problem | Enumeration and exact design of weighted voting games | Über Zerlegungen von Zahlen durch ihre grössten gemeinsammen Teiler | On the complexity of cooperative solution concepts | The desirability relation of simple games | The complexity of power-index comparison | A randomized method for the Shapley value for the voting game | An anytime approximation method for the inverse Shapley value problem | A linear approximation method for the Shapley value | On the complexity of dualization of monotone disjunctive normal forms | On minimal integer representations of weighted games | Enumeration of weighted games with minimum and an analysis of voting power for bipartite complete games with minimum | The golden number and fibonacci sequences in the design of voting structures | Weighted games without a unique minimal representation in integers | The complexity of testing properties of simple games | Complete voting systems with two classes of voters: weightedness and counting | The greatest allowed relative error in weights and threshold of strict separating systems | Threshold logic | A class of simple games | A new polynomial-time algorithm for linear programming | A survey on the computation of power indices | On Dedekind’s problem: The number of isotone boolean functions II | Faster algorithms for computing power indices in weighted voting games | Monotone boolean functions | Directed and weighted majority games | On minimum sum representations for weighted voting games | On the inverse power index problem | Is the allocation of voting power among EU states fair | Computation of power indices | Designing the voting system for the EU council of ministers | Voting power in the governance of the international monetary fund | Computing power indices for large voting games | Power indices as an aid to institutional design: the generalised apportionment problem | Values of large games, VI: Evaluating the electoral college exactly | A survey of algorithms for calculating power indices of weighted majority games | NP-completeness for calculating power indices of weighted majority games | Threshold logic and its applications | Majority functions of up to six variables | Enumeration of threshold functions of eight variables | On the unimodularity of some partition polynomials | The chow parameters problem | Circuit complexity and neural networks | Polynomial-time algorithms for regular setcovering and threshold synthesis | Introduction to the Theory of Cooperative Games | On the complexity of the decisive problem in simple, regular and weighted games | NP-completeness of some problems concerning voting games | A method for evaluating the distribution of power in a committee system | Discrete Neural Computation: A Theoretical Foundation | Sampling uniformly from the unit simplex | Ein Satz über Untermengen einer endlichen Menge | Weyl groups, the hard Lefschetz theorem, and the Sperner property | Fair allocation and re-weighting of votes and voting power in the EU before and after the next enlargement | Simple Games: Desirability Relations, Trading, Pseudoweightings | Efficient computation of power indices for weighted majority games | Enumeration of seven-argument threshold functions | Asymptotics of the logarithm of the number of threshold functions of the algebra of logic | On encoding and enumerating threshold functions",rejected,000
1204.5316.pdf.json,ILexicOn: toward an ECD-compliant interlingual lexical ontology described with semantic web formalisms,"In this paper we introduce and illustrate the core of the ongoing ULiS project that is at the barycenter of the Meaning-Text Theory (MTT), pivot-based NLP techniques, and the semantic web formalisms. What we aim for in the ULiS project is a universal linguistic system (ULiS), through which multiple actors could interact with interlingual knowledge bases in multiple controlled (i.e., restricted and formal) natural languages. Each controlled natural language (dictionary, grammar rules) would be described in a part of a universal linguistic knowledge base (ULK). Besides this, the ULK consists in one specific interlingual knowledge base. Actors could then enhance their controlled natural language through different Maxime Lefrançois, Fabien Gandon actions in controlled natural language (e.g., create, describe, modify, merge, or delete lexical units in the dictionaries and grammar rules; connect situational lexical units to interlingual lexical units; add linguistic attributes with their associated rules, etc.) These actions are assigned the top-priority as the universal linguistic knowledge base would be the cornerstone of the universal linguistic system. The aim of this paper is to introduce the core of such a universal linguistic knowledge base, i.e., the interlingual lexical ontology (ILexicOn). Roughly, we aim to port pure semantic features of explanatory combinatorial dictionaries (ECD) to the semantic web formalisms. The rest of this paper is organized as follows. Section 2 surveys the related work on lexical ontologies and interlingual lexical ontologies. Due to the novelty of our approach, we chose to develop a section on Semantic Web formalisms (Section 3), and to focus on one specific feature of our model: the formal definition of the interlingual lexical unit classes (ILUcs, Section 4). We give an overview and illustration on the architecture of our model (subsection 4.1), then we justify our novel approach for the lexicographic definition of ILUcs and introdu","The berkeley framenet project | Some Lexical Issues of UNL | Some controversial issues of UNL: Linguistic aspects | Sweetening ontologies with DOLCE, Knowledge engineering and knowledge management: Ontologies and the semantic Web | Cyc: toward programs with common sense | Introduction à la lexicologie explicative et combinatoire | Actants in semantics and syntax I: Actants in semantics | Introduction to wordnet: An on-line lexical database | Towards a standard upper ontology | Lexicons in the Mikrokosmos project | Lexical systems: graph models of natural language lexicons. Language resources and evaluation | Conceptual structures: information processing in mind and machine, System programming series, Addison-Wesley | EuroWordNet a multilingual database with lexical semantic networks, Computational Linguistics, 25(4)",rejected,000
1204.5805.pdf.json,Intelligent Automated Diagnosis of Client Device Bottlenecks in Private Clouds,,"A view of cloud computing | Elucidation of Upcoming Traffic Problems in Cloud Computing | The Cost of a Cloud : Research Problems in Data Center Networks | Wireless RF interference customer survey results | Pushing up performance for everyone | Experiences using Web100 for end-to-end network performance tuning | Automated packet trace analysis of TCP implementations | On inferring TCP behavior | Passive identification and analysis of TCP anomalies | Pathdiag: automated TCP diagnosis | Inferring TCP connection characteristics through passive measurements | Virtual Infrastructure Management in Private and Hybrid Clouds | Discriminating against new classes: One-class versus multi-class classification | Comparing techniques for multiclass classification using binary SVM predictors | The nature of statistical learning | Automatic construction of decision trees from data: A multi-disciplinary survey | Assistant 86: A knowledge elicitation tool for sophisticated users | Nearest neighbor pattern classification | Feature selection for high-dimensional genomic microarray data | Filters, wrappers and a boosting-based hybrid for feature selection | Detection of cancer-specific markers amid massive mass spectral data | Dummynet: a simple approach to the evaluation of network protocols | Measuring the evolution of transport protocols in the internet | Analysis of internet backbone traffic and header anomalies observed | A large-scale, passive analysis of end-to-end TCP performance over GPRS | How good delayed acknowledgement effects rate-based pacing tcp over multi-hop wireless network | Root cause analysis for long-lived TCP connections | CUBIC: a new TCP-friendly high-speed TCP variant | Binary increase congestion control (bic) for fast long-distance networks | The NewReno Modification to TCP’s Fast Recovery Algorithm | Netprints: diagnosing home network misconfigurations using shared knowledge | Developing the Web100 based network diagnostic tool (NDT) | Web100: extended TCP instrumentation for research, education and diagnosis | Nevermind, the problem is already fixed: proactively detecting and troubleshooting customer dsl problems | Pinpoint: problem determination in large, dynamic internet services | Passive Analysis of TCP Anomalies",rejected,000
1204.5859.pdf.json,On the Complexity of Second-Best Abductive Explanations,"The three basic reasoning mechanisms used in computational logic are deduction, induction, and abduction [25]. Deduction is the process of drawing conclusions from information and assumptions representing our knowledge of the world, so that the fact “battery is down” together with the rule “if the battery is down, the car will not start” allows concluding “car will not start”. Induction, on the other hand, derives rules from the facts: from the fact that the battery is down and that the car is not starting up, we may conclude the rule relating these two facts. Abduction is the inverse of deduction (to some ∗DIAG - Sapienza University of Rome, Via Ariosto 25, 00185 Rome, email: liberato@dis.uniroma1.it, phone: +39 347 6906915, corresponding author. †DIAG - Sapienza University of Rome, Via Ariosto 25, 00185 Rome, email: marco.schaerf@uniroma1.it extent [7]): from the fact that the car is not starting up, we conclude that the battery is down. In a more complete formalization of this environment there are many explanations for a car not starting up. This is an important difference between abduction and deduction, making the former, in general, more computationally complex. A given problem of abduction may have one, none, or even many possible solutions (explanations). Moreover, we need to perform both a consistency check and an inference just to verify an explanation. These facts intuitively explain why abduction is to be expected to be computationally harder than deduction. This observation has indeed been confirmed by theoretical results. Selman and Levesque [28, 27] and Bylander et al. [3, 4] proved the first results about fragments of abductive reasoning, Eiter and Gottlob [14] presented an extensive analysis, Creignou and Zanuttini [9] and Creignou, Schmidt, and Thomas [8] classified the complexity under two kinds of restrictions, Nordh and Zanuttini [24] located the tractability/intractability frontier, Eiter and Makino [17, 18, 19] studied the complexity of compu","Computational Complexity: A Modern Approach | Introduction to the Theory of Complexity. Prentice-Hall international series in computer science | Some results concerning the computational complexity of abduction | The computational complexity of abduction | Preprocessing of intractable problems | The complexity of conjunctive query abduction in DL-Lite | Abduction is not deduction-in-reverse | Complexity classifications for propositional abduction in post’s framework | A complete classification of the complexity of propositional abduction | An assumption-based TMS | A new method for consequence finding and compilation in restricted languages | The complexity of restricted consequence finding and abduction | On some tractable classes in deduction and abduction | The complexity of logic-based abduction | Abduction from logic programs: Semantics and complexity | Semantics and complexity of abduction from default theories | On computing all abductive explanations | Abduction and the dualization problem | Generating all abductive horn theories | The parameterized complexity of abduction | Counting complexity of propositional abduction | A knowledge-level account of abduction | Monotonic reductions, representative equivalence, and compilation of intractable problems | What makes propositional abduction tractable | Abduction and induction | Foundations of assumption-based truth maintenace systems: Preliminary report | Support set selection for abductive and default reasoning | Abductive and default reasoning: A computational core | Introduction to the Theory of Computation",rejected,000
1204.5920.pdf.json,,"A semantic embedding of propositional conditional logic in classical higher-order logic HOL (Church’s type theory) has been presented in [3]. This embedding exploits the natural correspondence between selection function semantics for conditional logics [10] and HOL. In fact, selection function semantics can be seen as an higher-order extension of well-known Kripke semantics for modal logic and cannot be naturally embedded into first-order logic. In this paper we extend the embedding in [3] to also include quantification over propositions and individuals. This embedding of quantified conditional logic in HOL is sound and complete.",General models and extensionality | Church’s type theory | Embedding and automating conditional logics in classical higher-order logic | Multimodal and intuitionistic logics in simple type theory | Quantified multimodal logics in simple type theory | Modal Logic: An Introduction | A formulation of the simple theory of types | Topics in conditional logic | A sequent calculus and a theorem prover for standard conditional logics | A theory of conditionals | Automated reasoning in higher-order logic using the TPTP THF infrastructure,rejected,000
1204.5981.pdf.json,"Containment, Equivalence and Coreness from CSP to QCSP and beyond","We consider the following increasingly stronger fragments of first-order logic: 1. primitive positive first-order ({∃,∧}-FO) 2. positive Horn ({∃,∀,∧}-FO) 3. positive equality-free first-order ({∃,∀,∧,∨}-FO); and, 4. positive first-order logic ({∃,∀,∧,∨,=}-FO) ∗Supported by EPSRC grant EP/G020604/1. ar X iv :1 20 4. 59 81 v1 [ cs .L O ] The model checking problem for a logic L takes as input a sentence of L and a structure B and asks whether B models L. The structure B is often assumed to be a fixed parameter and called the template; and, unless otherwise stated, we will assume implicitly that we work in this so-called non-uniform setting. For the above first three fragments, the model checking problem is better known as the constraint satisfaction problem CSP(B), the quantified constraint satisfaction problem QCSP(B) and its extension with disjunction which we shall denote by QCSP∨(B). Much of the theoretical research into CSPs is in respect of a large complexity classification project – it is conjectured that CSP(B) is always either in P or NP-complete [9]. This dichotomy conjecture remains unsettled, although dichotomy is now known on substantial classes (e.g. structures of size ≤ 3 [16, 3] and smooth digraphs [11, 1]). Various methods, combinatorial (graph-theoretic), logical and universal-algebraic have been brought to bear on this classification project, with many remarkable consequences. A conjectured delineation for the dichotomy was given in the algebraic language in [4]. Complexity classifications for QCSPs appear to be harder than for CSPs. Just as CSP(B) is always in NP, so QCSP(B) is always in Pspace. No overarching polychotomy has been conjectured for the complexities of QCSP(B), as B ranges over finite structures, but the only known complexities are P, NP-complete and Pspace-complete (see [2, 15] for some trichotomies). It seems plausible that these complexities are the only ones that can be so obtained. Distinct templates may give rise to the same mo",The CSP dichotomy holds for digraphs with no sources and no sinks (a positive answer to a conjecture of Bang-Jensen and Hell) | The complexity of constraint satisfaction games and QCSP | A dichotomy theorem for constraint satisfaction problems on a 3-element set | Classifying the complexity of constraints using finite algebras | Optimal implementation of conjunctive queries in relational data bases | Quantified constraints and containment problems | The complexity of constraint languages | Data exchange: getting to the core | The computational structure of monotone monadic SNP and constraint satisfaction: A study through Datalog and group theory | The core of a graph | On the complexity of H-coloring | Graphs and Homomorphisms | A tetrachotomy for positive first-order logic without equality | QCSP on partially reflexive forests | Towards a trichotomy for quantified H-coloring | The complexity of satisfiability problems,rejected,000
1204.6346.pdf.json,Magic Sets for Disjunctive Datalog Programs,"Disjunctive Datalog is a language that has been proposed for modeling incomplete data [48]. Together with a light version of negation, in this paper stratified negation, this language can in fact express any query of the complexity class ΣP2 (i.e., NP NP) [22], under the stable model semantics. It turns out that disjunctive Datalog with stratified negation is strictly more expressive (unless the polynomial hierarchy collapses to its first level) than normal logic programming (i.e., non-disjunctive Datalog with unstratified negation), as the latter can express “only” queries in NP. As shown in [22], the high expressive power of disjunctive Datalog has also some positive practical implications in terms of modelling knowledge, since many problems in NP can be represented more simply and naturally in stratified disjunctive Datalog than in normal logic programming. For this reason, it is not surprising that disjunctive Datalog has found several real-world applications [42,49,50,57,58], also encouraged by the availability of some efficient inference engines, such as DLV [43], GnT [37], Cmodels [46], or ClaspD [21]. As a matter of fact, these systems are continuously enhanced to support novel optimization strategies, enabling them to be effective over increasingly larger application domains. In this paper, we contribute to this development by providing a novel optimization technique, inspired by deductive database optimization techniques, in particular the Magic Set method [6,9,63]. The goal of the original Magic Set method (defined for non-disjunctive Datalog programs) is to exploit the presence of constants in a query for restricting the possible search space by considering only a subset of a hypothetical program instantiation that is sufficient to answer the query in question. In order to do this, a top-down computation for answering the query is simulated in an abstract way. This top-down simulation is then encoded by means of rules, defining new Magic Set predicates. ","Scalar aggregation in fd-inconsistent databases | Consistent query answers in inconsistent databases | Specifying and querying database repairs using logic programs with exceptions | Magic Sets and Other Strange Ways to Implement Logic Programs | Repairing databases with annotated predicate logic | Hyper Tableaux | On the power of magic | Soft stratification for magic set based query evaluation in deductive databases | Query answering in inconsistent databases | Consistent answers from integrated data sources | Consistent query answers in virtual data integration systems | Logic programming for consistently querying data integration systems | Default Logic as a Query Language | Query rewriting and answering under constraints in data integration systems | Minimal-change integrity maintenance using tuple deletions | Computing consistent query answers using conflict hypergraphs | Hippo: A System for Computing Consistent Answers to a Class of SQL Queries | Enhancing the magic-set method for disjunctive datalog programs | Conflict-Driven Disjunctive Answer Set Solving | Disjunctive Datalog | Enhancing Efficiency and Expressiveness in Answer Set Programming Systems | Magic Sets and their Application to Data Integration | Conquer: Efficient management of inconsistent databases | First-order query rewriting for inconsistent databases | Computers and Intractability, A Guide to the Theory of NP-Completeness | Gringo : A new grounder for answer set programming | The Stable Model Semantics for Logic Programming | Expressive Planning and Explicit Knowledge | A logic programming approach to the integration, repairing and querying of inconsistent databases | Optimization of Disjunction Queries | Binding Propagation Techniques for the Optimization of Bound Disjunctive Queries | The PushDown Method to Optimize Chain Logic Programs (Extended Abstract) | Magic-sets Transformation in Nonrecursive Systems | Reasoning in description logics by a reduction to disjunctive datalog | Unfolding Partiality and Disjunctions in Stable Model Semantics | Bottom-up evaluation and query optimization of well-founded models | Efficient query answering on stratified databases | Loop Formulas for Disjunctive Logic Programs | Data integration: A theoretical perspective | The INFOMIX System for Advanced Integration of Incomplete and Inconsistent Data | The DLV System for Knowledge Representation and Reasoning | Disjunctive Stable Models: Unfounded Sets, Fixpoint Semantics and Computation | OpenRuleBench: An analysis of the performance of rule engines | Disjunctive Answer Set Programming via Satisfiability | ASSAT: Computing Answer Sets of a Logic Program by SAT Solvers | Foundations of Disjunctive Logic Programming | The HiLeX system for semantic information extraction. Transactions on Large-Scale Data- and Knowledge-Centered Systems | On the complexity of regular-grammars with integer attributes | The consistency extractor system: Querying inconsistent databases using answer set programs | Foundations of Deductive Databases and Logic Programming | Reasoning in Description Logics using Resolution and Deductive Databases. PhD thesis, Fakultät für Wirtschaftswissenschaften, Universität | A comparison of reasoning techniques for querying large description logic aboxes | Magic is relevant | Logical Query Optimization by Proof-Tree Transformation | A logic-based system for e-tourism | Team-building with answer set programming in the Gioia-Tauro seaport | Modular Stratification and Magic Sets for Datalog Programs with Negation | Cost-based optimization for magic: Algebra and implementation | Extending and Implementing the Stable Model Semantics | Compiling query constraints | Principles of Database and Knowledge-Base Systems, Volume II",rejected,000
1205.1638.pdf.json,DOCUMENT SUMMARIZATION USING POSITIVE POINTWISE MUTUAL INFORMATION,"The escalation of the computer networks and easy access methods to information has led to increasing amount of storage of information, mostly textual. According to the latest report from IDC [1], the world’s information is doubling every two years. In 2011, the information created around the world was more than 1.8 zettabytes. By 2020 the world will generate 50 times the amount of information and 75 times the number of ""information containers"" while IT staff to manage it will grow less than 1.5 times. The report also points out the necessity of new ""information taming"" technologies for information processing and storage. To speedup the accessing, the flow of information needs to be filtered and stored systematically. For example, the working of Information Retrieval Systems (IRS) can be made effective by summarizing the entire collection of documents. Automatic text summarization can help by providing condensed versions of text documents. Expected summarization holds a list of applications like information extraction, document retrieval [2], evaluation of answer books [3], etc. Since the first study on text extraction by Luhn appeared, the text summarization process has attracted lot of research activities [14,16,17]. Depending on the purpose and intended users, a summary can be generic or user-focused [4]. A generic summary covers all major themes or aspects of the original document to serve a broad readership community rather than a particular group. A user-focused (or topic-focused, query oriented) summary favors specific themes. Summarization processes are traditionally confined to ad-hoc and simple techniques, without any symbolic or linguistic processing, and this limits the quality of summary that can be produced. Semantic similarity is a concept whereby a set of words within identified unique words are assigned a metric based on the worthiness/ correctness of their meaning or semantic content. In this paper we suggest a method based on Positive Pointwise Mut","Multi-Document Summarization as Applied in Information Retrieval | Methods for Automatically Evaluating Answers to Complex Questions | Automated Text Summarization | Co-occurrence vectors from corpora vs. distance vectors from dictionaries | Word association norms, mutual information, and lexicography | Word recognition by morphological analysis | The importance of stop word removal on recall values in text categorization | Information Retrieval: Data Structures and Algorithms | Stemming in the language modeling framework | An algorithm for suffix stripping, Program, 14(3) pp 130−137 | From Frequency to Meaning: Vector Space Models of Semantics | Co-occurrence vectors from corpora vs. distance vectors from dictionaries | The Challenges of Automatic Summarization | Generic Text Summarization Using Relevance Measure and Latent Semantic Analysis | Using Latent Semantic Analysis in Text Summarization and Summary Evaluation",rejected,000
1205.1645.pdf.json,Publishing and linking transport data on the Web,"This project to build a framework for publishing and interlinking transport data on the Web was developed in collaboration between LIRMM1, Université Montpellier 22 and CETE3 Méditerranée. The feasibility of publishing and interconnecting transport transport into linked data on the web will be studied concretely from two data sources: the directory information services Passim and XML files corresponding to the NEPTUNE format describing public transport routes. Open Data, in France, has been booming for the last 2 years. Open Data is the publication of public data, free of charge and in open formats so that people who want to use them can do it. This phenomenon is closely linked with the term Linked Data. It refers to a set of best practices for publishing and interlinking structured data on the Web. These best practices were introduced by Tim BernersLee and have become known as the Linked Data principles. These principles are 1) use URIs as names for things, 2) use URIs which are dereferenceable, 3) use RDF and SPARQL standards, 4) link URIs between them. So if all data is linked, a huge graph is created, which forms the Web of data (or Semantic Web). The Semantic Web, term introduced by Tim Berners-Lee [1], aims at putting data on the Web in a form that machines can naturally understand, so web content can be treated directly or indirectly by machines. This is done with the help of ontologies. An ontology, according to Tom Gruber [2] is the specification of a conceptualization. A conceptualization is an abstract and simplified view of the world that we want to represent. More 1 Laboratoire d’Informatique de Robotique et de Microélectronique de Montpellier (http://www.lirmm.fr) 2 http://www.univ-montp2.fr 3 Centre d’Etude Techniques de l’Equipement (http://www.cete-mediterranee.fr) simply an ontology represents knowledge as a set of concepts within a domain, and the relationships between those concepts.","Weaving the Web: The Past, Present and Future of the World Wide Web by its Inventor | Formal ontology in conceptual analysis and knowledge representation. Chapter: Towards principles for the design of ontologies used for knowledge sharing | Data.gouv.fr : de l’ouverture des données à l’ouverture des possibles | DataLift D2.1 Méthodes et indicateurs pour la sélection d’ontologies fiables et utilisables | Finding equivalent ontologies in Watson. ISWC | Falcons: searching and browsing entities on the semantic Web | Neologism: easy vocabulary publishing | D2R server – Publishing relational databases on the semantic Web. ISWC | Sesame: a generic architecture for storing and querying RDF and RDF Schema. ISWC | Benchmarking the Performance of Storage Systems that expose SPARQL Endpoints | Silk - a link discovery framework for the web of data | LIMES - A Time-Efficient Approach for Large-Scale Link Discovery on the Web of Data | MeLinDa: an interlinking framework for the Web of data | LDIF – Linked Data Integration Framework. ISWC | SPARQL Query Language for RDF | Sindice.com: Weaving the open linked data. ISWC | Describing linked datasets. LDOW | Semantic Sitemaps: Efficient and flexible access to datasets on the semantic Web. ESWC | DBPedia – A crystallization point for the Web of data",rejected,000
1205.2606.pdf.json,Exploring compact reinforcement-learning representations with linear regression,"Linear regression has, for decades, been a powerful tool in the kits of machine-learning researchers. While the field of Reinforcement Learning (RL) [16] has certainly made use of linear regression in approximating value functions [3], using online regression to learn parameters of a model has been limited to environments with linear dynamics (e.g. [7]), and has often been unable to make guarantees about the behavior of the resulting learning agent without strict assumptions. One of the great hindrances in applying linear regression to learn models in any RL environment was that the computational and sample efficiency guarantees of online regression learners (such as those that rely on distributional assumptions or do not maintain explicit confidences) did not port to the reinforcement-learning setting, which is not i.i.d. and where realizing what portion of the model needs to be explored is crucial to optimizing reward. Recently, the introduction of the KWIK (Knows What It Knows) framework [11] has provided a characterization of sufficient conditions for a model-learning algorithm to induce sample-efficient behavior in a reinforcement-learning agent. One of the first algorithms developed for this framework was a KWIK linear regression algorithm [15], which was used to learn the transition function of an MDP with linear dynamics. In this paper, we present an algorithm that improves on both the sample and computational bounds of this previous algorithm and apply it to a stable of learning problems for reinforcement-learning agents that employ “compact” representations. Specifically, we use KWIK linear regression (KWIK-LR) to learn the reward function in a factored MDP and the transition probabilities in domains encoded using Stochastic STRIPS [12] or Object Oriented MDPs (OOMDP) [5]. We note that learning these parameters is not typically associated with linear regression—this paper shows that KWIK-LR can be used to help learn models beyond its standard usage in lear",An improved on-line algorithm for learning linear evaluation functions | Adaptive and self-confident on-line learning | Least-squares temporal difference learning | R-MAX–a general polynomial time algorithm for near-optimal reinforcement learning | An object-oriented representation for efficient reinforcement learning | The adaptive kmeteorologists problem and its application to structure learning and feature selection in reinforcement learning | PAC adaptive control of linear systems | STRIPS: A new approach to the application of theorem proving to problem solving | Efficient reinforcement learning in factored MDPs | A Unifying Framework for Computational Reinforcement Learning Theory | Knows what it knows: A framework for self-aware learning | Learning symbolic models of stochastic domains | Improving action selection in MDP’s via knowledge transfer | Efficient structure learning in factored-state MDPs | Online linear regression and its application to model-based reinforcement learning | Reinforcement Learning: An Introduction | The many faces of optimism: a unifying approach | The First Probabilistic Track of the International Planning Competition,rejected,000
1205.2613.pdf.json,Measuring Inconsistency in Probabilistic Knowledge Bases,"Inconsistencies arise easily when experts share their knowledge in order to build a common knowledge base. Although these inconsistencies often affect only a little portion of the knowledge base or emerge from only little differences in the experts knowledge, they cause severe damage. Especially in knowledge bases that use classical logic as a means for knowledge representation, inconsistencies render the whole knowledge base useless, due to the well-known principle ex falso quodlibet. Therefore reasoning under inconsistency is an important field in AI and there are many proposals to deal with inconsistency in classical logic, e. g. (Rescher and Manor, 1970; Konieczny et al., 2005), or in other logical frameworks, e. g. paraconsistent logics (Bziau et al., 2007), default logics (Reiter, 1980), defeasible logics (Billington, 2008), and argumentation theory (Bench-Capon and Dunne, 2007). Furthermore there are several approaches to analyze and measure inconsistency in qualitative frameworks, e. g. (Lozinskii, 1994; Benferhat et al., 1997; Knight, 2001; Hunter and Konieczny, 2004), and some in quantitative frameworks (mainly possibilistic frameworks), e. g. (Dubois et al., 1992). Here, we aim at analyzing inconsistencies in a probabilistic framework and in particular measuring inconsistency in conditional probabilistic knowledge bases (Nute and Cross, 2002; Kern-Isberner, 2001; Benferhat et al., 1999; Rödder and Meyer, 1996). In these, knowledge is captured using conditionals (A |B) that describe rules of the form “If B then A” and are interpreted using conditional probabilities. In contrast to probabilistic networks like Bayesian Networks (Pearl, 1998) conditional probabilistic knowledge bases do not demand the complete specification of every conditional probability of every probabilistic dependence and thus do not define a unique probability distribution as the underlying model. Nonetheless, using maximum entropy methods (Grove et al., 1994) one can determine a singl",On the logic of theory change: Partial meet contraction and revision functions | Easy cases of probabilistic satisfiability | Argumentation in artificial intelligence | Some Syntactic Approaches to the Handling of Inconsistent Knowledge Bases: A Comparative Study – Part 1: The Flat Case | Possibilistic and Standard Probabilistic Semantics of Conditional Knowledge Bases | Propositional clausal defeasible logic | Fusion: General Concepts and Characteristics | Convex Optimization | Elements of Information Theory. WileyInterscience | Inconsistency in Possibilistic Knowledge Bases: To live with it or not live with it | Resolving inconsistencies in probabilistic knowledge bases | Random worlds and maximum entropy | Approaches to measuring inconsistent information | Shapley inconsistency values | Belief revision and information fusion in a probabilistic environment | Conditionals in Nonmonotonic Reasoning and Belief Revision | Measuring inconsistency | Reasoning under inconsistency: The forgotten connective | Resolving contradictions: A plausible semantics for inconsistent systems | The Uncertain Reasoner’s Companion: A Mathematical Perspective | Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference | A logic for default reasoning | On inference from inconsistent premises | Coherent Knowledge Processing at Maximum Entropy by SPIRIT | Elimination of inconsistent knowledge in the probabilistic expertsystem-shell spirit (in german) | A value for n-person games | Paraconsistent reasoning as an analytic tool,rejected,000
1205.2616.pdf.json,Bisimulation-based Approximate Lifted Inference,"While recent work in lifted inference [3, 15, 16, 17, 20] are promising steps towards developing efficient inference algorithms that can exploit the first-order structure provided by most first-order probabilistic models (see [8] for a survey), all of these techniques assume the first-order structure is provided in the input. In this work, we study the alternate problem of identifying the symmetry present in an underlying probabilistic model, and show how this can be exploited to provide new lifted inference algorithms. Our work builds on recent results on efficient query evaluation in probabilistic databases from the database community. A query over a probabilistic database results in a very large graphical model which has many repeated factors. In prior work [18], we showed how, using the symmetry present in the probabilistic model and methods closely related to the graph-theoretic concept of bisimulation, it is possible to compile a compressed version of the inference problem. The compressed data-structure, called an rv-elim graph, can then be used to perform faster inference. In this paper, we show how the above techniques are generally applicable to arbitrary graphical models, and, more importantly, develop approximate lifted inference techniques that allow the user to trade off accuracy of inference for computational efficiency. We show how our approximate lifted inference techniques can compress the rv-elim graph well beyond the compression achieved by exact lifted inference, producing more impressive speedups while keeping the error bounded using certain tunable parameters. Here is a summary of our contributions and results: • We review the results from [18] and show how they are applicable to general probabilistic graphical models. • Using techniques based on approximate bisimulation, we extend these methods and introduce a tunable parameter to move from approximate inference with high speedups to exact inference with perfect accuracy. • We introduce a seco",How to allocate network centers | Lifted first-order probabilistic inference | MPE and partial inversion in lifted probabilistic variable elimination | Mini-buckets: A general scheme for bounded inference | A threshold of ln(n) for approximating set cover | editors | Citeseer: An automatic indexing system | Approximation schemes for covering and packing problems in image processing and VLSI | An algorithmic approach to network location problems I: The p-centers | Graph triangulation: Algorithms giving small total state space | Automating the construction of internet portals with machine learning | Lifted probabilistic inference with counting formulas | SPOOK: A system for probabilistic object-oriented knowledge representation | Exploiting shared correlations in probabilistic databases | Collective classification in network data | Lifted first-order belief propagation | Approximation Algorithms | Generalized belief propagation | A simple approach to bayesian network computations,rejected,000
1205.2620.pdf.json,Exact Structure Discovery in Bayesian Networks with Less Space,"There has been relatively recent interest in devising exact algorithms for score-based structure learning in Bayesian networks (Eaton and Murphy, 2007; Koivisto and Sood, 2004; Koivisto, 2006; Perrier et al., 2008; Silander and Myllymäki, 2006; Singh and Moore, 2005). The research is motivated not only by theoretical curiosity but also by applications: an exact algorithm— that is guaranteed to produce an optimal solution or the exact quantity of interest—allows the user to concentrate on modelling issues and direct interpretation of the learning results, with no (extra) uncertainty on the quality of the algorithm’s output per se. The fastest known exact algorithms for Bayesian networks on n nodes (i.e, attributes or variables) compute and store intermediate results for all the possible 2n node subsets, running in time and space 2nnO(1), assuming the score obeys certain usual modularity properties (Koivisto and Sood, 2004; Ott and Miyano, 2003; Silander and Myllymäki, 2006; Singh and Moore, 2005). While both the time and the space requirement become soon prohibitive as n gets larger, it is particularly the space requirement that determines the feasibility limit in practice. Indeed, on typical modern desktop computers with a few gigabytes of memory the algorithms can handle networks on up to around 25 nodes before they run out of space, the running time being still in only some minutes or hours. The current record of 29 nodes was achieved by the streamlined Silander–Myllymäki implementation (Silander and Myllymäki, 2006) using nearly 100 gigabytes of hard disk. For making exact algorithms practically feasible in larger networks, reducing the space complexity is the main concern. To understand the nature of the algorithmic challenges at hand, it is useful to think the structure discovery problem as a “permutation problem”: one seeks a linear order of the n nodes that maximizes a sum of local scores, one per node; the local score for a node only depends on the set o",Complexity of finding embeddings in a k-tree | Dynamic programming treatment of the travelling salesman problem | Exact algorithms for exact satisfiability and number of perfect matchings | On exact algorithms for treewidth | A Bayesian method for the induction of probabilistic networks from data | Exact Bayesian structure learning from uncertain interventions | Being Bayesian about network structure: A Bayesian approach to structure discovery in Bayesian networks | Expected computation time for Hamiltonian path problem | Learning Bayesian networks: The combination of knowledge and statistical data | A dynamic programming approach to sequencing problems | Advances in exact Bayesian structure discovery in Bayesian networks | Exact Bayesian structure discovery in Bayesian networks | A comment on minimum feedback arc sets | Finding optimal gene networks using biological constraints | Finding optimal Bayesian network given a super-structure | A simple approach for finding the globally optimal Bayesian network structure | Finding optimal Bayesian networks by dynamic programming,rejected,000
1205.2621.pdf.json,Logical Inference Algorithms and Matrix Representations for Probabilistic Conditional Independence,"Knowledge elicitation is an important task in the field of reasoning under uncertainty [1]. For example, consider the problem of eliciting knowledge from several domain experts in an attempt to model a probabilistic system (e.g., a Bayesian or Markov network). The resulting incomplete expert feedback might be a combination of some specific subjective probabilities, (conditional) independence and dependence information for the random variables under consideration, and conditional probabilities. Furthermore, in some cases, statistical tests on different heterogeneous data sets could provide additional sources of evidence. Each of these bits of information can be interpreted as a constraint on the joint probability distribution one wants to model. Finding a suitable model can then be interpreted as a constraint satisfaction problem (CSP), and the approach to harness CSP solvers for instances of this and related problems has been known for more than 10 years (Druzdzel and van der Gaag [2], Dechter [3]). However, (conditional) independence and dependence statements pose a special problem, because they often introduce non-linear constraints which mostly result in infeasible CSP instances. Therefore, a remaining important challenge in the context of knowledge elicitation is to test for consistency of the (conditional) independence and dependence information that has been collected from different sources. For this to be possible, one would need an algorithm that decides the implication problem for CI statements (Geiger and Pearl [4]), that is, an algorithm that can infer CI statements which are logically implied by a set of given ones, relative to the class of discrete probability measures. There are several other important applications of an inference algorithm for CI statements. For example, the representation of CI information is mostly based on the well-known semigraphoid axioms of independence. There are ways to improve on this representation by using the notion of o-d",S | Elicitation of Probabilities for Belief Networks: Combining Qualitative and Quantitative Information | Constraint Processing | Logical and algorithmic properties of conditional independence and graphical models | Complexity of structural models | Stable independence and complexity of representation | Learning Markov Network Structure using Few Independence Tests | A Decision Method for Elementary Algebra and Geometry | Racing algorithms for conditional independence inference | Quantifier Elimination by Cylindrical Algebraic Decomposition–Twenty Years of Progress | Conditional Independence in Statistical Theory | On the conditional independence implication problem: A lattice-theoretic approach | Logical Properties of Stable Conditional Independence | Differential constraints | Ascending and descending conditional independence relations | Probabilistic reasoning in intelligent systems: networks of plausible inference | Probabilistic Conditional Independence Structures | Theory of Linear and Integer Programming | A Decision Procedure for Probability Calculus with Applications | Three counter-examples on semigraphoids,rejected,000
1205.2633.pdf.json,MAP Estimation of Semi-Metric MRFs via Hierarchical Graph Cuts,"Markov random fields (MRFs) offer an expressive and intuitive framework for several important problems in artificial intelligence and machine learning. Given a set of random variables along with a neighborhood relationship defined over them, an MRF offers a concise representation of the probability of each labeling (i.e. a particular assignment of labels to the variables) in terms of potentials defined over the cliques of random variables. Due to the central role of MRFs in various applications, algorithms that perform efficient and accurate inference on them are highly desirable. One important and well-studied class of inference, called maximum a posteriori (MAP) estimation, seeks the labeling with the maximum probability. We consider a special case of MAP estimation, known as semi-metric labeling [4], where (i) the size of the maximal clique is 2 (a pairwise MRF); and (ii) the pairwise potentials are defined by a semi-metric distance function over labels. Although these may seem like very restrictive assumptions, several problems in computer vision and related areas can be expressed using semi-metric labeling, from low level tasks like image denoising and stereo reconstruction [30] to high level tasks like pose estimation [9] and scene segmentation [27]. Hence, the semi-metric labeling problem merits special attention. We describe a novel algorithm for semi-metric labeling which approximates a given semi-metric distance function using a mixture of r-hierarchically well-separated tree (rHST) metrics [1]. The r-HST metrics form an amenable class of distance functions which admit elegant divide-andconquer approaches for several problems [1, 8]. In our case, they not only result in easier-to-solve instances of MAP estimation, they also provide an accurate approximation of the original problem. Given a mixture of r-HSTs, we reformulate semi-metric labeling using a set of r-HST metric labeling problems (i.e. MAP estimation for r-HST metric pairwise potentials), where ea","On approximating arbitrary metrics by tree metrics | Pseudo-boolean optimization | An experimental comparison of min-cut/max-flow algorithms for energy minimization in vision | Markov random fields with efficient approximations | Fast approximate energy minimization via graph cuts | Approximating a finite metric by a small number of tree metrics | A linear programming formulation and approximation algorithms for the metric labelling problem | A tight bound on approximating arbitrary metrics by tree metrics | Efficient matching of pictorial structures | Convergent message-passing algorithms for inference over general graphs with convex free energy | Approximation algorithms for classification problems with pairwise relationships: Metric labeling and Markov random fields | Robust higher order potentials for enforcing label consistency | On partial optimality in multi-label MRFs | Convergent tree-reweighted message passing for energy minimization | MRF optimization via dual decomposition: Message-passing revisited | Fast, approximately optimal solutions for single and dynamic MRFs | The partial constraint satisfaction problem: Facets and lifting theorems | MAP estimation of semi-metric MRFs via hierarchical graph cuts | An analysis of convex relaxations for MAP estimation | Improved moves for truncated convex models | FusionFlow: Discrete-continuous optimization for optical flow estimation | SIFT flow: Dense correspondence across different scenes | Object recognition from local scale-invariant features | Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference | Syntactic analysis of two-dimensional visual signals in noisy conditions | Efficient MRF deformation model for non-rigid image matching | Texton- Boost: Joint appearance, shape and context modeling for multi-class object recognition and segmentation | New outer bounds for the marginal polytope | Tightening LP relaxations for MAP using message passing | A comparative study of energy minimization methods for Markov random fields with smoothness-based priors | Support vector learning for interdependent and structured output spaces | Graph cut based optimization for MRFs with truncated convex priors | MAP estimation via agreement on trees: Message passing and linear programming | MAP estimation, linear programming and belief propagation with convex free energies | Global stereo reconstruction under second order smoothness priors | Generalized belief propagation",rejected,000
1205.2634.pdf.json,The Temporal Logic of Causal Structures,"Work on time series data has generally focused on identifying groups of similar or co-regulated elements using clustering techniques (Bar-Joseph, 2004) or finding patterns via data mining (Agrawal and Srikant, 1995) but comparatively little has been done to infer causal relationships between the elements of these time series. When trying to decipher the underlying structure of a system, what we would ultimately like to know are the rules governing its behavior. That is, knowing not simply its patterns of activity, but what is responsible for this activity would lead to a richer understanding of the system as well as the ability to better predict future events. In biological systems, one example of this is discovering dependencies between genes, finding those that influence others. These networks provide a model of biological processes that can then be tested and validated using knock-out experiments. Work in this area has primarily used graph based methods (Friedman et al., 2000; Spirtes et al., 2001; Murphy and Mian, 1999), such as Bayesian networks, which provide a less expressive framework than temporal logic in terms of the relationships they can represent and discover. We seek to enrich the existing frameworks in order to enable one to infer, describe and analyze arbitrarily complex causal relationships, which must involve temporal operators as well as probabilistic relationships and propositional connectives. We present a method for this purpose using a probabilistic temporal logic, which allows us to express a richer variety of causal relationships in a compact way. By posing our questions about how two events are related in terms of model checking and inference, we are able to efficiently infer relationships in large datasets with many variables. We will first introduce the problem of causality in philosophy and then discuss graphical methods for causal inference before describing our method and illustrating its use with two different data sets.","Mining sequential patterns | Symbolic model checking for probabilistic processes | Analyzing time series gene expression | The Transcriptome of the Intraerythrocytic Developmental Cycle of Plasmodium falciparum | Probabilistic Causality | Large-Scale Simultaneous Hypothesis Testing: The Choice of a Null Hypothesis | Causal reasoning in graphical time series models | Learning the structure of dynamic probabilistic networks | Using Bayesian Networks to Analyze Expression Data | Investigating causal relations by econometric models and cross-spectral methods | A logic for reasoning about time and reliability | Estimating the Null and the Proportion of non-Null effects in Large-scale Multiple Comparisons | Temporal logics as query languages for dynamic bayesian networks: Application to d. melanogaster embryo development | Towards inference and learning in dynamic bayesian networks using generalized evidence | Modelling gene expression data using dynamic bayesian networks | Causality: Models, Reasoning, and Inference | The Direction of Time | Causation, Prediction, and Search | Constructing Bayesian Network Models of Gene Expression Networks from Microarray Data | A probabilistic theory of causality",rejected,000
1205.2635.pdf.json,Constraint Processing in Lifted Probabilistic Inference,"Representations that mix graphical models and first-order logic—called either first-order or relational probabilistic models—were proposed nearly twenty years ago (Breese, 1992; Horsch and Poole, 1990) and many more have since emerged (De Raedt et al., 2008; Getoor and Taskar, 2007). In these models, random variables are parameterized by individuals belonging to a population. Even for very simple first-order models, inference at the propositional level—that is, inference that explicitly considers every individual—is intractable. The idea behind lifted inference is to carry out as much inference as possible without propositionalizing. An exact lifted inference procedure for first-order probabilistic directed models was originally proposed by Poole (2003). It was later extended to a broader range of problems by de Salvo Braz et al. (2007). Further work by Milch et al. (2008) expanded the scope of lifted inference and resulted in the C-FOVE algorithm, which is currently the state of the art in exact lifted inference. First-order models typically contain constraints on the pa- rameters (logical variables typed with populations). Constraints are important for capturing knowledge regarding particular individuals. In Poole (2003), each constraint is processed only when necessary to continue probabilistic inference. We call this approach splitting as needed. Conversely, in de Salvo Braz et al. (2007) all constraints are processed at the start of the inference (this procedure is called shattering), and at every point at which a new constraint arises. Both approaches need to use constraint processing to count the number of solutions to constraint satisfaction problems that arise during the probabilistic inference. Milch et al. (2008) adopt the shattering procedure, and avoid the need to use a constraint solver by requiring that the constraints be written in normal form. The impact of constraint processing on computational efficiency of lifted inference has been largely overlo",Construction of belief and decision networks | Operations for learning with graphical models | Lifted first-order probabilistic inference. In Introduction to Statistical Relational Learning | Introduction to Statistical Relational Learning | A dynamic approach to probabilistic inference using Bayesian networks | Combinatorial Problems and Exercises | Lifted probabilistic inference with counting formulas | First-order probabilistic inference | Lifted first-order belief propagation | A simple approach to Bayesian network computations,rejected,000
1205.2636.pdf.json,Monolingual Probabilistic Programming Using Generalized Coroutines,"Declarative programming is the division of what to do and how to do it into two modules that can be built and reused separately. In the case of probabilistic inference, the what is the definition of a stochastic model, and the how is the implementation of an inference algorithm. Dividing the two formally makes it easier to understand and maintain the meaning of the model and the working of the algorithm, especially in complex domains where it is impractical to customize an algorithm to a model by hand coding. Ever since Bayes nets were first used to represent distributions, declarative programming for probabilistic inference has been studied and practiced extensively (Koller et al. 1997; Getoor and Taskar 2007; Murphy 2007b; Goodman et al. 2008; inter alia). One approach is to encapsulate inference algorithms in a modeling toolkit, a library of distributions with operations such as conditionalization, then express models as client programs that invoke the toolkit through its API. Another approach is to express models in a probabilistic language, a programming language with constructs such as random choice, then encapsulate inference algorithms in interpreters or compilers for the language. These two approaches are dual, in that a toolkit operation is run by a model whereas a language implementation runs a model. They also have complementary strengths. On one hand, the development and use of a modeling toolkit takes advantage of an existing general-purpose language and its facilities such as types, a debugger, and I/O. In particular, if part of a model calls for a custom inference procedure, then the code for the model, written in the same language, can just perform the inference by sidestepping or extending the toolkit. Similarly, if a model needs to refer to an external database, then an existing connection library can be used. On the other hand, the syntax of a probabilistic language can express distributions more succinctly and naturally, as sampling procedures o","Abstracting control | Hierarchical Bayes compiler | Bucket elimination: A unifying framework for probabilistic inference | Markov logic: A unifying framework for statistical relational learning | Beyond continuations | Representing monads | AutoBayes: A system for generating data analysis programs from statistical models | Weighing and integrating evidence for stochastic simulation in Bayesian networks | Introduction to statistical relational learning | Church: A language for generative models | Logic continuations | Comparative evaluation of probabilistic logic languages and systems | Native delimited continuations in (bytecode) OCaml | Effective Bayesian inference for stochastic programs | The Objective Caml system, release | Case-factor diagrams for structured probabilistic modeling | BLOG: Probabilistic models with unknown objects | Bayes Net Toolbox for Matlab | The design and implementation of IBAL: A general-purpose probabilistic language | Artificial intelligence: Foundations of computational agents | Report on the probabilistic language Scheme | Artificial intelligence: A modern approach | A glimpse of symbolic-statistical modeling by PRISM | Simulation approaches to general probabilistic inference on belief networks",rejected,000
1205.2637.pdf.json,Counting Belief Propagation,"Message passing algorithms, in particular Belief Propagation (BP), have been very successful in efficiently computing interesting properties of probability distributions. Many graphical models, however, produce inference problems with a lot of symmetries not reflected in the graphical structure, and hence not exploited by BP. One of the most prominent examples are first-order and relational probabilistic models such as Markov logic networks [14]. Besides relational probabilistic models, however, there are also traditional, i.e., propositional probabilistic models that often produce inference problems with a lot of symmetries. In this work, we will demonstrate this for the classical model counting problem of computing the number of solutions of a given propositional formula. This problem vastly generalizes the NP-complete problem of propositional satisfiability, and hence is both highly useful and extremely expensive to solve in practice. In this context, the present work makes two contributions. The key contribution is the introduction of counting BP, which is a BP approach that exploits additional symmetries and hence often scales much better than standard BP. Its underlying idea is rather simple: group together nodes and factors into clusternodes and clusterfeatures that are indistinguishable in terms of messages received and sent given the evidence. Exploiting this symmetry present in the probabilistic model makes it often possible to greatly compress the factor graph. More importantly, the compressed graph can be used to perform a modified BP yielding the same results as BP applied to the uncompressed factor graph. The second contribution is that we show that such symmetries are actually encountered in challenging AI tasks. Specifically, we apply counting BP to inference for dynamic relational probabilistic models and to model counting for Boolean formulas. As our experimental evaluation will show, in both application domains significant efficiency gains are obt",Tractable inference for complex stochastic processes | editors | Lifted First Order Probabilistic Inference | MPE and Partial Inversion in Lifted Probabilistic Variable Elimination | A Model for Reasoning about Persistence and Causation | editors | Templatebased inference in symmetric relational Markov random fields | Leveraging Belief Propagation | Lifted Probabilistic Inference with Counting Formulas | The Factored Frontier Algorithm for Approximate Inference in DBNs | Loopy Belief Propagation for Approximate Inference: An Empirical Study | Reasoning in Intelligent Systems: Networks of Plausible Inference | First-Order Probabilistic Inference | Markov Logic Networks | Combining component caching and clause learning for effective model counting | Exploiting Shared Correlations in Probabilistic Databases | Lifted First-Order Belief Propagation,rejected,000
1205.2638.pdf.json,Temporal Action-Graph Games: A New Representation for Dynamic Games,"Game theory is the main formal model used to study decision-making in the presence of other rational agents (see e.g., [5]). In this paper we investigate game-theoretic models that include sequential moves (so-called extensiveform games) and utility uncertainty (so-called Bayesian games, or “chance nodes” in the extensive form). When agents move sequentially and are able to perfectly observe all moves, extensive-form games are said to exhibit perfect information; otherwise, extensive-form games exhibit imperfect information. In the last decade, researchers have begun to study compact representations of various game types, inspired by the success of probabilistic graphical models. For imperfectinformation extensive form games, the most influential model is multiagent influence diagrams, or MAIDs [11]. (Game networks are a very similar representation and were invented concurrently [13].) MAIDs are compact when players’ utility functions exhibit independencies; such compactness can also be leveraged for computational benefit [2]. Example 1: Twenty cars are approaching a tollbooth with three lanes. The drivers must decide which lane to use. The cars arrive in four waves of five cars each. In each wave, the drivers must pick lanes simultaneously, and can see the number of cars before them in each lane. A driver’s utility decreases with the number of cars that chose the same lane either before him or at the same time. When represented as a MAID, the game of Example 1 contains very little structure, meaning that computation would be highly inefficient. However, the game really is highly structured: agents’ payoffs exhibit context-specific independence (utility depends only on the number of cars in the chosen lane) and agents’ payoffs exhibit anonymity (utility depends on the numbers of other agents taking given actions, not on these agents’ identities). The problem with a straightforward MAID representation of this game is that it does not capture either of these kinds of ",Computing Nash equilibria of Action-Graph Games | A continuation method for Nash equilibria in structured games | Context-specific independence in Bayesian networks | Constant-space reasoning in dynamic Bayesian networks | Game Theory | Structure theorems for game trees | Causal independence for probability assessment and inference using Bayesian networks | A polynomial-time algorithm for Action-Graph Games | Action-graph games | Graphical models for game theory | Multi-agent influence diagrams for representing and solving games | Extensive games and the problem of information | Game networks | Local-effect games | Ignorable information in multiagent scenarios | Bayes Net Toolbox for Matlab | Evaluating influence diagrams using LIMIDs | Probabilistic reasoning for complex systems | Exploiting contextual independence in probabilistic inference | A class of games possessing pure-strategy Nash equilibria | Computational analysis of perfect-information position auctions,rejected,000
1205.2642.pdf.json,Improved Mean and Variance Approximations for Belief Net Responses via Network Doubling,"Consider a simple example. Suppose A represents presence/absence of a medical condition while B and Y are test results. Variables B and Y are conditionally independent given A, with A and B binary and Y continuous. The conditional independence assumption is represented by the directed acyclic graph structure in Figure 1(a). Let θa = P (A = a), θb|a = P (B = b |A = a), and let p(y |βa, σa) be the conditional density of Y given A = a, assumed normal with mean βa and variance σ2a. We want to estimate the probability that condition A is present given specified results from the two tests B and Y . Let Θ represent all of the parameters. If Θ were known, we would use the formula: q(Θ) = qa|b,y(Θ) = θaθb|ap(y |βa, σa)∑ a1 θa1θb|a1p(y |βa1 , σa1) . (1) In the Bayesian paradigm, uncertainty about Θ is quantified by modeling parameters as random variables. It follows that query probabilities such as (1) are also random. A query response is usually estimated by approximating its posterior mean. This approximation is similar to expression (1), but with θa and θb|a replaced by their posterior means and with the normal densities replaced by Student’s t densities. One may want more than just a point estimate. Van Allen et al. (2001, 2008) showed (for discrete networks) how one can approximate the variance and posterior distribution of a query. Their variance derivation employs the delta method; i.e., a first-order Taylor series expansion of the function q(Θ) about the posterior mean of Θ. They provide asymptotic theory and empirical experiments supporting this approach. They also showed how these approximations can be used to construct a Bayesian credible interval (error bars) for q(Θ). Guo and Greiner (2005) applied this delta method approximation as part of a mean squared error (i.e., squared bias + variance) measure designed to estimate the quality of different belief net structures when seeking a best classifier. Lee et al. (2006) provide a technique for combining independent b",,rejected,000
1205.2644.pdf.json,First-Order Mixed Integer Linear Programming,"Mixed integer linear programming has established itself as a successful formalism for decision-making under uncertainty in operation research and cooperative control, and has attracted attention more recently in AI and machine learning. For example, in OR, a common approach to solving multi-stage planning problems under uncertainty is stochastic programming with recourse (e.g., [Powell, 1996]); or, in AI, we can use MILPs for planning [Vossen et al., 1999] or to reason about uncertainty due to the actions of other agents in a nonzero-sum game [Sandholm et al., 2005]; or, in ML, we can use MILPs for MAP inference in graphical models (e.g., [Roth and Yih, 2005]); or, in cooperative control, we can use MILPs for task allocation under uncertainty [Alighanbari and How, 2005]. Many decision problems naturally contain objects, classes of objects, and relations among them. In such problems, there are many benefits to reasoning about entire classes of objects at once—so-called lifted reasoning. One benefit is representational: it is much simpler to state a single lifted constraint such as “all cars must follow the speed limit” than to state the constraint for each car separately. Another is computational: if we can derive a conclusion for all class members at once, then we don’t need to derive it separately for each individual object. Lifted inference may incur some initial overhead, but its cost is independent of the number of objects involved, even when this number is infinite. A final benefit is statistical: if we can share parameters among members of a class, we can often reduce the number of parameters we need to estimate, increasing the level of accuracy we can attain for a given amount of data. Unfortunately, MILPs lack an inherent mechanism to reason about classes of objects and relations. One might try to add this capability to MILPs using a “wrapper” or “compiler” such as AMPL [Fourer et al., 2002]: for example, to express a constraint that holds for all objects in","Cooperative task assignment of unmanned aerial vehicles in adversarial environments | Mathematical programming embeddings of logic | Lifted first-order probabilistic inference | Optimization methods for logical inference | Formulation of linear problems and solution by a universal machine | AMPL: A Modeling Language for Mathematical Programming | Outline of an algorithm for integer solutions to linear programs | Dudı́k. First-order mixed integer linear programming | Probabilistic entityrelationship models, PRMs, and plate models | Mixed logical/linear programming | BLOG: Probabilistic models with unknown objects | IBAL: A probabilistic rational programming language | The independent choice logic and beyond | A stochastic formulation of the dynamic assignment problem, with an application to truckload motor carriers | Integer linear programming inference for conditional random fields | Artificial Intelligence: A modern Approach | Mixed-integer programming methods for finding Nash equilibria | Markov logic in infinite domains | Lifted first-order belief propagation | On the use of integer programming models in AI planning | Integer and Combinatorial Optimization",rejected,000
1205.2645.pdf.json,Distributed Parallel Inference on Large Factor Graphs,"A computer cluster is a large collection of processors connected by a fast reliable communication network and configured to achieve a common task. Here we define a processor as a single processing element with a unique instruction counter1. Cluster computing confers both the obvious increase in computational throughput and memory capacity as well as the less obvious increase in memory bandwidth and cache capacity. With the availability of affordable commodity hardware and high performance networking, the AI community has increasing access to computer clusters. Unfortunately, many computationally intensive tasks in AI are not directly able to efficiently utilize cluster resources. Work by Newman et al. [2007] and Asuncion et al. [2008] in parallel inference for latent topic models and by Paskin et al. [2005] and Funiak et al. [2006] in distributed inference for sensor networks adopt a message based asynchronous computation model to address the important task of distributed graphical model inference. However their approaches are specialized to particular models or settings. Alternatively, in Gonzalez et al. [2009] we explored 1We treat each core on a multi-core computer as a separate processor. the problem of general parallel inference in the multicore shared memory setting. However, the shared memory model does not efficiently scale to large clusters, and the algorithm we proposed, ResidualSplash, makes scheduling assumptions that fail on large irregular models. Here, we extend the ResidualSplash algorithm to large factor graphs in the distributed memory cluster setting and address several critical challenges to distributed parallel inference. We adopt the message passing computational model for cluster parallelism. In this model, the state of the algorithm is spread over p processors which only exchange information by passing “messages.” This differs from the shared memory setting of Gonzalez et al. [2009], where every processor has direct access to all available me",Distributed inference for latent dirichlet allocation | Asynchronous distributed learning of topic models | A robust architecture for distributed inference in sensor networks | Distributed inference in dynamical systems | Residual splash for optimally parallelizing belief propagation | Probabilistic reasoning in intelligent systems: networks of plausible inference | Turbo decoding as an instance of Pearl’s belief propagation algorithm | Stereo matching using belief propagation | Understanding belief propagation and its generalizations | Approximate inference and protein folding | Residual belief propagation: Informed scheduling for asynchronous message passing | Multilevel k-way partitioning scheme for irregular graphs | Randomized static load balancing for tree-shaped computations | Algorithms for distributed termination detection | Detecting termination of distributed computations using markers | Markov logic: A unifying language for structural and statistical pattern recognition,rejected,000
1205.2647.pdf.json,Generating Optimal Plans in Highly-Dynamic Domains,"A natural way for an agent to decide how to act is to exploit a policy – a function that maps each state into an action to be performed. Unfortunately, computing a policy is time intensive, so in many applications an agent plans from a known initial state instead. Unfortunately, when the application is situated within a highly dynamic environment, this initial state may rapidly change in unpredictable ways during planning, possibly invalidating the current planning effort. We argue that neither boldly ignoring such changes nor replanning from scratch is an appealing option. While the former is unlikely to produce a good plan, the latter may never be able to complete a plan when unexpected events keep interrupting. Instead we propose an integrated planning and recovery algorithm that explicitly reasons about the relevance and impact of discrepancies between assumed and observed initial state. As a motivating example, consider a soccer playing robot in RoboCup, which, having the ball, deliberates about how to score. In RoboCup it is common to receive sensor readings 10 times per second. The game environment is very dynamic, resulting in frequent discrepancies between assumed and observed initial state. Such discrepancies may or may not affect the current planning process. But how can the robot tell? And how should the robot react when discrepancies are deemed relevant? For instance, assume that at some point during planning, the current most promising plan starts with turning slightly to face the goal and then driving there, pushing the ball. If the ball unexpectedly rolls 10 centimeters away while deliberating, the initial turn action may cause the robot to lose the ball, so this discrepancy is relevant and another plan, starting by re-approaching the ball, should be favored. But if the ball rolls closer, the original plan remains effective and the discrepancy should be ignored and planning continued. The contributions of this paper are three-fold: (1) We propose a n",Symbolic dynamic programming for first-order MDPs | Learning and executing generalized robot plans | University of Toronto | Fast plan adaptation through planning graphs: Local and systematic search techniques | A domainindependent algorithm for plan adaptation | Flucap: A heuristic search planner for first-order MDPs | A theory of plan modification | Heuristic search-based replanning | Plan reuse versus plan generation: A theoretical and empirical analysis | ADL: Exploring the middle ground between STRIPS and the situation calculus | Knowledge in Action: Logical Foundations for Specifying and Implementing Dynamical Systems | The fringesaving A* search algorithm - a feasibility study | Rationale-based monitoring for continuous planning in dynamic environments,rejected,000
1205.2651.pdf.json,Seeing the Forest Despite the Trees: Large Scale Spatial-Temporal Decision Making,"In some real world planning problems there are many actions to be taken in parallel over a spatial area. This is the case, for example, in urban planning when zoning different areas of a city for different uses. In infectious disease control, decisions need to be made about allocating medicine to thousands or millions of people spread across space based on need, cost, transportation or any number of other variables. In forestry planning, decisions come down to whether to cut each tree or not, or to perform some other activity at every point in the forest. We call problems of this form Large Scale Spatial-Temporal (LSST) planning problems. After further motivating the problem with details from the example of forestry planning we introduce a general definition of LSST planning as a reinforcement learning (Sutton and Barto, 1998) problem and discuss the properties a solution needs to possess. We demonstrate how policy gradients (Williams, 1992) can satisfy many of these properties for LSST problems. We compare two policy formulations: an explicit policy that identifies each location in space with parameters for controlling the actions taken and an abstract policy that represents the proportion of actions that will be taken across the entire space. We show that this abstract policy produces better results with far fewer parameters and we argue that the level of abstraction it uses more closely matches the level needed by human planners in forestry or other LSST domains that would utilize this method to aid in planning.",Recent advances in hierarchical reinforcement learning | Spatial forest planning: A review | Provincial level projection of the current mountain pine beetle outbreak | Coordinated reinforcement learning | Possible forest futures | Non-parametric policy gradients: A unified treatment of propositional and relational domains | Model-free least-squares policy iteration | Examining the performance of six heuristic optimisation techniques in different forest planning problems | Evaluation of policy gradient methods and variants on the cart-pole benchmark | Formal models and algorithms for decentralized decision making under uncertainty. JAAMAS | Reinforcement Learning: An Introduction | Policy gradient methods for reinforcement learning with function approximation | Simple statistical gradient-following algorithms for connectionist reinforcement learning,rejected,000
1205.2652.pdf.json,Complexity Analysis and Variational Inference for Interpretation-based Probabilistic Description Logics,"In this paper we investigate probabilistic description logics that are based on the well-known description logicALC. In ALC one deals with individuals, concepts, roles, Boolean operators, and restricted forms of quantification [1]. For example, the concept Fireman denotes the set of firemen, and Vegetarian u ∀buyFrom.Fireman denotes a set of individuals who are vegetarian and buy only from firemen. We can also have assertions such as Fireman(John), stating that John belongs to Fireman. We start from credalALC, a probabilistic description logic we have introduced previously [8, 33]. Credal ALC, referred to as CRALC, mixes constructs of ALC with features of relational Bayesian networks. Indeed most of this paper can be read as the study of those relational Bayesian networks that can be expressed with (variants) of ALC. In CRALC one can have probabilistic assessments such as P (C|D) = α for concepts C and D, or P (r) = β for role r. The semantics of these assessments is roughly given by: ∀x : P (C(x)|D(x)) = α, ∀x, y : P (r(x, y)) = β. Credal ALC is attractive because its semantics allows reasonably flexible probabilistic assessments and the calculation of probabilities over assertions; the language stays both close to the power of ALC and to the clarity of relational Bayesian networks. Section 2 reviews work on probabilistic description logics and in particular CRALC. To illustrate the main features of CRALC, consider an example whose syntax should be reasonably easy to grasp. Take the Kangaroo ontology, a small collection of facts about animals.1 Consider a probabilistic version as follows [33]: P (Animal)=0.9, P (Rational) =0.6, P (hasChild)=0.3, Human ≡ Animal u Rational, Beast ≡ Animal u ¬Rational, Parent ≡ Human u ∃hasChild.Human, P (Kangaroo|Beast) = 0.4, P (Kangaroo|¬Beast) = 0.0, MaternityKangaroo ≡ Kangaroo u ∃hasChild.Kangaroo. The most basic problem in CRALC is to compute the probability of an assertion, possibly conditional on other assertions. For instanc","Description Logic Handbook | Terminological cycles in a description logic with existential restrictions | Representing and Reasoning with Probabilistic Knowledge: A Logical Approach | The Classical Decision Problem | Nonrelativizing separations | On probabilistic inference by weighted model counting | PR-OWL: A framework for probabilistic ontologies | Loopy propagation in a probabilistic description logic | The inferential complexity of Bayesian and credal networks | Tractable reasoning with Bayesian description logics | Lifted first-order probabilistic inference | AND/OR search spaces for graphical models. Artificial Intelligence,171:73–106,2007 | BayesOWL: Uncertainty modeling in semantic web ontologies | Probabilistic ABox reasoning: preliminary results. Description Logics,pages104–111,2005 | 2U: An exact interval propagation algorithm for polytrees with binary variables | Introduction to Statistical Relational Learning | Reasoning about Uncertainty | Probabilistic description logics | From SHIQ and RDF to OWL: The making of a web ontology language | Approximate algorithms for credal networks with binary variables | Probabilistic reasoning in terminological logics | Relational Bayesian networks | Reasoning about infinite random structures with relational Bayesian networks | On the complexity of inference about probabilistic relational models | P-CLASSIC: A tractable probablistic description logic | and C | Stochastic Boolean satisfiability | Expressive probabilistic description logics | Managing uncertainty and vagueness in description logics for the semantic web | Gibbs and Markov random systems with constraints | Games against nature (extended abstract) | Computational Complexity | Inference in probabilistic ontologies with attributive concept descriptions and nominals | Logical and Relational Learning | Solving Bayesian networks by weighted model counting | Attributive concept descriptions with complements | A probabilistic terminological logic for modelling information retrieval | Lifted first-order belief propagation | The complexity of reasoning with cardinality restrictions and nominals in expressive description logics | Languages represented by Boolean formulas | Constructing free energy approximations and generalized belief propagation algorithms",rejected,000
1205.2655.pdf.json,Mean Field Variational Approximation for Continuous-Time Bayesian Networks,"Many real-life processes can be naturally thought of as evolving continuously in time. Examples cover a diverse range, including server availability, changes in socioeconomic status, and genetic sequence evolution. To realistically model such processes, we need to reason about systems that are composed of multiple components (e.g., many servers in a server farm, multiple residues in a protein sequence) and evolve in continuous time. Continuous-time Bayesian networks (CTBNs) provide a representation language for such processes, which allows to naturally exploit sparse patterns of interactions to compactly represent the dynamics of such processes [9]. Inference in multi-component temporal models is a notoriously hard problem [1]. Similar to the situation in dis- crete time processes, inference is exponential in the number of components, even in a CTBN with sparse interactions [9]. Thus, we have to resort to approximate inference methods. The recent literature has adapted several strategies from discrete graphical models to CTBNs. These include sampling-based approaches, where Fan and Shelton [5] introduced a likelihood-weighted sampling scheme, and more recently we [4] introduced a Gibbs-sampling procedure. Such sampling-based approaches yield more accurate answers with the investment of additional computation. However, it is hard to bound the required time in advance, tune the stopping criteria, or estimate the error of the approximation. An alternative class of approximations is based on variational principles. Recently, Nodelman et al. [11] introduced an Expectation Propagation approach, which can be roughly described as a local message passing scheme, where each message describes the dynamics of a single component over an interval. This message passing procedure can automatically refine the number of intervals according to the complexity of the underlying system [14]. Nonetheless, it does suffer from several caveats. On the formal level, the approximation has no c","Tractable inference for complex stochastic processes | Markov chains with stationary transition probabilities | Continuous time markov networks | Gibbs sampling in factorized continuous-time markov processes | Sampling for approximate inference in continuous time Bayesian networks | Handbook of stochastic methods | An introduction to variational approximations methods for graphical models | Continuous time Bayesian networks | Expectation maximization and complex duration distributions for continuous time Bayesian networks | Expectation propagation for continuous time Bayesian networks | Variational inference for Markov jump processes | Variational inference for Diffusion Processes | Reasoning at the right time granularity | Graphical models, exponential families, and variational inference | Dependence among sites in RNA evolution",rejected,000
1205.2659.pdf.json,Deterministic POMDPs Revisited,"The simplest model for sequential decision making is the deterministic model with known initial and goal states. Solutions are sequences of actions that map the initial state into a goal state that can be computed with standard search algorithms. This model has been studied thoroughly in AI with important contributions such as A*, IDA*, and others [30, 34]. The deterministic model has strong limitations on the type of problems that can be represented: it is not possible to model situations where actions have nondeterministic outcomes or where states are not fully observable. In such cases, one must resort to more expressive formalisms such as Markov Decision Processes (mdps) and Partially Observable mdps (pomdps). The generality of these models comes with a cost since the computation of solutions increase in complexity, specially for pomdps, and thus one gains in generality but loses in the ability to solve problems. pomdps, for example, are widely used as they offer one of the most general frameworks for sequential decision making [19], yet the known algorithms scale very poorly. However, we have seen that an important collection of problems that involve uncertainty and partial information have a common characteristic: they have actions with deterministic outcomes and the observations generated at each decision stage also behave deterministically. Indeed, these models have been used in recent proposals for planning with incomplete information [15, 16, 27], appear in works of more general scope [15, 20] and about causation [31], and are used for learning partially-observable action models [1]. These models were briefly considered in Littman’s thesis [21] under the name of Deterministic POMDPs (det-pomdps) for which some important theoretical results were obtained. Among others, he showed that a det-pomdp can be mapped into an mdp with an exponential number of states and thus solved with standard MDP algorithms, and that optimal nonstationary policies of polynomial h","Learning partially-observable deterministic action models | Learning to act using real-time dynamic programming | Dynamic Programming and Optimal Control, (2 Vols) | Labeled RTDP: Improving the convergence of real-time dynamic programming | An algorithm better than AO* | Algorithms for searching explicit AND/OR graphs and their applications to problem reduction search | Algorithm 360: Shortest path forest with topological ordering | On the diameter of permutation groups | On some problems of a statistical group theory, IV | Polynomial-time algorithms for permutation groups | The expected order of a random permutation | Expressive planning and explicit knowledge | LAO*: A heuristic search algorithm that finds solutions with loops | Contingent planning via heuristic forward search with implicit belief states | Conformant planning via heuristic forward search: A new approach | What makes some POMDP problems easy to approximate | The complexity of finding minimumlength generator sequences | Planning and acting in partially observable stochastic domains | Ppcp: Efficient probabilistic planning with clear preferences in partiallyknown environments | Algorithms for Sequential Decision Making | The computational complexity of probabilistic planning | Additive AND/OR graphs | Permutations of bounded degree generate groups of polynomial diameter | Complexity of finite-horizon markov decision process problems | Principles of Artificial Intelligence | From conformant into classical planning: Efficient translations that may be efficient too | The complexity of markov decision processses | Applications of heuristic search and information theory to sequential fault diagnosis | Heuristics | Causality: Models, Rreasoning and Inferece | Anytime point-based approximations for large POMDPs | Complexity of planning with partial observability | Artificial Intelligence: A Modern Approach | Introduction to Theory of Computation, 2nd Edition | Heuristic search value iteration for POMDPs | Perseus: Randomized point-based value iteration for POMDPs | The average order of a permutation",rejected,000
1205.2665.pdf.json,Lower Bound Bayesian Networks – An Efficient Inference of Lower Bounds on Probability Distributions in Bayesian Networks,"A Bayesian network is a popular means to represent joint probability distributions over a set of random variables. It consists of a graphical network which specifies dependencies between random variables by a directed graph, and of conditional probability tables (CPT) which specify for each variable a conditional probability distribution. Calculating the marginal probability distribution of a variable, given a set of observed variables (variables with evidence), is called inference in a Bayesian network. A special case of inference is prognostic inference which is the calculation of P (X|E1, . . . , Ev) if all evidence nodes E1, . . . , Ev are (direct or indirect) predecessors of node X and a predecessor of an evidence node is also an evidence node. Calculating any marginal distribution P (X) without evidence is, therefore, considered as a special case of prognostic inference. The inference result can be used, for example, to determine expected profits, or to make important decisions. Prognostic reasoning can be an important tool, for instance, in medicine where temporal dependencies are explicitly modeled with a Bayesian network. For example, the outcome of a treatment, measured by the life expectancy of a patient, can be modeled as a consequence of the observed symptoms before treatment, and a sequence of treatments [Lucas et al., 2004]. Obviously, outcomes and decisions of an inference are sensitive to the choice of the CPT in the Bayesian network. Since most of these probabilities are typically estimated, it makes sense to check how sensitive the outcome is regarding a change of these probabilities. A method which expresses the posterior as a function of a node probability is described in [Kjærulff and van der Gaag, 2000]. Various other types of approaches have been suggested to tackle this problem. A general idea is to model the uncertainty about the probabilities of each node and to propagate this uncertainty through the Bayesian network. A natural extension i",Knowledge fusion using Dempster-Shafer theory and the imprecise Dirichlet model | URL http://www.pmr.poli.usp.br/ltd/Software/ JavaBayes | Inference in polytrees with sets of probabilities | An optimal approximation algorithm for Bayesian inference | The inferential complexity of Bayesian and credal networks | Localized partial evaluation of belief networks | Interval influence diagrams | Approximate algorithms for credal networks with binary variables | Approximate inference in credal networks by variational mean field methods | Making sensitivity analysis computationally efficient | Bayesian networks in biomedicine and health-care | Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference | Intelligent probabilistic inference | Evidence absorption and propagation through evidence reversals | Interval probability propagation | Inferences from multinomial data: Learning about a bag of marbles,rejected,000
1205.2857.pdf.json,,"As a necessary supplement to some existing mathematical tools for handling uncertainty, Molodtsov [17] initiated the concept of soft sets via a set-valued mapping. A distinguishing feature of soft sets which is different from probability theory, fuzzy sets, and interval mathematics is that precise quantity such as probability and membership grade is not essential. This feature facilitates some applications because in most realistic settings the underlying probabilities and membership grades are not known with sufficient precision to justify the use of numerical valuations. Since its introduction, the concept of soft sets has gained considerable attention (see, for example, [1, 4, 8, 9, 10, 11, 12, 13, 14, 16, 20, 22, 24, 25]), including some successful applications in information processing [6, 7, 18, 26], decision [3, 15, 19], demand analysis [5], and forecasting [21]. In [14], Maji, Biswas, and Roy made a theoretical study of the soft set theory in more detail. Especially, they introduced the concepts of subset, intersection, union, and complement of soft sets and discussed their properties. These operations make it possible to construct new soft sets from given soft sets. Unfortunately, several basic properties presented in [14] are not true in general; these have been pointed out and improved by Yang [23] and Ali et al. [2]. In particular, to keep some classical set-theoretic laws true for soft sets, Ali et al. defined some restricted operations on soft sets such as the restricted intersection, the restricted union, and the restricted difference and improved the notion of complement of a soft set. Based upon these newly defined operations, they proved that certain De Morgan’s laws hold for soft sets. It is worth noting that the concept of complement [2, 14] 1 which is fundamental to De Morgan’s laws is based on the so-called NOT set of a parameter set. It means that the logic conjunction NOT is a prerequisite for defining the complement of a soft set; this is co","Soft sets and soft groups | On some new operations in soft set theory | An adjustable approach to fuzzy soft set based decision making | Soft rough sets with applications to demand analysis | On multi-soft sets construction in information systems | Soft set theoretic approach for dimensionality reduction | Extending soft sets with description logics | Soft set theory applied to ideals in d-algebras | Applications of soft sets in ideal theory of BCK/BCI-algebras | The normal parameter reduction of soft sets and its algorithm | An application of soft sets in a decision making problem | Generalised fuzzy soft sets | Soft set theory——First results | Texture classification using a novel, soft-set theory based classification algorithm | A fuzzy soft set theoretic approach to decision making problems | Exclusive disjunctive soft sets | A combined forecasting approach based on fuzzy soft sets | Vague soft sets and their properties | A note on “Soft Set Theory | Combination of interval-valued fuzzy set and soft set | Probabilistic soft sets | Data analysis approaches of soft sets under incomplete information",rejected,000
1205.3054.pdf.json,Approximate Modified Policy Iteration,"Modified Policy Iteration (MPI) (Puterman & Shin, 1978) is an iterative algorithm to compute the optimal policy and value function of a Markov Decision Process (MDP). Starting from an arbitrary value function v0, it generates a sequence of value-policy pairs πk+1 = G vk (greedy step) (1) vk+1 = (Tπk+1) mvk (evaluation step) (2) Appearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s). where G vk is a greedy policy w.r.t. vk, Tπk is the Bellman operator associated to the policy πk, and m ≥ 1 is a parameter. MPI generalizes the well-known dynamic programming algorithms Value Iteration (VI) and Policy Iteration (PI) for values m = 1 and m =∞, respectively. MPI has less computation per iteration than PI (in a way similar to VI), while enjoys the faster convergence of the PI algorithm (Puterman & Shin, 1978). In problems with large state and/or action spaces, approximate versions of VI (AVI) and PI (API) have been the focus of a rich literature (see e.g. Bertsekas & Tsitsiklis 1996; Szepesvári 2010). The aim of this paper is to show that, similarly to its exact form, approximate MPI (AMPI) may represent an interesting alternative to AVI and API algorithms. In this paper, we propose three implementations of AMPI (Sec. 3) that generalize the AVI implementations of Ernst et al. (2005); Antos et al. (2007); Munos & Szepesvári (2008) and the classification-based API algorithm of Lagoudakis & Parr (2003); Fern et al. (2006); Lazaric et al. (2010); Gabillon et al. (2011). We then provide an error propagation analysis of AMPI (Sec. 4), which shows how the Lp-norm of its performance loss can be controlled by the error at each iteration of the algorithm. We show that the error propagation analysis of AMPI is more involved than that of AVI and API. This is due to the fact that neither the contraction nor monotonicity arguments, that the error propagation analysis of these two algori",Fitted Qiteration in continuous action-space MDPs | approximate) iterated successive approximations algorithm for sequential decision processes | Tree-based batch mode reinforcement learning | Error propagation for approximate policy and value iteration | Approximate Policy Iteration with a Policy Language Bias: Solving Relational Markov Decision Processes | Classification-based policy iteration with a critic | Reinforcement Learning as Classification: Leveraging Modern Classifiers | Analysis of a Classification-based Policy Iteration Algorithm | Error Bounds for Approximate Policy Iteration | Performance Bounds in Lp-norm for Approximate Value Iteration | Finite-Time Bounds for Fitted Value Iteration | Modified policy iteration algorithms for discounted Markov decision problems | Approximate Modified Policy Iteration | Reinforcement Learning Algorithms for MDPs | Performance bound for Approximate Optimistic Policy Iteration | Let Π be a policy space with finite VC-dimension h = V C(Π) <∞ and s,rejected,000
1205.3109.pdf.json,Efficient Bayes-Adaptive Reinforcement Learning using Sample-Based Search,"An important objective in the theory of Markov Decision Processes (MDPs) is to maximize the expected sum of discounted rewards when the dynamics of the MDP are (perhaps partially) unknown. A discount factor pressures the agent to favor short-term rewards, but potentially costly exploration is necessary to discover how to get such rewards. This conflict leads to the well-known explorationexploitation trade-off. Early on, it was recognized [Bellman and Kalaba, 1959, Feldbaum, 1960] that one solution to the resulting partially observable MDP was to augment the regular state of the agent in the world with sufficient statistics for what it knows about the dynamics. One formulation of this idea is the augmented Bayes-Adaptive MDP (BAMDP) [Martin, 1967, Duff, 2002], in which the extra information is the posterior distribution over the dynamics, given the data so far observed. The agent starts in the belief state that corresponds to its prior and, by executing the greedy policy in the BAMDP whilst learning, acts optimally with respect to its belief in the original MDP. An attractive property of this framework for Bayesian reinforcement learning is that rich prior knowledge about statistics of the environment can be naturally incorporated into the planning process, potentially leading to more efficient exploration and exploitation of the uncertain world. The major obstacle to applying Bayesian reinforcement learning is its computational intractability. Various algorithms have been devised to approximate optimal learning, but often at rather large cost. In this paper, we present a tractable approach that exploits and extends recent advances in Monte-Carlo tree search [Kocsis and Szepesvári, 2006, Silver and Veness, 2010]. ar X iv :1 20 5. 31 09 v1 [ cs .L G ] At each iteration in our algorithm, a single MDP is sampled from the agent’s current beliefs. This single MDP is used to simulate a single episode. The outcome of this simulated episode is used to update the value of ea","A Bayesian sampling approach to exploration in reinforcement learning | Approaching Bayes-optimality using MonteCarlo tree search | On adaptive control processes | Pure exploration in multi-armed bandits problems | Smarter sampling in model-based Bayesian reinforcement learning | Bandit algorithms for tree search | Bayesian Q-learning | A | Efficient Bayesian parameter estimation in large discrete domains. Advances in neural information processing systems, pages 417–423 | Combining online and offline knowledge in UCT | Multi-armed bandit allocation indices. Wiley Online Library | A sparse sampling algorithm for nearoptimal planning in large Markov decision processes | Bandit based Monte-Carlo planning | Near-Bayesian exploration in polynomial time | Exploration of multi-state environments: Local measures and back-propagation of uncertainty | A Bayesian approach for learning and planning in Partially Observable Markov Decision Processes | Monte-Carlo planning in large POMDPs | Variance-based rewards for approximate Bayesian reinforcement learning | Integrating sample-based planning and model-based reinforcement learning | Bayesian sparse sampling for on-line reward optimization",rejected,000
1205.3336.pdf.json,DISTRIBUTION OF THE SEARCH OF EVOLUTIONARY PRODUCT UNIT NEURAL NETWORKS FOR CLASSIFICATION,"This research is about the distribution of processing involved in the search for the best product-unit neural network (PUNN) models [Durbin, 1990] [Martínez-Estudillo, 2006A], using evolutionary algorithms, EAs. A cluster of computers [Buyya, 1999] will be used to carry out the distribution of this processing. Many different types of neural network architectures have been used, but the most popular one has been the single-hidden-layer feedforward network. Amongst the numerous approaches that use neural networks in classification problems, we focus our attention on evolutionary artificial neural networks (EANNs). EANNs have been a key research area in the past decade providing an improved platform for optimizing network performance and architecture (number of hidden nodes and number of connections) simultaneously. [Miller, 1989] proposed that evolutionary computation was a very good candidate for searching the space of architectures because the fitness function associated with that space is complex, noisy, non-differentiable, multi-modal and deceptive. Since then, many evolutionary programming methods have been developed to evolve artificial neural networks, for instance [Yao, 1997] and [García-Pedrajas, 2002]. An objective of this paper is to design a neural network architecture that will be suitable for classification; this involves achieving a proper balance between the explorative/exploitative activities performed by a learning EA. The design of a search for good EANN models is usually based on trial and error (that is, exploring the number of nodes in the hidden layer and exploring the different parameters of the EA); the strategy follows a blind search using only a small group of possible configurations. This implies a high computational cost in order to solve a medium-sized problem, as well as the use of an EA in the search process, which makes the task practically overwhelming for even a well-equipped computer. In our case, we distribute certain network or EA","An evolutionary algorithm that constructs recurrent neural networks | Neural Networks for Pattern Recognition | High Performance Cluster Computing: Architectures and Systems, Vol. 1. Prentice Hall PTR, NJ | Weather forecasting with adaptive time-delay neural networks: A case study | Product Units: A computationally powerful and biologically plausible extension to backpropagation networks | Multiobjetive cooperative coevolution of artificial neural networks | Global optimization algorithms for training product unit neural networks | Training product unit neural networks with genetic algorithms | Introduction to Parallel Computing. Design and Analysis of Algorithms | Evolutionary Product Unit based Neural Networks for Regression | Hybridization of evolutionary algorithms and local search by means of a clustering method | Arquitectura de Computadores | Adaptative Pattern Recognition and Neural Networks | Proben1—A set of neural network benchmark problems and benchmarking rules. Fakultät für Informatik, Univ. Karlsruhe, Karlsruhe | Evolutionsstrategien: Optimierung technischer Systeme nach Prinzipien der biologischen Evolution | Law discovery from financial data using neural networks | On the Complexity of Computing and Learning with Multiplicative Neural Networks | Parallel Programming Techniques and applications using networked workstations and parallel computers | A new evolutionary system for evolving artificial neural networks",rejected,000
1205.3663.pdf.json,"The Good, the Bad, and the Odd: Cycles in Answer-Set Programs","Answer-set programming (ASP) is a popular framework to describe concisely search and combinatorial problems [14, 16]. It has been successfully applied in crypto-analysis, code optimization, the semantic web, and several other fields [18]. Problems are encoded by rules and constraints into disjunctive logic programs whose solutions are answer-sets (stable models). The complexity of finding an answer-set for a disjunctive logic program is ΣP2 -complete [4]. However this hardness result does not exclude quick solutions for large instances if we can exploit structural properties that might be present in real-world instances. Recently, Fichte and Szeider [5] have established a new approach to ASP based on the idea of backdoors, a concept that originates from the area of satisfiability [20]. Backdoors exploit the structure of instances by identifying sets of atoms that are important for reasoning. A backdoor of a disjunctive logic program is a set of variables such that any instantiation of the variables yields a simplified logic program that lies in a class of programs where the decision problem we are interested in is tractable. By means of a backdoor of size k for a disjunctive logic program we can solve the program by solving all the 2k tractable programs that correspond to the truth assignments of the atoms in the backdoor. For each answer set of each of the 2k tractable programs we need to check whether it gives rise to an answer set of the given program. In order to do this efficiently we consider tractable programs that have a small number of answer sets (e.g., stratified programs [9]). We consider target classes based on various notions of acyclicity on the directed/undirected dependency graph of the disjunctive logic program. A cycle is bad if it contains an edge that represents an atom from a negative body of a rule. Since larger target classes facilitate smaller backdoors, we are interested in large target classes that allow small backdoors and efficient algor","Towards a theory of declarative knowledge, 89–148 | U.N.: A polynomial algorithm for the parity path problem on perfectly orientable graphs | Parameterized Complexity | On the computational cost of disjunctive logic programming: Propositional case | Backdoors to tractable answer-set programming | Backdoors to Satisfaction | The alternating fixpoint of logic programs with negation | The well-founded semantics for general logic programs | The stable model semantics for logic programming | Classical negation in logic programs and disjunctive databases | Fixed-parameter complexity in AI and nonmonotonic reasoning | The even-path problem for graphs and digraphs | On odd and even cycles in normal logic programs | Stable models and an alternative logic programming paradigm | On the complexity of feedback set problems in signed digraphs | Logic programs with stable model semantics as a constraint programming paradigm | Permanents, Pfaffian orientations, and even directed circuits | Collection on answer set programming (ASP) and more | Pfaffian orientations, 0/1 permanents, and even cycles in directed graphs | Backdoors to typical case complexity | On the connections between backdoors, restarts, and heavy-tailedness in combinatorial search | Finding even cycles even faster | A Study of Answer set Programming",rejected,000
1205.3964.pdf.json,Machine Recognition of Hand Written Characters using Neural Networks,"Handwritten characters are vague in nature as there may not always be sharp perfectly straight lines, and curves not necessarily be smooth, unlikely the printed characters. Furthermore, characters can be drawn in different sizes and orientation which are often supposed to be written on a baseline in an upright or downright position. Therefore, a robust handwritten recognition system can be designed by considering these limitations. However, it is quiet tedious sometimes to recognize hand written characters as it can be seen that most of the people can not even read their own written notes. Therefore, there is an obligation for a writer to write clearly. But even today in Twenty First Century Handwritten communication has its own stand and most of the times, in daily life it is globally using as means of communication and recording the information like to be shared with others. Researchers already paid many efforts in designing hand written character recognition system most of them cited as [1-5] because of its important application like bank checking process, reading postal codes and reading different forms [6]. Handwritten digit recognition is still a problem for many languages like Arabic, Farsi, Chinese, English, etc [7]. A machine can perform more tasks than a human being in the same time; this kind of application saves time and money and eliminates the requirement that a human perform such a repetitive task. For the recognition of English handwritten characters, various methods have been proposed [8-12]. Also a few numbers of studies have been reported for Farsi language [13-15]. Proposed Hand written character recognition system for machine recognition can be developed in these phases: scanning of hand written characters i.e conversion into electronic data, usually an black & white image file; some preprocessing can be applied to the image; then the feature of the character will be extracted from the image; finally, on the basis of extracted features from the ","Recognition of handwritten Arabic characters | Arabic Text Recognition Using Neural Network | Online Handwriting Recognition with Support Vector Machine – A Kernel Approach | An Overview of Handwriting Recognition | Complementary Algorithms for Recognition of totally Unconstrained Handwritten Numerals | Benchmarking of state-of- the-art techniques | Handwritten numeral recognition using gradient and curvature of gray scale image | Robust vision-based features and classification schemes for off-line handwritten digit recognition | A Bayesian framework for deformable pattern recognition with application to handwritten character recognition | Handwritten character recognition based on moment features derived from image partition | Recognition of Persian handwritten digits using image profiles of multiple orientations | Recognition of English and Arabic numerals using a dynamic number of hidden neurons | Application of support vector machines for recognition of handwritten Arabic/Persian digits | Feature Extraction Methods for Character Recognition- A Survey, | A Neural Net OCR using geometrical and zonal pattern features | Classification of Hyperdimensional Data Based on Feature and Decision Fusion Approachs Using Projection Pursuit, Majority Voting, and Neural Networks | Reforming the theory of invariant moments for Pattern recognition, | Multicategory of Patterns Represented by High-Order Vectors of Multilevel Measurement | Recognition Letterpress Works Independent of Size and Displacement with Zernike Moments and Neural Networks | Recognition Printed Letters wit Zonong Features | Application of Combining classifiers for Recognition of Farsi handwritten digits",rejected,000
1205.3966.pdf.json,Neural Networks for Handwritten English Alphabet Recognition,"Optical character recognition is the past when in 1929 Gustav Tauschek got a patent on OCR in Germany followed by Handel who obtained a US Patent on OCR in USA in 1933. Since then number of character recognition systems have been developed and are in use for even commercial purposes also. But still there is a hope to build some more intelligent hand written character recognition system because hand writing differ from one person to other. His writing style, shape of alphabets and their sizes makes the difference and complexity to recognize the characters. Researchers already paid many efforts in designing hand written character recognition system most of them cited as [1-5] because of its important application like bank checking process, reading postal codes and reading different forms [6]. Handwritten digit recognition is still a problem for many languages like Arabic, Farsi, Chinese, English, etc [7]. A machine can perform more tasks than a human being in the same time; this kind of application saves time and money and eliminates the requirement that a human perform such a repetitive task. For the recognition of English handwritten characters, various methods have been proposed [8-12]. Also a few numbers of studies have been reported for Farsi language [13-15]. In some hand-writing, the characters are indistinguishable even to the human eye, and that they can only be distinguished by context. In order to distinguish between such similar characters, the tiny differences that they have must be identified. One of the major problems of doing this for hand written characters is that they do not appear at the same relative location of the letter due to the different proportions in which characters are written by different writers of the language. Even the same person may not always write the same letter with the same proportions. Here, the goal of a character recognition system is to transform a hand written text document on paper into a digital format that can be manip","Recognition of handwritten Arabic characters | Machine recognition of Arabic cursive script | Text Recognition Using Neural Network"" ISCAS 94 | Online Handwriting Recognition with Support Vector Machine – A Kernel Approach | An Overview of Handwriting Recognition | Complementary Algorithms for Recognition of totally Unconstrained Handwritten Numerals | Automatic Bankcheck Processing | Benchmarking of state-of- the-art techniques | Handwritten numeral recognition using gradient and curvature of gray scale image | Robust vision-based features and classification schemes for off-line handwritten digit recognition | A Bayesian framework for deformable pattern recognition with application to handwritten character recognition | Handwritten character recognition based on moment features derived from image partition | Recognition of Persian handwritten digits using image profiles of multiple orientations | Recognition of English and Arabic numerals using a dynamic number of hidden neurons | Application of support vector machines for recognition of handwritten Arabic/Persian digits",rejected,000
1205.4213.pdf.json,Online Structured Prediction via Coactive Learning,"In a wide range of systems in use today, the interaction between human and system takes the following form. The user issues a command (e.g. query) and receives a – possibly structured – result in response (e.g. ranking). The user then interacts with the results (e.g. clicks), thereby providing implicit feedback about the user’s utility function. Here are three examples of such systems and their typical interaction patterns: Web-search: In response to a query, a search engine presents the ranking [A,B,C,D, ...] and observes that the user clicks on documents B and D. Appearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s). Movie Recommendation: An online service recommends movie A to a user. However, the user rents movie B after browsing the collection. Machine Translation: An online machine translator is used to translate a wiki page from language A to B. The system observes some corrections the user makes to the translated text. In all the above examples, the user provides some feedback about the results of the system. However, the feedback is only an incremental improvement, not necessarily the optimal result. For example, from the clicks on the web-search results we can infer that the user would have preferred the ranking [B,D,A,C, ...] over the one we presented. However, this is unlikely to be the best possible ranking. Similarly in the recommendation example, movie B was preferred over movie A, but there may have been even better movies that the user did not find while browsing. In summary, the algorithm typically receives a slightly improved result from the user as feedback, but not necessarily the optimal prediction nor any cardinal utilities. We conjecture that many other applications fall into this schema, ranging from news filtering to personal robotics. Our key contributions in this paper are threefold. First, we formalize Coactive Learning as a model of int","Finite-time analysis of the multiarmed bandit problem | The non-stochastic multi-armed bandit problem | Predicting Structured Data | Scalable collaborative filtering with jointly derived neighborhood interpolation weights | Prediction, learning, and games | Yahoo! learning to rank challenge overview | Preference learning with gaussian processes | Pranking with ranking | Online convex optimization in the bandit setting: gradient descent without a gradient | An efficient boosting algorithm for combining preferences | Large margin rank boundaries for ordinal regression. In Advances in Large Margin Classifiers | Evaluating the accuracy of implicit feedback from clicks and query reformulations in web search | Beyond the session timeout: automatic hierarchical segmentation of search topics in query logs | Learning to rank for information retrieval | Introduction to Information Retrieval | Interactively optimizing information retrieval systems as a dueling bandits problem | The k-armed dueling bandits problem | Online convex programming and generalized infinitesimal gradient ascent",rejected,000
1205.4655.pdf.json,The View-Update Problem for Indefinite Databases,"A typical database system is large and complex. Users and applications rarely can access the entire system directly. Instead, it is more common that access is granted in terms of a view, a virtual database consisting of relations defined by a query to the stored and maintained database. Querying a view does not present a conceptual problem. In contrast, another key task, view updating, poses major challenges. Example 1. Let D = {q(a,b)} be a database over relation symbols q and r, where the relation r has arity three and is currently empty. Let us consider the view over D given by the Datalog program P = {p(X)← q(X ,Y ),r(X ,Y,Z)}. That view consists of a single unary relation p. Given the present state of D, the view is empty. To satisfy the request that p(a) holds in the view (as it is now, it does not), one needs to update the database D. Such update consists of executing update actions that specify facts to insert to and to delete from D. These update actions (in a simplified setting that we consider for now) are “signed” facts +F and −G, where +F stands for “insert F” and −G stands for “delete G.” In our case, the set of update actions {−q(a,b),+q(a,a),+r(a,a,a)} is a correct update to D. Executing it on D results in the database D′ = {q(a,a),r(a,a,a)}, which has the desired property that p(a) holds in the view determined by P. There are also other ways to satisfy the user’s request, for instance: {+r(a,b,a)} and {+q(c,d),+r(c,d,d)}, where c and d are any elements of the domain of the database. As this example suggests, view updating consists of translating a view-update request, that is, an update request against the view, into an update, a set of update actions against the stored (extensional) database. The example highlights the basic problem of view updating. It may be (in fact, it is common), that a view-update request can be fulfilled by any of a large number of database updates. One of them has to be committed to and executed. Thus, developing methods to","Intensional updates: Abduction via deduction | The role of abduction in database view updating | Abduction from logic programs: Semantics and complexity | Abduction compared with negation by failure | Handling existential derived predicates in view updating | The stable model semantics for logic programming | Classical negation in logic programs and disjunctive databases | Stratification criteria and rewriting techniques for checking chase termination | Database updates through abduction | A semantics-based approach to design of query languages for partial information | Consistency preserving updates in deductive databases | On closed world data bases | Updating knowledge bases while maintaining their consistency | Automatic constraint maintenance and updating defined relations | Semantic integrity support in sql: 1999 and commercial (object-)relational database management systems | Principles of Database and Knowledge-Base Systems, Volume I",rejected,000
1205.5098.pdf.json,A Simplified Description of Fuzzy TOPSIS,,Multi-criteria group decision making using a modified fuzzy topsis procedure | Ranking alternatives using fuzzy numbers | A method for group decision making with multigranularity linguistic assessment information,rejected,000
1206.0259.pdf.json,,,"A Computational Foundation for the Study of Cognition | Correlation vs. Causality: How/Why the Mind/Body Problem Is Hard. [Invited Commentary of Humphrey, N. ""How to Solve the Mind-­‐Body Problem""] Journal of Consciousness Studies | Topographic maps in human frontal and parietal cortex",rejected,000
1206.0918.pdf.json,Fuzzy Knowledge Representation Based on Possibilistic and Necessary Bayesian Networks,"Bayesian networks have attracted much attention recently as a possible solution to complex problems related to decision support under uncertainty. These networks are systems for uncertain knowledge representation and have a big number of applications with efficient algorithms and have strong theoretical foundations [1],[2],[3],[4],[5] and [11]. They use graphs capturing causality notion between variables, and probability theory (statistic data) to express the causality power. Although the underlying theory has been around for a long time, the possibility of building and executing realistic models has only been made possible because of recent improvements on algorithms and the availability of fast electronic computers. On the other hand, one of the main limits of Bayesian networks is necessity to provide a large number of numeric data; a constraint often difficult to satisfy when the number of random variables grows up. The goal of this paper is to develop a qualitative framework where the uncertainty is represented in possibility theory; an ordinal theory for uncertainty developed since more than ten years [6], [7], and [8]. Our framework propose to define a qualitative notion of independence (alternative to the probability theory), to propose techniques of decomposition of joined possibility distributions, and to develop some efficient algorithms for the revision of beliefs. Thus, on the first hand limitations of quantitative structure in Bayesian networks that use simple random variables have been noted by many researches. These limitations have motivated a variety of recent research in hierarchical and composable Bayesian models. On the other hand, another limitation of the use of probabilistic Bayesian networks in expert systems is difficulty of obtaining realistic probabilities. So to solve these problems we use a new modified possibilistic Bayesian method. Our new modified possibilistic Bayesian networks simultaneously make use of both possibilistic measures: ","Bayesian networks : a model of selfactivated memory for evidential reasoning | A constraint-propagation approach to probabilistic reasoning | Fusion, propagation and structuring in belief networks. UCLA Computer Science Department Technical Report | Graphoids : a graph-based logic for reasoning about relevance relations | Influence diagrams and d-separation | A semantics for possibility theory based on likelihoods | Fuzzy Sets and Systems: Theory and Applications | Qualitative possibilistic graphical models from independance to propagation algorithms | Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference.Morgan | Hybrid possibilistic networks. in proceeding of the Twentieth | On the transformation between possibilistic logic bases and possibilistic causal networks | The context model an integrating view of vagueness and uncertainty Int | Possibilistic networks with locally weighted knowledge bases | Fuzzy sets as a basis for a theory of possibility | Fuzzy Sets and Systems: Theory and applications | Belief structures, possibility theory and decomposable confidence | Possibilistic logic : a retrospective and prospective view | Constrained abductive reasoning with fuzzy parameters in Bayesian networks",rejected,000
1206.0925.pdf.json,Possibilistic Pertinence Feedback and Semantic Networks for Goal’s Extraction,"The effectiveness of a KES is therefore crucially related to the system's capability to deal with the vagueness and uncertainty of the Extraction process. Commercially available KESs generally ignore these aspects; they oversimplify both the representation of the Objects' content and the user-system interaction. The goal of a Knowledge Extraction System (KES) is to extract knowledge considered pertinent to a user's request, expressed in the natural language. The pertinence feedback of a KES is measured through parameters, which reflect the ability of the system to accomplish such goal. However, the nature of the goal is not deterministic, since uncertainty and vagueness are present in many different parts of the extraction process. The user's expression of his/her knowledge needs in a request is uncertain and often vague, the representation of an Object and/or a Goal informative content is uncertain, and so is the process by which a request representation is matched to an Object representation. The research in KE has aimed at modeling the vagueness and uncertainty, which invariably characterize the management of knowledge. A first glens of approaches is based on methods of analysis of natural language [1]. The main limitation of these methods is the level of deepness of the analysis of the language, and their consequent range of applicability: a satisfying interpretation of the Objects' meaning needs a too large number of decision rules even in narrow application domains. A second glens of approaches is more general: their objective is to define Extraction models, which deal with imprecision, and uncertainty independently on the application domain. The set of approaches belonging to this class goes under the name of Probabilistic Information Retrieval (IR) [2]. There is another set of approaches receiving increasing interest that aims at applying techniques for dealing with vagueness and uncertainty. This set of approaches goes under the name of Knowledge Extraction","Progress in the application of Natural Language Processing to Information Retrieval tasks | Fuzzy Sets and Semantic Networks for On- Line Assistance | Fuzzy Interactive System to Use Technical Divices: SIFADE | Introduction to modern information retrieval | Fuzzy sets and generalized Boolean retrieval systems | A mathematical model of a weighted Boolean retrieval system | An extended fnzzy linguistic approach to generalize Boolean information retrieval | A model for a weighted retrieval system | fIRST: fuzzy information retrieval system | Performance measurement in a fuzzy retrieval environment | Linguistic Variables Definition by Membership Function and Measure of Similarity | Measure of Similarity Between Fuzzy Concepts for Identification of Fuzzy User’s Requests in Fuzzy Semantic Networks. International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems.Vol | Relevance Feedback for Goal’s Extraction from Fuzzy Semantic Networks | A note on weighted queries in information retrieval systems | On ordered weighted averaging aggregation operators in multi criteria decision making | A Mathematical theory of evidence | theories of possibilities. application to the representation of knowledge in data processing | Data Word processor Telephone’s application Objects",rejected,000
1206.0976.pdf.json,,,,rejected,000
1206.1061.pdf.json,Use of Fuzzy Sets in Semantic Nets for Providing On-Line Assistance to User of Technological Systems,"Learning how to use new technological system is mainly an exploratory activity[2]. Exploring learning has shown to improve the abilities constructing to successful error handling and discovering, and eventually constructing, correct knowledge. But exploratory activity frequently leads to experience uninterested states does not reach the interested state goal. Users need assistance not only to avoid errors, but also to understand how the system interprets their commands [8, 9, 12]. In order to respond to a query, an executive assistant might know very precisely the goal the user has in mind [14], which means an object in a given state (the properties of the object being transformed). Moreover, even when goals are fairly well defined, it is often necessary to think about superordinate goals. The fuzzy set method has been used to develop the ""on-line instructions"" mechanisms of an Intelligent Assistance System. It can be seen as a supervisor of task execution that has the ""ideal user's knowledge"" of (i) prerequisites of procedures, (ii) subGoals structure[3]. And (iii) the semantic network of the elements of the device where applied procedures are used as properties, as well as (iv) the knowledge of perceptible and imperceptible effects of user's actions[4]. With an interactive dialogue with a user, the Assistance System tries to match items provided by users in natural language with the knowledge included in the ideal user's semantic network [3].","Entropy of similarity relations in questionnaires and decision trees | Formalisable models of user knowledge in human-computer interaction in working with computers: Theory versus Outcome | Fuzzy sets system for user's assistance: How Sifade diagnoses user's goal. The Second World Congress on Expert Systems: ""Moving towards Expert Systems Globally in the 21st Century | Fuzzy Sets and Semantic Nets for On-Line Assistance | Measure of Similarity Between Fuzzy Concepts for Identification of Fuzzy User’s Queries in Fuzzy Semantic Networks | Linguistic Variables definition by membership function and mesure of similarity | A Model and Representation for Type Information and Its Use in Reasoning with Defaults | The PROCOPE semantic network: an alternative to action grammars | An Object-oriented semantic description of procedures for evaluation of interfaces | Fuzzy control-heuristsce Regelung mittels unscharfer logik | Utilisation de hiérarchies de classes floues pour la représentation des connaissances imprécises et sujettes à exceptions: système SORCIER | Structural analysis of the intension and extension of semantic concepts | On mental models and the user interface. Human-computer interaction in Working with computers: Theory versus Outcome | Entropy measures under similarity relations | Similarity relations and fuzzy orderings | Pruf-a meaning representation language for naturel languages | Truth value flow inferences on factor spaces and approximate Reasoning based on Similarity Measures",rejected,000
1206.1291.pdf.json,Feature Weighting for Improving Document Image Retrieval System Performance,"Document Image Retrieval System (DIRS) based on keyword spotting is performing the matching directly in the image data bypassing OCR and using word-images as queries. In DIRS [1], no weights don’t assign to the extracted features and weights for all features is one, although some features more effect to retrieval. Feature weighting is a feature importance ranking algorithm where weights, not only ranks, are obtained [14]. Commonly used feature weighting methods only consider the distribution of a feature in the documents and do not consider class information for the weights of the features. Several methods were reported for feature weighting to be based on such as term frequency (TF) [16], inverse document frequency (IDF) [17]. In [15], a framework for integrating multiple, heterogeneous feature spaces in the kmeans clustering algorithm is presented. In this paper, we propose a feature weighting method for increase performance of Document Image Retrieval System based on exact word matching. The proposed method weights each feature in the words according to the different role of the features during the indexing process. The aim of this paper show that feature weighting recall, average precision. The reminder of the paper is organized as follows: section 2 surveys previous related works in document image retrieval. Section 3 describes Document Image Retrieval System. Section 4 describes the proposed system. Section 5 explains evaluation measures used in this paper. Section 6 will show the experimental results of the proposed system. Section 7 is the conclusion.","Papamarkos: “A Document Image Retrieval System | Matching word images for content-based retrieval from printed document images | Keyword Spotting in Document Images through Word Shape Coding”,10th | chew lim tan, “Document Image Retrieval through Word Shape Coding | The Indexing and Retrieval of Document Images. A Survey | Textual indexation of ancient documents DocEng’05 | Information Retrieval in Document Image Databases | Document Image Retrieval | G.,”Fontadaptative word indexing of modern printed documents | Imaged document text retrieval without OCR | Word recognition for information retrieval in the image domain | Fuzzy ARTMAP with Feature Weighting | Feature Weighting in k- Means Clustering | Indexing term weighting",rejected,000
1206.1319.pdf.json,Internet and Information Technology in Modern Organizations: Challenges & Answers 826 Certain Bayesian Network based on Fuzzy knowledge Bases,,Local and fuzzy logics | Relating and extending semantical approaches to possibilistic reasoning | Possibilistic logic | Fuzzy Set Theory and its Applications | On the transformation between possibilistic logic bases and possibilistic causal networks | Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference.Morgan | Possibilistic networks with locally weighted knowledge bases | Hybrid possibilistic networks | Possibilistic logic : a retrospective and prospective view | Constrained abductive reasoning with fuzzy parameters in Bayesian networks | Fuzzy Sets and Systems: Theory and applications,rejected,000
1206.1414.pdf.json,An Intelligent Approach for Negotiating between chains in Supply Chain Management Systems,"A supply chain is a complex and network of facilities and distribution channels which are responsible for provide and distribute materials throughout the chains. Materials can be raw materials, semi-finished product or final product. Primary and upstream chains in supply chain need raw materials and downstream chains send final product to consumer. Supply chain management applications in production industries and their supply chains consist of very complex techniques. Since there are also many other industries and chains in a supply chain of production industries, material distribution and supply management is one of the basic problems of these industries. Up to now, they have tried to increase speed in transfer chains messages using new technologies like internet and provide relationship between chains in the least time as possible. In current supply chain management methods (SCM), one central management is often used, that is, one of the chains which is nearer to chain center is recognized as manager of chains and tries to communicate with other chains using supply chain management systems. Supply chain management tries to solve one of the problems and discussions in production and operation management. Many published contexts mentioned to high supply chain potential in cooperation process between chains and tried to use this potential in providing combination of whole supply chain. On the basis of definition introduced by Kristopher: ""supply chain is the network of organizations that are involved, through upstream and downstream linkages, in the different processes and activities that produce value in the form of products and services in the hands of the ultimate consumer [2]"", but modern supply chains move towards converting organizations into chains and see a supply chain as the set of chains which can negotiate each other and move materials between each other. Therefore, in this paper we have tried to develop a new solution to communicate in chain supply chain","Supply Chain Management – Strategy, Planning, and Operation, Upper Saddle River | Logistics and Supply Chain Management: Strategies | Multiagent System Approach for Dynamic Lot-Sizing in Supply Chains | The bullwhip effect in supply chain | IBM Intelligent Agent Strategy | Developing material delivery processes in cooperation: An application example of the construction industry | Agent-mediated electronic commerce: a survey, Knowledge Engineering Review | Towards belief revision logic-based adaptive and persuasive negotiation | Auto-faq: An Experiment in Cyberspace Leveraging, | Architecture Table 1. Research domain  Literature Architecture design",rejected,000
1206.1418.pdf.json,A WEIGHTED COMBINATION SIMILARITY MEASURE FOR MOBILITY PATTERNS IN WIRELESS NETWORKS,"With the development of mobile computing and wireless communications, discovering knowledge about the movement of various groups of mobile objects in wireless networks has become critical in their mobility prediction. Although different mobile objects express differences in their movement behavior and the nature of their movement but they typically share similarities [1]. Discovering such similarities contributes significantly to predicting the next location of a mobile object based on the behaviors of members in a group. In our work [2], the prediction of the next location of a mobile object is only based on its own movement history. However, the incompleteness on information of movement history results in the lack of extracted mobility rules and may affect the accuracy of prediction. In this paper, we consider that with knowledge of groups to which a mobile object belongs, one can derive common behaviors among objects during their moving. Therefore, it is possible to predict the next location of an object based on the movement behavior of its group. And in turn, the behavior of a group of mobile objects is determined in terms of the similarity of movement patterns, which represent a homogeneous kind of correlations of behaviors of objects in wireless networks. The analysis of moving objects (i.e., entities whose positions or geometric attributes change over time) has recently attracted a great deal of studies, especially, investigating their trajectories (i.e. paths objects passed through in space and time). Measuring the similarity between trajectories and then clustering them are becoming crucial for movement prediction of mobile objects [3]. Approaches for computing the similarity between sequences in trajectory data of moving objects may be grouped into two classes. On the one hand, the methods based on Euclidean space such as in [4] [5] [6] [7] [8] consider similarity with the Euclidean distance. On the other hand, some works [9] [10] [11] have investigated t",Exploring Movement Similarity Analysis of Moving Objects,rejected,000
1206.1458.pdf.json,Dispelling Classes Gradually to Improve Quality of Feature Reduction Approaches,"Since the middle of 20 th century when artificial intelligence science was established, classification methods were too important. By the pass of time, datasets that were used for classification got more complex than past such as geographic or discovery dataset. One of the items that increase the complexity of dataset is the number of dimensions (features). So a new concept called feature reduction was inducted in the literature of AI (Fukunnaga 1991) [4]. Fukunnaga said, If we describe input data as a matrix like X= { … . . } , where ""n"" is the sample number and ""m"" is the original feature dimensions, So the purpose of linear feature extraction is to search for a projection matrix like W ′ that transforms into a desired low-dimensional representation ′ , where ′ W . Typically, the projection matrix W is learnt by optimizing a criterion describing certain desired or undesired statistical or geometric properties of the data set. Different criterions lead to different kinds of linear feature exaction algorithms. Among them, Principal Component Analysis (PCA) (Joliffe, 1986) and Linear Discriminant Analysis (LDA) (Fukunnaga, 1991) have been the two most popular ones owing to their simplicity and effectiveness. Another popular technique called Locality Preserving Projections (LPP) (He & Niyogi, 2004) [5], has been proposed for linear feature extraction by preserving the local relationships within the data set. In (Yan et al., 2007) [1], many classical linear feature extraction techniques are unified into a common framework known as Graph Embedding. To avoid the high time and memory usage associated with eigenvalue decomposition in LDA, the Spectral Regression Discriminant Analysis (SRDA) (Cai et al., 2008) [2], was proposed based on ridge regression. Now the output dataset Y is in a low-dimensional so the complexity of classification Y and the time of that are less. Also, computation complexity of Y for any other cases is less than X. It’s easy to know that feature extr",Graph embedding and extensions: A general framework for dimensionality reduction | An efficient algorithm for large-scale discriminant analysis | Robust Euclidean Embedding | Introduction to statistical pattern recognition | Locality preserving projections | Feature extraction using information theoretic learning | Kernel maximum entropy data transformation and an enhanced spectral clustering algorithm | robust feature extraction via information theoretic learning | Correntropy: Properties and applications in nongaussian signal processing | Breakdown points of Cauchy regression-scale estimators | On measures of information and entropy | Color texture classification approach based on combination of primitive pattern units and statistical features | Feature extraction by nonparametric mutual information maximization | To increase quality of feature reduction approaches based on processing input dataset,rejected,000
1206.1534.pdf.json,,"Software aging is a phenomenon that refers to progressive performance degradation or transient failures or even crashes in long running software systems such as web servers. It mainly occurs due to the deterioration of operating system resource, fragmentation and numerical error accumulation [1]. Unexpected downtime cost due to software aging is high mainly in ecommerce websites and safety/business-critical applications. Software aging injures the usability of the software system and brings inconvenience to the users. It mostly occurs due to the accumulation of runtime errors. Runtime errors are the resultant of residual software effects such as memory leaking and unreleased file locks. These residual defects are difficult to be unveiled in the testing phase because there are few observable errors during the in-house testing phase. Even if they are unveiled, practical experience shows that most of corresponding errors are transient in nature [6], and difficult to be localized and removed. Therefore, these residual defects must be tolerated by users during operational phase. Thus, like in humans, aging in software also cannot be avoided. We can just prolong the aging process or can reduce the effect caused by aging. So, the only possible solution to fight against aging is to reset the software system and clean its runtime environment before severe aging occurs, thereby avoiding system crash. This method is called software rejuvenation [7]. Software rejuvenation is a proactive fault management technique aimed at cleaning up the system internal state to prevent the occurrence of more severe crash failures in the future. It can maintain the robustness of software systems and avoid unexpected system outages.","Analysis of Software Aging in a Web Server | A Nonlinear Approach to Modeling of Software Aging in a Web Server | A Feedback Control Approach for Software Rejuvenation in a Web Server | A Threshold Autoregressive Model for Software Aging | An Approach for Estimation of Software Aging in a Web Server | On-board preventive maintenance: a design-oriented analytic study for long-life applications | Software Rejuvenation: Analysis, Module and Applications | Analysis of Software Rejuvenation Using Markov Regenerative Stochastic Petri Net | Analysis of software cost models with rejuvenation | Estimating software rejuvenation schedules in high assurance systems | Multilayer feedforward networks are universal approximators | Neural network forecasting for seasonal and trend time series | Fundamentals of Artificial Neural Networks | A Neural-Wavelet based Methodology for software Aging Forecasting | Httperf - A Tool for Measuring Web Server Performance | Application of an Uncertain Reasoning Approach to Software Aging Detection",rejected,000
1206.1898.pdf.json,A Nonparametric Conjugate Prior Distribution for the Maximizing Argument of a Noisy Function,"Historically, the fields of statistical inference and stochastic optimization have often developed their own specific methods and approaches. Recently, however, there has been a growing interest in applying inference-based methods to optimization problems and vice versa [1–4]. Here we consider stochastic optimization problems where we observe noise-contaminated values from an unknown nonlinear function and we want to find the input that maximizes the expected value of this function. The problem statement is as follows. Let X be a metric space. Consider a stochastic function f : X R mapping a test point x ∈ X to real values y ∈ R characterized by the conditional pdf P (y|x). Consider the mean function f̄(x) := E[y|x] = ∫ yP (y|x) dy. (1) The goal consists in modeling the optimal test point x∗ := argmax x {f̄(x)}. (2) Classic approaches to solve this problem are often based on stochastic approximation methods [5]. Within the context of statistical inference, Bayesian optimization methods have been developed where a prior distribution over the space of functions is assumed and uncertainty is tracked during the entire optimization process [6, 7]. In particular, non-parametric Bayesian approaches such as Gaussian Processes have been applied for derivative-free optimization [8, 9], also within the context of the continuum-armed bandit problem [10]. Typically, these Bayesian approaches aim to explicitly represent the unknown objective function of (1) by entertaining a posterior distribution over the space of objective functions. In contrast, we aim to model directly the distribution of the maximum of (2) conditioned on observations. The paper is structured as follows. Section 2 gives a brief description of the model suitable for direct implementation. The model is then derived in Section 3. Section 4 presents experimental results. Section 4 concludes.","A tutorial on bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning | Approximate inference and stochastic optimal control | Probabilistic Constrained Optimization: Methodology and Applications, chapter Statistical Inference of Stochastic Optimization Problems, pages 282–304 | Optimal control as a graphical model inference problem | Stochastic Approximation Algorithms and Applications | Application of bayesian approach to numerical methods of global and stochastic optimization | Practical Bayesian Optimization | Efficient global optimization of expensive blackbox functions | Gaussian processes for global optimization | Gaussian process optimization in the bandit setting: No regret and experimental design | The Elements of Statistical Learning | Simulation studies in optimistic Bayesian sampling in contextualbandit problems | A minimum relative entropy principle for learning and acting",rejected,000
1206.2082.pdf.json,Dimension Independent Similarity Computation,"Computing similarity between all pairs of vectors in large scale datasets is a challenge. Traditional approaches of sampling the dataset are limited and linearly dependent on the dimension of the data. We present an approach whose runtime is independent of the data dimension and geared towards modern distributed systems, in particular the MapReduce framework (Dean and Ghemawat, 2008). We focus on 5 similarity similarity measures: Cosine, Dice, Overlap, Conditional, and the Jaccard similarity measures. For Jaccard similiarity we present an improved version of the well known MinHash scheme (Broder, 1997). Our framework operates under the following assumptions, each of which we justify. First, we focus on the case where each dimension is sparse and therefore the natural way to store the data is segmented into dimensions. In our application each dimension is represented by a tweet, thus this assumption was natural. Second, our sampling scheme requires a “background model”, meaning the magnitude of each vector is assumed to be known and loaded into memory. In our application this was not a hurdle, since the magnitudes of vectors in our corpus needed to be computed for other tasks. To further address the issue, in the streaming computation model, we can remove the dependence by paying an extra logarithmic factor in memory used. Third, we prove results on highly similar pairs, c©2012 Reza Bosagh Zadeh and Ashish Goel. since common applications require thresholding the similarity score with a high threshold value. A ubiquitous problem is finding all pairs of objects that are in some sense ‘similar’ and in particular more similar than a threshold. For such applications of similarity, DISCO is particularly helpful since higher similarity pairs are estimated with provably better accuracy. There are many examples, including • Advertiser keyword suggestions: When targeting advertisements via keywords, it is useful to expand the manually input set of keywords by other similar key",Keyword generation for search engine advertising using semantic similarity between terms | Efficient exact set-similarity joins | Agglomerative clustering of a search engine query log | The hadoop distributed file system: Architecture and design | Semantic similarity between search engine queries using tem | Similarity search in high dimensions via hashing | Approximate nearest neighbors: towards removing the curse of dimensionality | Brute force and indexed approaches to pairwise document similarity comparisons with mapreduce | Web-scale distributional similarity and entity set expansion | Predicting click-through rate using keyword clusters | A web-based kernel function for measuring the similarity of short text snippets | Efficient set joins on similarity predicates | Evaluating similarity measures: a large-scale study in the orkut social network,rejected,000
1206.2347.pdf.json,Uncertain and Approximative Knowledge Representation to Reasoning on Classification with a Fuzzy Networks Based System,,Ordre et classification: algèbre et combinatoire. Paris: Hachette | Uncertainty in knowledge bases | Fuzzy Sets Based System for User's Assistance: How Sifade diagnoses user's goal | The Psychology of Human-Computer Interaction | Galois approach to the induction of concepts | Formalisable models of user knowledge in human-computer interaction in working with computers: Theory versus Outcome | Définition de classes d'objets flouts pour la représentation des connaissances procédurales et déclaratives. Troisième congrès national sur les applications des ensembles flous.Nîmes | Système interactif flou d’aide à l’utilisation de dispositifs techniques: SIFADE | Fuzzy Sets and Semantic Nets For On-Line Assistance | On-Line Assistance to User’s of Technological Systems using Fuzzy Sets and Semantic Nets. FLAIR'98 | A Model and Representation for Type Information and Its Use in Reasoning with Defaults | An Object-oriented semantic description of procedures for evaluation of interfaces | Problem-solving restructuration: elimination of implicit constraints | utilisation de hiérarchies de classes floues pour la représentation des connaissances imprécises et sujettes à exceptions: système SORCIER | Structural analysis of the intension and extension of semantic concepts | On mental models and the user interface. Human-computer interaction in Working with Computers: Theory versus Outcome | Semantic Networks of Action. NATO conference on Psychological and Educational Foundations of Technology-Based Learning Environments. Kolymbari (Crete) | Approximate Reasoning and Prototypical knowledge | Restructuring lattice theory: an approach based on hierarchies of concepts,rejected,000
1206.3111.pdf.json,,"Answer Set Programming (ASP) is a declarative approach to computer programming stemming roots in the area of nonmonotonic reasoning and logic programming (Gelfond and Lifschitz 1991; Niemelä 1999; Marek and Truszczyński 1999). The main advantage of ASP1 is its high declarative nature combined with a relatively high expressive power (Dantsin et al. 2001). After some pioneering work (Bell et al. 1994; Subrahmanian et al. 1995), nowadays there are a number of systems that support ASP and its variants (Anger et al. 2005; Dal Palù et al. 2009; Gebser et al. 2007; Janhunen and Niemelä 2004; Lefèvre and Nicolas 2009b; Leone et al. 2006; Lierler and Maratea 2004; Lin and Zhao 2004; Simons et al. 2002). The availability of some efficient systems 1 For introductory material on ASP, the reader might refer to (Baral 2003; Eiter et al. 2009). make ASP a powerful tool for developing advanced applications in several fields, ranging from Artificial Intelligence (Balduccini et al. 2001; Baral and Gelfond 2000; Baral and Uyan 2001; Friedrich and Ivanchenko 2008; Franconi et al. 2001; Nogueira et al. 2001; Wasp 2003) to Information Integration (Leone et al. 2005; Marileo and Bertossi 2010), Knowledge Management (Baral 2003; Bardadym 1996; Grasso et al. 2009), Bioinformatics (Palopoli et al. 2005; Dovier 2011; Gebser et al. 2011), and has stimulated some interest also in industry (Grasso et al. 2010; Ricca et al. 2010). ASP systems are evaluated in the now well-established ASP Competitions, that started with two informal trials at ASP Dagstuhl meetings in 2002 and 2005. The present competition, held at the University of Calabria (Italy), is the third official edition, since the rules of the contest were formalized and implemented in the first two “official” ASP Competitions (Gebser et al. 2007; Denecker et al. 2009). Besides comparing ASP systems with each other, one of the goals of the competition is to benchmark similar systems and declarative paradigms close in spirit to ASP. T",,rejected,000
1206.3232.pdf.json,AND/OR Importance Sampling,"Many problems in graphical models such as computing the probability of evidence in Bayesian networks, solution counting in constraint networks and computing the partition function in Markov random fields are summation problems, defined as a sum of a function over a domain. Because these problems are NP-hard, sampling based techniques are often used to approximate the sum. The focus of the current paper is on importance sampling. The main idea in importance sampling [Geweke, 1989, Rubinstein, 1981] is to transform the summation problem to that of computing a weighted average over the domain by using a special distribution called the proposal (or importance) distribution. Importance sampling then generates samples from the proposal distribution and approximates the true average over the domain by an average over the samples; often referred to as the sample average. The sample average is simply a ratio of the sum of sample weights and the number of samples, and it can be computed in a memory-less fashion since it requires keeping only these two quantities in memory. The main idea in this paper is to equip importance sampling with memoization or caching in order to exploit conditional independencies that exist in the graphical model. Specifically, we cache the samples on an AND/OR tree or graph [Dechter and Mateescu, 2007] which respects the structure of the graphical model and then compute a new weighted average over that AND/OR structure, yielding, as we show, an unbiased estimator that has a smaller variance than the importance sampling estimator. Similar to AND/OR search [Dechter and Mateescu, 2007], our new AND/OR importance sampling scheme recursively combines samples that are cached in independent components yielding an increase in the effective sample size which is part of the reason that its estimates have lower variance. We present a detailed experimental evaluation comparing importance sampling with AND/OR importance sampling on Bayesian network benchmarks. W",An empirical study of w-cutset sampling for bayesian networks | Ais-bn: An adaptive importance sampling algorithm for evidential reasoning in large bayesian networks | Hybrid propagation in junction trees | AND/OR search spaces for graphical models | Optimizing exact genetic linkage computations | Approximate inference algorithms for hybrid bayesian networks with discrete constraints. UAI2005 | Samplesearch: A scheme that searches for consistent samples | Mixing exact and importance sampling propagation algorithms in dependence graphs | Importance sampling algorithms for Bayesian networks: Principles and performance,rejected,000
1206.3233.pdf.json,Speeding Up Planning in Markov Decision Processes via Automatically Constructed Abstractions,"We focus on planning in stochastic shortest path problems (the problem of reaching some goal state under uncertainty) when planning time is critical — a situation that arises, for instance, in path planning for agents in commercial video games, where map congestions are modeled as uncertainty of transitions. Another example is path planning for multi-link robotic manipulators, where the uncertainty comes from unmodeled dynamics as well as sensor and actuator noise. More specifically, we consider the problem of finding optimal policies in a sequence of stochastic shortest-path problems (Bertsekas & Tsitsiklis, 1996), where the problems share the same dynamics and transition costs, and differ only in the location of the goal-state. When the state space underlying the problems is sufficiently large, exact planning methods are unable to deliver a solution within the required time, forcing the user to resort to approximate methods in order to scale to large domains. Exploiting the fact that multiple planning problems share the same dynamics and transition costs, we build an abstracted representation of the shared structure where planning is faster, then map the individual planning problem into the abstract space and derive a solution there. The solution is then refined back into the original space. In a related problem of path planning under real-time constraints in deterministic environments (e.g., Sturtevant, 2007), a particularly successful approach is implemented in the PR LRTS algorithm (Bulitko, Sturtevant, Lu, & Yau, 2007), which builds an abstract state space by partitioning the set of states into cliques (i.e., each state within each cluster is connected to each other state in that cluster with a single action). Each such cluster becomes a single abstract state. Two abstract states are connected by an abstract transition if there is a pair of non-abstract states (one from each abstract state) connected by a single action. The resulting abstract space is smaller ",State space reduction for hierarchical reinforcement learning | Effective control knowledge transfer through learning skill and representation hierarchies | Baldur’s Gate | Warcraft III: Reign of Chaos | Dynamic Control in Path-Planning with Real-Time Heuristic Search | Dynamic Control in Real-Time Heuristic Search. JAIR | Model reduction techniques for computing approximately optimal solutions for Markov decision processes | Hierarchical solution of Markov decision processes using macro-actions | Speeding up planning in Markov decision processes via automatically constructed abstraction | Solving factored MDPs using non-homogeneous partitions | Fast exact planning in Markov decision processes | Memory-efficient abstractions for pathfinding | Between MDPs and semi-MDPs: a framework for temporal abstraction in reinforcement learning,rejected,000
1206.3234.pdf.json,Adaptive Inference on General Graphical Models,"It is common in many applications to repeatedly perform inference on a variations of essentially the same graphical model. For example, in a number of learning problems we may use observed data to modify a portion of the model (e.g., fitting an observed marginal distribution), and then recompute various moments of the new model before updating the model further [8]. Another example is in the study of protein structures, where a graphical model can be used to represent the conformation space of a protein structure [15, 9]. The maximum-likelihood configuration in this model then corresponds to the minimum-energy conformation for the corresponding protein. An application of interest in this setting is to perform amino acid mutations in the protein to determine the effect of these mutations to the structure and the function of the protein. The changes described in the examples above can, of course, be handled by incorporating them into the model ∗U. A. Acar is supported by a gift from Intel. † R. R. Mettu is supported by a National Science Foundation CAREER Award (IIS-0643768). and then performing inference from scratch. However, in general we may wish to assess thousands of potential changes to the model; for example, the number of possible mutations in a protein structure grows exponentially with the number of considered sites. Adaptive inference refers to the problem of handling changes to the model (e.g. to conditional dependencies and even graph structure) more efficiently than performing inference from scratch. Delcher et al. [6] studied this problem under a set of fairly restrictive conditions, requiring that the graph be tree-structured and supporting only changes to the observed evidence in the model. They show that updates to observed evidence may be performed in expected O(log n) time, where n is the size of the graph. More recently, Acar et al. [2] gave a method of supporting more general changes to the model so long as the model remains tree-structured. Unf",Dynamizing static algorithms with applications to dynamic trees and history independence | Adaptive Bayesian inference | An experimental analysis of change propagation in dynamic trees | A graph-theory algorithm for rapid protein side-chain prediction | Bucket elimination: A unifying framework for probabilistic inference | Logarithmic-time updates and queries in probabilistic networks | Rotamer libraries in the 21st century | An iterative procedure for estimation in contingency tables | Free energy estimates of all-atom protein structures using generalized belief propagation | Factor graphs and the sum-product algorithm | Local computations with probabilities on graphical structures and their applications to expert systems | The Bayes net toolbox for Matlab | Probabilistic Reasoning in Intelligent Systems | A new force field for the molecular mechanical simulation of nucleic acids and proteins | Approximate inference and protein folding,rejected,000
1206.3235.pdf.json,Identifying reasoning patterns in games,"Games are strategic interactions between agents that have different capabilities, information and objectives. Such games, which often involve uncertainty about the world, have become vitally important in computer science as the basis for describing multiagent interaction. The standard solution concept for games is Nash equilibrium. Solving a game is usually taken to mean finding a Nash equilibrium which will specify the strategies of agents. Unfortunately, however, computing Nash equilibrium is a serious bottleneck to using the game theoretic approach; as Daskalakis et al. [2006] have shown, calculating a single Nash equilibrium is PPAD complete. The UAI community has developed graphical representations such as graphical games [Kearns et al. 2001], action graph games [Jiang and Leyton-Brown 2006] and multi-agent influence diagrams (MAIDs) [Koller and Milch 2001], all of which have structural properties that assist in the solution of games. Even in these frameworks, however, computing Nash equilibria can still be very hard. This paper addresses this bottleneck in two ways. First, it presents a method for simplifying a game in order to make it easier to solve. The method works by analyzing a MAID to discover the reasoning patterns that apply in the given situation. A reasoning pattern is a form of argument that can lead to or motivate a decision. Pfeffer and Gal [2007] showed that all reasoning patterns in MAIDs fall into one of four graphical categories. Furthermore, they showed that if no reasoning pattern holds for a particular decision, the agent making the decision has no reason to prefer one action over another. We present an algorithm that identifies whether reasoning patterns hold for different decisions, and simplifies the game if they do not. Our algorithm relies on the definitions of reasoning patterns in [Pfeffer and Gal 2007] and also integrates insights of Koller and Milch [2008] that identify cases in which edges can safely be removed from a MAID. We us",25 | In the 38th ACM Symposium on Theory of Computing | A Polynomial-Time Algorithm for Action-Graph Games | Graphical Models for Game Theory | Multi-Agent Influence Diagrams for Representing and Solving Games | Technical report MIT-CSAIL-TR-2008029 | Game Networks | On the Reasoning Patterns of Agents in Games | Bayes-Ball: The Rational Pastime | Multi-Agent Algorithms for Solving Graphical Games,rejected,000
1206.3240.pdf.json,Complexity of Inference in Graphical Models,"Graphical models offer a convenient representation for joint probability distributions over a large number of variables. Such models are defined as stochastic processes with respect to a graph: each vertex of the graph is associated with a random variable, and the edge structure specifies the conditional independence (Markov) properties among the variables. Due to their powerful modeling capabilities, graphical models have found applications in a variety of fields including computer vision (Szeliski, 1990), coding theory (McEliece et al., 1998), and statistical physics (Parisi, 1988). In many of these applications a commonly encountered problem is that of estimation or inference, which refers to computing the posterior marginal distribution of a variable at some vertex. We study the computational complexity of the inference problem in a graphical model consisting of discrete-valued variables as a function of structural properties of the underlying graph such as treewidth and planarity. It is well-known that inference is NP-hard if no assumptions are made about the structure of the underlying graphical model (Cooper, 1990), and remains NP-hard even to approximate (Roth, 1996) — assuming P 6= NP, for any algorithm there are some structures in which (approximate) inference takes time super-polynomial in the size of the structure. However, inference in specific structures can still be tractable. For models in which the underlying graph has low treewidth, the junction-tree method provides an effective inference procedure that has complexity polynomial in the size of the graph, though exponential in the treewidth. The notion of treewidth (Robertson and Seymour 1983; 1986) has led to several results in graph theory (Robertson et al., 1994) and to practical algorithms for a large class ofNP-hard problems (Freuder, 1990). Among these problems is inference in graphical models, which, as mentioned earlier, can be solved in polynomial-time if the treewidth of the underlying gra","Modern graph theory, vol | Loop series for discrete statistical models on graphs | The computational complexity of probabilistic inference using Bayesian belief networks | Probabilistic networks and expert systems | Subexponential parameterized algorithms on bounded-genus graphs and Hminor-free graphs | Algorithmic graph minor theory: Improved grid minor bounds and Wagner’s contraction | On the dimer solution of planar Ising models | Complexity of k-tree structured constraint satisfaction problems | Approximating polygons and subdivisions with minimum link paths | Which problems have strongly exponential complexity | Graphical models | Planar formulae and their uses | Can you beat treewidth? Proceedings of the 48th IEEE Symposium on Foundations of Computer Science (FOCS) (pp | Turbo decoding as an instance of Pearl’s ”Belief Propagation | Statistical field theory | Quickly excluding a planar graph | On the hardness of approximate reasoning | Bayesian modeling of uncertainty in low-level vision | Planar grid embedding in linear time | The complexity of counting in sparse, regular, and planar graphs | Approximation algorithms",rejected,000
1206.3244.pdf.json,Bayesian network learning by compiling to weighted MAX-SAT,"Bayesian network learning is a hard combinatorial optimisation problem which motivates applying state-ofthe-art algorithms for solving such problems. One of the most successful algorithms for solving SAT, the satisfiability problem in clausal propositional logic, is the local search WalkSAT algorithm [8]. The basic idea is to search for a satisfying assignment of a CNF formula by flipping the truth-values of atoms in that CNF. Both ‘directed’ flips which decrease the number of unsatisfied clauses and random flips are used. Frequent random restarts (‘tries’) are also used. The SAT problem can be extended to the weighted MAX-SAT problem where weights are added to each clause and the goal is to find an assignment that maximises the sum of the weights of satisfied clauses (equivalently minimises the sum of the weights of unsatisfied clauses which can then be viewed as costs). WalkSAT can be extended to MaxWalkSAT where truth value flipping is a mixture of random flips and those which aim to reduce the cost of unsatisfied clauses. Problems of probabilistic inference in Bayesian networks have already been encoded as weighted MAXSAT problems and various algorithms, including MaxWalkSAT have been applied to them [6, 7]. Similar approaches combined with MCMC have been used for inference in Markov logic [5]. The current paper appears to be the first to apply a MAX-SAT encoding to learning of Bayesian networks. The paper is structured as follows. Section 2 describes the synthetic datasets used. Section 3 describes how the necessary weights were extracted from these datasets. Section 4 is the key section where the method of encoding a BN learning problem as a weighted MAX-SAT one is given. Section 5 provides empirical evaluation of the technique for both model selection and model averaging. There then follow conclusions and pointers to future work in Section 6. All runs of MaxWalkSAT were conducted using the C implementation (sometimes slightly adapted) available from the WalkS",On inclusiondriven learning of Bayesian networks | Being Bayesian about network structure: A Bayesian approach to structure discovery in Bayesian networks | Learning Bayesian networks: The combination of knowledge and statistical data | Model selection and accounting for model uncertainty in graphical models using Occam’s window | Sound and efficient inference with probabilistic and deterministic dependencies | Solving Bayesian inference by weighted model counting | A dynamic approach to MPE and weighted MAX-SAT | Local search strategies for satisfiability testing,rejected,000
1206.3246.pdf.json,Strategy Selection in Influence Diagrams using Imprecise Probabilities,"An influence diagram is a graphical model for decision making under uncertainty [13]. It is composed by a directed graph where utility nodes are associated to profits and costs of actions, chance nodes represent uncertainties and dependencies in the domain and decision nodes represent actions to be taken. Given an influence diagram, a strategy defines which decision to take at each node, given the information available at that moment. Each strategy has a corresponding expected utility. One of the most important problems in influence diagrams is strategy selection, where we need to find the strategy with maximum expected utility. A simple approach is to evaluate each possible strategy and compare their expected utilities. However, the number of strategies grows exponentially in the number of decision to be taken. In this paper, we propose a new idea to find the best strategy based on a reformulation of the problem as an inference in a credal network [4]. We show through experiments that this approach can handle small and medium diagrams exactly, and provides an anytime approximation in case we stop the process early. Our idea works with a very general class of influence diagrams, named Limited Memory Influence Diagrams (LIMIDs) [15]. Limited Memory means that the assumption of no-forgetting usually employed in Influence Diagrams (that is, values of observed variables and decisions that have been taken are remembered at all later times) is relaxed. This class of diagrams is interesting because most other influence diagram proposals can be efficiently converted into LIMIDs. To solve strategy selection, many approaches work on special cases of influence diagrams, exploiting their characteristics to improve performance. In many cases, it is assumed that there is an ordering on which the decisions are to be taken and the no-forgetting rule, so as previous decisions are assumed to be known in the moment of the current decision [14, 18, 19, 20, 21]. The ordering of decision",Decision-theoretic specification of credal networks: A unified language for uncertain modeling with sets of Bayesian networks | A method for using belief updating as influence diagrams | A survey of concepts of independence for imprecise probabilities | Credal networks | Separation properties of sets of probabilities | Effects-based operations: a grand challenge for the analytical community | Inference in credal networks using multilinear programming | The inferential complexity of Bayesian and credal networks | Inference in credal networks through integer programming | Independence concepts for convex sets of probabilities | Effects-based operations: change in the nature of warfare | 2U: An exact interval propagation algorithm for polytrees with binary variables | Influence diagrams | From influence diagrams to junction trees | Representing and solving decision problems with limited information | Complexity results and approximation strategies for MAP explanations | A new method for influence diagram evaluation | Evaluating influence diagrams | Probabilistic inferences in influence diagrams | Stepwisedecomposable influence diagram | A factorization approach to evaluating simultaneous influence diagrams,rejected,000
1206.3248.pdf.json,Knowledge Combination in Graphical Multiagent Models,"Graphical models provide a compact representation for domains with decomposable structure, with concomitant computational advantages. Multiagent scenarios may be particularly amenable to decomposition, to the extent that interactions among the agents exhibit localized e ects. The idea of exploiting conditional independence among the e ects of agents' decisions was central to the multiagent in uence diagram (MAID) framework developed by Koller and Milch (2003). This observation was also a driving motivation for graphical game models, rst introduced by Kearns et al. (2001), and subsequently examined and extended in several research e orts (Kearns, 2007). In the basic graphical game approach, the model is a factored representation of a normal-form game, and special-purpose algorithms operate on this representation to identify approximate or exact Nash equilibria. Daskalakis and Papadimitriou (2006) demonstrated how to map a graphical game to a Markov random eld (MRF), assigning high potential to congurations where an agent plays a best response to its neighbors. They showed that the maximum a posteriori con gurations of the MRF correspond to purestrategy Nash equilibria (PSNE) of the game. This approach enables the exploitation of statistical inference tools for game-theoretic computation, including the full repertoire of graphical model algorithms. We build on these works to introduce graphical multiagent models (GMMs), which are simply graphical models where the joint probability distribution is interpreted as an uncertain belief (e.g., a prediction) about the agents' play. For instance, the Daskalakis and Papadimitriou mapping can be viewed as a GMM where we believe that the agents will play a PSNE if one exists. This is of course just one candidate for belief based on game-theoretic analysis. When reasoning about strategies to play, or designing a mechanism (which induces a game for other agents), we may wish to adopt alternative bases for forming beliefs about the","Computing pure Nash equilibria in graphical games via Markov random elds | Networks of in uence diagrams: A formalism for reasoning about agents' decision-making processes | Strictly proper scoring rules, prediction and estimation | Reinforcement learning algorithm for partially observable Markov decision problems | Mean eld approach to learning in Boltzmann machines | Computational game theory: A tutorial | Graphical games | Graphical models for game theory | Multi-agent in uence diagrams for representing and solving games | Internet industry partnerships | Graphical models for groups: Belief aggregation and risk sharing | Mechanism design based on beliefs about responsive play (position paper) | Information theory: The bridge connecting bounded rational game theory and statistical physics | Generalized belief propagation",rejected,000
1206.3250.pdf.json,Almost Optimal Intervention Sets for Causal Discovery,"Suppose we have a set of variables V = {X1, . . . , Xn} and we are interested in discovering the causal relations among these variables. That is, we want to find out which variable influences which other variable directly or indirectly. This problem is common in both the natural sciences (e.g. gene regulatory networks, drug testing etc.) and the social sciences (e.g. econometrics, policy decisions etc). Depending on the area of research the scientist will have different tools to investigate this problem and different model space assumptions and background knowledge will be appropriate or available. The main problem for the scientist is to determine and justify these assumptions and to use tools of investigation that will distinguish the true ∗Also: Department of Philosophy, Washington University in St. Louis, St. Louis, MO 63130; Contact: fde@berkeley.edu. causal structure from other possible causal structures, i.e. the scientist must reduce and, if possible, rule out underdetermination of the causal structure. For any particular set of causal variables, the scientist will consider a set of possible hypotheses that describe the causal relations among these variables. Causal Bayes nets (Spirtes et al. 2000; Pearl 2000) provide a concise framework by representing causal structures in terms of directed acyclic graphs (DAGs) connecting the variables, and a probability distribution over these variables, that factors according to the DAG. If nothing is known about the causal structure then the set of hypotheses is large, namely, all possible DAGs over the set of variables, including maybe structures that involve latent variables. For these cases search procedures can and have been devised (see Eberhardt 2007 for details and references) that – given a set of assumptions over the model space – determine the causal structure uniquely, or give a precise specification of the remaining underdetermination. In particular, the following result is relevant to this paper. In Eberhar","Optimal structure identification with greedy search | Causal discovery from a mixture of data | On the number of experiments sufficient and in the worst case necessary to identify all causal relations among N variables | Causation and Intervention | Graphs with monochromatic complete subgraphs in every edge coloring | Improved approximation algorithms for maximum cut and satisfiability problems using semidefinite programming | Causal inference and causal explanation with background knowledge | A decision theoretic approach to learning bayesian networks | Active learning of causal bayes net structure | Causality | A linear non-gaussian acyclic model for causal discovery | Causation, Prediction and Search | Active learning for structure in bayesian networks",rejected,000
1206.3253.pdf.json,Learning and Solving Many-Player Games through a Cluster-Based Representation,"Consider the problem of solving non-cooperative games of realistic size. As the number of agents increases, the size of the game increases exponentially and it becomes intractable to even represent a game explicitly never mind solve for the equilibrium of the game. Recognizing this, one direction adopted in the literature on computational game theory is to assume that games have some underlying structure and focus on succinctly representable games; e.g., graphical games [6] and action-graph games [2]. But what if there is no exact, structured representation of a game? A second natural direction is to find a suitable approx- imation of the game, that can be solved and will provide a good model of the strategic characteristics of the actual game, so that agents have low regret from adopting the strategy determined by solving the approximate game. This is the direction we follow in the current paper.1 We consider the use of a cluster-based representation, in which the same strategy is ultimately prescribed to every agent in a cluster. A cluster groups together agents with a similar “strategic view” of the game. This means that they have similar payoffs and similar effects on other agents. We do not require that the actual game is symmetric and allow for agents with different payoff functions even within a cluster. We do not require explicit knowledge of the full game. Instead, we learn (offline) the cluster-based representation from data consisting of strategy profiles and payoffs. The data may be obtained from observations of play, or we may have access to a simulator with which to generate payoffs for different strategy profiles. We learn both the clustering and also the payoffs to agents in each cluster given each profile of cluster strategies. A natural next step is to solve a clustered representation of the game to find a Nash equilibrium, and recommend the equilibrium strategies to agents in the original many-player game. However, using a naive clustered represen",Inductive reasoning and bounded rationality | Computing Nash equilibria of action-graph games | Progress in approximate nash equilibria | Computing equilibria in anonymous games | Analogy-based expectation equilibrium | Graphical models for game theory | Efficient nash computation in large population games with bounded influence | Gambit: Software tools for game theory | Noncooperative games | Learning payoff functions in infinite games | Approximate strategic reasoning through hierarchical reduction of large symmetric games,rejected,000
1206.3255.pdf.json,Church: a language for generative models,"Probabilistic models have proven to be an enormously useful tool in artificial intelligence, machine learning, and cognitive science. Most often these models are specified in a combination of natural and mathematical language, and inference for each new model is implemented by hand. Stochastic programming languages [e.g. 12, 14, 10] aim to tame the model-building process by giving a formal language which provides simple, uniform, and re-usable descriptions of a wide class of models, and supports generic inference techniques. In this paper we present the Church stochastic ∗The first two authors contributed equally to this work. programming language (named for computation pioneer Alonzo Church), a universal language for describing generative processes and conditional queries over them. Because this language is based on Church’s lambda calculus, expressions, which represent generative models, may be arbitrarily composed and abstracted. The distinctive features of Church, and the main contributions of this paper, are: 1) a Lisp-like language specification in which we view evaluation as sampling and query as conditional sampling, 2) a stochastic memoizer, which allows separate evaluations to share generative history and enables easy description of non-parametric probabilistic models, and, 3) generic schemes for exact and approximate inference, which implement the query primitive, so that any Church program may be run without writing specialpurpose inference code.","Structure and Interpretation of Computer Programs | The infinite hidden Markov model | Composable Probabilistic Inference with Blaise | A Set of Postulates for the Foundation of Logic | Adaptor grammars: A framework for specifying compositional nonparametric Bayesian models | Learning systems of concepts with an infinite relational model | The Infinite PCFG using Hierarchical Dirichlet Processes | WinBUGS-A Bayesian modelling framework: Concepts, structure, and extensibility | Random-world semantics and syntactic independence for expressive languages | A Basis for a Mathematical Theory of Computation | BLOG: Probabilistic models with unknown objects | Stochastic logic programs | IBAL: A probabilistic rational programming language | Combinatorial stochastic processes, 2002. Notes for Saint Flour Summer School | Report on the probabilistic language scheme | Definitional interpreters for higherorder programming | Markov logic networks | PRISM: A symbolicstatistical modeling language | A Constructive definition of Dirichlet priors | Probabilistic inference for solving (PO)MDPs",rejected,000
1206.3258.pdf.json,Toward Experiential Utility Elicitation for Interface Customization,"Intelligent software customization has become increasingly important as users are faced with larger, more complex applications. For a variety of reasons, software must be tailored to specific individuals and circumstances [21]. For example, adaptive interfaces are critical as different users may: require different functionality from multi-purpose software [5]; prefer different modes of interaction; use software on a variety of hardware devices [12]; or, due to expanding software complexity, require online and automated help to identify and master different software functions [16]. In the latter case, a system should ideally adapt the help it provides and the decision to interrupt a user [15] to account for specific user preferences. In this paper, we focus on interface customization where the attributes of interface widgets (e.g., location, transparency, and functionality) are automatically tailored to the needs of specific users. In particular, we are interested in intelligent systems that learn to predict user goals over time based on observed user behavior, and suggest ways (e.g., through interface customization) to help the user complete the desired goal. Considerable work has been devoted to the prediction of user needs and goals (e.g., [16; 1; 28; 3] among others), much of it is focused on developing probabilistic models of user goals. Less emphasis has been placed on assessing user preferences for software interaction and customization (for exceptions, see [11; 17]). However, accounting for user preferences is critical to good interface customization. For instance, consider automated word completion [10]. Some users may prefer single-word suggestions, while others may prefer several different suggestions. Similarly, some users may be satisfied with “partial help” (e.g., a partially correct word that saves a few keystrokes) while others may wish to use only completely correct completions. These preferences, and more importantly, a user’s strength of preference",Bayesian models for keyhole plan recognition in an adventure game | Optimal control of Markov decision processes with incomplete state estimation | Statistical goal parameter recognition | A POMDP formulation of preference elicitation problems | What role can adaptive support play in an adaptable system | Psychology of HCI | Utility elicitation as a classification problem | Implicit interest indicators | Data-driven refinement of a probabilistic model of user affect | User-friendly text prediction for translators | Preference elicitation for interface optimization | SUPPLE: automatically generating user interfaces | On the rate of gain of information | Cognitive modeling reveals menu search is both random and systematic | Learning and reasoning about interruption | The Lumière project: Bayesian user modeling for inferring the goals and needs of software users | BusyBody: creating and fielding personalized models of the cost of interruption | Distinction bias: misprediction and mischoice due to joint evaluation | Who’s asking for help? A Bayesian approach to intelligent assistance | The need for an interaction cost model | Requirements analysis for customizable software: a Goals-Skills-Preferences framework | Stimulus information as a determinant of reaction time | Predicting utility | Utility maximization and experienced utility | Back to Bentham? explorations of experienced utility | Automatic prediction of frustration | Decisions with Multiple Objectives: Preferences and Value Trade-Offs | Adaptive goal recognition | Interactive assessment of user preference models: The automated travel assistant | Beyond bags of words: Modeling implicit user preferences in information retrieval | User-involved preference elicitation | Intelligent profiling by example,rejected,000
1206.3261.pdf.json,Learning When to Take Advice: A Statistical Test for Achieving A Correlated Equilibrium,"In settings where agents repeatedly interact with each other (for example, through a repeated game), there are great opportunities for learning since agents are able to adapt their strategies given the history of play. This problem has garnished a lot of attention from several research communities, including the AI community and the game theory community. While many criteria have been proposed for measuring the success of learning approaches, one commonly used measure is whether the agents learn how to best-respond to the strategies being played by the others. That is, does the learning process converge to an equilibrium. In this paper we study the problem of agents interacting with each other in a repeated game setting, but we introduce a third party mediator or advisor who makes strategy suggestions to the agents. Ideally, by following the suggestions of the mediator, agents will be able to learn how to play against each other, possibly even reaching mutually beneficial outcomes which would not have been possible without the mediation. That is, our goal is for the agents to learn and adapt so that they find a correlated equilibrium [1]. However, a mediator is only useful if it can make good sug- gestions. Even if a mediator tries to make good suggestions it may be prevented by coding errors, memory limitations, etc. For an agent to accept a mediator’s suggestions, there must be some way for the agent to verify that the suggestions are reasonable. A mediator might not be willing to share its code with the agents, or be aware of its own limitations. Therefore, for a truly robust system, the agents themselves must have a way of checking the mediator’s suggestions. Thus, this paper introduces a statistical test based on hypothesis testing that, with high probability, can verify the mediator’s suggestions. While hypothesis testing has been proposed in the multiagent learning literature as a tool that agents might use to learn how to play Nash equilibria [5], to the bes","Subjectivity and correlation in randomized strategies | Statistical Power Analysis for the Behavioral Sciences | Combining expert advice in reactive environments | Calibrated learning and correlated equilibrium | Learning, hypothesis testing, and Nash equilibrium | Network games | Correlated Q-learning | A simple adaptive procedure leading to correlated equilibrium | Continuous Univariate Distributions, volume | Correlated equilibria in graphical games | Strong mediated equilibrium | All of Statistics",rejected,000
1206.3263.pdf.json,Sparse Stochastic Finite-State Controllers for POMDPs,"Partially observable Markov decision processes (POMDPs) provide a framework for decision-theoretic planning problems where actions need to be taken based on imperfect state information. Many researchers have shown that a policy for an infinite-horizon POMDP can be represented by a finite-state controller. In some cases, this is a deterministic controller in which a single action is associated with each node, and an observation results in a deterministic transition to a successor node (Kaelbling, Littman, & Cassandra, 1998; Hansen, 1998; Meuleau, Kim, Kaelbling, & Cassandra, 1999a). In other cases, it is a stochastic controller in which actions are selected based on a probability distribution associated with each node, and an observation results in a probabilistic transition to a successor node (Platzman, 1981; Meuleau, Peshkin, Kim, & Kaelbling, 1999b; Baxter & Bartlett, 2001; Poupart & Boutilier, 2004; Amato, Bernstein, & Zilberstein, 2007). Bounded policy iteration (BPI) is an approach to solving infinite-horizon POMDPs that represents policies as stochastic finite-state controllers and iteratively improves a controller by adjusting the parameters of each node using linear programming, where the parameters specify the action selection and node transition probabilities of the node (Poupart & Boutilier, 2004). BPI is related to an exact policy iteration algorithm for POMDPs due to Hansen (1998), but differs from it by providing an elegant and effective approach to approximation in which bounding the size of the controller allows a tradeoff between planning time and plan quality. Originally developed as an approach to solving single-agent POMDPs, BPI has also been generalized for use in solving decentralized POMDPs (Bernstein, Hansen, & Zilberstein, 2005). In BPI, the complexity of policy improvement depends on the size of the linear programs used to adjust the parameters of each node of the controller. In turn, this depends on the number of parameters of each node (",Solving POMDPs using quadratically constrained linear programs | Infinite-horizon policygradient estimation | Bounded policy iteration for decentralized POMDPs | Introduction to Linear Optimization | Tony’s POMDP file repository page.. http://pomdp.org/pomdp/examples/index.shtml | Approximate planning for factored POMDPs | Solving POMDPs by searching in policy space | Point-based policy iteration | Planning and acting in partially observable stochastic domains | Solving POMDPs by searching the space of finite policies | Learning finite-state controllers for partially observable environments | Point-based value iteration: An anytime algorithm for POMDPs | A feasible computational approach to infinite-horizon partially-observed Markov decision problems | Exploiting Structure to Efficiently Solve Large Scale Partially Observable Markov Decision Processes | Bounded finite state controllers | VDCBPI: An approximate scalable algorithm for large POMDPs,rejected,000
1206.3264.pdf.json,Sampling First Order Logical Particles,"Important AI applications like natural language processing, program verification, tracking, and robotics involve stochastic dynamic systems. The current state of such systems is changed by executing actions. Reasoning is the task of computing the posterior probability over the state of such dynamic systems given past actions and observations. Reasoning is difficult because the system’s exact initial state or the effects of its actions are uncertain (e.g., there may be some noise in the system or its actions may fail). Exact reasoning (e.g., [11; 1]) is not tractable for long sequence of actions in complex systems. This is because domain features become correlated after some steps, even if the domain has much conditional-independence structure [4]. Therefore, approximate reasoning is of much interest. One of the most commonly used classes of techniques for approximate reasoning is SMC sampling [5]. These methods are efficient, but they require many samples (exponential in the dimensionality of the domain) to yield a lower error rate. Recently, [8] introduced a new sampling approach which achieves higher precision than SMC techniques given a fixed number of samples. Still, it requires a large number of samples in complex domains because in their method the domains are represented using propositional logic. In this paper we present a sampling-based filtering algorithm in a first order dynamic system called Probabilistic Relational Action Model (PRAM). We show that our new algorithm takes fewer samples and yields better accuracy than previous sampling techniques. Such improvement is possible because of the underlying deterministic structure of the transition system, the compact representation of the domains using first order logic (FOL), and efficient subroutines for first order logical regression (e.g., [17]) and first order logical filtering [19; 14]. We model a PRAM (Section 2) using probabilistic situation calculus [17], extended with a first order probabilistic pri","Reasoning about noisy sensors and effectors in the situation | Symbolic dynamic programming for first-order MDPs | Clp(bn): Constraint logic programming for probabilistic knowledge | Probabilistic temporal reasoning | Sequential Monte Carlo | Raoblackwellised particle filtering for dynamic bayesian networks | Learning probabilistic relational models | Stochastic filtering in a probabilistic action model | Introduction to probabilistic graphical models | Logical hidden markov models | A computational scheme for reasoning in dynamic probabilistic networks | Stochastic logic programs | Dynamic Bayesian Networks: Representation, Inference and Learning | Reasoning about partially observed actions | Probabilistic horn abduction and bayesian networks | A tutorial on hidden Markov models and selected applications in speech recognition | Knowledge In Action | First order logical filtering | Discriminative probabilistic models for relational data | Infinite state bayesian networks | Logical particle filtering",rejected,000
1206.3265.pdf.json,The Computational Complexity of Sensitivity Analysis and Parameter Tuning,"The sensitivity of the output of a probabilistic network to small changes in the network’s parameters, has been studied by various researchers [1, 14, 7, 2, 19, 4]. Whether the parameter probabilities of a network are assessed by domain experts or estimated from data, they inevitably include some inaccuracies. In a sensitivity analysis of the network, the parameter probabilities are varied within a plausible range and the effect of the variation is studied on the output computed from the network, be it a posterior probability or the most likely value of an output variable. The results of a sensitivity analysis are used, for example, to establish the robustness of the network’s output. The results are used also upon engineering a probabilistic network, for example to distinguish between parameters which allow some imprecision and parameters which should be determined as accurately as possible [6]. Another use is for carefully tuning the parameter probabilities of a network to arrive at some desired model behavior [3]. Research efforts in sensitivity analysis and parameter tuning for probabilistic networks have resulted in a variety of fundamental insights and computational methods. While the majority of these insights and methods pertain to a one-way sensitivity analysis in which the effect of varying a single parameter probability on a single output probability or output value is studied, recently there also has been some pioneering work on extending these insights to higher-order analyses [2, 6]. The currently available algorithms for sensitivity analysis and parameter tuning of probabilistic networks have a running time that is exponential in the size of a network. This observation suggests that these problems are intractable in general. The actual computational complexity of the problems has not been studied yet, however. In this paper we define several variants of the tuning problem for probabilistic networks and show that these variants are NPPP-complete in gen","Sensitivity analysis in discrete Bayesian networks | Sensitivity analysis in Bayesian networks: From single to multiple parameters | A distance measure for bounding probabilistic belief change | Sensitivity analysis for threshold decision making with DBNs | L | and L | Properties of sensitivity analysis of Bayesian belief networks | The inferential complexity of bayesian and credal networks | Computers and Intractability | Computational complexity of Probabilistic Turing Machines | Making sensitivity analysis computationally efficient. In Sixteenth Conference in Uncertainty in Artificial Intelligence, pages 317–325 | On information and sufficiency | Sensitivity analysis for probability assessments in Bayesian networks | Stochastic boolean satisfiability | Computational Complexity | Complexity results and approximation settings for MAP explanations | On the hardness of approximate reasoning | Analysing sensitivity data | Sensitivity analysis of probabilistic networks | The complexity of combinatorial problems with succinct input representation",rejected,000
1206.3266.pdf.json,Partitioned Linear Programming Approximations for MDPs,"Markov decision processes (MDPs) [19] are an established framework for solving sequential decision problems under uncertainty. Unfortunately, traditional methods for solving MDPs, such as value and policy iteration, are unsuitable for solving real-world problems. These problems are generally structured, and their state and action spaces are represented by state and action variables. The size of these problems is naturally exponential in the number of the variables, and so are their exact solutions. Approximate linear programming (ALP) [21] has emerged as a promising approach to solving these problems efficiently [6, 12, 15]. The main idea of this method is to approximate the optimal value function by a set of basis functions and optimize their weights by linear programming (LP). The optimization can be performed in a structured manner [10, 20]. The structure is a result of combining the structure of factored MDPs and linear value function approximations. The complexity of computing exact ALP solutions [10, 20] is exponential in the treewidth of the dependency graph that represents the constraint space in ALP. Therefore, when the treewidth of an ALP is large, its exact solution is infeasible. This type of problems can be still solved approximately using Monte Carlo constraint sampling [7, 14]. This approach can be interpreted as an outer approximation to the feasible region of the ALP. In this work, we propose inner approximations to the feasible region. In comparison to the standard ALP formulation, the constraint space is factored into a set of subspaces. This structure allows for solving the new LP more efficiently. In particular, its constraints can be satisfied in a compact form without an exponential dependence on the treewidth of the original constraint space. We investigate both practical and theoretical aspects of the approach. In addition, we demonstrate that the approach yields an exponential speedup over ALP. The paper is organized as follows. First, we r",Dynamic Programming | Polynomial approximation – a new computational technique in dynamic programming: Allocation processes | Neuro-Dynamic Programming | Introduction to Linear Optimization | Exploiting structure in policy construction | The linear programming approach to approximate dynamic programming | On constraint sampling for the linear programming approach to approximate dynamic programming | A model for reasoning about persistence and causation | Bucket elimination: A unifying framework for probabilistic inference | Maxnorm projections for factored MDPs | Multiagent planning with factored MDPs | Efficient solution algorithms for factored MDPs | Computing factored value functions for policies in structured MDPs | An MCMC approach to solving hybrid factored MDPs | Solving factored MDPs with hybrid state and action variables | Samuel meets Amarel: Automating value function approximation using global state space analysis | Learning with Mixtures of Trees | Greedy linear valueapproximation for factored Markov decision processes | Markov Decision Processes: Discrete Stochastic Dynamic Programming | Direct valueapproximation for factored MDPs | Generalized polynomial approximations in Markovian decision processes | Planning Under Uncertainty in Complex Structured Environments,rejected,000
1206.3271.pdf.json,Learning Arithmetic Circuits,"Bayesian networks are a powerful language for probabilistic modeling, capable of compactly representing very complex dependences. Unfortunately, the compactness of the representation does not necessarily translate into efficient inference. Networks with relatively few edges per node can still require exponential inference time. As a consequence, approximate inference methods must often be used, but these can yield poor and unreliable results. If the network represents manually encoded expert knowledge, this is perhaps inevitable. But when the network is learned from data, the cost of inference can potentially be greatly reduced, without compromising accuracy, by suitably directing the learning process. Bayesian networks can be learned using local search to maximize a likelihood or Bayesian score, with operators like edge addition, deletion and reversal (Heckerman et al., 1995). Typically, the number of parameters or edges in the network is penalized to avoid overfitting, but this is only very indirectly related to the cost of inference. Two edge additions that produce the same improvement in likelihood can result in vastly difference inference costs. In this case, it seems reasonable to prefer the edge yielding the lowest inference cost. In this paper, we propose a learning method that accomplishes this, by directly penalizing the cost of inference in the score function. Our method takes advantage of recent advances in exact inference by compilation to arithmetic circuits (Darwiche, 2003). An arithmetic circuit is a representation of a Bayesian network capable of answering arbitrary marginal and conditional queries, with the property that the cost of inference is linear in the size of the circuit. When contextspecific independences are present, arithmetic circuits can be much more compact than the corresponding junction trees. We take advantage of this by learning arithmetic circuits that are equivalent to Bayesian networks with contextspecific independence, using l","Complexity of finding embeddings in a k-tree | Context-specific independence in Bayesian networks | Efficient principled learning of thin junction trees | A Bayesian approach to learning Bayesian networks with local structure | The WinMine toolkit | A logical approach to factoring belief networks | A differential approach to inference in Bayesian networks | Learning Bayesian networks with local structure | Mining complex models from arbitrarily large databases in constant time | Learning probabilistic decision graphs | organizers’ report: Peeling the onion | Naive Bayes models for probability estimation | Learning arithmetic circuits (Tech | Learning with mixtures of trees | Probabilistic reasoning in intelligent systems | On the hardness of approximate reasoning | Maximum likelihood Markov networks: An algorithmic approach | Let L be the logical image of C and L′ be the logical image of C ′. From Lemma 2 and the discussion of logical images, we know",rejected,000
1206.3272.pdf.json,Improving Gradient Estimation by Incorporating Sensor Data,"Policy search algorithms have been very effective in learning good policies in the reinforcement learning setting. Successful applications include helicopter flight [8], quadruped locomotion [5], and baseball hitting [10]. These methods work by adjusting the parameters of a policy to improve its value, i.e., the expected sum of rewards (possibly discounted) obtained during policy execution. To do this, the algorithms repeatedly estimate the gradient of the value with respect to the parameters, using information observed during policy trials, and then adjust the parameters in the “uphill” direction. Because trials can be expensive, especially in physical environments, a number of authors have presented techniques to reduce the number of required trials—mainly by reducing the variance of the gradient estimator [1, 3, 6, 7, 10, 9, 11, 13]. Generally speaking, these methods estimate the gradient from the policy parameter settings on each trial and the score (the actual sum of rewards), ignoring the sensor data.1 The main point of this paper is that the sensor data obtained during each trial also provides a useful signal that can reduce the variance of gradient estimators. To understand how this may be so, consider first a case in which it is not so: that is, the noise-free case where the score is a deterministic function of the policy parameters. In that case, the local gradient can be estimated exactly from a small set of trials with policy parameter settings closely spaced around the setting of interest, and the sensor data can provide no more information.2 In the noisy case, however, a gradient estimator can be easily misled by trials of bad policies that yield fortuitously good scores and vice versa. In essence, what we propose is that sensor data can account, at least partially, for the deviation in the score of each trial from its expected value. Conditioned on the sensor data, therefore, the posterior estimate for the policy value will be closer to the true value",Infinite-horizon policygradient estimation | A kinematic model of the upper limb based on the visible human project (vhp) image dataset | Variance reduction techniques for gradient estimates in reinforcement learning | Signaldependent noise determines motor | Machine learning for fast quadrupedal locomotion | Efficient gradient estimation for motor control learning | Pegasus: A policy search method for large MDPs and POMDPs | Autonomous helicopter flight via reinforcement learning | Learning from scarce experience | Natural actor-critic | Policy improvement for POMDPs using normalized importance sampling | Optimal control as a theory of motor coordination | The optimal reward baseline for gradient-based reinforcement learning | Perspectives and problems in motor learning,rejected,000
1206.3276.pdf.json,Explanation Trees for Causal Bayesian Networks,"A Bayesian network (BN, Pearl, 1988) is an algebraic tool to compactly represent the joint probability distribution of a set of variables V by exploiting conditional independence amongst variables. It represents all variables in a directed acyclic graph (DAG), where the absence of arcs between nodes denotes (conditional) independence. In addition to graphically representing the structure of the dependencies between the variables, BNs allow inference tasks to be solved more e ciently. In this paper, we discuss the extraction of explanations in causal BNs (Pearl, 2000; Spirtes et al., 2001) BNs where the arcs depict direct cause e ect relationships between variables. Generally, explanations in BNs can be classi ed in three categories (Lacave and Diez, 2002) depending on the focus of the explanation: • Explanation of evidence. Given a subset of observed (instantiated) variables O ( V, what is the state of (some of) the other variables V \ O that best explains O = o? • Explanation of the reasoning process. When we have received some evidence and belief states are updated by probabilistic inference, how was the reasoning process by which we arrive at this state? • Explanation of the model, which provides insight into the static components of a network such as (conditional) independence relationships, causal mechanisms, etc. We shall focus our attention on the explanation of evidence: we wish to explain why variables in O took on speci c observed values using assignments in V \ O. To this purpose, we discuss in section 2 the requirements of such an explanation. In section 3, we list the standard approaches to evidence explanation as well as some recent methods to make explanations more concise, and explain some of their drawbacks. We then present causal information trees in section 4, and detail experiments and comparisons in section 5.","Information ows in causal networks. Technical report, Max Planck Institute for Mathematics in the Sciences | De ning explanation in probabilistic systems | On the robustness of most probable explanations | Simplifying explanations in Bayesian belief networks | Bayesian networks Inference: Advanced algorithms for triangulation and partial abduction | Factor graphs and the sum-product algorithm | Causes and explanations: A structural-model approach. Part II: Explanations | Qualitative propagation and scenario-based scheme for exploiting probabilistic reasoning | Theory of Probability | Bayesian Networks and Decision Graphs | A review of explanation methods of Bayesian networks | Local computations with probabilities on graphical structures and their application to expert systems | On causal explanations in Bayesian networks. Master's thesis, IT University of Copenhagen | Map complexity results and approximation methods | Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference | Causal diagrams for empirical research | Causality: Models, Reasoning, and Inference | Explanation, irrelevance, and statistical independence | Causation, Prediction, and Search, Second Edition | Finding explanations in bayesian networks",rejected,000
1206.3281.pdf.json,Model-Based Bayesian Reinforcement Learning in Large Structured Domains,"In the past decades, reinforcement learning (RL) has emerged as a useful technique for learning how to optimally control systems with unknown dynamics (Sutton & Barto, 1998). However classical RL has many shortcomings. In particular, RL does not address the problem of how to efficiently gather data to learn the parameters of the system, as well as how to behave in systems where the costs incurred during learning matter, i.e. the well known exploration-exploitation tradeoff problem. These shortcomings are mostly related to the fact that classical RL does not consider the uncertainty in the learned parameters for decision-making, nor does it allow for flexibly including prior knowledge about the system’s dynamics. Model-based Bayesian RL methods have successfully addressed these issues by maintaining a posterior distribution over unknown model parameters and acting such as to maximize long-term expected rewards with respect to this posterior (Dearden, Friedman, & Andre, 1999; Duff, 2002; Poupart, Vlassis, Hoey, & Regan, 2006). Prior knowledge of the system can be defined explicitly by specifying a prior distribution over model parameters. This allows for a flexible way of encoding uncertain knowledge into the learning algorithm. Furthermore, if the resulting decision problem is solved exactly, this provides an optimal explorationexploitation tradeoff, in that the agent will behave such as to maximize long-term expected rewards with respect to the prior. However, due to the high complexity of model-based Bayesian RL, most approaches have been limited to very small domains (10-20 states). This is mainly due to two reasons. First, when the number of states is large, a large amount of data needs to be collected to learn a good model, unless very few parameters are unknown or some structural assumptions are made to represent the dynamics with few parameters. Second, most planning approaches in Bayesian RL become intractable as the number of states increases, since planning",A markovian decision process | Stochastic dynamic programming with factored representations | Model based bayesian exploration | Optimal learning: Computational procedures for Bayes-adaptive Markov decision processes | Bayesian structure learning using dynamic programming and MCMC | Being Bayesian about Bayesian network structure: A Bayesian approach to structure discovery in Bayesian networks | Efficient solution algorithms for factored MDPs | Learning bayesian networks: The combination of knowledge and statistical data | Planning and acting in partially observable stochastic domains | Approximate Planning for Factored POMDPs using Belief State Simplification | An analytic solution to discrete Bayesian reinforcement learning | Reinforcement Learning: An Introduction,rejected,000
1206.3282.pdf.json,Improving the Accuracy and Efficiency of MAP Inference for Markov Logic,"Many tasks in Machine Learning are inherently relational: the label given to an object often depends on labels given to a set of related objects. For example, in Semantic Role Labelling [Carreras and Marquez, 2005] we are asked to label phrases with the role they play with respect to a given verb. Here the role given to one phrase depends on roles we have assigned to other phrases in the same sentence. It is, for instance, not possible to have two phrases both labelled as the agent of the same verb. Statistical Relational Learning [SRL, Ng and Subrahmanian, 1992, Koller, 1999] seeks to provide generic, solid and efficient means to solve such relational tasks. It typically uses variants of First Order Logic to describe Graphical Models with repetitive structure in a compact fashion. This has two main benefits. Firstly, the meta-information provided by the first order model can be used to avoid a full instantiation of the Graphical Model in inference and learning. This can yield faster runtime and higher accuracy [Koller, 1999, de Salvo Braz et al., 2005, Singla and Domingos, 2006b]. Secondly, an SRL language along with a powerful interpreter allows application developers to focus on models, and machine learning researchers to focus on foundations. This paradigm of decoupling applications and algorithms has increased the speed of development in many domains [Domingos, 2006]. Markov Logic [ML, Richardson and Domingos, 2005] is an expressive SRL language that combines First Order Logic and Markov Networks. It has been successfully used for several tasks such as Information Extraction [Poon and Domingos, 2007] and Entity Resolution [Singla and Domingos, 2006a]. For most Markov Logic applications we need to solve the Maximum A Posteriori (MAP) problem of finding the most likely solution given some observation. Richardson and Domingos [2005] proposed the use of MaxWalkSAT [MWS, Kautz et al., 1996] to tackle this problem. In our experiments we apply MWS to two rather simple","The correlated correspondence algorithm for unsupervised registration of nonrigid surfaces | Adaptive duplicate detection using learnable string similarity measures | Introduction to the conll-2005 shared task: Semantic role labeling | Modelling compression with discourse constraints | Ultraconservative online algorithms for multiclass problems | Solution of a large-scale traveling salesman problem | Lifted first-order probabilistic inference | Artificial Intelligence: The. First Hundred Years, chapter What’s Missing in AI: The Interface Layer | Structured machine learning: Ten problems for the next ten years | Logical Foundations of Artificial Intelligence | When is the evaluation of conjunctive queries tractable | A general stochastic approach to solving problems with hard and soft constraints | Probabilistic relational models | Probabilistic logic programming | Map complexity results and approximation methods | Sound and efficient inference with probabilistic and deterministic dependencies | Joint inference in information extraction | Generalized inference with multiple semantic role labeling systems | Markov logic networks | Incremental integer linear programming for non-projective dependency parsing | Integer linear programming inference for conditional random fields | Discriminative training of markov logic networks | Entity resolution with markov logic | Memory-efficient inference in relational domains | New outer bounds on the marginal polytope | Learning Structured Prediction Models: a Large-Margin approach | A fast finite-state relaxation method for enforcing global constraints on sequence decoding | Model Building in Mathematical Programming",rejected,000
1206.3283.pdf.json,Observation Subset Selection as Local Compilation of Performance Profiles,"A typical diagnostic system consists of two types of variables: tests (observable) and hypotheses (unobservable), with statistical dependencies among variables. Each test, if performed, consumes resources (time or money), and provides a measurement of one or more test variables. After obtaining the values of the selected tests, the distribution of the model is updated. An objective function specifies a reward given to the system for the posterior distribution. The system should make its selection so as to optimize the objective function, a hard problem in the general case. Observation subset selection (OSS) is a restricted version of this problem, where all measurements must be selected in advance, prior to any observations. In this paper we develop approximation algorithms for some settings of the OSS problem for tree-shaped dependency structures. To tackle this problem we present OSS as a variant of the following well-known meta-reasoning problem. In systems composed of several computational components (CCs), the meta-level controller should reason about allocation of available computational resources for different CCs in order to optimize the overall performance of the entire system. This task is usually referred to in the research literature as the meta-level resource allocation (MRA) problem (see for example [11]). The standard approach used to optimize the MRA task was proposed by S. Zilberstein [10, 11, 12], the technique of local compilation (LC). This technique is applied to individual CCs, represented in a form of conditional performance profiles, and generates the optimal time allocation scheme for the entire system (see Section 2). However, local compilation requires the input monotonicity assumption and is, therefore, restricted to deterministic performance profiles with scalar output quality. In this paper we relax the input monotonicity assumption and extend the LC technique to more general classes of PPs. We then apply the extended approximation sche","Solving time-dependent planning problems | Incremental Pruning: A simple, fast, exact method for partially observable Markov decision processes | Reasoning about beliefs and actions under computational resource constraints | Models of continual computation | Continual computation policies for allocating offline and real-time resources | Near-optimal nonmyopic value of information in graphical models | Optimal nonmyopic value of information in graphical models - efficient algorithms and theoretical limits | Knowledgebased anytime computation | Efficient deterministic approximation algorithm for nonmyopic value of information in graphical models | Operational rationality through compilation of anytime algorithms | Optimizing decision quality with contract algorithms | Using anytime algorithms in intelligent systems",rejected,000
1206.3284.pdf.json,Bounding Search Space Size via (Hyper)tree Decompositions,"This paper develops a measure for bounding the performance of search algorithms for solving a variety of queries over graphical models. It has been known for a while that the complexity of inference algorithms (e.g., join-tree clustering, variable elimination) is exponentially bounded by the tree width of the graphical model’s underlying graph. The base of the exponent is often taken to be the maximum domain size. More accurate bounds were derived by looking at the respective domain sizes and their product in each cluster in of tree decomposition of the underlying graph [Kjærulff, 1990]. These tighter bounds were used in selecting good variable orderings, for example. It was recently shown that these bounds are also applicable to search algorithms that explore the context-minimal AND/OR search graph [Dechter and Mateescu, 2007]. The shortcoming of these bounds is that they are completely blind to context-sensitivity hidden in the functions of the graphical model and especially determinism. When a problem possesses high levels of determinism, its tree width bound can be large while its search space can be extremely pruned, due to propagation of inconsistencies across functions. Part of this shortcoming in worst-case complexity bounds is addressed by the more recent concept of hypertree decompositions [Gottlob et al., 2000]. It was shown that the maximum number of functions in the clusters of a hypertree decomposition (the hypertree width) exponentially bounds the problem complexity for constraint inference, a result that was extended to general graphical model inference in [Kask et al., 2005]. The base of the exponent in this case is the relation tightness, thus allowing the notion of determinism to play a role. However, in practice this bound often turns out to be far worse than the tree width bound, unless the problem exhibits substantial determinism [Dechter et al., 2008]. The contribution of this paper is in combining both ideas to tighten the existing bounds, us",Pearl: Tree Clustering for Constraint Networks | AND/OR search spaces for graphical models | On the Practical Significance of Hypertree vs. Tree Width | Heuristic Methods for Hypertree Decompositions | Maximum Likelihood Haplotyping for General Pedigrees | A comparison of structural CSP decomposition methods | Unifying tree decompositions for reasoning in graphical models | Local Computations with Probabilities on Graphical Structures and Their Application to Expert Systems | The Relationship Between AND/OR Search Spaces and Variable Elimination | Online system for faster linkage analysis via parallel execution on thousands of personal computers | Bounding Complexity in the Presence of Functional Dependencies,rejected,000
1206.3286.pdf.json,New Techniques for Algorithm Portfolio Design,"Many computational problems that arise in the world are NP-hard, and thus likely to be intractable from a worst-case point of view. However, the particular instances of these problems that are actually encountered can often be solved effectively using heuristics that do not have good worst-case guarantees. Typically there are a number of heuristics available for solving any particular NP-hard problem, and there is no one heuristic that performs best on all problem instances. Thus, when solving a particular instance of an NP-hard problem, it is not clear a priori how to best make use of the available CPU time. Specifically, suppose you wish to solve an instance x of a computational problem, and there are k heuristics available for solving it. Each heuristic, when run on instance x, will either solve the instance in finite time (e.g., by returning a provably correct “yes” or “no” answer to a decision problem, returning a provably optimal solution to an optimization problem), or will run forever without solving it. When solving x, you will in general have some prior knowledge of how each of the k heuristics behaves on other instances of the same computational problem. Naturally, you would like to solve x as quickly as possible. In this situation, a natural approach would be to label each previously-encountered problem instance with a set of features, and then to use some machine learning algorithm to predict which of the k heuristics will return an answer in the shortest amount of time. However, if we then run the predicted fastest heuristic and it does not yield an answer after some sufficiently large amount of time, we might suspect that the machine learning algorithm’s prediction was a mistake, and might try running a different heuristic instead. Alternatively, if the heuristic is randomized, we might try restarting it and running with a fresh random seed. We refer to the general problem of determining how to solve a problem instance in this setting as algorithm por",Generic ILP versus specialized 0-1 ILP: An update | From external to internal regret | Approximating min sum set | Dynamic algorithm portfolios | Algorithm portfolio design: Theory vs. practice | Boosting combinatorial search through randomization | An economics approach to hard computational problems | Optimal constructions of hybrid algorithms | Boosting as a metaphor for algorithm design | Optimal speedup of Las Vegas algorithms | Learning parallel portfolios of algorithms | Combining multiple heuristics | Using Online Algorithms to Solve NP-Hard Problems More Efficiently in Practice | An online algorithm for maximizing submodular functions | Combining multiple heuristics online | Restart schedules for ensembles of problem instances | SATzilla07: The design and analysis of an algorithm portfolio for SAT,rejected,000
1206.3288.pdf.json,Tightening LP Relaxations for MAP using Message Passing,"The task of finding the maximum aposteriori assignment (or MAP) in a graphical model comes up in a wide range of applications. For an arbitrary graph, this problem is known to be NP hard [11] and various approximation algorithms have been proposed. Linear Programming (LP) relaxations are commonly used to solve combinatorial optimization problems in computer science, and have a long history of being used to approximate the MAP problem in general graphical models (e.g., see [9]). LP relaxations have an advantage over other approximate inference schemes in that they come with an optimality guarantee – if the solution to the linear program is integral, then it is guaranteed to give the global optimum of the MAP problem. An additional attractive quality of LP relaxations is that they can be solved efficiently using messagepassing algorithms such as belief propagation and its generalizations [3, 13, 15]. In particular, by using message-passing algorithms, we can now use LP relaxations for large-scale problems where standard, offthe-shelf LP solvers could not be used [18]. Despite the success of LP relaxations, there are many real-world problems for which the basic LP relaxation is of limited utility in solving the MAP problem. For example, in a database of 97 protein design problems studied in [18], the standard LP relaxation allowed finding the MAP in only 2 cases. One way to obtain tighter relaxations is to use clusterbased LP relaxations, where local consistency is enforced between cluster marginals. As the size of the clusters grow, this leads to tighter and tighter relaxations. Furthermore, message-passing algorithms can still be used to solve these cluster-based relaxations, with messages now being sent between clusters and not individual nodes. Unfortunately, the computational cost increases exponentially with the size of the clusters, and for many real-world problems this severely limits the number of large clusters that can be feasibly incorporated into the appro",Iterative joingraph propagation | Residual belief propagation: informed scheduling for asynchronous message passing | Fixing max-product: Convergent message passing algorithms for MAP LPrelaxations | Protein side-chain placement through MAP estimation and problem-size reduction | Solving and analyzing side-chain positioning problems using linear and integer programming | Convergent tree-reweighted message passing for energy minimization | On the optimality of tree-reweighted max-product message-passing | Globally optimal solutions for energy minimization in stereo vision using reweighted belief propagation | On the generation of alternative explanations with implications for belief revision | A taxonomy and evaluation of dense two-frame stereo correspondence algorithms | Finding the MAPs for belief networks is NP-hard | New outer bounds on the marginal polytope | MAP estimation via agreement on trees: message-passing and linear programming | Graphical models | MAP estimation | On the choice of regions for generalized belief propagation | Structured region graphs: Morphing EP into GBP | Linear programming relaxations and belief propagation – an empirical study | Constructing free-energy approximations and generalized belief propagation algorithms,rejected,000
1206.3289.pdf.json,Efficient inference in persistent Dynamic Bayesian Networks,"Persistence is a common trait of many real-world systems. It is used to model permanent changes in state, such as when components of a system that have broken until someone intervenes to fix them. Especially interesting and useful are diagnostic models where misalignments and other process drifts may cause a cascade of other failures, all of which may also persist until the root cause is fixed. Even when such changes are not truly permanent, they are often reversed slowly relative to the time scale of the model, and persistence can be a good approximation in such systems. For instance, vehicular accidents cause obstructions on the road that last much longer than the required detection time and are thus persistent for the purpose of detection [20]. Another example is outbreak detection [4], where an infected population stays infected much longer than the desired detection time. There are many other examples of persistence and approximate persistence. Dynamic Bayesian Networks (DBNs) [5] are a general formalism for modeling temporal systems under uncertainty. Many standard time-series methods are special cases of DBNs, including Hidden Markov Models [18] and Kalman filters [7]. Discrete DBNs in particular are a very popular formalism, but usually suffer from intractability [1] when dense inter-temporal dependencies are present among hidden state variables, leading many to search for approximation algorithms [1, 13, 15, 14]. Unfortunately, modeling persistence with DBNs requires the introduction of many inter-temporal arcs, often making exact inference intractable with standard inference algorithms. In this paper, we define Persistent Causal DBNs (PCDBNs), a particular class of DBN models capable of modeling many real-world systems that involve long chains of causal influence coupled with persistence of causal effects. We show that a linear time algorithm exists for inference (smoothing) in linear chain and tree-based PC-DBNs. We then generalize our results to polytree","Tractable inference for complex stochastic processes | Compiling Bayesian networks with local stucture | Compiling Bayesian networks using variable elimination | Bayesian biosurveillance of disease outbreaks | A model for reasoning about persistence and causation | Continuous time Markov networks | A new approach to linear filtering and prediction problems. Transactions of the ASME | A computational model for combined causal and diagnostic reasoning in inference systems | Bayesian inference in the presence of determinism | The Bayes Net Toolbox for Matlab | Dynamic Bayesian Networks: Representation, Inference and Learning | The factored frontier algorithm for approximate inference in DBNs | Survey of Bayesian models for modelling of stochastic temporal processes | Exploiting Locality in Probabilistic Inference | Fusion, propagation, and structuring in belief networks | Fusion and propagation with multiple observations in belief networks | A tutorial on hidden Markov models and selected applications in speech recognition | Affine algebraic decision diagrams (AADDs) and their application to structured probabilistic inference | Learning to detect adverse traffic events from noisily labeled data | Understanding belief propagation and its generalizations",rejected,000
1206.3291.pdf.json,Hierarchical POMDP Controller Optimization by Likelihood Maximization,"Planning in partially observable domains is notoriously difficult. However, many planning tasks naturally decompose into subtasks that may be arranged hierarchically. For instance, the design of a soccer playing robot is often decomposed into low-level skills such as intercepting the ball, controlling the ball, passing the ball, etc. [16]. Similarly, prompting systems that assist older adults with activities of daily living (e.g., handwashing [8]) can be naturally decomposed into subtasks for each step of an activity. When a decomposition or hierarchy is known a priori, several approaches have demonstrated that planning can be simplified and performed faster [13, 7]. However, the hierarchy is not always known or easy to specify, and the optimal policy may only decompose approximately. To that effect, Charlin et al. [4] showed how a hierarchy can be discovered automatically by formulating the planning problem as a non-convex quartically constrained optimization problem with variables corresponding to the parameters of the policy, including its hierarchical structure. Unfortunately, the inherent computational difficulty of solving this optimization problem prevents the approach from scaling to real-world problems. Furthermore, it is not clear that automated hierarchy discovery simplifies planning since the space of policies remains the same. We propose an alternative approach that demonstrates that hierarchy discovery (i) can be done efficiently and (ii) performs a policy search with a different bias than non-hierarchical approaches that is advantageous when there exists good hierarchical policies. The approach combines Murphy and Paskin’s [10] factored encoding of hierarchical structures (see also [17]) into a dynamic Bayesian network (DBN) with Toussaint et al.’s [18] maximum-likelihood estimation technique for policy optimization. More precisely, we encode POMDPs with hierarchical controllers into a DBN in such a way that the policy and hierarchy parameters are ent","Solving POMDPs using quadratically constrained linear programs | Stochastic local search for POMDP controllers | Exact and approximate algorithms for partially observable Markov decision processes | Automated hierarchy discovery for planning in par-  tially observable environments | Maximum likelihood from incomplete data via the EM algorithm | An improved policy iteration algorithm for partially observable MDPs | Synthesis of hierarchical finite-state controllers for POMDPs | Assisting persons with dementia during handwashing using a partially observable Markov decision process | Learning finite-state controllers for partially observable environments | Linear time inference in hierarchical HMMs | A view of the EM algorithm that justifies incremental, sparse, and other variants | Tractable Planning Under Uncertainty: Exploiting Structure | Policycontingent abstraction for robust robot control | Bounded finite state controllers | Heuristic search value iteration for POMDPs | A layered approach to learning client behaviors in the RoboCup soccer server | Representing hierarchical POMDPs as DBNs for multi-scale robot localization | Probabilistic inference for solving (PO)MDPs",rejected,000
1206.3295.pdf.json,Refractor Importance Sampling,"The Bayesian Network (BN) [Pearl, 1988] formalism is one of the dominant representations for modeling uncertainty in intelligent systems [Neapolitan, 1990, Russell and Norvig, 1995]. A BN is a probabilistic graphical model of a joint probability distribution over a set of statistical variables. Bayesian inference on a BN answers probabilistic queries about the variables and their influence relationships. The posterior probability distribution is computed using belief updating methods [Pearl, 1988, Guo and Hsu, 2002]. Exact inference is NP-hard [Cooper, 1990]. Thus, exact methods only admit relatively small networks or simple network configurations in the worst case. Approximations are also NP-hard [Dagum and Luby, 1993]. However, approximate inference methods have anytime [Garvey and Lesser, 1994] and/or anywhere [Santos et al., 1995] properties that make these methods more attractive compared to exact methods. Stochastic simulation algorithms, also called stochastic sampling or Monte Carlo (MC) algorithms, form one of the most prominent subclasses of approximate inference algorithms of which Logic Sampling [Henrion, 1988] was the first and simplest sampling algorithm. Likelihood weighting [Fung and Chang, 1989] was designed to overcome the poor performance of logic sampling under evidential reasoning with unlikely evidence. Markov Chain Monte Carlo (MCMC) forms another important group of stochastic sampling algorithms. Examples in this group are Gibbs sampling, Metropolis sampling and hybrid-MC sampling [Geman and Geman, 1984, Gilks et al., 1996, MacKay, 1998, Pearl, 1987, Chavez and Cooper, 1990]. Stratified sampling [Bouckaert, 1994], hypercube sampling [Cheng and Druzdzel, 2000c], and quasi-MC methods [Cheng and Druzdzel, 2000b] generate random samples from uniform distributions using various methods to improve sampling results. The importance sampling methods [Rubinstein, 1981] are widely used in Bayesian inference. Self Importance Sampling (SIS) [Shachter and ","The ALARM monitoring system: A case study with two probabilistic inference techniques for belief networks | A randomized approximation algorithm for probabilistic inference on Bayesian belief networks. Networks, 20:661–685 | AIS-BN: An adaptive importance sampling algorithm for evidential reasoning in large Bayesian networks | Computational investigations of low-discrepancy sequences in simulation algorithms for Bayesian networks | Latin hypercube sampling in Bayesian networks | Approximating probabilistic inference in Bayesian belief networks is NP-hard | Weighting and integrating evidence for stochastic simulation in Bayesian networks | A survey of research in deliberative real-time artificial intelligence. Real-Time Systems, 6(3):317–347 | Stochastic relaxation, Gibbs distribution and the Bayesian restoration of images | A survey on algorithms for real-time Bayesian network inference. In In the joint AAAI-02/KDD-02/UAI02 workshop on Real-Time Decision Support and Diagnosis | Artificial intelligence: A modern approach | On a distributed anytime architecture for probabilistic reasoning | Simulation approaches to general probabilistic inference on belief networks | On evidence absorption for belief networks | Approximating Bayesian belief networks by arc removal",rejected,000
1206.3296.pdf.json,Inference for Multiplicative Models,"Probabilistic models that represent associations and/or interactions among random variables have been heavily applied in the past century in various fields of science and engineering. The statistical methods originating with the work of Fisher (1925, 1956) [6, 7] culminated in the log-linear models which describe the association patterns among a set of categorical variables without specifying any variable as a response (dependent) variable [1]. A specific type of probabilistic models, probabilistic graphical models, can be visually described as an interaction graph, and embody independence assumptions in the domain of interest [15]. Their main attraction is that the independences encoded in the structure of the model allow to indirectly specify the join distribution as a product of functions ψi(Di), each depends only on a limited set of variables Di. Algorithms that compute the posterior distribution conditioned on ev- idence, called inference algorithms, exploit this structure, avoiding a direct computation of the join probabilities [5, 19]. The complexity of such algorithms depends on the topology of the model, and is exponential in the tree-width of the underlying graph. The common distinction within graphical models is between undirected graphical models [15], a subset of log-linear models, where there are no restrictions on the functions ψ, and Bayesian networks (BNs) [19] in which every function is a conditional distribution ψi(Di) = P (Xi|Πi) where Πi is the set of parent variables of Xi in the model. Another type of probabilistic models that can be represented visually, called factor graphs, extends undirected graphical models and incorporates many of the desired properties of graphical modes [14]. Aside of the independences that are imposed by the model’s structure, often there exist additional independences stemming from the specific values of the functions. These independences are not systematically exploited by the traditional inference algorithms, resul",Discrete multivariate analysis | Context-specific independence in Bayesian networks | Log-Linear Models and Logistic Regression | The computational complexity of probabilistic inference using bayesian belief networks | Bucket elimination: A unifying framework for reasoning | Statistical Methods for Research Workers | Statistical Methods and Scientific Inference | Contingent influence diagrams | Knowledge representation and inference in similarity networks and bayesian multinets | Maximum entropy for hypothesis formulation | A tractable inference algorithm for diagnosing multiple diseases | Probabilistic Similarity Networks | Log-Linear Models | Factor graphs and the sum-product algorithm | Graphical Models | Conditional independence and log linear models for multi-dimensional contingency tables | Probabilistic diagnosis using a reformulation of the INTERNIST-1/QMR knowledge base: Part II. Evaluation of diagnostic performance | Decision graphs - an extension of decision trees | Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference | Exploiting contextual independence in probabilistic inference | Some generalized order-disorder transformations | A survey of decision tree classifier methodology | Structuring conditional relationships in influence diagrams | Exploiting causal independence in bayesian network inference,rejected,000
1206.3318.pdf.json,On Local Regret,"An online learning task involves repeatedly taking actions and, after an action is chosen, observing the result of that action. This is in contrast to offline learning where the decisions are made based on a fixed batch of training data. As a consequence offline learning typically requires i.i.d. assumptions about how the results of actions are generated (on the training data, and all future data). In online learning, no such assumptions are required. Instead, the metric of performance used is regret: the amount of additional utility that could have been gained if some alternative sequence of actions had been chosen. The set of alternative sequences that are considered defines the notion of regret. Regret is more than just a measure of performance, though, it also guides algorithms. For specific notions of regret, no-regret algorithms exist, for which the total regret is growing at worst sublinearly with time, hence their average regret goes to zero. These guarantees can be made with no i.i.d., or equivalent assumption, on the results of the actions. One traditional drawback of regret concepts is that the number of alternatives considered must be finite. This is typically achieved by assuming the number of available actions is finite, and for practical purposes, small. In offline learning this is not at all the case: offline hypothesis classes are usually very large, if not infinite. There have been attempts to achieve regret guarantees for infinite action spaces, but these have all required assumptions to be made on the action outcomes (e.g., convexity or smoothness). In this work, we propose new notions of regret, specifically for very large or infinite action sets, while avoiding any significant assumptions on the sequence of action outcomes. Instead, the action set is assumed to come equipped with a notion of locality, and regret is redefined to respect this notion of locality. This approach allows the online paradigm with its style of regret guarantees to be ap",An analog of the minimax theorem for vector payoffs | From external to internal regret | A general class of no regret learning algorithms and game-theoretic equilibria | Approximation to bayes risk in repeated plays | A simple adaptive procedure leading to correlated equilibrium | A wide range no-regret theorem | Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm | Programs for Machine Learning | Local search strategies for satisfiability testing | Online convex programming and generalized infinitesimal gradient ascent,rejected,000
1206.3437.pdf.json,Improving the Asymmetric TSP by Considering Graph Structure,"Given a n node, m arc complete directed weighted graph G = (V,A, f : A→ R), the Asymmetric Traveling Salesman Problem [1] (ATSP) consists in finding a partial subgraph G′ = (V,A′, f) of G which forms a Hamiltonian circuit of minimum cost. This NP-hard problem is one of the most studied by the Operation Research community. It has various practical applications such as vehicle routing problems of logistics, microchips production optimization or even scheduling. The symmetric TSP is well handled by linear programming techniques [1]. However, such methods suffer from the addition of side constraints and asymmetric cost matrix, whereas constraint programming models do not. Since the real world is not symmetric and industrial application often involve constraints such as time windows, precedences, loading capacities and several other constraints, improving the CP general model for solving the ATSP leads to make CP more competitive on real world routing problems. Recent improvements on cost based relaxations [4] had a very strong impact on the ability of CP technologies to solve the TSP. In this paper, we investigate how the graph structure can contribute to the resolution process, in order to tackle larger instances. For this purpose, we developed usual and original filtering algorithms using classical graph structures, such as strongly connected components or dominators. We analyzed their behavior both from a quantitative (time complexity) and a qualitative (consistency level) point of view. Also, we experimentally show that such implied propagators bring robustness to hard instances, and highlight the fact that the ar X iv :1 20 6. 34 37 v1 [ cs .D M ] 1 5 Ju n graph structure can significantly improve the behavior of search heuristics. Our main contribution is both a theoretical and an experimental study which lead to a robust model that outperforms state of the art results in CP. This paper is divided into six main parts. Section 2 provides some vocabulary and notatio","The Traveling Salesman Problem: A Computational Study | Combining Tree Partitioning, Precedence, and Incomparability | Necessary Condition for Path Partitioning Constraints | Conception d’une contrainte globale de chemin | Algorithms and codes for the assignment problem | Solving Small TSPs with Constraints | A tabu search heuristic for the static multi-vehicle dial-a-ride problem | CP(Graph): Introducing a Graph Computation Domain in Constraint Programming | The Minimum Spanning Tree Constraint | The ”Not-Too-Heavy Spanning Tree | Revisiting the tree Constraint | Lazy Clause Generation Reengineered | An additive bounding procedure for the asymmetric travelling salesman problem | Embedding Relaxations in Global Constraints for Solving TSP and TSPTW | A Hybrid Exact Algorithm for the TSPTW | Efficient algorithms for finding minimum spanning trees in undirected and directed graphs | Incremental Cycle Detection, Topological Ordering, and Strong Component Maintenance | The traveling-salesman problem and minimum spanning trees: Part II | An effective implementation of the Lin-Kernighan traveling salesman heuristic | A Filter for the Circuit Constraint | A Simpler Minimum Spanning Tree Verification Algorithm | The Hungarian Method for the Assignment Problem | Robust and Parallel Solving of a Network Design Problem | An Exact Constraint Logic Programming Algorithm for the Traveling Salesman Problem with Time Windows | Using Dominators for Solving Constrained Path Problems | A Filtering Algorithm for Constraints of Difference in CSPs | Tutorial: Modeling Problems in Constraint Programming | Simpler and Incremental Consistency Checking and Arc Consistency Filtering Algorithms for the Weighted Spanning Tree Constraint. In Integration of AI and OR Techniques in Constraint Programming for Combinatorial Optimization | The Weighted Spanning Tree Constraint Revisited. In Integration of AI  and OR Techniques in Constraint Programming for Combinatorial Optimization | Weakly Monotonic Propagators | Depth-First Search and Linear Graph Algorithms | O(n log n) Filtering Algorithms for Unary Resource Constraint",rejected,000
1206.3551.pdf.json,Sensitivity analysis in decision circuits,"Influence diagrams are powerful communication tools and computational aids for the analysis of practical decision problems [Howard and Matheson, 1984]. Decision circuits are a recent graphical representation that have been introduced for the efficient evaluation of influence diagrams [Bhattacharjya and Shachter, 2007]. In this paper, we show that they are also useful for efficient sensitivity analysis in influence diagrams. The phrase sensitivity analysis refers, in general, to understanding how the output for a system varies as a result of changes in the system’s input(s). For influence diagrams, one may be concerned about how the optimal solution and the certain equivalent (CE) change with respect to a change in the parameters, i.e. the probabilities and the utilities, or a change in the informational assumptions of the problem. There are many questions that we can use sensitivity analysis to answer. For example, suppose we vary one parameter keeping all other parameters constant. For what range of this varying parameter is the current optimal strategy still optimal? How does the value change as this parameter is varied? What if the structure of the influence diagram changes and an uncertainty that would not have been revealed before we make a decision is now observed before the first decision is made? These are only some of the queries on the model that we seek to answer. Several issues in sensitivity analysis of Bayesian belief networks have been studied, using arithmetic circuits [Darwiche, 2003] for efficient solutions [Chan and Darwiche, 2002; 2004; 2006]. Our work builds on this body of research. Arithmetic circuits are graphical representations that have been shown to be efficient at performing inference on belief networks. Decision circuits promise similar benefits in the context of sequential decision problems. In sections 2, 3 and 4 we briefly discuss some preliminaries, and review literature on circuits and sensitivity analysis in influence diagrams. In","Evaluating influence diagrams with decision circuits | Dynamic programming in decision circuits, Working paper | Sensitivity analysis in discrete Bayesian networks | When do numbers really matter | Sensitivity analysis in Bayesian networks: From single to multiple parameters | On the robustness of Most Probable Explanations | Compiling Bayesian networks with local structure | A differential approach to inference in Bayesian networks | A logical approach to factoring belief networks | A differential approach | Information value theory, IEEE transactions on Systems | The evolution of decision analysis | Making sensitivity analysis computationally efficient | Sensitivity analysis for probability assessments in Bayesian networks | Sensitivity analysis in influence diagrams | Decision Analysis: Introductory Lectures on Choices under Uncertainty, Addison-Wesley | The Foundations of Statistics, Wiley, New York | Evaluating influence diagrams | Model building with belief networks and influence diagrams | Analysing sensitivity data from probabilistic networks",rejected,000
1206.3555.pdf.json,A Dynamic Programming Algorithm for Inference in Recursive Probabilistic Programs,"Probabilistic programming allows rapid prototyping of complexly structured probabilistic models without requiring the design of model-specific inference algorithms. This makes probabilistic programs attractive for scientific research: when hypotheses are formalized as programs, it is possible to quickly explore the space of hypotheses. The same features make probabilistic programs compelling for education: students can focus on understanding modeling and inference patterns before they need to learn about inference implementations. However, the performance of current inference algorithms for generic probabilistic programs can vary greatly between models, even for models with a very small number of random choices. This presents an obstacle to the use of probabilistic programs in research and teaching. In fact, many of the models used in these domains are small enough that exact computation is feasible in principle, but they often exhibit patterns, such as nested conditioning, that make naive enumeration intractable. In this paper we develop a generic dynamic programming algorithm, which expands the applicability of exact inference for probabilistic programs. Given an interpreter for an arbitrary probabilistic programming language and a discrete probabilistic program, this algorithm computes the marginal distribution of the program—i.e., its distribution on return values—while sharing subcomputations where possible. By viewing conditioning as marginalization of a rejection sampler, this captures the full range of probabilistic operations over arbitrary models. The key obstacle to dynamic programming, which is neither present in caching deterministic interpreters nor in dynamic programming algorithms for more restricted model classes, is the possibility of stochastic self-recursion: an interpreter call with particular arguments can result in a call with the same arguments. Figure 1a shows a program that exhibits this property. This is not a corner case: for instance, al","Knowledge and implicature: Modeling language understanding as social cognition | Church: a language for generative models | Probabilistic models of cognition, 2011. URL http://projects | Effective bayesian inference for stochastic programs | IBAL: A probabilistic rational programming language | Sum-product networks: A new deep architecture | Generative Modeling by PRISM | Principles and implementation of deductive parsing | The blue-eyed islanders puzzle, 2008. URL http://terrytao.wordpress.com/2008/02/ 05/the-blue-eyed-islanders-puzzle | Depth-First Search and Linear Graph Algorithms | Lightweight Implementations of Probabilistic Programming Languages Via Transformational Compilation",rejected,000
1206.3658.pdf.json,Alan Turing and the “Hard” and “Easy” Problem of Cognition: Doing and Feeling,,,rejected,000
1206.3667.pdf.json,INFORMATION RETRIEVAL IN INTELLIGENT SYSTEMS: CURRENT SCENARIO & ISSUES,"Intelligent Information Retrieval (IR) [8] has been defined by different people in various manners, but the consistent theme has been one of the machine (or program) doing something for the user, or the machine (or program) taking over some functions that previously had to be performed by human beings (either user or intermediary). Information Retrieval Tool [1] is an important way for people to obtain knowledge and information. However, the technique of traditional information retrieval has been criticized as deeply flawed; the key reason is that the search technique is mainly based on the keyword match. In other words, users enter the inputs in the form of keywords which they want to search, and then retrieval system, like search engines, return the matching documents to users. Because of polysemy and synonyms, it is very hard to understand user’s exact requirements by keywords. Often the keywords entered do not get the results they want, the somewhat relevant or irrelevant documents are also retrieved. Let’s say that a user starts using a web application to order food, and he order fish every Sunday. He has much better understanding if, on Sundays, the application asked him “What would you like to order today?” rather than “Would you like to have fish today?” In the second case, the application somewhat realised that he likes fish on Sundays. Thus, the data created by user’s interaction with the site doesn’t affect how the application chooses the content of a page or how it’s presented. Asking a question that’s based on the user’s prior selections introduces a new kind of interactivity between the website and its users. So, we could say that websites with that property have a learning capacity [2]. The Information Retrieval [18] system consists of three major components [8]: 1. the user(s) in the system; 2. the knowledge resource to which the user has access and with which he/she interacts; and, 3. Some person(s) and/or device(s) which supports and mediates the u",,rejected,000
1206.3902.pdf.json,On the Complexity of Existential Positive Queries,"Background. Model checking, the computational problem of deciding if a logical sentence holds on a structure, is a fundamental task that is ubiquitous throughout computer science. Witness its appearance in areas such as logic, artificial intelligence, database theory, constraint satisfaction, and computational complexity. It is well-known to be intractable in general: for first-order logic on finite structures it is PSPACE-complete. Indeed, the natural bottom-up algorithm for evaluating a first-order sentence φ on a finite structure B can require time |B|m(φ), where |B| is the size of the universe of B, and m(φ) denotes the maximum number of free variables over subformulas of φ. This general intractability, coupled with the natural exponential dependence on the sentence, prompts the pursuit of restricted classes of sentences on which model checking is tractable. Certainly, one can pursue such tractable fragments with respect to the classical and wellestablished notion of polynomial-time tractability. However, as has been articulated in the literature, the typical situation in practical database settings is the evaluation of a short query against a large database, or, in logical parlance, evaluating a short formula on a large relational structure (see for example the discussion of Grohe, Schwentick, and Segoufin [14]). This suggests that one might relax the definition of polynomial-time tractability by requiring the running time to exhibit a polynomial dependence solely on the database, and allowing arbitrary dependence on the formula. Relaxing polynomial-time tractability so that arbitrary dependence in some parameter is tolerated yields, in essence, the notion of fixed-parameter tractability. This notion is the base tractability notion of parameterized complexity theory, an alternative framework for classifying the complexity of problems. Within relational first-order logic, there is currently a mature understanding of model checking on primitive positive logic, wh","Foundations of Databases | Tree-width for first order formulae | An n! lower bound on formula size | On preservation under homomorphisms and unions of conjunctive queries | Preprocessing of intractable problems | Optimal implementation of conjunctive queries in relational data bases | Decomposing quantified conjunctive (or disjunctive) formulas | Constraint satisfaction with succinctly specified relations | Constraint Satisfaction, Bounded Treewidth, and Finite-Variable Logics | Parameterized Complexity Theory | Query evaluation via tree-decompositions | The succinctness of first-order logic on linear orders | The complexity of homomorphism and constraint satisfaction problems seen from the other side | When is the evaluation of conjunctive queries tractable | The core of a graph | Turing machines that take advice | Conjunctive-Query Containment and Constraint Satisfaction | Tractable hypergraph properties for constraint satisfaction and conjunctive queries | Tractable hypergraph properties for constraint satisfaction and conjunctive queries | Tractable structures for constraint satisfaction with truth tables | Homomorphism preservation theorems | On the complexity of bounded-variable queries",rejected,000
1206.4391.pdf.json,Gray Image extraction using Fuzzy Logic,,"Outline of A New Approach to the Analysis of Complex Systems and Decision Processes | Fuzzy models and algorithms for pattern recognition and image processing | Mui, “A Survey on Image Segmentation | Image Segmentation Techniques | A Survey of Thresholding Techniques | A Summary of Image Segmentation Techniques | A Review on Image Segmentation Techniques | Computational Techniques in the Visual Segmentation of Static Scenes | Colour Image Segmentation – A Survey | Clist, “Comparison of supervised learning techniques applied to color segmentation of fruit image | Unsupervised color image segmentation with application to skin tumor borders | Segmentation of monochrome and color texture using moving average modeling approach | Unsupervised Segmentation of Color Images | Genetic Algorithm in Search, Optimization and Machine Learning | Genetic Learning for Adaptive Image Segmentation",rejected,000
1206.4603.pdf.json,Latent Collaborative Retrieval,"There exist today a growing number of applications that seamlessly blend the traditional tasks of retrieval and recommendation. For example, when users shop for a product online they are often recommended items that are similar to the item they are currently browsing. This is a retrieval problem using the currently browsed item as the query, however the user’s profile (including other items they may have browsed, bought or reviewed) should be taken into account making it a personal recommendation problem as well. Another related task is that of automatic playlist creation in music players. The user can request the creation of a Appearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s). playlist of songs given a query (based for instance on a seed track, artist or genre) but the songs retrieved for the query should also be songs that the user likes given their known profile. We call this class of problems collaborative retrieval tasks. To our knowledge these tasks have not been studied in depth, although there are several related areas which we will discuss later in the paper. Methods designed for this task need to combine both the retrieval and recommendation aspects of the problem into a single predictor. In a standard collaborative filtering (recommendation) setup, one is given a user × item matrix indicating the known relevance of the given item to a given user, but many elements of the matrix are unknown. On the other hand, In a typical retrieval task one is given, for each query, a list of relevant items that should be retrieved. Our task is the blend of the two, which is achieved by first building a tensor comprising of the query × user × item training data. Typically in a retrieval task, and sometimes in a recommendation task as well, one also has access to content-based features for the items, e.g. in document retrieval one has access to the words in the documen",Polynomial semantic indexing | Learning collaborative information filters | Indexing by latent semantic analysis | Content-based retrieval of music and audio | Foundations of the parafac procedure: models and conditions for an | Improving social bookmark search using personalised latent variable language models | Large margin rank boundaries for ordinal regression | Optimizing search engines using clickthrough data | Multiverse recommendation: n-dimensional tensor factorization for context-aware collaborative filtering | Algorithms for non-negative matrix factorization | Using probabilistic latent semantic analysis for personalized web search | Response prediction using collaborative filtering with hierarchies and side-information | Pairwise interaction tensor factorization for personalized tag recommendation | Tensor framework and combined symmetry for hypertext mining | Web-scale multimedia analysis: Does content matter | Web-page summarization using clickthrough data | Some mathematical notes on three-mode factor analysis | Ranking with ordered weighted pairwise classification | Collaborative topic modeling for recommending scientific articles | Cofirank-maximum margin matrix factorization for collaborative ranking | Large scale image annotation: Learning to rank with joint word-image embeddings | Large-scale music annotation and retrieval: Learning to rank in joint semantic spaces | Temporal collaborative filtering with bayesian probabilistic tensor factorization | A support vector method for optimizing average precision | Collaborative filtering meets mobile recommendation: A user-centered approach,rejected,000
1206.4604.pdf.json,Learning the Experts for Online Sequence Prediction,"Sequence prediction is a key task in machine learning and statistics. It involves predicting the next element in a sequence given the previous elements. Typical applications include stock market prediction, click prediction in web browsing and consumption predic- Appearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s). tion in smart grids. Although the sequence prediction problem has been well studied, current solutions either work for long sequences or require strong prior knowledge. In this work we provide a method that uses training data to learn how to predict a novel sequence. As we shall show, we use the training sequences to obtain the prior knowledge needed for predicting novel sequences. Sequence prediction is most naturally cast as an online prediction problem (Cesa-Bianchi and Lugosi, 2006), where at every step we predict the next element, and then receive the true value of the element while suffering a loss if we made a prediction error. We are then allowed to improve the model, and predict the next step. The online formulation is natural in most applications since the new element’s true value unfolds in real time and we are interested in minimizing the prediction loss of this process. One classical approach to the problem is the so called universal sequence prediction class of methods (Feder et al., 1992; Hutter, 2006). Such methods guarantee that asymptotically (with sequence size) the model will achieve optimal prediction error. However, the price we pay for universality is that good performance will be reached only after seeing long sequences. Intuitively, the reason for this is that no prior knowledge about the sequence is used, so it may take a while until we have a good model of it. An alternative approach which does introduce prior knowledge is predicting with expert advice (Littlestone and Warmuth, 1994; Vovk, 1990). Here one has a set of r expert","Multitask learning with expert advice | A framework for learning predictive structures from multiple tasks and unlabeled data | Agnostic online learning | An analog of the minimax theorem for vector payoffs | Prediction, learning, and games | Nearest neighbor pattern classification | Compound Bayes predictors for sequences with apparent Markov structure | Individual sequence prediction using memory-efficient context trees | Universal prediction of individual sequences | A discriminatively trained, multiscale, deformable part model | Approximation to Bayes risk in repeated play | Predicting nearly as well as the best pruning of a decision tree | Probabilistic latent semantic analysis | On the foundations of universal sequence prediction | The weighted majority algorithm | Problem complexity and method efficiency in optimization | An efficient extension to mixture techniques for prediction and decision trees | Factorizing personalized markov chains for next-basket recommendation | Asymptotically subminimax solutions of compound statistical decision problems | Smoothness, lownoise and fast rates | Aggregating strategies | The contexttree weighting method: basic properties | A stochastic memoizer for sequence data | Learning structural svms with latent variables | Covering number bounds of certain regularized linear function classes",rejected,000
1206.4606.pdf.json,TrueLabel + Confusions: A Spectrum of Probabilistic Models in Analyzing Multiple Ratings,,"Maximum likelihood estimation of observer error-rates using the em algorithm | Bayesian classifier combination | Managing crowdsourced human computation: a tutorial | Winbugs a bayesian modelling framework: Concepts, structure, and extensibility | Get another label? improving data quality and data mining using multiple, noisy labelers | Inferring ground truth from subjective labelling of venus images | Dealing with multimodal posteriors and non-identifiability in mixture models | Online crowdsourcing: rating annotators and obtaining cost-effective labels | The multidimensional wisdom of crowds",rejected,000
1206.4617.pdf.json,Continuous Inverse Optimal Control with Locally Optimal Examples,"Algorithms for inverse optimal control (IOC), also known as inverse reinforcement learning (IRL), recover an unknown reward function in a Markov decision process (MDP) from expert demonstrations of the corresponding policy. This reward function can be used to perform apprenticeship learning, generalize the expert’s behavior to new situations, or infer the expert’s goals (Ng & Russell, 2000). Performing IOC in continuous, high-dimensional domains is challenging, because IOC algorithms are usually much more computationally demanding than the corresponding “forward” control methods. In this paper, we present an IOC algorithm that efficiently handles deterministic MDPs with large, continuous state and action spaces by considering only the shape of the learned reward function in the neighborhood of the expert’s demonstrations. Since our method only considers the shape of the reward function around the expert’s examples, it does Appearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s). not integrate global information about the reward along alternative paths. This is analogous to trajectory optimization methods, which solve the forward control problem by finding a local optimum. However, while the lack of global optimality is a disadvantage for solving the forward problem, it can actually be advantageous in IOC. This is because it removes the assumption that the expert demonstrations are globally optimal, thus allowing our algorithm to use examples that only exhibit local optimality. For complex tasks, human experts might find it easier to provide such locally optimal examples. For instance, a skilled driver might execute every turn perfectly, but still take a globally suboptimal route to the destination. Our algorithm optimizes the approximate likelihood of the expert trajectories under a parameterized reward. The approximation assumes that the expert’s trajectory lies near",Apprenticeship learning via inverse reinforcement learning | Practical augmented lagrangian methods | Linear Matrix Inequalities in System and Control Theory | Inverse optimal control with linearly-solvable MDPs | Feature construction for inverse reinforcement learning | Nonlinear inverse reinforcement learning with gaussian processes | Algorithms for inverse reinforcement learning | Maximum margin planning | Learning to search: Functional gradient techniques for imitation learning | Accurate approximations for posterior moments and marginal densities | Modeling Purposeful Adaptive Behavior with the Principle of Maximum Causal Entropy | Maximum entropy inverse reinforcement learning,rejected,000
1206.4636.pdf.json,Modeling Latent Variable Uncertainty for Loss-based Learning,"Latent variable models (lvms) provide an elegant formulation for learning with weakly supervised datasets. Appearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s). For example, in computer vision, we may wish to learn a model for detecting an object such as ‘deer’ from images where the location of the deer is unknown, and is therefore treated as a latent variable. In computational medicine, we may wish to diagnose a patient based on the observed symptoms as well as other unknown factors, such as the family’s medical history, which can be represented using latent variables. Typically, an lvm employs a single distribution over three types of variables: (i) the observed variables, or input, whose values are known during both training and testing; (ii) the unobserved variables, or output, whose values are known only during training; and (iii) the unknown latent variables. In this setting, a natural framework would be to model the uncertainty in the value of the latent variables and learn an lvm by marginalizing them out (for example, in the case of the expectation-maximization, or em, algorithm). However, such an approach is unsuited for applications that require an accurate prediction of the latent variables during test time. For example, in the above deer detection application, we would like to infer not only whether an image contains a deer, but also the exact location of the deer. Alternately, we can use a delta distribution that provides a pointwise estimate of the output and the latent variables (for example, in the case of the latent support vector machines, or lsvm, framework). However, discarding the uncertainty in latent variables can make such an approach prone to error due to noise (for example, background clutter that can be confused with a deer in feature space). The above argument illustrates the deficiency of using a single joint distribution over the outp","Simultaneous object detection and ranking with weak supervision | Histograms of oriented gradients for human detection | Maximum likelihood from incomplete data via the EM algorithm | The PASCAL visual object classes (VOC) challenge | A discriminatively trained, multiscale, deformable part model | Bayesian Data Analysis | Cutting-plane training for structural SVMs | Self-paced learning for latent variable models | Learning specific-class segmentation from diverse data | Action recognition from a distributed representation of pose and appearance | Max-margin min-entropy models | Diversity and dissimilarity coefficients: A unified approach | Pegasos: Primal estimated sub-gradient solver for SVM | Maximum likelihood theory for incomplete data from an exponential family | Support vector machine learning for interdependent and structured output spaces | Learning structural SVMs with latent variables",rejected,000
1206.4639.pdf.json,Adaptive Regularization for Weight Matrices,"Many machine learning tasks involve models in the form of a matrix. As an important example, consider the problem of linear metric learning where the dissimilarity between a pair of samples is measured using the Mahalanobis distance, parametrized by a positive semi-definite matrix. A second important example is the matrix model obtained when learning multiple linear classifiers regularized jointly, like in the case of object recognition with many classes. Appearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s). Many algorithms were developed for learning these two tasks, including online algorithms developed recently in the context of classification and ranking costs (Davis et al., 2007; Jain et al., 2008; Chechik et al., 2009). While such linear matrix models are common for metric and multiclass learning, the broader class of ”vector” linear model are a popular choice in many domains since they provide a good balance between simplicity, scalability and performance. Methods to generate linear classifiers from data have flourished in the past decade, including SVMImportantly, when learning linear models, it was recently shown that modeling the second order information about the set of models (Crammer et al. (2009) and the references therein), or using this information during training (Duchi et al., 2010) improves the convergence rate of the learning algorithms as well as the performance of the resulting classifiers. These very effective methods were developed primarily for handling vector models, and were not designed to handle matrix models. At first sight, problems that involve learning matrices could be handled directly using methods developed for learning vectors, including the second order methods described above. In practice however, matrix models often pose a challenge to scalability, since both their memory and their runtime complexity scale quadratically with ","A secondorder perceptron algorithm | An online algorithm for large scale image similarity learning | Adaptive regularization of weighted vectors | Information-theoretic metric learning | Hierarchical semantic indexing for large scale image retrieval | Confidenceweighted linear classification | Adaptive subgradient methods for online learning and stochastic optimization | Caltech-256 object category dataset | Matrix Variate Distributions | Online metric learning and fast similarity search | K.Saenko, and T.Darrell. What you saw is not what you get: Domain adaptation using asymmetric kernel transforms | Learning to filter netnews | Learning multi-modal similarity | Multiresolution gray-scale and rotation invariant texture classification with local binary patterns | New adaptive algorithms for online classification | Distance metric learning for large margin nearest neighbor classification | Wsabie: Scaling up to large vocabulary image annotation | A comparative study on feature selection in text categorization",rejected,000
1206.4647.pdf.json,Active Learning for Matching Problems,"The burgeoning interest in recommender systems has led to a plethora of techniques for predicting user preferences or ratings for unseen items (e.g., products in e-commerce applications). Collaborative filtering (CF) methods (Goldberg et al., 1992) have proven especially popular and have attained impressive performance (Koren, 2009). In practice, however, recommendations must not only account for user preferences in isolation; one usually has to tradeoff preferences for recommended items with various constraints or objectives. For example, an online retailer may want to limit the number of recommendations (to different users) for any particular item so stock is not depleted (which would create unsatisfied customers). The same retailer may wish to facilitate serendipitous purchases by ensuring items recommended to any single user are diverse (McNee et al., 2006). In this paper we focus on match-constrained recom- Appearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s). mendation, where the quality of a set of recommendations or matching is measured relative to constraints or objectives that account for the entire set of users to whom an item is recommended, the entire set of items recommended to a single user, or both. These are traded off against the predicted degree of preference of individual recommendations. Match-constrained recommendation has wide application. For example, consider the problem of assigning papers to reviewers: given preferences (self-assessed expertise) of reviewers for certain papers, we want to find the best assignment of papers to reviewers. Recent work has used learning techniques such as CF to predict missing preferences— allowing reviewers to specify preferences for only a small selection of papers—and finding high quality matches subject to specific “collective” constraints on the matching (e.g., number of papers per reviewer, number of re","Formal models for expert finding in enterprise | A tutorial on Bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning. TR-2009-23 | A framework for optimizing paper | Recommender systems for the conference paper assignment | College admissions and the stability of marriage | Using collaborative filtering to weave an information tapestry | Eigentaste: A Constant Time Collaborative Filtering Algorithm | Discriminative batch mode active | Personalized active learning for collaborative | The efficient allocation of individuals to positions | A Bayesian approach toward active learning for collaborative | The BellKor solution to the Netflix grand prize | Being accurate is not enough: how accuracy metrics have hurt recommender systems | Expertise modeling for matching papers with reviewers | An iterative rating method: application to webbased conference | An algorithm to determine peer-reviewers | The evolution of the labor market for medical interns and residents: A case study in game theory | Bayesian probabilistic matrix factorization using Markov chain | Active learning literature survey | On the optimal assignment of conference papers to reviewers | COFI RANK – Maximum margin matrix factorization for collaborative",rejected,000
1206.4652.pdf.json,The Most Persistent Soft-Clique in a Set of Sampled Graphs,"Graphs are used ubiquitously in computer science in order to represent data objects and their interrelations. Consequently, machine learning and data mining research has developed a large number of methods to analyze given graph structures and to identify substructures of predefined properties, in particular cliques, i.e. subsets of vertices that are fully connected with respect to the graph’s edge set. In this work, we extend this reasoning to the case where multiple, potentially noisy or incomplete, instances of a graph are available for analysis. The hard criterion of a set of vertices being fully connected becomes too limiting in this case, so instead we look for persistent soft-cliques, i.e. subgraphs that are almost fully or at least densely connected, and that persists through all or most instances of the graph. For given several instances of a weighted graph, we are interested to find a persistent soft-clique with the highest weight. We call this a most persistent soft-clique problem. By solving the most persistent clique problem we can extend a wide range of applications that relied on finding cliques in graphs to situations where a collection of graphs is available, e.g. measurements at different points of times, but where each graph instance might have a different edge set, e.g. due to noisy or incomplete observations. These noisy snapshots of the same graph pose challenging tasks related to inconsistent patterns, but could give us more confidence in characterizing the inherent pattern or phenomenon. Take as an illustrative example, the usage of dense subgraphs in mobile phone or location-based social networks to identify groups of friends or families. A temporal dimension arises naturally for such a graph where, for example, different hours in a day lead to several samples of the graphs. It is reasonable to assume that dense subgraphs that appear in all of the samples of the graphs are the groups of friends or families that we would like to identify. How",A graph-theoretic definition of a sociometric clique | Random graphs | Convex Optimization | Segmentation as maximum-weight independent set | On effectively finding maximal quasi-cliques in graphs | Friendship and mobility: Friendship and mobility: User movement in location-based social networks | Robust one-class clustering using hybrid global and local search | Image segmentation by figure-ground composition into maximal cliques | Étude comparative de la distribution florale dans une portion des alpes et des jura | Robust graph mode seeking by graph shift | A method of matrix analysis of group | Maxima for graphs and a new proof of a theorem of turan | The maximum clique problem | Dominant sets and pairwise clustering | Constraint-based pattern mining in dynamic graphs | Optimizing binary mrfs via extended roof duality | Support Vector Learning | Learning with Kernels | Dealing with large diagonals in kernel matrices | Social network analysis,rejected,000
1206.4656.pdf.json,Machine Learning that Matters,"At one time or another, we all encounter a friend, spouse, parent, child, or concerned citizen who, upon learning that we work in machine learning, wonders “What’s it good for?” The question may be phrased more subtly or elegantly, but no matter its form, it gets at the motivational underpinnings of the work that we do. Why do we invest years of our professional lives in machine learning research? What difference does it make, to ourselves and to the world at large? Much of machine learning (ML) research is inspired by weighty problems from biology, medicine, finance, astronomy, etc. The growing area of computational sustainability (Gomes, 2009) seeks to connect ML advances to real-world challenges in the environment, economy, and society. The CALO (Cognitive Assistant that Learns and Organizes) project aimed to integrate learning and reasoning into a desktop assistant, potentially impacting everyone who uses a computer (SRI International, 2003–2009). Machine learning has effec- Appearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 California Institute of Technology. tively solved spam email detection (Zdziarski, 2005) and machine translation (Koehn et al., 2003), two problems of global import. And so on. And yet we still observe a proliferation of published ML papers that evaluate new algorithms on a handful of isolated benchmark data sets. Their “real world” experiments may operate on data that originated in the real world, but the results are rarely communicated back to the origin. Quantitative improvements in performance are rarely accompanied by an assessment of whether those gains matter to the world outside of machine learning research. This phenomenon occurs because there is no widespread emphasis, in the training of graduate student researchers or in the review process for submitted papers, on connecting ML advances back to the larger world. Even the rich assortment of applications-","Human development index: Methodology and measurement | The Netflix Prize | Machine learning: A maturing field | Yahoo! Learning to Rank Challenge overview | Computational sustainability: Computational methods for a sustainable environment, economy, and society | The WEKA data mining software: An update | The meaning and use of the area under a receiver operating characteristic (ROC) curve | The Elements of Statistical Learning: Data Mining, Inference, and Prediction | Statistical phrase-based translation | The changing science of machine learning | AUC: a misleading measure of the performance of predictive distribution models | CALO: Cognitive assistant that learns and organizes | Resolving confusion of tongues in statistics and machine learning: A primer for biologists and bioinformaticians | A machine learning approach to the detection of fetal hypoxia during labor and delivery | Ending Spam: Bayesian Content Filtering and the Art of Statistical Language Classification",rejected,000
1206.4667.pdf.json,Unachievable Region in Precision-Recall Spaceand Its Effect on Empirical Evaluation,"Precision-recall (PR) curves are a common way to evaluate the performance of a machine learning algorithm. PR curves illustrate the tradeoff between the proportion of positively labeled examples that are truly positive (precision) as a function of the proportion of correctly classified positives (recall). In particular, PR analysis is preferred to ROC analysis when there is a large skew in the class distribution. In this situation, even a relatively low false positive rate can produce a large number of false positives and hence a low precision (Davis & Goadrich, 2006). Many applications are Appearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s). characterized by a large skew in the class distribution. In information retrieval (IR), only a few documents are relevant to a given query. In medical diagnoses, only a small proportion of the population has a specific disease at any given time. In relational learning, only a small fraction of the possible groundings of a relation are true in a database. The area under the precision-recall curve (AUCPR) often serves as a summary statistic when comparing the performance of different algorithms. For example, IR systems are frequently judged by their mean average precision, or MAP (not to be confused with the same acronym for “maximum a posteriori”), which is an approximation of the mean AUCPR over the queries (Manning et al., 2008). Similarly, AUCPR often serves as an evaluation criteria for statistical relational learning (SRL) (Kok & Domingos, 2010; Davis et al., 2005; Sutskever et al., 2010; Mihalkova & Mooney, 2007) and information extraction (IE) (Ling & Weld, 2010; Goadrich et al., 2006). Additionally, some algorithms, such as SVM-MAP (Yue et al., 2007) and SAYU (Davis et al., 2005), explicitly optimize the AUCPR of the learned model. There is a growing body of work that analyzes the properties of PR curves (Davis & Goadr","Nonparametric estimation of the precision-recall curve | The relationship between precision-recall and ROC curves | An integrated approach to learning Bayesian networks of rules | Apples-to-apples in crossvalidation studies: pitfalls in classifier performance measurement | Gleaner: creating ensembles of first-order clauses to improve recall-precision curves | Predicting outcome for collaborative featured article nomination in wikipedia | Learning Markov logic networks using structural motifs | Temporal information extraction | Comparing evaluation metrics for sentence boundary detection | Introduction to Information Retrieval | Bottom-up learning of Markov logic network structure | Gradient-based boosting for statistical relational learning: The relational dependency network case | ARTS: accurate recognition of transcription starts in human | Modelling relational data using Bayesian clustered tensor factorization | SVMs modeling for highly imbalanced classification. Systems, Man, and Cybernetics, Part B: Cybernetics | A support vector method for optimizing average precision",rejected,000
1206.5157.pdf.json,Leaf vein segmentation using Odd Gabor filters and morphological operations,,"Denglerb,” Leaf Vascular Pattern Formation | A Leaf Vein Extraction Method Based On Snakes Technique | Leaf Vein Extraction | Scale multiplication in odd Gabor transform domain for edge detection”, Journal of Visual communication and image representation, Volume 18 Issue | Complete discrete 2-D Gabor transforms by neural networks for image analysis and compression | Odd Gabor filter-based edge detection | Computer and Robot Vision | Fundamentals of Digital Image Processing",rejected,000
1206.5242.pdf.json,Studies in Lower Bounding Probability of Evidence using the Markov Inequality,,An anytime scheme for bounding posterior beliefs | Improving bound propagation | Ais-bn: An adaptive importance sampling algorithm for evidential reasoning in large bayesian networks | Approximating probabilistic inference in bayesian belief networks is np-hard | An optimal approximation algorithm for bayesian inference | Mixtures of deterministic-probabilistic networks and their and/or search space. In UAI | Mini-buckets: A general scheme for bounded inference | Optimizing exact genetic linkage computations | Approximate inference algorithms for hybrid bayesian networks with discrete constraints. UAI | Samplesearch: A scheme that searches for consistent samples. AISTATS-2007 | From sampling to model counting | A monte carlo algorithm for probabilistic propagation in belief networks based on importance sampling and stratified simulation techniques | Knowledge engineering for large belief networks | Minisat v1.13-a sat solver with conflict-clause minimization | Importance sampling algorithms for Bayesian networks: Principles and performance,rejected,000
1206.5244.pdf.json,Search for Choquet-optimal paths under uncertainty,"An important source of complexity in practical applications of problem solving methods developed in AI is the imperfect knowledge of the real problem to deal with. This is particularly true in path-planning problems where the map is not always the territory. When seeking the optimal path from a given node to a goal node, several uncertainty factors might indeed increase the complexity of the optimization task. Firstly, the consequences of the actions might not be certain, which can be modeled by non-deterministic transitions between states. Secondly, the current state might not be known exactly (partial observability), which requires maintaining beliefs on possible states revised during the search. These problems are widely discussed in the litterature on MDPs and POMDPs, see e.g. Puterman (1994), Kaebling et al. (1999). Beside these sources of complexity, the cost transitions between states might also be uncertain. This eventuality has motivated work aimed at revisiting, under uncertainty, the shortest path problem in a state space graph, and its classical resolution with the A∗ algorithm. For example, Wellman and Wurman consider a case where the costs are time dependent and representable by random variables (Wellman et al., 1995). They introduce the SDA∗ algorithm to determine the preferred paths according to the stochastic dominance partial order. Moreover, an extension of this algorithm specifically designed to cope with both uncertainty and multiple criteria is proposed in (Wurman and Wellman, 1996). Another way of introducing uncertainty in costs is to consider a set of plausible scenarios, each bringing a different valuation to transitions and therefore to solution paths. This is the natural formulation when the costs depend on exogenous variables not controlled by the decision maker, these variables having an overall impact on the graph (e.g. transfer times in a city depending on the weather, security of moves depending on enemy positions, asset values depen","A constraint satisfaction approach to the robust spanning tree with interval data | Local-mobius transforms of monotone capacities | Diversification, convex preferences and non-empty core in the choquet expected utlity model | Theory of capacities | Dynamic programming for deterministic discrete-time systems | Risk, ambiguity and the Savage axioms | The application of fuzzy integrals in multicriteria decision making | On the maximum probability which is consistent with a convex capacity | Planning and acting in partially observable stochastic domains | Robust discrete optimization and its applications | A new approach to multiobjective A∗ search | Solving min-max shortest-path problems on a network | An axiomatic approach to robustness in search problems with multiple scenarios | State space search for risk-averse agents | Markov decision processes, discrete stochastic dynamic programming | Integral representation without additivity | A Mathematical Theory of Evidence | Cores of convex games | Multiobjective A | Path planning under time-dependent uncertainty | Optimal factory scheduling using stochastic dominance A∗",rejected,000
1206.5251.pdf.json,Node Splitting: A Scheme for Generating Upper Bounds in Bayesian Networks,,Encoding CNFs to empower component analysis | Compiling Bayesian networks using variable elimination | An edge deletion semantics for belief propagation and its practical impact on approximation quality | A variational approach for approximating Bayesian networks by edge deletion | Bucket elimination: A unifying framework for probabilistic inference | Iterative join-graph propagation | Mini-buckets: A general scheme for bounded inference | A revolution: Belief propagation in graphs with cycles | Solving map exactly by searching on compiled arithmetic circuits | Efficient stochastic local search for MPE solving | On the optimality of tree-reweighted max-product message passing | AND/OR branchand-bound for graphical models | Systematic vs. non-systematic algorithms for solving the MPE task | Using weighted max-sat engines to solve MPE | Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference | Empirical evaluation of approximation algorithms for probabilistic decoding | Solving Bayesian networks by weighted model counting | Probabilistic inference in multiply connected networks using loop cutsets | Map estimation via agreement on trees: messagepassing and linear programming | Correctness of local probability propagation in graphical models with loops | Constructing free-energy approximations and generalized belief propagation algorithms | Exploiting causal independence in bayesian network inference,rejected,000
1206.5253.pdf.json,Reachability Under Uncertainty,,Integer Convex Maximization | An improved FPTAS for restricted shortest path | Overview of constraint-based path selection algorithms for QoS routing | Introduction to Global Optimization | A simple efficient approximation scheme for the restricted shortest paths problem | Bicriteria network design problems | Stochastic Shortest Paths Via Quasi-convex Maximization. | Randomized rounding: a technique for provably good algorithms and algorithmic proofs | Contrastive estimation: training log-linear models on unlabeled data | Probabilistic Finite-State Machines-Part I | Probabilistic Finite-State Machines-Part II,rejected,000
1206.5255.pdf.json,Minimax regret based elicitation of generalized additive utilities,,"Graphical models for preference and utility | A POMDP formulation of preference elicitation problems | UCP-Networks: A directed graphical representation of conditional utilities | Constraint-based optimization and utility elicitation using the minimax decision criterion | Eliciting bid taker non-price preferences in (combinatorial) auctions | Local utility elicitation in GAI models | Interdependence and additivity in multivariate, unidimensional expected utility theory | GAI networks for utility elicitation | Conjoint analysis in consumer research: Issues and outlook | Decisions with Multiple Objectives: Preferences and Value Trade-offs | Robust Discrete Optimization and Its Applications | Preference ratios in multiattribute evaluation (PRIME)–elicitation and decision procedures under incomplete information | The Foundations of Statistics | Incremental utility elicitation with the minimax regret decision criterion",rejected,000
1206.5257.pdf.json,Evaluating influence diagrams with decision circuits,,"Sensitivity analysis in Bayesian networks: From single to multiple parameters | On the robustness of Most Probable Explanations | Compiling Bayesian networks with local structure | Compiling relational Bayesian networks for exact inference | A method for using belief networks as influence diagrams | A differential approach to inference in Bayesian networks | Decomposable negation normal form | A logical approach to factoring belief networks | A compiler for deterministic, decomposable negation normal form | A differential approach to inference in Bayesian networks | Applying numerical trees to evaluate asymmetric decision problems | A definition and graphical representation for causality | Solving MAP exactly by searching on compiled arithmetic circuits | From influence diagrams to junction trees | A differential semantics for jointree algorithms | Decision Analysis: Introductory Lectures on Choices under Uncertainty, Addison-Wesley | The Foundations of Statistics, Wiley, New York | Evaluating influence diagrams | Probabilistic inference and influence diagrams | Bayes-ball: The rational pastime (for determining irrelevance and requisite information in belief networks and influence diagrams) | Efficient value of information | Gaussian influence diagrams | Decision making using probabilistic inference | Valuation based systems for Bayesian decision analysis, Operations Research, 40 (MayJune) | Dynamic programming and influence diagrams",rejected,000
1206.5258.pdf.json,Optimizing Memory-Bounded Controllers for Decentralized POMDPs,,Solving POMDPs using quadratically constrained linear programs | Bounded policy iteration for decentralized POMDPs | On the global convergence of a filter-SQP algorithm | Dynamic programming for partially observable stochastic games | Memorybounded dynamic programming for DEC-POMDPs | Reinforcement Learning: An Introduction | An optimal bestfirst search algorithm for solving infinite horizon DECPOMDPs | MAA*: A heuristic search algorithm for solving decentralized POMDPs,rejected,000
1206.5260.pdf.json,Reasoning at the Right Time Granularity,,A model for reasoning about persistence and causation | Nested junction trees | Graphical models | Expectation propagation for approximate bayesian inference | Expectation propagation for continuous time Bayesian networks. UAI | Continuous time Bayesian networks | Markov chains | An introduction to hidden Markov models | Nonparametric belief propagation,rejected,000
1206.5266.pdf.json,AND/OR Multi-Valued Decision Diagrams (AOMDDs) for Weighted Graphical Models,,A complexity analysis of space-bound learning algorithms for the constraint satisfaction problem | Nonserial Dynamic Programming | Graph-based algorithms for boolean function manipulation | Compiling bayesian networks using variable elimination | Model Checking | Recursive conditioning | A knowledge compilation map | Bucket elimination: A unifying framework for reasoning | AND/OR search spaces for graphical models | Compiling csps into treedriven automata for interactive solving | Taking advantage of stable sets of variables in constraint satisfaction problems | Representation of switching circuits by binary-decision programs | Compiling constraint networks into AND/OR multi-valued decision diagrams (AOMDDs) | Case-factor diagrams for structured probabilistic modeling | Symbolic Model Checking | Compiling bayesian networks by symbolic probability calculation based on zero-suppressed bdds | Valuation-based systems for bayesian decision analysis | Decision diagrams for the computation of semiring valuations,rejected,000
1206.5268.pdf.json,Best-First AND/OR Search for Most Probable Explanations,,Probabilistic Reasoning in Intelligent Systems | A general scheme for automatic generation of search heuristics from specification dependencies | And/or branch-andbound for graphical models | And/or search spaces for graphical models | Memory intensive branch-and-bound search for graphical models | Best-first and/or search for 0-1 integer programming | And/or branch-andbound search for pure 0/1 integer linear programming problems | Best-first and/or search for graphical models | Taking advantage of stable sets of variables in constraint satisfaction problems | Generalized best-first search strategies and the optimality of a | Mini-buckets: A general scheme for approximating inference | Recursive conditioning | Solving Bayesian networks by weighted model counting | Maximum likelihood haplotyping for general pedigrees | Heuristic search in restricted memory,rejected,000
1206.5271.pdf.json,Learning Bayesian Network Structure from Correlation-Immune Data,,"On correlation-immune functions | Learning Bayesian networks is NP-Hard (Technical Report MSR-TR-94-17) | A male-speci ̄c lethal mutation in Drosophila melanogaster that transforms sex | A Bayesian method for the induction of probabilistic networks from data | Construction of correlation immune Boolean functions | Data perturbation for escaping local maxima | Learning Bayesian network structure from massive datasets: The “Sparse Candidate | Learning Bayesian networks: The combination of knowledge and statistical data | Otx2, Gbx2 and Fgf8 interact to position and maintain a mid-hindbrain organizer | Lookahead and pathology in decision tree induction | Generating better decision trees | Skewing: An efficient alternative to lookahead for decision tree induction | Oversearching and layered search in empirical learning | Why skewing works: learning difficult Boolean functions with greedy tree learners | Estimating the dimension of a model | Probabilistic diagnosis using a reformulation of the INTERNIST1/QMR knowledge base",rejected,000
1206.5273.pdf.json,Survey Propagation Revisited,,"On the solutionspace geometry of random constraint satisfaction problems | Survey propagation as local equilibrium equations | Survey propagation: an algorithm for satisfiability | Factor graphs and the sum-product algorithm | A new look at survey propagation and its generalizations | Analytic and Algorithmic Solution of Random Satisfiability Problems | Loopy belief propagation for approximate inference: An empirical study | Learning Bayesian Networks. PrenticeHall, Inc | Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference | Towards efficient sampling: Exploiting random walk strategies",rejected,000
1206.5276.pdf.json,Template Based Inference in Symmetric Relational Markov Random Fields,,et al | et al | Lifted firstorder probabilistic inference | Inducing features of random fields | Residual belief propagation: Informed scheduling for asynchronous message passing | Learning probabilistic relational models | et al | Stochastic relaxation | Learning probabilistic models of relational structure | Assessing degeneracy in statistical models of social networks | Towards an integrated protein-protein interaction network: a relational Markov network approach | An introduction to variational approximations methods for graphical models | et al | Factor graphs and the sum-product algorithm | MIPS: a database for genomes and protein sequences | Loopy belief propagation for approximate inference: An empirical study | SPOOK: A system for probabilistic object-oriented knowledge representation | First-order probabilistic inference | D | Discriminative probabilistic models for relational data | Link prediction in relational data | Constructing free energy approximations and generalized belief propagation algorithms,rejected,000
1206.5279.pdf.json,Making life better one large system at a time: Challenges for UAI research,,"Automated discovery of sevice and host dependencies in networked systems | Using Magpie for request extraction and workload modelling | Controlling the false discovery rate: A practical and powerful approach to multiple testing | Statistical Decision Theory and Bayesian Analysis | Testing of a point null hypothesis: The irreconciability of significance levels and evidence (with discussion) | Recovery-oriented computing: building multitier dependability | Correlating instrumentation data to system states: A building block for automated diagnosis and control | Capturing | A Bayesian method for the induction of probabilistic models from data | Modern science and the Bayesian-frequentist controversy | Self-repairing computers | On the application of the boostrap for computing confidence measures on features of induced Bayesian networks | Being Bayesian about network structure | Learning Bayesian networks: The combination of knowledge and statistical data | Querying the internet with PIER | Autopilot: Automatic data center management | The vision of autonomic computing | The art of computer programming | Determining the number of non-spurious arcs in a learned DAG model: Investigation of a Bayesian and a frequentist approach | Model selection and accounting for model uncertainty in graphical models using Occam’s window | Causality: models | Astrolabe: A robust and scalable technology for distributed system monitoring, management, and data mining | All of Statistics",rejected,000
1206.5284.pdf.json,More-or-Less CP-Networks,,"Graphical models for preference and utility | Semiringbased constraint satisfaction and optimization | Ucpnetworks: A directed graphical representation of conditional utilities | Reasoning with conditional ceteris paribus preference statem | Cp-nets: A tool for representing and reasoning with conditional ceteris paribus preference statements | Cp-nets: Reasoning and consistency testing | Reasoning about soft constraints and conditional preferences: complexity results and approximation techniques | Background to qualitative decision theory | Representing preferences as ceteris paribus comparatives | Qualitative reasoning. In The Computer Science and Engineering Handbook, pages 715–733 | From preference representation to combinatorial vote",rejected,000
1206.5287.pdf.json,Policy Iteration for Relational MDPs,,Algebraic decision diagrams and their applications | Stochastic dynamic programming with factored representations | Symbolic dynamic programming for first-order MDPs | Approximate policy iteration with a policy language bias | Exploiting first-order regression in inductive policy selection | Generalizing plans to new environments in relational MDPs | A logic-based approach to dynamic programming. AAAI-04 workshop on learning and planning in Markov Processes – advances and challenges | Markov decision processes: Discrete stochastic dynamic programming | Approximate linear programming for first-order MDPs | Practical linear valueapproximation techniques for first-order MDPs | First order decision diagrams for relational MDPs,rejected,000
1206.5288.pdf.json,Constrained Automated Mechanism Design for Infinite Games of Incomplete Information,,"Antisocial agents and Vickrey auctions | Complexity of mechanism design | Applications of automated mechanism design | Computational criticisms of the revelation principle | Microeconomic Theory | Selling spectrum rights | Optimal auction design | Generating Trading Agent Strategies: Analytic and Empirical Methods for Infinite and Large Games | Computing best-response strategies in infinite games of incomplete information | Introduction to Stochastic Search and Optimization | Empirical mechanism design: Methods, with an application to a supply chain scenario",rejected,000
1206.5292.pdf.json,Markov Logic in Infinite Domains,"Most AI problems are characterized by both uncertainty and complex structure, in the form of multiple interacting objects and relations. Handling both requires combining the capabilities of probabilistic models and firstorder logic. Attempts to achieve this have a long history, and have gathered steam in recent years. Within AI, Nilsson (1986) is an early example. Bacchus (1990), Halpern (1990) and coworkers (e.g., Bacchus et al. (1996)) produced a substantial body of relevant theoretical work. Around the same time, several authors began using logic programs to compactly specify complex Bayesian net- works, an approach known as knowledge-based model construction (Wellman et al., 1992). More recently, many combinations of (subsets of) first-order logic and probability have been proposed in the burgeoning field of statistical relational learning (Getoor & Taskar, 2007), including probabilistic relational models (Friedman et al., 1999), stochastic logic programs (Muggleton, 1996), Bayesian logic programs (Kersting & De Raedt, 2001), and others. One of the most powerful representations to date is Markov logic (Richardson & Domingos, 2006). Markov logic is a simple combination of Markov networks and first-order logic: each first-order formula has an associated weight, and each grounding of a formula becomes a feature in a Markov network, with the corresponding weight. The use of Markov networks instead of Bayesian networks obviates the difficult problem of avoiding cycles in all possible groundings of a relational model (Taskar et al., 2002). The use of first-order logic instead of more limited representations (e.g., description logics, Horn clauses) makes it possible to compactly represent a broader range of dependencies. For example, a dependency between relations like “Friends of friends are (usually) friends” cannot be specified compactly in (say) probabilistic relational models, but in Markov logic it suffices to write down the corresponding formula and weight. Mark",Representing and reasoning with probabilistic knowledge | From statistical knowledge bases to degrees of belief | Probability and measure (3rd Ed.) | Applying probability measures to abstract languages | Statistical properties of probabilistic context-free grammars | Unifying logical and statistical AI | Learning probabilistic relational models | Logical foundations of artificial intelligence | Gibbs measures and phase transitions | Introduction to Statistical Relational Learning | An analysis of first-order logics of probability | Reasoning about infinite random structures with relational Bayesian networks | Towards combining inductive logic programming with Bayesian networks | The Alchemy system for statistical relational AI (Tech. Rept.) | Of starships and Klingons: Bayesian logic for 23rd century | Recursive random fields | Approximate inference for infinite contingent Bayesian networks | Stochastic logic programs | Probabilistic logic | Semantics and inference for recursive probability models | The independent choice logic for modelling multiple agents under uncertainty | PRISM: A symbolic-statistical modeling language | Markov logic in infinite domains (Tech | Discriminative probabilistic models for relational data | From knowledge bases to decision models,rejected,000
1206.5295.pdf.json,Improved Memory-Bounded Dynamic Programming for Decentralized POMDPs,,The Complexity of Decentralized Control of Markov Decision Processes | Approximate Solutions for Partially Observable Stochastic Games with Common Payoffs | In Proceedings of the Nineteenth National Conference on Artificial Intelligence (AAAI) | Task Modelling in Collective Robotics | Taming Decentralized POMDPs: Towards Efficient Policy Computation for Multiagent Settings | Point-based value iteration: An anytime algorithm for POMDPs | The Communicative Multiagent Team Decision Problem: Anaylzing Teamwork Theories and Models | The Complexity of Multiagent Systems: The Price of Silence | Formal Models and Algorithms for Decentralized Control of Multiple Agents | Memory-Bounded Dynamic Programming for DEC-POMDPs | Point-Based POMDP Algorithms: Improved Analysis and Implementation | In Proceedings of the Twenty-First National Conference on Artificial Intelligence (AAAI) | MAA*: A Heuristic Search Algorithm for Solving Decentralized POMDPs,rejected,000
1206.6230.pdf.json,Decentralized Data Fusion and Active Sensing with Mobile Sensors for Modeling and Predicting Spatiotemporal Traffic Phenomena,"Knowing and understanding the traffic conditions and phenomena over road networks has become increasingly important to the goal of achieving smooth-flowing, congestion-free traffic, especially in densely-populated urban cities. According to a 2011 urban mobility report (Schrank et al., 2011), traffic congestion in the USA has caused 1.9 billion gallons of extra fuel, 4.8 billion hours of travel delay, and $101 billion of delay and fuel cost. Such huge resource wastage can potentially be mitigated if the spatiotemporally varying traffic phenomena (e.g., speeds and travel times along road segments) are predicted accurately enough in real time to detect and forecast the congestion hotspots; network-level (e.g., ramp metering, road pricing) and user-level (e.g., route replanning) measures can then be taken to relieve this congestion, so as to improve the overall efficiency of road networks. In practice, it is non-trivial to achieve real-time, accurate prediction of a spatiotemporally varying traffic phenomenon because the quantity of sensors that can be deployed to observe an entire road network is costconstrained. Traditionally, static sensors such as loop detectors (Krause et al., 2008a; Wang and Papageorgiou, 2005) are placed at designated locations in a road network to collect data for predicting the traffic phenomenon. However, they provide sparse coverage (i.e., many road segments are not observed, thus leading to data sparsity), incur high installation and maintenance costs, and cannot reposition by themselves in response to changes in the traffic phenomenon. Low-cost GPS technology allows the collection of traffic data using passive mobile probes (Work et al., 2010) (e.g., taxis/cabs). Unlike static sensors, they can directly measure the travel times along road segments. But, they provide fairly sparse coverage due to low GPS sampling frequency (i.e., often imposed by taxi/cab companies) and no control over their routes, incur high initial implementation cost, p",,rejected,000
1206.6399.pdf.json,Demand-Driven Clustering in Relational Domainsfor Predicting Adverse Drug Events,"Statistical relational learning (SRL) (Getoor & Taskar, 2007) focuses on developing learning and reasoning formalisms that combine the benefits of relational representations, such as relational databases or first-order logic, with those of probabilistic, graphical models for Appearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s). handling uncertainty. SRL is especially applicable to domains where it is important to incorporate information from multiple different relations in a learned model and explicitly model uncertainty. One emerging application that meets both criteria is analyzing electronic medical records (EMR). An EMR is a relational database that stores a patient’s clinical history: disease diagnoses, procedures, prescriptions, lab results, etc. Using EMRs it is possible to build models to address important medical problems such as predicting which patients are most at risk for having an adverse response to a certain drug. However, EMRs pose challenges due to their relational schemas (i.e., the database contains separate relational tables for diagnoses, prescriptions, labs, etc.), longitudinal nature (e.g., time of diagnosis may be important), and because different patients may have dramatically different numbers of entries in any given table, such as diagnoses or vitals. Furthermore, it is important to model the uncertain, non-deterministic relationships between patients’ clinical histories and current and future predictions about their health status. Latent structure poses a substantial challenge for using machine learning to analyze EMR data. A patient’s clinical history records information about specific prescribed medications (e.g., name, dosage, duration) or specific disease diagnoses. It does not explicitly mention important connections between different medications or diagnoses, such as which other medications could be prescribed to treat an illness.",Change of representation for statistical relational learning | A comparative review of selected methods for learning from examples | Discovering hidden variables: A structure-based approach | Bayesian networks classifiers | An Introduction to Statistical Relational Learning | Learning systems of concepts with an infinite relational model | Statistical predicate invention | Extracting semantic networks from text via relational clustering | Inverse entailment and Progol | Machine invention of firstorder predicates by inverting resolution | Cluster-based concept invention for statistical relational learning | Modelling relational data using Bayesian clustered tensor factorization | Infinite hidden relational models,rejected,000
1206.6405.pdf.json,Bounded Planning in Passive POMDPs,,Optimizing fixed-size stochastic controllers for POMDPs and decentralized POMDPs | Multiterminal source coding | Reinforcement learning with perceptual aliasing: The perceptual distinctions approach | Optimal control as a graphical model inference problem | Bright illusions reduce the eye’s pupil | Point-based value iteration: An anytime algorithm for POMDPs | Bounded finite state controllers | Exponential family PCA for belief compression in POMDPs | Information theory of decisions and actions | Linearly-solvable Markov decision problems,rejected,000
1206.6424.pdf.json,Anytime Marginal Maximum a Posteriori Inference,"The maximum a posteriori (MAP) assignment problem consists in finding an assignment that maximizes the posterior probability of a given set of variables. To facilitate modeling, the model often includes latent variables that are neither to be maximized nor observed, but marginalized. It is this more general form of the problem (a.k.a. partial or marginal MAP) that we tackle in this paper. Moreover, we assume that the probability distribution is represented as a discrete graphical model, which allows for compactness. Computationally, this is a very hard problem. It is NPPP-hard even if all variables are binary, and NP-hard if either the underlying graph has bounded treewidth or there are no latent variables (Park & Darwiche, 2004). Also producing a provably good approximate solution is NP-hard, even if the treewidth of the underlying graph is bounded (Park & Darwiche, 2004). A positive result has recently been given by de Campos (2011), which derived a fully polynomial-time approximation scheme when both treewidth and number of states per variable are bounded. MAP assignment problems can be seen as a composition of two different tasks: the computation of marginal probabilities and the combinatorial search Appearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s). over assignments. The former is responsible for evaluating the quality of a candidate assignment produced by the latter. When the marginal probability inference is tractable, standard combinatorial search approaches such as branch-and-bound for exact solutions and local search for approximate results have been used (Park & Darwiche, 2003; Yuan et al., 2004). When it is hard, researchers have resorted to loopy belief propagation algorithms (Liu & Ihler, 2011; Jiang et al., 2011) and factor decomposition (Meek & Wexler, 2011). In this paper, we present a new anytime algorithm to perform marginal MAP inference in g",New complexity results for MAP in Bayesian networks | Message-passing for approximate MAP inference with latent variables | Probabilistic Graphical Models: Principles and Techniques | Variational algorithms for marginal MAP | Approximating max-sumproduct problems using multiplicative error bounds | Solving MAP exactly using systematic search | Complexity results and approximation strategies for MAP explanations,rejected,000
1206.6460.pdf.json,Output Space Search for Structured Prediction,"Structured prediction involves learning a predictor that can produce complex structured outputs given complex structured inputs. As an example, consider the problem of image scene labeling, where the structured input is an image and the structured output is a semantic labeling of the image regions. We study a new search-based approach to structured prediction. The approach involves first defining a combinatorial search space over complete structured outputs that allows for traversal of the output space. Next, given a struc- Appearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s). tured input, a state-based search strategy (e.g. best-first or greedy search), guided by a learned cost function, is used to explore the space of outputs for a specified time bound. The least cost output uncovered by the search is then returned as the prediction. The effectiveness of our approach depends critically on: 1) The identification of an effective combination of search space and search strategy over structured outputs, and 2) Our ability to learn a cost function for effectively guiding the search for high quality outputs. The main contribution of our work is to provide generic solutions to these two issues. First, we describe the limited-discrepancy search space, as a generic search space over complete outputs that can be customized to a particular problem by leveraging the power of (non-structured) classification learning algorithms. Second, we give a generic cost function learning algorithm that can be instantiated for a wide class of “ranking-based search strategies.” The key idea is to learn a cost function that allows for imitating the search behavior of the algorithm when guided by the true loss function. We also provide experimental results for our approach on a number of benchmark problems and show that even when using a relatively small amount of search, the performance is c",A comparison of ID3 and backpropagation for english text-tospeech | The generalized A | Approximate policy iteration with a policy language bias: Solving relational Markov decision processes | Search-based structured prediction | Lower bounds for reductions | Conditional random fields: Probabilistic models for segmenting and labeling sequence data | Efficient reductions for imitation learning | A reduction of imitation learning and structured prediction to no-regret online learning | A reduction from apprenticeship learning to classification | Maxmargin markov networks | Support vector machine learning for interdependent and structured output spaces | Semantic modeling of natural scenes for content-based image retrieval | Structured prediction cascades | Sidestepping intractable inference with structured ensemble cascades | Samplerank: Training factor graphs with atomic gradients,rejected,000
1206.6484.pdf.json,Apprenticeship Learning for Model Parameters of  Partially Observable Environments,"Learning from Demonstration (LfD) is a framework for learning to perform a complex task by observing demonstration (task execution) by an expert (Argall et al., 2009). LfD is particularly useful for domains where the expert knowledge of the domain is limited or difficult to represent, because demonstrations are much easier than designing a controller for the task. Apprenticeship Learning via Inverse Reinforcement Learning (Abbeel & Ng, 2004), which is an application of LfD for reinforcement learning, is an algorithm that learns the reward function of the environment un- Appearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s). der the assumption that the expert is trying to maximize the reward. The idea is that, although reinforcement learning can produce an optimal policy with respect to a given reward function, designing a reward function that captures the desired task behavior is not always obvious and requires expert knowledge of the domain. Moreover, learning the reward function from demonstration requires much less amount of demonstration compared to learning the policy directly from the demonstration, because the reinforcement learning combines the reward function with the environment model for optimizing the policy for future rewards. Inverse reinforcement learning is successfully applied to tasks where the environment is fully observable, including aerobatic helicopter flight (Abbeel et al., 2010), robot hand control (Boularias et al., 2011) and prediction of linguistic structures (Neu & Szepesvári, 2009). Inverse reinforcement learning in partially observable environments when an exact model is available has also been studied (Ziebart et al., 2010; Henry et al., 2010; Choi & Kim, 2011). However, the design bottleneck is not limited to the reward function. In many tasks, how to model the environment is not obvious as well, and requires expert knowledge of the",Apprenticeship learning via inverse reinforcement learning | A survey of robot learning from demonstration | A bayesian sampling approach to exploration in reinforcement learning | Input-output HMM’s for sequence processing | Relative entropy inverse reinforcement learning | Inverse reinforcement learning in partially observable environments | Learning to navigate through crowded environments | What makes some POMDP problems easy to approximate | The NLopt nonlinear-optimization package | Planning and acting in partially observable stochastic domains | A frame-based probabilistic framework for spoken dialog management using dialog examples | SARSOP: Efficient point-based POMDP planning by approximating optimally reachable belief spaces | Controlling Listening-oriented Dialogue using Partially Observable Markov Decision Processes | Equations of state calculations by fast computing machines | Training parsers by inverse reinforcement learning | Direct search algorithms for optimization calculations | Bayesian inverse reinforcement learning | The optimal control of partially observable Markov processes over a finite horizon | Parameter learning for POMDP spoken dialogue models | Partially observable Markov decision processes with continuous observations for dialogue management | Modeling interaction via the principle of maximum causal entropy,rejected,000
1206.6817.pdf.json,A Variational Approach for Approximating Bayesian Networks by Edge Deletion,"The complexity of algorithms for exact inference on Bayesian networks is generally exponential in the network treewidth (Jensen, Lauritzen, & Olesen, 1990; Lauritzen & Spiegelhalter, 1988; Zhang & Poole, 1996; Dechter, 1996; Darwiche, 2001). Therefore, networks with high treewidth (and no local structure, Chavira & Darwiche, 2005) can be inaccessible to these methods, necessitating the use of approximate algorithms. Iterative Belief Propagation (IBP), also known as Loopy Belief Propagation (Pearl, 1988; Murphy, Weiss, & Jordan, 1999), is one such algorithm that has been critical for enabling certain classes of applications, which have been intractable for exact algorithms (e.g., Frey & MacKay, 1997). We have proposed in previous work a new perspective on this influential algorithm, viewing it as an exact inference algorithm on a polytree approximation of the original network (Choi & Darwiche, 2006; Choi, Chan, & Darwiche, 2005). The approximate polytree results from deleting edges from the original network, where the loss of each edge is offset by introducing new parameters into the approximate network. We have shown that the iterations of IBP can be understood as searching for specific values of these parameters that satisfy intuitive conditions that we characterized formally (Choi & Darwiche, 2006). This has led to a number of implications. On the theoretical side, it provided a new, network–specific, characterization of the fixed points of IBP. On the practical side, it has led to a concrete framework for improving approximations returned by IBP by deleting fewer edges than those necessary to yield a polytree; that is, we delete enough edges to obtain a multiply connected network which is still tractable for exact inference. In this paper, we consider another criterion for determining the auxiliary parameters introduced by deleting edges, which is based on minimizing the KL– divergence between the original and approximate network. This proposal leads to a number ","The generalized distributive law and free energy minimization | On the revision of probabilistic beliefs using uncertain evidence | Compiling Bayesian networks with local structure | On Bayesian network approximation by edge deletion | An edge deletion semantics for belief propagation and its practical impact on approximation quality | Propositional and relational Bayesian networks associated with imprecise and qualitative probabilistic assessments | Recursive conditioning | Bucket elimination: A unifying framework for probabilistic inference | Iterative join-graph propagation | A revolution: Belief propagation in graphs with cycles | Sequentially fitting “inclusive” trees for inference in noisy-or networks | Structured variational inference procedures and their realizations | Factorial hidden markov models | Modelindependent mean-field theory as a local method for approximate propagation of information | Advanced Mean Field methods - Theory and Practice, chap. Tutorial on Variational Approximation Methods | Bayesian updating in recursive graphical models by local computation | An introduction to variational methods for graphical models | Reduction of computational complexity in Bayesian networks through removal of weak dependences | Optimal nonmyopic value of information in graphical models - efficient algorithms and theoretical limits | Local computations with probabilities on graphical structures and their application to expert systems | Tree-structured approximations by expectation propagation | Loopy belief propagation for approximate inference: An empirical study | Complexity results and approximation strategies for map explanations | Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference | Exploiting tractable substructures in intractable networks | Explanation in Bayesian Belief Networks | Approximating Bayesian belief networks by arc removal | Variational approximations between mean field theory and the junction tree algorithm | A generalized mean field algorithm for variational inference in exponential families | Constructing free-energy approximations and generalized belief propagation algorithms | Exploiting causal independence in bayesian network inference",rejected,000
1206.6818.pdf.json,Sensitivity Analysis for Threshold Decision Making with Dynamic Networks,"Probabilistic graphical models are often used in contexts where human decision makers have to make a decision in uncertainty. The marginal probability distributions yielded by the model then are taken as input to a decision-making model. The simplest model for choosing between alternative decisions is the threshold decision-making model, in which an output probability is compared against a number of fixed threshold probabilities which demarcate the boundaries for the various decisions [13]. In our application for ICU care, for example, a clinician has to decide whether or not to start antibiotics treatment for a patient who is suspected of having ventilator-associated pneumonia (VAP), based upon the probability of VAP being present. Probabilistic graphical models are typically learned from data or constructed with the help of domain experts. Due to incompleteness of data and partial knowledge of the domain under study, the numerical parameters of the model tend to be inaccurate to at least some degree. The inaccuracies may affect the output probabilities of the model as well as the decisions based upon these probabilities. The effects of inaccuracies in the parameters of a network on its output probabilities can be studied by subjecting the network to a sensitivity analysis [2, 7, 8, 9]. In view of a decisionmaking model, however, robustness of the output of a probabilistic graphical model pertains not just to the computed output probabilities but also to the decisions based upon these probabilities. In this paper, we study this type of robustness for dynamic Bayesian networks (DBNs) in view of the threshold decision-making model. Previous work on sensitivity analysis of Bayesian networks (BNs) in general showed that any posterior probability for an output variable is a quotient of two linear functions in any of the network’s parameters [8]; the posterior probability can further be expressed as a sum of such functions in all parameters from a single conditional prob","Inference and Learning in Complex Stochastic Processes | When do numbers really matter | Sensitivity analysis in Bayesian networks: From single to multiple parameters | Sensitivity properties of Markovian models | A dynamic Bayesian network for diagnosing ventilator-associated pneumonia in ICU patients | Sensitivity analysis of Markovian models | Properties of sensitivity analysis of Bayesian belief networks | Making sensitivity analysis computationally efficient | Sensitivity analysis for probability assessments in Bayesian networks | Dynamic Bayesian Networks: Representation, Inference and Learning | Solving a polynomial equation: Some history and recent progress | The threshold approach to clinical decision making | A tutorial on hidden Markov models and selected applications in speech recognition | Sensitivity analysis for threshold decision making with Bayesian belief networks. AI*IA 99: Advances in Artificial Intelligence, Lecture | Analysing sensitivity data from probabilistic networks",rejected,000
1206.6819.pdf.json,On the Robustness of Most Probable Explanations,"A Most Probable Explanation (MPE) in a Bayesian network is a complete variable instantiation which has the highest probability given current evidence [1]. Given an MPE solution for some piece of evidence, we concern ourselves in this paper with the following question: What is the amount of change one can apply to some network parameter without changing this current MPE solution? Our goal is then to deduce robustness conditions for MPE under single parameter changes. This problem falls into the realm of sensitivity analysis. Here, we treat the Bayesian network as a system which accepts network parameters as inputs, and produces the MPE as an output. Our goal is then to characterize conditions under which the output is guaranteed to be the same (or different) given a change in some input value. This question is very useful in a number of application areas, including what-if analysis, in addition to the ∗This work was completed while Hei Chan was at UCLA. design and debugging of Bayesian networks. For an example, consider Figure 1 which depicts a Bayesian network for diagnosing potential problems in a car. Suppose now that we have the following evidence: the dashboard test and the lights test came out positive, while the engine test came out negative. When we compute the MPE in this case, we get a scenario in which all car components are working normally. This seems to be counterintuitive as we expect the most likely scenario to indicate at least that the engine is not working. The methods developed in this paper can be used to debug this scenario. In particular, we will be able to identify the amount of change in each network parameter which is necessary to produce a different MPE solution. We will revisit this example later in the paper and discuss the specific recommendations computed by our proposed algorithm. Previous results on sensitivity analysis have focused mostly on the robustness of probability values, such as the probability of evidence, under single or mu",Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference | When do numbers really matter | Sensitivity analysis in Bayesian networks: From single to multiple parameters | Sensitivity analysis in discrete Bayesian networks | Using sensitivity analysis for efficient quantification of a belief network | Making sensitivity analysis computationally efficient | Sensitivity analysis for probability assessments in Bayesian networks | The sensitivity of belief networks to imprecise probabilities: An experimental investigation | Analysing sensitivity data from probabilistic networks | A differential approach to inference in Bayesian networks | A differential semantics for jointree algorithms | Compiling Bayesian networks with local structure | Compiling relational Bayesian networks for exact inference,rejected,000
1206.6820.pdf.json,Optimal Coordinated Planning Amongst Self-Interested Agents with Private State,"Consider a multi-agent system in a dynamic and uncertain environment in which there is a situation of strategic interdependence. Specifically, suppose that individual agents are self-interested in that each cares only about maximizing its own payoff, and that agent behaviors are interdependent in that some actions are incompatible with others (imagine, e.g., competition for a shared resource that is required for any agent to act). In this paper we address the social planning problem for such settings. Suppose that a central planner has knowledge of each agent’s local world model and initial state, and has been given the authority to make decisions on the agents’ behalf. To do optimal planning a significant distributed problem remains, as the current state of each agent is private to that agent, and the planner must somehow gain access to the true state information to execute a system-optimal plan. For example, consider the problem of operating a taxi cab dispatch. Each cab driver is an agent, whose state can be considered the location of his taxi at any given point in time. Drivers receive “reward” (payment) when they have a fare, the magnitude of which is wellknown given the route request made by a client to the dispatcher. The dispatcher’s task is to do optimal planning: assign cabs to clients in a way that maximizes total profit. However, cab drivers may have incentive to misreport their location in order to be allocated more fares. Here, as in a vast array of other multi-agent problems, a coordination mechanism is required to disarm individuals’ self-interest in order to reach socially-optimal outcomes. In our solution, the planner solicits claims from agents about their current state each period, proposes and enforces the optimal joint action based on agent reports, and then collects specific payments in order to bring truthful reporting (which enables systemoptimal planning) into a Markov perfect equilibrium (MPE) of the induced stochastic game. The MPE proper",159(1–2):24–47 | Pricing WiFi at Starbucks– Issues in online mechanism design | Games and Economic Behavior | Game Theory | Dynamic mechanism design for online commerce | A dynamic allocation index for the sequential design of experiments | Multi-armed Bandit Allocation Indices | Econometrica | on Electronic Commerce | Journal of Economic Theory | In The Encyclopedia of Life Support Systems | Econometrica | The multi-armed bandit problem: decomposition and computation | 2nd ACM Conf | Cognitive Systems Research | Markov perfect equilibrium: I | 17th Annual Conf,rejected,000
1206.6822.pdf.json,Cutset Sampling with Likelihood Weighting,"Stochastic sampling is a popular approach for estimating answers to Bayesian queries when exact inference is intractable. Based on the generated samples, we can obtain estimates that converge to the exact values as the number of samples increases. However, convergence may be slow in large networks due to increase in sampling variance. This is the problem we address in this paper. Based on Rao-Blackwell theorem, we can reduce sampling variance and speed up convergence by sampling only a subset of the variables (a cutset). However, the efficiency of sampling from lower-dimensional spaces is hindered by the overhead of computing the sampling distributions. The latter is equivalent to performing exact inference which is exponential in the induced width of the network whose instantiated variables (evidence and sampled) are removed. We defined previously an efficient parametrized Gibbs cutset sampling scheme, called w-cutset sampling [2, 3], where the complexity of generating a single sample is bounded exponentially by w. In this paper, we extend the cutset sampling principle to likelihood weighting (LW) [11, 21], which is a form of importance sampling [21], focusing on sampling from a loop-cutset. The resulting scheme, which we call LWLC, computes a sample over a loop-cutset C in O((|C| + |E|) · N), where E is evidence and N is the size of the input network. While we present our scheme for LW, it is applicable to other importance sampling schemes. While both cutset schemes, one based on Gibbs sampling and one based on likelihood weighting, exploit the network structure to manage the complexity of exact inference, they compute different sampling distributions. Gibbs sampler draws a new value of variable Xi from distribution P (Xi|x\xi). Likelihood weighting samples a new value from P (Xi|x1, ..., xi−1). Furthermore, while both schemes benefit from reducing the size of the sampling space, it is hard to predict which of the two schemes is superior. The convergence speed of ","Blackwellised particle filtering via data augmentation | Cycle-cutset sampling for Bayesian networks | Empirical study of wcutset sampling for Bayesian networks | Rao-Blackwellised likelihood weighting | AIS-BN: An adaptive importance sampling algorithm for evidenctial reasoning in large baysian networks | Bucket elimination: A unifying framework for reasoning | Constraint Processing | Rao-Blackwellised particle filtering for dynamic Bayesian networks | Particle filters for state estimation of jump markov linear systems | Monte Carlo: concepts, algorithms, and applications | Weighing and integrating evidence for stochastic simulation in Bayesian networks | Backward simulation in Bayesian networks. In Uncertainty in AI, pages 227–234 | Towards normative expert systems: Part i. the pathfinder project | Blocking Gibbs sampling for linkage analysis in large pedigrees with many loops. Research Report R-96-2048 | Information Theory and Statistics | Sequential importance sampling for nonparametric bayes models: The next generation | Loopy belief propagation for approximate inference: An empirical study | Probabilistic Reasoning in Intelligent Systems | Knowledge engineering for large belief networks | Empirical evaluation of approximation algorithms for probabilistic decoding | Simulation approaches to general probabilistic inference on belief networks | An importance sampling algorithm based on evidence prepropagation",rejected,000
1206.6823.pdf.json,An Efficient Triplet-based Algorithm for Evidential Reasoning,"In this paper, we propose a novel evidence structure − a triplet − which can be used to represent multiple pieces of evidence to improve effectiveness and efficiency in computing Dempster’s rule of combination and in making decisions. In particular, it is designed to represent the outputs of ensemble classifiers and it is capable of incorporating the prioritized outputs − evidence − into the decision making process, resulting in an improvement of classification accuracy. We have developed a formalism for the triplet structure, and we show that the mass functions defined on this formalism satisfy the properties embedded in the Dempster-Shafer theory of evidence (Shafer 1976). We also developed a range of formulae for realizing linear time computations of combining various triplet mass functions, which are applicable to the other evidential functions of belief function, commonality function, plausibility function, and doubt function. The evidential functions are defined on sets and their enumeration. Broadly speaking, the time complexity of computing evidential functions is exponential. Essentially, it is not feasible to translate the evidence theory into an efficient direct implementation (Barnett 1981). Therefore the applications of the DempsterShafer theory of evidence to real-world problems have been until recently limited (Denoeux 2000), in particular, to text categorization. Considerable efforts have been devoted to developing efficient algorithms for computing evidential functions (Barnett 1981; Shafer, et al. 1987; Kennes, et al. 1990; Moral, et al. 1994; Guan, et al. 1995; Shafer, et al. 2002). However, a particular structure embedded in evidence plays a dominant role in developing practical and linear algorithms for computing evidential functions and for realworld applications (Xu, et al. 1992; Denoeux 2000). For example, Barnett (1981) proposed a method for partitioning an evidence space in several independent ways and clustering pieces of evidence into the","A Mathematical Theory of Evidence | Computational methods for a mathematical theory of evidence | A neural network classifier based on Dempster-Shafer theory | Implementing Dempsters rule for Hierarchical Evidence | Computational aspects of the Moebius Transform | A Monte Carlo Algorithm for Calculation of Dempster-Shafer Belief | Computational methods for automated reasoning in knowledge based systems | Efficient algorithms for automated reasoning in expert systems | Special Issue on DempsterShafer Theory, Methodology, and Applications | Several Methods for Combining Multiple Classifiers and Their Applications in Handwritten Character Recognition | Combining Multiple Classifiers For Text Categorization Using The Dempster-Shafer Theory Of Evidence, PhD thesis, University of Ulster, UK",rejected,000
1206.6827.pdf.json,Linear Algebra Approach to Separable Bayesian Networks,"Separable Bayesian Networks, or the Influence Model, are dynamic Bayesian Networks in which the conditional probability distribution can be separated into a function of only the marginal distribution of a node’s neighbors, instead of the joint distributions. In terms of modeling, separable networks has rendered possible siginificant reduction in complexity, as the state space is only linear in the number of variables on the network, in contrast to a typical state space which is exponential. We describe the connection between an arbitrary Conditional Probability Table (CPT) and separable systems using linear algebra. We give an alternate proof to [Pfeffer00] on the equivalence of sufficiency and separability. We present a computational method for testing whether a given CPT is separable.","Influence Model: A Tractable Representations for the Dynamics of Networked Markov Chains, Ph.D | The Influence Model, IEEE Control Systems | Towards Measuring Human Interactions in Conversational Settings | Sufficiency, Separability, and Temporal Probabilistic Models. Uncertainty in Artificial Intelligence",rejected,000
1206.6831.pdf.json,Pearl’s Calculus of Intervention Is Complete,"This paper focuses on graphical criteria used to infer the strength of cause-and-effect relationships from a causal Bayesian network [Pearl, 1995, Pearl, 2000], which is an acyclic directed graph representing nonexperimental data and causal relationships. In the 1990s, some graphical conditions were given to show whether the causal effect, that is, the joint response of any set S of variables to interventions on a set T of action variables, denoted as PT (S)1, is identifiable or not. Those results are summarized in [Pearl, 2000]. For example, “back-door” and “front-door” criteria and do-calculus [Pearl, 1995]; graphical criteria to identify PT (S) when T is a singleton [Galles and Pearl, 1995]; special graphical conditions under which it is possible 1The notations P (s|do(t)) and P (s|t̂) are used in [Pearl, 2000], and the notation Pt(s) is used in [Tian and Pearl, 2002b, Tian and Pearl, 2003]. to identify PT (S) [Pearl and Robins, 1995]. Some further study can be also found in [Robins, 1997] and [Kuroki and Miyakawa, 1999]. In all these graphical criteria, Pearl’s three do-calculus (inference) rules are in the core position. All the other graphical rules can be obtained from them. Pearl conjectures that they are sufficient for the identification problem, but the conjecture has remained opened until now. In the current decade, Tian and Pearl published a series of papers related to the identification problem [Tian and Pearl, 2002a, Tian and Pearl, 2002b, Tian and Pearl, 2003]. Their new methods combined the graphical character of causal graph and the algebraic definition of causal effect. They used both algebraic and graphical methods to identify causal effects. Based on their work, Huang and Valtorta proved that Tian and Pearl’s identify algorithm for semi-Markovian graphs is complete [Huang and Valtorta, 2006a]. Here, semiMarkovian graphs are defined as causal graphs in which each unobservable variable is a root and has exactly two observable children; semi-Markovi","Testing identifiability of causal effects | On the completeness of an identifiability algorithm for semi-Markovian models | A study of identifiability in causal Bayesian network | Identifiability criteria for causal effects | Probabilistic evaluation of sequential plans from causal models with hidden variables | Identification of joint interventional distributions in recursive semi-Markovian causal models. Technical report, Cognitive Systems Laboratory, University of California at Los Angeles | A general identification condition for causal effects | On the testable implications of causal models with hidden variables | On the identification of causal effects, Technical report 290-L. Technical report, Cognitive Systems Laboratory, University of California at Los Angeles. Extended version available at http://www.cs.iastate.edu/ jtian/r290-L.pdf",rejected,000
1206.6834.pdf.json,A new axiomatization for likelihood gambles,,"The Likelihood Principle, 2 ed | Great expectations. Part I: Tailoring generalized expected utility to capture different postulates | Great expectations. Part II: generalized expected utility as a universal decision rule | Risk, ambiguity and the Savage’s axioms | Statistical decisions using likelihood information without prior probabilities | Decision making on the sole basis of statistical likelihood | Maximin expected utility with a non-unique prior | An axiomatic approach to measurable utility | An introduction to Bernoullian utility theory I: Utility functions | A smooth model of decision making under ambiguity | Risk, uncertainty and profit | Subjective probability and expected utility without additivity | A Mathematical Theory of Evidence | A catalog of noninformative priors",rejected,000
1206.6836.pdf.json,Methods for Computing State Similarity in Markov Decision Processes,"Markov decision processes (MDPs) are the model of choice for decision making under uncertainty (Boutilier et al., 1999), and provide a standard formalism for describing multi-stage decision making in probabilistic environments. The objective of the decision making is to maximize a cumulative measure of long-term performance, called the return. Dynamic programming algorithms, e.g., value iteration or policy iteration (Puterman, 1994), allow computing the optimal expected return for any state, as well as the way of behaving (policy) that generates this return. However, in many practical situations, the state space of an MDP is too large for the standard algorithms to be applied. One popular technique for overcoming this problem is state aggregation: states are grouped together into blocks, or partitions, and a new MDP is defined over these. The hope is that this can be done in such a manner as to construct an “essentially equiv- alent” MDP with drastically reduced state space, thereby allowing the use of classical solution methods, while at the same time providing a guarantee that solutions of the reduced MDP can be extended to the original model. It has been well argued that the notion of “essentially equivalent” in probabilistic systems is perhaps best captured formally by bisimulation (Milner, 1980; Park, 1981; Larsen & Skou, 1991). In the context of MDPs, bisimulation can roughly be described as the largest equivalence relation on the state space of an MDP that relates two states precisely when for every action, they achieve the same immediate reward and have the same probability of transitioning to classes of equivalent states. This means that bisimilar states lead to essentially the same long-term behavior. The bisimulation equivalence classes can even be computed iteratively in polynomial time (Givan et al., 2003). However, it has also been well established that using exact equivalences in probabilistic systems is problematic. A notion of equivalence is two-val",Decisiontheoretic planning: Structural assumptions and computational leverage | Exploiting structure in policy | Metrics for labeled Markov systems | Metrics for finite Markov decision processes Proceedings of the 20th conference on Uncertainty in artificial intelligence | Metrics for Markov decision processes with infinite state spaces Proceedings of the 21st conference on Uncertainty in artificial intelligence | A Computational Study of Cost Reoptimization for Min Cost Flow Problems | Equivalence notions and model minimization in markov decision processes | Bisimulation through probabilistic testing | A calculus of communicating systems | Algorithms for the assignment and transportation problems | A faster strongly polynomial minimum cost flow algorithm | Concurrency and automata on infinite sequences | Markov decision processes: Discrete stochastic dynamic programming | Towards quantitative verification of probabilistic transition systems | An algorithm for quantitative verification of probabilistic transition systems | Topics in Mass Transportation. [http: //www.math.toronto.edu/hmaroofi,rejected,000
1206.6837.pdf.json,Residual Belief Propagation: Informed Scheduling for Asynchronous Message Passing,"Probabilistic graphical models for representing and reasoning about complex distributions have gained wide spread popularity, and are playing a role in a broad range of applications. As these models are applied to a greater variety of real-world problems, practitioners are encountering more and more networks for which inference poses a significant challenge. Consequently, the past decade has seen an explosion in the development of new methods for approximate inference in graphical models. One of the most popular class of methods used are message passing algorithms, which pass messages over the graph (or a related cluster graph) until convergence. These methods, which originated with the simple loopy belief propagation (BP) algorithm of Pearl (1988), have been the focus of much research; multiple extensions have been proposed, and have been applied successfully to a variety of domains (e.g., (McEliece et al., 1998; Freeman and Pasztor, 2000; Taskar et al., 2004)). Nevertheless, the application of message passing algorithms to complex, real-world networks remains problematic: BP and its extensions simply do not converge for challenging models and convergent alternatives (e.g., (Yuille, 2001; Welling and Teh, 2001)) have not been widely adopted in practice (see Section 6). Moreover, in large networks, even if convergence is possible, this may be at a significant computational cost. In practice, researchers often abandon a non-convergent model in favor of a simpler one, or simply stop the algorithm at an arbitrary point. In this paper, we propose a very simple yet surprisingly effective method for improving the convergence properties of any message passing algorithm. Our method derives from the well-known empirical observation that asynchronous message passing algorithms, where messages are updated sequentially, generally converge faster and more often than the synchronous variant, where all messages are updated in parallel. Yet, many practitioners continue to use the s",Distributed asynchronous computation of fixed points | Parallel and Distributed Computation: Numerical Methods | Chaotic relaxation | Learning low-level vision | Loopy belief propagation: Convergence and effects of message errors | Towards an integrated protein-protein interaction network | An introduction to variational approximations methods for graphical models | Parallel versus sequential updating for belief propagation decoding | Turbo decoding as an instance of Pearl’s belief propagation algorithm | Expectation propagation for approximate Bayesian inference | Sufficient conditions for convergence of loopy belief propagation | Probabilistic Reasoning in Intelligent Systems | On rates of convergence of jacobi and gaussseidel methods for m-functions | Link prediction in relational data | The information bottleneck method | Comparison of Jacobi and Gauss-Seidel parallel iterations | Tree-based reparameterization for approximate estimation on loopy graphs | Reduced latency iterative decoding of LDPC codes | On the optimality of solutions of the max-product belief-propagation algorithm in arbitrary graphs | Belief optimization for binary networks : A stable alternative to loopy belief propagation | Approximate inference and protein folding | Generalized belief propagation | Cccp algorithms to minimize the Bethe and Kikuchi free energies: Convergent alternatives to belief propagation,rejected,000
1206.6841.pdf.json,Asymmetric Separation for Local Independence Graphs,"Classical graphical models and Bayesian networks represent (conditional) independence between random variables. They can be adapted to variables observed in discrete or discretized time, like e.g. time series or dynamic Bayesian networks. This does not, however, capture the intuitive notion of dynamic dependence between processes, which is asymmetric, and we therefore propose an alternative. Put informally, we are interested in the following kind of dynamic (conditional) independencies among stochastic processes X(t), Y (t) and Z(t): present of X⊥⊥past of Y | past of (X, Z), which will be denoted by Y →/ X|Z, or more formally X(t)⊥⊥FYt− | FX,Zt− , where Ft− is the history of a process. Such independence underlies the notion of Granger non–causality for time series (Granger, 1969), which has been used as the basis for a graphical representation by Eichler (2002). It also underlies the continuous–time notion of local independence given by Schweder (1970) for Markov processes, and its bivariate version for general continuous–time processes by Aalen (1987) with a multivariate version in Didelez (2000, pp.65). A special case of Schweder’s concept are the dependencies represented in the continuous time Bayesian networks developed by Nodelman et al. (2002) for homogenous Markov processes. Cyclic graphs have also been proposed to represent non–recursive structural equation models or feedback processes (Sprites, 1995; Pearl and Dechter, 1996), but with the above notion of dependence between past and present we explicitly consider processes instead of cross sectional measurements of variables in equilibrium. Consider the following example illustrating the idea of local dependence and its graphical representation. In some countries programs exist to assist the elderly, e.g. through regular visits by nurses. Assume that these visits reduce the frequency of hospitalizations but do not in any other way affect future survival (this could be the null hypothesis). Assume further tha",Dynamic modelling and causality | Statistical models based on counting processes | Graphoid properties of epistemic irrelevance and independence | Conditional independence in statistical theory | Conditional independence for statistical operations | Separoids: A mathematical framework for conditional independence and irrele | Graphical models for event history data based on local independence | Graphical models for marked point processes based on local independence | Graphical models for composable finite Markov processes | Granger-causality and path diagrams for multivariate time series | Axioms of causal relevance | Investigating causal relations by econometric models and cross–spectral | Graphical models | Continuous time Bayesian networks | Learning continuous time Bayesian networks | Probabilistic reasoning in intelligent systems | Identifying independencies in causal graphs with feedback | Graphoids: A graph– based logic for reasoning about relevancy relations | Composable Markov processes | Directed cyclic graphical representations of feedback models | Causal networks: Semantics and expressiveness,rejected,000
1206.6844.pdf.json,From influence diagrams to multi-operator cluster DAGs,"Since the first algorithms based on decision trees or arc-reversal operations [Shachter, 1986], several exact methods have been proposed to solve influence diagrams using local computations, such as the ones based on the Shenoy-Shafer, the HUGIN, or the Lazy Propagation architectures [Shenoy, 1992; Jensen et al., 1994; Madsen and Jensen, 1999]. These methods have successfully adapted classical Variable Elimination (VE) techniques (which are basically designed to compute one type of marginalization on a combination of local functions with only one type of combination operator), in order to handle the multiple types of information (probabilities and utilities), the multiple types of marginalizations (sum and max), and the multiple types of combination (× for probabilities, + for utilities) involved in an influence diagram. The key mechanism used for such an extension consists in using elements known as potentials [Ndilikilikesha, 1994]. In this paper, we define a new architecture, called the Multi-operator Cluster DAG (MCDAG) architecture, which does not use potentials, but still relies on VE. Compared to existing schemes, MCDAGs actively exploit the composite nature of influence diagrams. We first present the potential-based approach and motivate the need for a new architecture (Section 2). Then, MCDAGs are introduced (Section 3) and a VE algorithm is defined (Section 4). Finally, this work is compared with existing approaches (Section 5) and extended to other frameworks (Section 6). All proofs are available in [Pralet et al., 2006b].",Topological Parameters for Time-Space Tradeoff | Possibility Theory as a Basis for Qualitative Decision Theory | Influence Diagrams | From Influence Diagrams to Junction Trees | Representing and Solving Decision Problems with Limited Information | Lazy Evaluation of Symmetric Bayesian Decision Problems | Potential Influence Diagrams | Complexity Results and Approximation Strategies for MAP Explanations | Decision with Uncertainties | From Influence Diagrams to MCDAGs: Extended version | Evaluating Influence Diagrams | Valuation-based Systems for Discrete Optimization | Valuation-based Systems for Bayesian Decision Analysis,rejected,000
1206.6849.pdf.json,General-Purpose MCMC Inference over Relational Structures,"Many probabilistic reasoning problems involve reconstructing the set of (possibly related) real-world objects that underlie some observed data: for instance, the publications and authors that are mentioned in a set of bibliographic citations, or the aircraft that underlie a set of observed radar blips. Because the number of possible ways to map a set of observations to underlying objects is huge, these problems are extremely challenging for standard proba- bilistic inference algorithms. Specialized algorithms have been developed in the fields of record linkage [Fellegi and Sunter, 1969] and data association [Bar-Shalom and Fortmann, 1988] that yield approximate solutions for particular classes of models. Recently, Pasula et al. [2003] and Oh et al. [2004] have achieved state-of-the-art results on these problems using Markov chain Monte Carlo (MCMC) methods. Given a probability distribution p on an outcome space Ω, an MCMC algorithm approximates the probability of a query event Q given an evidence event E by generating a sequence of samples s1, s2, . . . , sN from a Markov chain over Ω. This Markov chain is chosen so that it only visits outcomes consistent with E, and its stationary distribution is proportional to p(s). The desired probability p(Q|E) is then approximated as the fraction of s1, . . . , sN that are in Q. If the Markov chain is ergodic, then this approximation converges to the correct posterior probability as N →∞. Pasula et al. [2003] and Oh et al. [2004] use the MetropolisHastings (M-H) algorithm [Metropolis et al., 1953; Hastings, 1970] to construct a Markov chain whose stationary distribution is proportional to p(s). In the M-H algorithm, when the current state of the chain is sn, a new state is sampled from a proposal distribution q(s′|sn). The acceptance probability for this proposed move is: α(sn, s ′) , max ( 1, p(s′)q(sn|s ′) p(sn)q(s′|sn) ) (1) With probability α(sn, s′), the move is accepted and sn+1 is set to s′; otherwise, sn+1 = sn. The pr",Markov chain Monte Carlo using tree-based priors on model structure | Exploiting informative priors for Bayesian classification and regression trees | Tracking and Data Association | A theory for record linkage | Iterative and non-iterative sampling algorithms | A language and program for complex Bayesian modelling | Monte Carlo sampling methods using Markov chains and their applications | Complex probabilistic modeling with recursive relational Bayesian networks | Importance sampling on relational Bayesian networks | A split-merge Markov chain Monte Carlo procedure for the Dirichlet process mixture model | Of starships and Klingons: First-order Bayesian logic for the 23rd century | Autonomous citation matching | Generic reversible jump MCMC using graphical models | A note on the graph isomorphism counting problem | Efficient clustering of high-dimensional data sets with application to reference matching | Equations of state calculations by fast computing machines | BLOG: Probabilistic models with unknown objects | Approximate inference for infinite contingent Bayesian networks | Variable-structure systems from graphs and grammars | Markov chain Monte Carlo data association for general multiple-target tracking problems | Identity uncertainty and citation matching | IBAL: A probabilistic rational programming language | Markov logic networks | An integrated,rejected,000
1206.6850.pdf.json,Visualization of Collaborative Data,"Collaborative data, which are composed of correlated users and items, are abundant: movie recommendations, music rankings, and book reviews, for example. Most of the work on such data has been in the area of collaborative filtering: making predictions or recommendations based on prior user ratings. However, no previous algorithms have approached the problem of visualizing collaborative information. In this work, we initiate this problem and propose an approach. Many visualization problems are “soft” in nature and it is difficult to compare alternative methods. For this task, we introduce a simple evaluation criterion which is natural and allows for numeric comparisons of possible visualizations. Using all the ratings, the visualization problem is to extract the intrinsic similarities or dissimilarities between all the users and items involved, and represent them graphically. This has a wide range of applications, for example guided on-line shopping. Traditional stores allow for easy browsing by physically walking up and down the aisles and visually inspecting the store’s contents. Such browsing is not easy on-line. Amazon.com, for instance, has thousands of items in many categories. While collaborative filtering allows an on-line seller to recommend a list of objects that the buyer might also like, it does not supply a good way of browsing an on-line collection in a more free-form fashion. We propose building an embedded graph of all the items using the collaborative rating data, and allowing the shopper to zoom in on a portion of the graph and scroll around as he or she searches for items of interest. If constructed well, nearby items will also be of interest to the shopper and local directions in the space will have “meaning” to the user. Spatial layouts have been shown in the past to increase interest in exploration and to aid in finding information (Chennawasin et al., 1999). We assume a D-dimensional Euclidean space, which we call the embedded space (for most c","Empirical analysis of predictive algorithms for collaborative filtering | An emperical study of memory and information retrieval with a spatial user interface | Maximum likelihood from incomplete data via the EM algorithm | Euclidean embedding of co-occurrence data | Eigentaste: A constant time collaborative filtering algorithm | Rank correlation methods | Optimization by simulated annealing | Equation of state calculations by fast computing machines | Collaborative filtering by personality diagnosis: A hybrid memory- and model-based approach | Think globally, fit locally: Unsupervised learning of low dimensional manifolds",rejected,000
1206.6854.pdf.json,Belief Update in CLG Bayesian Networks With Lazy Propagation,"The framework of BNs is an efficient knowledge representation for reasoning under uncertainty [12, 3, 4]. Traditionally, the variables of a BN are assumed to be either discrete or continuous. In recent years BNs with a mixture of continuous and discrete variables have received an increasing level of attention. Here exact belief update in CLG BNs is considered. Extending the class of BNs containing discrete (or continuous) variables only to the class of BNs containing both discrete and continuous variables is not simple. The work by Pearl [12] on BNs containing continuous variables imposed three constraints on the variables in the network. The interaction between variables is linear, the sources of uncertainty are Gaussian distributed and uncorrelated, and the causal network is singly connected. Later, Shachter & Kenley [14] described how to solve Gaussian influence diagrams under similar constraints, but allowing multiple connected causal networks. Lauritzen [5] presents a scheme for modeling and exact belief update in CLG BNs. This scheme is more general than the scheme proposed by Pearl. The conditional distribution of the continuous variables given the discrete variables is assumed to be multivariate Gaussian. Only continuous variables which are linear additively Gaussian distributed are considered. The asymmetry between continuous and discrete variables induces a number of constraints on the model specification and the inference structure. Using a similar approach Chang & Fung [1] extend the SPI algorithm [13] to solve arbitrary queries against CLG BNs. The Lauritzen [5] architecture is known to suffer from problems causing numerical instability. For this reason the architecture was later revised by Lauritzen & Jensen [6] in order to improve the numerical stability of belief update. Recently, Cowell [2] introduced an alternative architecture for belief update based on message passing in an elimination tree using the arcreversal operation of Shachter & Kenley [14",Symbolic probabilistic inference with both discrete and continuous  variables | Local Propagation In Conditional Gaussian Bayesian Networks | Probabilistic Networks and Expert Systems | Bayesian Networks and Decision Graphs | Propagation of probabilities | Stable Local Computation with Mixed Gaussian Distributions | Local computations with probabilities on graphical structures and their application to expert systems | Graphical models for associations between variables | All Good Things Come to Those Who Are Lazy - Efficient Inference in Bayesian Networks and Influence Diagrams Based on Lazy Evaluation | Variations Over the Message Computation Algorithm of Lazy Propagation | Lazy propagation: A junction tree inference algorithm based on lazy evaluation | Probabilistic Reasoning in Intelligence Systems | B | Gaussian influence diagrams,rejected,000
1206.6856.pdf.json,Reasoning about Uncertainty in Metric Spaces,"For formal representation of uncertainty with probabilistic or belief theoretic measures, there exists a wide spectrum of models with complete logical systems (eg. see Halpern 2003, Nilsson 1986, Bacchus 1990, Gerla 1994). There also exists a wide variety of formal systems on spatial reasoning (eg. see Gabelaia et al. 2005, Asher & Vieu 1995, Lemon & Pratt 1998) and especially on reasoning about metric spaces (eg. see Kutz et al. 2003, Wolter & Zakharyaschev 2005). But it is hard to find a formal system when probabilistic uncertainty is present on metric spaces. In probabilistic or statistical analysis, it is usually assumed that values of random variables are real numbers. Since most of statistical inference is related to reasoning about expectation and variance, restricting the range of random variables to the spaces where those values are well defined is considered as an acceptable sacrifice. A formal reasoning system on expectations with respect to probability measures and other belief theoretic measures can be found in (Halpern & Pucella 2002). Even though expectations of an event cannot be defined on arbitrary metric spaces, the expectation of distances with respect to a fixed set is well defined in any metric space. For example, an expectation of a random location on a sphere cannot be defined, but an expected distance of a random location from the south hemisphere is a well defined notion. The expected distance is often interpreted as a loss function in statistical decision theory (Berger 1985). Loss(a) = EP (d(X, a)). In this case, the distance function d(x, a) with respected to a fixed point a is used to calculate the cost for predicting x when a is a true state. A complimentary concept of a cost function in decision theory is a utility function. The expected utility function has been an important topic in economics for a long time (Von Neumann & Morgenstern 1944; Savage 1954; Schmeidler 1989). We can also find more generalized expected utility functions d",Toward a geometry of common sense: A semantics and a complete axiomatization of mereotopology | Representing and reasoning with probabilistic knowledge: a logical approach to probabilities | Statistical decision theory and Bayesian analysis | Great expectations | Great expectations | Reasoning about knowledge and probability | A logic for reasoning about probabilities | Combining spatial and temporal logics: Expressiveness vs | A theory of higher order probabilities | Inferences in probability logic | Reasoning about expectation | Reasoning about uncertainty | Logics of metric spaces | Probabilistic reasoning on metric spaces | On the incompleteness of modal logics of space: advancing complete modal logics of place | Probabilistic logic | The foundations of statistics | Subjective-probability and expected utility without additivity | A mathematical theory of evidence | Theory of games and economic behavior | A logic for metric and topology | Entropy measures under similarity relations | Probability measures of fuzzy events,rejected,000
1206.6859.pdf.json,Propagation of Delays in the National Airspace System,"A great deal of research attention has been devoted to the study of flight delay. Traditional linear or nonlinear regression methods have been applied to explain the influence of causal factors on delays. Micro- and macrolevel simulation tools have been applied to simulate delays at different levels of detail. Over the years, research methods have shifted from independently investigating particular components of delay, to simultaneously examining multiple components of delay within a single analysis. Examining different components of delay together is important because the components interact in complex ways under the effects of airport conditions, weather conditions, and system effects from NAS. However, “our ability to predict delays because of weather has not improved.” And “system predictability in convective weather remains an unresolved puzzle.” [1] Examining just the marginal distributions does not reveal the effects of weather or airport conditions (e.g., congestion), nor does it reveal the relationships of the components in the figure to each other. The Bayesian network model presented in this paper goes beyond the marginal distribution, providing a methodology for quantitatively analyzing the major causal factors affecting each delay component and the relationships among the delay components. The Bayesian network model not only provides predictions of future delays that incorporate the interrelationships among causal factors, but also provides a means of assessing the effects of causal factors and inferring the factors that contributed most to the final arrival delay. We choose ORD as the departing airport because about 70% of departures from ORD are connecting flights. Both ORD and ATL are listed among the airports with the most serious delay problems. Since delays in different flight phases tend to have different causes, one BN model segment was developed for each phase of flights from ORD to ATL. In each phase, candidate causal factors were identified b","A.(1999).Observations of Departure Processes at Logan Airport to Support the Development of Departure Planning Tools, Air Traffic control Quarterly Journal | Queuing Model for Taxi-Out Time Estimation | Spectral Analysis of Airport Capacity and Delay, 5 USA/Europe ATM R&D Seminar | An Econometric Analysis of U.S. Airline Flight Delays with Time-of-Day Effects | Bayesian Data Analysis",rejected,000
1206.6867.pdf.json,Axiomatic Foundations for a Class of Generalized Expected Utility: Algebraic Expected Utility,"Axiomatic justification of a decision model is essential as it underlines the properties of the decision model and reveals what decision behavior it can or cannot describe. The seminal work presented in von Neumann and Morgenstern (1944) made expected utility (EU) the first axiomatized decision model. This axiomatization was then reformulated and simplified (Fishburn (1970); Machina (1988)). In von Neumann-Morgenstern (vNM) like axiomatizations, (objective) probabilities are assumed to be given. This assumption is relaxed in the axiomatization proposed by Savage (1954). In such a setting, (subjective) probabilities are constructed from the preferences of the decision maker if and only if some required axioms are satisfied. However the assumption that the uncertainty is represented by objective probability (vNM setting) or the requirement of axioms leading to the construction of subjective probability (Savagean setting) can be debatable in some situations, especially those where data are imprecise and/or scarce (Ellsberg (1961)). Moreover, even when the decision problem imposes probability as the natural uncertainty measure, it can be difficult to assess. To tackle these difficulties, other models for uncertainty have been proposed as generalizations of probability: belief functions (Shafer (1976)), κ-rankings (Spohn (1988); Goldszmidt and Pearl (1992)), possibility theory (Dubois and Prade (1990)), symbolic probability (Darwiche and Ginsberg (1992)) to name a few. They are all instances of plausibility measures (not to be confused with plausibility functions) introduced by Friedman and Halpern (1995). For all these uncertainty representations, decision models have been proposed (Jaffray and Wakker (1993); Giang and Shenoy (2000); Dubois and Prade (1995),...). Some of these already proposed criteria share some formal similarities. This fact has been recently underlined in Giang and Sandilya (2004) who axiomatically justified a general decision model based on symbolic","A definition of subjective probability | Semiring-based CSPs and valued CSPs: Frameworks, properties and comparison | Lexicographic probabilities and choice uncertainty | On the axiomatization of qualitative decision criteria | Great expectations | Great expectations | A symbolic generalization of probability theory | Aggregation of decomposable measures with application to utility theory | Advances in qualitative decision theory: refined rankings | Hybrid probabilisticpossibilistic measures and applications to utility functions | Hybrid probabilisticpossibilistic mixtures and utility functions | Fuzzy sets and systems: theory and applications | An introduction to possibilistic and fuzzy logics | Possibility theory as a basis of qualitative decision theory | Risk, ambiguity, and the savage axioms | Utility theory for decision making | Plausibility measures: A user’s guide | Decision making for symbolic probability | A qualitative linear utility theory for spohn’s theory of epistemic beliefs | A comparison of axiomatic approaches to qualitative decision making using possibility theory | Statistical decisions using likelihood information without prior probabilities | Decision making with partially consonant belief functions | Rank-based systems: a simple approach to belief revision, belief update and reasoning about evidence and actions | Graphs and algorithms | Decision making with belief functions: Compatibility and incompatibility with the surething principle | Games and Decisions | Expected utility hypothesis | Theory of games and economic behavior | Algebraic markov decision processes | The foundations of statistics | Subjective probability and expected utility without additivity | A mathematical theory of evidence | A general non-probabilistic theory of inductive reasoning | ⊥-decomposable measures and integrals for achimedian t-conorms ⊥ | Qualitative decision making under possibilistic uncertainty: Toward more discriminating criteria | General belief measures | An order of magnitude calculus",rejected,000
1206.6869.pdf.json,Recognizing Activities and Spatial Context Using Wearable Sensors,"Recent advances in wearable sensing and computing devices and in fast probabilistic inference techniques make possible the fine-grained estimation of a person’s activities over extended periods of time [12]. Such technologies enable applications ranging from context aware computing [9] to support for cognitively impaired people [16] to long-term health and fitness monitoring to automatic after action reporting of military missions. The focus of our work is on providing accurate information about a person’s activities and environmental context in everyday environments based on wearable sensors and GPS devices. More specifically, we wish to estimate a person’s motion type (such as walking, running, going upstairs/downstairs, or driving a vehicle) and whether a person is outdoors, inside a building, or in a vehicle. These ac- tivity estimates are additionally combined with GPS information so as to estimate the trajectory of the person along with information about which buildings the person enters. To do this, our approach assumes that the bounding boxes of buildings (i.e., maps) are known. This assumption is reasonable, given the availability of satellite images from which these bounding boxes can be extracted manually or via computational vision algorithms. Our main emphasis is on performing activity recognition that is not only accurate, but that also requires a minimum number of sensor devices. There are in fact a variety of systems that utilize multiple sensors and measurements taken all over the body [11, 15]. Our approach, by contrast, attempts to produce as accurate as possible activity recognition requiring only one sensing device mounted only at one location on the body. Our reasoning for reducing the total number of sensors is threefold: 1) it can be unwieldy for the person wearing the sensors to have many such sensors and battery packs mounted all over the body, 2) we wish to minimize overall system cost, and 3) we wish to extend operational time between bat",Using GPS to learn significant locations and predict movement across multiple users | Activity recognition from userannotated acceleration data | On soft evidence in bayesian networks | On triangulating dynamic graphical models | Combining labeled and unlabeled data with co-training | editors | Probabilistic temporal reasoning | Constraint Processing | Using context-aware computing to reduce the perceived burden of interruptions from mobile devices | Wearable sensing to annotate meeting recordings | Recognizing context for annotating a live life recording | A hybrid discriminative-generative approach for modeling human activities | Learning and inferring transportation routines | Location-based activity recognition | Recognizing workshop activity using body worn microphones and accelerometers | Opportunity Knocks: a system to provide cognitive assistance with transportation services | Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference | Rao- Blackwellized particle filters for recognizing activities and spatial context from wearable sensors | Unsupervised word sense disambiguation rivaling supervised methods,rejected,000
1206.6875.pdf.json,A Simple Approach for Finding the Globally Optimal Bayesian Network Structure,"Inspired by Koivisto & Sood (2004), we set ourselves to implement an exact Bayesian network structure discovery for complete discrete data. In its beautiful generality, the original paper concentrates on calculating the probability of any modular feature in Bayesian networks, and hints to the actual structure discovery as a straight forward modification of the general theory. Much of the theory and experiments in Koivisto & Sood (2004) also deals with the cases subject to some given upper bound for the number of parents in the Bayesian network. In this paper we give a much simpler algorithm for finding the globally optimal Bayesian network structure without any structural constraints. The algo- rithm itself could deal with structural constraints, but that would complicate the presentation. The simplicity of our method will also reveal obvious ways to distribute the computation to many computers. However, in this paper, we will not concentrate on the distributed implementation. We hope a simple account of our method together with the freely available software, will rapidly add this technique to the commonly used data analysis toolbox. Furthermore, having the tool handy would hopefully incite further studies on structure discovery algorithms, different scoring metrics, etc. One could also wish for healthy competition on the task. Finding the best Bayesian network structure is NP-hard (Chickering, Meek, & Heckerman, 2003), so the techniques presented will be feasible only for small networks. We present a best network for a data set with 29 variables, and we conduct our experiments with 30 data sets with at most 20 variables. After implementing our method, we learned about the work of of Singh and Moore (2005). They had come to similar conclusions about the methods presented in Koivisto & Sood (2004) and attacked the problem of structure learning more directly. However, they state their method, the SM-algorithm, to be feasible for n < 26 and demonstrate it with n = 22. ",,rejected,000
1206.6879.pdf.json,Practical Linear Value-approximation Techniques for First-order MDPs,"Markov decision processes (MDPs) have become the de facto standard model for decision-theoretic planning problems. While classic dynamic programming algorithms for MDPs require explicit state and action enumeration, recent techniques for exploiting propositional structure in factored MDPs [4] avoid explicit state and action enumeration. While such techniques for factored MDPs have proven effective, they cannot generally exploit first-order structure. Yet many realistic planning domains are best represented in first-order terms, exploiting the existence of domain objects, relations over these objects, and the ability to express objectives and action effects using quantification. As a result, a new class of algorithms has been introduced to explicitly handle MDPs with relational (RMDP) and first-order (FOMDP) structure.1 Symbolic dynamic programming (SDP) [5], first-order value iteration (FOVIA) [12, 13], and the relational Bellman algorithm (ReBel) [14] are model-based algorithms for solving FOMDPs and RMDPs, using appropriate generalizations of value iteration. Approximate policy iteration [7] induces rule-based policies from sampled experience in small-domain instantiations of RMDPs and generalizes these policies to larger domains. In a similar vein, inductive policy selection using first-order regression [9] uses regression to provide the hypothesis space over which a policy is induced. Approximate linear programming (for RMDPs) [10] is an approximation technique using linear program optimization to find a best-fit value function over a number of sampled RMDP domain instantiations. A recent technique for first-order approximate linear programming (FOALP) [21] in FOMDPs approximates a value function by a linear combination of first-order basis functions. While FOALP incorporates elements of symbolic dynamic programming (SDP) [5], it uses a more compact approximation framework and avoids the need for logical simplification. This stands in contrast with exact value i",Reasoning about noisy sensors in the situation calculus | mGPT: A probabilistic planner based on heuristic search | Prioritized goal decomposition of Markov decision processes: Toward a synthesis of classical and decision theoretic planning | Decisiontheoretic planning: Structural assumptions and computational leverage | Symbolic dynamic programming for first-order MDPs | The linear programming approach to approximate dynamic programming | Approximate policy iteration with a policy language bias | Thiebaux. NMRDPP: Decision-theoretic planning with control knowledge | Exploiting first-order regression in inductive policy selection | Generalizing plans to new environments in relational MDPs | Efficient solution methods for factored MDPs | A logic-based approach to dynamic programming | A heuristic search algorithm for solving first-order MDPs | Bellman goes relational | Introduction to the probabilistic planning track | Samuel meets Amarel: Automating value function approximation using global state space analysis | Solving very large weakly coupled Markov decision processes | Piecewise linear value function approximation for factored MDPs | Knowledge in Action: Logical Foundations for Specifying and Implementing Dynamical Systems | The design and implementation of vampire | Approximate linear programming for first-order MDPs | Direct value approximation for factored MDPs | How to dynamically merge Markov decision processes | Learning reactive policies for probabilistic planning domains | PPDDL: The probabilistic planning domain definition language: http://www.cs.cmu.edu/ ̃lorens/papers/ppddl.pdf,rejected,000
1206.7064.pdf.json,,"Automated evaluation of programs is beneficial for both teachers and students (Pears, Seidman, Malmi, Mannila, Adams, Bennedsen, Devlin, & Paterson, 2007). For teachers, automated evaluation is helpful in grading assignments and it leaves more time for other activities with students. For students, it provides immediate feedback which is very important in process of studying, especially in computer science where students take a challenge of making the computer follow their intentions (Nipkow, 2012). Immediate feedback is particularly helpful at first programming courses where students have frequent and deep misconceptions (Vujošević-Janičić & Tošić, 2008). Benefits of automated evaluation of programs are even more significant in the context of online learning. A number of world’s leading universities offer numerous online courses. The number of students taking such courses is measured in millions and quickly growing (Allen & Seaman, 2010). In online courses, the teaching process is carried out on the computer, the contact with teacher is already minimal and hence the fast and substantial automatic feedback is especially desirable. Therefore, automation of evaluation tasks in online learning is very important. Most of the tools for automated evaluation of students’ code are based on automated testing (Douce, Livingstone, & Orwell, 2005). Testing is used for checking functional correctness of student’s solution, i.e., whether the student’s program exhibits the desired behavior on selected inputs. Testing can also be used for detecting bugs. We consider bugs to be runtime errors and exclude errors that only compromise functional correctness (for example, in programming language C, some important bugs are buffer overflow, null pointer dereferencing and division by zero). Although there is a variety of software verification tools that could enhance automated bug finding in students’ programs (by analyzing the code without executing it), these tools are usually too c","A Survey of Automated Assessment Approaches for Programming Assignments | Learning on demand: Online education | Webtoteach: an interactive focused programming exercise system | Satisfiability modulo theories | A measure of similarity between graph vertices: Applications to synonym extraction and web searching | Klee: Unassisted and automatic generation of high-coverage tests for complex systems programs | On automated grading | S2e: a platform for in-vivo | A tool for checking ansi-c programs | Smt-based bounded model | Abstract interpretation: A unified lattice model | Automatic test-based assessment | The quiver system | Automated assessment of gui programs using jewl | Open/cæsar: An open software architecture for verification | Sage: Whitebox fuzzing | Linear Regression | An automatic grading scheme for simple | Deriving phylogenetic trees from the similarity | The use of program dependence graphs in software | Creating and visualizing test data from programming exercises | Grading student programs - a software testing approach | The boss online submission | Symbolic execution and program testing | Authoritative sources in a hyperlinked environment | Use of machine learning techniques for educational proposes: a decision support system for forecasting students’ grades | The hungarian method for the assignment problem | The LLVM Instruction Set and Compilation Strategy | Binary codes capable of correcting deletions, insertions, and reversals | Design and implementation of semantic matching based automatic scoring system for c programming language | Mining lms data to develop an ”early warning system” for educators: a proof of concept | A system for automatic evaluation of c programs | Kassandra: The automatic grading system | Automatically grading java programming assignments via reflection, inheritance, and regular expressions | Automatic grading of student’s programming assignments: an interactive process and suit of programs | Marking student programs using graph similarity | Measuring similarity of graph nodes by neighbor matching | Teaching semantics with a proof assistant: No more lsd trip proofs | A survey of literature on the teaching of introductory programming | Fully automatic assessment of programming exercises | The economic impacts of inadequate infrastructure for software testing | Pex white box test generation for .net | Development and evaluation of LAV: an SMT-based error finding platform. In Verified Software: Theories, Tools and Experiments (VSTTE), LNCS | The role of programming paradigms in the first programming courses | Semantic similarity-based grading of student programs | Using testing and junit across the curriculum",rejected,000
1207.0117.pdf.json,Rule Based Expert System for Cerebral Palsy Diagnosis,"With the advent of latest technologies in computer and information technology sector, the relationship between human and computer has reached a new level. The use of computer science is not only confined to the core computer areas like networks [7], network security [1, 4, 6], databases [2] etc. but also used in many cross disciplinary domains such as biology [12], chemistry [3], medical diagnosis [11] etc. In this paper, we present a rule based expert system for the diagnosis of Cerebral Palsy and classify it as mild, severe or moderate according to the symptoms presented by the users. Expert System is software which has the ability to replicate the thinking and reasoning capacity of humans based on some facts and rules presented to it. The use of expert systems finds its place in diverse sectors like medical diagnosis, decision support systems, educational and tutorial software etc. The use of expert system in medical diagnosis dates back to the early 70’s when MYCIN [13], an expert system for identifying bacteria causing diseases was developed at Stanford University. Since then, various expert systems like Internist – I, CADUCEUS etc. have been developed [14]. The goal of such an expert system is to aid the medical experts in making diagnosis of certain diseases or help the layman to diagnose the disease themselves. In this paper we focus on Cerebral Palsy, which is a disorder that effects the body movement and posture due to some damage in the brain and spinal cord which had occurred during the development of the fetus , during birth of the baby or even during early childhood. According to a report by [5], Cerebral Palsy is the most commonly occurring motor function disorder among children. But many diseases which have similar symptoms like Pelizaeus-Merzbacher disease, Rett Syndrome, Charcot- 1 Marie-Tooth disease can be mistaken for Cerebral Palsy without the advice of an expert medical professional [8]. In this case, the Expert System for Cerebral Palsy Diagn","A Distributed Security Scheme for Ad Hoc Networks"", ACM Crossroads | An LSB Data Hiding Technique Using Prime Numbers | A Multifactor Security Protocol For Wireless Payment-Secure Web Authentication using Mobile Devices | Impact of Node Mobility on MANET Routing Protocols Models | Diseases That Can Be Mistaken for Cerebral Palsy | The RETE algorithm demystified | Computer aided fuzzy medical diagnosis | Identification of novel transcripts in annotated genomes using RNA-Sequence | Rule Based Expert Systems: The Mycin Experiments of the Stanford Heuristic Programming Project | Intelligent and Expert Systems in Medicine – A Review | Development and reliability of a system to classify gross motor function in children with cerebral palsy | Expert System : Design And Development",rejected,000
1207.6713.pdf.json,Model-Lite Case-Based Planning,"Most work in planning assumes that complete domain models are given as input in order to synthesize plans. However, there is increasing awareness that building domain models at any level of completeness presents steep challenges for domain creators. Indeed, recent work in web-service composition (c.f. (Bertoli, Pistore, and Traverso 2010; Hoffmann, Bertoli, and Pistore 2007)) and work-flow management (c.f. (Blythe, Deelman, and Gil 2004)) suggest that dependence on complete models can well be the real bottle-neck inhibiting applications of current planning technology. There has thus been interest in the so-called “model-lite” planning approaches (c.f. (Kambhampati 2007)) that aim to synthesize plans even in the presence of incomplete domain models. The premise here is that while complete models cannot be guaranteed, it is often possible for the domain experts to put together reasonable but incomplete models. The challenge then is to work with these incomplete domain models, and yet produce plans that have a high chance of success with respect to the “complete” (but unknown) domain model. This is only possible if the planner has access to additional sources of knowledge besides the incomplete domain model. Copyright c© 2012, All rights reserved. Interestingly, one of the original motivations for casebased planning was also the realization that in many domains complete domain models are not available. Over years however, case-based planning systems deviated from this motivation and focused instead on “plan reuse” where the motivation is to improve the performance of a planner operating with a complete domain model. In this paper, we return to the original motivation by considering “model-lite casebased planning.” In particular, we consider plan synthesis when the planner has an incomplete domain theory, but has access to a library of plans that “worked” in the past. This plan library can thus be seen as providing additional knowledge of the domain over and above the i","E | Automated composition of web services via planning in asynchronous domains | Automatically composedworkflows for grid environments | and Weber | N | K | Web service composition as planning, revisited: In between background theoriesandinitial state uncertainty | and Kambhampati | J | M | Mining sequential patterns by pattern-growth: The prefixspan approach | I | A | Learning action models from plan examples using weighted MAX-SAT | M | L | L",rejected,000
1208.1692.pdf.json,On Finding Optimal Polytrees,"There has been extensive research on learning probabilistic networks from data by maximizing some suitable scoring function. Edmonds (1967) gave an efficient algorithm for the class of branchings, that is, directed forests with in-degree at most one; the algorithm was discovered independently by Chu and Liu (1965), and it has been later simplified and expedited by others Bock (1971); Camerini, Fratta, and Maffioli (1979); Fulkerson (1974); Gabow et al. (1986); Gabow, Galil, and Spencer (1989); Karp (1971); Tarjan (1977). Chickering (1996) showed that for general directed acyclic graphs, DAGs, the problem is NP-hard even if the in-degree is at most two. Motivated by this gap, Dasgupta (1999) asked for a network class that is more general than branchings yet admitting provably good structure-learning algorithms; his findings concerning polytrees, that is, DAGs without undirected cycles, were however rather negative, showing that the optimization problem is NP-hard even if the in-degree is at most two. Given the recent advances in exact exponential algorithms in general (see, e.g., the book by Fomin and Kratsch (2010)), and in finding optimal DAGs in particular, it is natural to ask, whether “fast” exponential-time algorithms exist for finding optimal polytrees. For general DAGs the fastest known algorithms run in time within a polynomial factor of 2n, where n is the number of nodes Koivisto and Sood (2004); Ott and Miyano (2003); Parviainen and Koivisto (2009); Silander and Myllymäki (2006). However, it is not clear, whether even these bounds can be achieved for polytrees; a brute-force algorithm would visit each polytree one by one, whose num- ber scales as the number of directed labelled trees nn−22n−1 Cayley (1889). Do significantly faster algorithms exist? Does the problem become easier if only a small number of nodes are allowed an in-degree larger than one? In this work, we take a first step towards answering these questions by considering polytrees that differ","An algorithm to construct a minimum directed spanning tree in a directed network | Two algorithms for weighted matroid intersection | A note on finding optimum branchings | A theorem on trees | A transformational characterization of equivalent Bayesian network structures | Learning Bayesian networks is NP-complete | On the shortest arborescence of a directed graph | Learning polytrees | Parameterized Complexity | Optimum branchings | Submodular functions, matroids and certain polyhedra | Matroid intersection | Parameterized Complexity Theory, volume XIV of Texts in Theoretical Computer Science | Exact Exponential Algorithms | A weighted matroid intersection algorithm | Bayesian network classifiers | Packing rooted directed cuts in a weighted directed graph | Efficient algorithms for finding minimum spanning trees in undirected and directed graphs | Efficient implementation of graph algorithms using contraction | Computers and Intractability | Learning Bayesian networks: The combination of knowledge and statistical data | Which problems have strongly exponential complexity? J | An algorithm for finding an optimal ’independent’ assignment | A simple derivation of Edmonds’ algorithm for optimum branchings | Exact Bayesian structure discovery in Bayesian networks | Learning Bayesian belief networks: An approach based on the MDL principle | Combinatorial Optimization: Networks and Matroids | Algorithms and complexity results for exact Bayesian structure learning | Finding optimal gene networks using biological constraints | Exact structure discovery in Bayesian networks with less space | On the parameterized complexity of the fixed alphabet shortest common supersequence and longest common subsequence problems | A simple approach for finding the globally optimal Bayesian network structure | Finding optimum branchings",rejected,000
1208.2566.pdf.json,The Complexity of Planning Revisited – A Parameterized Analysis,"Bylander 1994 made an extensive analysis of the computational complexity of propositional STRIPS under various restrictions, like limiting the number of preconditions or effects. Bäckström and Nebel 1995 made a similar analysis of planning with multi-valued state variables in the SAS+ formalism, investigating the complexity of all combinations of the P, U, B and S restrictions introduced by Bäckström and Klein 1991. These were among the first attempts to understand why and when planning is hard or easy and have had heavy influence on recent research in planning, of which we list a few representative examples. Giménez and Jonsson 2008, Chen and Giménez 2010 as well as Katz and Domshlak 2008 have studied the complexity of planning for various restrictions on the causal graph, the latter also considering combinations with restrictions P and U. Katz and Domshlak further pointed out a particularly important usage of such results, saying: Computational tractability can be an invaluable tool even for dealing with problems that fall outside all the known tractable fragments of planning. For instance, tractable fragments of planning provide the foundations for most (if not all) rigorous heuristic estimates employed in planning as heuristic search. Two examples of slightly different ways to do this are the following. Helmert 2004 used a planning algorithm for a simpler restricted problem to compute heuristic values for subproblems and then combine these values. Similarly, the popular h+ heuristic Hoffmann (2005) exploits Bylander’s results that planning is simpler with only positive preconditions and uses this as a relaxation for computing a heuristic value. As a complement to such analyses of restricted planning lanugages, Helmert 2006 studied the complexity and inherent restrictions in a number of application problems. We revisit these early classifications of STRIPS and of SAS+, but using parameterized complexity analysis rather than standard complexity analysis. Par","All PSPACE-complete planning problems are equal but some are more equal than others | Planning in polynomial time: The SAS-PUBS class | Computational Complexity of Reasoning about Plans | Planning using transformation between equivalent formalisms: A case study of efficiency | Structure and complexity in planning with unary operators | On the fixed-parameter tractability of composition-consistent tournament solutions | The computational complexity of propositional STRIPS planning | Causal graphs and structurally restricted planning | Parameterized Complexity | The Computer Journal special issue on parameterized complexity: Foreword by the guest editors | Parameterized Complexity: A Framework for Systematically Confronting Computational Intractability, volume 49 of DIMACS Series in Disc | Program model checking via action planning | Summary of Dagstuhl seminar 06172 on directed model checking | Taming numbers and durations in the model checking integrated planning system | Parameterized Complexity Theory, volume XIV of Texts in Theoretical Computer Science | Kernels for global constraints | The complexity of planning problems with simple causal graphs | Bounded treewidth as a key to tractability of knowledge representation and reasoning | A planning heuristic based on causal graph analysis | New complexity results for classical planning benchmarks | Where ’ignoring delete lists’ works: Local search topology in planning benchmarks | New islands of tractability of cost-optimal planning | Systematic nonlinear planning | Augmenting tractable fragments of abstract argumentation | On the parameterized complexity of the fixed alphabet shortest common supersequence and longest common subsequence problems | The causal graph revisited for directed model checking | A reactive planner for a model-based executive",rejected,000
1211.2290.pdf.json,Dating Texts without Explicit Temporal Cues,"Temporal analysis of text has been an active area of research since the early days of text mining with different focus in different disciplines. In early computational linguistics research it was primarily concerned with the fine-grained ordering of temporal events (Allen, 1983; Vilain, 1982). Information retrieval research has focused largely on timesensitive document ranking (Dakka et al., 2008; Li and Croft, 2003), temporal organization of search results (Alonso et al., 2009), and how queries and documents change over time (Kulkarni et al., 2011). This paper explores temporal analysis models that use ideas present in both computational linguistics and information retrieval. While some prior research has focused on extracting explicit mentions of temporal expressions (Alonso et al., 2009), we investigate the feasibility of using text alone to assign timestamps to documents. Following previous document dating work (de Jong et al., 2005; Kanhabua and Nørvåg, 2008; Kumar et al., 2011), we construct supervised language models that capture the temporal distribution of words over chronons, which are contiguous atomic time spans used to discretized the timeline. Each chronon model is smoothed by interpolation with the entire training set collection. For each test document, a unigram language model is computed and used to find the document’s similarity with each chronon’s language model. This provides a ranking over chronons for the document, representing the document’s likelihood of being similar to the time periods covered by each chronon (de Jong et al., 2005; Kanhabua and Nørvåg, 2008). Our chronon models are learned from Wikipedia biographies spanning 3800 B.C. to 2010 A.D. Wikipedia-based training is advantageous since its recency enables us to control against stylistic vs. content factors influencing vocabulary use (e.g. consider the difference between William Mavor’s 1796 discussion1 of Sir Walter Raleigh vs. a modern retrospective biography2). This contrasts wi","Maintaining knowledge about temporal intervals | Clustering and exploring search results using timeline constructions | Dynamic topic models | Jointly combining implicit constraints improves temporal ordering | Labeling documents with timestamps: Learning from their time expressions | Structural and temporal analysis of the blogosphere through community factorization | Finding wormholes with flickr geotags | Answering general time sensitive queries | Temporal Language Models for the Disclosure of Historical Text | A latent variable model for geographic lexical variation | Real-time event extraction for infectious disease outbreaks | Studying the history of ideas using topic models | Improving temporal language models for determining time of non-timestamped documents | Understanding temporal query dynamics | Supervised language modeling for temporal resolution of texts | Document language models, query models, and risk minimization for information retrieval | Document language models, query models, and risk minimization for information retrieval | Time-based language models | Learning to resolve geographical and temporal references in text | WikiWars: A new corpus for research on temporal expressions | Identifying relevant temporal expressions for realworld events | A language modeling approach to information retrieval | The TimeBank corpus | Heideltime: High quality rule-based extraction and normalization of temporal expressions | A system for reasoning about time | Topics over time: a non-markov continuous-time model of topical trends | Continuous time dynamic topic models | Simple supervised document geolocation with geodesic grids | A study of smoothing methods for language models applied to information retrieval | Evolutionary hierarchical dirichlet processes for multiple correlated time-varying corpora",rejected,000
1211.2399.pdf.json,Mining Determinism in Human Strategic Behavior,"Game theory is one of many scientific disciplines predicting outcomes of social, economical and competitive interactions among humans on the granularity level of individual decisions [1, p.4]. People are assumed to be autonomous and intelligent, and to decide according to their preferences. People can be regarded as rational, if they always make decisions, whose execution has according to their subjective estimation the most preferred consequences [2,3]. The correctness of subjective estimation depends on the level of intelligence. Rationality can justify own decisions and predictions of other people’s decisions. If interacting people satisfy the concept of rationality and apply mutually and even recursively this concept, then the interaction is called strategic interaction (SI). Further, game is a notion for the formal structure of a concrete SI [4]. A definition of a game consists of a number of players, their legal actions and players’ preferences. The preferences can be replaced by a payoff function under assumed payoff maximization. The payoff function defines each player’s outcome depending on his actions, other players’ actions and random events in the environment. The game-theoretic solution of a game is a prediction about the behavior of the players aka an equilibrium. The assumption of rationality is the basis for an equilibrium. Deviating from an equilibrium is beyond rationality, because it does not maximize the payoff. Not every game has an equilibrium. However, there is at least one mixed strategies equilibrium (MSE) in finite games [5]. The notion of game is commonly used for pleasant time spending activities like board games, but can also be extended to all social, economical and competitive interactions among humans. A board game can have the same game structure as a war. Some board games are even developed to train people, like Prussian army war game ”Kriegspiel Chess” [6] for officers. We like it to train ourselves in order to perform better in ga","Strategische Interaktion realer Agenten: Ganzheitliche Konzeptualisierung und Softwarekomponenten einer interdisziplinren Forschungsinfrastruktur | Artificial Intelligence | A course in game theory | Theory of Games and Economic Behavior | Non-cooperative games | Kriegspiel: Chess Under Uncertainty | General game playing: Overview of the aaai competition | Putting game theory to the test | Behavioral Game Theory | Ten Theories of Human Nature | Economics wins, psychology loses, and society pays | Cognitive Psychology: A Student’s Handbook | An experimental imperfect market | Learning to apply theory of mind | Reasoning | The probabilistic approach to human reasoning | Judgment Under Uncertainty: Heuristics and Biases | Not that bad after all: Generation of random sequences | Hypotheses about typical general human strategic behavior in a concrete case | A language for modeling agents’ decision making processes in games | Semantical considerations on modal logic | Modeling reciprocal behavior in human bilateral negotiation | Cognitive modeling versus game theory: Why cognition matters | Background, structure, and preview of the model comparison | Machine Learning | Data Mining | Fast training of support vector machines using sequential minimal optimization | Predicting human interactive learning by regret-driven neural networks | The power of decision tables",rejected,000
1211.2719.pdf.json,Quantum Consciousness Soccer Simulator,"The robot soccer, or commonly called RoboCup, is a standard AI problem for catalyzing research on the field of autonomous agent technology [14]. In RoboCup, there are several different kinds of leagues. Currently, in the case of RoboCup 2D Soccer Simulation League (2D RCSS), all aspects of the game of the world’s best teams are quite real if compared to the matches among various humanoid teams, while the same cannot be said of the case of the other leagues of RoboCup. In 2D soccer simulations, the rcssserver [19] establishes the reality of the simulated soccer world. Through UDP/IP, client agents have connected to this simulated reality. But they are taking part in the establishment of reality only through the rcssserver using RCSS protocol [5]. Following this protocol, the client agents receive their sensory input from the rcssserver, then send back a ”conscious” response, and this cycle takes place repeatedly in the usual manner in autonomous agent technologies. ar X iv :1 21 1. 27 19 v2 [ cs .A I] 1 3 N ov 2 In contrast with this, we would like to develop a new concept for simulation of soccer in that the client agents are more directly related to the establishment of reality. The new soccer simulation environment is partly inspired by several interpretations of quantum mechanics [17, 22, 21, 18, 7, 8, 20], for example Hugh Everett’s Many-worlds, Wheeler’s participatory universe, Many-minds, Copenhagen or Neumann and Wigner’s interpretations. But it is important to note that we are only at the popular science level of understanding of these issues and the quantum mechanical inspiration will play no part in the next chapters. However, in the case of soccer, some interpretations of quantum mechanics may enable, in theory, that all actions of all client agents might be real by representing forks in the simulation process. In this case, the known question is that how the client agents are to be selected such that they play the same match. In philosophical level, it m","Footballer and football simulation markup language and related simulation software development | Football(er) Simulation Markup Language, 2010-2012 | Conscious machines and consciousness oriented programming | Quantum Consciousness | and X | Is it an agent | In Search of Schrodinger’s Cat | Schrodinger’s Kittens and the Search for Reality: Solving the Quantum Mysteries | Quantum computation in brain microtubules? The Penrose-Hameroff ’Orch OR’ model of consciousness | How quantum brain biology can rescue conscious free will | Conscious events as orchestrated spacetime selections | Orchestrated Objective Reduction of Quantum Coherence in Brain Microtubules: The ”Orch OR | and K | Robocup: The robot world cup initiative | Boost.Asio, 2003-2012. URL http://www.boost.org/ doc/libs/1_51_0/doc/html/boost_asio.html | The emperor’s new mind: concerning computers | The Nine Lives of Schroedinger’s Cat | Schrödingerék macskája és más történetek | Mathematical Foundations of Quantum Mechanics | Symmetries and Reflections: Scientific Essays of Eugene P",rejected,000
1211.2736.pdf.json,Hybrid Systems for Knowledge Representation in Artificial Intelligence,,"Comparative Study of Three Declarative Knowledge representation Techniques | Comparative Study of Three Declarative Knowledge Representation Techniques | Knowledge representation and inference in similarity networks and Bayesian multinets | An overview of the KL-ONE Knowledge Representation System | A Logic of Implicit and Explicit Belief. | Small Can Be Beautiful in Knowledge Representation | Knowledge Base Integration: What we can learn from Database Integration Research”, A.I | The Restricted Language Architecture for Hybrid Representation System | An Overview of the Programmer's Apprentice | An Effective Knowledge base system Architecture and issues in representation techniques",rejected,000
1211.2972.pdf.json,Segregating event streams and noise with a Markov renewal process model,"Various approaches exist for the task of inferring the temporal evolution of multiple sources based on joint observations (Mahler, 2007; Van Gael et al., 2008). They are generally based on a model in which sources are continuously observable, in the sense that they are expected to emit/return observations at every time step (though there may be missed detections). Yet there are various types of source for which observations are inherently intermittent, and for which this intermittence exhibits temporal structure that can be characterised as a point process. Examples include sound event sequences such as bird calls or footsteps (Wang and Brown, 2006), internet access logs (Arlitt and Williamson, 1997), pulsars in astronomy (Keane et al., 2010) and neural firing patterns (Bobrowski et al., 2009). Intermittent observations are also often output from sparse representation techniques, which transform signals into a representation with activations distributed sparsely in time and state (Plumbley et al., 2010). In this paper we describe a generic problem setting that may be applied to such data, along with an approach to estimation. We are given a set of timestamped data, and we assume each datum is produced by one of a set of similar but independent signal processes, or by a “clutter” noise process, with known parameters. We do not know the true partitioning of the data into sequences each generated by a single process, and wish to infer this. We do not know how many processes are active, and we do not assume that each process produces the same number of observations, or observations at the same time points. ar X iv :1 21 1. 29 72 v1 [ cs .A I] 1 3 N ov 2 This specific type of clustering problem has applications in various domains. For example, when sparse representation techniques are used for source separation in time series, they often yield a set of atomic activations which must be clustered according to their underlying source, and preferably to discard any spurious ","Internet web servers: Workload characterization and performance implications | Digraphs: Theory, Algorithms and Applications | Bayesian filtering in spiking neural networks: Noise, adaptation, and multisensory integration | Effects of differences in timbre on sequential grouping | On the complexity of time table and multi-commodity flow problems | Further searches for rotating radio transients in the Parkes Multi-beam Pulsar Survey | Exact Bayesian structure discovery in Bayesian networks | Normalized cuts for predominant melodic source separation | Statistical Multisource-Multitarget Information Fusion | Non-negative hidden Markov modeling of audio with application to source separation | Recognition of individuals by song, using cross-correlation of sonograms of Ortolan buntings emberiza hortulana | Sparse representations in audio and music: From coding to source separation | Hemim. Song variation in the chiffchaffs (phylloscopus collybita) of the western pyreneesthe contact zone between the collybita and brehmii | Normalized cuts and image segmentation | The infinite factorial hidden Markov model | Computational Auditory Scene Analysis: Principles, Algorithms, and Applications | Multistability in auditory stream segregation: a predictive coding view | Data Mining: Practical Machine Learning Tools and Techniques",rejected,000
1211.3089.pdf.json,ET-LDA: Joint Topic Modeling for Aligning Events and their Twitter Feedback,"During public broadcast events such as the Superbowl, the U.S. Presidential and Primary debates, the last episode of a TV drama series, etc., Twitter has become the de facto platform for crowds to share perspectives and commentaries about these events. Given an event and an associated largescale collection of tweets, we face two fundamental problems in analyzing and understanding them, namely, extracting the topics covered in the event and tweets, and segmenting the event into topically coherent segments. Tackling the two problems is critical to applications like computational advertising, community detection, journalistic investigation, storytelling, playback of events, etc. While both topical modeling and event segmentation have received considerable attention in recent years, they have been mainly viewed as separate problems and studied in isolation. For example, there have been significant efforts on developing Bayesian models to discover the patterns that reflect the underlying topics from the document (Blei, Ng, and Jordan 2003; Griffiths et al. 2004; Wang and McCallum 2006; Titov and McDonald 2008). Similarly, there is also a rich body of work devoted to segmentation of events/discourses/meetings via heuristics, machine learning, etc. (Hearst 1993; Boykin Copyright c© 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. and Merlino 2000; Galley et al. 2003; Dielmann and Renals 2004). Directly applying these current solutions to analyze the event and its associated tweets however has a major drawback: they treat event and tweets independently, thus ignoring the topical influences of the event on its associated tweets. In reality they are obviously inter-dependent. For example, in practice, when tweets are generated by the crowds to express their interests in the event, their content is essentially influenced by the topics covered in the event in some way. Based on such dependencies, i.e., topical influences, a p",Statistical models for text segmentation | and Lafferty | M | and Merlino | and Blei | and Renals | Unsupervised prediction of citation influences | Discourse segmentation of multi-party conversation | and Steyvers | J | and Liu | Exploiting internal and external semantics for the clustering of short texts using world knowledge | What were the tweets about? topical associations between public events and twitter feeds | Event analytics via social media | Joint latent topic models for text and citations | Unsupervised topic modelling for multi-party spoken discourse | Characterizing microblogs with topic models | and Heilman | Tweet the debates: understanding community annotation of uncollected sources | and McDonald | and McCallum,rejected,000
1211.3212.pdf.json,Distributed Non-Stochastic Experts,"In this paper, we consider the well-studied non-stochastic expert problem in a distributed setting. In the standard (non-distributed) setting, there are a total of n experts available for the decisionmaker to consult, and at each round t = 1, . . . , T , she must choose to follow the advice of one of the experts, say at, from the set [n] = {1, . . . , n}. At the end of the round, she observes a payoff vector pt ∈ [0, 1]n, where pt[a] denotes the payoff that would have been received by following the advice of expert a. The payoff received by the decision-maker is pt[at]. In the non-stochastic setting, an adversary decides the payoff vectors at any time step. At the end of the T rounds, the regret of the decision maker is the difference in the payoff that she would have received using ∗This research was carried out while the author was at Harvard University supported in part by grant NSF-CCF09-64401 †This research was carried out while the author was at Harvard University supported in part by grants NSF-IIS0964473 and NSF-CCF-0915922 ar X iv :1 21 1. 32 12 v1 [ cs .L G ] 1 4 the single best expert at all times in hindsight, and the payoff that she actually received, i.e. R = maxa∈[n] ∑T t=1 p t[a] − ∑T t=1 p t[at]. The goal here is to minimize her regret; this general problem in the non-stochastic setting captures several applications of interest, such as experiment design, online ad-selection, portfolio optimization, etc. (See [1, 2, 3, 4, 5] and references therein.) Tight bounds on regret for the non-stochastic expert problem are obtained by the so-called follow the regularized leader approaches; at time t, the decision-maker chooses a distribution, xt, over the n experts. Here xt minimizes the quantity ∑t−1 s=1 p t · x + r(x), where r is a regularizer. Common regularizers are the entropy function, which results in Hedge [1] or the exponentially weighted forecaster (see chap. 2 in [2]), or as we consider in this paper r(x) = η̄ · x, where η̄ ∈R [0, η]n is a random v",,rejected,000
1211.3371.pdf.json,A Comparison of Meta-heuristic Search for Interactive Software Design,"The application of automated search to a range of software development activities has attracted significant research attention. Indeed, Search-Based Software Engineering (SBSE) (Harman 2007, Harman 2011) is now a well-established discipline. SBSE historically focused on software testing where solutions can be represented fairly naturally and metrics such as structural and functional test coverage can be automatically calculated to serve as quality functions. However, in the upstream stages of the software design, such as the object-oriented modeling of design classes, the choice of evaluation functions is much less well defined – for example, Bowman et al. (2010) cite 6 different possible metrics relating to the structural integrity of the design with respect to design coupling and cohesion. Here the precise balance of factors affecting the subjective judgments of the human software engineer is less well understood – hence the oftheard references to the “art” of software design. Indeed, this is precisely the sort of scenario in which Interactive Evolutionary Algorithms (IEAs) have been shown to perform well (see e.g. the survey in Takagi (2001), and more recent work such as Tagaki and Ohsaki (2007), Celeb-Solly and Smith (2007), Brintrup et al. (2008) and Pauplin et al. (2010) ). Our earlier work demonstrates that we can indeed successfully use meta-heuristics to provide computational support for an interactive software design process, evolving object-oriented class models that met designers’ criteria –both subjective (Simons et al. 2010) and aesthetic (Simons and Parmee (2012). As with most papers in the field, such interactive design search uses an Evolutionary Algorithm (EA) (Eiben and Smith, 2003) because of their long history of successful applications. However, as the name of the field of SearchBased Software Engineering suggests, potentially any search algorithm could be used, although in practice research effort has also tended to concentrate on metaheuristi","An object-oriented high-level design-based class cohesion metric | Interactive concept-based search using MOEA | On the invariance of ant colony | Visual interactive evolutionary algorithm for high dimensional data | Solving the class responsibility assignment problem | A unified framework for coupling measurement | Ergonomic chair design by fusing qualitative | Adaptive surface inspection via interactive evolution | The Blind Watchmaker | Ant Colony Optimisation | Automatic structural testing using genetic algorithms | Evolving objects: a general purpose evolutionary computation library | Interactive solving of vehicle routing and scheduling problems: basic concepts and qualification of tabu search approaches | ECJ 20: A java-based evolutionary computation research system | An investigation into the applicability and validity of object-oriented design metrics | The current state and future of search based software engineering | Software engineering meets evolutionary computation | Search-based software engineering | Pareto optimal search-based refactoring at the design level | Emergence of profitable search strategies based on a simple inheritance mechanism | Multiple fuzzy state-value functions for human evaluation through interactive trajectory planning of a partner robot | Interactive genetic algorithm with wavelet coefficients for emotional image retrieval | Interactive evolution for cochlear implants | Revisiting the Restricted Growth Function Genetic Algorithm for Grouping Problems | Towards a new evolutionary computation: advances in estimation of distribution | Interactive particle swarm optimisation | Genetic operators, the fitness landscape and the traveling salesman problem | Search-based software test data generation: a survey | The magical number seven, plus or minus two: some limits on our capacity for processing information | An input method using discrete fitness values for interactive GA | Search-based refactoring for software maintenance | User-centric image segmentation using an interactive parameter adaptation tool | Cooperative co-evolutionary optimisation of software project assignments and job scheduling | Self-adaption of mutation operator and probability for permutation representations in genetic algorithms | Interactive evolutionary computing in early lifecycle software engineering design | Use Case Specifications for Cinema Booking System | Use Case Specifications for Graduate Development Program | Use Case Specifications for Select Cruises | 2012d) Manual Software Designs for Problem Domains | Interactive, evolutionary search in upstream objectoriented class design | Dynamic parameter control of interactive local search in UML software design | Elegant object-oriented software design via interactive evolutionary computation | Source code, Extended Results and Analysis for this paper. http://www.cems.uwe.ac.uk/~clsimons/CaseStudies/Appendix.htm Accessed | Interactive evolution of dynamical systems | Artificial evolution for computer graphics | Modelling GAs with self-adaptive mutation rates | Microprocessor design verification by two-phase evolution of variable length tests | Staggemeir A (2009) A genetic approach to statistical disclosure control | Evolving software test data - GAs learn self- expression | Strategy parameter variety in self-adaptation of mutation rates | Interactive evolutionary computation: fusion of the capabilities of EC optimization and human evaluation | Interactive evolutionary computation-based hearing-aid fitting | The Vehicle Routing Problem | RGFGA: An efficient representation and crossover for grouping genetic algorithms | An interactive simulation and analysis software for solving TSP using ant colony optimization algorithms | Automatic program repair with evolutionary computing | Application of genetic algorithms to software testing | Repository of publications on search-based software engineering",rejected,000
1211.3882.pdf.json,Gliders2012: Development and Competition Results,"The RoboCup Simulation League [10] incorporates several challenging features, setting a benchmark for Artificial Intelligence (AI). The following list includes some of the most prominent characteristics of the RoboCup 2D Simulation League: – distributed client/server system running on a network, leading to fragmented, localized and imprecise (noisy and latent) information about the environment (field) [12]; – concurrent communication with a medium-sized number of agents [21]; – heterogeneous sensory data (visual, auditory, kinetic) and limited range of basic com- mands/effectors (turn, kick, dash, . . .) [19]; – asynchronous perception-action activity and limited window of opportunity to perform an action [6]; – autonomous decision-making under constraints enforced by teamwork (collaboration) and opponent (competition) [20]; – conflicts between reactivity and deliberation [18]; – no centralized controllers and centralized world model (no global vision, etc.) [16,17]. From the onset of the RoboCup effort it was recognized that, as a benchmark, RoboCup is fairly different from another classical AI problem — chess. As pointed out by Asada et al. [4], chess and RoboCup differ in a few key elements: environment (static vs dynamic), state change (turn-taking vs real-time), information accessibility (complete vs incomplete), sensor readings (symbolic vs non-symbolic), and control (central vs distributed). This difference has been well understood over the last decade. Nevertheless, there are some similarities, for example, efficient evaluation functions used by the RoboCup agents are conceptually similar ? CSIRO authors are listed in alphabetical order. ar X iv :1 21 1. 38 82 v2 [ cs .A I] 2 1 N ov 2 01 2 to evaluation functions used by chess computers: in either case the agent is attempting to consider multiple future states, assign some values to the alternative outcomes, and choose an action optimizing the evaluations. One may argue that superior performance of recent wo","Multi-agent positioning mechanism in the dynamic environment | Helios2010 team description | RoboCup: Today and tomorrow – What we have have learned | Wrighteagle and ut austin villa: Robocup 2011 simulation league champions | Flexible synchronisation within RoboCup environment: A comparative analysis | Users Manual: RoboCup Soccer Server — for Soccer Server Version 7.07 and Later | Computers in Sport, chapter Approaching a Formal Soccer Theory from the Behavior Specification in Robotic Soccer, pages 161–186 | robocup2flash version 0.3 | The RoboCup Synthetic Agent Challenge 97 | Chess Programming Part VI: Evaluation Functions | The RoboCup Soccer Server and CMUnited Clients: Implemented Infrastructure for MAS Research | Flexible coordination of multiagent team behavior using HTN planning | Revision vs. update: Taking a closer look | Gliders2012: Tactics with action-dependent evaluation functions | Relating the entropy of joint beliefs to multi-agent coordination | Evaluating team performance at the edge of chaos | Situation based strategic positioning for coordinating a team of homogeneous agents | Layered disclosure: Revealing agents’ internals | Defining and using ideal teammate and opponent models | Task decomposition, dynamic role assignment, and lowbandwidth communication for real-time strategic teamwork | Team-partitioned, opaque-transition reinforced learning",rejected,000
1211.4488.pdf.json,,"Much research in recent years has focused on constructing semi-automatic and automatic aligned data resources, which are essential for many Natural Language Processing Tasks; however for some pairs of languages there is still a huge lack of annotated data. Manual construction of Parallel corpus requires high quality translators, besides It is time consuming and expensive. With the proliferation of the internet and the immense amount of data, a number of researchers have proposed using the World Wide Web as a large-scale corpus[5]. However due to redundancy and ambiguous information on the web, we must find methods of extracting only the information that is useful for a given task. [4]. Extracting parallel sentences from a comparable corpus is a challenging task, due to the fact that despite two documents can be referred to a same topic, it can be possible that both documents do not have a single sentence in common. In this study, we propose an approach for extracting Japanese-Spanish parallel sentences from Wikipedia using Part-of-Speech rule based alignment and Dictionary based translation. We use as comparable corpora to Wikipedia articles, a dictionary extracted from the Wikipedia links and Aulex a free Japanese-Spanish dictionary",Finding Similar Sentences across Multiple Languages in Wikipedia | Using Encyclopedic Knowledge for Named Entity Disambiguation | Japanese-Spanish Thesaurus Construction Using English as a Pivot | A Bean-Search Extraction Algorithm for Comparable Data | A Simple Sentence-Level Extraction Algorithm for Comparable Data,rejected,000
1211.4524.pdf.json,MANOEUVRING TARGET TRACKING USING PARTICLE FILTERING,"Multi target tracking is one of the important research areas in computer vision. Human tracking in monitoring applications and aircraft tracking in military applications are known as important applications areas of multi target tracking. Multi target tracking includes two main stages: 1) pose estimation and 2) data association. Kalman filtering and grid-based methods are the most important methods for pose estimation that are used in linear systems with Gaussian noises. For linear-Gaussian systems, Kalman filter is an analytical and optimal method. Particle filtering is a numerical and suboptimal method that is used for pose estimation. Unlike the Kalman filtering, Particle filtering method can be used in non-linear system with non-Gaussian noises. This is the most important advantage of particle filtering over other methods. Estimation of manoeuvring target' s state is one of the most important problems in pose estimation. Multiple Model (MM) approach is a common solution to resolve this problem [1-3]. Target' s posteriori density function is represented by weighted sum of the output of several parallel filters in MM approach [4]. A real-time approach is presented in [1 5 ] for tracking a manoeuvring target by incorporating dynamic components in the target model. They employed particle filter based tracker. This tracker exploits a first order dynamic model and continuously performs adaptation of model noise for balancing uncertainty between the static and dynamic components of the state vector. The presented experimental evaluation shows that this approach is particularly effective in video sequences where appearance and motion have quick changes and there are partial or full target occlusions. Data association algorithm associates each measurement to track. In cluttered environments, measurements may arise from detected targets or clutter. From the view of implementation, Global Nearest Neighbor (GNN) is the simplest method for data association [ 5 ]. Usually, thi","N | Tracking and Data Association | and M | An Algorithm for Tracking Multiple Targets | N | N | S | E | 2010 ) "" Fiducial Facial Points Tracking Using Particle Filter and Geometric Features",rejected,000
1211.4957.pdf.json,,,"The Description Logic Handbook: Theory, Implementation, and Applications - 2: Basic Description Logics | Web Semantico in Le Scienze - 393 (Italian translation of The Semantic Web | A Decidable Quantified Fragment of Set Theory Involving Ordered Pairs with Applications to Description Logics in Computer Science Logic (CSL’11) - 25th International Workshop/20th | Foundations of Semantic Web Technologies | Reducing OWL entailment to description logic satisfiability | Resource Description Framework (RDF): Concepts and Abstract | Set Theory for Knowledge Representation | The Description Logic Handbook: Theory, Implementation, and Applications - 1: An Introduction to Description Logics | RDFS(FA): Connecting RDF(S) and OWL DL in IEEE Transaction on Knowledge and Data Engineering",rejected,000
1211.5766.pdf.json,Visualization and clustering by 3D cellular automata: Application to unstructured data,,"A concept space approach to addressing the vocabulary problem in scientific information retrieval: An experiment on the worm community system | The vocabulary problem in collaboration [Special Issue on CSCW | Text mining: The state of the art and the challenges | Knowledge discovery in textual databases (KDT) | Data clustering: A review | Recent trends in hierarchic document clustering: A critical review | Information retrieval. London: Butterworths | Data clustering and learning | A comparative study of clustering methods | Clustering Algorithms | A survey of recent advances in hierarchical clustering algorithms | Optimization by Simulated Annealing | Evolution Strategies: A Comprehensive Introduction | The Theory of Evolution Strategies | Dynamic partitional clustering using evolution strategies | Genetic Programming: On the Programming of Computers by Means of Natural Evolution | A Learning System Based on Genetic Adaptive Algorithms, PhD dissertation (University of Pittsburgh) | A representation for the adaptive generation of simple sequential programs | A clustering algorithm using an evolutionary programmingbased approach | Ant Colony Optimization | Particle swarm optimization | Image classification using particle swarm optimization | Particle swarm optimization method for image clustering | The SMART Retrieval System.Prentice-Hall, Englewood Cliffs, NJ | Introduction to Modern Information Retrieval.McGraw | Using linear algebra for intelligent information retrieval | Machine learning in automated text categorization | Cluster analysis, 3rd edition",rejected,000
1211.5829.pdf.json,,"Extracting the points from an image that can give best define from an object in image namely keypoints is very important and valuable. These points have many applications in image processing like object detection, object and shape recognition, image registation and object tracking. By extracting the keypoints, we can use them for finding objects in the other images. Detect and recognize the object by using the keypoints and a segmentation algorithm is very accurate because if the keypoints are correctly identified, they achieve the best information from the image. ASIFT is a fully affine invariant method with respect to six parameters of affine transform [1,2], wherease the previous method SIFT was invariant with respect to four parameters namely translation, rotation and change in scale (zoom) [3]. ASIFT cover two other parameters namely longitude and latitude angle that are relevant to camera axis orientation. It means that ASIFT is more effective for our goal and can be more robust in the changes of images. Many image segmentation and object recognition algorithms have been presented, each having its own specifications [4,5]. Some of these algorithm are interactive image segmentation based on region merging [6,7]. One of them is a powerful algorithm [8] for detecting object and its boundary but it is not an automatic algorithm and has a problem. In this algorithm the users must indicate some of locations and regions of the background and object to run the algorithm. In this paper, we combined ASIFT results and a region merging algorithm to recognize objects in images and detect them with full boundary. The presented algorithm does not have the stated problem in region merging algorithm. It means that, the algorithm does not need to indicate regions by user. We use the best keypoints of object that has been obtained from ASIFT results and apply them into the image. Therefore, the method will be an automatic algorithm and will not need marks by users and the achiev",,rejected,000
1211.6205.pdf.json,Neuro-Fuzzy Computing System with the Capacity of Implementation on Memristor-Crossbar and Optimization-Free Hardware Training,,"Hardware implementation of an artificial neural network using field programmable gate arrays (FPGA’s) | Direct Neural-Network Hardware-Implementation Algorithm | A fuzzy neural network model and its hardware implementation | The missing memristor found | Memristor - the missing circuit element | From synapses to circuitry: Using memristive memory to explore the electronic brain | Nanoscale Memristor Device as Synapse in Neuromorphic Systems | Short-Term Memory to Long-Term Memory Transition in a Nanoscale Memristor | Memristor Crossbar-Based Hardware Implementation of the IDS Method | Memristive Neuro- Fuzzy System | Adaptive Resonance Theory Design in Mixed Memristive-Fuzzy Hardware | A neuronal learning rule for sub-millisecond temporal coding | Neural Synaptic Weighting With a Pulse-Based Memristor Circuit | Hebbian Learning in Spiking Neural Networks With Nanocrystalline Silicon TFTs and Memristive Synapses | Implementation of biologically plausible spiking neural network models on the memristor crossbar-based CMOS/nano circuits | Memristor Bridge Synapse-Based Neural Network and Its Learning | The organization of behavior | Digital Logic Circuit Analysis and Design | Fundamentals of Neural Networks: Architectures, Algorithms and Applications | Flexible Neuro-Fuzzy Systems: Structures, Learning and Performance Evaluation | Reconfigurable nano-crossbar architectures | Memristive devices and systems | High-precision tuning of state for memristive devices by adaptable variation-tolerant algorithm | Time-dependency of the threshold voltage in memristive devices | Regression modeling in back-propagation and projection pursuit learning | Objective functions for training new hidden units in constructive neural networks | Constructive feedforward neural networks using Hermite polynomial activation functions | A study on the modeling ability of the IDS method: A soft computing technique using pattern-based information processing | ANFIS:Adaptive-Network-based Fuzzy Inference Systems",rejected,000
1211.6898.pdf.json,On the Use of Non-Stationary Policies for Stationary Infinite-Horizon Markov Decision Processes,"Given an infinite-horizon stationary γ-discounted Markov Decision Process [24, 4], we consider approximate versions of the standard Dynamic Programming algorithms, Policy and Value Iteration, that build sequences of value functions vk and policies πk as follows Approximate Value Iteration (AVI): vk+1 ← Tvk + ǫk+1 (1) Approximate Policy Iteration (API): { vk ← vπk + ǫk πk+1 ← any element of G(vk) (2) where v0 and π0 are arbitrary, T is the Bellman optimality operator, vπk is the value of policy πk and G(vk) is the set of policies that are greedy with respect to vk. At each iteration k, the term ǫk accounts for a possible approximation of the Bellman operator (for AVI) or the evaluation of vπk (for API). Throughout the paper, we will assume that error terms ǫk satisfy for all k, ‖ǫk‖∞ ≤ ǫ for some ǫ ≥ 0. Under this assumption, it is well-known that both algorithms share the following performance bound (see [25, 11, 4] for AVI and [4] for API): Theorem 1. For API (resp. AVI), the loss due to running policy πk (resp. any policy πk in G(vk−1)) instead of the optimal policy π∗ satisfies lim sup k→∞ ‖v∗ − vπk‖∞ ≤ 2γ (1− γ)2 ǫ. The constant 2γ(1−γ)2 can be very big, in particular when γ is close to 1, and consequently the above bound is commonly believed to be conservative for practical applications. Interestingly, this very constant 2γ(1−γ)2 appears in many works analyzing AVI algorithms [25, 11, 27, 12, 13, 23, 7, 6, 20, 21, 22, 9], API algorithms [15, 19, 16, 1, 8, 18, 5, 17, 10, 3, 9, 2] and in one of their generalization [26], suggesting that it cannot be improved. Indeed, the bound (and the 2γ(1−γ)2 constant) are tight for API [4, Example 6.4], and we will show in Section 3 – to our knowledge, this has never been argued in the literature – that it is also tight for AVI. Even though the theory of optimal control states that there exists a stationary policy that is optimal, the main contribution of our paper is to show that looking for a non-stationary policy (instead o",Cs | Dynamic Policy Programming with Function Approximation | Approximate policy iteration: a survey and some new methods | Neuro-Dynamic Programming | Leastsquares methods for Policy Iteration | Tree-based batch mode reinforcement learning | Planning in pomdps using multiplicity automata | Cs | Error propagation for approximate policy and value iteration (extended version) | Classification-based Policy Iteration with a Critic | Stable Function Approximation in Dynamic Programming | Max-norm projections for factored MDPs | Efficient Solution Algorithms for Factored MDPs | On the Sample Complexity of Reinforcement Learning | Approximately Optimal Approximate Reinforcement Learning | Least-squares policy iteration | Finite-Sample Analysis of Least-Squares Policy Iteration | Finite Sample Analysis of Bellman Residual Minimization | Error Bounds for Approximate Policy Iteration | Performance Bounds in Lp norm for Approximate Value Iteration | Finite time bounds for sampling based fitted value iteration | Biasing Approximate Dynamic Programming with a Lower Discount Factor | Point-based value iteration: An anytime algorithm for POMDPs | Markov Decision Processes | An Upper Bound on the Loss from Approximate Optimal-Value Functions | Least-Squares λ Policy Iteration: Bias-Variance Trade-off in Control Problems | Feature-Based Methods for Large Scale Dynamic Programming,rejected,000
1211.6971.pdf.json,A New Automatic Method to Adjust Parameters for Object Recognition,,"S.Jacob, “Parameter Optimization of an Image Processing System using Evolutionary Algorithms | A Reinforcement Learning Framework for Parameter Control in Computer Vision Applications | AG: “Reinforcement Learning | Q-Learning”. Machine Learning | Artificial intelligence: a modern approach | Introduction to Reinforcement Learning | Textural Features for Image Classification | Application of reinforcement learning for segmentation of transrectal ultrasound images",rejected,000
1212.0059.pdf.json,Artificial Neural Network Fuzzy Inference System (ANFIS) For Brain Tumor Detection,,"Image processing,Analysis, and Machine Vision, II Edition, Vikas Publishing | Neural Network Fundamentals with Graphs, Algorithms, and Applications, Edition ,TMH, India | Digital ImageProcessing, II Indian Edition, Pearson Education, New Delhi,India | Deformable region model for locating the boundary of brain tumors | A computer-aided diagnosis for locating abnormalities in bone scintigraphy by fuzzy system with a three-step minimization approach | An object-based approach for detecting small brain lesions:Application to Virchow-robin spaces | F.Threedimensional segmentation of MR images of the head using probability and connectivity | Multispectral magnetic resonance image analysis | etal.: Statistical structure analysis in MRI brain tumor",rejected,000
1212.0079.pdf.json,,"The concept of permission plays an important role in many normative domains in that it may be crucial in characterising notions such as those of authorisation and derogation [11,30,33]. For example, sometimes it may happen that we mistakenly drive to a building site, or a road-work restricted area, with signs out saying “No admittance. Authorised personnel only”. Or consider when we subscribe to an on-line sale agreement accepting to enter our personal data on the condition that this information is only used for shipping, and other necessary purposes to communicate with us or deliver the products to us. In both cases, a permission (to enter a restricted area or to use our personal data) is stated as an exception to a general prohibition. Despite this fact, the concept of permission is still elusive in this field of literature and has not been extensively investigated in deontic logic as the notion of obligation. For a long time, deontic logicians mostly viewed permission as the dual of obligation: Pa ≡ ¬O¬a. This view is unsatisfactory, as it hardly allows us to grasp the meaning of examples like the ones previously mentioned. For this, and other reasons, the attempt to reduce permissions to duals of obligations has been criticised (see [2,1]). One important distinction that has traditionally contributed to a richer account of this concept is the one between weak (or negative) and strong (or positive) permission [35]. The former corresponds to saying that some a is permitted if ¬a is not provable as mandatory. In other words, something is allowed by a code iff(only when) it is not prohibited by that code. At least when dealing with unconditional obligations, the notion of weak permission is trivially equivalent to the dual of obligation [25]. The latter concept of strong permission is more complicated, as it amounts to saying that some a is permitted by a code iff such a code explicitly states that a is permitted. It follows that a strong permission is not derived f","Alchourrón. Philosophical foundations of deontic logic and the logic of defeasible conditionals | Permission and permissive norms | The expressive conception of norms. In Risto Hilpinen, editor, New Studies in Deontic Logic, pages 95–125 | On balancing and subsumption. a structural comparison | Representation results for defeasible logic | A family of defeasible reasoning logics and its implementation | Defeasible logic is stable | Teoria della norma giuridica | Permissions and obligations in hierarchical normative systems | Permissions and undercutters | Permission and authorization in normative multiagent systems | Conditional obligation and positive permission for agents in time | Permissive norms and normative systems | Logic of violations: A gentzen system for reasoning with contrary-to-duty obligations | Justice delayed is justice denied: Logics for a temporal account of reparations and legal compliance | Three concepts of defeasible permission | A defeasible logic for modelling policy-based intentions and motivational attitudes | Possible world semantics for defeasible deontic logic | Temporalised normative positions in defeasible logic | The journey to business process compliance | Rule based business process compliance | What are the Necessity Rules in Defeasible Reasoning | Propositional defeasible logic has linear complexity | Input-output logics | Permission from an input/output perspective | On a fundamental problem of deontic logic | Normative systems, permission and deontic logic | Directives and norms | The logic of enactment | Legal Reasoning: A Cognitive Approach to the Law | Doing justice to rights and values: teleological reasoning and proportionality | Relevance, derogation and permission | A theory of permission based on the notion of derogation | Norm and action: A logical inquiry",rejected,000
1212.0582.pdf.json,Compositional Stochastic Modeling and Probabilistic Programming,"Programming languages typically have semantics that is compositional, deterministic, and defined in discrete time and space. “Probabilistic programming” (PP) proposes to change the “deterministic” part of this description. If one also changes the “discrete time” part of this description, allowing continuous time which is more natural for most scientific applications, we arrive at a class of computational modeling languages rather than programming languages: compositional stochastic modeling (CSM) languages. Such languages have many attractive features for modeling real-world processes: a close match of computational and physical semantics, a systematic way to derive algorithms for sampling, inference, and model reduction, and relevance to new vistas in biocomputing and abstract mathematics, among others. Unfortunately the jump between continuous and discrete time seems like a large one – even more so if continuous space is also admitted for modeling purposes. On the other hand conventional computational “engines” are possible for such languages, so perhaps the gap can be closed. What would the consequences be of taking CSM as a model of computation? Obviously such a model would be probabilistic. How can it be related to probabilistic programming, to their mutual enrichment? After a brief review of one approach to CSM, we discuss various points that bear on these questions, and then address the applications that may benefit from CSMs.","Stochastic Process Semantics for Dynamical Grammars | Stochastic Parameterized Grammars: Formalization, Inference, and Modeling Applications | A process algebra master equation | Time-Ordered Product Expansions for Computational Stochastic Systems Biology | Parameter inference for discretely observed stochastic kinetic models using stochastic gradient descent | A Note on the Physical Possibility of Ordinal Computation | Dependency Diagrams and Graph-­‐Constrained Correlation Dynamics: New Systems for Probabilistic Graphical Modeling | Continuous time Bayesian networks | Expectation maximization and complex duration distributions for continuous time Bayesian networks | CTPPL: A Continuous Time Probabilistic Programming Language | Rules for modeling signal-transduction systems. Science’s STKE 2006:re6 | Rule-based modelling of cellular signaling | DOLFIN: Automated Finite Element Computing | All Compact Hausdorff Lambda Models are Degenerate”, Fundamenta Informaticae",rejected,000
1212.0768.pdf.json,AN ONTOLOGY-BASED APPROACH TO RELAX TRAFFIC REGULATION FOR AUTONOMOUS VEHICLE ASSISTANCE,"Imagine that you are driving your car and that a truck is before you on the street, engine stopped, rear door open and unloading furniture for some close apartment. Since your car’s lane is delimited by a continuous line and a sidewalk, you must not overtake according to the traffic regulation. You are then condemned to wait until the truck has finished unloading, a process which might keep you stopped for an uncertain, probably long, amount of time. To take a second example, imagine that you are about to reach a roundabout, but that the car before yours on the lane has stopped, probably with an engine problem, e.g., electric power cut. Here again, since this lane is delimited by a continuous line and a sidewalk, strict respect of traffic regulation condemns you to wait behind the defective car until that car can move again, a process which might probably be counted in hours. Many similar practical situations can be imagined, or taken from every driver’s experience. Human drivers can cope with such abnormal situations. For example, after having waited for some amount of time, a human driver might decide to cross the continuous line: He checks for the absence of vehicles on the adjacent opposite lane, makes a small left turn, crosses the continuous line, overtakes the unloading truck or the defective car, drives a few meters on the adjacent lane, and comes back to its initial lane once the obstacle is passed. Alternatively, the driver could decide to slowly run on the sidewalk to overtake the stopped truck / defective car. Strictly speaking, traffic regulation is violated indeed: The French road traffic regulation states that “vehicles must circulate on roadways, except in case of absolute emergency” (section R412-7 [8] for France, [6] for an international definition). But in practice, given the above unusual circumstances, no one will blame a driver for safely crossing the above continuous line after having waited for a reasonable amount of time. Perhaps even a poli","A Scheme for Coordinating Multi-Robot Planning Activity and Plans Execution | Situation awareness of drivers : fondamental aspects, methods and application to driver training (« Conscience de la situation des conducteurs : aspects fondamentaux, méthodes et application pour la formation des conducteurs ») | Benchmarking OWL reasoners | A VANET-based Emergency Vehicle Warning System | Automated Planning : Theory and Practice | A Translation Approach to Portable Ontology Specifications | SWRL: A Semantic Web Rule Language Combining OWL and RuleML | Traffic Intersection Situation Description Ontology for Advanced Driver Assistance | The Century of Intelligent Car (“Le siècle de la voiture intelligente”) | Vehicle Traffic Congestion Management in Vehicular ad-hoc Networks | Mobility Modeling, Spatial Traffic Distribution, and Probability of Connectivity for Sparse and Dense Vehicular Ad Hoc Networks | A Novel Approach to Reduce Traffic Chaos in Emergency and Evacuation Scenarios",rejected,000
1212.1570.pdf.json,,,"An Architecture for Action Selection in Robotic Soccer. AGENTS’01 | RoboCup­99: Robot Soccer World Cup III, Springer­Verlag, Brelin | Soccer server: A tool for research on multi Agent systems | Advanced Multi­Agent Fuzzy Reinforcement Learning | Training a Simulated Soccer Agent how to Shoot using Artificial Neural Networks | A thesis for Master of Science in Engineering Physics | An Improved Fuzzy Mechanism for 3D Soccer Player Agent’s Shoot Skill | Context speci ̄c multiagent coordination and planning with factored MDPs | RoboCup 3D Simulator ­ FC Portugal user’s guide, http://www.ieeta.pt/robocup/archive.htm | Coordination among Heterogeneous Robotic Soccer Players | Task decomposition, dynamic role assignment and low bandwidth communication for real time strategic team work",rejected,000
1212.1625.pdf.json,Testing the AgreementMaker System in the Anatomy Task of OAEI 2012,"AgreementMaker is a powerful, flexible and extensible system for matching ontologies and schemas that has been in development since 2001 [1]. Originally focused on geospatial applications, AgreementMaker has since been expanded to include many types of matching algorithms and thus handle diverse applications. In addition to its use in practical applications, the AgreementMaker system has been tested in the Ontology Alignment Evaluation Initiative (OAEI) competition. The development of AgreementMaker focused in particular on the anatomy task, which is a real world application consisting in matching the Adult Mouse Anatomy and the NCI Thesaurus describing the human anatomy. In this task, AgreementMaker was the best performing system, both in OAEI 2010 and OAEI 2011. While the AgreementMaker system did not compete in the OAEI 2012, here we report on its performance in the 2012 anatomy task, using the configurations used for OAEI 2011 [2]. Additionally, since one of the matching algorithms used in OAEI 2011 uses UBERON [3] as a mediating ontology, we also tested AgreementMaker with an updated version of UBERON.","AgreementMaker: efficient matching for large real-world schemas and ontologies | Using AgreementMaker to align ontologies for OAEI | Uberon, an integrative multi-species anatomy ontology | GOMMA results for OAEI | Preliminary results of the ontology alignment evaluation",rejected,000
1212.1798.pdf.json,"IK-PSO, PSO Inverse Kinematics Solver with Application to Biped Gait Generation","A legged system is a robotic system that has a specific mission, ensuring locomotion. Such a system could be analyzed from its kinematics aspects and also its dynamics aspects. The kinematics aspects are centered on the joints motions, constraints and limits. Forward kinematics is the mathematical relationship between the end segments of an articulated system and its joints motions. In inverse kinematics, the problem consists of computing the needed joints motion s leading a known end segment position [1]. Biped robots are specific robotic system that combines open and close kinematics chains; in biped locomotion two key phases are important, the double support phase and the single support phase also known as stance phase and swing phase. In double support both legs are in contact with the flow the obtained articulated body tend to move its COM, Centre of mass, position to prepare the next step, in single support or swing phase a leg is used as a support while the opposite one swings forwards, this motion causes the displacement of the COM in the same direction of the swing, when the swing leg is once again in contact with the floor the COM is placed on its surface and that gives a forward step. The forward kinematics model of a robot could be simply obtained using the classical Denavit-Hartenberg method [2], while the inverse kinematics problem is little bit more complex. A classical approach to inverse kinematics consist in in writing the inverse mathematical formulation of the forward model, This approach is know to be time and memory consuming. The classical inverse modeling process based on geometric [3], algebraic or iterative methods is limited if the system structure is complex [4]. Many alternative methods are proposed to solve inverse kinematics problem. To tackle the inverse kinematics modeling an ANFIS (adaptive neuro fuzzy inference system) methodology were introduced in [5]. Basically, ANFIS methods used a set of data representing the end points of an ","Simulation kinematics model of a multi-legged mobile robot | A robotics toolbox for MATLAB | A new geometrical approach to solve inverse kinematics of hyper redundant robots with variable link length | Inverse kinematic algorithms for redundant systems | Neuro-Fuzzy based Approach for Inverse Kinematics solution of Industrial Robot Manipulators | Inverse kinematics of redundant robots using genetic algorithms | Evolutionary algorithms in kinematic design of robotic systems | Multi-objective optimization in gait planning of biped robot using genetic algorithm and particle swarm optimization tool | On the Stability of Biped Locomotion | Toward Intelligent Biped-Humanoids Gaits Generation | A kinematics notation for lower-pair mechanisms based on matrices | Particle swarm optimization | A modified particle swarm optimizer | Ant supervised by PSO | Architectural Proposal for a Robotized Intelligent humanoid, IZiman | Benbousasa and A.M ALIMI | From GAITS TO ROBOT, A HYBRID METHODOLOGY FOR A BIPED WALKER | Biped robot control using particle swarm optimization | Prototyping a Biped Robot Using an Educational Robotics Kit",rejected,000
1212.2005.pdf.json,The Dynamic Controllability of Conditional STNs with Uncertainty,"Workflow systems have been used to model business, manufacturing and medical-treatment processes. However, as Bettini et al. (2002) observed: “It would greatly enhance the capabilities of current workflow systems if quantitative temporal constraints on the duration of activities and their synchronization requirements can be specified and reasoned about.” Toward that end, Combi et al. (2007; 2009; 2010) presented a new workflow model that accommodates the following key features: tasks with uncertain/uncontrollable durations; temporal constraints among tasks; and branching paths, where the branch taken is not known in advance. Fig. 1 shows a sample workflow from the health-care domain, similar to one presented by Combi and Posenato (2009). In this workflow, all times are in minutes, and: • tasks are represented by rounded boxes; • branching points are represented by nine-sided boxes called split or join connectors1; • tasks and connectors have duration attributes, [x, y]; ∗Funded in part by the Phoebe H. Beadle Science Fund. Copyright c© 2012, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. 1Combi and Posenato (2009) used diamonds for connectors. • the flow, represented by solid arrows moving downward, specifies a partial order among tasks and connectors; • intervals between consecutive tasks or connectors—called delays—are bounded by intervals of the form [x, y]; • additional temporal constraints are represented by dashed arrows, also labeled by intervals of the form [x, y]. The S and E notations on temporal constraints are used to indicate whether a constraint applies to the starting or ending times of the tasks/connectors it links. For example, the notation S[136, 150]E on the arrow from T4 to T5 indicates that the duration of the interval from the start of T4 to the end of T5 must be in the range, [136, 150]. The tasks and their uncontrollable durations are: T1: Pre-hospital issues, 2–4 min. T2: Initial patient evalu","Temporal reasoning in workflow systems | Controllability in temporal conceptual workflow schemata | Towards temporal controllabilities for workflow schemata | Conceptual modeling of temporal clinical workflows | Drake: An efficient executive for temporal plans with choice | Flexible execution of plans with choice and uncertainty | Temporal constraint networks | Fixing the semantics for dynamic controllability and providing a more practical characterization of dynamic execution strategies | Dynamic control of plans with temporal uncertainty | A structural characterization of temporal dynamic controllability | CTP: A new constraint-based formalism for conditional, temporal planning",rejected,000
1212.2056.pdf.json,,"Classical constraint satisfaction problems (CSPs) [12] represent an expressive and natural formalism useful to specify different types of real-life problems. A CSP can be described as a set of variables associated with a domain of values, and a set of constraints. A constraint is a limitation of the possible combinations of the values of some variables. So, solving a CSP consists in finding an assignment of values to all its variables guaranteeing that all constraints are satisfied. Despite their applicability, the main limit suffered by CSPs is the ability of just stating if an assignment of certain values to the variables is allowed or not. This is indeed not enough to model scenarios where the knowledge is not either entirely available or not crisp. In these cases constraints are preferences and, when the problem is overconstrained, one would like to find a solution that is not so bad, i.e., the best solution according to the levels of preferences. For this reason, in [2,3], the soft CSP framework has been proposed. It extends classical constraints by adding to the usual notion of CSP the concept of a structure representing the levels of satisfiability or the costs of a constraint. Such a structure is represented by a semiring, that is, a set with two operations: one (usually denoted by +) is used to generate an ordering over the levels, while ⋆ Research partially supported by the EU FP7-ICT IP ASCEns. the other one (denoted by ×) is used to define how two levels can be combined and which level is the result of such a combination. Constraint logic programming (CLP) [10] extends logic programming (LP) by embedding constraints in it: term equalities is replaced with constraints and the basic operation of LP languages, the unification, is replaced by constraint handling in a constraint system. It therefore inherits the declarative approach of LP, according to which the programmer specifies what to compute while disregarding how to compute it, by also offering effici","Constraint logic programming using Eclipse | Constraint solving over semirings | Semiring-based constraint satisfaction and optimization | Semiring-based contstraint logic programming: syntax and semantics | Unicast and multicast QoS routing with soft-constraint logic programming | The ciao prolog system | Cc-pi: A constraint-based language for specifying service level agreements | About permutation algebras, (pre)sheaves and named sets | Electric vehicle travel optimization - customer satisfaction despite resource constraints | Constraint logic programming | Perfect relaxation in constraint logic programming | Foundations of constraint satisfaction",rejected,000
1212.2262.pdf.json,Bag-of-words Representation for Biomedical Time Series Classification,,"Entropies for detection of epilepsy in EEG, | Automatic epileptic seizure detection in EEGs based on line length feature and artificial neural networks, | Epileptic EEG classification based on extreme learning machine and nonlinear features, | Brain computer interfaces for communication and control, | Multiclass filters by a weighted pairwise criterion for EEG single-trial classification, | A feature selection method for multilevel mental fatigue EEG classification, | A generic and robust system for automated patient-specific classification of ECG signals, | Heartbeat time series classification with support vector machines, | Recurrent neural networks for time series | Classification of the electrocardiogram signals using supervised classifiers and efficient features, | Rotation-invariant similarity in time series using bag-of-patterns representation, | The locally weighted bag of words framework for document representation, | Latent dirichlet allocation, | A bayesian hierarchical model for learning natural scene categories, | Unsupervised learning of human action categories using spatial-temporal words, | Creating efficient codebooks for visual recognition, | Supervised learning of gaussian mixture models for visual vocabulary generation, | A new metric for probability distributions, | The pyramid match kernel: Efficient learning with sets of features, | ECG analysis: a new approach in human identification, | Human identification by quantifying similarity and dissimilarity in electrocardiogram phase space, | Indications of nonlinear deterministic and finite-dimensional structures in time series of brain electrical activity: dependence on recording region and brain state. | A review on time series data mining, | Classification of epileptiform EEG using a hybrid system based on decision tree classifier and fast fourier transform, | Automatic detection of epileptic seizures in EEG using discrete wavelet transform and approximate entropy,",rejected,000
1212.2314.pdf.json,Tree Projections and Structural Decomposition Methods: Minimality and Game-Theoretic Characterization,,"Marshals, monotone marshals, and hypertree-width | Width Functions for Hypertree Decompositions | Tree-Related Widths of Graphs and Hypergraphs | Hypertree-Width and Related Hypergraph Invariants | On the Power of k-Consistency | The power of natural semijoins | A Linear-Time Algorithm for Finding Tree-Decompositions of Small Treewidth | A unified theory of structural tractability for constraint satisfaction problems | Tree clustering for constraint networks | Degrees of acyclicity for hypergraphs and relational database schemes | Connected Treewidth and Connected Graph Searching | Complexity of K-tree structured constraint satisfaction problems | A Comparison of Structural CSP Decomposition Methods | Hypertree decompositions and tractable queries | Robbers, marshals, and guards: game theoretic and logical characterizations of hypertree width | Generalized hypertree decompositions: NP-hardness and tractable variants | Syntactic characterization of tree database schemas | The tree projection theorem and relational query processing | Tree Projections: Hypergraph Games and Minimality | Structural Tractability of Enumerating CSP Solutions | Tree Projections and Structural Decomposition Methods: The Power of Local Consistency and Larger Islands of Tractability | The complexity of homomorphism and constraint satisfaction problems seen from the other side | Constraint solving via fractional edge covers | Acyclic hypergraph projections | Tractable Hypergraph Properties for Constraint Satisfaction and Conjunctive Queries | Graph minors III: Planar tree-width | Solving Queries by Tree Projections | Graph searching and a min-max theorem for tree-width | Backtracking Procedures for Hypertree, HyperSpread and Connected Hypertree Decomposition of CSPs",rejected,000
1212.2614.pdf.json,A Study on Fuzzy Systems,"A system is a set of interacting or interdependent components forming an integrated whole. A system comprises multiple views such as planning, analysis, design, implementation, deployment, structure, behavior, input and output data, etc. As an interdisciplinary and multiperspective domain systems’ theory brings together principles and concepts from ontology, philosophy of science, information and computer science, mathematics, as well as physics, biology, engineering, social and cognitive sciences, management and economics, strategic thinking, fuzziness and uncertainty, etc. Thus, it serves as a bridge for an interdisciplinary dialogue between autonomous areas of study. The emphasis with systems’ theory shifts from parts to the organization of parts, recognizing that interactions of the parts are not static and constant, but dynamic processes. Most systems share common characteristics including structure, behaviour, interconnectivity (the various parts of a system have functional and structural relations to each other), sets of functions, etc. We scope a system by defining its boundary; this means choosing which entities are inside the system and which are outside, part of the environment. The systems’ modelling is a basic principle in engineering, in natural and in social sciences. When we face a problem concerning a system’s operation (e.g. maximizing the productivity of an organization, minimizing the functional costs of a company, etc) a model is required to describe and represent the system’s multiple views. The model is a simplified representation of the basic characteristics of the real system including only its entities and features under concern. In this sense, no model of a complex system could include all features and/or all entities belonging to the system. In fact, in this way the model’s structure could become very complicated and therefore its use in practice could be very difficult and sometimes impossible. Therefore the construction of the model usu","Fuzzy Sets, Uncertainty and Information | Principles of Uncertainty: What are they? Why do we mean them? | Measuring the student group capacity for obtaining geometric information in the van Hiele development thought process: A fuzzy approach | Using Fuzzy Sets to Determine the Continuity of the van Hiele Levels | Decision, Order and Time in Human Affairs | A mathematical theory of communications | Application of Fuzzy Logic to Learning Assessment”, Didactics of Mathematics: Problems and Investigations | Fuzzy logic and the concept of the Zone of Proximate Development”, Didactics of Mathematics: Problems and Investigations | Operations Research – An Introduction | Fast and accurate centre of gravity defuzzification of fuzzy system outputs defined on trapezoidal fuzzy partitions | Measuring mathematical model building abilities | The process of learning mathematics: A fuzzy set approach | A stochastic model for the modelling process”, In Mathematical Modelling: Education, Engineering and Economics, C | Fuzzy Sets in Case-Based Reasoning | Gr., “Stochastic and fuzzy models in Mathematics Education, Artificial Intelligence and Management”, Lambert Academic Publishing, Saarbrucken, Germany, 2011 (for more details look at http://amzn.com./3846528218 | Fuzzy Models for Analogical Reasoning | Fuzzy Sets",rejected,000
1212.2657.pdf.json,,"The configuration problem consists in finding a sequence of actions required to assemble a target artifact from a set of components of predefined types. All allowed components types, their attributes and possible relations between components are specified as configuration constraints. In addition, configuration constraints put restrictions on sets of related components required by the design of the target artifact such as a product or a service. The customization of an artifact required by the customer is formulated as customer requirements. Often these requirements can also capture customer preferences for a solution of the configuration problem. In this case the best solutions (configurations) are determined by an objective function specified in the configuration requirements. In their nature configuration problems are combinatorial (optimization) problems. In order to find a configuration a solver has to instantiate a number of components of a some type and each of these components can be used in a relation defined for a type. Therefore, many solutions of a configuration problem have symmetric ones which can be obtained by replacing some component of a solution by another one of the same type. These symmetric solutions decrease performance of optimization algorithms because of two reasons: a) they satisfy all requirements and cannot be pruned out from the search space; and b) existence of symmetric optimal solutions does not allow to prove the optimum in feasible time. ar X iv :1 21 2. 26 57 v1 [ cs .A I] 1 1 D ec 2 01 2",Solving difficult instances of boolean satisfiability in the presence of symmetry | Efficient Symmetry Breaking for Boolean Satisfiability | Symmetry-breaking Answer Set Solving | Re)configuration using Answer Set Programming | Groups and Constraints: Symmetry Breaking during Search | Engineering an Efficient Canonical Labeling Tool for Large and Sparse Graphs | Handbook of Satisfability | Lparse 1.0 User Manual | General symmetry breaking constraints,rejected,000
1212.2671.pdf.json,Performance Analysis of ANFIS in short term Wind Speed Prediction,,"A new strategy for wind speed forecasting using artificial intelligent methods, Renewable Energy 34(2009):845-848 | Short term wind speed forecasting  in La Venta, Oaxaca, México, using artificial neural networks | Shaahhid, Modeling and forecasting the mean hourly wind speed time series using GMDH-based abductive networks | Accurate short term Wind speed prediction by exploiting diversity in input data using Banks of artificial neural networks | Fuzzy Modeling Using Generalized Neural Networks and Kalman Filter Algorithm, | ANFIS: Adaptive-Network-based Fuzzy Inference Systems, | Neural network application for direct feedback controllers | Distributed  representation of fuzzy rules and its application to pattern classification | Selecting fuzzy If-Then rules for classification problems using genetic algorithms | Artificial Intelligence: A Modern Approach, 2nd edn | Com- binations of genetic algorithms and neural networks: a sur- vey of the state of the art | Using single layered neural net- works for the extraction of conjunctive rules | Fuzzy Logic and NeuroFuzzy Appli- cations in Business and Finance | Computing with words - A paradigm shift | FPGA-based implementation of intelligent predictor for global solar irradiation, Part I: Theory and simulation | Artificial Intelligence: A Guide to Intelligent Systems, Michael Negnevitsky, 2da edicion, ed",rejected,000
1212.2958.pdf.json,"Spike and Tyke, the Quantized Neuron Model",,"Synaptic modification of correlated activity: Hebb’s postulate revisited | Spiking Neuron Models | Hebbian learning and spiking neurons | Mathematical formulations of hebbian learning | Learning input correlations through nonlinear temporally asymmetric hebbian plasticity | Fundamental of computational neuroscience | Nanoscale Memristor Device as Synapse in Neuromorphic Systems | STDP CMOS and Memristor Based Neural Network Design for Position Detection | Experimental Demonstration of Associative Memory with Memristive Neural Networks | A VLSI array of low-power spiking neurons and bistable synapses with spike-timing dependent plasticity | Total regional and global number of synapses in the human brain neocortex | The missing memristor found | The elusive memristor: properties of basic electrical circuits | Which model to use for cortical spiking neurons? | A quantitative description of membrane current and application to conduction and excitation in nerve | Simple model of spiking neurons | Spatiotemporal correlations and visual signaling in a complete neuronal population | A characterization of the timerescaled gamma process as a model for spike trains | Optimizing Time Histograms for Non-Poissonian Spike Trains | Statistical Physics"", 2 Edition, pages 250-256 | Introduction to Quantum Mechanics (Manchester Physics Series) | The dynamics of free calcium in dendritic spines in response to repetitive synaptic | Synaptic activity and the construction of cortical circuits",rejected,000
1212.3996.pdf.json,Increasing Air Traffic: What is the Problem?,,Mathematical Optimizationg Models for Air Traffic Flow Management: A Review | The Flow Management Problem in Air Traffic Control | Dynamic Solution to the Ground-Holding Problem in Air Traffic Control | A Dynamic Stochastic Model for the Single Airport Ground Holding Problem | The Multi-Airport Ground- Holding Problem in Air Traffic Control | The Air Traffic Flow Management Problem with Enroute Capacities | An Integer Optimization Approach to Large-Scale Air Traffic Flow Management | On Air Traffic Flow Management with Rerouting. Part I: Deterministic Case | On Air Traffic Flow Management with Rerouting. Part II: Stochastic Case | Air Traffic Management by Stochastic Optimization | Slot Allocation with Constraint Programming: Models and Results | Air-Traffic Complexity Resolution in Multi-Sector Planning using Constraint Programming | Optimal Path Planning for Air Traffic Flow Management under Stochastic Weather and Capacity Constraints | Modeling and Optimization in Traffic Flow Management | Eulerian Trilogy | Probabilistic Graphical Models: Principles and Techniques | An Introduction to MCMC for Machine Learning,rejected,000
1212.3998.pdf.json,Online Learning for Ground Trajectory Prediction,,"Energy Rate Prediction Using an Equivalent Thrust Setting Profile | Programmation évolutionnaire appliquée à la prévision de trajectoire | Climb trajectory prediction enhancement using airline flight-planning information | Combining Monte Carlo and worst-case methods for trajectory prediction in air traffic control: a case study | Analyse Numerique pour ingenieurs, 4ed | Trajectory Computation Infrastructure | A Stochastic Hybrid Model for Air Traffic Control Simulation | Prédiction de trajectoires d’avions à l’aide de la régression floue | Benchmarking a BI-Population CMA-ES on the BBOB- 2009 Function Testbed | References to CMA-ES Applications | Comparison of Evolutionary Algorithms on a Benchmark Function Set. CEC’05 | Comparing Results of 31 Algorithms from the Black-Box Optimization Benchmarking BBOB-2009 | Reducing the Time Complexity of the Derandomized Evolution Strategy with Covariance Matrix Adaptation (CMA-ES) | Adapting Arbitrary Normal Mutation Distributions in Evolution Strategies: The Covariance Matrix Adaption | Completely Derandomized Self- Adaptation in Evolution Strategies | The CMA Evolution Strategy: A Tutorial | Fundamentals of Airplane Flight Mechanics | Hybrid Optimal Control for Aircraft Trajectory Design with a Variable Sequence of Modes | Using Neural Networks to predict aircraft trajectories | Hybrid Systems: Foundations, Advanced Topics and Applications | Literature Survey of Trajectory Predictor Technology | BBOB workshop, volume 12th Annual Genetic and Evolutionary Computation Conference GECCO 2010 Companion Publication | Evolutionstrategie: Optimierung Technisher Systeme nach Prinzipien des Biologischen Evolution | Numerical Optimization of Computer Models | Common Trajectory Prediction Capability for Decision Support Tools",rejected,000
1212.5461.pdf.json,Interactive Ant Colony Optimization (iACO) for Early Lifecycle Software Design,"Software design is both fundamental to the successful development of softwareintensive systems and cognitively demanding for software engineers to perform. Indeed, in early-lifecycle software design, designers wrestle with numerous tradeoff judgments as they formulate candidate design solutions as a basis for subsequent down-stream development activities. In an attempt to assist the software designer, interactive meta-heuristic search techniques such as evolutionary algorithms (EAs) with the software designer ‘in-the-loop’ have been recently studied and show promising results. After early empirical investigations incorporating designer preferences in search [1], [2], subsequent studies have combined quantitative machine-calculated fitness functions with qualitative designer evaluation of design elegance in a dynamic, multi-objective, interactive search [3]. These studies show that the precise balance of factors affecting the subjective judgments of the human software designer is highly significant but poorly understood – hence the oft-heard references to the “art” of software design. Interestingly, however, recent investigations comparing different meta- heuristic search approaches have shown that ant colony optimization (ACO) can outperform evolutionary computation in quantitative search with respect to arriving at design solution candidates of superior fitness at earlier iterations / generations [4], [5]. This suggests that as an engine for interactive search, ACO has great potential. One major contribution of this paper is to exploit this potential by surveying a range of approaches to interactive multi-objective search, and then making an informed proposal for interactive ACO (iACO) for software design (Section 3). To evaluate the proposal, we describe the experimental methodology for an empirical study involving a number of software engineers in three case studies of early lifecycle software design (Section 4). Results of empirical investigations are presented ","An Empirical Investigation of Search-based Computational Support for Conceptual Software Engineering Design | Interactive, Evolutionary Search in Upstream Object-oriented Software Design | Elegant, Object-Oriented Software Design via Interactive Evolutionary Computation | A Comparison of Evolutionary Algorithms and Ant Colony Optimisation for Interactive Software Design | A Comparison of Meta-heuristic Search for Interactive Software Design | Application of Genetic Algorithms to Software Testing | Evolving Software Test Data - GAs Learn Self-expression | Search-Based Software Engineering | Cooperative Co-evolutionary Optimisation of Software Project Assignments and Job Scheduling | Solving the Class Responsibility Assignment Problem in Object-Oriented Analysis with Multi-objective Genetic Algorithms | Search-Based Software Test Data Generation: a Survey | Automatic Program Repair with Evolutionary Computing | Search-Based Refactoring for Software Maintenance | Repository of Publications on Search-based Software Engineering | Agile Software Development: Principles, Patterns and Practices | Requirements and Aesthetics | Interactive Evolutionary Computation: Fusion of the Capabilities of EC Optimization and Human Evaluation | Tracking a Criminal Suspect through ""Face-Space"" with a Genetic Algorithm | Artificial Evolution for Computer Graphics | Interactive Evolution for Cochlear Implants Fitting | Nonlinear Multiobjective Optimization | Interactive Multiobjective Optimization from a Learning Perspective | Advances in Evolutionary Multi-Objective Optimization | Adaptive Surface Inspection via Interactive Evolution | An Input Method using Discrete Fitness Values for Interactive Genetic Algorithms | The Magical Number Seven, Plus or Minus Two: Some Limits on our Capacity for Processing Information | Interactive Genetic Algorithm with Wavelet Coefficients for Emotional Image Retrieval | Visual Interactive Evolutionary Algorithm for High Dimensional Data Clustering and Outlier Detection | Multiple Fuzzy State-value Functions for Human Evaluation through Interactive Trajectory Planning of a Partner Robot | Interactive Concept-based Search using MOEA: the Hierarchical Preference Case | Ergonomic Chair Design by Fusing Qualitative and Quantitative Criteria using Interactive Genetic Algorithms | Introduction to Evolutionary Computing, Springer | Ant Algorithms for Discrete Optimization | Ant Colony Optimization | The Ant Colony Metaphor for Search Continuous Design Spaces | Interactive Particle Swarm Optimisation | Interactive Fuzzy Multi-Objective Ant Colony Optimisation with Linguistically Quantified Decision Functions for Flexible Job Shop Scheduling Problems | An Interactive Simulation and Analysis Software for Solving TSP using Ant Colony Optimization Algorithms | Exploring Ant Colony Optimisation for Adaptive Interactive Search | The Vehicle Routing Problem | An Investigation into the Applicability and Validity of Object-oriented Design Metrics | Ant Colony for Multi-Objective Optimisation Problems | Ant Colony Optimisation: Overview and Recent Advances | An Experimental Analysis of Design Choices for Multi- Objectives Ant Colony Optimisation Algorithms | MAX-MIN Ant System | The Effects of Anchoring in Interactive MCDM Solution Methods | An Introduction to Evolutionary Computing, Springer | Use Case Specifications for Cinema Booking System | Use Case Specifications for Graduate Development Program | Use Case Specifications for Select Cruises | Manual Software Designs for Problem Domains | Ethical Approval Documents | Anti-Patterns: Refactoring Software, Architectures, and Projects in Crisis, Wiley",rejected,000
1212.6207.pdf.json,,,"Levels of Ordering in Software Design and Thinking | Sorudeykin “A model of Spatial Thinking for Computational Intelligence”, 9th IEEE East-West Design & Test Symposium, (EWDTS’11) | An Operational Analysis and the Degree of Inertia in Thinking Process Modeling | A Research of Heuristic Optimization Approaches to the Test Set Compaction Procedure Based On a Decomposition Tree for Combinational Circuits | Suggestopaedia – desuggestive teaching. Communicative method on the level of the hidden reserves of the human mind | Reasoning and the Logic of Things | An essay on the psychology of invention in the mathematical field",rejected,000
1212.6216.pdf.json,,,Multi-agent Positioning Mechanism in the Dynamic Environment | Training of Agent Positioning Using Human’s Instruction | Handbook of Genetic Algorithms.,rejected,000
1212.6273.pdf.json,Human-Recognizable Robotic Gestures,,"A survey of socially interactive robots | Toward sociable robots | Socialization between toddlers and robots at an early childhood education center | Social and collaborative aspects of interaction with a service robot | A social robot that stands in line | A biologically inspired architecture for an autonomous and social robot | Robot therapy: A new approach for mental healthcare of the elderly - A mini-review | Socially intelligent robots: Dimensions of human-robot interaction | Children-robot interaction: a pilot study in autism therapy | Social robotics: Integrating advances in engineering and computer science (keynote speech) | Towards an effective design of social robots  | Human-Inspired Robots | Android science: Conscious and subconscious recognition | Integration of action and language knowledge: A roadmap for developmental robotics | The intelligent ASIMO: System overview and integration | Natural interface using pointing behavior for human-robot gestural interaction | Explorations in engagement for humans and robots | Gesture based interface for human-robot interaction | Using the rhythm of nonverbal human-robot interaction as a signal for learning | Cognitive development in partner robots for information support to elderly people | Human-Recognizable Robotic Gestures | Towards gesture-based programming: Shape from motion primordial learning of sensorimotor primitives | Teaching and learning of robot tasks via observation of human performance | Mimetic communication model with compliant physical contact in human-humanoid interaction | Dynamical system modulation for robot learning via kinesthetic demonstrations | Incremental learning of gestures by imitation in a humanoid robot | Learning and reproduction of gestures by imitation | A humanoid robot that pretends to listen to route guidance from a human | EEG evidence for mirror neuron activity during the observation of human and robot actions: Toward an analysis of the human qualities of interactive robots | Iconic Gestures of Children and Adults | Strategy signals in face-to-face interaction | On signalling that it's your turn to speak | Some signals and rules for taking speaking turns in conversations | Some functions of gaze-direction in social interaction | Ellesworth, Person Perception, 2nd ed | The nature of rapport and its nonverbal correlates | Nonverbal Communication in Human Interaction, 4th ed | Nonverbal Signals | Interpersonal perception in Japanese and British observers | Mind, Self and Society from the Standpoint of a Social Behaviorist | Why do we gesture when we speak | Gesture and speech: How they interact | The communicative functions of hand illustrators | Human-Recognizable Robotic Gestures | Minimal Set of Recognizable Gestures for a 10 DOF Anthropomorphic Robot | Evidence for distinct contributions of form and motion information to the recognition of emotions from body gestures | Perceiving affect from arm movement | Distributional analyses in auditory lexical decision: Neighborhood density and word-frequency effects | Iconic gestures prime words | Gaze and task performance in shared virtual environments | Head gestures, gaze and the principles of conversational structure | Some Uses of the Head Shake | Linguistic functions of head movements in the context of speech | Interviewer Head Nodding and Interviewee Speech Durations | Neonate movement is synchronized with adult speech: interactional participation and language acquisition | Quantitative evaluation of infant behaviour and mother–infant interaction | The effect of head-nod recognition in human-robot conversation | When my robot smiles at me: Enabling human-robot rapport via real-time head gesture mimicry | The sound of many hands clapping | A novel eigenspace-based method for human action recognition | Detection of goal event in soccer videos | Action recognition for surveillance applications using optic flow and SVM | Human action recognition using Dynamic Time Warping | Human activity recognition in videos: A systematic approach | Differential use of attentional and visual communicative signaling by orangutans (Pongo pygmaeus) and gorillas (Gorilla gorilla) in response to the attentional status of a human | Clapping in chimpanzees: Evidence of exclusive hand preference in a spontaneous, bimanual gesture | Ape gestures and language evolution | Hand-clapping as a communicative gesture by wild female swamp gorillas | Human-Recognizable Robotic Gestures | Human-robot communication with hand-clapping language | Lying and nonverbal behavior: Theoretical issues and new findings | Nonverbal behavior and communication | Towards Humanlike Social Touch for Sociable Robotics and Prosthetics: Comparisons on the Compliance, Conformance and Hysteresis of Synthetic and Human Fingertip Skins | Nonverbal maternal warmth and children's locus of control of reinforcement | Antecedents of individual differences in locus of control of reinforcement: A critical review | Origins of Generalized Control Expectancies: Reported Child Stress and Observed Maternal Control and Warmth | Oxytocin increases trust in humans | Oxytocin increases generosity in humans | Design and Development of Nancy, a Social Robot | Model-free impedance control for safe human-robot interaction | Impedance control for multi-point human-robot interaction | Prosthetic finger phalanges with lifelike skin compliance for low-force social touching interactions | Towards humanlike social touch for prosthetics and sociable robotics: Handshake experiments and finger phalange indentations | Force and motion analyses of the human patting gesture for robotic social touching | Towards social robots: Designing a emotion-based architecture | Umilta ""Brain response to a humanoid robot in areas implicated in the perception of human emotional gestures, | Facial expression and emotion | Scientific Issues Concerning Androids | Efficient bipedal robots based on passive-dynamic walkers | Effort-Shape and kinematic assessment of bodily expression of emotion during gait | Measurement of lower extremity kinematics during level walking | Human-Recognizable Robotic Gestures | Emotional influences on locomotor behavior | Full-body gesture recognition using inertial sensors for playful interaction with small humanoid robot | A storytelling robot: Modeling and evaluation of human-like gaze behavior | Culture in the elementary foreign language classroom | The educational use of Home Robots for children | Interactive robots as social partners and peer tutors for children : A field trial",rejected,000
1212.6837.pdf.json,,"Informing robot manipulation with computer vision continues to be a challenging problem in unstructured human environments, such as homes. Two types of challenges are particularly notable. First, the robot must handle wide variation in the appearance of task-relevant components of the world that can affect its ability to perform tasks successfully. Lighting can vary from home to home and from hour to hour due to indoor lighting and windows. In addition, important components, such as drawer handles and the drawer faces that serve as background, can be distinctive or even unique. The perspective from which a mobile robot observes the component will also vary. ar X iv :1 21 2. 68 37 v1 [ cs .R O ] 3 1 D ec Second, the relationship between the appearance of task-relevant components and the success or failure of a manipulation behavior is complex. For example, the mechanics of a specific device may require that the robot act at a distinct location, such as a finicky drawer that needs to be pushed in the center to be closed, or a convoluted handle that the robot’s gripper can only grasp at particular locations. The robot itself may also change over time and thus alter the relationship between visual appearance and a manipulation behavior, as parts of its body settle, deform, and wear. One potential solution to these two problems is for robots to autonomously learn how specific objects respond to manipulation attempts using a behavior, and to continue to learn as they perform tasks. By using selfgenerated data, robots can learn direct mappings from visual features to the input parameters for behaviors, enabling robust execution despite errors in calibration, variations in robot pose, sensor noise, unexpected environmental interactions, and other factors. By continuing to learn over time, robots can also adapt to changes in the environment, the objects, and their bodies. In this work, we present a system that enables mobile manipulators to autonomously gather data about the",,rejected,000
1301.1332.pdf.json,A Logic Programming Approach to Integration Network Inference,"Enterprises are highly connected to partners and even competitors as part of value chains consisting of business processes. The business document exchange is actually implemented by complex, underlying networks of application and middleware systems, called integration networks. To remain competitive enterprises have to adapt their business processes in a timely and flexible manner, which requires visibility and control over the integration network. However, currently information is locked into systems of an enterprise. To overcome this situation, a new discipline, called Network Mining (NM), strives to discover and extract raw data hidden within heterogeneous systems in complex enterprise landscapes [21,20]. The raw data implicitly contains information about the integration network, i.e. middleware and application. From that, our system reconstructs integration networks. For the system user, the resulting linked real-world data describing the ”as-is” network can then be captured in e.g. network-centric BPMN models [19]. A generalized view of such a network is shown in Fig. 1. When looking at an enterprise landscape, the systems within the integration network can be classified into different categories based on the integration content and the role they ar X iv :1 30 1. 13 32 v2 [ cs .D B ] 8 J an 2 01 3 play. The classification provides insight into the capabilities and complexity of the network and allows to manage business processes, contextualized visualization and operation on the network. These categories span from applications with embedded integration or even mediation capabilities, like proxies, enterprise services, composite applications or applications with service adaptation (Categories I+II), over standalone Enterprise Service Bus (ESB) or middleware instances with flexible pipeline processing, e.g. mapping, routing and connectivity for legacy systems (Category III+IV), to Business to Business (B2B) gateways for cross-enterprise document exchange (Categor","Process Mining: Discovery | BOOMAnalytics: Exploring Data-centric, Declarative Programming for the Cloud | Dedalus: Datalog in Time and Space | Approximating Constraint Propagation in Datalog | Datalog for Enterprise Applications – From Industrial Applications to Rese | LogicBlox for Enterprise Applications | Datalog and Emerging Applications: An Interactive Tutorial | Distributed data management on the web | Linked Data – The Story so Far | The Emerging Web of Linked Data | Network virtualization: state of the art and research challenges | The magic of logical inference in probabilistic programming | The Declarative Imperative – Experiences and Conjectures in Distributed Logic | Enterprise Integration Patterns: Designing, Building, and Deploying Messaging Solutions | Using Datalog on the Semantic Web | Efficiently Compiling Efficient Query Plans for Modern Hardware | Topic Overview – IT Service Management | Building a Business Graph System and Network integration | From Network Mining to Large Scale Business Networks | Towards Business Network Management | Using Datalog for Rule-Based Reasoning over Web Data: Challenges and Next Steps | A Path Algebra for Multi-Relational Graphs | Optimizing Large-Scale Semi-Naive Datalog Evaluation in Hadoop | Principles of Database and Knowledge-Base Systems Volume I | DTProbLog: A decision-theoretic probabilistic Prolog",rejected,000
1301.1385.pdf.json,Translating NP-SPEC into ASP,"NP-SPEC is a language that was proposed in [4,2] in order to specify problems in the complexity class NP in a simple, clear, and declarative way. The language is based on Datalog with circumscription, in which some predicates are circumscribed, while others are not and are thus “left open”. Some practical features are added to this basic language, often by means of reductions. The original software system supporting NP-SPEC was described in [2] and was written in the ECLiPSe Constraint Programming System, based on Prolog. A second software system, SPEC2SAT1, was proposed in [3], which rewrites NP-SPEC into propositional formulas for testing satisfiability. The system has also been tested quite extensively in [5], also for several problems taken from CSPLIB, with promising results. Interestingly, to our knowledge so far no attempt has been made to translate NPSPEC into Answer Set Programming (ASP), which is very similar in spirit to Datalog with circumscription, and thus a good candidate as a transformation target. Moreover, several efficient ASP software systems are available, which should guarantee good performance. A crucial advantage of ASP versus propositional satisfiability is the fact that NP-SPEC problem descriptions are in general not propositional, and therefore a reduction from NP-SPEC to SAT has to include an implicit instantiation (or grounding) step. Also ASP allows for variables, and ASP systems indeed provide optimized grounding procedures, which include many advanced techniques from database theory (such as indexing, join-ordering, etc). This takes the burden of instantiating in a smart way from the NP-SPEC translation when using ASP systems. ? This work was supported by M.I.U.R. within the PRIN project LoDeN. 1 http://www.dis.uniroma1.it/cadoli/research/projects/NP-SPEC/ code/SPEC2SAT/ ar X iv :1 30 1. 13 85 v1 [ cs .A I] 8 J an 2 01 In this paper we provide a translation from NP-SPEC into various variants of ASP. We discuss properties and limitatio","Knowledge Representation, Reasoning and Declarative Problem Solving | An Executable Specification Language for Solving all the Problems in NP | SAT as an effective solving technology for constraint problems | NP-SPEC: An executable specification language for solving all problems in NP | Compiling problem specifications into SAT | Symmetry-breaking answer set solving | An extensible SAT-solver | Potassco: The potsdam answer set solving collection | Conflict-driven answer set solving | Gringo : A new grounder for answer set programming | Classical Negation in Logic Programs and Disjunctive Databases | The DLV System | The DLV System for Knowledge Representation and Reasoning | A constraint-based approach to narrow search trees for satisfiability",rejected,000
1301.1386.pdf.json,SPARC – Sorted ASP with Consistency Restoring Rules,"The paper continues work on design and implementation of knowledge representation languages based on Answer Set Prolog (ASP) [1]. In particular we concentrate on the extension of ASP called CR-Prolog – Answer Set Prolog with consistency restoring rules (CR-rules for short) [2]. The language, which allows a comparatively simple encoding of indirect exceptions to defaults, has been successfully used for a number of applications including planning [3], probabilistic reasoning [4], and reasoning about intentions [5]. This paper is a preliminary report on our attempts to make CR-Prolog (and hence other dialects of ASP) more user friendly and more suitable for use in teaching and large applications. This work goes in two different, but connected, directions. First we expand the syntax of CR-Prolog by introducing sorts. Second, we translate a basic version of the CR-Prolog into the language of DLV with weak constraints [6] and compare the efficiency of the resulting DLV based CR-Prolog solver with the CR-Prolog solver implemented in [7]. The original hope for the second part of the work was to obtain a substantially more efficient inference engine for CR-Prolog. This was a reasonable expectation – the older engine is built on top of existing ASP solvers and hence does not fully exploit their inner structure. However this didn’t quite work out. Each engine has its strong and weak points and the matter requires further investigation. But we believe that even preliminary results are of interest since they shed some light on the relationship between two useful knowledge representation constructs: CR-rules and weak constraints. The first goal requires a lengthier explanation. Usually, a program of an Answer Set Prolog based language is understood as a pair, consisting of a signature and a collection of logic programming rules formed from symbols of this signature. ar X iv :1 30 1. 13 86 v1 [ cs .P L ] 8 J an 2 01 3 The syntax of the language does not provide any means for speci",Classical negation in logic programs and disjunctive databases | Logic Programs with Consistency-Restoring Rules | USA-Smart: Improving the quality of plans in answer set planning | Causal and probabilistic reasoning in P-log | Reasoning about the intentions of agents | Disjunctive Datalog with Strong and Weak Constraints: Representational and Computational Issues | CR-MODELS: An inference engine for CR-Prolog | Language independence and language tolerance in logic programs | Modules and signature declarations for a-prolog: Progress report | Answer sets | The DLV system for knowledge representation and reasoning | Conflict-driven answer set enumeration | Integrating answer set programming and constraint logic programming,rejected,000
1301.1387.pdf.json,Language ASP{f} with Arithmetic Expressions and Consistency-Restoring Rules,"In this paper we describe an extension of Answer Set Programming (ASP) [12,16,4] called ASP{f,cr}. This work continues our research on the introduction of nonHerbrand functions in ASP. In logic programming, functions are typically interpreted over the Herbrand Universe, with each functional term f(x) mapped to its own canonical syntactical representation. That is, in most logic programming languages, the value of an expression f(x) is f(x) itself, and thus, if equality is understood as identity, f(x) = 2 is false. This type of functions, the corresponding languages and efficient implementation of solvers is the subject of a substantial amount of research (we refer the reader to e.g. [8,6]). When representing certain kinds of knowledge, however, it is sometimes convenient to use functions with non-Herbrand domains (non-Herbrand functions for short), i.e. functions that are interpreted over domains other than the Herbrand Universe. For example, when describing a domain in which people enter and exit a room over time, it may be convenient to represent the number of people in the room at step s by means of a function occupancy(s) and to state the effect of a person entering the room by means of a statement such as occupancy(S + 1) = O + 1← occupancy(S) = O where S is a variable ranging over the possible time steps in the evolution of the domain and O ranges over natural numbers. ar X iv :1 30 1. 13 87 v1 [ cs .A I] 8 Of course, in most logic programming languages, non-Herbrand functions can still be represented, but the corresponding encodings are not as natural and declarative as the one above. For instance, a common approach consists in representing the functions of interest using relations, and then characterizing the functional nature of these relations by writing auxiliary axioms. In ASP, one would encode the above statement by (1) introducing a relation occupancy′(s, o), whose intuitive meaning is that occupancy′(s, o) holds iff the value of occupancy(s) is o; and","Answer Set Solving and Non-Herbrand Functions | Correct Reasoning: Essays on Logic-Based AI in Honour of Vladimir Lifschitz, chap | Logic Programs with Consistency-Restoring Rules | Knowledge Representation, Reasoning, and Declarative Problem Solving | Logic Programming and Knowledge Representation | A Decidable Subclass of Finitary Programs | Functional Answer Set Programming | Enhancing ASP by Functions: Decidable Classes and Implementation Techniques | Constraint Answer Set Solving | Strong Introspection | New Semantics for Epistemic Specifications | Classical Negation in Logic Programs and Disjunctive Databases | Reasoning with Prioritized Defaults | Logic Programs with Intensional Functions (Preliminary Report) | Answer Set Programming with Functions | The Logic Programming Paradigm: a 25-Year Perspective, chap | Weight Constraint Programs with Functions",rejected,000
1301.1388.pdf.json,Utilizing ASP for Generating and Visualizing Argumentation Frameworks,"Instantiation-based argumentation [7] is a central paradigm in nonmonotonic reasoning since it gives a formal handle to separate the logical and non-classical contents of reasoning in the presence of contradicting information. Hereby, one starts with a knowledge base and constructs arguments from it. Arguments typically consist of two parts, namely a support, which is grounded in the knowledge base and a claim derived from it. In [4] the process is described with an underlying propositional knowledge base using minimal sets of consistent support classically entailing the claim. In a second step, conflicts between these arguments have to be identified. The obtained arguments and the relation between them yield a so-called argumentation framework [9]. This simple, yet expressive formalism is basically a directed graph whereby the arguments are represented via vertices and the conflicts with directed edges. Argumentation frameworks are then evaluated with one of the numerous semantics for abstract argumentation available, resulting in potentially multiple acceptable sets of arguments [3]. Here we are only interested in the instantiation part, however, which received less attention wrt. realized systems. Notable exceptions are the Carneades system, which can construct arguments using heuristics [16] and the recent TOAST implementation ar X iv :1 30 1. 13 88 v1 [ cs .A I] 8 J an 2 01 for the ASPIC+ framework [27]. The reason for the lack of implementations is potentially twofold: First, due to the inherent high complexity of the problem; already constructing a single argument is hard for the second level of the polynomial hierarchy [23]. Secondly, standard instantiation schemes for propositional knowledge bases result in infinite argumentation frameworks even for finite knowledge bases [1]. The first obstacle calls for highly expressive languages, making answer-set programming [6, 21, 22] (ASP, for short) a well suited candidate. For the second obstacle, we restrict ours","Identifying the Core of Logic-Based Argumentation Systems | Learning by diagramming Supreme Court oral arguments | Semantics of Abstract Argument Systems | A logic-based theory of deductive arguments | DUNESDialogic and Argumentative Negotiation Educational Software-Technical Realization | Answer set programming at a glance | On the evaluation of argumentation formalisms | ASPVIZ: Declarative Visualisation and Animation Using Answer Set Programming | On the Acceptability of Arguments and its Fundamental Role in Nonmonotonic Reasoning, Logic Programming and n-Person Games | Complexity-Sensitive Decision Procedures for Abstract Argumentation | Answer-set programming encodings for argumentation frameworks | On the Computational Cost of Disjunctive Logic Programming: Propositional Case | Answer Set Programming: A Primer | ASPIDE: Integrated Development Environment for Answer Set Programming | Potassco: The Potsdam Answer Set Solving Collection | An Overview of the Carneades Argumentation Support System | Instantiating abstract argumentation with classical logic arguments: Postulates and properties | Computer supported argumentation and collaborative decision making: the HERMES system | Kara: A System for Visualising and Visual Editing of Interpretations for Answer-Set Programs | The DLV system for knowledge representation and reasoning | Stable Models and an Alternative Logic Programming Paradigm. In The Logic Programming Paradigm – A 25-Year Perspective, pages 375–398 | Logic Programming with Stable Model Semantics as a Constraint Programming Paradigm | Properties and Complexity of Some Formal Inter-agent Dialogues | Araucaria: Software for Argument Analysis, Diagramming and Representation | ArguNet a software tool for collaborative argumentation analysis and research | Cohere: Towards Web 2.0 Argumentation | ArguMed - A Template-Based Argument Mediation System for Lawyers | IDPDraw, a tool used for visualizing answer sets. https://dtai.cs",rejected,000
1301.1389.pdf.json,Planning and Scheduling in Hybrid Domains Using Answer Set Programming,"In this paper we are interested in modeling intelligent agents capable of planning, acting and reasoning in a dynamic environment. We are primarily interested in hybrid domains - domains that exhibit both discrete and continuous behavior. Many real world situations such as a robot in a manufacturing plant, a decision control system of a space shuttle etc. deal with both discrete change as well as continuous change. For example, a decision control system in a space shuttle is capable of opening and closing valves of fuel tanks to supply fuel to some jets. The actions open and close change positions of valves. The valves will remain in a certain position as long as no open or close actions occurs. The change of position of valves is, therefore, discrete. However, the fuel level in the tank can change continuously with time when the valve is open or there is an incoming supply of fuel to the tank. This type of continuous change coupled with discrete change makes this domain hybrid. We are not only interested in modeling such domains but also to solve planning and scheduling problems in such domains. A simple planning and scheduling problem in the above example would be to fire a jet within 10 seconds. This would require opening and closing the appropriate valves and delivering fuel to the jet in time to achieve the goal. To model intelligent agents we need to provide the agent with knowledge about its environment and its own capabilities and goals. There are several approaches to representing and reasoning about such knowledge. In this paper, we use action language ar X iv :1 30 1. 13 89 v1 [ cs .A I] 8 J an 2 01 H - a high level language for representing and reasoning about actions and their effects. We chose this language mainly because it is capable of representing and reasoning about hybrid domains. A description written in H describes a transition diagram whose states correspond to possible physical states of the system and whose arcs are labeled by actions. A tra",Representing constraint satisfaction problems in answer set programming | Reasoning agents in dynamic domains | Integrated planning and scheduling for petroleum refinery operations | A New Incarnation of Action Language H | Towards Answer Set Programming Based Architectures for Intelligent Agents | Modeling mixed discrete-continuous domains for planning | The stable model semantics for logic programming | Classical negation in logic programs and disjunctive databases | A causal theory of ramifications and qualifications | Integrating Answer Set Programming and Constraint Logic Programming | Improving Efficiency of Solving Computational Problems with ASP | Temporal planning with continuous change | Knowledge in Action: Logical Foundations for Specifying and Implementing Dynamical Systems | Solving the frame problem,rejected,000
1301.1390.pdf.json,Eliminating Unfounded Set Checking for HEX-Programs,"In the last years, Answer Set Programming (ASP) has emerged as an increasingly popular approach to declarative problem solving for a range of applications [2], thanks to expressive and efficient systems like SMODELS [20], DLV [19], cmodels [17], and CLASP [15]. However, recent developments in computing, in which context awareness, distribution and heterogeneous information sources gain importance, raised the need for access to external sources in programs, be it in the context of the Web to access web services, databases, or ontological information in different formats, in the context of agents to acquire sensor input, etc. To cater for this need, HEX-programs [11] extend ASP with so called external atoms, through which the user can couple any external data source with a logic program. Roughly, such atoms pass information from the program, given by predicate extensions, ? This research has been supported by the Austrian Science Fund (FWF) project P20840, P20841, P24090, and by the Vienna Science and Technology Fund (WWTF) project ICT08-020. ar X iv :1 30 1. 13 90 v1 [ cs .L O ] 8 J an 2 01 3 into an external source which returns output values of an (abstract) function that it computes. This extension has been utilized for a range of applications, including querying data and ontologies on the Web, multi-context reasoning, and reasoning about actions and planning, to mention a few (cf. [5]). Notably, recursive data exchange between the rules and the external sources is supported, which makes the formalism powerful. The semantics of a HEX-program Π is defined in terms of answer sets based on the FLP reduct [14]: an interpretation A is an answer set of Π , if and only if it is a ⊆-minimal model of the FLP-reduct fΠA of Π wrt. A, which is the set of all rules whose body is satisfied by A. For ordinary logic programs, this semantics coincides with the one where the canonical GL-reduct [16] is in place of fΠA, and it is more appealing for extensions with nonmonotonic aggre","Equilibria in Heterogeneous Nonmonotonic Multi-Context Systems | Answer set programming at a glance | Conflict-driven disjunctive answer set solving | On the acceptability of arguments and its fundamental role in nonmonotonic reasoning, logic programming and n-person games | Pushing efficient evaluation of HEX programs by modular decomposition | Conflict-driven ASP solving with external sources | Exploiting Unfounded Sets for HEX-Program Evaluation. In: JELIA’12 | Improving HEX-Program Evaluation based on Unfounded Sets | Finding explanations of inconsistency in Multi-Context Systems | Exploiting conjunctive queries in description logic programs | A Uniform Integration of Higher-Order Reasoning and External Evaluations in Answer-Set Programming | Effective Integration of Declarative Rules with External Evaluations for Semantic-Web Reasoning | Unfounded sets for disjunctive logic programs with arbitrary aggregates | Semantics and complexity of recursive aggregates in answer set programming | Conflict-driven answer set solving: From theory to practice | Classical Negation in Logic Programs and Disjunctive Databases | Answer set programming based on propositional satisfiability | Splitting a logic program | The DLV System for Knowledge Representation and Reasoning | Extending and Implementing the Stable Model Semantics",rejected,000
1301.1391.pdf.json,Backdoors to Normality for Disjunctive Logic Programs,"Over the last two decades, propositional satisfiability (Sat) has become one of the most successful and widely applied techniques for the solution of NP-complete problems. Today’s Sat-solvers are extremely efficient and robust, instances with hundreds of thousands of variables and clauses can be solved routinely. In fact, due to the success of Sat, NP-complete problems have lost their scariness, as in many cases one can efficiently encode NP-complete problems to Sat and solve them by means of a Sat-solver [Gomes et al., 2008; Biere et al., 2009]. We investigate transformations into Sat for problems that are harder than NP or co-NP. In particular, we consider various search problems that arise in disjunctive answer set programming ∗Research supported by the ERC, Grant COMPLEX REASON 239962. †This is the author’s self-archived copy including detailed proofs. A preliminary version of the paper was presented on the workshop ASPOCP’12. (Asp). With Asp one can describe a problem by means of rules that form a disjunctive logic program, whose solutions are answer sets. Many important problems of AI and reasoning can be represented in terms of the search for answer sets [Brewka et al., 2011; Marek and Truszczynski, 1999; Niemelä, 1999]. Two of the most fundamental Asp problems are Brave Reasoning (is a certain atom contained in at least one answer set?) and Skeptical Reasoning (is a certain atom contained in all answer sets?). Both problems are located at the second level of the Polynomial Hierarchy [Eiter and Gottlob, 1995] and thus assumed to be harder than NP or co-NP. It would be desirable to utilize Sat-solvers for these problems. However, we cannot transform these two reasoning problems into Sat in polynomial time, unless the Polynomial Hierarchy collapses, which is believed to be unlikely. New Contribution In this work we show how to utilize certain structural aspects of disjunctive logic programs to transform the two Asp reasoning problems into Sat. In particular, w","editors | Artif | Comput | editors | Characterizations of the disjunctive well-founded semantics: Confluent calculi and iterated GCWA | Answer set programming at a glance | The third answer set programming competition: Preliminary report of the system competition track | Logic Programming and Nonmonotonic Reasoning, volume 6645 of Lecture Notes in Computer Science, pages 388–403 | editors | Improved parameterized upper bounds for vertex cover | Logic and Data Bases | Logic Programming | Springer Verlag | editors | On the computational cost of disjunctive logic programming: Propositional case | Consistency of Clark’s completion and existence of stable models | Technical report | the bad | volume XIV of Theoret | editors | editor | editors | editors | editors | Classical negation in logic programs and disjunctive databases | Answer set programming based on propositional satisfiability | Chapter 2 satisfiability solvers | Fixed-parameter algorithms for artificial intelligence | Unfolding partiality and disjunctions in stable model semantics | editors | editors | editors | Some (in)translatability results for normal logic programs and propositional theories | editors | Propositional logic: deduction and algorithms | editor | A model-theoretic counterpart of loop formulas | Why are there so many loop formulas? ACM Transactions on Computational Logic (TOCL) | ASSAT: Computing answer sets of a logic program by SAT solvers | Look-back techniques and heuristics in dlv: Implementation | In Proceedings of the 1st International Conference on Logic Programming and Nonmonotonic Reassoning (LPNMR’91) | ACM | editors | Oxford Lecture Series in Mathematics and its Applications | Artif | editors | In Proceedings of the 23nd International Joint Conference on Artificial Intelligence (IJCAI’13) | editors | On the complexity of derivation in propositional calculus | 23:733–742 | editors",rejected,000
1301.1392.pdf.json,Answer Set Programming for Stream Reasoning,"The advance of Internet and Sensor technology has brought about new challenges evoked by the emergence of continuous data streams, like web logs, mobile locations, or online measurements. While existing data stream management systems [4] allow for high-throughput stream processing, they lack complex reasoning capacities [5]. We address this shortcoming and elaborate upon approaches to knowledge-intense stream reasoning, based on Answer Set Programming (ASP; [6]) as a prime tool for Knowledge Representation and Reasoning (KRR; [7]). The emphasis thus shifts from rapid data processing towards complex reasoning, as required in application areas like ambient assisted living, robotics, or dynamic scheduling. In contrast to traditional ASP methods, which are devised for singular problem solving, “stream reasoning, instead, restricts processing to a certain window of concern, focusing on a subset of recent statements in the stream, while ignoring previous statements” [8]. To accommodate this in ASP, we develop new techniques to formulate and process problems dealing with emerging as well as expiring data in a seamless way. Our modeling approaches rely on the novel concept of time-decaying logic programs [1], where logic program parts are associated with life spans to steer their emergence as well as expiration upon continuous reasoning. Time-decaying logic programs are implemented as a recent extension of the reactive ASP system oclingo [9], using the ASP grounder gringo [10] for the recurrent composition of a static “offline” encoding with dynamic “online” data into queries to the ASP solver clasp [11]. While oclingo makes powerful ASP technology accessible for stream reasoning, its continuous query formulation and processing impose particular modeling challenges. ? This paper complements a short KR’12 paper [1]; an extended draft [2] is available at [3]. ?? Affiliated with Simon Fraser University, Canada, and Griffith University, Australia. ar X iv :1 30 1. 13 92 v1 [ cs","Stream reasoning with answer set programming: Preliminary report | Stream reasoning with answer set programming: Extended version | Data Stream Management | It’s a streaming world! reasoning upon rapidly changing information | Knowledge Representation, Reasoning and Declarative Problem Solving | Handbook of Knowledge Representation | Deductive and inductive stream reasoning for semantic social media analytics | Conflict-driven answer set solving | Answer set programming and plan generation | Handbook of Satisfiability | Extending and implementing the stable model semantics | Engineering an incremental ASP solver | Automated Planning: Theory and Practice | An incremental answer set programming based system for finite model computation | A simple solution to the Yale shooting problem | Nonmonotonic causal theories | Scheduling Algorithms | Algorithm = logic + control | Proceedings of the Eleventh International Conference on Logic Programming and Nonmonotonic Reasoning (LPNMR’11)",rejected,000
1301.1393.pdf.json,Two New Definitions of Stable Models of Logic Programs with Generalized Quantifiers,"Most versions of the stable model semantics involve grounding. For instance, according to the FLP semantics from [1; 2], assuming that the domain is {−1, 1, 2}, program p(2) ← ınot SUM〈x :p(x)〉<2 p(−1) ← SUM〈x :p(x)〉>−1 p(1) ← p(−1) (1) is identified with its ground instance w.r.t the domain: p(2) ← ınot SUM〈{−1:p(−1), 1:p(1), 2:p(2)}〉<2 p(−1) ← SUM〈{−1:p(−1), 1:p(1), 2:p(2)}〉>−1 p(1) ← p(−1) . (2) As described in [1], it is straightforward to extend the definition of satisfaction to ground aggregate expressions. For instance, set {p(−1), p(1)} does not satisfy the body of the first rule of (2), but satisfies the bodies of the other rules. The FLP reduct of program (2) relative to {p(−1), p(1)} consists of the last two rules, and {p(−1), p(1)} is its minimal model. Indeed, {p(−1), p(1)} is the only FLP answer set of program (2). On the other hand, according to the semantics from [3], program (2) is identified with some complex propositional formula containing nested implications:( ¬ ( (p(2)→p(−1)∨p(1)) ∧ (p(1)∧p(2)→p(−1)) ∧ (p(−1)∧p(1)∧p(2)→⊥) ) → p(2) ) ∧ (( p(−1)→p(1)∨p(2) ) → p(−1) ) ∧ ( p(−1)→ p(1) ) . ar X iv :1 30 1. 13 93 v1 [ cs .L O ] 8 J an 2 01 3 Under the stable model semantics of propositional formulas [3], this formula has two answer sets: {p(−1), p(1)} and {p(−1), p(1), p(2)}. The relationship between the FLP and the Ferraris semantics was studied in [4; 5]. Unlike the FLP semantics, the definition from [3] is not applicable when the domain is infinite because it would require the representation of an aggregate expression to involve “infinite” conjunctions and disjunctions. This limitation was overcome in the semantics presented in [4; 6], which extends the first-order stable model semantics from [7; 8] to incorporate aggregate expressions. Recently, it was further extended to formulas involving generalized quantifiers [9], which provides a unifying framework of various extensions of the stable model semantics, including programs with aggregates, prog",Recursive aggregates in disjunctive logic programs: Semantics and complexity | Semantics and complexity of recursive aggregates in answer set programming | Answer sets for propositional theories | On reductive semantics of aggregates in answer set programming | First-order extension of the flp stable model semantics via modified circumscription | On the stable model semantics of first-order formulas with aggregates | A new perspective on stable models | Stable models and circumscription | Stable models of formulas with generalized quantifiers (preliminary report) | Logic programs with abstract constraint atoms | Combining answer set programming with description logics for the semantic web | Connecting first-order ASP and the logic FO(ID) through reducts | A uniform integration of higher-order reasoning and external evaluations in answer-set programming | A logical semantics for description logic programs | Generalized quantifiers | First-order predicate logic with generalized quantifiers | Stable models of formulas with generalized quantifiers | Reformulating the situation calculus and the event calculus in the general theory of stable models and in answer set programming | System F2LP — computing answer sets of first-order formulas,rejected,000
1301.1394.pdf.json,Lloyd-Topor Completion and General Stable Models,"The theorem by François Fages [1] describing a case when the stable model semantics is equivalent to program completion is one of the most important results in the theory of stable models. It was generalized in [2,3,4], it has led to the invention of loop formulas [5], and it has had a significant impact on the design of answer set solvers. The general stable model semantics defined in [6] characterizes the stable models of a first-order sentence F as arbitrary models of a certain second-order sentence, denoted by SM[F ];1 logic programs are viewed there as first-order sentences written in “logic programming notation.” In this note we define an extension of Fages’ theorem that can be used as a tool for transforming SM[F ], in some cases, into an equivalent first-order formula. That extension refers to the version of program completion introduced by John Lloyd and Rodney Topor in [7]. Their definition allows the body of a rule to contain propositional connectives and quantifiers. Earlier work in this direction is reported in [6] and [8]. These papers do not mention completion in the sense of Lloyd and Topor explicitly. Instead, they discuss ways to convert a logic program to “Clark normal form” by strongly equivalent transformations [9,10] and completing programs in this normal form by replacing implications with equivalences. But this is essentially what Lloyd-Topor completion does. The following examples illustrate some of the issues involved. Let F be the program p(a), q(b), p(x)← q(x), (1) 1 To be precise, the definition of SM in that paper requires that a set of “intensional predicates” be specified. In the examples below, we assume that all predicate symbols occurring in F are intensional. ar X iv :1 30 1. 13 94 v1 [ cs .L O ] 8 J an 2 01 3 or, in other words, the sentence p(a) ∧ q(b) ∧ ∀x(q(x)→ p(x)). The Clark normal form of (1) is tight in the sense of [6], and Theorem 11 from that paper shows that SM[F ] in this case is equivalent to the conjunction of the",Consistency of Clark’s completion and existence of stable models | Foundations of logic programming | Tight logic programs | On tight logic programs and yet another translation from normal logic programs to propositional logic | ASSAT: Computing answer sets of a logic program by SAT solvers | Stable models and circumscription | Making Prolog more expressive | First-order stable model semantics and first-order loop formulas | Strongly equivalent logic programs | A characterization of strong equivalence for logic programs with variables | Connecting first-order asp and the logic fo(id) through reducts | Answer sets for propositional theories,rejected,000
1301.1395.pdf.json,Extending FO(ID) with Knowledge Producing Definitions: Preliminary Results,"Today, Answer Set Programming (ASP) is a vibrant domain, boasting both mature technologies and successful real-world applications. The roots of ASP lie in the fields of Logic Programming (LP) and Non-monotonic Reasoning (NMR). Both of these were initially motivated by dissatisfaction with classical first-order logic (FO), be it its computational properties (in the case of LP) or its suitability for representing common-sense knowledge (in the case of NMR). The current success of ASP suggests that, to a large extent, this domain was indeed able to overcome these problems of classical logic. It is, however, not yet quite clear how precisely this was done. That is to say, the relation between ASP and classical logic is, in our opinion, not yet fully ar X iv :1 30 1. 13 95 v1 [ cs .L O ] 8 J understood. Currently, ASP still stands as an alternative to FO: to effectively write ASP programs, one basically has to leave behind all methodologies, tools and intuitive understandings of classical logic and start anew in a different setting. This paper is part of a research project that attempts to close this gap [10]. The aim is to investigate whether and how the achievements of ASP can be reformulated as modular improvements or extensions of classical logic. Ultimately, we would like to be able to characterize ASP as a set of specific solutions to a number of orthogonal problems/limitations of classical logic, such that someone working in classical logic could add as many or as few “ASP-style features” to his knowledge base as is needed for that particular application. Of course, the motivation for this research is not purely practical. By reformulating the contributions of ASP in the classical framework, we also hope to provide a synthesis that will eventually lead to an increased understanding of classical and computational logic, and their role in problem solving. Ironically, ASP’s relation to classical logic seems currently best understood when it comes to computational asp",Enfragmo: A system for modelling and solving search problems with logic | Negation as failure | Extending classical logic with inductive definitions | Logic programming revisited: Logic programs as inductive definitions | A Tarskian informal semantics for ASP | Inductive situation calculus | A logic of nonmonotone inductive definitions | Well-founded semantics and the algebraic theory of non-monotone inductive definitions | The second answer set programming system competition | Answer set programming’s contributions to classical logic | Tableau Calculi for Answer Set Programming | The stable model semantics for logic programming | Logic programs with classical negation | Classical negation in logic programs and disjunctive databases | On the relation among answer set solvers | Abstract answer set solvers with backjumping and learning | Answer set programming and plan generation | On the relation between ID-Logic and Answer Set Programming | The IDP framework for declarative problem solving | A framework for representing and solving NP search problems | The alternating fixpoint of logic programs with negation | The well-founded semantics for general logic programs | Ordered epistemic logic,rejected,000
1301.1502.pdf.json,Fuzzy Soft Set Based Classification for Gene Expression Data,,"Marhaban.M.H, ”New Entropy-Based Method for Gene Selection” | Soft set theory-first results | An application of soft sets in a decision making problem | Generalised fuzzy soft sets | Texture classification using a novel, Soft set theory based classification algorithm | Mat,“Similarity Approach on Fuzzy Soft Set Based Numerical Data Classification | SigeruOmat, “A model for gene selection and classification of gene expression data",rejected,000
1301.1932.pdf.json,,"Stuttering also known as dysphemia and stammering is a speech fluency disorder that affects the flow of speech. It is one of the serious problems in speech pathology and poorly understood disorder. Approximately about 1% of the population suffering from this disorder and has found to affect four times as many males as females [11, 5, 16, 3]. Stuttering is the subject of interest to researchers from various domains like speech physiology, pathology, psychology, acoustics and signal analysis. Therefore, this area is a multidisciplinary research field of science. The speech fluency can be defined in terms of continuity, rate, co-articulation and effort. Continuity relates to the degree to which syllables and words are logically sequenced and also the presence or absence of pauses. If semantic units follow one another in a continual and logical flow of information, the speech is interpreted as fluent [4]. If there is a break in the smooth, meaningful flow of speech, then it is dysfluent speech. The types of dysfluency that characterize stuttering disorder are shown in Table 1 [6]. There are not many clear and quantifiable characteristic to distinguish the dysfluencies of dysfluent and fluent speakers. It was found from literature survey that sound or syllable repetitions, word repetitions and prolongation are sufficient to differentiate them [6, 12]. There are number of diagnosis methods to evaluate stuttering. The stuttering assessment process is carried out by transcribing the recorded speech and locating the dysfluencies occurred and counting the number of occurrences. These types of stuttering assessments are based on the knowledge and experience of speech pathologist. The main drawbacks of making such assessment are time consuming, subjective, inconsistent and prone to error. In this work, we are proposing an approach to classify dysfluent and fluent speech using MFCC feature extraction. In order to classify stuttered speech we have considered three types of dyflue",What causes stuttering? | Voice recognition algorithms using Mel Frequency Cepstral Coefficients (MFCC) and Dynamic Time Warping (DTW) techniques | Three-dimensional model analysis and processing | A frequency spectral feature modelling for Hidden Markov Model based automated speech recognition | An introduction to support vector machines and other kernel-based learning methods | A tutorial on support vector machine-based methods for classification problems in chemometrics,rejected,000
1301.1950.pdf.json,,"Before making a semantic analysis of natural language, we should define the lexicon and syntactic rules of a formal grammar useful in generating simple sentences in the respective language (for example, English, French, or Romanian). We shall consider a simple grammar, having some rules for the lexicon, and some rules for the grammatical categories. The rules for the lexicon will be of the type (1):","Aspects of the Theory of Syntax | Curs de Lingvistică computaţională, Faculty of Informatics, ""Alexandru Ioan Cuza"" University of Iaşi, Romania | Procesarea limbajului Natural. Analiza automată a frazei. Aplicaţii, University of Craiova, Faculty of Mathematics-Informatics, Romania | Context Free Grammars | ADX — Agent for Morphologic Analysis of Lexical Entries in a Dictionary | Natural Language Processing: Syntactic Analysis, Lexical Disambiguation, Logical Formalisms, Discourse Theory, Bivalent Verbs, Germany, Munich: AVM – Akademische | A Delphi Application for the Syntactic and Lexical Analysis of a Phrase Using Cocke, Younger, and Kasami Algorithm"" in BRAIN | Definite clause grammars for language analysis | Author Bogdan Pătruţ Bogdan Pătruţ is associate professor in computer science at Vasile Alecsandri University of Bacau, Romania, with a Ph D in computer science and a Ph D in accounting. His domains of interest/ research are natural language processing, multiagent systems and computer science applied in social, economic and political sciences",rejected,000
1301.2005.pdf.json,A Distance-based Paraconsistent Semantics in DL-Lite,"The DL-Lite [1] is a family of lightweight description logics (DLs), the logical foundation of OWL 2.0 QL, one of the three profiles of OWL 2.0 for Web ontology language recommended by W3C. In description logics, an ontology is expressed as a knowledge base (KB). Inconsistency is not rare in ontology applications and may be caused by several reasons, such as errors in modeling, migration from other formalisms, ontology merging, and ontology evolution. Therefore, handling inconsistency is always considered an important problem in DL and ontology management communities. However, DL-Lite reasoning mechanism based on classical DL semantics faces problem when inconsistency occurs, which is referred to as the triviality problem. That is, any conclusions, that are possibly irrelevant or even contradicting, will be entailed from an inconsistent DL-Lite ontology under the classical semantics. In many practical ontology applications, there is a strong need for inferring (only) useful information from inconsistent ontologies. For instance, consider a simple DLLite KB K = (T ,A) where T = {Penguin ⊑ Bird, Swallow ⊑ Bird,Bird ⊑ Fly} and A = {Penguin(tweety),¬Fly(tweety), Swallow(fred)}. Under the classical semantics for DLs, anything can be inferred from K. Intuitively, one might wish to still infer Brid(fred) and Fly(fred), while they are useless to derive both Fly(tweety) and ¬Fly(tweety) from K. There exist several proposals for reasoning with inconsistent DL-Lite KBs in the literature. These approaches usually fall into one of two fundamentally different streams. The first one is based on the assumption that inconsistencies are caused by erroneous data and thus, they should be removed in order to obtain a consistent KB ([2, 3, 4, 5, 6]). In most approaches in this stream, the task of repairing inconsistent ontologies is actually reduced to finding a maximum consistent subset of the original KB. A shortcoming of these approaches is the so-called multi-extension problem. That ",The dl-lite family and relations | Repairing unsatisfiable concepts in OWL ontologies | Finding maximally satisfiable terminologies for the description logic ALC | Scalable cleanup of information extraction data using ontologies | Computing minimum cost diagnoses to repair populated DLbased ontologies | A new operator for abox revision in DL-Lite | Non-standard reasoning services for the debugging of description logic terminologies | Reasoning with inconsistent ontologies | Query rewriting for inconsistent dl-lite ontologies | An argumentation framework for description logic ontology reasoning and management | Paraconsistent reasoning for OWL | A tableau algorithm for handling inconsistency in OWL | Quasi-classical description logic. Multiple-Valued Logic and Soft Computing | Distance-based paraconsistent logics | A new approach to knowledge base revision in DL-Lite | Can you tell the difference between DL-Lite ontologies | Tractable reasoning and efficient query answering in description logics: The DL-Lite family | Distance-based measures of inconsistency and incoherency for description logics,rejected,000
1301.2137.pdf.json,A Forgetting-based Approach to Merging Knowledge Bases,,"Arbitration (or how to merge knowledge bases) | Merging information under constraints: a logical framework | Merging first-order knowledge using dilation operators, in Proc. international conference on Foundations of information and knowledge systems (FoIKS’08) | DA2 merging operators | Investigations into a theory of knowledge base revision | Knowledge base merging by majority, Dynamic Worlds: From the Frame Problem to Knowledge Management | On the semantics of theory change: arbitration between old and new information, in Proc. ACM SIGACT-SIGMOD-SIGART symposium on Principles of database systems (PODS’93) | Database systems: Achievements and opportunities, Communications of the ACM | Reasoning under inconsistency: A forgettingbased approach",rejected,000
1301.2146.pdf.json,A Paraconsistent Tableau Algorithm Based on Sign Transformation in Semantic Web,,"The Semantic Web | The Semantic Web revisited | N3logic. A logical framework for the World | Using Semantic Web technologies for policy management on the web | Non-standard reasoning services for the debugging of description logic terminologies. In:Proceedings of the 8 International Joint Conference on Artificial Intelligence (IJCAI’03),Acapulco,Mexico,2003 | Reasoning with inconsistent ontogies | Paraconsistent resolution for four-valued description logics. In:Proceedings of the 4 European Semantic Web Conference (ESWC’07).Innsbruck | Extending description logics with uncertainty reasoning in possibilistic logic. In:Proceedings of the 9 European Conference on Symbolic and Quantitative Approaches to Reasoning with Uncertainty (ECSQARU’07), Hammamet, Tunisia | Paraconsistent reasoning with quasi-classical semantics in ALC. In:Proceedings of the 2 International Conference of Web Reasoning and Rule Systems (RR’08) | A Tableau Algorithm for Handling Inconsistency in OWL | The description Logic in Handbook: Theory, Implementation, and Applications | Reasoning with individuals for the description logic SHIQ | Tableau Systems for Paraconsistency and Minimal Inconsistency | Dealing with inconsistencies in the Semantic Web. [Ph.D.Thesis]. Beijing: Peking University, 2008(in Chinese with English abstract | Attributive concept descriptions with complements",rejected,000
1301.2253.pdf.json,Efficient Approximation for Triangulation of Minimum Treewidth,,Complexity of finding embeb­ dings in a K-tree | Tree clustering for constraint networks | Bayesian updating in recursive graphical mod­ els by local computation | Graph minors XIII. the disjoint paths problem | Triangulated graphs and the elimination process | A practical algorithm for finding optimal triangulations,rejected,000
1301.2254.pdf.json,Markov Chain Monte Carlo using Tree-Based Priors on Model Structure,,"Bayesian CART model search | Stochastic logic programs: Sampling, inference and applications | Parameter estimation in stochastic logic programs | Being Bayesian about network structure. In Uncertainty in Artificial In­ telligence | Enumerating Markov equivalence classes of acyclic digraph mod­ els | A tutorial on learning with Bayesian networks | Bayesian model averaging and model selection for Markov equivalence classes of acycic digraphs | Bayesian graphical models for discrete data | Bayesian model comparison via jump diffusions | Markov chain concepts related to sampling algorithms",rejected,000
1301.2255.pdf.json,Graphical readings of possibilistic logic bases,,"Independence in qual­ itative uncertainty frameworks | Possibilistic logic bases and possibilistic graphs | Deci­ sion theoric planning: Structural assumptions and computational leverage | Supremumpreserving upper probabilities | Possibilistic logic. In Handbook of Logic in Artificial Intelli­ gence and Logic Programming, 3, Oxford Univer­ sity Press:pages | Epistemic entrench­ ment and possibilistic logic | When upper proba­ bilities are possibility measures | Conditional independence in possibility theory | Possinfer - a software tool for possibilistic inference | Foundations for a possibility theory | Propositional information systems | Logic, knowledge representation, and Bayesian decision theory | The transferable belief model for quan­ tified belief representation | Quantified possibility theory seen as an hyper cautious transferable belief model | Ordinal conditional functions: a dy­ namic theory of epistemic states | Statistical inferences based on a second-order possibility distribution | Fuzzy sets as a basis for a theory of possibility",rejected,000
1301.2256.pdf.json,Pre-processing for Triangulation of Probabilistic Networks,,"Local computations with probabilities on graphical structures and their applica­ tion to expert systems | Bayesian up­ dating in causal probabilistic networks by local computa­ tions | Complex­ ity of finding embeddings in a k-tree | A practical algorithm for finding optimal triangulations | A partial k-arboretum of graphs with bounded treewidth | Algorithmic Graph Theory and Perfect Graphs | Characterization and recognition of partial 3-trees | A sufficiently fast algorithm for finding close to optimal junction trees | Simple linear time algo­ rithms to test chordality of graphs, test acyclicity of graphs, and selectively reduce acyclic hypergraphs | Algorithmic as­ pects of vertex elimination on graphs | On linear recognition of tree-width at most four | Maximal prime subgraph decomposition of Bayesian networks",rejected,000
1301.2259.pdf.json,UCP-Networks: A Directed Graphical Representation of Conditional Utilities,,Graphical mod­ els for preference and utility | Utility indepen­ dence in qualitative decision theory | Reasoning with conditional ceteris paribus preference statements | Making rational decision using adaptive utility elic­ itation | Mini-buckets: A general scheme for generating approximations in automated reasoning in probabilistic inference,rejected,000
1301.2260.pdf.json,Confidence Inference in Bayesian Networks,,20(5):661-685 | AIS-BN: An adaptive importance sam­ pling algorithm for evidential reasoning in large Ba­ yesian networks | Computational Statistics | A Bayesian analysis of simulation algo­ rithms for inference in belief networks | An optimal approximation algorithm for Ba­ yesian inference | An optimal al­ gorithm for Monte Carlo estimation | Monte Carlo: concepts | In Un­ certainty in Artificial Intelligence 5 | Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Infer­ ence | In Proceedings of the Twelfth Annual Conference on Uncertainty in Artificial Intelligence (UAI-96) | Knowledge engineering for large belief networks | In Un­ certainty in Artificial Intelligence 5 | Artificial Intelli­ gence,rejected,000
1301.2263.pdf.json,Linearity Properties of Bayes Nets with Binary Variables,,"From Covariation to Causation: A Causal Power Theory. | A Characterization of Monotone Unidimensional Latent Variable Models. | Causality: Models, Reasoning, and Inference",rejected,000
1301.2265.pdf.json,Hybrid Processing of Beliefs and Constraints*,,Nonserial Dynamic Programming | Hybrid processing of belief and constraints | Bucket elimination: A unifying framework for probabilistic inference al­ gorithms | Bucket elimination: A unifying framework for reasoning | A tractable in­ ference algorithm for diagnosing multiple diseases | A computational theory of decision net­ works | Probabilistic models for query approx­ imation with 20 large sparse binary data sets | Probabilistic Reasoning in In­ telligent Systems | Probabilistic partial evalua­ tion: Exploiting structure in probabilistic inference | Bayesian networks for dependency anal­ ysis: an application to digital control | Res­ olution vs | Turbo decoding as an instance of pearl's belief propagation algorithm,rejected,000
