{
  "name" : "98.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "1 000\n012\n013\n014\n015\n016\n017\n018\n019\n020\n021\n022\n023\n024\n025\n026\n027\n028\n029\n030\n031\n032\n033\n034\n035\n036\n037\n038\n039\n040\n041\n042\n043\n044\n045\n046\n047\n048\n049\n050\n051\n064\n065\n066\n067\n068\n069\n070\n071\n072\n073\n074\n075\n076\n077\n078\n079\n080\n081\n082\n083\n084\n085\n086\n087\n088\n089\n090\n091\n092\n093\n094\n095\n096\n097\n098\n099\n100\n101\n102\n103"
    }, {
      "heading" : "1 Introduction",
      "text" : "In the last two decades, many dependency treebanks for various languages have been manually annotated. They differ in word categories (POS tagset), syntactic categories (dependency relations), and structure for individual language phenomena. The CoNLL shared tasks for dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007) unified the file format, and thus the dependency parsers could easily work with 20 different treebanks. Still, the parsing outputs were not comparable between languages since the annotation styles differed even between closely related languages.\nIn recent years, there have been a huge effort to normalize dependency annotation styles. The Stanford dependencies (de Marneffe and Manning, 2008) were adjusted to be more universal across languages (de Marneffe et al., 2014). Mc-\ndonald et al. (2013) started to develop Google Universal Treebank, a collection of new treebanks with common annotation style using the Stanford dependencies and Universal tagset (Petrov et al., 2012) consisting of 12 part-of-speech tags. Zeman et al. (2012) produced a collection of treebanks HamleDT, in which about 30 treebanks were automatically converted to a Prague Dependency Treebank style (Hajič et al., 2006). Later, they converted all the treebanks also into the Stanford style (Rosa et al., 2014).\nThe researchers from the previously mentioned projects joined their efforts to create one common standard: Universal Dependencies (Nivre et al., 2016). They used the Stanford dependencies (de Marneffe et al., 2014) with minor changes, extended the Google universal tagset (Petrov et al., 2012) from 12 to 17 part-of-speech tags and used the Interset morphological features (Zeman, 2008) from the HamleDT project (Zeman et al., 2014). In the current version 1.2, Universal Dependencies collection (UD) consists of 37 treebanks of 33 different languages and it is very likely that it will continue growing and become common source and standard for many researchers. Now, it is time to revisit the dependency parsing methods and to investigate their behavior on this new unified style.\nThe goal of this paper is to apply cross language delexicalized transfer parsers (e.g. (McDonald et al., 2011)) on UD and compare their results with unsupervised and minimally supervised parser. Both the methods are intended for parsing languages, for which no annotated treebank exists and both the methods can profit from UD.\nIn the area of dependency parsing, the term ”unsupervised” is understood as that no annotated treebanks are used for training and when supervised POS tags are used for grammar inference, we can deal with them only as with further un-\n2\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n123\n124\n125\n126\n127\n128\n129\n130\n131\n132\n133\n134\n135\n136\n137\n138\n139\n140\n141\n142\n143\n144\n145\n146\n147\n148\n149\n150\n151\n152\n153\n154\n155\n156\n157\n158\n159\n160\n161\n162\n163\n164\n165\n166\n167\n168\n169\n170\n171\n172\n173\n174\n175\n176\n177\n178\n179\n180\n181\n182\n183\n184\n185\n186\n187\n188\n189\n190\n191\n192\n193\n194\n195\n196\n197\n198\n199\n200\n201\n202\n203\n204\n205\n206\n207\nspecified types of word.1 Therefore, we introduce a minimally supervised parser: We use unsupervised dependency parser operating on supervised POS tags, however, we add external prior probabilities that push the inferred dependency trees in the right way. These external priors can be set manually as handwritten rules or trained on other treebanks, similarly as the transfer parsers. This allows us to compare the parser settings with different degrees of supervision:\n• delexicalized training of supervised parsers\n• minimally supervised parser using some external probabilities learned in supervised way\n• minimally supervised parser using a couple of external probabilities set manually\n• fully unsupervised parser\nIdeally, the parser should learn only the language-independent characteristics of dependency trees. However, it is hard to define what such characteristics are. For each particular language, we will show what degree of supervision is the best for parsing. Our hypothesis is that a kind of minimally supervised parser can compete with delexicalized transfer parsers."
    }, {
      "heading" : "2 Related Work",
      "text" : "There were many papers dealing with delexicalized parsing. Zeman and Resnik (2008) transfer a delexicalized parsing model to Danish and Swedish. McDonald et al. (2011) present a transfer-parser matrix from/to 9 European languages and introduce also multi-source transfer, where more training treebanks are concatenated to form more universal data. Both papers mention the problem of different annotation styles across treebanks, which complicates the transfer. Rosa (2015) uses already harmonized treebanks (Rosa et al., 2014) and compare the delexicalized parsing for Prague and Stanford annotation styles.\nUnsupervised dependency parsing methods made a big progress started by the Dependency Model with Valence (Klein and Manning, 2004), which was further improved by many other researchers (Headden III et al., 2009; Blunsom and Cohn, 2010; Spitkovsky et al., 2011b; Spitkovsky\n1In the fully unsupervised setting, we cannot for example simply push verbs to the roots and nouns to become their dependents. This is already a kind of supervision.\net al., 2012). Many of these works induce grammar based on the gold POS tags, some of them use unsupervised word classes (Spitkovsky et al., 2011a; Mareček, 2015). However, it seems that the research in this field declines in the recent years, probably because its results are still not able to compete with projection and delexicalized methods. Naseem et al. (2010) joined unsupervised grammar induction with a couple of syntactic rules."
    }, {
      "heading" : "3 Data",
      "text" : "In all our experiments, we use the Universal Dependencies treebank collection2 in its current version 1.2. For languages for which there is more than one treebank, we experiment only with the first one.3 We also exclude ’Japan-KTC’ treebank, since the full data are not available. Finally, we experiment with 32 dependency treebanks, each representing a different language. The treebanks, their language families, and their sizes are listed in Table 1.\nBefore training the parsers, all the treebanks are delexicalized. We substitute all the forms and lemmas by underscores, which are used for undefined values. The same is done with the morphological features and dependency relations. The only information remained is the universal POS tags and the dependency structure (the parent number for each token). The Universal Dependencies use POS tagset consisting of 17 POS tags listed in Table 2."
    }, {
      "heading" : "4 Experiments",
      "text" : "In the following experiments, we compare delexicalized transfer parsing methods and minimallysupervised methods on the UD treebanks. All the experiments are conducted as if we parsed a language whose syntax is unknown for us. This means that we do not prefer training on syntactically similar languages, we do not prefer right branching or left branching, and do not add language specific word-order rules like preferring SVO or SOV, adjectives before nouns, prepositions vs. postpositions etc.\n2universaldependencices.org 3We exclude ’Ancient Greek-PROIEL’, ’Finnish-FTB’,\n’Japan-KTC’, ’Latin-ITT’, and ’Latin-PROIEL’ treebanks.\n3\n209\n210\n211\n212\n213\n214\n215\n216\n217\n218\n219\n220\n221\n222\n223\n224\n225\n226\n227\n228\n229\n230\n231\n232\n233\n234\n235\n236\n237\n238\n239\n240\n241\n242\n243\n244\n245\n246\n247\n248\n249\n250\n251\n252\n253\n254\n255\n256\n257\n258\n259\n260\n261\n262\n263\n264\n265\n266\n267\n268\n269\n270\n271\n272\n273\n274\n275\n276\n277\n278\n279\n280\n281\n282\n283\n284\n285\n286\n287\n288\n289\n290\n291\n292\n293\n294\n295\n296\n297\n298\n299\n300\n301\n302\n303\n304\n305\n306\n307\n308\n309\n310\n311\nlanguage family tokens ar Arabic Semitic 282384 bg Bulgarian Slavic 156319 cu Old Slav. Slavic 57507 cs Czech Slavic 1503738 da Danish Germanic 100733 de German Germanic 293088 el Greek Hellenic 59156 en English Germanic 254830 es Spanish Romance 423346 et Estonian Uralic 6461 eu Basque isolate 121443 fa Persian Iranian 151624 fi Finnish Uralic 181022 fr French Romance 389764 ga Irish Celtic 23686 got Gothic Germanic 56128 grc Old Greek Hellenic 244993 he Hebrew Semitic 115535 hi Hindi Indo-Iranian 351704 hr Croatian Slavic 87765 hu Hungarian Uralic 26538 id Indonesian Malayic 121923 it Italian Romance 252967 la Latin Romance 47303 nl Dutch Germanic 200654 no Norwegian Germanic 311277 pl Polish Slavic 83571 pt Portuguese Romance 212545 ro Romanian Romance 12094 sl Slovenian Slavic 140418 sv Swedish Germanic 96819 ta Tamil Dravidian 9581\nTable 1: Languages and their families used in the experiments and sizes of the respective treebanks.\nADJ adjective PART particle ADP adposition PRON pronoun ADV adverb PROPN proper noun AUX auxiliary verb PUNCT punctuation\nCONJ coord. conj. SCONJ subord. conj. DET determiner SYM symbol INTJ interjection VERB verb\nNOUN noun X other NUM numeral\nTable 2: List of part-of-speech tags used in Universal-Dependencies treebanks."
    }, {
      "heading" : "4.1 Delexicalized parsing",
      "text" : "We apply the multi-source transfer of delexicalized parser on the UD treebanks in a similar way as McDonald et al. (2011). We use the leave-oneout method: for each language, the delexicalized parser is trained on all other treebanks excluding the one on which the parser is tested. Since all the treebanks share the tagset and annotation style, the training data can be simply concatenated together. To decrease the size of the training data and to reduce the training time, we decided to take only first 10,000 tokens for each language, so the final size of the training data is about 300,000 tokens, which is enough for training delexicalized parser. We use the Malt parser4 (Nivre, 2009), and MST parser (McDonald et al., 2005) with several parameter settings. The results are shown in Table 5."
    }, {
      "heading" : "4.2 Minimally supervised parsing",
      "text" : "The goal of this paper is to investigate whether the unsupervised parser with added external prior probabilities reflecting the universal annotation scheme is able to compete with the delexicalized methods described in Section 4.1.\nWe use the unsupervised dependency parser (UDP) implemented by Mareček and Straka (2013). The reason for this choice was that it has reasonably good results across many languages (Mareček, 2015), the source code is freely available,5 and because it includes a mechanism how to import external probabilities. The UDP is based on Dependency Model with Valence, a generative model which consists of two sub-models:\n• Stop model pstop(·|tg, dir) represents probability of not generating another dependent in direction dir to a node with POS tag tg. The direction dir can be left or right. If pstop = 1, the node with the tag tg cannot have any dependent in direction dir. If it is 1 in both directions, the node is a leaf.\n• Attach model pattach(td|tg, dir) represents probability that the dependent of the node with POS tag tg in direction dir is labeled with POS tag td.\nIn other words, the stop model generates edges, while the attachmodel generates POS tags for the\n4Malt parser in the current version 1.8.1 (http://maltparser.org)\n5http://ufal.mff.cuni.cz/udp\n4\n313\n314\n315\n316\n317\n318\n319\n320\n321\n322\n323\n324\n325\n326\n327\n328\n329\n330\n331\n332\n333\n334\n335\n336\n337\n338\n339\n340\n341\n342\n343\n344\n345\n346\n347\n348\n349\n350\n351\n352\n353\n354\n355\n356\n357\n358\n359\n360\n361\n362\n363\n370\n371\n372\n373\n374\n375\n376\n377\n378\n379\n380\n381\n382\n383\n384\n385\n386\n387\n388\n389\n390\n391\n392\n393\n394\n395\n396\n397\n398\n399\n400\n401\n402\n403\n404\n405\n406\n407\n408\n409\n410\n411\n412\n413\n414\n415\ntg p ext stop ADP, ADV, AUX, CONJ, DET, INTJ, NUM, PART, 1.0 PRON, PUNCT, SCONJ, SYM ADJ 0.9 PROPN 0.7 X 0.5 NOUN 0.3 VERB 0.1\nTable 3: Manual assignment of stop probabilities for individual POS tags.\nnew nodes. The inference is done using blocked Gibbs sampling (Gilks et al., 1996). During the inference, the attach and the stop probabilities can be combined linearly with external prior probabilities pext:\npfinalstop = (1− λstop) · pstop + λstop · pextstop,\npfinalattach = (1− λatach) · pattach + λattach · p ext attach,\nwhere the parameters λ define their weights. In the original paper (Mareček and Straka, 2013), the external priors pextstop were computed based on the reducibility principle on a big raw corpora."
    }, {
      "heading" : "4.2.1 Manually Assigned Priors",
      "text" : "We use the external prior probabilities to define grammatical rules for POS tags based on UD annotation style. The first type of priors describes how likely a node with a particular POS is a leaf. We manually set the pextstop as listed in Table 3. Even though it is possible to define different left and right pextstop, we decided to set it equally for both the directions, since it is linguistically more language independent.\nIn a similar way, we predefine external priors for pextattach, describing dependency edges.\n6 Preliminary experiments showed that less is more in this type of rules. We ended up only with four rules for attaching punctuation and prepositions, as defined in Table 4.7 Similarly as for pextstop, we set them equally for both left and right directions. We set λattach = 0 for all other possible types of edges, since the priors are not defined for them.\n6We had to change the original parser code to do this. 7Note that for example pextattach(PUNC|V ERB, dir) = 1 does not mean that all the dependents of VERB must be PUNC. Since the λattach is less than one, the value 1 only pushes punctuation to be attached below verbs."
    }, {
      "heading" : "4.2.2 Automatically Assigned Priors",
      "text" : "Instead of setting the external probabilities manually, we can compute them automatically from other treebanks. Such experiments are somewhere in the middle between delexicalized parsers and the minimally supervised parser with some manually added knowledge. They learn some regularities but not as many as the delexicalized parsers do.\nSimilarly as for delexicalized transfer parser, we compute the probabilities on all treebanks but the one which is currently tested. The probabilities are computed in the following way:\npextstop(·|tg, dir) = NC(tg)\nCC(tg, dir) +NC(tg) ,\nwhere NC(tg) is count of all nodes labelled with tag tg across all the training treebanks, CC(tg, dir) is the total number of children in direction dir of all tg nodes in the treebanks, and\npextattach(td|tg, dir) = NE(tg, td, dir)\nNE(tg, ∗, dir) ,\nwhere NE(tg, td, dir) is number of dependency edges where the governing node has the POS tag tg, and the dependent node td and is in direction dir from the governing one.\nWe introduce two additional experiments: direction-dependent learned priors (DDLP) and direction-independent learned priors (DILP). The external probabilities for DDLP are computed according to the previously mentioned formulas.\nIn DILP, the probabilities are independent on the direction parameter dir. pextstop(·|tg) and pextattach(td|tg) obtain the same values for both directions. Such approach is therefore less supervised. We suppose, that it gains worse results form majority of languages, however, it could be better for some of languages with word ordering different from the majority of languages.\n5\n417\n418\n419\n420\n421\n422\n423\n424\n425\n426\n427\n428\n429\n430\n431\n432\n433\n434\n435\n436\n437\n438\n439\n440\n441\n442\n443\n444\n445\n446\n447\n448\n449\n450\n451\n452\n453\n454\n455\n456\n457\n458\n459\n460\n461\n462\n463\n464\n465\n466\n467\n468\n469\n470\n471\n472\n473\n474\n475\n476\n477\n478\n479\n480\n481\n482\n483\n484\n485\n486\n487\n488\n489\n490\n491\n492\n493\n494\n495\n496\n497\n498\n499\n500\n501\n502\n503\n504\n505\n506\n507\n508\n509\n510\n511\n512\n513\n514\n515\n516\n517\n518\n519\nMST parser Malt parser UDP lang. proj nproj lazy nivre basic +rules DDLP DILP ar 48.8 51.2 50.2 50.4 42.9 51.7 55.2 48.0 bg 79.0 78.5 78.1 77.4 52.6 74.6 73.2 66.8 cu 64.8 66.0 63.1 62.6 46.8 58.1 64.5 59.7 cs 68.0 68.4 66.3 65.8 43.6 60.2 62.8 55.4 da 71.0 71.7 66.9 67.2 40 9 57.7 89.6 54.8 de 69.8 70.0 65.2 65.4 37.4 60.9 63.5 59.8 el 64.3 64.9 63.8 64.1 13.1 63.2 62.3 55.9 en 62.1 62.4 58.2 58.3 28.1 54.6 54.5 53.0 es 71.5 72.2 68.8 69.0 20.4 63.7 66.3 56.1 et 76.4 75.1 70.9 70.5 26.8 79.2 74.6 80.3 eu 50.0 51.2 51.8 50.9 47.1 53.8 50.5 52.3 fa 52.8 54.8 54.0 54.0 41.0 54.8 57.5 45.0 fi 55.1 55.8 50.5 50.4 27.6 48.8 46.6 48.7 fr 74.3 74.8 71.5 71.5 36.0 65.8 69.0 57.9 ga 60.7 61.4 61.1 61.3 37.1 60.2 61.5 57.3 got 63.6 64.5 62.8 62.1 47.3 60.2 62.4 57.4 grc 47.2 48.0 45.8 45.5 41.2 50.6 51.4 51.2 he 62.5 64.0 63.1 62.7 28.2 62.4 64.0 56.5 hi 33.5 34.2 35.5 35.1 42.3 50.9 38.4 54.0 hr 69.3 69.4 67.3 67.1 24.7 61.5 63.4 54.8 hu 57.4 58.0 54.6 54.2 53.4 57.4 55.4 62.8 id 58.5 61.0 59.2 58.6 22.7 48.4 61.3 51.6 it 76.4 77.1 74.0 73.8 42.3 68.8 71.5 60.1 la 56.5 55.9 55.5 55.8 47.0 51.8 52.0 47.1 nl 60.2 60.1 56.5 57.3 37.5 51.2 54.9 48.5 no 70.2 70.4 67.2 66.9 40.9 58.5 61.4 55.7 pl 75.6 76.0 74.7 75.0 63.8 68.0 67.7 64.6 pt 73.9 74.3 72.4 71.7 40.1 64.6 69.4 58.2 ro 68.3 69.3 68.2 67.7 60.4 57.9 66.3 58.9 sl 72.2 72.8 71.2 70.6 48.6 68.6 64.9 56.8 sv 70.2 70.8 66.2 66.2 41.5 59.5 61.7 58.7 ta 34.3 36.5 35.5 35.6 52.2 52.9 48.4 58.4 avg 63.1 63.8 61.6 61.4 39.9 59.4 60.5 56.5\nTable 5: Unlabeled attachment scores for the parsers across the languages. The best results are in bold. For MST parser, we used the second order features and its projective (proj) and non-projective (nonproj) variant. For the Malt parser, we used lib-SVM training and stacklazy (lazy) and nivreeager (nivre) algorithms. Unsupervised dependency parser (UDP) was tested without any external priors (basic), with manual prior probabilities (+rules), and with automatically learned probabilities direction dependent (DDLP) and direction independent (DILP)."
    }, {
      "heading" : "5 Results",
      "text" : "The results of delexicalized transfer parsers, unsupervised parser and minimally supervised parsers with different degrees of supervision on Universal Dependencies are compared in Table 5. We try several settings of parameters for both Malt parser and MST parser, and show the results of two of\nthem for each one.8 We run the Unsupervised dependency parser by Mareček and Straka (2013), labeled as UDP. For UDP, we report four different setings. The basic variant is completely unsupervised parsing without any external prior probabilities. The +rules column shows the results of\n8The results of different parameter settings for both parser varied only little (at most 2% difference for all the languages).\n6\n521\n522\n523\n524\n525\n526\n527\n528\n529\n530\n531\n532\n533\n534\n535\n536\n537\n538\n539\n540\n541\n542\n543\n544\n545\n546\n547\n548\n549\n550\n551\n552\n553\n554\n555\n556\n557\n558\n559\n560\n561\n562\n563\n564\n565\n566\n567\n568\n569\n570\n571\n572\n573\n574\n575\n576\n577\n578\n579\n580\n581\n582\n583\n584\n585\n586\n587\n588\n589\n590\n591\n592\n593\n594\n595\n596\n597\n598\n599\n600\n601\n602\n603\n604\n605\n606\n607\n608\n609\n610\n611\n612\n613\n614\n615\n616\n617\n618\n619\n620\n621\n622\n623\n0\n20\n40\n60\n80\n100\nbg cu cs hr pl sl da de en got nl no sv et fi hu\n+rules dilp ddlp mst\n0\n20\n40\n60\n80\n100\nes fr it la pt ro el grc fa ga ar eu he hi id ta\n+rules dilp ddlp mst\nFigure 1: Comparison of delexicalized parsing methods with different degrees of supervision. UDP with manually set priors (+rules), direction dependent (DDLP) and independent (DILP) learning of priors versus delexicalized transfer of MST parser (mst). Languages are ordered according to their language families: Slavic (bg, cu, cs, hr, pl, sl), Germanic (da, de, en, got, nl, no, sv), Romance (es, fr, it, la, pt, ro), Hellenic (el, grc), Uralic (et, fi, hu), and others (fa, ga, ar, eu, he, hi, id, ta).\nour minimally supervised parser (Section 4.2.1) using the external probabilities defined manually (Tables 3 and 4). Both the λstop and λattach parameters are set to 0.5. The DDLP and DILP variants use automatically learned prior probabilities form other treebanks (Section 4.2.2)."
    }, {
      "heading" : "5.1 Discussion",
      "text" : "It is evident that the MST parser achieved the best scores. It parsed best 20 out of 32 languages and its non-projective variant reached 63.8% averaged attachment score. The Malt parser was worse than MST by 2% in the averaged attachment score.9 The basic UDP without additional rules performs very poorly, however, with added external prior probabilities, it is competitive with the delexicalized transfer parser methods. 12 out of 32 languages were parsed better by UDP using one variant of the external priors.\nWith hand-written prior probabilities (+rules),\n9We used the Malt parser with its default feature set. Tuning in this specific delexicalized task would probably bring a bit better results.\nthe averaged attachment score reached only 59%, however, it is better than the MST parser on 6 languages: Arabic, Estonian, Basque, Old Greek, Hindi, and Tamil, in two cases by a wide margin. For Persian, the scores are equal.\nThe averaged attachment score for UDP with direction-independent learned priors (DILP) is even lower (56.5%), however, it parsed 6 languages better than MST: Estonian, Basque, Old Greek, Hindi, Hungarian, and Tamil. Direction dependent learning of priors end up with 60.5% attachment score and 9 languages better than MST.\nBased on these results, we can say that the minimally supervised parser, which takes less information from other annotated treebanks, is more suitable for the more exotic languages, i.e. for languages whose families are less common among the annotated treebanks. Figure 4.2.2 shows histograms of attachment scores across languages, now ordered according to the language families. All the Slavic and Romance languages and almost all the Germanic languages10 are parsed best by\n10Danish is the only exception.\n7\n625\n626\n627\n628\n629\n630\n631\n632\n633\n634\n635\n636\n637\n638\n639\n640\n641\n642\n643\n644\n645\n646\n647\n648\n649\n650\n651\n652\n653\n654\n655\n656\n657\n658\n659\n660\n661\n662\n663\n664\n665\n666\n667\n668\n669\n670\n671\n672\n673\n674\n675\n676\n677\n678\n679\n680\n681\n682\n683\n684\n685\n686\n687\n688\n689\n690\n691\n692\n693\n694\n695\n696\n697\n698\n699\n700\n701\n702\n703\n704\n705\n706\n707\n708\n709\n710\n711\n712\n713\n714\n715\n716\n717\n718\n719\n720\n721\n722\n723\n724\n725\n726\n727\nthe MST parser. Finnish from the three Uralic languages and Greek from the two Hellenic languages are also parsed best by MST. Other 12 languages were better parsed by one of the less supervised methods.\nLess-resourced languages, for which the annotated treebanks are missing, may be therefore better parsed by less supervised parsers, especially if they do not belong to the Indo-European language family. The MST transfer parser has probably been over-trained on these Indo-European family languages and is not able to generalize enough to more distant languages. The rules we added to the unsupervised dependency parser (+rules experiment) are universal in the direction of dependencies (left/right branching) and cover much more languages."
    }, {
      "heading" : "5.2 Transfer parser comparison between different styles",
      "text" : "We compare the best transfer parser results also with the previous works. Even though the results are not directly comparable, because different annotation styles were used, we suppose that the annotation unification across the treebanks in Universal Dependencies should improve the transfer parser scores. McDonald et al. (2011) presented 61.7% of averaged accuracy over 8 languages. On the same languages, our transfer parser on UD reached 70.1%. When compared to Rosa (2015), we experimented with 23 common languages, our average score on them is 62.5%, Rosa’s is 56.6%. The higher attachment scores in our experiments confirms that the annotations in UD treebanks are more unified and serve better for transferring between languages."
    }, {
      "heading" : "6 Conclusions",
      "text" : "We used the Universal Dependencies treebank collection to test delexicalized transfer parsers and unsupervised dependency parser enriched by external attach and stop prior probabilities. We found that whereas the MST delexicalized transfer parser is better in average, our minimally supervised parser performs better on many non-IndoEuropean languages and therefore can be suitable to parse often low-resourced exotic languages, for which treebanks do not exist."
    } ],
    "references" : [ {
      "title" : "Unsupervised induction of tree substitution grammars for dependency parsing",
      "author" : [ "Phil Blunsom", "Trevor Cohn." ],
      "venue" : "Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP ’10, pages 1204–1213,",
      "citeRegEx" : "Blunsom and Cohn.,? 2010",
      "shortCiteRegEx" : "Blunsom and Cohn.",
      "year" : 2010
    }, {
      "title" : "CoNLL-X shared task on multilingual dependency parsing",
      "author" : [ "Sabine Buchholz", "Erwin Marsi." ],
      "venue" : "Proceedings of the Tenth Conference on Computational Natural Language Learning, CoNLL-X ’06, pages 149–164, Stroudsburg, PA, USA. Association",
      "citeRegEx" : "Buchholz and Marsi.,? 2006",
      "shortCiteRegEx" : "Buchholz and Marsi.",
      "year" : 2006
    }, {
      "title" : "The stanford typed dependencies representation",
      "author" : [ "Marie-Catherine de Marneffe", "Christopher D. Manning." ],
      "venue" : "Coling 2008: Proceedings of the Workshop on Cross-Framework and Cross-Domain Parser Evaluation, CrossParser ’08, pages 1–8,",
      "citeRegEx" : "Marneffe and Manning.,? 2008",
      "shortCiteRegEx" : "Marneffe and Manning.",
      "year" : 2008
    }, {
      "title" : "Universal stanford dependencies: A cross-linguistic typology",
      "author" : [ "Marie-Catherine de Marneffe", "Timothy Dozat", "Natalia Silveira", "Katri Haverinen", "Filip Ginter", "Joakim Nivre", "Christopher D Manning." ],
      "venue" : "Proceedings of the 9th Conference on Lan-",
      "citeRegEx" : "Marneffe et al\\.,? 2014",
      "shortCiteRegEx" : "Marneffe et al\\.",
      "year" : 2014
    }, {
      "title" : "Markov chain Monte Carlo in practice",
      "author" : [ "Walter R. Gilks", "S. Richardson", "David J. Spiegelhalter." ],
      "venue" : "Interdisciplinary statistics. Chapman & Hall.",
      "citeRegEx" : "Gilks et al\\.,? 1996",
      "shortCiteRegEx" : "Gilks et al\\.",
      "year" : 1996
    }, {
      "title" : "Improving unsupervised dependency parsing with richer contexts and smoothing",
      "author" : [ "William P. Headden III", "Mark Johnson", "David McClosky." ],
      "venue" : "Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American",
      "citeRegEx" : "III et al\\.,? 2009",
      "shortCiteRegEx" : "III et al\\.",
      "year" : 2009
    }, {
      "title" : "Corpus-based induction of syntactic structure: models of dependency and constituency",
      "author" : [ "Dan Klein", "Christopher D. Manning." ],
      "venue" : "Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, ACL ’04, Stroudsburg, PA,",
      "citeRegEx" : "Klein and Manning.,? 2004",
      "shortCiteRegEx" : "Klein and Manning.",
      "year" : 2004
    }, {
      "title" : "Multilingual unsupervised dependency parsing with unsupervised pos tags",
      "author" : [ "David Mareček." ],
      "venue" : "Grigorii Sidorov and N. Sofı́a Galicia-Haro, editors, Advances in Artificial Intelligence and Soft Computing: 14th Mexican International Conference on Arti-",
      "citeRegEx" : "Mareček.,? 2015",
      "shortCiteRegEx" : "Mareček.",
      "year" : 2015
    }, {
      "title" : "Stopprobability estimates computed on a large corpus improve Unsupervised Dependency Parsing",
      "author" : [ "David Mareček", "Milan Straka." ],
      "venue" : "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long",
      "citeRegEx" : "Mareček and Straka.,? 2013",
      "shortCiteRegEx" : "Mareček and Straka.",
      "year" : 2013
    }, {
      "title" : "Non-Projective Dependency Parsing using Spanning Tree Algorithms",
      "author" : [ "Ryan McDonald", "Fernando Pereira", "Kiril Ribarov", "Jan Hajič." ],
      "venue" : "Proceedings of Human Langauge Technology Conference and Conference on Empirical Methods in Natural",
      "citeRegEx" : "McDonald et al\\.,? 2005",
      "shortCiteRegEx" : "McDonald et al\\.",
      "year" : 2005
    }, {
      "title" : "Multi-source transfer of delexicalized dependency parsers",
      "author" : [ "Ryan McDonald", "Slav Petrov", "Keith Hall." ],
      "venue" : "Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP 2011, pages 62–72, Stroudsburg, PA, USA.",
      "citeRegEx" : "McDonald et al\\.,? 2011",
      "shortCiteRegEx" : "McDonald et al\\.",
      "year" : 2011
    }, {
      "title" : "Using universal linguistic knowledge to guide grammar induction",
      "author" : [ "Tahira Naseem", "Harr Chen", "Regina Barzilay", "Mark Johnson." ],
      "venue" : "Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP 2010, pages",
      "citeRegEx" : "Naseem et al\\.,? 2010",
      "shortCiteRegEx" : "Naseem et al\\.",
      "year" : 2010
    }, {
      "title" : "The CoNLL 2007 Shared Task on Dependency Parsing",
      "author" : [ "Joakim Nivre", "Johan Hall", "Sandra Kübler", "Ryan McDonald", "Jens Nilsson", "Sebastian Riedel", "Deniz Yuret." ],
      "venue" : "Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007, pages",
      "citeRegEx" : "Nivre et al\\.,? 2007",
      "shortCiteRegEx" : "Nivre et al\\.",
      "year" : 2007
    }, {
      "title" : "Universal dependencies v1: A multilingual",
      "author" : [ "Joakim Nivre", "Marie-Catherine de Marneffe", "Filip Ginter", "Yoav Goldberg", "Jan Hajič", "Christopher Manning", "Ryan McDonald", "Slav Petrov", "Sampo Pyysalo", "Natalia Silveira", "Reut Tsarfaty", "Daniel Zeman" ],
      "venue" : null,
      "citeRegEx" : "Nivre et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Nivre et al\\.",
      "year" : 2016
    }, {
      "title" : "Non-projective dependency parsing in expected linear time",
      "author" : [ "Joakim Nivre." ],
      "venue" : "Keh-Yih Su, Jian Su, and Janyce Wiebe, editors, ACL/IJCNLP, pages 351–359. The Association for Computer Linguistics.",
      "citeRegEx" : "Nivre.,? 2009",
      "shortCiteRegEx" : "Nivre.",
      "year" : 2009
    }, {
      "title" : "A universal part-of-speech tagset",
      "author" : [ "Slav Petrov", "Dipanjan Das", "Ryan McDonald." ],
      "venue" : "Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC’12), Istanbul, Turkey, May. European Language Resources",
      "citeRegEx" : "Petrov et al\\.,? 2012",
      "shortCiteRegEx" : "Petrov et al\\.",
      "year" : 2012
    }, {
      "title" : "Hamledt 2.0: Thirty dependency treebanks stanfordized",
      "author" : [ "Rudolf Rosa", "Jan Mašek", "David Mareček", "Martin Popel", "Daniel Zeman", "Zdeněk Žabokrtský" ],
      "venue" : "In Proceedings of the Ninth International Conference on Language Resources and Eval-",
      "citeRegEx" : "Rosa et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Rosa et al\\.",
      "year" : 2014
    }, {
      "title" : "Multi-source cross-lingual delexicalized parser transfer: Prague or stanford? In Proceedings of the Third International Conference on Dependency Linguistics (Depling 2015), pages 281– 290, Uppsala, Sweden",
      "author" : [ "Rudolf Rosa." ],
      "venue" : "Uppsala University.",
      "citeRegEx" : "Rosa.,? 2015",
      "shortCiteRegEx" : "Rosa.",
      "year" : 2015
    }, {
      "title" : "Unsupervised dependency parsing without gold part-of-speech tags",
      "author" : [ "Valentin I. Spitkovsky", "Hiyan Alshawi", "Angel X. Chang", "Daniel Jurafsky." ],
      "venue" : "Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing",
      "citeRegEx" : "Spitkovsky et al\\.,? 2011a",
      "shortCiteRegEx" : "Spitkovsky et al\\.",
      "year" : 2011
    }, {
      "title" : "Punctuation: Making a point in unsupervised dependency parsing",
      "author" : [ "Valentin I. Spitkovsky", "Hiyan Alshawi", "Daniel Jurafsky." ],
      "venue" : "Proceedings of the Fifteenth Conference on Computational Natural Language Learning (CoNLL-2011).",
      "citeRegEx" : "Spitkovsky et al\\.,? 2011b",
      "shortCiteRegEx" : "Spitkovsky et al\\.",
      "year" : 2011
    }, {
      "title" : "Three Dependency-and-Boundary Models for Grammar Induction",
      "author" : [ "Valentin I. Spitkovsky", "Hiyan Alshawi", "Daniel Jurafsky." ],
      "venue" : "Proceedings of the 2012 Conference on Empirical Methods in Natural Language Processing and Computational Nat-",
      "citeRegEx" : "Spitkovsky et al\\.,? 2012",
      "shortCiteRegEx" : "Spitkovsky et al\\.",
      "year" : 2012
    }, {
      "title" : "Crosslanguage parser adaptation between related languages",
      "author" : [ "Daniel Zeman", "Philip Resnik." ],
      "venue" : "IJCNLP 2008 Workshop on NLP for Less Privileged Languages, pages 35–42, Hyderabad, India. Asian Federation of Natural Language Process-",
      "citeRegEx" : "Zeman and Resnik.,? 2008",
      "shortCiteRegEx" : "Zeman and Resnik.",
      "year" : 2008
    }, {
      "title" : "HamleDT: To Parse or Not to Parse",
      "author" : [ "Daniel Zeman", "David Mareček", "Martin Popel", "Loganathan Ramasamy", "Jan Štěpánek", "Zdeněk Žabokrtský", "Jan Hajič" ],
      "venue" : "In Proceedings of the Eight International Conference on Language Resources",
      "citeRegEx" : "Zeman et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Zeman et al\\.",
      "year" : 2012
    }, {
      "title" : "HamleDT: Harmonized multi-language dependency treebank",
      "author" : [ "Daniel Zeman", "Ondřej Dušek", "David Mareček", "Martin Popel", "Loganathan Ramasamy", "Jan Štěpánek", "Zdeněk Žabokrtský", "Jan Hajič." ],
      "venue" : "Language Resources and Evaluation,",
      "citeRegEx" : "Zeman et al\\.,? 2014",
      "shortCiteRegEx" : "Zeman et al\\.",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "The CoNLL shared tasks for dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007) unified the file format, and thus the dependency parsers could easily work with 20 different treebanks.",
      "startOffset" : 46,
      "endOffset" : 92
    }, {
      "referenceID" : 12,
      "context" : "The CoNLL shared tasks for dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007) unified the file format, and thus the dependency parsers could easily work with 20 different treebanks.",
      "startOffset" : 46,
      "endOffset" : 92
    }, {
      "referenceID" : 15,
      "context" : "(2013) started to develop Google Universal Treebank, a collection of new treebanks with common annotation style using the Stanford dependencies and Universal tagset (Petrov et al., 2012) consisting of 12 part-of-speech tags.",
      "startOffset" : 165,
      "endOffset" : 186
    }, {
      "referenceID" : 16,
      "context" : "Later, they converted all the treebanks also into the Stanford style (Rosa et al., 2014).",
      "startOffset" : 69,
      "endOffset" : 88
    }, {
      "referenceID" : 1,
      "context" : "The CoNLL shared tasks for dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007) unified the file format, and thus the dependency parsers could easily work with 20 different treebanks. Still, the parsing outputs were not comparable between languages since the annotation styles differed even between closely related languages. In recent years, there have been a huge effort to normalize dependency annotation styles. The Stanford dependencies (de Marneffe and Manning, 2008) were adjusted to be more universal across languages (de Marneffe et al., 2014). Mcdonald et al. (2013) started to develop Google Universal Treebank, a collection of new treebanks with common annotation style using the Stanford dependencies and Universal tagset (Petrov et al.",
      "startOffset" : 47,
      "endOffset" : 590
    }, {
      "referenceID" : 1,
      "context" : "The CoNLL shared tasks for dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007) unified the file format, and thus the dependency parsers could easily work with 20 different treebanks. Still, the parsing outputs were not comparable between languages since the annotation styles differed even between closely related languages. In recent years, there have been a huge effort to normalize dependency annotation styles. The Stanford dependencies (de Marneffe and Manning, 2008) were adjusted to be more universal across languages (de Marneffe et al., 2014). Mcdonald et al. (2013) started to develop Google Universal Treebank, a collection of new treebanks with common annotation style using the Stanford dependencies and Universal tagset (Petrov et al., 2012) consisting of 12 part-of-speech tags. Zeman et al. (2012) produced a collection of treebanks HamleDT, in which about 30 treebanks were automatically converted to a Prague Dependency Treebank style (Hajič et al.",
      "startOffset" : 47,
      "endOffset" : 828
    }, {
      "referenceID" : 13,
      "context" : "The researchers from the previously mentioned projects joined their efforts to create one common standard: Universal Dependencies (Nivre et al., 2016).",
      "startOffset" : 130,
      "endOffset" : 150
    }, {
      "referenceID" : 15,
      "context" : ", 2014) with minor changes, extended the Google universal tagset (Petrov et al., 2012) from 12 to 17 part-of-speech tags and used the Interset morphological features (Zeman, 2008) from the HamleDT project (Zeman et al.",
      "startOffset" : 65,
      "endOffset" : 86
    }, {
      "referenceID" : 23,
      "context" : ", 2012) from 12 to 17 part-of-speech tags and used the Interset morphological features (Zeman, 2008) from the HamleDT project (Zeman et al., 2014).",
      "startOffset" : 126,
      "endOffset" : 146
    }, {
      "referenceID" : 10,
      "context" : "(McDonald et al., 2011)) on UD and compare their results with unsupervised and minimally supervised parser.",
      "startOffset" : 0,
      "endOffset" : 23
    }, {
      "referenceID" : 16,
      "context" : "Rosa (2015) uses already harmonized treebanks (Rosa et al., 2014) and compare the delexicalized parsing for Prague and Stanford annotation styles.",
      "startOffset" : 46,
      "endOffset" : 65
    }, {
      "referenceID" : 6,
      "context" : "Unsupervised dependency parsing methods made a big progress started by the Dependency Model with Valence (Klein and Manning, 2004), which was further improved by many other researchers (Headden III et al.",
      "startOffset" : 105,
      "endOffset" : 130
    }, {
      "referenceID" : 11,
      "context" : "Zeman and Resnik (2008) transfer a delexicalized parsing model to Danish and Swedish.",
      "startOffset" : 0,
      "endOffset" : 24
    }, {
      "referenceID" : 6,
      "context" : "McDonald et al. (2011) present a transfer-parser matrix from/to 9 European languages and introduce also multi-source transfer, where more training treebanks are concatenated to form more universal data.",
      "startOffset" : 0,
      "endOffset" : 23
    }, {
      "referenceID" : 6,
      "context" : "McDonald et al. (2011) present a transfer-parser matrix from/to 9 European languages and introduce also multi-source transfer, where more training treebanks are concatenated to form more universal data. Both papers mention the problem of different annotation styles across treebanks, which complicates the transfer. Rosa (2015) uses already harmonized treebanks (Rosa et al.",
      "startOffset" : 0,
      "endOffset" : 328
    }, {
      "referenceID" : 18,
      "context" : "Many of these works induce grammar based on the gold POS tags, some of them use unsupervised word classes (Spitkovsky et al., 2011a; Mareček, 2015).",
      "startOffset" : 106,
      "endOffset" : 147
    }, {
      "referenceID" : 7,
      "context" : "Many of these works induce grammar based on the gold POS tags, some of them use unsupervised word classes (Spitkovsky et al., 2011a; Mareček, 2015).",
      "startOffset" : 106,
      "endOffset" : 147
    }, {
      "referenceID" : 7,
      "context" : ", 2011a; Mareček, 2015). However, it seems that the research in this field declines in the recent years, probably because its results are still not able to compete with projection and delexicalized methods. Naseem et al. (2010) joined unsupervised grammar induction with a couple of syntactic rules.",
      "startOffset" : 9,
      "endOffset" : 228
    }, {
      "referenceID" : 14,
      "context" : "We use the Malt parser4 (Nivre, 2009), and MST parser (McDonald et al.",
      "startOffset" : 24,
      "endOffset" : 37
    }, {
      "referenceID" : 9,
      "context" : "We use the Malt parser4 (Nivre, 2009), and MST parser (McDonald et al., 2005) with several parameter settings.",
      "startOffset" : 54,
      "endOffset" : 77
    }, {
      "referenceID" : 9,
      "context" : "1 Delexicalized parsing We apply the multi-source transfer of delexicalized parser on the UD treebanks in a similar way as McDonald et al. (2011). We use the leave-oneout method: for each language, the delexicalized parser is trained on all other treebanks excluding the one on which the parser is tested.",
      "startOffset" : 123,
      "endOffset" : 146
    }, {
      "referenceID" : 7,
      "context" : "The reason for this choice was that it has reasonably good results across many languages (Mareček, 2015), the source code is freely available,5 and because it includes a mechanism how to import external probabilities.",
      "startOffset" : 89,
      "endOffset" : 104
    }, {
      "referenceID" : 7,
      "context" : "We use the unsupervised dependency parser (UDP) implemented by Mareček and Straka (2013). The reason for this choice was that it has reasonably good results across many languages (Mareček, 2015), the source code is freely available,5 and because it includes a mechanism how to import external probabilities.",
      "startOffset" : 63,
      "endOffset" : 89
    }, {
      "referenceID" : 4,
      "context" : "The inference is done using blocked Gibbs sampling (Gilks et al., 1996).",
      "startOffset" : 51,
      "endOffset" : 71
    }, {
      "referenceID" : 8,
      "context" : "In the original paper (Mareček and Straka, 2013), the external priors pext stop were computed based on the reducibility principle on a big raw corpora.",
      "startOffset" : 22,
      "endOffset" : 48
    }, {
      "referenceID" : 7,
      "context" : "8 We run the Unsupervised dependency parser by Mareček and Straka (2013), labeled as UDP.",
      "startOffset" : 47,
      "endOffset" : 73
    }, {
      "referenceID" : 9,
      "context" : "McDonald et al. (2011) presented 61.",
      "startOffset" : 0,
      "endOffset" : 23
    }, {
      "referenceID" : 9,
      "context" : "McDonald et al. (2011) presented 61.7% of averaged accuracy over 8 languages. On the same languages, our transfer parser on UD reached 70.1%. When compared to Rosa (2015), we experimented with 23 common languages, our average score on them is 62.",
      "startOffset" : 0,
      "endOffset" : 171
    } ],
    "year" : 2016,
    "abstractText" : "In this paper, we compare delexicalized transfer and minimally supervised parsing techniques on 32 different languages from Universal Dependencies treebank collection. The minimal supervision is in adding handcrafted universal grammatical rules for POS tags. The rules are incorporated into the unsupervised dependency parser in forms of external prior probabilities. We also experiment with learning this probabilities from other treebanks. The average attachment score of our parser is slightly lower then the delexicalized transfer parser, however, it performs better for languages from less resourced language families (non-Indo-European) and is therefore suitable for those, for which the treebanks often do not exist.",
    "creator" : "TeX"
  }
}