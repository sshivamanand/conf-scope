{
  "name" : "66.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Generating Memorable Mnemonic Encodings of Numbers",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "1 000\n011\n012\n013\n014\n015\n016\n017\n018\n019\n020\n021\n022\n023\n024\n025\n026\n027\n028\n029\n030\n031\n032\n033\n034\n035\n036\n037\n038\n039\n040\n041\n042\n043\n044\n045\n046\n047\n048\n049\n074\n075\n076\n077\n078\n079\n080\n081\n082\n083\n084\n085\n086\n087\n088\n089\n090\n091\n092\n093\n094\n095\n096\n097\n098\n099"
    }, {
      "heading" : "1 Introduction",
      "text" : "The major system is a mnemonic device used to help memorize numbers. The system works by mapping each digit of a number to a consonant phoneme and allowing for arbitrary insertion of vowel phonemes to produce words (FauvelGouraud, 1845). For instance, the digit 1 maps to <T>, and the digit 2 maps to <N>. The number 121 can then be encoded as the word tent by replacing both 1s with <T>s, replacing the 2 with <N>, and inserting an <e>. The full major system mapping is shown in Table 1.\nThe difficulty of generating a memorable sequence of words that encodes a number with the major system stems from the constraint that the sequence of words must encode exactly the given digits. While there are many sequences of words that correctly encode a given number, the vast majority of these sequences are incoherent and thus difficult to remember. So, this task requires the use of a language model that balances the encoding constraints with syntactic plausibility and some notion of memorability.\nWe have developed a system that automatically produces a sequence of words to encode a se-\nquence of digits. Each such encoding is a sequence of sentences that balance memorability and length. We sample from a distribution of partof-speech (POS) templates to produce a syntactically plausible sentence, then use an n-gram language model to fill each POS slot in the selected template to produce an encoding.\nA system like ours can be used to memorize fairly short numbers, such as a numeric password, a phone number, or an account number; or to memorize arbitrarily long numbers, like digits of π. One could use our system to encode a smartphone passcode as a short sentence. Thus, our system can help improve the strength of security practices.\nTo test the effectiveness of our system, we conducted a study on password memorability. Participants were asked to memorize an eight-digit number representing a numeric password and a phrase produced by our system to encode the same number. After seven days, participants remembered the encoding produced by our final model better than the number itself. Participants also stated a\n2\n101\n102\n103\n104\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n123\n124\n125\n126\n127\n128\n129\n130\n131\n132\n133\n134\n135\n136\n137\n138\n139\n140\n141\n142\n143\n144\n145\n146\n147\n148\n149\n150\n151\n152\n153\n154\n155\n156\n157\n158\n159\n160\n161\n162\n163\n164\n165\n166\n167\n168\n169\n170\n171\n172\n173\n174\n175\n176\n177\n178\n179\n180\n181\n182\n183\n184\n185\n186\n187\n188\n189\n190\n191\n192\n193\n194\n195\n196\n197\n198\n199\nstrong preference for our final model’s encodings. The rest of this paper is organized as follows. Section 2 describes existing systems for automatically generating encodings with the major system and puts our work in the context of related academic problems. In Section 3, we describe the different encoding models that we studied. Section 4 gives results and analysis of our models. In Section 5, we describe the password memorability study we conducted. We describe possible extensions to our work and conclude in Section 6."
    }, {
      "heading" : "2 Previous Work",
      "text" : "Several tools are available online for generating naive encodings of numbers using the major system. In this section, we describe those tools and identify the shortcomings in those implementations that are addressed by our work. We also put our work into the context of previous studies on password memorability."
    }, {
      "heading" : "2.1 Existing Tools",
      "text" : "There are a number of existing tools that use the major system to encode sequences of digits as sequences of words. However, all such tools we found have considerable limitations. Most notably, the majority of these tools simply return the entire set of words that can individually encode the given number.\nMany mobile applications will generate encodings, but their focus appears to be on helping users learn the major system and not on generating memorable encodings automatically (Shichijo, 2014; Reindl, 2015; Vladislav, 2016; Scott, 2015a; Pfeiffer, 2013; Buder, 2012). None of these tools rank the multiple encodings they produce, and none of them produce sentences. Most of these tools only produce one- or two-word encodings, greatly limiting the length of sequences they can encode (Graaff, 2016; Rememberg, 2010; Jurkowski, 2014).\nOther tools produce encodings of longer sequences of digits by breaking the sequence into chunks of a fixed length, often two digits per word, and most do not combine the single-word encodings into one sequence of words (Ströbele, 2013; Scott, 2015b; Parcel, 2016; Got2Know, 2013).\nThus, these existing approaches are ill-suited for the memorization of even moderately long sequences of digits. Since the most sophisticated of these approaches are equivalent to our baseline\nmodels, we do not empirically compare these tools to our models."
    }, {
      "heading" : "2.2 Related Academic Work",
      "text" : "We are only aware of two previous corpus-based methods for generating mnemonic encodings. The first presents a method to help remember text passwords by finding a newspaper headline from the Reuters Corpus such that the first letters of each word in the headline match the letters in the password (Jeyaraman and Topkara, 2005). However, the restriction of using only newspaper headlines means that only about 40% of seven-character passwords are covered.\nThe second corpus-based method addresses the related problem of memorizing random strings of bits. Ghazvininejad and Knight (2015) created a method to encode random 60-bit strings as memorable sequences of words. However, their methods that create the most memorable passwords do not allow the user to mentally convert their memorized sequence of words to the original string. In contrast, our use of the major system allows users to easily convert any sequence of words into the encoded number in their head.\nAlthough these methods encode a sequence of letters and a string of bits while our system encodes a sequence of digits, all aim to create memorable sentences as output. Based on the results of these two previous methods, our system favors unique words and sentences of moderate length. Because our system needs to encode any arbitrary sequence of digits, we use a language model to generate sentences instead of relying on a preexisting set of newspaper headlines.\nSubstantially more work has been done on the memorability and security of passwords. Forget and Biddle (2008) found that modifying usercreated passwords to increase security had the unintended consequence of reducing memorability. Yan et al. (2004)’s work provides a possible means of dealing with that tension between security and memorability, showing that passwords based on mnemonic phrases were as easy to remember as naively created passwords and as strong as random passwords. Their positive results for mnemonicbased passwords are encouraging for our own mnemonic-based system. Our system is further informed by the work of Leiva and Sanchis-Trilles (2014), who analyzed different methods of sampling memorable sentences from corpora to use as\n3\n201\n202\n203\n204\n205\n206\n207\n208\n209\n210\n211\n212\n213\n214\n215\n216\n217\n218\n219\n220\n221\n222\n223\n224\n225\n226\n227\n228\n229\n230\n231\n232\n233\n234\n235\n236\n237\n238\n239\n240\n241\n242\n243\n244\n245\n246\n247\n248\n249\n250\n251\n252\n253\n254\n255\n256\n257\n258\n259\n260\n261\n262\n263\n264\n265\n266\n267\n268\n269\n270\n271\n272\n273\n274\n275\n276\n277\n278\n279\n280\n281\n282\n283\n284\n285\n286\n287\n288\n289\n290\n291\n292\n293\n294\n295\n296\n297\n298\n299\nprompts in text entry research. They found that prompts are more memorable when they are complete phrases and have fewer words.\nOur user study experiment evaluating the memorability of the phrases generated by our systems is informed by the existing work in this area. The format of our human subjects experiment is largely informed by the work of Vu et al. (2004). They examined the use of passphrases created by taking the first letter of each word in a sentence. Their user study split participants into two passphrase groups, the second of which had to include a number and a special character in the passphrase. The participants were not allowed to write the passwords down. The researchers then tested the participants’ recall after five minutes and after a week. The results showed that the second group produced much more secure passwords but at the cost of memorability."
    }, {
      "heading" : "3 Methodology",
      "text" : "In this section, we describe the data we used to train our models and present the six mnemonicgenerating systems we considered. These models include two baseline models, three preliminary models, and the final sentence encoder model. The source code for these models will be made available online 1."
    }, {
      "heading" : "3.1 Data Sets",
      "text" : "We use two data sets in our system. The first is the Brown corpus, which contains about 56,000 types and 1.2 million tokens (Francis and Kuera, 1964). We use this corpus to train our n-gram models. The corpus is also tagged with part-of-speech data, which we use to train our part-of-speech n-gram model and our sentence encoder model.\nThe second data set we use is the CMU Pronouncing Dictionary (Lenzo, 2014). This data set is a file of about 134,000 words, each labeled with its pronunciation in the Arpabet phoneme set. We work with the intersection of these two data sets, which contains about 34,000 words. This ensures that all the words produced by our language model can be pronounced from the CMU Pronouncing Dictionary. We pre-process both data sets to lowercase all words.\n1 URL withheld for blind review."
    }, {
      "heading" : "3.2 Baseline Models",
      "text" : "We designed two baseline models to compare our results against. Each of these baselines satisfies the requirement that the sequences of words produced encode exactly the input digits. Both baselines are greedy: they generate encodings one word at a time. At each time step, they choose a word from the set of words that encode the maximum number of digits possible. They differ in how a word is chosen from that set:\nRandom Encoder: At each step, a word is selected at random.\nUnigram Encoder: At each step, the word with the highest unigram probability is selected."
    }, {
      "heading" : "3.3 Preliminary Models",
      "text" : "We also considered three models that were more sophisticated than our baseline models. Unlike the baseline models that greedily encode as many digits per word as possible, these models consider all words that can encode at least one digit.\nn-gram Encoder: Words are generated one at a time. At each step, the next word is chosen using an n-gram language model with Stupid Backoff (Brants et al., 2007). We tested different combinations of hyperparameters and decided on default values of n = 3 and backoff factor α = 0.1. An additional hyperparameter indicates if the model should select the word with the highest n-gram probability or sample from a weighted probability distribution based on n-gram probabilities, with the former option as the default.\nPart-of-Speech (POS) Encoder: Words are generated one at a time, but a POS trigram model is used to restrict the set of possible words at each step so that the generated phrases are syntactically motivated. Each word is associated with the POS tag it most often has in the Brown corpus. To select each word in the encoding, the most likely POS tag is identified from the POS trigram model. From all words with that POS, we choose the word that has the greatest likelihood according to a word trigram model.\nChunk Encoder: Instead of generating encodings one word at a time, we generate one sentence at a time. Each sentence must match a\n4\n301\n302\n303\n304\n305\n306\n307\n308\n309\n310\n311\n312\n313\n314\n315\n316\n317\n318\n319\n320\n321\n322\n323\n324\n325\n326\n327\n328\n329\n330\n331\n332\n333\n334\n335\n336\n337\n338\n339\n340\n341\n342\n343\n344\n345\n346\n347\n348\n349\n350\n351\n352\n353\n354\n355\n356\n357\n358\n359\n360\n361\n362\n363\n364\n365\n366\n367\n368\n369\n370\n371\n372\n373\n374\n375\n376\n377\n378\n379\n380\n381\n382\n383\n384\n385\n386\n387\n388\n389\n390\n391\n392\n393\n394\n395\n396\n397\n398\n399\nfixed phrase template: <noun phrase><verb phrase><noun phrase>. Additionally, each chunk encodes exactly three digits. This encoder breaks the given number into chunks of three digits and encodes each chunk as one or two words that can be parsed as the desired chunk type. For each chunk, the phrase that has the greatest likelihood according to a bigram language model is selected."
    }, {
      "heading" : "3.4 Final Model: Sentence Encoder",
      "text" : "After examining the output of the three preliminary models, we combined the best elements of each into a final model, which we call the Sentence Encoder. This model aims to produce a variety of sentence structures that are both adequately long and reasonably likely to occur.\nThe sentence encoder trains a trigram model on the Brown corpus and stores the 100 most frequent sentence templates found in the corpus. A sentence template is a sequence of part-of-speech tags from the corpus’s simple “universal” tag set. We filter these sentence templates to only contain sentences that have a verb, do not have any numbers or “other”-category words (like foreign words), and are guaranteed to produce at least 5 words.\nTo encode a sequence of digits, the sentence encoder first samples a sentence template based on the templates’ frequencies in the training corpus. Then, for every part of speech in the template, the encoder selects the word that encodes at least the next digit with the most likely trigram score based on the previous words. If the encoder is unable to find a word that matches the necessary part of speech, it replaces the current sentence with a different, newly sampled sentence template. This process is repeated until all digits are encoded, possibly resulting in the end of the last sentence template being unused.\nA few additional changes to this model greatly improve its performance:\n• We allow nouns in place of pronouns, since there are more possible nouns than pronouns.\n• We allow certain parts of speech - determiners, adjectives, and adverbs - to be skipped if no word is found that matches them.\n• We weight the trigram score of each word based on how many digits it encodes. We\ndo this by multiplying the score by the number of digits the word encodes raised to some power, which is set to 10 by default. We previously found that the most likely sequences of words tend to encode only one or two digits per word, resulting in sentences that are long and thus less memorable.\n• We run a post-processing pass over the output sentences. The post-processing pass iterates over each word, calculates the probabilities for all possible words that encode the exact same digits using a bigram language model with the preceding and following words, and replaces the original word with the most likely word.\nWith these four changes, the sentence encoder is able to encode all numbers as memorable, syntactically plausible sentences of a reasonable length.\nAs an example, consider the number 86101521. The sentence encoder first samples a sentence template, such as “<verb> <noun> <conj> <verb> <adv>.” Then, the sentence encoder finds a verb that encodes at least the first digit, 8. The sentence encoder selects the verb “officiate,” which has consonant sounds “<F>,<SH>,<T>,” to represent 861. The remaining digits are 01521. The sentence encoder then selects the noun “wasteland,” with consonant sounds “<S>,<T>,<L>,<N>,<D>,” to represent 01521. So, 86101521 is encoded as “Officiate wasteland.”"
    }, {
      "heading" : "4 Model Output",
      "text" : "For each model, we look at the encoding generated for two numbers. The first number is a random eight-digit number, and the second is the first fifty digits of π.\nThe eight-digit number demonstrates each model’s ability to encode fairly short sequences of digits, such as a numeric password, a phone number, or an account number. Table 2 shows how each model encoded the number 86101521.\nThe first fifty digits of π demonstrates each model’s ability to encode an arbitrarily long sequence of digits. Table 3 shows how each model encoded the first fifty digits of π: 31415926535897932384626433832795028841971 693993751.\n5\n401\n402\n403\n404\n405\n406\n407\n408\n409\n410\n411\n412\n413\n414\n415\n416\n417\n418\n419\n420\n421\n422\n423\n424\n425\n426\n427\n428\n429\n430\n431\n432\n433\n434\n435\n436\n437\n438\n439\n440\n441\n442\n443\n444\n445\n446\n447\n448\n449\n450\n451\n452\n453\n454\n455\n456\n457\n458\n459\n460\n461\n462\n463\n464\n465\n466\n467\n468\n469\n470\n471\n472\n473\n474\n475\n476\n477\n478\n479\n480\n481\n482\n483\n484\n485\n486\n487\n488\n489\n490\n491\n492\n493\n494\n495\n496\n497\n498\n499\nEncoder Phrase Random Vouching wits widely and Unigram Fish this tell and n-gram Of which the house to all. And POS Wife age at sea with law in the Chunk Half shut settle night. Sentence Officiate wasteland.\nTable 2: Encodings generated by each model for the 8-digit code 86101521.\nEncoder Phrase Random meeting rawhide yelping hunch alum levy bog boom annum ivory gin sharing meme\nfemme knock appeal sinning vivo readying bake twitch beaming pub hammock highlighting\nUnigram made right help enjoy william life back p.m. name over john sure mama foam neck able seen five right back touch p.m. baby make old n-gram Him to hire youth all. Be in show all my life. Be echoing be my own home. Of our age in which our. Him home of my own. Go up all his own. Of every day by god. Which by him by be. Him go along with. POS Matter with law by an age along mile of hope. Week by man among every age in age. Year among aim of man. Week by law use in favor with pike with age by humming by boy among week along the. Chunk Matter would leap new jail. Home life book by money home. Average enjoy her home movie. Human ego being less won five. Earth by god she poem by. Buy make lead. Sentence Matter tell been shell among life. Pickup man moving or which nature. Mama of many couples in favor. Tobacco touch pump by my cold.\nTable 3: Encodings generated by each model for the first 50 digits of π."
    }, {
      "heading" : "4.1 Comparison of Encodings",
      "text" : "The random encoder generates mnemonic encodings that use obscure words without any structure. As such, the random encoder does not produce memorable encodings.\nThe unigram encoder improves on the random encoder by favoring more common words, which tends to result in shorter encodings. However, as neither model considers part-of-speech information, the two baselines produce unrelated sequences of words, which are difficult to chunk and to remember.\nThe n-gram encoder generates encodings that tend to be long and unmemorable. The encoder often produces incoherent phrases of common words, such as “the of which by his own.” The sentences produced by the other three nonbaseline models tend to be more memorable.\nFor example, the POS encoder generates longer, more syntactically plausible sentences. The biggest drawback of this model is the relative lack of verbs in its generated sentences.\nThe chunk encoder produces encodings similar to those produced by the POS encoder but with a noun-verb-noun pattern that results in relatively short, simply structured sentences. However, the chunk encoder has a slow running time due to the relatively expensive process of parsing each possible noun phrase and verb phrase.\nThe sentence encoder produces words such that each word encodes many digits and tends to be distinctive. This means that fewer words and thus fewer sentences are needed to encode a given sequence of digits, making the mnemonic encodings generated by the sentence encoder easy to chunk and memorable. We hypothesize that the sentence encoder generates more memorable sentences. We tested that hypothesis through a user study."
    }, {
      "heading" : "5 User Study",
      "text" : "We conducted a user study to test the memorability of the phrases generated by our models. The study was presented as a study of password mem-\n6\n501\n502\n503\n504\n505\n506\n507\n508\n509\n510\n511\n512\n513\n514\n515\n516\n517\n518\n519\n520\n521\n522\n523\n524\n525\n526\n527\n528\n529\n530\n531\n532\n533\n534\n535\n536\n537\n538\n539\n540\n541\n542\n543\n544\n545\n546\n547\n548\n549\n550\n551\n552\n553\n554\n555\n556\n557\n558\n559\n560\n561\n562\n563\n564\n565\n566\n567\n568\n569\n570\n571\n572\n573\n574\n575\n576\n577\n578\n579\n580\n581\n582\n583\n584\n585\n586\n587\n588\n589\n590\n591\n592\n593\n594\n595\n596\n597\n598\n599\norability, in which each password was an 8-digit number or its encoding from the n-gram encoder or the sentence encoder. We compared the ngram model (which served as our baseline) to the sentence model (which we hypothesized best balances all aspects of memorability) for four factors:\nShort-Term Recall: How well can participants remember the number or its encoding after five minutes?\nLong-Term Recall: How well can participants remember the number or its encoding after one week?\nLong-Term Recognition: How well can participants identify the number or its encoding from a list of options after one week?\nSubjective Comparison: How easy does each number or its encoding seem to users? This comparison may give an indication of how likely users are to consider trying a particular mnemonic."
    }, {
      "heading" : "5.1 Study Overview",
      "text" : "The study was comprised of two online surveys, which together take about fifteen minutes to complete. We recruited participants through emails to a computer science summer research program and through social media posts. Participants were compensated with a five-dollar Amazon.com gift card via email after completing the second survey.\nWhile we had 167 participants complete both surveys, we found in the second survey that 101 of the respondents were fraudulent. These responses shared a number of suspicious characteristics:\n• They were completed consecutively, usually with only a few seconds from one response to the next, for both the first and the second survey.\n• None of them spent as much time on the survey tasks as other participants. The median time spent on our distraction task, for example, was 4 seconds for these participants. For other participants, the median time spent on the same task was 81 seconds.\n• They appeared in groups of consecutive email addresses from the same free email provider.\n• They all remembered the numeric code and its encoding perfectly after one week.\nRemoving these participants left 67 responses to the first survey and 66 responses to the second."
    }, {
      "heading" : "5.2 Study Design",
      "text" : "Each participant was randomly assigned to one of two groups, n-gram or sentence. Participants were identified by the email address they entered in the first survey, which we then used to send them a link to the second survey and to identify their responses.\nThe first survey presented each participant with an 8-digit sequence and a corresponding sequence of words from either the n-gram encoder or the sentence encoder that encoded the same 8-digit sequence. The participant was asked to remember both the number and the encoding, without writing them down, and was informed that they would be asked to recall both sequences at the end of the first survey and on the second survey. After entering both sequences to confirm initial memorization, the participant was asked to read a page of baking recipes for approximately five minutes. This page, containing numbers and words, served to clear the participant’s working memory. Next, the participant was asked to enter both sequences, with an “I forgot” button available if necessary. Each correct or incorrect attempt was recorded, as was the time spent on each page of the survey.\nThe second survey was sent to each participant seven days after their completion of the first survey. The survey again asked each participant to recall both sequences and recorded the same information. The participant was then asked to recognize their 8-digit sequence from a list of five sequences and to recognize their word sequence from a list of five word sequences generated by their group’s encoder. Next, the participant was shown an 8-digit sequence, its n-gram encoding, and its sentence encoding and asked to rank the three passwords from “easiest to remember” to “hardest to remember.” Finally, the participant was asked to share the approach they used to memorize the two sequences."
    }, {
      "heading" : "5.3 Study Results",
      "text" : "Our primary goal in performing this user study was to evaluate our hypothesis that the sentence encoder produced more memorable encodings than the n-gram encoder. We also sought\n7\n601\n602\n603\n604\n605\n606\n607\n608\n609\n610\n611\n612\n613\n614\n615\n616\n617\n618\n619\n620\n621\n622\n623\n624\n625\n626\n627\n628\n629\n630\n631\n632\n633\n634\n635\n636\n637\n638\n639\n640\n641\n642\n643\n644\n645\n646\n647\n648\n649\n650\n651\n652\n653\n654\n655\n656\n657\n658\n659\n660\n661\n662\n663\n664\n665\n666\n667\n668\n669\n670\n671\n672\n673\n674\n675\n676\n677\n678\n679\n680\n681\n682\n683\n684\n685\n686\n687\n688\n689\n690\n691\n692\n693\n694\n695\n696\n697\n698\n699\nto determine whether the sentence encodings are more memorable than the relatively short 8-digit sequences themselves.\nShort-Term Recall: On the first survey, more participants correctly confirmed the sentence password than the n-gram password. 29 of the 31 sentence password participants (94%) remembered the password, as opposed to only 26 of the 36 n-gram password participants (72%). This difference is statistically significant at α = 0.05 under a z-test for two proportions with p = 0.02. Participants with the sentence password also spent significantly less time on the confirmation page than did participants with the n-gram password (27 seconds versus 52 seconds, with p = 0.019 under an independent two-tailed t-test). After reading the recipes distraction page, more participants recalled the numeric password than the n-gram password (55/67 versus 23/36, p = 0.0403).\nLong-Term Recall: On the second survey, we found no statistically significant differences between the number of participants who recalled the n-gram password, the sentence password, or the numeric password (respectively 9/36, 10/30, 25/66).\nLong-Term Recognition: On the second survey, more participants recognized the sentence password than the numeric password when shown five options for each (30/30 versus 58/66, p = 0.05).\nSubjective Comparison: More participants rated the sentence password as “easiest to remember” than the numeric password (36/66 versus 24/66, p = 0.04), and more participants rated the numeric password as “easiest to remember” than the n-gram password (24/66 versus 6/66, p < 0.001).\nThe results of our user study indicate that the sentence encoder produces more memorable encodings than the n-gram encoder does. These results also indicate that n-gram encodings are harder to remember in the short-term than the number itself. While few participants recalled any passwords after seven days, more participants recognized the sentence password than the numeric password, indicating that the sentence password is more memorable. Furthermore, the sentence password was most frequently rated “easiest to remember,” followed by the numeric password and the n-gram password. We conclude that the sentence encoder produces more memorable encod-\nings than the n-gram encoder and effectively aids in the memorization of numbers."
    }, {
      "heading" : "6 Conclusions and Future Work",
      "text" : "We have described several systems for generating encodings of numbers using the major system. While n-gram models generate sentences that accurately match their training corpora, the sentences tend to be long and unmemorable. Sentences based on POS tags tend to be more memorable but are still not syntactically reasonable. Forcing the same sentence structure on every sentence by parsing ensures a reasonable structure but at a high computational cost. Ultimately, ensuring that each sentence is of a known but randomly selected syntactic structure that favors short encodings produces a reasonable balance of syntactic correctness, length, and memorability. A user study on password memorability supports our claim that the sentence encoder produces memorable mnemonic encodings of numbers.\nFuture work could further improve the sentence encoder. We could produce a more interesting variety of sentences by using punctuation from the training corpus besides periods, such as commas, exclamation marks, and question marks. The sentence encoder often produces a fragment as its last sentence because it runs out of digits to encode. This problem could be mitigated by making the encoder select shorter sentence templates when there are few digits remaining. Furthermore, the encoder could use more nuanced sentence templates to enforce subject-verb agreement and grammatical use of auxiliary verbs.\nWhile the sentence encoder takes a greedy approach in an effort to encode digits in as few words as possible, another potential approach would be to use a dynamic programming algorithm to efficiently search through all possible encodings. Given a suitable objective function as a proxy for memorability, this could potentially produce a more memorable encoding than the sentence encoder without excessively increasing the encoding’s length.\nOne issue in our user study was the unexpectedly short amount of time spent on the distraction page, with an average of 81 seconds instead of the intended five minutes. Future user studies should enforce a set distraction time through the use of a timer or other mechanism when studying shortterm recall.\n8\n701\n702\n703\n704\n705\n706\n707\n708\n709\n710\n711\n712\n713\n714\n715\n716\n717\n718\n719\n720\n721\n722\n723\n724\n725\n726\n727\n728\n729\n730\n731\n732\n733\n734\n735\n736\n737\n738\n739\n740\n741\n742\n743\n744\n745\n746\n747\n748\n749\n750\n751\n752\n753\n754\n755\n756\n757\n758\n759\n760\n761\n762\n763\n764\n765\n766\n767\n768\n769\n770\n771\n772\n773\n774\n775\n776\n777\n778\n779\n780\n781\n782\n783\n784\n785\n786\n787\n788\n789\n790\n791\n792\n793\n794\n795\n796\n797\n798\n799\nA future user study could examine the effectiveness of our system on longer numbers. While our user study did not show that any particular type of password was easiest to recall after seven days, we expect that a study involving longer passwords would show the sentence password to be easiest to recall. This is because the major system is wellsuited for aiding the memorization of long numbers while the eight-digit numeric passwords used in our study are relatively short. It would also be interesting to see how memorable our encodings are in a context where users are prompted to recall the password each day over a long period of time."
    } ],
    "references" : [ {
      "title" : "Large Language Models in Machine Translation",
      "author" : [ "Thorsten Brants", "Ashok C Popat", "Peng Xu", "Franz J Och", "Jeffrey Dean." ],
      "venue" : "Proc. EMNLP and CoNLL. Citeseer.",
      "citeRegEx" : "Brants et al\\.,? 2007",
      "shortCiteRegEx" : "Brants et al\\.",
      "year" : 2007
    }, {
      "title" : "Phreno-mnemotechny: Or, The Art of Memory: the Series of Lectures, Explanatory of the Principles of the System, Delivered in New York and Philadelphia, in the Beginning of 1844",
      "author" : [ "F. Fauvel-Gouraud." ],
      "venue" : "Wiley and Putnam.",
      "citeRegEx" : "Fauvel.Gouraud.,? 1845",
      "shortCiteRegEx" : "Fauvel.Gouraud.",
      "year" : 1845
    }, {
      "title" : "Memorability of Persuasive Passwords",
      "author" : [ "Alain Forget", "Robert Biddle." ],
      "venue" : "CHI ’08 Extended Abstracts on Human Factors in Computing Systems. ACM, New York, NY, USA, CHI EA ’08, pages 3759–3764.",
      "citeRegEx" : "Forget and Biddle.,? 2008",
      "shortCiteRegEx" : "Forget and Biddle.",
      "year" : 2008
    }, {
      "title" : "A Standard Corpus of Present-Day Edited American English, for use with Digital Computers",
      "author" : [ "W.N. Francis", "H. Kuera." ],
      "venue" : "Brown University, Providence, Rhode Island.",
      "citeRegEx" : "Francis and Kuera.,? 1964",
      "shortCiteRegEx" : "Francis and Kuera.",
      "year" : 1964
    }, {
      "title" : "How to memorize a random 60-bit string",
      "author" : [ "Marjan Ghazvininejad", "Kevin Knight." ],
      "venue" : "Parking 11(70.8):58–83.",
      "citeRegEx" : "Ghazvininejad and Knight.,? 2015",
      "shortCiteRegEx" : "Ghazvininejad and Knight.",
      "year" : 2015
    }, {
      "title" : "Phonetic Mnemonic System Keyword Search Tool",
      "author" : [ "Tyson Graaff." ],
      "venue" : "http://www.phoneticmnemonic. com.",
      "citeRegEx" : "Graaff.,? 2016",
      "shortCiteRegEx" : "Graaff.",
      "year" : 2016
    }, {
      "title" : "Have the cake and eat it too - Infusing usability into text-password based authentication systems",
      "author" : [ "S. Jeyaraman", "U. Topkara." ],
      "venue" : "21st Annual Computer Security Applications Conference. pages 10 pp.–482. https://doi.org/10.1109/CSAC.2005.28.",
      "citeRegEx" : "Jeyaraman and Topkara.,? 2005",
      "shortCiteRegEx" : "Jeyaraman and Topkara.",
      "year" : 2005
    }, {
      "title" : "Simple Major System",
      "author" : [ "Jurkowski." ],
      "venue" : "https://play.google.com/store/apps/details?id= de.cjcj.number2majorsystem.",
      "citeRegEx" : "Jurkowski.,? 2014",
      "shortCiteRegEx" : "Jurkowski.",
      "year" : 2014
    }, {
      "title" : "Representatively Memorable: Sampling the Right Phrase Set to Get the Text Entry Experiment Right",
      "author" : [ "Luis A. Leiva", "Germán Sanchis-Trilles." ],
      "venue" : "Proc. SIGCHI Conference on Human Factors in Computing Systems. ACM, New",
      "citeRegEx" : "Leiva and Sanchis.Trilles.,? 2014",
      "shortCiteRegEx" : "Leiva and Sanchis.Trilles.",
      "year" : 2014
    }, {
      "title" : "The CMU Pronouncing Dictionary",
      "author" : [ "Kevin Lenzo." ],
      "venue" : "http://www.speech.cs.cmu.edu/cgi-bin/ cmudict.",
      "citeRegEx" : "Lenzo.,? 2014",
      "shortCiteRegEx" : "Lenzo.",
      "year" : 2014
    }, {
      "title" : "A+ Major System",
      "author" : [ "Magic Parcel." ],
      "venue" : "https://play.google.com/store/apps/details?id= com.magicparcel.app.majorsystem.",
      "citeRegEx" : "Parcel.,? 2016",
      "shortCiteRegEx" : "Parcel.",
      "year" : 2016
    }, {
      "title" : "Mnemo Major System Trainer",
      "author" : [ "Gerald Reindl." ],
      "venue" : "https://itunes.apple.com/us/app/mnemomajor-system-trainer/id649905769?mt=8.",
      "citeRegEx" : "Reindl.,? 2015",
      "shortCiteRegEx" : "Reindl.",
      "year" : 2015
    }, {
      "title" : "Memorize numbers with this online mnemonic generator",
      "author" : [ "Rememberg." ],
      "venue" : "http://www.rememberg. com.",
      "citeRegEx" : "Rememberg.,? 2010",
      "shortCiteRegEx" : "Rememberg.",
      "year" : 2010
    }, {
      "title" : "Numzi",
      "author" : [ "Stephen Scott." ],
      "venue" : "https://itunes.apple. com/us/app/id1036895529?mt=8.",
      "citeRegEx" : "Scott.,? 2015a",
      "shortCiteRegEx" : "Scott.",
      "year" : 2015
    }, {
      "title" : "Numzi",
      "author" : [ "Stephen Scott." ],
      "venue" : "http://numzi.com/ numzi.",
      "citeRegEx" : "Scott.,? 2015b",
      "shortCiteRegEx" : "Scott.",
      "year" : 2015
    }, {
      "title" : "Mnemonic Major System",
      "author" : [ "Kyoto-shi Shimogyo-ku Shichijo." ],
      "venue" : "https://play.google.com/store/apps/ details?id=com.cyandroid.majorsystem.",
      "citeRegEx" : "Shichijo.,? 2014",
      "shortCiteRegEx" : "Shichijo.",
      "year" : 2014
    }, {
      "title" : "Major System database",
      "author" : [ "Jonathan Ströbele." ],
      "venue" : "http: //major-system.info.",
      "citeRegEx" : "Ströbele.,? 2013",
      "shortCiteRegEx" : "Ströbele.",
      "year" : 2013
    }, {
      "title" : "Promoting Memorability and Security of Passwords through Sentence Generation",
      "author" : [ "Kim-Phuong L Vu", "Bik-Lam Belin Tai", "Abhilasha Bhargav", "E Eugene Schultz", "Robert W Proctor." ],
      "venue" : "Proc. Human Factors and Ergonomics Society An-",
      "citeRegEx" : "Vu et al\\.,? 2004",
      "shortCiteRegEx" : "Vu et al\\.",
      "year" : 2004
    }, {
      "title" : "Password Memorability and Security: Empirical Results",
      "author" : [ "Jeff Jianxin Yan", "Alan F Blackwell", "Ross J Anderson", "Alasdair Grant." ],
      "venue" : "IEEE Security & privacy 2(5):25–31.",
      "citeRegEx" : "Yan et al\\.,? 2004",
      "shortCiteRegEx" : "Yan et al\\.",
      "year" : 2004
    } ],
    "referenceMentions" : [ {
      "referenceID" : 15,
      "context" : "Many mobile applications will generate encodings, but their focus appears to be on helping users learn the major system and not on generating memorable encodings automatically (Shichijo, 2014; Reindl, 2015; Vladislav, 2016; Scott, 2015a; Pfeiffer, 2013; Buder, 2012).",
      "startOffset" : 176,
      "endOffset" : 266
    }, {
      "referenceID" : 11,
      "context" : "Many mobile applications will generate encodings, but their focus appears to be on helping users learn the major system and not on generating memorable encodings automatically (Shichijo, 2014; Reindl, 2015; Vladislav, 2016; Scott, 2015a; Pfeiffer, 2013; Buder, 2012).",
      "startOffset" : 176,
      "endOffset" : 266
    }, {
      "referenceID" : 13,
      "context" : "Many mobile applications will generate encodings, but their focus appears to be on helping users learn the major system and not on generating memorable encodings automatically (Shichijo, 2014; Reindl, 2015; Vladislav, 2016; Scott, 2015a; Pfeiffer, 2013; Buder, 2012).",
      "startOffset" : 176,
      "endOffset" : 266
    }, {
      "referenceID" : 5,
      "context" : "Most of these tools only produce one- or two-word encodings, greatly limiting the length of sequences they can encode (Graaff, 2016; Rememberg, 2010; Jurkowski, 2014).",
      "startOffset" : 118,
      "endOffset" : 166
    }, {
      "referenceID" : 12,
      "context" : "Most of these tools only produce one- or two-word encodings, greatly limiting the length of sequences they can encode (Graaff, 2016; Rememberg, 2010; Jurkowski, 2014).",
      "startOffset" : 118,
      "endOffset" : 166
    }, {
      "referenceID" : 7,
      "context" : "Most of these tools only produce one- or two-word encodings, greatly limiting the length of sequences they can encode (Graaff, 2016; Rememberg, 2010; Jurkowski, 2014).",
      "startOffset" : 118,
      "endOffset" : 166
    }, {
      "referenceID" : 16,
      "context" : "Other tools produce encodings of longer sequences of digits by breaking the sequence into chunks of a fixed length, often two digits per word, and most do not combine the single-word encodings into one sequence of words (Ströbele, 2013; Scott, 2015b; Parcel, 2016; Got2Know, 2013).",
      "startOffset" : 220,
      "endOffset" : 280
    }, {
      "referenceID" : 14,
      "context" : "Other tools produce encodings of longer sequences of digits by breaking the sequence into chunks of a fixed length, often two digits per word, and most do not combine the single-word encodings into one sequence of words (Ströbele, 2013; Scott, 2015b; Parcel, 2016; Got2Know, 2013).",
      "startOffset" : 220,
      "endOffset" : 280
    }, {
      "referenceID" : 10,
      "context" : "Other tools produce encodings of longer sequences of digits by breaking the sequence into chunks of a fixed length, often two digits per word, and most do not combine the single-word encodings into one sequence of words (Ströbele, 2013; Scott, 2015b; Parcel, 2016; Got2Know, 2013).",
      "startOffset" : 220,
      "endOffset" : 280
    }, {
      "referenceID" : 6,
      "context" : "The first presents a method to help remember text passwords by finding a newspaper headline from the Reuters Corpus such that the first letters of each word in the headline match the letters in the password (Jeyaraman and Topkara, 2005).",
      "startOffset" : 207,
      "endOffset" : 236
    }, {
      "referenceID" : 3,
      "context" : "Ghazvininejad and Knight (2015) created a method to encode random 60-bit strings as memorable sequences of words.",
      "startOffset" : 0,
      "endOffset" : 32
    }, {
      "referenceID" : 2,
      "context" : "Forget and Biddle (2008) found that modifying usercreated passwords to increase security had the unintended consequence of reducing memorability.",
      "startOffset" : 0,
      "endOffset" : 25
    }, {
      "referenceID" : 2,
      "context" : "Forget and Biddle (2008) found that modifying usercreated passwords to increase security had the unintended consequence of reducing memorability. Yan et al. (2004)’s work provides a possible means of dealing with that tension between security and memorability, showing that passwords based on mnemonic phrases were as easy to remember as naively created passwords and as strong as random passwords.",
      "startOffset" : 0,
      "endOffset" : 164
    }, {
      "referenceID" : 2,
      "context" : "Forget and Biddle (2008) found that modifying usercreated passwords to increase security had the unintended consequence of reducing memorability. Yan et al. (2004)’s work provides a possible means of dealing with that tension between security and memorability, showing that passwords based on mnemonic phrases were as easy to remember as naively created passwords and as strong as random passwords. Their positive results for mnemonicbased passwords are encouraging for our own mnemonic-based system. Our system is further informed by the work of Leiva and Sanchis-Trilles (2014), who analyzed different methods of sampling memorable sentences from corpora to use as",
      "startOffset" : 0,
      "endOffset" : 580
    }, {
      "referenceID" : 17,
      "context" : "The format of our human subjects experiment is largely informed by the work of Vu et al. (2004). They examined the use of passphrases created by taking the first letter of each word in a sentence.",
      "startOffset" : 79,
      "endOffset" : 96
    }, {
      "referenceID" : 3,
      "context" : "2 million tokens (Francis and Kuera, 1964).",
      "startOffset" : 17,
      "endOffset" : 42
    }, {
      "referenceID" : 9,
      "context" : "The second data set we use is the CMU Pronouncing Dictionary (Lenzo, 2014).",
      "startOffset" : 61,
      "endOffset" : 74
    }, {
      "referenceID" : 0,
      "context" : "At each step, the next word is chosen using an n-gram language model with Stupid Backoff (Brants et al., 2007).",
      "startOffset" : 89,
      "endOffset" : 110
    } ],
    "year" : 2017,
    "abstractText" : "The major system is a mnemonic system that can be used to memorize sequences of numbers. In this work, we present a method to automatically generate sentences that encode a given number. We propose several encoding models and compare the most promising ones in a password memorability study. The results of the study show that a model combining part-of-speech sentence templates with an n-gram language model produces the most memorable password representations.",
    "creator" : "LaTeX with hyperref package"
  }
}