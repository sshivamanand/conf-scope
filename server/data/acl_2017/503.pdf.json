{
  "name" : "503.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Probabilistic Regular Graph Languages",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "1 000\n011\n012\n013\n014\n015\n016\n017\n018\n019\n020\n021\n022\n023\n024\n025\n026\n027\n028\n029\n030\n031\n032\n033\n034\n035\n036\n037\n038\n039\n040\n041\n042\n043\n044\n045\n046\n047\n048\n049\n067\n068\n069\n070\n071\n072\n073\n074\n075\n076\n077\n078\n079\n080\n081\n082\n083\n084\n085\n086\n087\n088\n089\n090\n091\n092\n093\n094\n095\n096\n097\n098\n099"
    }, {
      "heading" : "1 Introduction",
      "text" : "NLP systems for machine translation, summarization, paraphrasing, and other problems often fail to preserve the compositional semantics of sentences and documents because they model language as bags of words, or at best syntactic trees. To preserve semantics, they must model semantics. In pursuit of this goal, several datasets have been produced which pair natural language with compositional semantic representations in the form of directed acyclic graphs (DAGs), including the Abstract Meaning Represenation Bank (AMR; Banarescu et al. 2013), the Prague Czech-English Dependency Treebank (Hajič et al., 2012), Deep-\nbank (Flickinger et al., 2012), and the Universal Conceptual Cognitive Annotation (Abend and Rappoport, 2013). To make use of this data, we require probabilistic models of graphs.\nConsider how we might use compositional semantic representations in machine translation (Figure 1). We first parse a source sentence to its semantic representation, and then generate a target sentence from this representation. Stated more formally, we first predict a graph G from a source string s, and then predict a target string t from G, giving us a conditional model P(t, G|s), which we can decompose as P(t, G|s) = P(t|G)P(G|s). Jones et al. (2012) observe that this decomposition can be modeled with a pair of probabilistic synchronous grammars over domains of strings and graphs. Given a domain of source strings Ls, a domain of source graphs LG, a domain of target graphs LG′ and a domain of target strings Lt, these grammars define relationsR ⊆ Ls×LG and R′ ⊆ LG′ ×Lt. Translation is then the solution to the following inference problem, given input s:\narg max t∈Lt ∑ {G|(s,G)∈R∧(G,t)∈R′} P(t|G)P(G|s)\nIn practical settings the sum over G is typically replaced with an arg max. Either way, we must\n2\n101\n102\n103\n104\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n123\n124\n125\n126\n127\n128\n129\n130\n131\n132\n133\n134\n135\n136\n137\n138\n139\n140\n141\n142\n143\n144\n145\n146\n147\n148\n149\n150\n151\n152\n153\n154\n155\n156\n157\n158\n159\n160\n161\n162\n163\n164\n165\n166\n167\n168\n169\n170\n171\n172\n173\n174\n175\n176\n177\n178\n179\n180\n181\n182\n183\n184\n185\n186\n187\n188\n189\n190\n191\n192\n193\n194\n195\n196\n197\n198\n199\ndefine probability distributions over the graph domains and efficiently compute their intersection.\nFor NLP problems in which data is in the form of strings and trees, such distributions can be represented by finite automata (Mohri et al., 2008; Allauzen et al., 2014), which are closed under intersection and can be made probabilistic. It is therefore natural to ask whether there is a family of graph languages with similar properties to finite automata. Recent work in NLP has focused primarily on two families of graph languages: hyperedge replacement languages (HRL; Drewes et al. 1997), a context-free graph rewriting formalism that has been studied in an NLP context by several researchers (Chiang et al., 2013; Peng et al., 2015; Bauer and Rambow, 2016); and DAG automata languages, (Kamimura and Slutzki, 1981), studied by Quernheim and Knight (2012). Thomas (1991) showed that the latter are a subfamily of the monadic second order languages (MSOL), which are of special interest to us, since, when restricted to strings or trees, they exactly characterize the regular languages of each (Büchi, 1960; Büchi and Elgot, 1958; Trakhtenbrot, 1961).\nThe HRL and MSOL families are incomparable: that is, the context-free graph languages do not contain the regular graph languages, as is the case in languages of strings and trees (Courcelle, 1990). So, while each formalism has appealing characteristics, none appear adequate for the problem outlined above: HRLs can be made probabilistic, but they are not closed under intersection; and while DAGAL and MSOL are closed under intersection, it is unclear how to make them probabilistic (Quernheim and Knight, 2012).1\nThis paper investigates the regular graph languages (RGL; Courcelle 1991), defined as a restricted form of HRL (§2). The restrictions ensure that RGLs are a subfamily of MSOL. Courcelle (1991) defined regular graph grammars as an auxiliary result of a theoretical research question quite different from ours.2 As a consequence, they have\n1Semiring-weighted MSOLs have been defined, where weights may be in the tropical semiring (Droste and Gastin, 2005). However, for the weights to define a probability distribution, they must meet the stronger condition that the sum of multiplied weights over all definable objects is one. This does not appear to have been demonstrated for DAGAL, which violate the sufficient conditions that Booth and Thompson (1973) give for probabilistic languages. We suspect that there are DAGAL (hence MSOL) for which it is not possible.\n2The primary research question of Courcelle (1991) is a conjecture which has only quite recently been proven (Bojanczyk and Pilipczuk, 2016).\nHRL∗ MSOL† Graphs\nCFTL∗\nCFL∗\nRTL†∗ Trees\nRL†∗ Strings\nRGL†∗ DAGAL†\nFigure 2: Containment relationships for families of regular and context-free string and tree languages, hyperedge replacement languages (HRL), monadic second order definable graph languages (MSOL), directed acyclic graph automata languages (DAGAL), and regular graph languages (RGL). ∗ indicates that the family of languages is probabilistic and † indicates that the family of languages is intersectible.\nnot been widely studied, and they have never been applied to NLP. We present two new results.\n1. We prove that RGLs are closed under intersection (§3).\n2. We give a parsing algorithm for RGL that is linear in the size of the input graph (§4).\nFigure 2 summarizes the relationship of RGL to other formalisms and their properties. We conclude with a discussion of how RGL relates to other recently-discovered formalisms and its capacity to represent semantics as graphs (§5)."
    }, {
      "heading" : "2 Regular Graph Languages",
      "text" : "We use the following notation. If n is an integer, [n] denotes the set {1, . . . , n}. IfA is a set, s ∈ A∗ denotes that s is a sequence of arbitrary length, each element of which is in A. We denote by |s| the length of s. A ranked alphabet is an alphabet A paired with an arity function rank: A→ N. Definition 1. A hypergraph over a ranked alphabet Γ is a tuple G = (VG, EG, attG, labG, extG) where VG is a finite set of nodes; EG is a finite set of edges (distinct from VG); attG : EG → V ∗G maps each edge to a sequence of nodes; labG : EG → Γ maps each edge to a label such that |attG(e)| = rank(labG(e)); and extG is an ordered subset of VG called the external nodes of G.\nWe assume that both the elements of extG and the elements of attG(e) for each edge e are pairwise distinct. An edge e is attached to its nodes by tentacles, each labeled by an integer indicating the node’s position in attG(e) = (v1, . . . , vk). The\n3\n201\n202\n203\n204\n205\n206\n207\n208\n209\n210\n211\n212\n213\n214\n215\n216\n217\n218\n219\n220\n221\n222\n223\n224\n225\n226\n227\n228\n229\n230\n231\n232\n233\n234\n235\n236\n237\n238\n239\n240\n241\n242\n243\n244\n245\n246\n247\n248\n249\n258\n259\n260\n261\n262\n263\n264\n265\n266\n267\n268\n269\n270\n271\n272\n273\n274\n275\n276\n277\n278\n279\n280\n281\n282\n283\n284\n285\n286\n287\n288\n289\n290\n291\n292\n293\n294\n295\n296\n297\n298\n299\ntentacle from e to vi will have label i, so the tentacle labels lie in the set [k] where k = rank(e). To express that a node v is attached to the ith tentacle of an edge e then we say vert(e, i) = v. Likewise, the nodes in extG are labeled by their position in extG. In figures, the ith external node will be labeled (i). The rank of an edge e is k if att(e) = (v1, . . . , vk) (or equivalently, rank(lab(e)) = k). The rank of a hypergraph G is the size of extG. Example 1. Hypergraph G in Figure 3 has four nodes (shown as black dots) and three hyperedges labeled a, b, and X (shown boxed). The bracketed numbers (1) and (2) denote its external nodes and the numbers between edges and the nodes are tentacle labels. Call the top node v1 and, proceeding clockwise, call the other nodes v2, v3, and v4. Call its edges e1, e2 and e3. Its definition would state:\nattG(e1) = (v1, v2) labG(e1) = a\nattG(e2) = (v2, v3) labG(e2) = b\nattG(e3) = (v1, v4, v3) labG(e3) = X\nextG = (v4, v2).\nDefinition 2. Let G be a hypergraph with an edge e of rank k and letH be a hypergraph also of rank k disjoint from G. The replacement of e by H is the graph G′ = G[e/H]. Its node set VG′ is VG ∪ VH where the ith node of e in G is fused with the ith external node of VH . Its hyperedge set EG′ is (EG−{e})∪EH . For each e′ ∈ EG′ , attG′(e′) = attG(e′) if e′ ∈ EG and attG′(e′) = attH(e′) if e′ ∈ EH . For each e′ ∈ EG′ , labG′(e′) = labG(e′) if e′ ∈ EG and labG′(e′) = labH(e′) if e′ ∈ EH . Its external node list is ext′G = extG. Example 2. Replacement is shown in Figure 3. We denote the replacement as G[X/H] since the edge is unambiguous given its label."
    }, {
      "heading" : "2.1 Hyperedge Replacement Grammars",
      "text" : "Definition 3. A hyperedge replacement grammar G = (NG , TG , PG , SG) consists of a finite set of ranked nonterminal symbols NG , a finite set of ranked terminal symbols TG (disjoint from NG), a finite set of productions PG , and a start symbol SG ∈ NG . Every production in PG is of the form X → G where X ∈ NG and G is a hypergraph over NG ∪ TG . For each production, the rank of e must equal the rank of G.\nFor each production p : X → G, we will use L(p) to refer to X (the left-hand side of p) and R(p) to refer to G (the right-hand side of p). An\nedge is a terminal edge if its label is terminal and a nonterminal edge if its label is nonterminal. A graph is a terminal graph if all of its edges are labeled with terminal symbols. The terminal subgraph of a graph is the subgraph consisting of all terminal edges and their endpoints.\nGiven a HRG G, we say that graph G derives graph G′, denoted G → G′, iff there is an edge e ∈ EG and a nonterminal X ∈ NG such that labG(e) = X and G′ = G[e/H], where X → H is in PG . We extend the idea of derivation to its transitive closure G →∗ G′. For every X ∈ NG we also use X to denote the connected graph consisting of a single edge e with lab(e)=X and nodes (v1, . . . , vrank(X)) such that attG(e) = (v1, . . . , vrank(X)), and we define the language LX(G) as {G | X →∗ G ∧ G is terminal}. The language of G is then L(G) = LSG (G). We call the family of languages that can produced by any HRG the hyperedge replacement languages (HRL).\nWe assume that terminal edges are always of rank 1 or 2, and depict them as directed edges where the direction is determined by the tentacle labels: the tentacle labeled 1 attaches to the source of the edge and the tentacle labeled 2 attaches to the target of the edge, if it exists.\nExample 3. Table 1 shows a HRG deriving AMR graphs for sentences of the form ‘I need to want to need to want to ... to want to go’. Figure 4 is a graph derived by the grammar. The grammar is somewhat unnatural, a point we will return to (§5)."
    }, {
      "heading" : "2.2 Properties of HRGs",
      "text" : "A HRG can be made probabilistic just as a CFG can: for each nonterminal symbol, we define a distribution over the right-hand sides of all productions with that symbol as its left-hand side (Booth and Thompson, 1973). HRLs are not closed under intersection, just as the CFLs (which they general-\n4\n301\n302\n303\n304\n305\n306\n307\n308\n309\n310\n311\n312\n313\n314\n315\n316\n317\n318\n319\n320\n321\n322\n323\n324\n325\n326\n327\n328\n329\n330\n331\n332\n333\n334\n335\n336\n337\n338\n339\n340\n341\n342\n343\n344\n345\n346\n347\n348\n349\n350\n351\n352\n353\n354\n355\n356\n357\n358\n359\n360\n361\n362\n363\n364\n365\n366\n367\n368\n373\n374\n375\n376\n377\n378\n379\n380\n381\n382\n383\n384\n385\n386\n387\n388\n389\n390\n391\n392\n393\n394\n395\n396\n397\n398\n399\nSp : X\n(1)\n1 go 1\n2 I\narg0 Y Zs : (1)\n(2)\n1\n2\n1\narg0\narg1\nXq : W\nY\n(2)\n(1) 1\n2\n1 1\n2\narg1\narg0 Wt :\n(1) 1\nwant\nYr : Z\nX\n(2)\n(1) 1\n2\n1 1\n2\narg1\narg0 Zu :\n(1) 1\nneed\nTable 1: Productions of a HRG. The labels p, q, r, s, t, and u label the productions so that we can refer to them in the text. Note that Y can rewrite in two ways, either via production r or s.\n(1)\narg1\narg1\narg1\narg1\nneed\nwant\nneed\nwant\ngo\nI\narg0\narg0\narg0\narg0 arg0\nFigure 4: Graph derived by grammar in Table 1.\nize) are not: emptiness of HRLs is decidable, but given two HRLs simulating CFLs, the emptiness of their intersection is undecidable."
    }, {
      "heading" : "2.3 Regular Graph Grammars",
      "text" : "A regular graph grammar (RGG; Courcelle 1991) is a restricted form of HRG. To explain the restrictions, we first require some definitions.\nDefinition 4. Given a graph G, a path in G from a node v to a node v′ is a sequence\n(v0, i1, e1, j1, v1)(v1, i2, e2, j2, v2)\n. . . (vk−1, ik, ek, jk, vk) (1)\nsuch that v0 = v, vk = v′, vert(er, ir) = vr−1, and vert(er, jr) = vr, for each r ∈ {1, . . . , k}. The length of this path is k.\nA path is terminal if every edge in the path has a terminal label. A path is internal if each vi is internal for 1 ≤ i ≤ k−1. Note that the endpoints v0 and vk of an internal path can be external.\nDefinition 5. A HRG G is a Regular Graph Grammar if each nonterminal in NG has rank at least one and for each p ∈ PG the following hold:\n(C1) R(p) has at least one edge. Either it is a single terminal edge, all nodes of which are external, or each of its edges has at least one internal node.\n(C2) Every pair of nodes in R(p) is connected by a terminal and internal path.\nExample 4. The grammar in Table 1 is an RGG. Regular string and tree grammars are also RGGs (Figures 5 and 6).\nX\n(1)\nY Z\n(1)1 a\n1 2\n1 1\nb\nFigure 6: RGGs generalize regular tree grammars.\nWe call the family of languages generated by RGGs the regular graph languages (RGLs)."
    }, {
      "heading" : "3 RGLs are closed under intersection",
      "text" : "Monadic second-order languages (MSOLs; Courcelle and Engelfriet 2011) are graph languages defined by statements in monadic second-order (MSO) logic. An MSO formula ϕ defines the graph language L(ϕ) = {G | G |= ϕ}. A full explanation is beyond the scope of this paper but we provide a brief discussion of MSO in the supplementary materials. Courcelle (1991) proves that restrictions C1 and C2 ensure that any RGL is also a MSOL.\nMSOL is trivially closed under intersection, since the conjunction of two MSO statements is\n5\n401\n402\n403\n404\n405\n406\n407\n408\n409\n410\n411\n412\n413\n414\n415\n416\n417\n418\n419\n420\n421\n422\n423\n424\n425\n426\n427\n428\n429\n430\n431\n432\n433\n434\n435\n436\n437\n438\n439\n440\n441\n442\n443\n444\n445\n446\n447\n448\n449\n450\n451\n452\n453\n454\n455\n456\n457\n458\n459\n460\n461\n462\n463\n464\n465\n466\n467\n468\n469\n470\n471\n472\n473\n474\n475\n476\n477\n478\n479\n480\n481\n482\n483\n484\n485\n486\n487\n488\n489\n490\n491\n492\n493\n494\n495\n496\n497\n498\n499\nalso an MSO statement: if ϕ1 and ϕ2 are both MSO formulae, thenL(ϕ1)∩L(ϕ2) = L(ϕ1∧ϕ2). However, this does not guarantee that an arbitrary subfamily of MSOL is closed under intersection— it only guarantees that the intersection of two languages in subfamilyG are in MSOL, not necessarily inG itself. Here, we give a sufficient condition for a subfamily G to be closed under intersection.\nProposition 1. Let G be (1) a subclass of HRG, defined as a restriction on the right-hand sides of its productions that does not depend on nonterminal labels; and (2) MSO-definable. Then for any pair of languages L1, L2 ∈ G, the language L1 ∩ L2 is also in G.\nProof. Since both L1 and L2 are both in HRL and MSOL, we can look at them from both perspectives. Let G1 be a HRG deriving L1 and let φ2 be an MSO statement defining L2. Propositions 1.10 and 4.8 in Courcelle (1990) prove that the intersection of a HR language and an MSO language is in HRL, by constructing a HRG which derives all and only those graphs in the intersection of the two languages.3 This HRG has finitely many nonterminals defined by the cross product of the nonterminals of the original HRG and a finite set of ‘states’ of the MSO.4 The productions of the intersection grammar are copies of the original HRG, with different nonterminal labels. Hence we can construct HRG G∩ such that L(G∩) = L1 ∩ L2 and the productions in G∩ satisfy any restriction that G1 satisfied since the restriction is in terms of the right-hand sides of the productions but not the nonterminal labels. Therefore, G∩ is in G.\nRGG satisfies the conditions of Proposition 1, so RGLs are closed under intersection. Importantly, both proofs—that RGL is in MSOL and that RGL is closed under intersection—are constructive, implying that it is possible to construct the intersection grammar."
    }, {
      "heading" : "4 RGL Parsing",
      "text" : "To parse RGG, we will exploit the property that every nonterminal including the start symbol has rank at least one (Definition 5), and we assume\n3This is a generalization to graphs of the proof that the intersection of a context-free and regular string language is a context-free string language (Bar-Hillel et al., 1961).\n4For each MSO-definable language L in some set of all possible graphs L′, there exists a set A, a homomorphism h : L′ → A, and a finite subset C of A such that L = h−1(C). The finite set of ‘states’ here is the set C.\nthat the corresponding external node is identified in the input graph. This mild assumption may be a reasonable for applications like AMR parsing, where grammars could be designed so that the external node is always the unique root. Later we will relax this assumption.\nThe availability of an identifiable external node suggests a top-down algorithm, and we take inspiration from a top-down parsing algorithm the predictive top-down parsable grammars, another subclass of HRG (Drewes et al., 2015). These grammars, the graph equivalent of LL(1) string grammars, are incomparable to RGG, but the algorithms are related in their use of top-down prediction and in that they both fix an order of the edges in the right-hand side of each production."
    }, {
      "heading" : "4.1 Top-down Parsing for RGLs",
      "text" : "Just as the algorithm of Chiang et al. (2013) generalizes CKY to HRG, our algorithm generalizes Earley’s algorithm (Earley, 1970). Both algorithms operate by recognizing incrementally larger subgraphs of the input graph, using a succinct representation for subgraphs that depends on an arbitrarily chosen marker node m of the input graph.\nDefinition 6. (Chiang et al. 2013; Definition 6) Let I be a subgraph of G. A boundary node of I is a node which is either an endpoint of an edge in G\\I or an external node of G. A boundary edge of I is an edge in I which has a boundary node as an endpoint. The boundary representation of I is the tuple b(I) = 〈bn(I), be(I),m ∈ I〉 where\n1. bn(I) is the set of boundary nodes of I 2. be(I) is the set of boundary edges of I 3. (m ∈ I) is a flag indicating whether the\nmarker node is in I .\nChiang et al. (2013) prove each subgraph has a unique boundary representation, and give algorithms that use only boundary representations to compute the union of two subgraphs, requiring time linear in the number of boundary nodes; and to check disjointness of subgraphs, requiring time linear in the number of boundary edges.\nFor each production p of the grammar, we impose a fixed order on the edges of R(p), as in Drewes et al. (2015). We discuss this order in detail in §4.2. As in Earley’s algorithm, we use dotted rules to represent partial recognition of productions: X → ē1 . . . ēi−1 · ēi . . . ēn means that we have identified the edges ē1 to ēi−1 and that we must next recognize edge ēi. We write ē and\n6\n501\n502\n503\n504\n505\n506\n507\n508\n509\n510\n511\n512\n513\n514\n515\n516\n517\n518\n519\n520\n521\n522\n523\n524\n525\n526\n527\n528\n529\n530\n531\n532\n533\n534\n535\n536\n537\n538\n539\n540\n541\n542\n543\n544\n545\n546\n547\n548\n549\n550\n551\n552\n553\n554\n555\n556\n557\n558\n559\n560\n561\n562\n563\n564\n565\n566\n567\n568\n569\n570\n571\n572\n573\n574\n575\n576\n577\n578\n579\n580\n581\n582\n583\n584\n585\n586\n587\n588\n589\n590\n591\n592\n593\n594\n595\n596\n597\n598\n599\nv̄ for edges and nodes in productions and e and v for edges and nodes in a derived graph. When the identity of the sequence is immaterial we abbreviate it as α, for example writing X → ·α.\nWe present our parser as a deductive proof system (Shieber et al., 1995). The items of the parser are of the form [b(I), p : X → ē1 . . .· ēi . . . ēn, φp] where I is a subgraph that has been recognised as matching ē1, . . . , ēi−1; p : X → ē1, . . . , ēn is a production (called p) in the grammar with the edges in order; and φp : ER(p) → V ∗G is maps the endpoints of edges in R(p) to nodes in G.\nFor each production, p, we number the nodes in some arbitrary order. Using this, we construct the function φ0p : ER(p) → V ∗R(p) such that for ē ∈ ER(p) if att(ē) = (v̄1, v̄2) then φ0p(ē) = (v̄1, v̄2). As we match edges in the graph with edges in p, we assign the nodes v̄ to nodes in the graph. For example, if we have an edge ē in a production p such that att(ē) = (v̄1, v̄2) and we find an edge e which matches ē, then we update φp to record this fact, written φp[att(ē) = att(e)]. We also use φp to record assignments of external nodes. If we assign the ith external node to v, we write φp[extp(i) = v]. We write φ0p to represent a mapping with no grounded nodes.\nSince our algorithm makes top-down predictions based on known external nodes, our boundary representation must cover the case where a subgraph is empty except for these nodes. If at some point we know that our subgraph has external nodes φ(ē), then we use the shorthand φ(ē) rather than the full boundary representation 〈φ(ē), ∅,m ∈ φ(ē)〉.\nTo keep notation uniform, we use dummy nonterminal S∗ 6∈ NG that derives SG via production p0. For graph G, our system includes the axiom:\n[extG, p0 : S∗ →·SG , φ0p0 [extR(p0) = extG]]. Our goal is to prove:\n[b(G), S∗ → SG·, φ] where φ is the union of the φps for each production p used to derive G.\nAs in Earley’s algorithm, we have three inference rules: PREDICT, SCAN and COMPLETE (Table 2). PREDICT is applied when the edge after the dot is nonterminal, assigning any external nodes\nthat have been identified. SCAN is applied when the edge after the dot is terminal. Using φp, we may already know where some of the endpoints of the edge should be, so it requires the endpoints of the scanned edge to match. COMPLETE requires that a recognized subgraph J match on the external nodes of its edge in the parent graph, and that the combined subgraphs are edge-disjoint.5\nExample 5. Using the RGG in Table 1, we show how to parse the graph in Figure 7, which can be derived by applying production s followed by production u, where the external nodes of Y are (v3, v2). Assume the ordering of the edges in production s is arg1, arg0, Z; the top node is v̄1; the bottom node is v̄2; and the node on the right is v̄3; and that the marker node is not in this subgraph— we elide reference to it for simplicity. The external nodes of Y are determined top-down, so the parse of this subgraph is triggered by this item: [(v3, v2), Y →· arg1arg0Z, φs] where φs(arg1) = (v̄1, v3), φs(arg0) = (v̄1, v2), and φs(Z) = (v̄1).\nTable 3 shows how we can prove the item\n[〈{v3, v2}, {e3, e2}〉, Y → arg1arg0Z·, φ] The boundary representation 〈{v3, v2}, {e3, e2}〉 in this item represents the whole subgraph shown in Figure 7.\nv1\nv2\nv3 . . .\n. . .\nneed (e1)\narg0 (e2)\narg1 (e3)\nFigure 7: Top left subgraph of Figure 4. To refer to nodes and edges in the text, they are labeled v1, v2, v3, e1, e2, and e3."
    }, {
      "heading" : "4.2 Normal Ordering",
      "text" : "Our algorithm requires a fixed ordering of the edges in the right-hand sides of each production. We will constrain this ordering to exploit the structure of RGG productions, allowing us to bound\n5We provide a soundness and completeness proof of the parser in the supplementary materials.\n7\n601\n602\n603\n604\n605\n606\n607\n608\n609\n610\n611\n612\n613\n614\n615\n616\n617\n618\n619\n620\n621\n622\n623\n624\n625\n626\n627\n628\n629\n630\n631\n632\n633\n634\n635\n636\n637\n638\n639\n640\n641\n642\n643\n644\n645\n646\n647\n648\n649\n650\n651\n652\n653\n654\n655\n656\n657\n658\n659\n660\n661\n662\n663\n664\n665\n666\n667\n668\n669\n670\n671\n672\n673\n674\n675\n676\n677\n678\n679\n680\n681\n682\n683\n684\n685\n686\n687\n688\n689\n690\n691\n692\n693\n694\n695\n696\n697\n698\n699\nName Rule Conditions\nPREDICT [b(I), p : X → ē1 . . .· ēi . . . ēn, φp][q : Y → α]\n[φp(ēi), Y → ·α, φ0q [extR(q) = φp(ēi)]] lab(ēi) = Y\nSCAN [b(I), X → ē1 . . .· ēi . . . ēn, φp][e = edglab(ēi)(v1, . . . , vm)]\n[b(I ∪ {e}), X → ē1 . . .· ēi+1 . . . ēn, φp[att(ēi) = (v1, . . . , vm)]] φp(ēi)(j) ∈ VG ⇒ φp(ēi)(j) = vert(e, j)\nCOMPLETE [b(I), p : X → ē1 . . .· ēi . . . ēn, φp][b(J), q : Y → α·, φq] [b(I ∪ J), X → ē1 . . .· ēi+1 . . . ēn, φp ∪ φq] φp(ēi) = φq(extR(q))\nlab(ēi) = Y EI ∩ EJ = ∅\nTable 2: The inference rules for the top-down parser.\nCurrent Item Reason 1. [(v3, v2), Y → · arg1arg0Z, φs] Axiom 2. [〈{v3, v2, v1}, {e3}〉, Y → arg1· arg0Z, φs[att(arg1) = (v1, v3)]] SCAN: 1. and e3 = edgarg1(v1, v3) 3. [〈{v3, v2, v1}, {e3, e2}〉, Y → arg1arg0·Z, φs[att(arg0) = (v1, v2)]] SCAN: 2. and e2 = edgarg0(v1, v2)] 4. [(v1), Z → · need, φ0u[extR(u) = φs(Z)]] PREDICT: 3. and Z → need 5. [〈{v1}, {e1}〉, Z → need·, φu[att(need) = (v1)]] SCAN: 4. and e1 = edgneed(v1) 6. [〈{v3, v2}, {e3, e2}〉, Y → arg1arg0Z ·, φs ∪ φu] COMPLETE: 3. and 5.\nTable 3: The steps of recognising that the subgraph shown in Figure 7 is derived from productions r2 and u in the grammar in Table 1.\n(1) X (2)a 1 2 b\nFigure 8: This graph cannot be normally ordered.\nparsing complexity. If s = ē1 . . . ēn is an order, define si:j = ēi . . . ēj .\nDefinition 7. Let s be the order of a right-hand side of a production. s is normal if it has the following properties:\n1. ē1 is connected to an external node, 2. s1:j is a connected graph for all j ∈ {1, . . . , n},\n3. if ēi is nonterminal, each endpoint of ēi must be shared with ēj where ēj is terminal and j < i.\nExample 6. The ordering of the edges of production s in Example 5 is normal.\nArbitrary HRGs do not necessarily admit a normal ordering. For example, the graph in Figure 8 cannot satisfy properties 2 and 3 simultaneously. However, RGGs do admit a normal ordering.\nProposition 2. If G is an RGG, for every p ∈ PG , there is a normal ordering of the edges in R(p).\nProof. If R(p) contains a single node then it must be an external node and it must have a terminal edge attached to it since R(p) must contain at least one terminal edge. If R(p) contains multiple nodes then by C2 there must be terminal internal paths between all of them, so there must be a terminal edge attached to the external node, which we use to satisfy property 1. We select terminal edges once one of their endpoints is connected to an ordered edge, and nonterminal edges once all endpoints are connected to ordered edges, possible by C2. Therefore, properties 2 and 3 are satisfied.\nNormal ordering tightly constrains recognition of edges. Property 3 ensures that when we apply PREDICT, the external nodes of the predicted edge are all bound to specific nodes in the graph. Properties 1 and 2 ensures that when we apply SCAN, at least one endpoint of the edge is bound."
    }, {
      "heading" : "4.3 Parsing Complexity",
      "text" : "Assume a normally-ordered RGG. Let the maximum number of edges in the right-hand side of any\n8\n701\n702\n703\n704\n705\n706\n707\n708\n709\n710\n711\n712\n713\n714\n715\n716\n717\n718\n719\n720\n721\n722\n723\n724\n725\n726\n727\n728\n729\n730\n731\n732\n733\n734\n735\n736\n737\n738\n739\n740\n741\n742\n743\n744\n745\n746\n747\n748\n749\n750\n751\n752\n753\n754\n755\n756\n757\n758\n759\n760\n761\n762\n763\n764\n765\n766\n767\n768\n769\n770\n771\n772\n773\n774\n775\n776\n777\n778\n779\n780\n781\n782\n783\n784\n785\n786\n787\n788\n789\n790\n791\n792\n793\n794\n795\n796\n797\n798\n799\nproduction be m; the maximum number of nodes in any right-hand side of a production k; the maximum degree of any node in the input graph d; and the number of nodes in the input graph n.\nRemark 1. The maximum number of nodes in any right-hand side of a production (k) is also the maximum number of boundary nodes for any subgraph in the parser.\nCOMPLETE combines subgraphs I and J only when the entire subgraph derived from Y has been recognized. Boundary nodes of J are also boundary nodes of I since they are nodes in the terminal subgraph of R(p) where Y connects. The boundary nodes of I ∪J are also bounded by k since are a subset of the boundary nodes of I .\nRemark 2. Given a boundary node, there are at most (dm)k−1 ways of identifying the remaining boundary nodes of a subgraph that is isomorphic to the terminal subgraph of the right-hand side of a production.\nThe terminal subgraph of each production is connected by C2, with a maximum path length of m. For each edge in the path, there are at most d subsequent edges. Hence for the k − 1 remaining boundary nodes there are (dm)k−1 ways of choosing them.\nWe count instantiations of COMPLETE for an upper bound on complexity (McAllester, 2002), using similar logic to (Chiang et al., 2013). The number of boundary nodes of I, J and I ∪ J is at most k. Therefore, if we choose an arbitrary node to be some boundary node of I ∪J , there are at most (dm)k−1 ways of choosing its remaining boundary nodes. For each of these nodes, there are at most (3d)k states of their attached boundary edges: in I , in J , or in neither. The total number of instantiations is thenO(n(dm)k−1(3d)k), linear in the number of input nodes and exponential in the degree of the input graph. In the case of the AMR dataset, the maximum node degree is 17 and the average degree is 2.12.\nWe observe that RGGs could be relaxed to produce graphs with no external nodes by adding a dummy nonterminal S′ with rank 0 and a single production S′ → S. To adapt the parsing algorithm, we would first need to guess where the graph starts. This would add a factor of n to the complexity as the graph could start at any node, requiring n runs of the algorithm."
    }, {
      "heading" : "5 Discussion and Conclusions",
      "text" : "RGG supports probabilistic interpretation and is closed under intersection, making it similar to regular families of string and tree languages that are widely used in NLP. The constraints of RGG also enable more efficient parsing than general HRG, and this tradeoff is reasonable since HRG is very expressive—when generating strings, it can express non-context-free languages (Engelfriet and Heyker, 1991; Bauer and Rambow, 2016), far more power than needed to express semantic graphs. On the other hand, RGG is so constrained that it may not be expressive enough: it would be more natural to derive the graph in Figure 4 from outermost to innermost predicate; but constraint C2 makes it difficult to express this, and the grammar in Table 1 does not. Perhaps we need less expressivity than HRG but more than RGG.\nSince RGLs are a subfamily of both HRL and MSOL, they inherit probability and intersection closure, respectively. Courcelle (1991) discusses exactly those languages that are both HRL and MSOL, which he calls strongly contextfree languages (SCFL).6 SCFLs are defined nonconstructively, but it is natural to ask whether other, less restrictive subfamilies of SCFLs can be constructed using similar mathematical tools. Courcelle (1991) identifies the family of seriesparallel graphs as one such family, but it seems of little relevance to NLP. However, there are two recent independently-developed formalisms that may be useful. Tree-like Grammars (TLG; Matheja et al. 2015) and Restricted DAG Grammars (RDG; Björklund et al. 2016), both explicitly defined as restrictions on HRG. TLGs are in MSOL (and are closed under intersection) but we do not yet know if RDG is a subfamily of MSOL, or whether they are closed under intersection. They are both incomparable to RGG, but they share important characteristics, including the fact that the terminal subgraph of every production is connected. This means that our top-down parsing algorithm is applicable to both. In addition, if RDGs are in fact MSOL, Proposition 1 applies to them and means they are closed under intersection. We conjecture that larger, less restrictive subfamilies of SCFLs may be found based on a weaker restriction of connected terminal subgraphs, and we plan to explore these questions in future work.\n6Courcelle’s definition of strongly context-free is unrelated to use of this term in NLP.\n9\n801\n802\n803\n804\n805\n806\n807\n808\n809\n810\n811\n812\n813\n814\n815\n816\n817\n818\n819\n820\n821\n822\n823\n824\n825\n826\n827\n828\n829\n830\n831\n832\n833\n834\n835\n836\n837\n838\n839\n840\n841\n842\n843\n844\n845\n846\n847\n848\n849\n850\n851\n852\n853\n854\n855\n856\n857\n858\n859\n860\n861\n862\n863\n864\n865\n866\n867\n868\n869\n870\n871\n872\n873\n874\n875\n876\n877\n878\n879\n880\n881\n882\n883\n884\n885\n886\n887\n888\n889\n890\n891\n892\n893\n894\n895\n896\n897\n898\n899"
    } ],
    "references" : [ {
      "title" : "Universal conceptual cognitive annotation (ucca)",
      "author" : [ "Omri Abend", "Ari Rappoport." ],
      "venue" : "ACL (1). The Association for Computational Linguistics, pages 228–238. http://dblp.unitrier.de/db/conf/acl/acl2013-1.html#AbendR13.",
      "citeRegEx" : "Abend and Rappoport.,? 2013",
      "shortCiteRegEx" : "Abend and Rappoport.",
      "year" : 2013
    }, {
      "title" : "Pushdown automata in statistical machine translation",
      "author" : [ "Cyril Allauzen", "William Byrne", "Adria de Gispert", "Gonzalo Iglesias", "Michael Riley." ],
      "venue" : "Computational Linguistics .",
      "citeRegEx" : "Allauzen et al\\.,? 2014",
      "shortCiteRegEx" : "Allauzen et al\\.",
      "year" : 2014
    }, {
      "title" : "Abstract meaning representation for sembanking",
      "author" : [ "Laura Banarescu", "Claire Bonial", "Shu Cai", "Madalina Georgescu", "Kira Griffitt", "Ulf Hermjakob", "Kevin Knight", "Philipp Koehn", "Martha Palmer", "Nathan Schneider." ],
      "venue" : "Proceedings of the",
      "citeRegEx" : "Banarescu et al\\.,? 2013",
      "shortCiteRegEx" : "Banarescu et al\\.",
      "year" : 2013
    }, {
      "title" : "On formal properties of simple phrase structure grammars",
      "author" : [ "Yehoshua Bar-Hillel", "Micha A. Perles", "Eli Shamir." ],
      "venue" : "Zeitschrift für Phonetik, Sprachwissenschaft und Kommunikationsforschung (14):143– 172.",
      "citeRegEx" : "Bar.Hillel et al\\.,? 1961",
      "shortCiteRegEx" : "Bar.Hillel et al\\.",
      "year" : 1961
    }, {
      "title" : "Hyperedge replacement and nonprojective dependency structures",
      "author" : [ "Daniel Bauer", "Owen Rambow." ],
      "venue" : "Proceedings of the 12th International Workshop on Tree Adjoining Grammars and Related Formalisms",
      "citeRegEx" : "Bauer and Rambow.,? 2016",
      "shortCiteRegEx" : "Bauer and Rambow.",
      "year" : 2016
    }, {
      "title" : "Between a Rock and a Hard Place – Uniform Parsing for Hyperedge Replacement DAG Grammars, Springer International Publishing, Cham, pages 521–532",
      "author" : [ "Henrik Björklund", "Frank Drewes", "Petter Ericson." ],
      "venue" : "https://doi.org/10.1007/978-",
      "citeRegEx" : "Björklund et al\\.,? 2016",
      "shortCiteRegEx" : "Björklund et al\\.",
      "year" : 2016
    }, {
      "title" : "Definability equals recognizability for graphs of bounded treewidth",
      "author" : [ "Mikolaj Bojanczyk", "Michal Pilipczuk." ],
      "venue" : "Proceedings of the 31st Annual ACM/IEEE Symposium on Logic in Computer Science. ACM, New",
      "citeRegEx" : "Bojanczyk and Pilipczuk.,? 2016",
      "shortCiteRegEx" : "Bojanczyk and Pilipczuk.",
      "year" : 2016
    }, {
      "title" : "Applying probability measures to abstract languages",
      "author" : [ "T.L. Booth", "R.A. Thompson." ],
      "venue" : "IEEE Transactions on Computers 22(5):442–450. https://doi.org/http://doi.ieeecomputersociety.org/10.1109/TC.1973.223746.",
      "citeRegEx" : "Booth and Thompson.,? 1973",
      "shortCiteRegEx" : "Booth and Thompson.",
      "year" : 1973
    }, {
      "title" : "On a decision method in restricted second-order arithmetic",
      "author" : [ "Julius Richard Büchi." ],
      "venue" : "Proceedings Logic, Methodology and Philosophy of Sciences .",
      "citeRegEx" : "Büchi.,? 1960",
      "shortCiteRegEx" : "Büchi.",
      "year" : 1960
    }, {
      "title" : "Decision problems of weak second order arithmetic and finite",
      "author" : [ "Julius Richard Büchi", "Calvin Elgot" ],
      "venue" : null,
      "citeRegEx" : "Büchi and Elgot.,? \\Q1958\\E",
      "shortCiteRegEx" : "Büchi and Elgot.",
      "year" : 1958
    }, {
      "title" : "Parsing graphs with hyperedge replacement grammars",
      "author" : [ "David Chiang", "Jacob Andreas", "Daniel Bauer", "Karl Moritz Hermann", "Bevan Jones", "Kevin Knight." ],
      "venue" : "Proceedings of the 51st Annual Meeting of the Associa-",
      "citeRegEx" : "Chiang et al\\.,? 2013",
      "shortCiteRegEx" : "Chiang et al\\.",
      "year" : 2013
    }, {
      "title" : "The monadic second-order logic of graphs i",
      "author" : [ "Bruno Courcelle." ],
      "venue" : "recognizable sets of finite graphs. Information and Computation pages 12–75.",
      "citeRegEx" : "Courcelle.,? 1990",
      "shortCiteRegEx" : "Courcelle.",
      "year" : 1990
    }, {
      "title" : "The monadic second-order logic of graphs V: on closing the gap between definability and recognizability",
      "author" : [ "Bruno Courcelle." ],
      "venue" : "Theor. Comput. Sci. 80(2):153–202. https://doi.org/10.1016/03043975(91)90387-H.",
      "citeRegEx" : "Courcelle.,? 1991",
      "shortCiteRegEx" : "Courcelle.",
      "year" : 1991
    }, {
      "title" : "Graph Structure and Monadic Second-Order Logic, a Language Theoretic Approach",
      "author" : [ "Bruno Courcelle", "Joost Engelfriet." ],
      "venue" : "Cambridge University Press.",
      "citeRegEx" : "Courcelle and Engelfriet.,? 2011",
      "shortCiteRegEx" : "Courcelle and Engelfriet.",
      "year" : 2011
    }, {
      "title" : "Predictive Top-Down Parsing for Hyperedge Replacement Grammars, Springer International Publishing, Cham, pages 19–34",
      "author" : [ "Frank Drewes", "Berthold Hoffmann", "Mark Minas." ],
      "venue" : "https://doi.org/10.1007/978-3-319-21145-9 2.",
      "citeRegEx" : "Drewes et al\\.,? 2015",
      "shortCiteRegEx" : "Drewes et al\\.",
      "year" : 2015
    }, {
      "title" : "Hyperedge replacement graph grammars",
      "author" : [ "Frank Drewes", "Hans-Jörg Kreowski", "Annegret Habel." ],
      "venue" : "Grzegorz Rozenberg, editor, Handbook of Graph Grammars and Computing by Graph Transformation, World Scientific, pages 95–162.",
      "citeRegEx" : "Drewes et al\\.,? 1997",
      "shortCiteRegEx" : "Drewes et al\\.",
      "year" : 1997
    }, {
      "title" : "Weighted Automata and Weighted Logics, Springer Berlin Heidelberg, Berlin, Heidelberg, pages 513–525",
      "author" : [ "Manfred Droste", "Paul Gastin." ],
      "venue" : "https://doi.org/10.1007/11523468 42.",
      "citeRegEx" : "Droste and Gastin.,? 2005",
      "shortCiteRegEx" : "Droste and Gastin.",
      "year" : 2005
    }, {
      "title" : "An efficient context-free parsing algorithm",
      "author" : [ "Jay Earley." ],
      "venue" : "ACM, New York, NY, USA, volume 13, pages 94–102. https://doi.org/10.1145/362007.362035.",
      "citeRegEx" : "Earley.,? 1970",
      "shortCiteRegEx" : "Earley.",
      "year" : 1970
    }, {
      "title" : "The string generating power of context-free hypergraph grammars",
      "author" : [ "Joost Engelfriet", "Linda Heyker." ],
      "venue" : "Journal of Computer and System Sciences 43(2):328–360.",
      "citeRegEx" : "Engelfriet and Heyker.,? 1991",
      "shortCiteRegEx" : "Engelfriet and Heyker.",
      "year" : 1991
    }, {
      "title" : "Deepbank : a dynamically annotated treebank of the wall street journal",
      "author" : [ "Dan Flickinger", "Yi Zhang", "Valia Kordoni." ],
      "venue" : "Proceedings of the Eleventh International Workshop on Treebanks and Linguistic Theories (TLT11). Lisbon, pages 85–96. HU.",
      "citeRegEx" : "Flickinger et al\\.,? 2012",
      "shortCiteRegEx" : "Flickinger et al\\.",
      "year" : 2012
    }, {
      "title" : "Confidential Review Copy. DO NOT DISTRIBUTE. Announcing prague czech-english dependency treebank 2.0",
      "author" : [ "Khalid Choukri", "Thierry Declerck", "Mehmet Uur Doan", "Bente Maegaard", "Joseph Mariani", "Asun" ],
      "venue" : "ACL",
      "citeRegEx" : "Chair. et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Chair. et al\\.",
      "year" : 2017
    }, {
      "title" : "Semanticsbased machine translation with hyperedge replacement grammars",
      "author" : [ "Bevan Jones", "Jacob Andreas", "Daniel Bauer", "Karl Mortiz Hermann", "Kevin Knight." ],
      "venue" : "Proceedings of COLING.",
      "citeRegEx" : "Jones et al\\.,? 2012",
      "shortCiteRegEx" : "Jones et al\\.",
      "year" : 2012
    }, {
      "title" : "Parallel and two-way automata on directed ordered acyclic graphs",
      "author" : [ "Tsutomu Kamimura", "Giora Slutzki." ],
      "venue" : "Information and Control 49(1):10–51.",
      "citeRegEx" : "Kamimura and Slutzki.,? 1981",
      "shortCiteRegEx" : "Kamimura and Slutzki.",
      "year" : 1981
    }, {
      "title" : "Tree-Like Grammars and Separation Logic, Springer International Publishing, Cham, pages 90–108",
      "author" : [ "Christoph Matheja", "Christina Jansen", "Thomas Noll." ],
      "venue" : "https://doi.org/10.1007/978-3-31926529-2 6.",
      "citeRegEx" : "Matheja et al\\.,? 2015",
      "shortCiteRegEx" : "Matheja et al\\.",
      "year" : 2015
    }, {
      "title" : "On the complexity analysis of static analyses",
      "author" : [ "David McAllester." ],
      "venue" : "J. ACM 49(4):512–537. https://doi.org/10.1145/581771.581774.",
      "citeRegEx" : "McAllester.,? 2002",
      "shortCiteRegEx" : "McAllester.",
      "year" : 2002
    }, {
      "title" : "Speech recognition with weighted finite-state transducers",
      "author" : [ "Mehryar Mohri", "Fernando C.N. Pereira", "Michael Riley." ],
      "venue" : "Larry Rabiner and Fred Juang, editors, Handbook on Speech Processing and Speech Communication, Part E: Speech recognition,",
      "citeRegEx" : "Mohri et al\\.,? 2008",
      "shortCiteRegEx" : "Mohri et al\\.",
      "year" : 2008
    }, {
      "title" : "A synchronous hyperedge replacement grammar based approach for AMR parsing",
      "author" : [ "Xiaochang Peng", "Linfeng Song", "Daniel Gildea." ],
      "venue" : "Proceedings of the 19th Conference on Computational Natural Language Learning, CoNLL 2015,",
      "citeRegEx" : "Peng et al\\.,? 2015",
      "shortCiteRegEx" : "Peng et al\\.",
      "year" : 2015
    }, {
      "title" : "Towards probabilistic acceptors and transducers for feature structures",
      "author" : [ "Daniel Quernheim", "Kevin Knight." ],
      "venue" : "Proceedings of the Sixth Workshop on Syntax, Semantics and Structure in Statistical Translation. Association for Computational Linguistics,",
      "citeRegEx" : "Quernheim and Knight.,? 2012",
      "shortCiteRegEx" : "Quernheim and Knight.",
      "year" : 2012
    }, {
      "title" : "Principles and implementation of deductive parsing",
      "author" : [ "Stuart M. Shieber", "Yves Schabes", "Fernando C.N. Pereira." ],
      "venue" : "Journal of Logic Programming 24(1-2).",
      "citeRegEx" : "Shieber et al\\.,? 1995",
      "shortCiteRegEx" : "Shieber et al\\.",
      "year" : 1995
    }, {
      "title" : "Automata, Languages and Programming: 18th International Colloquium",
      "author" : [ "Wolfgang Thomas" ],
      "venue" : null,
      "citeRegEx" : "Thomas.,? \\Q1991\\E",
      "shortCiteRegEx" : "Thomas.",
      "year" : 1991
    }, {
      "title" : "Finite automata and logic of monadic predicates",
      "author" : [ "Boris Trakhtenbrot." ],
      "venue" : "Doklady Akademii Nauk SSSR pages 140:326–329.",
      "citeRegEx" : "Trakhtenbrot.,? 1961",
      "shortCiteRegEx" : "Trakhtenbrot.",
      "year" : 1961
    } ],
    "referenceMentions" : [ {
      "referenceID" : 2,
      "context" : "In pursuit of this goal, several datasets have been produced which pair natural language with compositional semantic representations in the form of directed acyclic graphs (DAGs), including the Abstract Meaning Represenation Bank (AMR; Banarescu et al. 2013), the Prague Czech-English Dependency Treebank (Hajič et al.",
      "startOffset" : 230,
      "endOffset" : 258
    }, {
      "referenceID" : 21,
      "context" : "Figure 1: Semantic machine translation using AMR (Jones et al., 2012).",
      "startOffset" : 49,
      "endOffset" : 69
    }, {
      "referenceID" : 19,
      "context" : "bank (Flickinger et al., 2012), and the Universal Conceptual Cognitive Annotation (Abend and Rappoport, 2013).",
      "startOffset" : 5,
      "endOffset" : 30
    }, {
      "referenceID" : 0,
      "context" : ", 2012), and the Universal Conceptual Cognitive Annotation (Abend and Rappoport, 2013).",
      "startOffset" : 59,
      "endOffset" : 86
    }, {
      "referenceID" : 0,
      "context" : ", 2012), and the Universal Conceptual Cognitive Annotation (Abend and Rappoport, 2013). To make use of this data, we require probabilistic models of graphs. Consider how we might use compositional semantic representations in machine translation (Figure 1). We first parse a source sentence to its semantic representation, and then generate a target sentence from this representation. Stated more formally, we first predict a graph G from a source string s, and then predict a target string t from G, giving us a conditional model P(t, G|s), which we can decompose as P(t, G|s) = P(t|G)P(G|s). Jones et al. (2012) observe that this decomposition can be modeled with a pair of probabilistic synchronous grammars over domains of strings and graphs.",
      "startOffset" : 60,
      "endOffset" : 613
    }, {
      "referenceID" : 25,
      "context" : "For NLP problems in which data is in the form of strings and trees, such distributions can be represented by finite automata (Mohri et al., 2008; Allauzen et al., 2014), which are closed under intersection and can be made probabilistic.",
      "startOffset" : 125,
      "endOffset" : 168
    }, {
      "referenceID" : 1,
      "context" : "For NLP problems in which data is in the form of strings and trees, such distributions can be represented by finite automata (Mohri et al., 2008; Allauzen et al., 2014), which are closed under intersection and can be made probabilistic.",
      "startOffset" : 125,
      "endOffset" : 168
    }, {
      "referenceID" : 15,
      "context" : "Recent work in NLP has focused primarily on two families of graph languages: hyperedge replacement languages (HRL; Drewes et al. 1997), a context-free graph rewriting formalism that has been studied in an NLP context by several researchers (Chiang et al.",
      "startOffset" : 109,
      "endOffset" : 134
    }, {
      "referenceID" : 10,
      "context" : "1997), a context-free graph rewriting formalism that has been studied in an NLP context by several researchers (Chiang et al., 2013; Peng et al., 2015; Bauer and Rambow, 2016); and DAG automata languages, (Kamimura and Slutzki, 1981), studied by Quernheim and Knight (2012).",
      "startOffset" : 111,
      "endOffset" : 175
    }, {
      "referenceID" : 26,
      "context" : "1997), a context-free graph rewriting formalism that has been studied in an NLP context by several researchers (Chiang et al., 2013; Peng et al., 2015; Bauer and Rambow, 2016); and DAG automata languages, (Kamimura and Slutzki, 1981), studied by Quernheim and Knight (2012).",
      "startOffset" : 111,
      "endOffset" : 175
    }, {
      "referenceID" : 4,
      "context" : "1997), a context-free graph rewriting formalism that has been studied in an NLP context by several researchers (Chiang et al., 2013; Peng et al., 2015; Bauer and Rambow, 2016); and DAG automata languages, (Kamimura and Slutzki, 1981), studied by Quernheim and Knight (2012).",
      "startOffset" : 111,
      "endOffset" : 175
    }, {
      "referenceID" : 22,
      "context" : ", 2015; Bauer and Rambow, 2016); and DAG automata languages, (Kamimura and Slutzki, 1981), studied by Quernheim and Knight (2012).",
      "startOffset" : 61,
      "endOffset" : 89
    }, {
      "referenceID" : 8,
      "context" : "Thomas (1991) showed that the latter are a subfamily of the monadic second order languages (MSOL), which are of special interest to us, since, when restricted to strings or trees, they exactly characterize the regular languages of each (Büchi, 1960; Büchi and Elgot, 1958; Trakhtenbrot, 1961).",
      "startOffset" : 236,
      "endOffset" : 292
    }, {
      "referenceID" : 9,
      "context" : "Thomas (1991) showed that the latter are a subfamily of the monadic second order languages (MSOL), which are of special interest to us, since, when restricted to strings or trees, they exactly characterize the regular languages of each (Büchi, 1960; Büchi and Elgot, 1958; Trakhtenbrot, 1961).",
      "startOffset" : 236,
      "endOffset" : 292
    }, {
      "referenceID" : 30,
      "context" : "Thomas (1991) showed that the latter are a subfamily of the monadic second order languages (MSOL), which are of special interest to us, since, when restricted to strings or trees, they exactly characterize the regular languages of each (Büchi, 1960; Büchi and Elgot, 1958; Trakhtenbrot, 1961).",
      "startOffset" : 236,
      "endOffset" : 292
    }, {
      "referenceID" : 11,
      "context" : "The HRL and MSOL families are incomparable: that is, the context-free graph languages do not contain the regular graph languages, as is the case in languages of strings and trees (Courcelle, 1990).",
      "startOffset" : 179,
      "endOffset" : 196
    }, {
      "referenceID" : 27,
      "context" : "So, while each formalism has appealing characteristics, none appear adequate for the problem outlined above: HRLs can be made probabilistic, but they are not closed under intersection; and while DAGAL and MSOL are closed under intersection, it is unclear how to make them probabilistic (Quernheim and Knight, 2012).",
      "startOffset" : 286,
      "endOffset" : 314
    }, {
      "referenceID" : 1,
      "context" : ", 2008; Allauzen et al., 2014), which are closed under intersection and can be made probabilistic. It is therefore natural to ask whether there is a family of graph languages with similar properties to finite automata. Recent work in NLP has focused primarily on two families of graph languages: hyperedge replacement languages (HRL; Drewes et al. 1997), a context-free graph rewriting formalism that has been studied in an NLP context by several researchers (Chiang et al., 2013; Peng et al., 2015; Bauer and Rambow, 2016); and DAG automata languages, (Kamimura and Slutzki, 1981), studied by Quernheim and Knight (2012). Thomas (1991) showed that the latter are a subfamily of the monadic second order languages (MSOL), which are of special interest to us, since, when restricted to strings or trees, they exactly characterize the regular languages of each (Büchi, 1960; Büchi and Elgot, 1958; Trakhtenbrot, 1961).",
      "startOffset" : 8,
      "endOffset" : 622
    }, {
      "referenceID" : 1,
      "context" : ", 2008; Allauzen et al., 2014), which are closed under intersection and can be made probabilistic. It is therefore natural to ask whether there is a family of graph languages with similar properties to finite automata. Recent work in NLP has focused primarily on two families of graph languages: hyperedge replacement languages (HRL; Drewes et al. 1997), a context-free graph rewriting formalism that has been studied in an NLP context by several researchers (Chiang et al., 2013; Peng et al., 2015; Bauer and Rambow, 2016); and DAG automata languages, (Kamimura and Slutzki, 1981), studied by Quernheim and Knight (2012). Thomas (1991) showed that the latter are a subfamily of the monadic second order languages (MSOL), which are of special interest to us, since, when restricted to strings or trees, they exactly characterize the regular languages of each (Büchi, 1960; Büchi and Elgot, 1958; Trakhtenbrot, 1961).",
      "startOffset" : 8,
      "endOffset" : 637
    }, {
      "referenceID" : 1,
      "context" : ", 2008; Allauzen et al., 2014), which are closed under intersection and can be made probabilistic. It is therefore natural to ask whether there is a family of graph languages with similar properties to finite automata. Recent work in NLP has focused primarily on two families of graph languages: hyperedge replacement languages (HRL; Drewes et al. 1997), a context-free graph rewriting formalism that has been studied in an NLP context by several researchers (Chiang et al., 2013; Peng et al., 2015; Bauer and Rambow, 2016); and DAG automata languages, (Kamimura and Slutzki, 1981), studied by Quernheim and Knight (2012). Thomas (1991) showed that the latter are a subfamily of the monadic second order languages (MSOL), which are of special interest to us, since, when restricted to strings or trees, they exactly characterize the regular languages of each (Büchi, 1960; Büchi and Elgot, 1958; Trakhtenbrot, 1961). The HRL and MSOL families are incomparable: that is, the context-free graph languages do not contain the regular graph languages, as is the case in languages of strings and trees (Courcelle, 1990). So, while each formalism has appealing characteristics, none appear adequate for the problem outlined above: HRLs can be made probabilistic, but they are not closed under intersection; and while DAGAL and MSOL are closed under intersection, it is unclear how to make them probabilistic (Quernheim and Knight, 2012).1 This paper investigates the regular graph languages (RGL; Courcelle 1991), defined as a restricted form of HRL (§2). The restrictions ensure that RGLs are a subfamily of MSOL. Courcelle (1991) defined regular graph grammars as an auxiliary result of a theoretical research question quite different from ours.",
      "startOffset" : 8,
      "endOffset" : 1625
    }, {
      "referenceID" : 16,
      "context" : "Semiring-weighted MSOLs have been defined, where weights may be in the tropical semiring (Droste and Gastin, 2005).",
      "startOffset" : 89,
      "endOffset" : 114
    }, {
      "referenceID" : 6,
      "context" : "The primary research question of Courcelle (1991) is a conjecture which has only quite recently been proven (Bojanczyk and Pilipczuk, 2016).",
      "startOffset" : 108,
      "endOffset" : 139
    }, {
      "referenceID" : 6,
      "context" : "This does not appear to have been demonstrated for DAGAL, which violate the sufficient conditions that Booth and Thompson (1973) give for probabilistic languages.",
      "startOffset" : 103,
      "endOffset" : 129
    }, {
      "referenceID" : 6,
      "context" : "This does not appear to have been demonstrated for DAGAL, which violate the sufficient conditions that Booth and Thompson (1973) give for probabilistic languages. We suspect that there are DAGAL (hence MSOL) for which it is not possible. The primary research question of Courcelle (1991) is a conjecture which has only quite recently been proven (Bojanczyk and Pilipczuk, 2016).",
      "startOffset" : 103,
      "endOffset" : 288
    }, {
      "referenceID" : 7,
      "context" : "2 Properties of HRGs A HRG can be made probabilistic just as a CFG can: for each nonterminal symbol, we define a distribution over the right-hand sides of all productions with that symbol as its left-hand side (Booth and Thompson, 1973).",
      "startOffset" : 210,
      "endOffset" : 236
    }, {
      "referenceID" : 11,
      "context" : "Monadic second-order languages (MSOLs; Courcelle and Engelfriet 2011) are graph languages defined by statements in monadic second-order (MSO) logic. An MSO formula φ defines the graph language L(φ) = {G | G |= φ}. A full explanation is beyond the scope of this paper but we provide a brief discussion of MSO in the supplementary materials. Courcelle (1991) proves that restrictions C1 and C2 ensure that any RGL is also a MSOL.",
      "startOffset" : 39,
      "endOffset" : 357
    }, {
      "referenceID" : 11,
      "context" : "8 in Courcelle (1990) prove that the intersection of a HR language and an MSO language is in HRL, by constructing a HRG which derives all and only those graphs in the intersection of the two languages.",
      "startOffset" : 5,
      "endOffset" : 22
    }, {
      "referenceID" : 3,
      "context" : "To parse RGG, we will exploit the property that every nonterminal including the start symbol has rank at least one (Definition 5), and we assume This is a generalization to graphs of the proof that the intersection of a context-free and regular string language is a context-free string language (Bar-Hillel et al., 1961).",
      "startOffset" : 295,
      "endOffset" : 320
    }, {
      "referenceID" : 14,
      "context" : "The availability of an identifiable external node suggests a top-down algorithm, and we take inspiration from a top-down parsing algorithm the predictive top-down parsable grammars, another subclass of HRG (Drewes et al., 2015).",
      "startOffset" : 206,
      "endOffset" : 227
    }, {
      "referenceID" : 17,
      "context" : "(2013) generalizes CKY to HRG, our algorithm generalizes Earley’s algorithm (Earley, 1970).",
      "startOffset" : 76,
      "endOffset" : 90
    }, {
      "referenceID" : 10,
      "context" : "1 Top-down Parsing for RGLs Just as the algorithm of Chiang et al. (2013) generalizes CKY to HRG, our algorithm generalizes Earley’s algorithm (Earley, 1970).",
      "startOffset" : 53,
      "endOffset" : 74
    }, {
      "referenceID" : 10,
      "context" : "1 Top-down Parsing for RGLs Just as the algorithm of Chiang et al. (2013) generalizes CKY to HRG, our algorithm generalizes Earley’s algorithm (Earley, 1970). Both algorithms operate by recognizing incrementally larger subgraphs of the input graph, using a succinct representation for subgraphs that depends on an arbitrarily chosen marker node m of the input graph. Definition 6. (Chiang et al. 2013; Definition 6) Let I be a subgraph of G. A boundary node of I is a node which is either an endpoint of an edge in G\\I or an external node of G. A boundary edge of I is an edge in I which has a boundary node as an endpoint. The boundary representation of I is the tuple b(I) = 〈bn(I), be(I),m ∈ I〉 where 1. bn(I) is the set of boundary nodes of I 2. be(I) is the set of boundary edges of I 3. (m ∈ I) is a flag indicating whether the marker node is in I . Chiang et al. (2013) prove each subgraph has a unique boundary representation, and give algorithms that use only boundary representations to compute the union of two subgraphs, requiring time linear in the number of boundary nodes; and to check disjointness of subgraphs, requiring time linear in the number of boundary edges.",
      "startOffset" : 53,
      "endOffset" : 877
    }, {
      "referenceID" : 10,
      "context" : "1 Top-down Parsing for RGLs Just as the algorithm of Chiang et al. (2013) generalizes CKY to HRG, our algorithm generalizes Earley’s algorithm (Earley, 1970). Both algorithms operate by recognizing incrementally larger subgraphs of the input graph, using a succinct representation for subgraphs that depends on an arbitrarily chosen marker node m of the input graph. Definition 6. (Chiang et al. 2013; Definition 6) Let I be a subgraph of G. A boundary node of I is a node which is either an endpoint of an edge in G\\I or an external node of G. A boundary edge of I is an edge in I which has a boundary node as an endpoint. The boundary representation of I is the tuple b(I) = 〈bn(I), be(I),m ∈ I〉 where 1. bn(I) is the set of boundary nodes of I 2. be(I) is the set of boundary edges of I 3. (m ∈ I) is a flag indicating whether the marker node is in I . Chiang et al. (2013) prove each subgraph has a unique boundary representation, and give algorithms that use only boundary representations to compute the union of two subgraphs, requiring time linear in the number of boundary nodes; and to check disjointness of subgraphs, requiring time linear in the number of boundary edges. For each production p of the grammar, we impose a fixed order on the edges of R(p), as in Drewes et al. (2015). We discuss this order in detail in §4.",
      "startOffset" : 53,
      "endOffset" : 1294
    }, {
      "referenceID" : 28,
      "context" : "We present our parser as a deductive proof system (Shieber et al., 1995).",
      "startOffset" : 50,
      "endOffset" : 72
    }, {
      "referenceID" : 24,
      "context" : "We count instantiations of COMPLETE for an upper bound on complexity (McAllester, 2002), using similar logic to (Chiang et al.",
      "startOffset" : 69,
      "endOffset" : 87
    }, {
      "referenceID" : 10,
      "context" : "We count instantiations of COMPLETE for an upper bound on complexity (McAllester, 2002), using similar logic to (Chiang et al., 2013).",
      "startOffset" : 112,
      "endOffset" : 133
    }, {
      "referenceID" : 18,
      "context" : "The constraints of RGG also enable more efficient parsing than general HRG, and this tradeoff is reasonable since HRG is very expressive—when generating strings, it can express non-context-free languages (Engelfriet and Heyker, 1991; Bauer and Rambow, 2016), far more power than needed to express semantic graphs.",
      "startOffset" : 204,
      "endOffset" : 257
    }, {
      "referenceID" : 4,
      "context" : "The constraints of RGG also enable more efficient parsing than general HRG, and this tradeoff is reasonable since HRG is very expressive—when generating strings, it can express non-context-free languages (Engelfriet and Heyker, 1991; Bauer and Rambow, 2016), far more power than needed to express semantic graphs.",
      "startOffset" : 204,
      "endOffset" : 257
    }, {
      "referenceID" : 23,
      "context" : "Tree-like Grammars (TLG; Matheja et al. 2015) and Restricted DAG Grammars (RDG; Björklund et al.",
      "startOffset" : 19,
      "endOffset" : 45
    }, {
      "referenceID" : 5,
      "context" : "2015) and Restricted DAG Grammars (RDG; Björklund et al. 2016), both explicitly defined as restrictions on HRG.",
      "startOffset" : 34,
      "endOffset" : 62
    }, {
      "referenceID" : 4,
      "context" : "The constraints of RGG also enable more efficient parsing than general HRG, and this tradeoff is reasonable since HRG is very expressive—when generating strings, it can express non-context-free languages (Engelfriet and Heyker, 1991; Bauer and Rambow, 2016), far more power than needed to express semantic graphs. On the other hand, RGG is so constrained that it may not be expressive enough: it would be more natural to derive the graph in Figure 4 from outermost to innermost predicate; but constraint C2 makes it difficult to express this, and the grammar in Table 1 does not. Perhaps we need less expressivity than HRG but more than RGG. Since RGLs are a subfamily of both HRL and MSOL, they inherit probability and intersection closure, respectively. Courcelle (1991) discusses exactly those languages that are both HRL and MSOL, which he calls strongly contextfree languages (SCFL).",
      "startOffset" : 234,
      "endOffset" : 773
    }, {
      "referenceID" : 4,
      "context" : "The constraints of RGG also enable more efficient parsing than general HRG, and this tradeoff is reasonable since HRG is very expressive—when generating strings, it can express non-context-free languages (Engelfriet and Heyker, 1991; Bauer and Rambow, 2016), far more power than needed to express semantic graphs. On the other hand, RGG is so constrained that it may not be expressive enough: it would be more natural to derive the graph in Figure 4 from outermost to innermost predicate; but constraint C2 makes it difficult to express this, and the grammar in Table 1 does not. Perhaps we need less expressivity than HRG but more than RGG. Since RGLs are a subfamily of both HRL and MSOL, they inherit probability and intersection closure, respectively. Courcelle (1991) discusses exactly those languages that are both HRL and MSOL, which he calls strongly contextfree languages (SCFL).6 SCFLs are defined nonconstructively, but it is natural to ask whether other, less restrictive subfamilies of SCFLs can be constructed using similar mathematical tools. Courcelle (1991) identifies the family of seriesparallel graphs as one such family, but it seems of little relevance to NLP.",
      "startOffset" : 234,
      "endOffset" : 1075
    } ],
    "year" : 2017,
    "abstractText" : "Distributions over strings and trees can be represented by probabilistic regular languages, which characterize many models in natural language processing. Recently, several datasets have become available which represent natural language phenomena as graphs, so it is natural to ask whether there is an equivalent of probabilistic regular languages for graphs. To answer this question, we review three families of graph languages: Hyperedge Replacement Languages (HRL), which can be made probabilistic; Monadic Second Order Languages (MSOL), which support the crucial property of closure under intersection; and Regular Graph Languages (RGL; Courcelle 1991), a subfamily of both HRL and MSOL which inherits these properties, and has not been widely studied or applied to NLP. We prove that RGLs are closed under intersection and provide an efficient parsing algorithm, with runtime linear in the size of the input graph.",
    "creator" : "LaTeX with hyperref package"
  }
}