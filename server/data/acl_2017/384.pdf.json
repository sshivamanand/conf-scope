{
  "name" : "384.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Identifying 1950s American Jazz Composers: Fine-Grained IsA Extraction via Modifier Composition",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "1 000\n012\n013\n014\n015\n016\n017\n018\n019\n020\n021\n022\n023\n024\n025\n026\n027\n028\n029\n030\n031\n032\n033\n034\n035\n036\n037\n038\n039\n040\n041\n042\n043\n044\n045\n046\n047\n048\n049\n069\n070\n071\n072\n073\n074\n075\n076\n077\n078\n079\n080\n081\n082\n083\n084\n085\n086\n087\n088\n089\n090\n091\n092\n093\n094\n095\n096\n097\n098\n099"
    }, {
      "heading" : "1 Introduction",
      "text" : "Substantial attention has been paid to automatically acquiring taxonomic knowledge, like that “Charles Mingus” is a “composer”, from text (Snow et al., 2006; Shwartz et al., 2016). The majority of approaches for extracting such “IsA” relations rely on lexical patterns as the primary signal of whether an instance belongs to a class: for example, observing a pattern like “X such as Y” is a strong indication that Y is an instance of class X (Hearst, 1992).\nMethods based on these “Hearst patterns” assume that class labels can be treated as atomic lexicalized units. This assumption has several significant weakness. First, in order to recognize an instance of a class, these patternbased methods require that the entire class label be observed verbatim in text. The requirement is reasonable for class labels containing a single word, but in practice, there are many possible fine-grained classes: not only “composers” but also “1950s American jazz composers”. The probability that a given label will appear in its entirety within one of the\nexpected patterns is very low, even in large amounts of text. Second, when class labels are treated as though they cannot be decomposed, every class label must be modeled independently, even those containing overlapping words (“American jazz composer”, “French jazz composer”). As a result, the number of meaning representations to be learned is exponential in the length of the class label, and quickly becomes intractable. Thus, compositional models of taxonomic relations are necessary for better language understanding.\nWe introduce a compositional approach for reasoning about fine-grained class labels. Our approach is based on the notion from formal semantics in which modifiers (“1950s”) correspond to properties which differentiate instances of a subclass (“1950s composers”) from instances of the superclass (“composers”) (Heim and Kratzer, 1998). Our method consists of two stages: interpreting each modifier relative to the head (“composers active during 1950s”), and using the interpretations to identify instances of the class from text (Figure 1). Our main contributions are: 1) a compositional method for IsA extraction, which in-\n2\n101\n102\n103\n104\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n123\n124\n125\n126\n127\n128\n129\n130\n131\n132\n133\n134\n135\n136\n137\n138\n139\n140\n141\n142\n143\n144\n145\n146\n147\n148\n149\n150\n151\n152\n153\n154\n155\n156\n157\n158\n159\n160\n161\n162\n163\n164\n165\n166\n167\n168\n169\n170\n171\n172\n173\n174\n175\n176\n177\n178\n179\n180\n181\n182\n183\n184\n185\n186\n187\n188\n189\n190\n191\n192\n193\n194\n195\n196\n197\n198\n199\nvolves a novel application of noun-phrase paraphrasing methods to the task of semantic taxonomy induction and 2) the operationalization of a formal semantics framework to address two aspects of semantics that are often kept separate in NLP: assigning intrinsic “meaning” to a phrase, and reasoning about that phrase in a truth-theoretic context."
    }, {
      "heading" : "2 Related Work",
      "text" : "Noun Phrase Interpretation. Compound noun phrases (“jazz composer”) communicate implicit semantic relations between modifiers and the head. Many efforts to provide semantic interpretations of such phrases rely on matching the compound to pre-defined patterns or semantic ontologies (Fares et al., 2015; Séaghdha and Copestake, 2007; Tratz and Hovy, 2010; Surtani and Paul, 2015; Choi et al., 2015). Recently, interpretations may take the form of arbitrary natural language predicates (Hendrickx et al., 2013). Most approaches are supervised, comparing unseen noun compounds to the most similar phrase seen in training (Wijaya and Gianfortoni, 2011; Nulty and Costello, 2013; Van de Cruys et al., 2013). Other unsupervised approaches apply information extraction techniques to paraphrase noun compounds (Kim and Nakov, 2011; Xavier and de Lima, 2014; Pasca, 2015). They focus exclusively on providing good paraphrases for an input noun compound. To our knowledge, ours is the first attempt to use these interpretations for the downstream task of IsA relation extraction.\nSemantic Taxonomy Induction. Most efforts to learn taxonomic relations from text build on the seminal work of Hearst (1992), which observes that certain textual patterns– e.g., “X and other Y”–are high-precision indicators of whether X is a member of class Y. Recent work focuses on learning such patterns automatically from corpora (Snow et al., 2006; Shwartz et al., 2016). These IsA extraction techniques provide a key step for the more general task of knowledge base population. The “universal schema” approach (Riedel et al., 2013; Kirschnick et al., 2016; Verga et al., 2016), which infers relations using matrix factorization, often includes Hearst patterns as input features. Graphical (Bansal et al., 2014)\nand joint inference models (Movshovitz-Attias and Cohen, 2015) typically require Hearst patterns to define an inventory of possible classes. A separate line of work avoids Hearst patterns by instead exploiting semi-structured data from HTML markup (Wang and Cohen, 2009; Dalvi et al., 2012; Pasupat and Liang, 2014). These approaches all share the limitation that, in practice, in order for a class to be populated with instances, the entire class label has to have been observed verbatim in text. This requirement limits the ability to handle arbitrarily fine-grained classes. Our work addresses this limitation by modeling fine-grained class labels compositionally. Thus the proposed method can combine evidence from multiple sentences, and can perform IsA extraction without requiring any example instances of a given class.1"
    }, {
      "heading" : "3 Modifiers as Functions",
      "text" : "Formalization. In formal semantics, modification is modeled as function application. Specifically, let MH be a class label consisting of a head H, which we assume to be a common noun, preceded by a modifier M . We use J·K to represent the “interpretation function” which maps a linguistic expression to its denotation in the world. The interpretation of a common noun is the set of entities2 in the universe U which are denoted by the noun (Heim and Kratzer, 1998):\nJHK = {e ∈ U | e is a H} (1)\nThe interpretation of a modifier M is a function that maps between sets of entities. That is, modifiers select a subset3 of the input set:\nJMK(H) = {e ∈ H | e satisfies M} (2)\nThis formalization leaves open how one decides whether or not “e satisfiesM”. This nontrivial, as the meaning of a modifier can vary depending on the class it is modifying: if e is a “good student”, e is not necessarily a “good\n1Pasupat and Liang (2014) also focuses on zero-shot IsA extraction, but exploits HTML document structure, rather than reasoning compositionally.\n2We use “entities” and “instances” interchangeably;“entities” is standard terminology in linguistics.\n3As does virtually all previous work in information extraction, we assume that modifiers are subsective, acknowledging the limitations (Kamp and Partee, 1995).\n3\n201\n202\n203\n204\n205\n206\n207\n208\n209\n210\n211\n212\n213\n214\n215\n216\n217\n218\n219\n220\n221\n222\n223\n224\n225\n226\n227\n228\n229\n230\n231\n232\n233\n234\n235\n236\n237\n238\n239\n240\n241\n242\n243\n244\n245\n246\n247\n248\n249\n250\n251\n252\n253\n254\n255\n256\n257\n258\n259\n260\n261\n262\n263\n264\n265\n266\n267\n268\n269\n270\n271\n272\n273\n274\n275\n276\n277\n278\n279\n280\n281\n282\n283\n284\n285\n286\n287\n288\n289\n290\n291\n292\n293\n294\n295\n296\n297\n298\n299\nperson”, making it difficult to model whether “e satisfies good” in general. We therefore reframe the above equation, so that the decision of whether “e satisfies M” is made by calling a binary function φM , parameterized by the class H within which e is being considered:\nJMK(H) = {e ∈ H | φM (H, e)} (3)\nConceptually, φM captures the core “meaning” of the modifier M , which is the set of properties that differentiate members of the output class MH from members of the more general input class H. This formal semantics framework has two important consequences. First, the modifier has an intrinsic “meaning”. The properties entailed by the modifier are independent of the particular state of the world. This makes it possible to make inferences about “1950s composers” even if no 1950s composers have been observed. Second, the modifier is a function that can be applied in a truth-theoretic setting. That is, applying “1950s” to the set of “composers” returns exactly the set of “1950s composers”.\nComputational Approaches. While the notion of modifiers as functions has been incorporated into computational models previously, prior work focuses on either assigning an intrinsic meaning to M or on operationalizing M in a truth-theoretic sense, but not on doing both simultaneously. For example, Young et al. (2014) focuses exclusively on the subset selection aspect of modification. That is, given a set of instances H and a modifier M , their method could return the subset MH. However, their method does not model the meaning of the modifier itself, so that, e.g., if there were no red cars in their model of the world, the phrase “red cars” would have no meaning. In contrast, Baroni and Zamparelli (2010) models the meaning of modifiers explicitly as functions which map between vector-space representations of nouns. However, their model focuses on similarity between class labels–e.g., to say that “important routes” is similar to “major roads”–and it is not obvious how the method could be operationalized in order to identify instances of those classes. A contribution of our work is to model the semantics of M intrinsically, but in a way that permits application in the\nmodel theoretic setting. We learn an explicit model of the “meaning” of a modifier M relative to a head H, represented as a distribution over properties which differentiate the members of the class MH from those of the class H. We then use this representation to identify the subset of instances of H which constitute the subclass MH."
    }, {
      "heading" : "4 Learning Modifier Interpretations",
      "text" : ""
    }, {
      "heading" : "4.1 Setup",
      "text" : "For each modifier M , we would like to learn the function φM from Eq. 3. Doing so makes it possible, given H and an instance e ∈ H, to decide whether e has the properties required to be an instance of MH. In general, there is no systematic way to determine the implied relation between M and H, as modifiers can arguably express any semantic relation, given the right context (Weiskopf, 2007). We therefore model the semantic relation between M and H as a distribution over properties which could potentially define the subclass MH ⊆ H. We will refer to this distribution as a “property profile” for M relative to H. We make the assumption that relations between M and H that are discussed more often are more likely to capture the important properties of the subclass MH. This assumption is not perfect (Section 4.4) but has given good results for paraphrasing noun phrases (Nakov and Hearst, 2013; Pasca, 2015). Our method for learning property profiles is based on the unsupervised method proposed by Pasca (2015), which uses query logs as a source of common sense knowledge, and rewrites noun compounds by matching MH (“American composers”) to queries of the form “H(.∗)M” (“composers from America”)."
    }, {
      "heading" : "4.2 Inputs",
      "text" : "We assume two inputs: 1) an IsA repository, O, containing 〈e, C〉 tuples where C is a category and e is an instance of C, and 2) a fact repository, D, containing 〈s, p, o, w〉 tuples where s and o are noun phrases, p is a predicate, and w is a confidence that p expresses a true relation between s and o. Both O and D are extracted from a sample of around 1 billion Web documents in English. The supplementary material gives additional details.\n4\n301\n302\n303\n304\n305\n306\n307\n308\n309\n310\n311\n312\n313\n314\n315\n316\n317\n318\n319\n320\n321\n322\n323\n324\n325\n326\n327\n328\n329\n330\n331\n332\n333\n334\n335\n336\n337\n338\n339\n340\n341\n342\n343\n344\n345\n346\n347\n348\n349\n350\n351\n352\n353\n354\n355\n356\n357\n358\n359\n360\n361\n362\n363\n364\n365\n366\n367\n368\n369\n370\n371\n372\n373\n374\n375\n376\n377\n378\n379\n380\n381\n382\n383\n384\n385\n386\n387\n388\n389\n390\n391\n392\n393\n394\n395\n396\n397\n398\n399\nGood property profiles Bad property profiles rice dish French violinist Led Zeppelin song still life painter child actor risk manager * serve with rice * live in France Led Zeppelin write * * known for still life * have child * take risk * include rice * born in France Led Zeppelin play * * paint still life * expect child * be at risk * consist of rice * speak French Led Zeppelin have * still life be by * * play child * be aware of risk\nTable 1: Example property profiles learned by observing predicates that relate instances of class H to modifier M (I2). Results are similar when using the class label H directly (I1). We spell out inverted predicates (Section 4.2) so wildcards (*) may appear as subjects or objects.\nWe instantiate O with an IsA repository constructed by applying Hearst patterns to the Web documents. Instances are represented as automatically-disambiguated entity mentions4 which, when possible, are resolved to Wikipedia pages. Classes are represented as (non-disambiguated) natural language strings. We instantiate D with a large repository of facts extracted using in-house implementations of ReVerb (Fader et al., 2011) and OLLIE (Mausam et al., 2012). The predicates are extracted as natural language strings. Subjects and objects may be either disambiguated entity references or natural language strings. Every tuple is included in both the forward and the reverse direction. E.g. 〈jazz, perform at, venue〉 also appears as 〈venue,←perform at, jazz〉, where ← is a special character signifying inverted predicates. These inverted predicates simplify the following definitions. In total, O contains 1.1M tuples and D contains 30M tuples."
    }, {
      "heading" : "4.3 Building Property Profiles",
      "text" : "Properties. Let I be a function which takes as input a noun phrase MH and returns a property profile for M relative to H. We define a “property” to be an SPO tuple in which the subject position5 is a wildcard, e.g. 〈∗, born in,America〉. Any instance which fills the wildcard slot then “has” the property. We expand adjectival modifiers to encompass nominalized forms using a nominalization dictionary extracted from WordNet (Miller, 1995). If MH is “American composer” and we require a tuple to have the form 〈H, p,M,w〉, we will include tuples in which the third element is either “American” or “America”.\n4“Entity mentions” may be individuals, like “Barack Obama”, but may also be concepts like “jazz”.\n5Inverse predicates capture properties in which the wildcard is conceptually the object of the relation, but occupies the subject slot in the tuple. For example, 〈venue,←perform at, jazz〉 captures that a “jazz venue” is a “venue” e such that “jazz performed at e”.\nRelating M to H Directly. We first build property profiles by taking the predicate and object from any tuple in D in which the subject is the head and the object is the modifier:\nI1(MH) = {〈〈p,M〉, w〉 | 〈H, p,M,w〉 ∈ D} (4)\nRelating M to an Instance of H. We also consider an extension in which, rather than requiring the subject to be the class label H, we require the subject to be an instance of H.\nI2(MH) = {〈〈p,M〉, w〉 | 〈e,H〉 ∈ O ∧〈e, p,M,w〉 ∈ D}\n(5)\nModifier Expansion. In practice, when building property profiles, we do not require that the object of the fact tuple match the modifier exactly, as suggested in Eq. 4 and 5. Instead, we follow Pasca (2015) and take advantage of facts involving distributionally similar modifiers. Specifically, rather than looking only at tuples in D in which the object matches M , we consider all tuples, but discount the weight proportionally to the similarity between M and the object of the tuple. Thus, I1 is computed as below:\nI1(MH) = {〈〈p,M〉, w × sim(M,N)〉 | 〈H, p,N,w〉 ∈ D} (6)\nwhere sim(M,N) is the cosine similarity between M and N . I2 is computed analogously. We compute sim using a vector space built from Web documents following Lin and Wu (2009); Pantel et al. (2009). We retain the 100 most similar phrases for each of∼10M phrases, and consider all other similarities to be 0."
    }, {
      "heading" : "4.4 Analysis of Property Profiles",
      "text" : "Table 1 provides examples of good and bad property profiles for several MHs. In general, frequent relations between M and H capture relevant properties of MH, but it is not always\n5\n401\n402\n403\n404\n405\n406\n407\n408\n409\n410\n411\n412\n413\n414\n415\n416\n417\n418\n419\n420\n421\n422\n423\n424\n425\n426\n427\n428\n429\n430\n431\n432\n433\n434\n435\n436\n437\n438\n439\n440\n441\n442\n443\n444\n445\n446\n447\n448\n449\n450\n451\n452\n453\n454\n455\n456\n457\n458\n459\n460\n461\n462\n463\n464\n465\n466\n467\n468\n469\n470\n471\n472\n473\n474\n475\n476\n477\n478\n479\n480\n481\n482\n483\n484\n485\n486\n487\n488\n489\n490\n491\n492\n493\n494\n495\n496\n497\n498\n499\nClass label Property profile American company * based in America American composer * born in America American novel * written in America jazz album * features jazz jazz composer * writes jazz jazz venue jazz performed at *\nTable 2: Head-specific property profiles learned by relating instances of H to the modifier M (I2). Results are similar using I1.\nthe case. To illustrate, the most frequently discussed relation between “child” and “actor” is that actors have children, but this property is not indicative of the meaning of “child actor”. Qualitatively, the top-ranked interpretations learned by using the head noun directly (I1, Eq. 4) are very similar to those learned using instances of the head (I2, Eq. 5). However, I2 returns many more properties (10 on average per MH) than I1 (just over 1 on average). Anecdotally, we see that I2 captures more specific relations than does I1. For example, for “jazz composers”, both methods return “* write jazz” and “* compose jazz”, but I2 additionally returns properties like “* be major creative influence in jazz”. We compare I1 and I2 quantitatively in Section 6. Importantly, we do see that both I1 and I2 are capable of learning head-specific property profiles for a modifier. Table 2 provides examples."
    }, {
      "heading" : "5 Class-Instance Identification",
      "text" : "Instance finding. After finding properties that relate a modifier to a head, we turn to the task of identifying instances of fine-grained classes. That is, for a given modifier M , we want to instantiate the function φM from Eq. 3. In practice, rather than being a binary function which decides whether or not e is in class MH, our instantiation, φ̂M , will return a realvalued score expressing the confidence that e is a member of MH. For notational convenience, let D(〈s, p, o〉) = w, if 〈s, p, o, w〉 ∈ D and 0 otherwise. We define φ̂M as follows:\nφ̂M (H, e) = ∑\n〈〈p,o〉,w〉∈I(MH)\nw ×D(〈e, p, o〉)\n(7) Applying M to H, then, is as in Eq. 3 except that instead of a discrete set, it returns a scored list of candidate instances:\nJMK(H) = {〈e, φ̂M (H, e)〉 | 〈e,H〉 ∈ O} (8)\nUltimately, we need to identify instances of arbitrary class labels, which may contain multiple modifiers. Given a class label C = M1 . . .MkH which contains a head H preceded by modifiers M1 . . .Mk, we generate a list of candidate instances by finding all instances of H which have some property to support every modifier:\nk⋂ i=1 {〈e, s(e)〉 | 〈e, w〉 ∈ JMiK(H) ∧w > 0} (9)\nwhere s(e) is the mean6 of the scores assigned by each separate φ̂Mi . From here on, we use Mods to refer to our method which generates lists of instances for a class using Eq. 8 and 9. When φ̂M (Eq. 7) is implemented using I1, we use the name ModsH (for “heads”). When it is implemented using I2, we use the name ModsI (for “instances”).\nWeakly Supervised Reranking. Eq. 8 uses a naive ranking in which the weight for e ∈MH is the product of how often e has been observed with some property and the weight of that property for the class MH. Thus, instances of H with overall higher counts in D receive high weights for every MH. We therefore train a simple logistic regression model to predict the likelihood that e belongs to MH. We use a small set of features7, including the raw weight as computed in Eq. 7. For training, we sample 〈e, C〉 pairs from our IsA repository O as positive examples and random pairs that were not extracted by any Hearst pattern as negative examples. We frame the task as a binary prediction of whether e ∈ C, and use the model’s confidence as the value of φ̂M in place of the function in Eq. 7."
    }, {
      "heading" : "6 Evaluation",
      "text" : ""
    }, {
      "heading" : "6.1 Experimental Setup",
      "text" : "Evaluation Sets. We evaluate our models on their ability to return correct instances for arbitrary class labels. As a source of evaluation data, we use Wikipedia category pages8. These are pages in which the title is the name of the category (e.g., “pakistani film actresses”) and the body is a manually\n6Also tried minimum, but mean gave better results. 7Feature templates in supplementary material. 8http://en.wikipedia.org/wiki/Help:Category\n6\n501\n502\n503\n504\n505\n506\n507\n508\n509\n510\n511\n512\n513\n514\n515\n516\n517\n518\n519\n520\n521\n522\n523\n524\n525\n526\n527\n528\n529\n530\n531\n532\n533\n534\n535\n536\n537\n538\n539\n540\n541\n542\n543\n544\n545\n546\n547\n548\n549\n550\n551\n552\n553\n554\n555\n556\n557\n558\n559\n560\n561\n562\n563\n564\n565\n566\n567\n568\n569\n570\n571\n572\n573\n574\n575\n576\n577\n578\n579\n580\n581\n582\n583\n584\n585\n586\n587\n588\n589\n590\n591\n592\n593\n594\n595\n596\n597\n598\n599\n2008 california wildfires · australian army chaplains · australian boy bands · canadian business journalists · canadian military nurses · canberra urban places · cellular automaton rules · chinese rice dishes · coldplay concert tours · daniel libeskind designs · economic stimulus programs · german film critics · invasive amphibian species · log flume rides · malayalam short stories · pakistani film actresses · puerto rican sculptors · string theory books · tampa bay devil rays scouts\nTable 3: Examples of labels from UniformSet.\ncurated list of links to other pages which fall under the category. We measure the precision and recall of each method for discovering the instances listed on these pages given the page title (henceforth “class label”).\nWe collect the titles of all Wikipedia category pages, removing those in which the last word is capitalized or which contain fewer than three words. These heuristics are intended to retain compositional titles in which the head is a single common noun. We also remove any titles which contain links to sub-categories. This is to favor fine-grained classes (“pakistani film actresses”) over coarse-grained ones (“film actresses”). We perform heuristic modifier chunking in order to group together multiword modifiers (e.g., “puerto rican”); for details, see supplementary material. From the resulting list of class labels, we draw two samples of 100 labels each, enforcing that no H appear as the head of more than three class labels per sample. The first sample is chosen uniformly at random (denoted UniformSet). The second (WeightedSet) is weighted so that the probability of drawing M1 . . .MkH is proportional to the total number of class labels in whichH appears as the head. Available at http://anonymized, these different evaluation sets are intended to evaluate performance on the head versus the tail of class label distribution, since information retrieval methods often perform differently on different parts of the distribution. On average, there are 17 instances per category in UniformSet and 19 in WeightedSet. Table 3 gives example class labels from UniformSet.\nBaselines. We implement two baselines using our IsA repository (O as defined in Section 4.1). Our simplest baseline ignores modifiers altogether, and simply assumes that any instance of H is an instance of MH, regardless of M . In this case the confidence value for 〈e,MH〉 is equivalent to that for 〈e,H〉. We\nrefer to this baseline simply as Baseline. Our second, stronger baseline uses the IsA repository directly to identify instances of the finegrained class C = M1 . . .MkH. That is, we consider e to be an instance of the class if 〈e, C〉 ∈ O, meaning the entire class label appeared in a source sentence matching some Hearst pattern. We refer to this baseline as Hearst. The weight used to rank the candidate instances is the confidence value assigned by the Hearst pattern extraction (Section 4.2).\nCompositional Models. As a baseline compositional model, we augment the Hearst baseline via set intersection. Specifically, for a class C = M1 . . .MkH, if each of the MiH appears in O independently, we take the instances of C to be the intersection of the instances of each of the MiH. We assign the weight of an instance e to be the sum of the weights associated with each independent modifier. We refer to this method as Hearst∩. We contrast this with our proposed model which recognizes instances of a fine-grained class by 1) assigning a meaning to each modifier in the form of a property profile and 2) checking whether a candidate instance exhibits these properties. We refer to the versions of our method as ModsH and ModsI , as described in Section 5. When relevant, we use “raw” to refer to the version in which instances are ranked using raw weights and “RR” to refer to the version in which instances are ranked using logistic regression (Section 5). We also try using the proposed methods to extend rather than replace the Hearst baseline. We combine predictions by merging the ranked lists produced by each system: i.e. the score of an instance is the inverse of the sum of its ranks in each of the input lists. If an instance does not appear at all in an input list, its rank in that list is set to a large constant value. We refer to these combination systems as Hearst+ModsH and Hearst+ModsI ."
    }, {
      "heading" : "6.2 Results",
      "text" : "Precision and Coverage. We first compare the methods in terms of their coverage, the number of class labels for which the method is able to find some instance, and their precision, to what extent the method is able to correctly rank true instances of the class above\n7\n601\n602\n603\n604\n605\n606\n607\n608\n609\n610\n611\n612\n613\n614\n615\n616\n617\n618\n619\n620\n621\n622\n623\n624\n625\n626\n627\n628\n629\n630\n631\n632\n633\n634\n635\n636\n637\n638\n639\n640\n641\n642\n643\n644\n645\n646\n647\n648\n649\n650\n651\n652\n653\n654\n655\n656\n657\n658\n659\n660\n661\n662\n663\n664\n665\n666\n678\n679\n680\n681\n682\n683\n684\n685\n686\n687\n688\n689\n690\n691\n692\n693\n694\n695\n696\n697\n698\n699\nFlemish still life painters: Clara Peeters · Willem Kalf · Jan Davidsz de Heem · Pieter Claesz · Peter Paul Rubens · Frans Snyders · Jan Brueghel the Elder · Hans Memling · Pieter Bruegel the Elder · Caravaggio · Abraham Brueghel Pakistani cricket captains: Salman Butt · Shahid Afridi · Javed Miandad · Azhar Ali · Greg Chappell · Younis Khan · Wasim Akram · Imran Khan · Mohammad Hafeez · Rameez Raja · Abdul Hafeez Kardar · Waqar Younis · Sarfraz Ahmed Thai buddhist temples: Wat Buddhapadipa · Wat Chayamangkalaram · Wat Mongkolratanaram · Angkor Wat · Preah Vihear Temple ·Wat Phra Kaew ·Wat Rong Khun ·Wat Mahathat Yuwaratrangsarit · Vat Phou · Tiger Temple · Sanctuary of Truth · Wat Chalong · Swayambhunath · Mahabodhi Temple · Tiger Cave Temple · Harmandir Sahib\nTable 4: Instances extracted for several fine-grained classes from Wikipedia. Lists shown are from ModsI . Instances in italics were also returned by Hearst∩. Strikethrough denotes incorrect.\nnon-instances. We report total coverage, the number of labels for which the method returns any instance, and correct coverage, the number of labels for which the method returns a correct instance. For precision, we compute the average precision (AP) for each class label. AP ranges from 0 to 1, where 1 indicates that all positive instances were ranked above all negative instances. We report mean average precision (MAP), which is the mean of the APs across all the class labels. MAP is only computed over class labels for which the method returns something, meaning methods are not punished for returning empty lists.\nUniformSet WeightedSet Coverage MAP Coverage MAP\nBaseline 95 / 70 0.01 98 / 74 0.01 Hearst 9 / 9 0.63 8 / 8 0.80 Hearst∩ 13 / 12 0.62 9 / 9 0.80 ModsH raw 56 / 32 0.23 50 / 30 0.16 ModsH RR 56 / 32 0.29 50 / 30 0.25 ModsI raw 62 / 36 0.18 59 / 38 0.20 ModsI RR 62 / 36 0.24 59 / 38 0.23\nTable 5: Coverage and precision for populating Wikipedia category pages with instances. “Coverage” is the number of class labels (out of 100) for which at least one instance was returned, followed by the number for which at least one correct instance was returned. “MAP” is mean average precision. MAP does not punish methods for returning empty lists, thus favoring the baseline (see Figure 2).\nTable 4 gives examples of instances returned for several class labels and Table 5 shows the precision and coverage for each of the methods. Figure 2 illustrates how the single mean AP score (as reported in Table 5) can misrepresent the relative precision of different methods. In combination, Table 5 and Figure 2 demonstrate that the proposed methods extract instances about as well as the baseline, whenever the baseline can extract anything at all; i.e. the proposed method does not cause a precision drop on classes covered by the base-\nline. In addition, there are many classes for which the baseline is not able to extract any instances, but the proposed method is.\nTable 5 also reveals that the reranking model (RR) consistently increases MAP for the proposed methods. Therefore, going forward, we only report results using the reranking model (i.e. ModsH and ModsI will refer to ModsH RR and ModsI RR, respectively).\nManual Re-Annotation. It possible that true instances of a class are missing from our Wikipedia reference set, and thus that our precision scores underestimate the actual precision of the systems. We therefore manually verify the top 10 predictions of each of the systems for a random sample of 25 class labels. We choose class labels for which Hearst was able to return at least one instance, in order to ensure reliable precision estimates. For each of these labels, we manually check the top 10 instances proposed by each method to determine whether each belongs to the class. Table 6 shows the precision scores for each method computed against the\n8\n701\n702\n703\n704\n705\n706\n707\n708\n709\n710\n711\n712\n713\n714\n715\n716\n717\n718\n719\n720\n721\n722\n723\n724\n725\n726\n727\n728\n729\n730\n731\n732\n733\n734\n735\n736\n737\n738\n739\n740\n741\n742\n743\n744\n745\n746\n747\n748\n749\n750\n751\n752\n753\n754\n755\n756\n757\n758\n759\n760\n761\n762\n763\n764\n765\n766\n767\n768\n769\n770\n771\n772\n773\n774\n775\n776\n777\n778\n779\n780\n781\n782\n783\n784\n785\n786\n787\n788\n789\n790\n791\n792\n793\n794\n795\n796\n797\n798\n799\n(a) Uniform random sample (UniformSet). (b) Weighted random sample (WeightedSet).\nFigure 3: ROC curves for selected methods (Hearst in blue, proposed in red). Given a ranked list of instances, ROC curves plot true positives vs. false positives retained by setting various cutoffs. The curve becomes linear once all remaining instances have the same score (e.g., 0), as this makes it impossible to add true positives without also including all remaining false positives.\noriginal Wikipedia list of instances and against our manually-augmented list of gold instances. The overall ordering of the systems does not change, but the precision scores increase notably after re-annotation. We continue to evaluate against the Wikipedia lists, but acknowledge that reported precision is likely an underestimate of true precision.\nWikipedia Gold Hearst 0.56 0.79 Hearst∩ 0.53 0.78 ModsH 0.23 0.39 ModsI 0.24 0.42 Hearst+ModsH 0.43 0.63 Hearst+ModsI 0.43 0.63\nTable 6: P@10 before/after re-annotation; Wikipedia underestimates true precision.\nPrecision-Recall Analysis. We next look at the precision-recall tradeoff in terms of the area under the curve (AUC) achieved when each method attempts to rank the complete list of candidate instances. We take the union of all of the instances proposed by all of the methods (including the Baseline method which, given a class label M0 . . .MkH, proposes every instance of the head H as a candidate). Then, for each method, we rank this full set of candidates such that any instance returned by the method is given the score the method assigns, and every other instance is scored as 0. Table 7 reports the AUC and recall and Figure 3 plots the full ROC curves. The requirement by Hearst that class labels appear in full in a single sentence results in very low recall, which translates into very low AUC when considering the full set of candi-\ndate instances. By comparison, the proposed compositional methods make use of a larger set of sentences, and provide non-zero scores for many more candidates, resulting in a >10 point increase in AUC on both UniformSet and WeightedSet (Table 7).\nUniformSet WeightedSet AUC Recall AUC Recall\nBaseline 0.55 0.23 0.53 0.28 Hearst 0.56 0.03 0.52 0.02 Hearst∩ 0.57 0.04 0.53 0.02 ModsH 0.68 0.08 0.60 0.06 ModsI 0.71 0.09 0.65 0.09 Hearst∩+ModsH 0.70 0.09 0.61 0.08 Hearst∩+ModsI 0.73 0.10 0.66 0.10\nTable 7: Recall of instances on Wikipedia category pages, measured against the full set of instances from all pages in sample. AUC captures tradeoff between true and false positives."
    }, {
      "heading" : "7 Conclusion",
      "text" : "We have presented an approach to IsA extraction which takes advantage of the compositionality of natural language. Existing approaches often treat class labels as atomic units which must be observed in full in order to be populated with instances. As a result, current methods are not able to handle the infinite number of classes describable in natural language, most of which never appear in text. Our method reasons about each modifier in the label individually, in terms of the properties that it implies about the instances. This approach allows us to harness information that is spread across multiple sentences, significantly increasing in the number of finegrained classes which we are able to populate.\n9\n801\n802\n803\n804\n805\n806\n807\n808\n809\n810\n811\n812\n813\n814\n815\n816\n817\n818\n819\n820\n821\n822\n823\n824\n825\n826\n827\n828\n829\n830\n831\n832\n833\n834\n835\n836\n837\n838\n839\n840\n841\n842\n843\n844\n845\n846\n847\n848\n849\n850\n851\n852\n853\n854\n855\n856\n857\n858\n859\n860\n861\n862\n863\n864\n865\n866\n867\n868\n869\n870\n871\n872\n873\n874\n875\n876\n877\n878\n879\n880\n881\n882\n883\n884\n885\n886\n887\n888\n889\n890\n891\n892\n893\n894\n895\n896\n897\n898\n899"
    } ],
    "references" : [ {
      "title" : "Structured learning for taxonomy induction with belief propagation",
      "author" : [ "M. Bansal", "D. Burkett", "G. de Melo", "D. Klein." ],
      "venue" : "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Pa-",
      "citeRegEx" : "Bansal et al\\.,? 2014",
      "shortCiteRegEx" : "Bansal et al\\.",
      "year" : 2014
    }, {
      "title" : "Nouns are vectors, adjectives are matrices: Representing adjective-noun constructions in semantic space",
      "author" : [ "M. Baroni", "R. Zamparelli." ],
      "venue" : "Proceedings of the 2010 Conference on Empirical Methods in Natural Language Process-",
      "citeRegEx" : "Baroni and Zamparelli.,? 2010",
      "shortCiteRegEx" : "Baroni and Zamparelli.",
      "year" : 2010
    }, {
      "title" : "Scalable semantic parsing with partial ontologies",
      "author" : [ "E. Choi", "T. Kwiatkowski", "L. Zettlemoyer." ],
      "venue" : "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics (ACL-15). Beijing, China,",
      "citeRegEx" : "Choi et al\\.,? 2015",
      "shortCiteRegEx" : "Choi et al\\.",
      "year" : 2015
    }, {
      "title" : "Websets: Extracting sets of entities from the Web using unsupervised information extraction",
      "author" : [ "B. Dalvi", "W. Cohen", "J. Callan." ],
      "venue" : "Proceedings of the 5th ACM Conference on Web Search and Data Mining (WSDM-12). Seattle,",
      "citeRegEx" : "Dalvi et al\\.,? 2012",
      "shortCiteRegEx" : "Dalvi et al\\.",
      "year" : 2012
    }, {
      "title" : "Identifying relations for open information extraction",
      "author" : [ "A. Fader", "S. Soderland", "O. Etzioni." ],
      "venue" : "Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP-11). Edinburgh, Scotland, pages",
      "citeRegEx" : "Fader et al\\.,? 2011",
      "shortCiteRegEx" : "Fader et al\\.",
      "year" : 2011
    }, {
      "title" : "Identifying compounds: On the role of syntax",
      "author" : [ "M. Fares", "S. Oepen", "E. Velldal." ],
      "venue" : "International Workshop on Treebanks and Linguistic Theories (TLT14). page 273.",
      "citeRegEx" : "Fares et al\\.,? 2015",
      "shortCiteRegEx" : "Fares et al\\.",
      "year" : 2015
    }, {
      "title" : "Automatic acquisition of hyponyms from large text corpora",
      "author" : [ "M. Hearst." ],
      "venue" : "Proceedings of the 14th Conference on Computational Linguistics - Volume 2 . COLING ’92, pages 539– 545.",
      "citeRegEx" : "Hearst.,? 1992",
      "shortCiteRegEx" : "Hearst.",
      "year" : 1992
    }, {
      "title" : "Semantics in generative grammar , volume 13",
      "author" : [ "I. Heim", "A. Kratzer." ],
      "venue" : "Blackwell Oxford.",
      "citeRegEx" : "Heim and Kratzer.,? 1998",
      "shortCiteRegEx" : "Heim and Kratzer.",
      "year" : 1998
    }, {
      "title" : "SemEval-2013 task 4: Free paraphrases of noun compounds",
      "author" : [ "I. Hendrickx", "Z. Kozareva", "P. Nakov", "D. Ó Séaghdha", "S. Szpakowicz", "T. Veale." ],
      "venue" : "Proceedings of SemEval-13 . pages 138–143.",
      "citeRegEx" : "Hendrickx et al\\.,? 2013",
      "shortCiteRegEx" : "Hendrickx et al\\.",
      "year" : 2013
    }, {
      "title" : "Prototype theory and compositionality",
      "author" : [ "H. Kamp", "B. Partee." ],
      "venue" : "Cognition 57(2):129–191.",
      "citeRegEx" : "Kamp and Partee.,? 1995",
      "shortCiteRegEx" : "Kamp and Partee.",
      "year" : 1995
    }, {
      "title" : "Large-scale noun compound interpretation using bootstrapping and the Web as a corpus",
      "author" : [ "N. Kim", "P. Nakov." ],
      "venue" : "Proceedings of the",
      "citeRegEx" : "Kim and Nakov.,? 2011",
      "shortCiteRegEx" : "Kim and Nakov.",
      "year" : 2011
    }, {
      "title" : "Phrase clustering for",
      "author" : [ "D. Lin", "X. Wu" ],
      "venue" : null,
      "citeRegEx" : "66",
      "shortCiteRegEx" : "66",
      "year" : 2009
    }, {
      "title" : "Open language learning",
      "author" : [ "O. Etzioni" ],
      "venue" : null,
      "citeRegEx" : "Etzioni.,? \\Q2012\\E",
      "shortCiteRegEx" : "Etzioni.",
      "year" : 2012
    }, {
      "title" : "WordNet: a lexical database",
      "author" : [ "G. Miller" ],
      "venue" : null,
      "citeRegEx" : "Miller.,? \\Q1995\\E",
      "shortCiteRegEx" : "Miller.",
      "year" : 1995
    }, {
      "title" : "Interpreting compound noun",
      "author" : [ "M. Pasca" ],
      "venue" : null,
      "citeRegEx" : "Pasca.,? \\Q2015\\E",
      "shortCiteRegEx" : "Pasca.",
      "year" : 2015
    }, {
      "title" : "Zero-shot entity extraction from web pages",
      "author" : [ "P. Pasupat", "P. Liang." ],
      "venue" : "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Association for Computational Linguis-",
      "citeRegEx" : "Pasupat and Liang.,? 2014",
      "shortCiteRegEx" : "Pasupat and Liang.",
      "year" : 2014
    }, {
      "title" : "Relation extraction with matrix factorization and universal schemas",
      "author" : [ "S. Riedel", "L. Yao", "A. McCallum", "B. Marlin." ],
      "venue" : "Proceedings of the 2013 Conference of the North American Chapter of the Association for Computa-",
      "citeRegEx" : "Riedel et al\\.,? 2013",
      "shortCiteRegEx" : "Riedel et al\\.",
      "year" : 2013
    }, {
      "title" : "Cooccurrence contexts for noun compound interpretation",
      "author" : [ "D. Ó Séaghdha", "A. Copestake." ],
      "venue" : "proceedings of the Workshop on A Broader Perspective on Multiword Expressions. Association for Computational Linguis-",
      "citeRegEx" : "Séaghdha and Copestake.,? 2007",
      "shortCiteRegEx" : "Séaghdha and Copestake.",
      "year" : 2007
    }, {
      "title" : "Improving hypernymy detection with an integrated path-based and distributional method",
      "author" : [ "V. Shwartz", "Y. Goldberg", "I. Dagan." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume",
      "citeRegEx" : "Shwartz et al\\.,? 2016",
      "shortCiteRegEx" : "Shwartz et al\\.",
      "year" : 2016
    }, {
      "title" : "Semantic taxonomy induction from heterogenous evidence",
      "author" : [ "R. Snow", "D. Jurafsky", "A. Ng." ],
      "venue" : "Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association",
      "citeRegEx" : "Snow et al\\.,? 2006",
      "shortCiteRegEx" : "Snow et al\\.",
      "year" : 2006
    }, {
      "title" : "A vsm-based statistical model for the semantic relation interpretation of noun-modifier pairs",
      "author" : [ "N. Surtani", "S. Paul." ],
      "venue" : "Recent Advances in Natural Language Processing page 636.",
      "citeRegEx" : "Surtani and Paul.,? 2015",
      "shortCiteRegEx" : "Surtani and Paul.",
      "year" : 2015
    }, {
      "title" : "A taxonomy, dataset, and classifier for automatic noun compound interpretation",
      "author" : [ "S. Tratz", "E. Hovy." ],
      "venue" : "Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics. Association for Computational Lin-",
      "citeRegEx" : "Tratz and Hovy.,? 2010",
      "shortCiteRegEx" : "Tratz and Hovy.",
      "year" : 2010
    }, {
      "title" : "MELODI: A supervised distributional approach for free paraphrasing of noun compounds",
      "author" : [ "T. Van de Cruys", "S. Afantenos", "P. Muller." ],
      "venue" : "Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval-",
      "citeRegEx" : "Cruys et al\\.,? 2013",
      "shortCiteRegEx" : "Cruys et al\\.",
      "year" : 2013
    }, {
      "title" : "Generalizing to unseen entities and entity pairs with row-less universal schema",
      "author" : [ "P. Verga", "A. Neelakantan", "A. McCallum." ],
      "venue" : "arXiv preprint arXiv:1606.05804 .",
      "citeRegEx" : "Verga et al\\.,? 2016",
      "shortCiteRegEx" : "Verga et al\\.",
      "year" : 2016
    }, {
      "title" : "Automatic set instance extraction using the Web",
      "author" : [ "R. Wang", "W. Cohen." ],
      "venue" : "Proceedings of the 47th Annual Meeting of the Association for Computational Linguistics (ACL-IJCNLP09). Singapore, pages 441–449.",
      "citeRegEx" : "Wang and Cohen.,? 2009",
      "shortCiteRegEx" : "Wang and Cohen.",
      "year" : 2009
    }, {
      "title" : "Compound nominals, context, and compositionality",
      "author" : [ "D. Weiskopf." ],
      "venue" : "Synthese 156(1):161–204.",
      "citeRegEx" : "Weiskopf.,? 2007",
      "shortCiteRegEx" : "Weiskopf.",
      "year" : 2007
    }, {
      "title" : "Nut case: What does it mean?: Understanding semantic relationship between nouns in noun compounds through paraphrasing and ranking the paraphrases",
      "author" : [ "D. Wijaya", "P. Gianfortoni." ],
      "venue" : "Proceedings of the 1st interna-",
      "citeRegEx" : "Wijaya and Gianfortoni.,? 2011",
      "shortCiteRegEx" : "Wijaya and Gianfortoni.",
      "year" : 2011
    }, {
      "title" : "Boosting open information extraction with noun-based relations",
      "author" : [ "C. Xavier", "V. Strube de Lima." ],
      "venue" : "LREC . pages 96–100.",
      "citeRegEx" : "Xavier and Lima.,? 2014",
      "shortCiteRegEx" : "Xavier and Lima.",
      "year" : 2014
    }, {
      "title" : "From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions",
      "author" : [ "P. Young", "A. Lai", "M. Hodosh", "J. Hockenmaier." ],
      "venue" : "Transactions of the Association for Computational Linguistics",
      "citeRegEx" : "Young et al\\.,? 2014",
      "shortCiteRegEx" : "Young et al\\.",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 19,
      "context" : "Substantial attention has been paid to automatically acquiring taxonomic knowledge, like that “Charles Mingus” is a “composer”, from text (Snow et al., 2006; Shwartz et al., 2016).",
      "startOffset" : 138,
      "endOffset" : 179
    }, {
      "referenceID" : 18,
      "context" : "Substantial attention has been paid to automatically acquiring taxonomic knowledge, like that “Charles Mingus” is a “composer”, from text (Snow et al., 2006; Shwartz et al., 2016).",
      "startOffset" : 138,
      "endOffset" : 179
    }, {
      "referenceID" : 6,
      "context" : "The majority of approaches for extracting such “IsA” relations rely on lexical patterns as the primary signal of whether an instance belongs to a class: for example, observing a pattern like “X such as Y” is a strong indication that Y is an instance of class X (Hearst, 1992).",
      "startOffset" : 261,
      "endOffset" : 275
    }, {
      "referenceID" : 7,
      "context" : "Our approach is based on the notion from formal semantics in which modifiers (“1950s”) correspond to properties which differentiate instances of a subclass (“1950s composers”) from instances of the superclass (“composers”) (Heim and Kratzer, 1998).",
      "startOffset" : 223,
      "endOffset" : 247
    }, {
      "referenceID" : 5,
      "context" : "Many efforts to provide semantic interpretations of such phrases rely on matching the compound to pre-defined patterns or semantic ontologies (Fares et al., 2015; Séaghdha and Copestake, 2007; Tratz and Hovy, 2010; Surtani and Paul, 2015; Choi et al., 2015).",
      "startOffset" : 142,
      "endOffset" : 257
    }, {
      "referenceID" : 17,
      "context" : "Many efforts to provide semantic interpretations of such phrases rely on matching the compound to pre-defined patterns or semantic ontologies (Fares et al., 2015; Séaghdha and Copestake, 2007; Tratz and Hovy, 2010; Surtani and Paul, 2015; Choi et al., 2015).",
      "startOffset" : 142,
      "endOffset" : 257
    }, {
      "referenceID" : 21,
      "context" : "Many efforts to provide semantic interpretations of such phrases rely on matching the compound to pre-defined patterns or semantic ontologies (Fares et al., 2015; Séaghdha and Copestake, 2007; Tratz and Hovy, 2010; Surtani and Paul, 2015; Choi et al., 2015).",
      "startOffset" : 142,
      "endOffset" : 257
    }, {
      "referenceID" : 20,
      "context" : "Many efforts to provide semantic interpretations of such phrases rely on matching the compound to pre-defined patterns or semantic ontologies (Fares et al., 2015; Séaghdha and Copestake, 2007; Tratz and Hovy, 2010; Surtani and Paul, 2015; Choi et al., 2015).",
      "startOffset" : 142,
      "endOffset" : 257
    }, {
      "referenceID" : 2,
      "context" : "Many efforts to provide semantic interpretations of such phrases rely on matching the compound to pre-defined patterns or semantic ontologies (Fares et al., 2015; Séaghdha and Copestake, 2007; Tratz and Hovy, 2010; Surtani and Paul, 2015; Choi et al., 2015).",
      "startOffset" : 142,
      "endOffset" : 257
    }, {
      "referenceID" : 8,
      "context" : "Recently, interpretations may take the form of arbitrary natural language predicates (Hendrickx et al., 2013).",
      "startOffset" : 85,
      "endOffset" : 109
    }, {
      "referenceID" : 26,
      "context" : "Most approaches are supervised, comparing unseen noun compounds to the most similar phrase seen in training (Wijaya and Gianfortoni, 2011; Nulty and Costello, 2013; Van de Cruys et al., 2013).",
      "startOffset" : 108,
      "endOffset" : 191
    }, {
      "referenceID" : 10,
      "context" : "Other unsupervised approaches apply information extraction techniques to paraphrase noun compounds (Kim and Nakov, 2011; Xavier and de Lima, 2014; Pasca, 2015).",
      "startOffset" : 99,
      "endOffset" : 159
    }, {
      "referenceID" : 14,
      "context" : "Other unsupervised approaches apply information extraction techniques to paraphrase noun compounds (Kim and Nakov, 2011; Xavier and de Lima, 2014; Pasca, 2015).",
      "startOffset" : 99,
      "endOffset" : 159
    }, {
      "referenceID" : 19,
      "context" : "Recent work focuses on learning such patterns automatically from corpora (Snow et al., 2006; Shwartz et al., 2016).",
      "startOffset" : 73,
      "endOffset" : 114
    }, {
      "referenceID" : 18,
      "context" : "Recent work focuses on learning such patterns automatically from corpora (Snow et al., 2006; Shwartz et al., 2016).",
      "startOffset" : 73,
      "endOffset" : 114
    }, {
      "referenceID" : 16,
      "context" : "The “universal schema” approach (Riedel et al., 2013; Kirschnick et al., 2016; Verga et al., 2016), which infers relations using matrix factorization, often includes Hearst patterns as input features.",
      "startOffset" : 32,
      "endOffset" : 98
    }, {
      "referenceID" : 23,
      "context" : "The “universal schema” approach (Riedel et al., 2013; Kirschnick et al., 2016; Verga et al., 2016), which infers relations using matrix factorization, often includes Hearst patterns as input features.",
      "startOffset" : 32,
      "endOffset" : 98
    }, {
      "referenceID" : 0,
      "context" : "Graphical (Bansal et al., 2014) and joint inference models (Movshovitz-Attias and Cohen, 2015) typically require Hearst patterns to define an inventory of possible classes.",
      "startOffset" : 10,
      "endOffset" : 31
    }, {
      "referenceID" : 24,
      "context" : "A separate line of work avoids Hearst patterns by instead exploiting semi-structured data from HTML markup (Wang and Cohen, 2009; Dalvi et al., 2012; Pasupat and Liang, 2014).",
      "startOffset" : 107,
      "endOffset" : 174
    }, {
      "referenceID" : 3,
      "context" : "A separate line of work avoids Hearst patterns by instead exploiting semi-structured data from HTML markup (Wang and Cohen, 2009; Dalvi et al., 2012; Pasupat and Liang, 2014).",
      "startOffset" : 107,
      "endOffset" : 174
    }, {
      "referenceID" : 15,
      "context" : "A separate line of work avoids Hearst patterns by instead exploiting semi-structured data from HTML markup (Wang and Cohen, 2009; Dalvi et al., 2012; Pasupat and Liang, 2014).",
      "startOffset" : 107,
      "endOffset" : 174
    }, {
      "referenceID" : 4,
      "context" : "Most efforts to learn taxonomic relations from text build on the seminal work of Hearst (1992), which observes that certain textual patterns– e.",
      "startOffset" : 81,
      "endOffset" : 95
    }, {
      "referenceID" : 7,
      "context" : "The interpretation of a common noun is the set of entities2 in the universe U which are denoted by the noun (Heim and Kratzer, 1998):",
      "startOffset" : 108,
      "endOffset" : 132
    }, {
      "referenceID" : 9,
      "context" : "As does virtually all previous work in information extraction, we assume that modifiers are subsective, acknowledging the limitations (Kamp and Partee, 1995).",
      "startOffset" : 134,
      "endOffset" : 157
    }, {
      "referenceID" : 27,
      "context" : "For example, Young et al. (2014) focuses exclusively on the subset selection aspect of modification.",
      "startOffset" : 13,
      "endOffset" : 33
    }, {
      "referenceID" : 1,
      "context" : "In contrast, Baroni and Zamparelli (2010) models the meaning of modifiers explicitly as functions which map between vector-space representations of nouns.",
      "startOffset" : 13,
      "endOffset" : 42
    }, {
      "referenceID" : 25,
      "context" : "In general, there is no systematic way to determine the implied relation between M and H, as modifiers can arguably express any semantic relation, given the right context (Weiskopf, 2007).",
      "startOffset" : 171,
      "endOffset" : 187
    }, {
      "referenceID" : 14,
      "context" : "4) but has given good results for paraphrasing noun phrases (Nakov and Hearst, 2013; Pasca, 2015).",
      "startOffset" : 60,
      "endOffset" : 97
    }, {
      "referenceID" : 6,
      "context" : "4) but has given good results for paraphrasing noun phrases (Nakov and Hearst, 2013; Pasca, 2015). Our method for learning property profiles is based on the unsupervised method proposed by Pasca (2015), which uses query logs as a source of common sense knowledge, and rewrites noun compounds by matching MH (“American composers”) to queries of the form “H(.",
      "startOffset" : 71,
      "endOffset" : 202
    }, {
      "referenceID" : 4,
      "context" : "We instantiate D with a large repository of facts extracted using in-house implementations of ReVerb (Fader et al., 2011) and OLLIE (Mausam et al.",
      "startOffset" : 101,
      "endOffset" : 121
    }, {
      "referenceID" : 13,
      "context" : "We expand adjectival modifiers to encompass nominalized forms using a nominalization dictionary extracted from WordNet (Miller, 1995).",
      "startOffset" : 119,
      "endOffset" : 133
    }, {
      "referenceID" : 14,
      "context" : "Instead, we follow Pasca (2015) and take advantage of facts involving distributionally similar modifiers.",
      "startOffset" : 19,
      "endOffset" : 32
    } ],
    "year" : 2017,
    "abstractText" : "We present a method for populating fine-grained classes (e.g., “1950s American jazz composers”) with instances (e.g., Charles Mingus). While stateof-the-art methods tend to treat class labels as single lexical units, the proposed method considers each of the individual modifiers in the class label relative to the head. An evaluation on the task of reconstructing Wikipedia category pages demonstrates a >10 point increase in AUC, over a strong baseline relying on widely-used Hearst patterns.",
    "creator" : "LaTeX with hyperref package"
  }
}