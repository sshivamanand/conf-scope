{
  "name" : "193.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "1 000\n011\n012\n013\n014\n015\n016\n017\n018\n019\n020\n021\n022\n023\n024\n025\n026\n027\n028\n029\n030\n031\n032\n033\n034\n035\n036\n037\n038\n039\n040\n041\n042\n043\n044\n045\n046\n047\n048\n049\n061\n062\n063\n064\n065\n066\n067\n068\n069\n070\n071\n072\n073\n074\n075\n076\n077\n078\n079\n080\n081\n082\n083\n084\n085\n086\n087\n088\n089\n090\n091\n092\n093\n094\n095\n096\n097\n098\n099"
    }, {
      "heading" : "1 Introduction",
      "text" : "Universal Conceptual Cognitive Annotation (UCCA, Abend and Rappoport, 2013) is a crosslinguistically applicable semantic representation scheme, building on the established Basic Linguistic Theory typological framework (Dixon, 2010a,b, 2012), and Cognitive Linguistics literature (Croft and Cruse, 2004). It has demonstrated applicability to multiple languages, including English, French, German and Czech, support for rapid annotation, and stability under translation (Sulem et al., 2015). It has also proven useful for machine translation evaluation (Birch et al., 2016). UCCA differs from syntactic schemes in terms of content and formal structure. It exhibits reentrancy, discontinuous nodes and non-terminals, which no single existing parser\nsupports. Lacking a parser, UCCA’s applicability has been so far limited, a gap this work addresses.\nWe present the first UCCA parser, TUPA (Transition-based UCCA Parser), building on recent advances in discontinuous constituency and dependency graph parsing, and further introducing novel transitions and features for UCCA. Transition-based techniques are a natural starting point for UCCA parsing, given the conceptual similarity of UCCA’s distinctions, centered around predicate-argument structures, to distinctions expressed by dependency schemes, and the achievements of transition-based methods in dependency parsing (Dyer et al., 2015; Andor et al., 2016; Kiperwasser and Goldberg, 2016). We are further motivated by the strength of transition-based methods in related tasks, including dependency graph parsing (Sagae and Tsujii, 2008; Ribeyre et al., 2014; Tokgöz and Eryiğit, 2015), constituency parsing (Sagae and Lavie, 2005; Zhang and Clark, 2009; Zhu et al., 2013; Maier, 2015; Maier and Lichte, 2016), AMR parsing (Wang et al., 2015a,b, 2016; Misra and Artzi, 2016; Goodman et al., 2016; Zhou et al., 2016; Damonte et al., 2017) and CCG parsing (Zhang and Clark, 2011; Ambati et al., 2015, 2016).\nWe evaluate TUPA on the English UCCA corpora, including in-domain and out-of-domain settings. To assess the ability of existing parsers to tackle the task, we develop a conversion procedure from UCCA to bilexical graphs and trees. Results show superior performance for TUPA, demonstrating the effectiveness of the presented approach.1\nThe rest of the paper is structured as follows: Section 2 describes UCCA in more detail. Section 3 introduces TUPA. Section 4 discusses the data and experimental setup. Section 5 presents\n1Our code and models will be made freely available upon publication.\n2\n101\n102\n103\n104\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n123\n124\n125\n126\n127\n128\n129\n130\n131\n132\n133\n134\n135\n136\n137\n138\n139\n140\n141\n142\n143\n144\n145\n146\n147\n148\n149\n150\n151\n152\n172\n173\n174\n175\n176\n177\n178\n179\n180\n181\n182\n183\n184\n185\n186\n187\n188\n189\n190\n191\n192\n193\n194\n195\n196\n197\n198\n199\nthe experimental results. Section 6 summarizes related work, and Section 7 concludes the paper."
    }, {
      "heading" : "2 The UCCA Scheme",
      "text" : "UCCA graphs are labeled, directed acyclic graphs (DAGs), whose leaves correspond to the tokens of the text. A node (or unit) corresponds to a terminal or to several sub-units (not necessarily contiguous) viewed as a single entity according to semantic or cognitive considerations. Edges bear a category, indicating the role of the sub-unit in the parent relation. Figure 1 presents a few examples.\nUCCA is a multi-layered representation, where each layer corresponds to a “module” of semantic distinctions. UCCA’s foundational layer, targeted in this paper, covers the predicate-argument structure evoked by predicates of all grammatical categories (verbal, nominal, adjectival and others), the inter-relations between them, and other major linguistic phenomena such as coordination and multi-word expressions. The layer’s basic notion is the scene, describing a movement, action or state. Each scene contains one main relation (marked as either a Process or a State), as well as one or more Participants. For example, the sentence “After graduation, John moved to Paris” (Figure 1a) contains two scenes, whose main relations are “graduation” and “moved”. “John” is a Participant in both scenes, while “Paris” only in the latter. Further categories account for interscene relations and the internal structure of complex arguments and relations (e.g. coordination, multi-word expressions and modification).\nOne incoming edge for each non-root node is marked as primary, and the rest (mostly used for implicit relations and arguments) as remote edges, a distinction made by the annotator. The primary edges thus form a tree structure, whereas the remote edges enable reentrancy, forming a DAG.\nWhile parsing technology in general, and transition-based parsing in particular, is wellestablished for syntactic parsing, UCCA has several distinct properties that distinguish it from syntactic representations, mostly UCCA’s tendency to abstract away from syntactic detail that do not affect argument structure. For instance, consider the following examples where the concept of a scene has a different rationale from the syntactic concept of a clause. First, non-verbal predicates in UCCA are represented like verbal ones, such as when they appear in copula clauses or noun phrases. Indeed,\n(a) After\nL\ngraduation P\nH\n, U\nJohn\nA\nmoved\nP\nto R\nParis\nC\nA\nH\nA\n(b) John\nA\ngave\nC\neverything up\nC\nP\nA P process A participant H linked scene C center R relator N connector L scene linker U punctuation F function unit\n(c)\nJohn\nC\nand\nN\nMary\nC\n’s\nF\nA\ntrip\nP\nhome\nA\nin Figure 1a, “graduation” and “moved” are considered separate events, despite appearing in the same clause. Second, in the same example, “John” is marked as a (remote) Participant in the graduation scene, despite not being overtly marked. Third, consider the possessive construction in Figure 1c. While in UCCA “trip” evokes a scene in which “John and Mary” is a Participant, a syntactic scheme would analyze this phrase similarly to “John and Mary’s children”.\nThese examples demonstrate that a UCCA parser, and more generally semantic parsers, face an additional level of ambiguity compared to their syntactic counterparts (e.g., “after graduation” is formally very similar to “after 2pm”, which does not evoke a scene). Section 6 discusses UCCA in the context of other semantic schemes, such as AMR (Banarescu et al., 2013).\nAlongside recent progress in dependency parsing into projective trees, there is increasing interest in parsing into representations with more general structural properties (see Section 6). One such property is reentrancy, namely the sharing of semantic units between predicates. For instance, in Figure 1a, “John” is an argument of both “graduation” and “moved”, yielding a DAG rather than a tree. A second property is discontinuity, as in Figure 1b, where “gave up” forms a discontinuous semantic unit. Discontinuities are perva-\n3\n201\n202\n203\n204\n205\n206\n207\n208\n209\n210\n211\n212\n213\n214\n215\n216\n217\n218\n219\n220\n221\n222\n223\n224\n225\n226\n227\n228\n229\n230\n231\n232\n233\n234\n235\n236\n237\n238\n239\n240\n241\n242\n243\n244\n245\n246\n247\n248\n249\n250\n251\n252\n253\n254\n255\n256\n257\n258\n259\n260\n261\n262\n263\n264\n265\n266\n267\n268\n269\n270\n271\n272\n273\n274\n275\n276\n277\n278\n279\n280\n281\n282\n283\n284\n285\n286\n287\n288\n289\n290\n291\n292\n293\n294\n295\n296\n297\n298\n299\nsive, e.g., with multi-word expressions (Schneider et al., 2014). Finally, unlike most dependency schemes, UCCA uses non-terminal nodes to represent units comprising more than one word. The use of non-terminal nodes is motivated by constructions with no clear head, including coordination structures (e.g., “John and Mary” in Figure 1c), some multi-word expressions (e.g., “The Haves and the Have Nots”), and prepositional phrases (either the preposition or the head noun can serve as the constituent’s head). To our knowledge, no existing parser supports all structural properties required for UCCA parsing."
    }, {
      "heading" : "3 Transition-based UCCA Parsing",
      "text" : "We now turn to presenting TUPA. Building on previous work on parsing reentrancies, discontinuities and non-terminal nodes, we define an extended set of transitions and features that supports the conjunction of these properties.\nTransition-based parsers (Nivre, 2003) scan the text from start to end, and create the parse incrementally by applying a transition at each step to the parser’s state, defined using three data structures: a buffer B of tokens and nodes to be processed, a stack S of nodes currently being processed, and a graph G = (V,E, `) of constructed nodes and edges, where V is the set of nodes, E is the set of edges, and ` : E → L is the label function, L being the set of possible labels. Some states are marked as terminal, meaning that G is the final output. A classifier is used at each step to select the next transition based on features encoding the parser’s current state. During training, an oracle creates training instances for the classifier, based on gold-standard annotations.\nTransition Set. Given a sequence of tokens w1, . . . , wn, we predict a UCCA graph G over the sequence. Parsing starts with a single node on the stack (an artificial root node), and the input tokens in the buffer. Figure 2 shows the transition set.\nIn addition to the standard SHIFT and REDUCE operations, we follow previous work in transition-based constituency parsing (Sagae and Lavie, 2005), adding the NODE transition for creating new non-terminal nodes. For every X ∈ L, NODEX creates a new node on the buffer as a parent of the first element on the stack, with an Xlabeled edge. LEFT-EDGEX and RIGHT-EDGEX create a new primary X-labeled edge between the first two elements on the stack, where the parent is\nthe left or the right node, respectively. As a UCCA node may only have one incoming primary edge, EDGE transitions are disallowed if the child node already has an incoming primary edge. LEFTREMOTEX and RIGHT-REMOTEX do not have this restriction, and the created edge is additionally marked as remote. We distinguish between these two pairs of transitions to allow the parser to create remote edges without the possibility of producing invalid graphs. To support the prediction of multiple parents, node and edge transitions leave the stack unchanged, as in other work on transition-based dependency graph parsing (Sagae and Tsujii, 2008; Ribeyre et al., 2014; Tokgöz and Eryiğit, 2015). REDUCE pops the stack, to allow removing a node once all its edges have been created. To handle discontinuous nodes, SWAP pops the second node on the stack and adds it to the top of the buffer, as with the similarly named transition in previous work (Nivre, 2009; Maier, 2015). Finally, FINISH pops the root node and marks the state as terminal.\nClassifier. The choice of classifier and feature representation has been shown to play an important role in transition-based parsing (Chen and Manning, 2014; Andor et al., 2016; Kiperwasser and Goldberg, 2016). To investigate the impact of the type of transition classifier in UCCA parsing, we experiment with three different models.\n1. Starting with a simple and common choice (e.g., Maier and Lichte, 2016), TUPASparse uses a linear classifier with sparse features, trained with the averaged structured perceptron algorithm (Collins and Roark, 2004) and MINUPDATE (Goldberg and Elhadad, 2011): each feature requires a minimum number of updates in training to be included in the model.2\n2. Changing the model to a feedforward neural network with dense embedding features, TUPAMLP (“multi-layer perceptron”), uses an architecture similar to that of Chen and Manning (2014), but with two rectified linear layers instead of one layer with cube activation. The embeddings and classifier are trained jointly.\n3. Finally, TUPABiLSTM uses a bidirectional LSTM for feature representation, on top of the 2We also experimented with a linear model using dense embedding features, trained with the averaged structured perceptron algorithm. It performed worse than the sparse perceptron model and was hence discarded.\n4\n301\n302\n303\n304\n305\n306\n307\n308\n309\n310\n311\n312\n313\n314\n315\n316\n317\n318\n319\n320\n321\n322\n323\n324\n325\n326\n327\n328\n329\n330\n331\n332\n333\n334\n335\n336\n337\n338\n339\n340\n341\n342\n343\n344\n345\n346\n347\n348\n349\n350\n351\n352\n353\n354\n355\n356\n357\n358\n359\n360\n361\n362\n363\n364\n365\n366\n367\n368\n369\n370\n371\n372\n373\n374\n375\n376\n377\n378\n379\n380\n381\n382\n383\n384\n385\n386\n387\n388\n389\n390\n391\n392\n393\n394\n395\n396\n397\n398\n399\nBefore Transition Transition After Transition Condition Stack Buffer Nodes Edges Stack Buffer Nodes Edges Terminal? S x | B V E SHIFT S | x B V E − S | x B V E REDUCE S B V E − S | x B V E NODEX S | x y | B V ∪ {y} E ∪ {(y, x)X} − x 6= root S | y, x B V E LEFT-EDGEX S | y, x B V E ∪ {(x, y)X} − \nx 6∈ w1:n, y 6= root, y 6;G x\nS | x, y B V E RIGHT-EDGEX S | x, y B V E ∪ {(x, y)X} − S | y, x B V E LEFT-REMOTEX S | y, x B V E ∪ {(x, y)∗X} − S | x, y B V E RIGHT-REMOTEX S | x, y B V E ∪ {(x, y)∗X} − S | x, y B V E SWAP S | y x | B V E − i(x) < i(y) [root] ∅ V E FINISH ∅ ∅ V E +\nFigure 2: The transition set of TUPA. We write the stack with its top to the right and the buffer with its head to the left. (·, ·)X denotes a primary X-labeled edge, and (·, ·)∗X a remote X-labeled edge. i(x) is a running index for the created nodes. In addition to the specified conditions, the prospective child in an EDGE transition must not already have a primary parent.\ndense embedding features, an architecture similar to Kiperwasser and Goldberg (2016). The BiLSTM runs on the input tokens in forward and backward directions, yielding a vector representation that is then concatenated with dense features representing the parser state (e.g., existing edge labels and previous parser actions; see below). This representation is then fed into a feedforward network similar to TUPAMLP. The feedforward layers, BiLSTM and embeddings are all trained jointly.\nFor all classifiers, inference is performed greedily, i.e., without beam search. Hyperparameters are tuned on the development set (see Section 4).\nFeatures. TUPASparse uses binary indicator features representing the words, POS tags, syntactic dependency labels and existing edge labels related to the top four stack elements and the next three buffer elements, in addition to their children and grandchildren in the graph. We also use bi- and trigram features based on these values (Zhang and Clark, 2009; Zhu et al., 2013), features related to discontinuous nodes (Maier, 2015, including separating punctuation and gap type), features representing existing edges and the number of parents and children, as well as the past actions taken by the parser. In addition, we use use a novel, UCCAspecific feature: number of remote children.3\nFor TUPAMLP and TUPABiLSTM, we replace all indicator features by a concatenation of the vector embeddings of all represented elements: words, POS tags, syntactic dependency labels, edge labels, punctuation, gap type and parser actions. These embeddings are initialized randomly. We additionally use external word embeddings initialized with pre-trained word2vec vectors (Mikolov\n3See Appendix A for a full list of used feature templates.\net al., 2013),4 updated during training. In addition to dropout between NN layers, we apply word dropout (Kiperwasser and Goldberg, 2016): with a certain probability, the embedding for a word is replaced with a zero vector. We do not apply word dropout to the external word embeddings.\nFinally, for all classifiers we add a novel realvalued feature to the input vector, ratio, corresponding to the ratio between the number of terminals to number of nodes in the graph G. This feature serves as a regularizer for the creation of new nodes, and should be beneficial for other transition-based constituency parsers too.\nTraining. For training the transition classifiers, we use a dynamic oracle (Goldberg and Nivre, 2012), i.e., an oracle that outputs a set of optimal transitions: when applied to the current parser state, the gold standard graph is reachable from the resulting state. For example, the oracle would predict a NODE transition if the stack has on its top a parent in the gold graph that has not been created, but would predict a RIGHT-EDGE transition if the second stack element is a parent of the first element according to the gold graph and the edge between them has not been created. The transition predicted by the classifier is deemed correct and is applied to the parser state to reach the subsequent state, if the transition is included in the set of optimal transitions. Otherwise, a random optimal transition is applied, and for the perceptronbased parser, the classifier’s weights are updated according to the perceptron update rule.\nPOS tags and syntactic dependency labels are extracted using spaCy (Honnibal and Johnson, 2015).5 We use the categorical cross-entropy ob-\n4https://goo.gl/6ovEhC 5https://spacy.io\n5\n401\n402\n403\n404\n405\n406\n407\n408\n409\n410\n411\n412\n413\n414\n415\n416\n417\n418\n419\n420\n421\n422\n423\n424\n425\n426\n427\n428\n429\n430\n431\n432\n433\n434\n435\n436\n437\n438\n439\n440\n441\n442\n443\n444\n445\n446\n447\n448\n449\n463\n464\n465\n466\n467\n468\n469\n470\n471\n472\n473\n474\n475\n476\n477\n478\n479\n480\n481\n482\n483\n484\n485\n486\n487\n488\n489\n490\n491\n492\n493\n494\n495\n496\n497\n498\n499\nParser state\nS\n,\nB\nJohn moved to Paris .\nG\nAfter\nL\ngraduation\nP\nH\nTransition classifier\nAfter\nLSTM\nLSTM\nLSTM\nLSTM\ngraduation\nLSTM\nLSTM\nLSTM\nLSTM\nto\nLSTM\nLSTM\nLSTM\nLSTM\nParis\nLSTM\nLSTM\nLSTM\nLSTM\n. . .\n. . .\n. . .\n. . .\n. . .\nMLP\nNODEU\nFigure 3: Illustration of the TUPA model. Top: parser state (stack, buffer and intermediate graph). Bottom: TUPABiLTSM architecture. Vector representation for the input tokens is computed by two layers of bidirectional LSTMs. The vectors for specific tokens are concatenated with embedding and numeric features from the parser state (for existing edge labels, number of children, etc.), and fed into the MLP for selecting the next transition.\njective function and optimize the NN classifiers with the Adam optimizer (Kingma and Ba, 2014)."
    }, {
      "heading" : "4 Experimental Setup",
      "text" : "Data. We conduct our experiments on the UCCA Wikipedia corpus (henceforth, Wiki), and use the English part of the UCCA Twenty Thousand Leagues Under the Sea English-French parallel corpus (henceforth, 20K Leagues) as outof-domain data.6 Table 1 presents some statistics for the two corpora. We use passages of indices up to 676 of the Wiki corpus as our training set, passages 688–808 as development set, and passages 942–1028 as in-domain test set. While UCCA edges can cross sentence boundaries, we adhere to the common practice in semantic parsing and train our parsers on individual sentences, discarding inter-relations between them (0.18% of the edges). We also discard linkage nodes and\n6http://cs.huji.ac.il/˜oabend/ucca.html\nedges (as they often express inter-sentence relations and are thus mostly redundant when applied at the sentence level) as well as implicit nodes.7 In the out-of-domain experiments, we apply the same parsers (trained on the Wiki training set) to the 20K Leagues corpus without parameter re-tuning.\nImplementation. We use the DyNet package (Neubig et al., 2017) for implementing the NN classifiers. Unless otherwise noted, we use the default values provided by the package. See Appendix C for the hyperparameter values we found by tuning on the development set.\nEvaluation. We define a simple measure for comparing UCCA structures Gp = (Vp, Ep, `p) and Gg = (Vg, Eg, `g), the predicted and goldstandard graphs, respectively, over the same sequence of terminals W = {w1, . . . , wn}. For an edge e = (u, v) in either graph, u being the parent and v the child, its yield y(e) ⊆ W is the set of terminals in W that are descendants of v. Define the set of mutual edges between Gp and Gg:\nM(Gp, Gg) =\n{(e1, e2) ∈ Ep × Eg | y(e1) = y(e2) ∧ `p(e1) = `g(e2)}\nLabeled precision and recall are defined by dividing |M(Gp, Gg)| by |Ep| and |Eg|, respectively, and F-score by taking their harmonic mean. We report two variants of this measure: one where we consider only primary edges, and another for remote edges (see Section 2). Performance on remote edges is of pivotal importance in this investigation, which focuses on extending the class of graphs supported by statistical parsers.\n7Appendix B further discusses linkage and implicit units.\n6\n501\n502\n503\n504\n505\n506\n507\n508\n509\n510\n511\n512\n513\n514\n515\n516\n517\n518\n519\n520\n521\n522\n523\n524\n525\n526\n527\n528\n529\n530\n531\n532\n533\n534\n535\n536\n537\n538\n539\n540\n541\n542\n543\n544\n545\n546\n547\n548\n549\n550\n551\n552\n553\n554\n555\n556\n557\n558\n559\n560\n561\n562\n563\n564\n565\n566\n567\n568\n569\n570\n571\n572\n573\n574\n575\n576\n577\n578\n579\n580\n581\n582\n583\n584\n585\n586\n587\n588\n589\n590\n591\n592\n593\n594\n595\n596\n597\n598\n599\nAfter graduation , John moved to Paris\nL U A\nA\nH\nR\nA\nJohn gave everything up\nA A\nC\nJohn and Mary went home\nA\nN\nC\nA\nFigure 4: Bilexical graph approximation (dependency graph) for the sentences in Figure 1.\nAfter\nL\ngraduation P\nH\n, U\nJohn\nA\nmoved\nP\nto R\nParis\nC\nA\nH\nAfter graduation , John moved to Paris\nL U A\nH\nR\nA\nFigure 5: Tree approximation (constituency) for the sentence in Figure 1a (top), and bilexical tree approximation (dependency) for the same sentence (bottom). These are identical to the original graphs, apart from the removal of remote edges.\nWe note that the measure collapses to the standard PARSEVAL constituency evaluation measure if Gp and Gg are trees. Punctuation is excluded from the evaluation, but not from the datasets.\nComparison to bilexical graph parsers. As no direct comparison with existing parsers is possible, we compare TUPA to bilexical dependency graph parsers, which support reentrancy and discontinuity but not non-terminal nodes. To facilitate the comparison, we convert our training set into bilexical graphs (see examples in Figure 4), train each of the parsers, and evaluate them by applying them to the test set and then reconstructing UCCA graphs, which are compared with the gold standard.8 In Section 5 we report the upper bounds on the achievable scores due to the error resulting from the removal of non-terminal nodes.\nComparison to tree parsers. For completeness, and as parsing technology is considerably more mature for tree (rather than graph) parsing, we also\n8See Appendix D for the conversion procedures.\nperform a tree approximation experiment, converting UCCA to (bilexical) trees and evaluating constituency and dependency tree parsers on them (see examples in Figure 5). Our approach is similar to the tree approximation approach used for dependency graph parsing (Agić et al., 2015; Fernández-González and Martins, 2015), where dependency graphs were converted into dependency trees and then parsed by dependency tree parsers. In our setting, the conversion to trees consists simply of removing remote edges from the graph, and then to bilexical trees by applying the same procedure as for bilexical graphs.\nBaseline parsers. We evaluate two bilexical graph semantic dependency parsers: DAGParser (Ribeyre et al., 2014), the leading transition-based parser in SemEval 2014 (Oepen et al., 2014) and TurboParser (Almeida and Martins, 2015), a graph-based parser from SemEval 2015 (Oepen et al., 2015); UPARSE (Maier and Lichte, 2016), a transition-based constituency parser supporting discontinuous constituents; and two bilexical tree parsers: MaltParser (Nivre et al., 2007),9 and the stack LSTM-based parser of Dyer et al. (2015, henceforce “LSTM Parser”). Default settings are used in all cases. DAGParser and UPARSE use beam search by default, with a beam size of 5 and 4 respectively. The other parsers are greedy."
    }, {
      "heading" : "5 Results",
      "text" : "Table 2 presents our main experimental results, as well as upper bounds for the baseline parsers, reflecting the error resulting from the conversion.\nDAGParser and UPARSE are most directly comparable to TUPASparse, as they also use a perceptron classifier with sparse features. TUPASparse considerably outperforms both, where DAGParser does not predict any remote edges in the out-ofdomain setting. TurboParser fares worse in this comparison, despite somewhat better results on remote edges. The LSTM parser of Dyer et al. (2015) obtains the highest primary F-score among the baseline parsers, with a considerable margin.\nUsing a feedforward NN and embedding features, TUPAMLP obtains higher scores than TUPASparse, but is outperformed by the LSTM parser on primary edges. However, using better input encoding, TUPABiLSTM obtains substantially higher scores than TUPAMLP and all other parsers,\n9For MaltParser we use the ARCEAGER transition set and SVM classifier. Other configurations yielded lower scores.\n7\n601\n602\n603\n604\n605\n606\n607\n608\n609\n610\n611\n612\n613\n614\n615\n616\n617\n618\n619\n620\n621\n622\n623\n624\n625\n626\n627\n628\n629\n630\n631\n632\n633\n634\n635\n636\n637\n638\n639\n640\n641\n642\n643\n644\n645\n646\n647\n648\n649\n650\n651\n652\n653\n654\n655\n656\n657\n658\n659\n660\n661\n662\n663\n664\n665\n666\n667\n668\n669\n670\n671\n672\n673\n674\n675\n676\n677\n678\n679\n680\n681\n682\n683\n684\n685\n686\n687\n688\n689\n690\n691\n692\n693\n694\n695\n696\n697\n698\n699\nWiki (in-domain) 20K Leagues (out-of-domain) Primary Remote Primary Remote\nLP LR LF LP LR LF LP LR LF LP LR LF TUPASparse 64.5 63.7 64.1 19.8 13.4 16 59.6 59.9 59.8 22.2 7.7 11.5 TUPAMLP 65.2 64.6 64.9 23.7 13.2 16.9 62.3 62.6 62.5 20.9 6.3 9.7 TUPABiLSTM 74.4 72.7 73.5 47.4 51.6 49.4 68.7 68.5 68.6 38.6 18.8 25.3 Bilexical Approximation (Dependency DAG Parsers)\nUpper Bound 91 58.3 91.3 43.4 DAGParser 61.8 55.8 58.6 9.5 0.5 1 56.4 50.6 53.4 – 0 0 TurboParser 57.7 46 51.2 77.8 1.8 3.7 50.3 37.7 43.1 100 0.4 0.8 Tree Approximation (Constituency Tree Parser)\nUpper Bound 100 – 100 – UPARSE 60.9 61.2 61.1 – – – 52.7 52.8 52.8 – – – Bilexical Tree Approximation (Dependency Tree Parsers)\nUpper Bound 91 – 91.3 – MaltParser 62.8 57.7 60.2 – – – 57.8 53 55.3 – – – LSTM Parser 73.2 66.9 69.9 – – – 66.1 61.1 63.5 – – –\nTable 2: Experimental results, in percents, on the Wiki test set (left) and the 20K Leagues set (right). Columns correspond to labeled precision, recall and F-score, for both primary and remote edges. F-score upper bounds are reported for the conversions. For the tree approximation experiments, only primary edges scores are reported, as they are unable to predict remote edges. TUPABiLSTM obtains the highest F-scores in all metrics, surpassing the bilexical parsers, tree parsers and other classifiers.\non both primary and remote edges, both in the in-domain and out-of-domain settings. Its performance in absolute terms, of 73.5% F-score on primary edges, is encouraging in light of UCCA’s inter-annotator agreement of 80–85% F-score on them (Abend and Rappoport, 2013).\nThe parsers resulting from tree approximation are unable to recover any remote edges, as these are removed in the conversion.10 The bilexical DAG parsers are quite limited in this respect as well. While some of the DAG parsers’ difficulty can be attributed to the conversion upper bound of 58.3%, this in itself cannot account for their poor performance on remote edges, which is an order of magnitude lower than that of TUPABiLSTM."
    }, {
      "heading" : "6 Related Work",
      "text" : "While earlier work on anchored11 semantic parsing has mostly concentrated on shallow semantic analysis, focusing on semantic role labeling of verbal argument structures, the focus has recently shifted to parsing of more elaborate representations that account for a wider range of phenomena.\n10We also experimented with a simpler version of TUPA lacking REMOTE transitions, obtaining an increase of up to 2 labeled F-score points on primary edges, at the cost of not being able to predict remote edges.\n11By anchored we mean that the semantic representation directly corresponds to the words and phrases of the text.\nGrammar-Based Parsing. Linguistically expressive grammars such as HPSG (Pollard and Sag, 1994), CCG (Steedman, 2000) and TAG (Joshi and Schabes, 1997) provide a theory of the syntax-semantics interface, and have been used as a basis for semantic parsers by defining compositional semantics on top of them (Flickinger, 2000; Bos, 2005, among others). Depending on the grammar and the implementation, such semantic parsers can support some or all of the structural properties UCCA exhibits. Nevertheless, this line of work differs from our grammarless approach in two important ways. First, the representations are different. UCCA does not attempt to model the syntax-semantics interface and is thus less coupled with syntax. Second, while grammar-based parsers explicitly model syntax, grammarless approaches, as presented here, directly model the relation between tokens and semantic structures.\nBroad-Coverage Semantic Parsing. Most closely related to this work is Broad-Coverage Semantic Dependency Parsing (SDP), addressed in two SemEval tasks (Oepen et al., 2014, 2015). Like UCCA parsing, SDP addresses a wide range of semantic phenomena, and supports discontinuous units and reentrancy. However, SDP uses bilexical dependencies, disallowing non-terminal nodes, useful for representing structures that have no clear head, such as co-\n8\n701\n702\n703\n704\n705\n706\n707\n708\n709\n710\n711\n712\n713\n714\n715\n716\n717\n718\n719\n720\n721\n722\n723\n724\n725\n726\n727\n728\n729\n730\n731\n732\n733\n734\n735\n736\n737\n738\n739\n740\n741\n742\n743\n744\n745\n746\n747\n748\n749\n750\n751\n752\n753\n754\n755\n756\n757\n758\n759\n760\n761\n762\n763\n764\n765\n766\n767\n768\n769\n770\n771\n772\n773\n774\n775\n776\n777\n778\n779\n780\n781\n782\n783\n784\n785\n786\n787\n788\n789\n790\n791\n792\n793\n794\n795\n796\n797\n798\n799\nordination (Ivanova et al., 2012). It also differs from UCCA in the type of distinctions it makes, which are more tightly coupled with syntactic considerations, where UCCA aims to capture purely semantic cross-linguistically applicable notions. For instance, the “poss” label in the DM target representation is used to annotate syntactic possessive constructions, regardless of whether they correspond to semantic ownership (e.g., “John’s dog”) or other semantic relations, such as marking an argument of a nominal predicate (e.g., “John’s kick”). UCCA reflects the difference between these constructions.\nRecent interest in SDP has yielded numerous works on graph parsing (Ribeyre et al., 2014; Thomson et al., 2014; Almeida and Martins, 2015; Du et al., 2015), including tree approximation (Agić and Koller, 2014; Schluter et al., 2014) and joint syntactic/semantic parsing (Henderson et al., 2013; Swayamdipta et al., 2016).\nAbstract Meaning Representation. Another line of work addresses parsing into AMRs (Flanigan et al., 2014; Vanderwende et al., 2015; Pust et al., 2015; Artzi et al., 2015), which, like UCCA, abstract away from syntactic distinctions and represent meaning directly, using OntoNotes predicates (Weischedel et al., 2013). Events in AMR may also be evoked by non-verbal predicates, including possessive constructions.\nUnlike in UCCA, the alignment between AMR concepts and the text is not explicitly marked. While sharing much of this work’s motivation, not anchoring the representation in the text complicates the parsing task, as it requires the alignment to be automatically (and imprecisely) detected. Indeed, despite considerable technical effort (Flanigan et al., 2014; Pourdamghani et al., 2014; Werling et al., 2015), concept identification is only about 80%–90% accurate. Furthermore, anchoring allows breaking down sentences into semantically meaningful sub-spans, which is useful for many applications (Fernández-González and Martins, 2015; Birch et al., 2016).\nSeveral transition-based AMR parsers have been proposed: CAMR assumes syntactically parsed input, processing dependency trees into AMR (Wang et al., 2015a,b, 2016; Goodman et al., 2016). In contrast, the parsers of Damonte et al. (2017) and Zhou et al. (2016) do not require syntactic pre-processing. Damonte et al. (2017) perform concept identification using a simple heuris-\ntic selecting the most frequent graph for each token, and Zhou et al. (2016) perform concept identification and parsing jointly. UCCA parsing does not require separately aligning the input tokens to the graph. TUPA creates non-terminal units as part of the parsing process.\nFurthermore, existing transition-based AMR parsers are not general DAG parsers. They are only able to predict a subset of reentrancies and discontinuities, as they may remove nodes before their parents have been predicted (Damonte et al., 2017). They are thus limited to a sub-class of AMRs in particular, and specifically cannot produce arbitrary DAG parses. TUPA’s transition set, on the other hand, allows general DAG parsing.12"
    }, {
      "heading" : "7 Conclusion",
      "text" : "We present TUPA, the first parser for UCCA. Evaluated in in-domain and out-of-domain settings, we show that coupled with a NN classifier and BiLSTM feature extractor, it accurately predicts UCCA graphs from text, outperforming a variety of strong baselines by a margin.\nDespite the recent diversity of semantic parsing work, the effectiveness of different approaches for structurally and semantically different schemes is not well-understood (Kuhlmann and Oepen, 2016). Our contribution to this literature is a general grammarless parser that supports multiple parents, discontinuous units and non-terminal nodes.\nFuture work will explore different target representations and conversion procedures (Kong et al., 2015), to compare different representations, suggesting ways for a data-driven design of semantic annotation. A parser for UCCA will enable using the framework for new tasks, in addition to existing applications such as machine translation evaluation (Birch et al., 2016). We believe UCCA’s merits in providing a cross-linguistically applicable, broad-coverage annotation will support ongoing efforts to incorporate deeper semantic structures into various applications, such as sentence simplification (Narayan and Gardent, 2014) and summarization (Liu et al., 2015)."
    } ],
    "references" : [ {
      "title" : "Universal Conceptual Cognitive Annotation See Appendix E for a proof sketch for the completeness",
      "author" : [ "Omri Abend", "Ari Rappoport" ],
      "venue" : null,
      "citeRegEx" : "Abend and Rappoport.,? \\Q2013\\E",
      "shortCiteRegEx" : "Abend and Rappoport.",
      "year" : 2013
    }, {
      "title" : "Potsdam: Semantic dependency parsing by bidirectional graph-tree transformations and syntactic parsing",
      "author" : [ "Željko Agić", "Alexander Koller." ],
      "venue" : "Proc. of SemEval. pages 465–470. http://aclweb.org/anthology/S14-2081.",
      "citeRegEx" : "Agić and Koller.,? 2014",
      "shortCiteRegEx" : "Agić and Koller.",
      "year" : 2014
    }, {
      "title" : "Semantic dependency graph parsing using tree approximations",
      "author" : [ "Željko Agić", "Alexander Koller", "Stephan Oepen." ],
      "venue" : "Proc. of IWCS. pages 217– 227. http://aclweb.org/anthology/W15-0126.",
      "citeRegEx" : "Agić et al\\.,? 2015",
      "shortCiteRegEx" : "Agić et al\\.",
      "year" : 2015
    }, {
      "title" : "Lisbon: Evaluating TurboSemanticParser on multiple languages and out-of-domain data",
      "author" : [ "Mariana S.C. Almeida", "André F.T. Martins." ],
      "venue" : "Proc. of SemEval. pages 970–973. http://aclweb.org/anthology/S15-2162.",
      "citeRegEx" : "Almeida and Martins.,? 2015",
      "shortCiteRegEx" : "Almeida and Martins.",
      "year" : 2015
    }, {
      "title" : "An incremental algorithm for transition-based CCG parsing",
      "author" : [ "Bharat Ram Ambati", "Tejaswini Deoskar", "Mark Johnson", "Mark Steedman." ],
      "venue" : "Proc. of NAACL. pages 53–63. http://aclweb.org/anthology/N15-1006.",
      "citeRegEx" : "Ambati et al\\.,? 2015",
      "shortCiteRegEx" : "Ambati et al\\.",
      "year" : 2015
    }, {
      "title" : "Shift-reduce CCG parsing using neural network models",
      "author" : [ "Bharat Ram Ambati", "Tejaswini Deoskar", "Mark Steedman." ],
      "venue" : "Proc. of NAACL-HLT . pages 447–453. http://aclweb.org/anthology/N161052.",
      "citeRegEx" : "Ambati et al\\.,? 2016",
      "shortCiteRegEx" : "Ambati et al\\.",
      "year" : 2016
    }, {
      "title" : "Globally normalized transition-based neural networks",
      "author" : [ "Daniel Andor", "Chris Alberti", "David Weiss", "Aliaksei Severyn", "Alessandro Presta", "Kuzman Ganchev", "Slav Petrov", "Michael Collins." ],
      "venue" : "Proc. of ACL. pages 2442–2452.",
      "citeRegEx" : "Andor et al\\.,? 2016",
      "shortCiteRegEx" : "Andor et al\\.",
      "year" : 2016
    }, {
      "title" : "Broad-coverage CCG semantic parsing with AMR",
      "author" : [ "Yoav Artzi", "Kenton Lee", "Luke Zettlemoyer." ],
      "venue" : "Proc. of EMNLP. pages 1699–1710. http://aclweb.org/anthology/D15-1198.",
      "citeRegEx" : "Artzi et al\\.,? 2015",
      "shortCiteRegEx" : "Artzi et al\\.",
      "year" : 2015
    }, {
      "title" : "Abstract Meaning Representation for sembanking",
      "author" : [ "Laura Banarescu", "Claire Bonial", "Shu Cai", "Madalina Georgescu", "Kira Griffitt", "Ulf Hermjakob", "Kevin Knight", "Martha Palmer", "Nathan Schneider." ],
      "venue" : "Proc. of the Linguistic Annotation",
      "citeRegEx" : "Banarescu et al\\.,? 2013",
      "shortCiteRegEx" : "Banarescu et al\\.",
      "year" : 2013
    }, {
      "title" : "HUME: Human UCCA-based evaluation of machine translation",
      "author" : [ "Alexandra Birch", "Omri Abend", "Ondřej Bojar", "Barry Haddow." ],
      "venue" : "Proc. of EMNLP. pages 1264–1274. http://aclweb.org/anthology/D16-1134.",
      "citeRegEx" : "Birch et al\\.,? 2016",
      "shortCiteRegEx" : "Birch et al\\.",
      "year" : 2016
    }, {
      "title" : "Towards wide-coverage semantic interpretation",
      "author" : [ "Johan Bos" ],
      "venue" : null,
      "citeRegEx" : "Bos.,? \\Q2005\\E",
      "shortCiteRegEx" : "Bos.",
      "year" : 2005
    }, {
      "title" : "A fast and accurate dependency parser using neural networks",
      "author" : [ "Danqi Chen", "Christopher Manning." ],
      "venue" : "Proc. of EMNLP. pages 740–750. http://aclweb.org/anthology/D14-1082.",
      "citeRegEx" : "Chen and Manning.,? 2014",
      "shortCiteRegEx" : "Chen and Manning.",
      "year" : 2014
    }, {
      "title" : "Incremental parsing with the perceptron algorithm",
      "author" : [ "Michael Collins", "Brian Roark." ],
      "venue" : "Proc. of ACL. pages 111–118. http://aclweb.org/anthology/P04-1015.",
      "citeRegEx" : "Collins and Roark.,? 2004",
      "shortCiteRegEx" : "Collins and Roark.",
      "year" : 2004
    }, {
      "title" : "Cognitive linguistics",
      "author" : [ "William Croft", "D Alan Cruse." ],
      "venue" : "Cambridge University Press.",
      "citeRegEx" : "Croft and Cruse.,? 2004",
      "shortCiteRegEx" : "Croft and Cruse.",
      "year" : 2004
    }, {
      "title" : "An incremental parser for abstract meaning representation",
      "author" : [ "Marco Damonte", "Shay B. Cohen", "Giorgio Satta." ],
      "venue" : "Proceedings of EACL. http://homepages.inf.ed.ac.uk/scohen/eacl17amr.pdf.",
      "citeRegEx" : "Damonte et al\\.,? 2017",
      "shortCiteRegEx" : "Damonte et al\\.",
      "year" : 2017
    }, {
      "title" : "Basic Linguistic Theory: Grammatical Topics, volume 2",
      "author" : [ "Robert M.W. Dixon." ],
      "venue" : "Oxford University Press.",
      "citeRegEx" : "Dixon.,? 2010a",
      "shortCiteRegEx" : "Dixon.",
      "year" : 2010
    }, {
      "title" : "Basic Linguistic Theory: Methodology, volume 1",
      "author" : [ "Robert M.W. Dixon." ],
      "venue" : "Oxford University Press.",
      "citeRegEx" : "Dixon.,? 2010b",
      "shortCiteRegEx" : "Dixon.",
      "year" : 2010
    }, {
      "title" : "Basic Linguistic Theory: Further Grammatical Topics, volume 3",
      "author" : [ "Robert M.W. Dixon." ],
      "venue" : "Oxford University Press.",
      "citeRegEx" : "Dixon.,? 2012",
      "shortCiteRegEx" : "Dixon.",
      "year" : 2012
    }, {
      "title" : "Peking: Building semantic dependency graphs with a hybrid parser",
      "author" : [ "Yantao Du", "Fan Zhang", "Xun Zhang", "Weiwei Sun", "Xiaojun Wan." ],
      "venue" : "Proc. of SemEval. pages 927–931. http://aclweb.org/anthology/S15-2154.",
      "citeRegEx" : "Du et al\\.,? 2015",
      "shortCiteRegEx" : "Du et al\\.",
      "year" : 2015
    }, {
      "title" : "Transitionbased dependeny parsing with stack long shortterm memory",
      "author" : [ "Chris Dyer", "Miguel Ballesteros", "Wang Ling", "Austin Matthews", "Noah A. Smith." ],
      "venue" : "Proc. of ACL. pages 334–343. http://aclweb.org/anthology/P15-1033.",
      "citeRegEx" : "Dyer et al\\.,? 2015",
      "shortCiteRegEx" : "Dyer et al\\.",
      "year" : 2015
    }, {
      "title" : "Parsing as reduction",
      "author" : [ "Daniel Fernández-González", "André FT Martins." ],
      "venue" : "Proc. of ACL. pages 1523–1533. http://aclweb.org/anthology/P15-1147.",
      "citeRegEx" : "Fernández.González and Martins.,? 2015",
      "shortCiteRegEx" : "Fernández.González and Martins.",
      "year" : 2015
    }, {
      "title" : "A discriminative graph-based parser for the abstract meaning representation",
      "author" : [ "Jeffrey Flanigan", "Sam Thomson", "Jaime Carbonell", "Chris Dyer", "Noah A. Smith." ],
      "venue" : "Proc. of ACL. pages 1426–1436. http://aclweb.org/anthology/P14-1134.",
      "citeRegEx" : "Flanigan et al\\.,? 2014",
      "shortCiteRegEx" : "Flanigan et al\\.",
      "year" : 2014
    }, {
      "title" : "On building a more efficient grammar by exploiting types",
      "author" : [ "Daniel Flickinger." ],
      "venue" : "Collaborative Language Engineering, CLSI, Stanford, CA, volume 6, pages 15–28.",
      "citeRegEx" : "Flickinger.,? 2000",
      "shortCiteRegEx" : "Flickinger.",
      "year" : 2000
    }, {
      "title" : "Learning sparser perceptron models",
      "author" : [ "Yoav Goldberg", "Michael Elhadad." ],
      "venue" : "Technical report. http://www.cs.bgu.ac.il/ ̃yoavg/publications.",
      "citeRegEx" : "Goldberg and Elhadad.,? 2011",
      "shortCiteRegEx" : "Goldberg and Elhadad.",
      "year" : 2011
    }, {
      "title" : "A dynamic oracle for arc-eager dependency parsing",
      "author" : [ "Yoav Goldberg", "Joakim Nivre." ],
      "venue" : "Proc. of COLING. pages 959–976. http://aclweb.org/anthology/C12-1059.",
      "citeRegEx" : "Goldberg and Nivre.,? 2012",
      "shortCiteRegEx" : "Goldberg and Nivre.",
      "year" : 2012
    }, {
      "title" : "Noise reduction and targeted exploration in imitation learning for Abstract Meaning Representation parsing",
      "author" : [ "James Goodman", "Andreas Vlachos", "Jason Naradowsky." ],
      "venue" : "Proc. of ACL. pages 1–",
      "citeRegEx" : "Goodman et al\\.,? 2016",
      "shortCiteRegEx" : "Goodman et al\\.",
      "year" : 2016
    }, {
      "title" : "Multilingual joint parsing of syntactic and semantic dependencies with a latent variable model",
      "author" : [ "James Henderson", "Paola Merlo", "Ivan Titov", "Gabriele Musillo." ],
      "venue" : "Computational Linguistics 39(4):949–998. http://cognet.mit.edu/node/27348.",
      "citeRegEx" : "Henderson et al\\.,? 2013",
      "shortCiteRegEx" : "Henderson et al\\.",
      "year" : 2013
    }, {
      "title" : "An improved non-monotonic transition system for dependency parsing",
      "author" : [ "Matthew Honnibal", "Mark Johnson." ],
      "venue" : "Proc. of EMNLP. pages 1373– 1378. http://aclweb.org/anthology/D15-1162.",
      "citeRegEx" : "Honnibal and Johnson.,? 2015",
      "shortCiteRegEx" : "Honnibal and Johnson.",
      "year" : 2015
    }, {
      "title" : "Who did what to whom? A contrastive study of syntacto-semantic dependencies",
      "author" : [ "Angelina Ivanova", "Stephan Oepen", "Lilja Øvrelid", "Dan Flickinger." ],
      "venue" : "Proc. of LAW. pages 2–11. http://aclweb.org/anthology/W12-3602.",
      "citeRegEx" : "Ivanova et al\\.,? 2012",
      "shortCiteRegEx" : "Ivanova et al\\.",
      "year" : 2012
    }, {
      "title" : "TreeAdjoining Grammars",
      "author" : [ "Aravind Joshi", "Yves Schabes." ],
      "venue" : "Grzegorz Rozenberg and Arto Salomaa, editors, Handbook of Formal Languages, Springer, Berlin, volume 3, pages 69–124.",
      "citeRegEx" : "Joshi and Schabes.,? 1997",
      "shortCiteRegEx" : "Joshi and Schabes.",
      "year" : 1997
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "Diederik P. Kingma", "Jimmy Ba." ],
      "venue" : "CoRR abs/1412.6980. http://arxiv.org/abs/1412.6980.",
      "citeRegEx" : "Kingma and Ba.,? 2014",
      "shortCiteRegEx" : "Kingma and Ba.",
      "year" : 2014
    }, {
      "title" : "Simple and accurate dependency parsing using bidirectional LSTM feature representations",
      "author" : [ "Eliyahu Kiperwasser", "Yoav Goldberg." ],
      "venue" : "TACL 4:313–327. https://transacl.org/ojs/index.php/tacl/article/view/885.",
      "citeRegEx" : "Kiperwasser and Goldberg.,? 2016",
      "shortCiteRegEx" : "Kiperwasser and Goldberg.",
      "year" : 2016
    }, {
      "title" : "Transforming dependencies into phrase structures",
      "author" : [ "Lingpeng Kong", "Alexander M. Rush", "Noah A. Smith." ],
      "venue" : "Proc. of NAACL HLT . https://aclweb.org/anthology/N15-1080.",
      "citeRegEx" : "Kong et al\\.,? 2015",
      "shortCiteRegEx" : "Kong et al\\.",
      "year" : 2015
    }, {
      "title" : "Towards a catalogue of linguistic graph banks",
      "author" : [ "Marco Kuhlmann", "Stephan Oepen." ],
      "venue" : "Computational Linguistics https://mn.uio.no/ifi/english/people/aca/oe/cl.pdf.",
      "citeRegEx" : "Kuhlmann and Oepen.,? 2016",
      "shortCiteRegEx" : "Kuhlmann and Oepen.",
      "year" : 2016
    }, {
      "title" : "Toward abstractive summarization using semantic representations",
      "author" : [ "Fei Liu", "Jeffrey Flanigan", "Sam Thomson", "Norman Sadeh", "Noah A. Smith." ],
      "venue" : "Proc. of NAACL. pages 1077–1086. http://aclweb.org/anthology/N15-1114.",
      "citeRegEx" : "Liu et al\\.,? 2015",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2015
    }, {
      "title" : "Discontinuous incremental shift-reduce parsing",
      "author" : [ "Wolfgang Maier." ],
      "venue" : "Proc. of ACL. pages 1202– 1212. http://aclweb.org/anthology/P15-1116.",
      "citeRegEx" : "Maier.,? 2015",
      "shortCiteRegEx" : "Maier.",
      "year" : 2015
    }, {
      "title" : "Discontinuous parsing with continuous trees",
      "author" : [ "Wolfgang Maier", "Timm Lichte." ],
      "venue" : "Proc. of Workshop on Discontinuous Structures in NLP. pages 47–",
      "citeRegEx" : "Maier and Lichte.,? 2016",
      "shortCiteRegEx" : "Maier and Lichte.",
      "year" : 2016
    }, {
      "title" : "Efficient estimation of word representations in vector space",
      "author" : [ "Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean." ],
      "venue" : "CoRR abs/1301.3781. https://arxiv.org/pdf/1301.3781.",
      "citeRegEx" : "Mikolov et al\\.,? 2013",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2013
    }, {
      "title" : "Neural shift-reduce CCG semantic parsing",
      "author" : [ "Dipendra K Misra", "Yoav Artzi." ],
      "venue" : "Proc. of EMNLP. pages 1775–1786. http://aclweb.org/anthology/D16-1183.",
      "citeRegEx" : "Misra and Artzi.,? 2016",
      "shortCiteRegEx" : "Misra and Artzi.",
      "year" : 2016
    }, {
      "title" : "Hybrid simplification using deep semantics and machine translation",
      "author" : [ "Shashi Narayan", "Claire Gardent." ],
      "venue" : "Proc. of ACL. pages 435–445. http://aclweb.org/anthology/P14-1041.",
      "citeRegEx" : "Narayan and Gardent.,? 2014",
      "shortCiteRegEx" : "Narayan and Gardent.",
      "year" : 2014
    }, {
      "title" : "DyNet: The dynamic neural network toolkit",
      "author" : [ "Lingpeng Kong", "Adhiguna Kuncoro", "Gaurav Kumar", "Chaitanya Malaviya", "Paul Michel", "Yusuke Oda", "Matthew Richardson", "Naomi Saphra", "Swabha Swayamdipta", "Pengcheng Yin." ],
      "venue" : "arXiv preprint",
      "citeRegEx" : "Kong et al\\.,? 2017",
      "shortCiteRegEx" : "Kong et al\\.",
      "year" : 2017
    }, {
      "title" : "An efficient algorithm for projective dependency parsing",
      "author" : [ "Joakim Nivre." ],
      "venue" : "Proc. of IWPT . pages 149–160. http://aclweb.org/anthology/W06-2933.",
      "citeRegEx" : "Nivre.,? 2003",
      "shortCiteRegEx" : "Nivre.",
      "year" : 2003
    }, {
      "title" : "Non-projective dependency parsing in expected linear time",
      "author" : [ "Joakim Nivre." ],
      "venue" : "Proc. of ACL. pages 351–359. http://aclweb.org/anthology/P09-1040.",
      "citeRegEx" : "Nivre.,? 2009",
      "shortCiteRegEx" : "Nivre.",
      "year" : 2009
    }, {
      "title" : "MaltParser: A language-independent system for data-driven dependency parsing",
      "author" : [ "Joakim Nivre", "Johan Hall", "Jens Nilsson", "Atanas Chanev", "Gülsen Eryigit", "Sandra Kübler", "Svetoslav Marinov", "Erwin Marsi." ],
      "venue" : "Natural Language Engineering",
      "citeRegEx" : "Nivre et al\\.,? 2007",
      "shortCiteRegEx" : "Nivre et al\\.",
      "year" : 2007
    }, {
      "title" : "SemEval 2015 task 18: Broad-coverage semantic dependency parsing",
      "author" : [ "Stephan Oepen", "Marco Kuhlmann", "Yusuke Miyao", "Daniel Zeman", "Silvie Cinková", "Dan Flickinger", "Jan Hajič", "Zdeňka Urešová." ],
      "venue" : "Proc. of SemEval. pages 915–926.",
      "citeRegEx" : "Oepen et al\\.,? 2015",
      "shortCiteRegEx" : "Oepen et al\\.",
      "year" : 2015
    }, {
      "title" : "SemEval 2014 task 8: Broad-coverage semantic dependency parsing",
      "author" : [ "Stephan Oepen", "Marco Kuhlmann", "Yusuke Miyao", "Daniel Zeman", "Dan Flickinger", "Jan Hajič", "Angelina Ivanova", "Yi Zhang." ],
      "venue" : "Proc. of SemEval. pages 63–72.",
      "citeRegEx" : "Oepen et al\\.,? 2014",
      "shortCiteRegEx" : "Oepen et al\\.",
      "year" : 2014
    }, {
      "title" : "Head Driven Phrase Structure Grammar",
      "author" : [ "Carl Pollard", "Ivan Sag." ],
      "venue" : "CSLI Publications, Stanford, CA.",
      "citeRegEx" : "Pollard and Sag.,? 1994",
      "shortCiteRegEx" : "Pollard and Sag.",
      "year" : 1994
    }, {
      "title" : "Aligning English strings with abstract meaning representation graphs",
      "author" : [ "Nima Pourdamghani", "Yang Gao", "Ulf Hermjakob", "Kevin Knight." ],
      "venue" : "Proc. of EMNLP. pages 425–429. http://aclweb.org/anthology/D14-1048.",
      "citeRegEx" : "Pourdamghani et al\\.,? 2014",
      "shortCiteRegEx" : "Pourdamghani et al\\.",
      "year" : 2014
    }, {
      "title" : "Parsing English into abstract meaning representation using syntax-based machine translation",
      "author" : [ "Michael Pust", "Ulf Hermjakob", "Kevin Knight", "Daniel Marcu", "Jonathan May." ],
      "venue" : "Proc. of EMNLP. pages 1143–1154.",
      "citeRegEx" : "Pust et al\\.,? 2015",
      "shortCiteRegEx" : "Pust et al\\.",
      "year" : 2015
    }, {
      "title" : "Alpage: Transitionbased semantic graph parsing with syntactic features",
      "author" : [ "Corentin Ribeyre", "Eric Villemonte de la Clergerie", "Djamé Seddah." ],
      "venue" : "Proc. of SemEval. pages 97–103. http://aclweb.org/anthology/S14-2012.",
      "citeRegEx" : "Ribeyre et al\\.,? 2014",
      "shortCiteRegEx" : "Ribeyre et al\\.",
      "year" : 2014
    }, {
      "title" : "A classifierbased parser with linear run-time complexity",
      "author" : [ "Kenji Sagae", "Alon Lavie." ],
      "venue" : "Proc. of IWPT . pages 125–132. http://aclweb.org/anthology/W05-1513.",
      "citeRegEx" : "Sagae and Lavie.,? 2005",
      "shortCiteRegEx" : "Sagae and Lavie.",
      "year" : 2005
    }, {
      "title" : "Shift-reduce dependency DAG parsing",
      "author" : [ "Kenji Sagae", "Jun’ichi Tsujii" ],
      "venue" : "In Proc. of COLING",
      "citeRegEx" : "Sagae and Tsujii.,? \\Q2008\\E",
      "shortCiteRegEx" : "Sagae and Tsujii.",
      "year" : 2008
    }, {
      "title" : "Copenhagen-Malmö: Tree approximations of semantic parsing problems",
      "author" : [ "Natalie Schluter", "Anders Søgaard", "Jakob Elming", "Dirk Hovy", "Barbara Plank", "Héctor Martı́nez Alonso", "Anders Johanssen", "Sigrid Klerke" ],
      "venue" : "In Proc. of SemEval",
      "citeRegEx" : "Schluter et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Schluter et al\\.",
      "year" : 2014
    }, {
      "title" : "Discriminative lexical semantic segmentation with gaps: running the MWE gamut",
      "author" : [ "Nathan Schneider", "Emily Danchik", "Chris Dyer", "Noah A Smith." ],
      "venue" : "TACL 2:193–206. http://aclweb.org/anthology/Q14-1016.pdf.",
      "citeRegEx" : "Schneider et al\\.,? 2014",
      "shortCiteRegEx" : "Schneider et al\\.",
      "year" : 2014
    }, {
      "title" : "The Syntactic Process",
      "author" : [ "Mark Steedman." ],
      "venue" : "MIT Press, Cambridge, MA.",
      "citeRegEx" : "Steedman.,? 2000",
      "shortCiteRegEx" : "Steedman.",
      "year" : 2000
    }, {
      "title" : "Conceptual annotations preserve structure across translations: A French-English case study",
      "author" : [ "Elior Sulem", "Omri Abend", "Ari Rappoport." ],
      "venue" : "Proc. of S2MT . pages 11–22. http://aclweb.org/anthology/W15-3502.",
      "citeRegEx" : "Sulem et al\\.,? 2015",
      "shortCiteRegEx" : "Sulem et al\\.",
      "year" : 2015
    }, {
      "title" : "Greedy, joint syntactic-semantic parsing with stack LSTMs",
      "author" : [ "Swabha Swayamdipta", "Miguel Ballesteros", "Chris Dyer", "Noah A. Smith." ],
      "venue" : "Proc. of CoNLL. pages 187–197. http://aclweb.org/anthology/K16-1019.",
      "citeRegEx" : "Swayamdipta et al\\.,? 2016",
      "shortCiteRegEx" : "Swayamdipta et al\\.",
      "year" : 2016
    }, {
      "title" : "Transitionbased dependency DAG parsing using dynamic oracles",
      "author" : [ "Alper Tokgöz", "Gülsen Eryiğit." ],
      "venue" : "Proc. of ACL Student Research Workshop. pages 22–27. http://aclweb.org/anthology/P153004.",
      "citeRegEx" : "Tokgöz and Eryiğit.,? 2015",
      "shortCiteRegEx" : "Tokgöz and Eryiğit.",
      "year" : 2015
    }, {
      "title" : "An AMR parser for English, French, German, Spanish and Japanese and a new AMRannotated corpus",
      "author" : [ "Lucy Vanderwende", "Arul Menezes", "Chris Quirk." ],
      "venue" : "Proc. of NAACL. pages 26–30. http://aclweb.org/anthology/N15-3006.",
      "citeRegEx" : "Vanderwende et al\\.,? 2015",
      "shortCiteRegEx" : "Vanderwende et al\\.",
      "year" : 2015
    }, {
      "title" : "CAMR at SemEval2016 task 8: An extended transition-based amr parser",
      "author" : [ "Chuan Wang", "Sameer Pradhan", "Xiaoman Pan", "Heng Ji", "Nianwen Xue." ],
      "venue" : "Proc. of SemEval. pages 1173–1178. http://aclweb.org/anthology/S16-1181.",
      "citeRegEx" : "Wang et al\\.,? 2016",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2016
    }, {
      "title" : "Boosting transition-based AMR parsing with refined actions and auxiliary analyzers",
      "author" : [ "Chuan Wang", "Nianwen Xue", "Sameer Pradhan." ],
      "venue" : "Proc. of ACL. pages 857–862. http://aclweb.org/anthology/P15-2141.",
      "citeRegEx" : "Wang et al\\.,? 2015a",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2015
    }, {
      "title" : "A transition-based algorithm for AMR parsing",
      "author" : [ "Chuan Wang", "Nianwen Xue", "Sameer Pradhan." ],
      "venue" : "Proc. of NAACL. pages 366–375. http://aclweb.org/anthology/N15-1040.",
      "citeRegEx" : "Wang et al\\.,? 2015b",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2015
    }, {
      "title" : "OntoNotes release 5.0 LDC2013T19",
      "author" : [ "Ralph Weischedel", "Martha Palmer", "Mitchell Marcus", "Eduard Hovy", "Sameer Pradhan", "Lance Ramshaw", "Nianwen Xue", "Ann Taylor", "Jeff Kaufman", "Michelle Franchini" ],
      "venue" : null,
      "citeRegEx" : "Weischedel et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Weischedel et al\\.",
      "year" : 2013
    }, {
      "title" : "Robust subgraph generation improves abstract meaning representation parsing",
      "author" : [ "Keenon Werling", "Gabor Angeli", "Christopher D. Manning." ],
      "venue" : "Proc. of ACL. pages 982–991. http://aclweb.org/anthology/P15-1095.",
      "citeRegEx" : "Werling et al\\.,? 2015",
      "shortCiteRegEx" : "Werling et al\\.",
      "year" : 2015
    }, {
      "title" : "Transition-based parsing of the Chinese treebank using a global discriminative model",
      "author" : [ "Yue Zhang", "Stephen Clark." ],
      "venue" : "Proc. of IWPT . Association for Computational Linguistics, pages 162–171. http://aclweb.org/anthology/W09-3825.",
      "citeRegEx" : "Zhang and Clark.,? 2009",
      "shortCiteRegEx" : "Zhang and Clark.",
      "year" : 2009
    }, {
      "title" : "Shift-reduce CCG parsing",
      "author" : [ "Yue Zhang", "Stephen Clark." ],
      "venue" : "Proc. of ACL. pages 683–692. http://aclweb.org/anthology/P11-1069.",
      "citeRegEx" : "Zhang and Clark.,? 2011",
      "shortCiteRegEx" : "Zhang and Clark.",
      "year" : 2011
    }, {
      "title" : "AMR parsing with an incremental joint model",
      "author" : [ "Junsheng Zhou", "Feiyu Xu", "Hans Uszkoreit", "Weiguang Qu", "Ran Li", "Yanhui Gu." ],
      "venue" : "Proc. of EMNLP. pages 680–689. http://aclweb.org/anthology/D16-1065.",
      "citeRegEx" : "Zhou et al\\.,? 2016",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2016
    }, {
      "title" : "Fast and accurate shiftreduce constituent parsing",
      "author" : [ "Muhua Zhu", "Yue Zhang", "Wenliang Chen", "Min Zhang", "Jingbo Zhu." ],
      "venue" : "Proc. of ACL. pages 434–443. http://aclweb.org/anthology/P13-1043.",
      "citeRegEx" : "Zhu et al\\.,? 2013",
      "shortCiteRegEx" : "Zhu et al\\.",
      "year" : 2013
    } ],
    "referenceMentions" : [ {
      "referenceID" : 13,
      "context" : "Universal Conceptual Cognitive Annotation (UCCA, Abend and Rappoport, 2013) is a crosslinguistically applicable semantic representation scheme, building on the established Basic Linguistic Theory typological framework (Dixon, 2010a,b, 2012), and Cognitive Linguistics literature (Croft and Cruse, 2004).",
      "startOffset" : 279,
      "endOffset" : 302
    }, {
      "referenceID" : 55,
      "context" : "It has demonstrated applicability to multiple languages, including English, French, German and Czech, support for rapid annotation, and stability under translation (Sulem et al., 2015).",
      "startOffset" : 164,
      "endOffset" : 184
    }, {
      "referenceID" : 9,
      "context" : "It has also proven useful for machine translation evaluation (Birch et al., 2016).",
      "startOffset" : 61,
      "endOffset" : 81
    }, {
      "referenceID" : 19,
      "context" : "Transition-based techniques are a natural starting point for UCCA parsing, given the conceptual similarity of UCCA’s distinctions, centered around predicate-argument structures, to distinctions expressed by dependency schemes, and the achievements of transition-based methods in dependency parsing (Dyer et al., 2015; Andor et al., 2016; Kiperwasser and Goldberg, 2016).",
      "startOffset" : 298,
      "endOffset" : 369
    }, {
      "referenceID" : 6,
      "context" : "Transition-based techniques are a natural starting point for UCCA parsing, given the conceptual similarity of UCCA’s distinctions, centered around predicate-argument structures, to distinctions expressed by dependency schemes, and the achievements of transition-based methods in dependency parsing (Dyer et al., 2015; Andor et al., 2016; Kiperwasser and Goldberg, 2016).",
      "startOffset" : 298,
      "endOffset" : 369
    }, {
      "referenceID" : 31,
      "context" : "Transition-based techniques are a natural starting point for UCCA parsing, given the conceptual similarity of UCCA’s distinctions, centered around predicate-argument structures, to distinctions expressed by dependency schemes, and the achievements of transition-based methods in dependency parsing (Dyer et al., 2015; Andor et al., 2016; Kiperwasser and Goldberg, 2016).",
      "startOffset" : 298,
      "endOffset" : 369
    }, {
      "referenceID" : 51,
      "context" : "We are further motivated by the strength of transition-based methods in related tasks, including dependency graph parsing (Sagae and Tsujii, 2008; Ribeyre et al., 2014; Tokgöz and Eryiğit, 2015), constituency parsing (Sagae and Lavie, 2005; Zhang and Clark, 2009; Zhu et al.",
      "startOffset" : 122,
      "endOffset" : 194
    }, {
      "referenceID" : 49,
      "context" : "We are further motivated by the strength of transition-based methods in related tasks, including dependency graph parsing (Sagae and Tsujii, 2008; Ribeyre et al., 2014; Tokgöz and Eryiğit, 2015), constituency parsing (Sagae and Lavie, 2005; Zhang and Clark, 2009; Zhu et al.",
      "startOffset" : 122,
      "endOffset" : 194
    }, {
      "referenceID" : 57,
      "context" : "We are further motivated by the strength of transition-based methods in related tasks, including dependency graph parsing (Sagae and Tsujii, 2008; Ribeyre et al., 2014; Tokgöz and Eryiğit, 2015), constituency parsing (Sagae and Lavie, 2005; Zhang and Clark, 2009; Zhu et al.",
      "startOffset" : 122,
      "endOffset" : 194
    }, {
      "referenceID" : 50,
      "context" : ", 2014; Tokgöz and Eryiğit, 2015), constituency parsing (Sagae and Lavie, 2005; Zhang and Clark, 2009; Zhu et al., 2013; Maier, 2015; Maier and Lichte, 2016), AMR parsing (Wang et al.",
      "startOffset" : 56,
      "endOffset" : 157
    }, {
      "referenceID" : 64,
      "context" : ", 2014; Tokgöz and Eryiğit, 2015), constituency parsing (Sagae and Lavie, 2005; Zhang and Clark, 2009; Zhu et al., 2013; Maier, 2015; Maier and Lichte, 2016), AMR parsing (Wang et al.",
      "startOffset" : 56,
      "endOffset" : 157
    }, {
      "referenceID" : 67,
      "context" : ", 2014; Tokgöz and Eryiğit, 2015), constituency parsing (Sagae and Lavie, 2005; Zhang and Clark, 2009; Zhu et al., 2013; Maier, 2015; Maier and Lichte, 2016), AMR parsing (Wang et al.",
      "startOffset" : 56,
      "endOffset" : 157
    }, {
      "referenceID" : 35,
      "context" : ", 2014; Tokgöz and Eryiğit, 2015), constituency parsing (Sagae and Lavie, 2005; Zhang and Clark, 2009; Zhu et al., 2013; Maier, 2015; Maier and Lichte, 2016), AMR parsing (Wang et al.",
      "startOffset" : 56,
      "endOffset" : 157
    }, {
      "referenceID" : 36,
      "context" : ", 2014; Tokgöz and Eryiğit, 2015), constituency parsing (Sagae and Lavie, 2005; Zhang and Clark, 2009; Zhu et al., 2013; Maier, 2015; Maier and Lichte, 2016), AMR parsing (Wang et al.",
      "startOffset" : 56,
      "endOffset" : 157
    }, {
      "referenceID" : 38,
      "context" : ", 2013; Maier, 2015; Maier and Lichte, 2016), AMR parsing (Wang et al., 2015a,b, 2016; Misra and Artzi, 2016; Goodman et al., 2016; Zhou et al., 2016; Damonte et al., 2017) and CCG parsing (Zhang and Clark, 2011; Ambati et al.",
      "startOffset" : 58,
      "endOffset" : 172
    }, {
      "referenceID" : 25,
      "context" : ", 2013; Maier, 2015; Maier and Lichte, 2016), AMR parsing (Wang et al., 2015a,b, 2016; Misra and Artzi, 2016; Goodman et al., 2016; Zhou et al., 2016; Damonte et al., 2017) and CCG parsing (Zhang and Clark, 2011; Ambati et al.",
      "startOffset" : 58,
      "endOffset" : 172
    }, {
      "referenceID" : 66,
      "context" : ", 2013; Maier, 2015; Maier and Lichte, 2016), AMR parsing (Wang et al., 2015a,b, 2016; Misra and Artzi, 2016; Goodman et al., 2016; Zhou et al., 2016; Damonte et al., 2017) and CCG parsing (Zhang and Clark, 2011; Ambati et al.",
      "startOffset" : 58,
      "endOffset" : 172
    }, {
      "referenceID" : 14,
      "context" : ", 2013; Maier, 2015; Maier and Lichte, 2016), AMR parsing (Wang et al., 2015a,b, 2016; Misra and Artzi, 2016; Goodman et al., 2016; Zhou et al., 2016; Damonte et al., 2017) and CCG parsing (Zhang and Clark, 2011; Ambati et al.",
      "startOffset" : 58,
      "endOffset" : 172
    }, {
      "referenceID" : 65,
      "context" : ", 2017) and CCG parsing (Zhang and Clark, 2011; Ambati et al., 2015, 2016).",
      "startOffset" : 24,
      "endOffset" : 74
    }, {
      "referenceID" : 8,
      "context" : "Section 6 discusses UCCA in the context of other semantic schemes, such as AMR (Banarescu et al., 2013).",
      "startOffset" : 79,
      "endOffset" : 103
    }, {
      "referenceID" : 53,
      "context" : ", with multi-word expressions (Schneider et al., 2014).",
      "startOffset" : 30,
      "endOffset" : 54
    }, {
      "referenceID" : 41,
      "context" : "Transition-based parsers (Nivre, 2003) scan the text from start to end, and create the parse incrementally by applying a transition at each step to the parser’s state, defined using three data structures: a buffer B of tokens and nodes to be processed, a stack S of nodes currently being processed, and a graph G = (V,E, `) of constructed nodes and edges, where V is the set of nodes, E is the set of edges, and ` : E → L is the label function, L being the set of possible labels.",
      "startOffset" : 25,
      "endOffset" : 38
    }, {
      "referenceID" : 50,
      "context" : "In addition to the standard SHIFT and REDUCE operations, we follow previous work in transition-based constituency parsing (Sagae and Lavie, 2005), adding the NODE transition for creating new non-terminal nodes.",
      "startOffset" : 122,
      "endOffset" : 145
    }, {
      "referenceID" : 51,
      "context" : "To support the prediction of multiple parents, node and edge transitions leave the stack unchanged, as in other work on transition-based dependency graph parsing (Sagae and Tsujii, 2008; Ribeyre et al., 2014; Tokgöz and Eryiğit, 2015).",
      "startOffset" : 162,
      "endOffset" : 234
    }, {
      "referenceID" : 49,
      "context" : "To support the prediction of multiple parents, node and edge transitions leave the stack unchanged, as in other work on transition-based dependency graph parsing (Sagae and Tsujii, 2008; Ribeyre et al., 2014; Tokgöz and Eryiğit, 2015).",
      "startOffset" : 162,
      "endOffset" : 234
    }, {
      "referenceID" : 57,
      "context" : "To support the prediction of multiple parents, node and edge transitions leave the stack unchanged, as in other work on transition-based dependency graph parsing (Sagae and Tsujii, 2008; Ribeyre et al., 2014; Tokgöz and Eryiğit, 2015).",
      "startOffset" : 162,
      "endOffset" : 234
    }, {
      "referenceID" : 42,
      "context" : "To handle discontinuous nodes, SWAP pops the second node on the stack and adds it to the top of the buffer, as with the similarly named transition in previous work (Nivre, 2009; Maier, 2015).",
      "startOffset" : 164,
      "endOffset" : 190
    }, {
      "referenceID" : 35,
      "context" : "To handle discontinuous nodes, SWAP pops the second node on the stack and adds it to the top of the buffer, as with the similarly named transition in previous work (Nivre, 2009; Maier, 2015).",
      "startOffset" : 164,
      "endOffset" : 190
    }, {
      "referenceID" : 11,
      "context" : "The choice of classifier and feature representation has been shown to play an important role in transition-based parsing (Chen and Manning, 2014; Andor et al., 2016; Kiperwasser and Goldberg, 2016).",
      "startOffset" : 121,
      "endOffset" : 197
    }, {
      "referenceID" : 6,
      "context" : "The choice of classifier and feature representation has been shown to play an important role in transition-based parsing (Chen and Manning, 2014; Andor et al., 2016; Kiperwasser and Goldberg, 2016).",
      "startOffset" : 121,
      "endOffset" : 197
    }, {
      "referenceID" : 31,
      "context" : "The choice of classifier and feature representation has been shown to play an important role in transition-based parsing (Chen and Manning, 2014; Andor et al., 2016; Kiperwasser and Goldberg, 2016).",
      "startOffset" : 121,
      "endOffset" : 197
    }, {
      "referenceID" : 12,
      "context" : ", Maier and Lichte, 2016), TUPASparse uses a linear classifier with sparse features, trained with the averaged structured perceptron algorithm (Collins and Roark, 2004) and MINUPDATE (Goldberg and Elhadad, 2011): each feature requires a minimum number of updates in training to be included in the model.",
      "startOffset" : 143,
      "endOffset" : 168
    }, {
      "referenceID" : 23,
      "context" : ", Maier and Lichte, 2016), TUPASparse uses a linear classifier with sparse features, trained with the averaged structured perceptron algorithm (Collins and Roark, 2004) and MINUPDATE (Goldberg and Elhadad, 2011): each feature requires a minimum number of updates in training to be included in the model.",
      "startOffset" : 183,
      "endOffset" : 211
    }, {
      "referenceID" : 11,
      "context" : "Changing the model to a feedforward neural network with dense embedding features, TUPAMLP (“multi-layer perceptron”), uses an architecture similar to that of Chen and Manning (2014), but with two rectified linear layers instead of one layer with cube activation.",
      "startOffset" : 158,
      "endOffset" : 182
    }, {
      "referenceID" : 31,
      "context" : "dense embedding features, an architecture similar to Kiperwasser and Goldberg (2016). The BiLSTM runs on the input tokens in forward and backward directions, yielding a vector representation that is then concatenated with dense features representing the parser state (e.",
      "startOffset" : 53,
      "endOffset" : 85
    }, {
      "referenceID" : 64,
      "context" : "We also use bi- and trigram features based on these values (Zhang and Clark, 2009; Zhu et al., 2013), features related to discontinuous nodes (Maier, 2015, including separating punctuation and gap type), features representing existing edges and the number of parents and children, as well as the past actions taken by the parser.",
      "startOffset" : 59,
      "endOffset" : 100
    }, {
      "referenceID" : 67,
      "context" : "We also use bi- and trigram features based on these values (Zhang and Clark, 2009; Zhu et al., 2013), features related to discontinuous nodes (Maier, 2015, including separating punctuation and gap type), features representing existing edges and the number of parents and children, as well as the past actions taken by the parser.",
      "startOffset" : 59,
      "endOffset" : 100
    }, {
      "referenceID" : 31,
      "context" : "In addition to dropout between NN layers, we apply word dropout (Kiperwasser and Goldberg, 2016): with a certain probability, the embedding for a word is replaced with a zero vector.",
      "startOffset" : 64,
      "endOffset" : 96
    }, {
      "referenceID" : 24,
      "context" : "For training the transition classifiers, we use a dynamic oracle (Goldberg and Nivre, 2012), i.",
      "startOffset" : 65,
      "endOffset" : 91
    }, {
      "referenceID" : 27,
      "context" : "POS tags and syntactic dependency labels are extracted using spaCy (Honnibal and Johnson, 2015).",
      "startOffset" : 67,
      "endOffset" : 95
    }, {
      "referenceID" : 30,
      "context" : "jective function and optimize the NN classifiers with the Adam optimizer (Kingma and Ba, 2014).",
      "startOffset" : 73,
      "endOffset" : 94
    }, {
      "referenceID" : 2,
      "context" : "Our approach is similar to the tree approximation approach used for dependency graph parsing (Agić et al., 2015; Fernández-González and Martins, 2015), where dependency graphs were converted into dependency trees and then parsed by dependency tree parsers.",
      "startOffset" : 93,
      "endOffset" : 150
    }, {
      "referenceID" : 20,
      "context" : "Our approach is similar to the tree approximation approach used for dependency graph parsing (Agić et al., 2015; Fernández-González and Martins, 2015), where dependency graphs were converted into dependency trees and then parsed by dependency tree parsers.",
      "startOffset" : 93,
      "endOffset" : 150
    }, {
      "referenceID" : 49,
      "context" : "We evaluate two bilexical graph semantic dependency parsers: DAGParser (Ribeyre et al., 2014), the leading transition-based parser in SemEval 2014 (Oepen et al.",
      "startOffset" : 71,
      "endOffset" : 93
    }, {
      "referenceID" : 45,
      "context" : ", 2014), the leading transition-based parser in SemEval 2014 (Oepen et al., 2014) and TurboParser (Almeida and Martins, 2015), a graph-based parser from SemEval 2015 (Oepen et al.",
      "startOffset" : 61,
      "endOffset" : 81
    }, {
      "referenceID" : 3,
      "context" : ", 2014) and TurboParser (Almeida and Martins, 2015), a graph-based parser from SemEval 2015 (Oepen et al.",
      "startOffset" : 24,
      "endOffset" : 51
    }, {
      "referenceID" : 44,
      "context" : ", 2014) and TurboParser (Almeida and Martins, 2015), a graph-based parser from SemEval 2015 (Oepen et al., 2015); UPARSE (Maier and Lichte, 2016), a transition-based constituency parser supporting discontinuous constituents; and two bilexical tree parsers: MaltParser (Nivre et al.",
      "startOffset" : 92,
      "endOffset" : 112
    }, {
      "referenceID" : 36,
      "context" : ", 2015); UPARSE (Maier and Lichte, 2016), a transition-based constituency parser supporting discontinuous constituents; and two bilexical tree parsers: MaltParser (Nivre et al.",
      "startOffset" : 16,
      "endOffset" : 40
    }, {
      "referenceID" : 43,
      "context" : ", 2015); UPARSE (Maier and Lichte, 2016), a transition-based constituency parser supporting discontinuous constituents; and two bilexical tree parsers: MaltParser (Nivre et al., 2007),9 and the stack LSTM-based parser of Dyer et al.",
      "startOffset" : 163,
      "endOffset" : 183
    }, {
      "referenceID" : 19,
      "context" : "The LSTM parser of Dyer et al. (2015) obtains the highest primary F-score among the baseline parsers, with a considerable margin.",
      "startOffset" : 19,
      "endOffset" : 38
    }, {
      "referenceID" : 0,
      "context" : "5% F-score on primary edges, is encouraging in light of UCCA’s inter-annotator agreement of 80–85% F-score on them (Abend and Rappoport, 2013).",
      "startOffset" : 115,
      "endOffset" : 142
    }, {
      "referenceID" : 46,
      "context" : "Linguistically expressive grammars such as HPSG (Pollard and Sag, 1994), CCG (Steedman, 2000) and TAG (Joshi and Schabes, 1997) provide a theory of the syntax-semantics interface, and have been used as a basis for semantic parsers by defining compositional semantics on top of them (Flickinger, 2000; Bos, 2005, among others).",
      "startOffset" : 48,
      "endOffset" : 71
    }, {
      "referenceID" : 54,
      "context" : "Linguistically expressive grammars such as HPSG (Pollard and Sag, 1994), CCG (Steedman, 2000) and TAG (Joshi and Schabes, 1997) provide a theory of the syntax-semantics interface, and have been used as a basis for semantic parsers by defining compositional semantics on top of them (Flickinger, 2000; Bos, 2005, among others).",
      "startOffset" : 77,
      "endOffset" : 93
    }, {
      "referenceID" : 29,
      "context" : "Linguistically expressive grammars such as HPSG (Pollard and Sag, 1994), CCG (Steedman, 2000) and TAG (Joshi and Schabes, 1997) provide a theory of the syntax-semantics interface, and have been used as a basis for semantic parsers by defining compositional semantics on top of them (Flickinger, 2000; Bos, 2005, among others).",
      "startOffset" : 102,
      "endOffset" : 127
    }, {
      "referenceID" : 28,
      "context" : "ordination (Ivanova et al., 2012).",
      "startOffset" : 11,
      "endOffset" : 33
    }, {
      "referenceID" : 49,
      "context" : "Recent interest in SDP has yielded numerous works on graph parsing (Ribeyre et al., 2014; Thomson et al., 2014; Almeida and Martins, 2015; Du et al., 2015), including tree approximation (Agić and Koller, 2014; Schluter et al.",
      "startOffset" : 67,
      "endOffset" : 155
    }, {
      "referenceID" : 3,
      "context" : "Recent interest in SDP has yielded numerous works on graph parsing (Ribeyre et al., 2014; Thomson et al., 2014; Almeida and Martins, 2015; Du et al., 2015), including tree approximation (Agić and Koller, 2014; Schluter et al.",
      "startOffset" : 67,
      "endOffset" : 155
    }, {
      "referenceID" : 18,
      "context" : "Recent interest in SDP has yielded numerous works on graph parsing (Ribeyre et al., 2014; Thomson et al., 2014; Almeida and Martins, 2015; Du et al., 2015), including tree approximation (Agić and Koller, 2014; Schluter et al.",
      "startOffset" : 67,
      "endOffset" : 155
    }, {
      "referenceID" : 1,
      "context" : ", 2015), including tree approximation (Agić and Koller, 2014; Schluter et al., 2014) and joint syntactic/semantic parsing (Henderson et al.",
      "startOffset" : 38,
      "endOffset" : 84
    }, {
      "referenceID" : 52,
      "context" : ", 2015), including tree approximation (Agić and Koller, 2014; Schluter et al., 2014) and joint syntactic/semantic parsing (Henderson et al.",
      "startOffset" : 38,
      "endOffset" : 84
    }, {
      "referenceID" : 26,
      "context" : ", 2014) and joint syntactic/semantic parsing (Henderson et al., 2013; Swayamdipta et al., 2016).",
      "startOffset" : 45,
      "endOffset" : 95
    }, {
      "referenceID" : 56,
      "context" : ", 2014) and joint syntactic/semantic parsing (Henderson et al., 2013; Swayamdipta et al., 2016).",
      "startOffset" : 45,
      "endOffset" : 95
    }, {
      "referenceID" : 21,
      "context" : "Another line of work addresses parsing into AMRs (Flanigan et al., 2014; Vanderwende et al., 2015; Pust et al., 2015; Artzi et al., 2015), which, like UCCA, abstract away from syntactic distinctions and represent meaning directly, using OntoNotes predicates (Weischedel et al.",
      "startOffset" : 49,
      "endOffset" : 137
    }, {
      "referenceID" : 58,
      "context" : "Another line of work addresses parsing into AMRs (Flanigan et al., 2014; Vanderwende et al., 2015; Pust et al., 2015; Artzi et al., 2015), which, like UCCA, abstract away from syntactic distinctions and represent meaning directly, using OntoNotes predicates (Weischedel et al.",
      "startOffset" : 49,
      "endOffset" : 137
    }, {
      "referenceID" : 48,
      "context" : "Another line of work addresses parsing into AMRs (Flanigan et al., 2014; Vanderwende et al., 2015; Pust et al., 2015; Artzi et al., 2015), which, like UCCA, abstract away from syntactic distinctions and represent meaning directly, using OntoNotes predicates (Weischedel et al.",
      "startOffset" : 49,
      "endOffset" : 137
    }, {
      "referenceID" : 7,
      "context" : "Another line of work addresses parsing into AMRs (Flanigan et al., 2014; Vanderwende et al., 2015; Pust et al., 2015; Artzi et al., 2015), which, like UCCA, abstract away from syntactic distinctions and represent meaning directly, using OntoNotes predicates (Weischedel et al.",
      "startOffset" : 49,
      "endOffset" : 137
    }, {
      "referenceID" : 62,
      "context" : ", 2015), which, like UCCA, abstract away from syntactic distinctions and represent meaning directly, using OntoNotes predicates (Weischedel et al., 2013).",
      "startOffset" : 128,
      "endOffset" : 153
    }, {
      "referenceID" : 21,
      "context" : "Indeed, despite considerable technical effort (Flanigan et al., 2014; Pourdamghani et al., 2014; Werling et al., 2015), concept identification is only about 80%–90% accurate.",
      "startOffset" : 46,
      "endOffset" : 118
    }, {
      "referenceID" : 47,
      "context" : "Indeed, despite considerable technical effort (Flanigan et al., 2014; Pourdamghani et al., 2014; Werling et al., 2015), concept identification is only about 80%–90% accurate.",
      "startOffset" : 46,
      "endOffset" : 118
    }, {
      "referenceID" : 63,
      "context" : "Indeed, despite considerable technical effort (Flanigan et al., 2014; Pourdamghani et al., 2014; Werling et al., 2015), concept identification is only about 80%–90% accurate.",
      "startOffset" : 46,
      "endOffset" : 118
    }, {
      "referenceID" : 20,
      "context" : "Furthermore, anchoring allows breaking down sentences into semantically meaningful sub-spans, which is useful for many applications (Fernández-González and Martins, 2015; Birch et al., 2016).",
      "startOffset" : 132,
      "endOffset" : 190
    }, {
      "referenceID" : 9,
      "context" : "Furthermore, anchoring allows breaking down sentences into semantically meaningful sub-spans, which is useful for many applications (Fernández-González and Martins, 2015; Birch et al., 2016).",
      "startOffset" : 132,
      "endOffset" : 190
    }, {
      "referenceID" : 25,
      "context" : "Several transition-based AMR parsers have been proposed: CAMR assumes syntactically parsed input, processing dependency trees into AMR (Wang et al., 2015a,b, 2016; Goodman et al., 2016).",
      "startOffset" : 135,
      "endOffset" : 185
    }, {
      "referenceID" : 14,
      "context" : "They are only able to predict a subset of reentrancies and discontinuities, as they may remove nodes before their parents have been predicted (Damonte et al., 2017).",
      "startOffset" : 142,
      "endOffset" : 164
    }, {
      "referenceID" : 7,
      "context" : ", 2015; Artzi et al., 2015), which, like UCCA, abstract away from syntactic distinctions and represent meaning directly, using OntoNotes predicates (Weischedel et al., 2013). Events in AMR may also be evoked by non-verbal predicates, including possessive constructions. Unlike in UCCA, the alignment between AMR concepts and the text is not explicitly marked. While sharing much of this work’s motivation, not anchoring the representation in the text complicates the parsing task, as it requires the alignment to be automatically (and imprecisely) detected. Indeed, despite considerable technical effort (Flanigan et al., 2014; Pourdamghani et al., 2014; Werling et al., 2015), concept identification is only about 80%–90% accurate. Furthermore, anchoring allows breaking down sentences into semantically meaningful sub-spans, which is useful for many applications (Fernández-González and Martins, 2015; Birch et al., 2016). Several transition-based AMR parsers have been proposed: CAMR assumes syntactically parsed input, processing dependency trees into AMR (Wang et al., 2015a,b, 2016; Goodman et al., 2016). In contrast, the parsers of Damonte et al. (2017) and Zhou et al.",
      "startOffset" : 8,
      "endOffset" : 1162
    }, {
      "referenceID" : 7,
      "context" : ", 2015; Artzi et al., 2015), which, like UCCA, abstract away from syntactic distinctions and represent meaning directly, using OntoNotes predicates (Weischedel et al., 2013). Events in AMR may also be evoked by non-verbal predicates, including possessive constructions. Unlike in UCCA, the alignment between AMR concepts and the text is not explicitly marked. While sharing much of this work’s motivation, not anchoring the representation in the text complicates the parsing task, as it requires the alignment to be automatically (and imprecisely) detected. Indeed, despite considerable technical effort (Flanigan et al., 2014; Pourdamghani et al., 2014; Werling et al., 2015), concept identification is only about 80%–90% accurate. Furthermore, anchoring allows breaking down sentences into semantically meaningful sub-spans, which is useful for many applications (Fernández-González and Martins, 2015; Birch et al., 2016). Several transition-based AMR parsers have been proposed: CAMR assumes syntactically parsed input, processing dependency trees into AMR (Wang et al., 2015a,b, 2016; Goodman et al., 2016). In contrast, the parsers of Damonte et al. (2017) and Zhou et al. (2016) do not require syntactic pre-processing.",
      "startOffset" : 8,
      "endOffset" : 1185
    }, {
      "referenceID" : 7,
      "context" : ", 2015; Artzi et al., 2015), which, like UCCA, abstract away from syntactic distinctions and represent meaning directly, using OntoNotes predicates (Weischedel et al., 2013). Events in AMR may also be evoked by non-verbal predicates, including possessive constructions. Unlike in UCCA, the alignment between AMR concepts and the text is not explicitly marked. While sharing much of this work’s motivation, not anchoring the representation in the text complicates the parsing task, as it requires the alignment to be automatically (and imprecisely) detected. Indeed, despite considerable technical effort (Flanigan et al., 2014; Pourdamghani et al., 2014; Werling et al., 2015), concept identification is only about 80%–90% accurate. Furthermore, anchoring allows breaking down sentences into semantically meaningful sub-spans, which is useful for many applications (Fernández-González and Martins, 2015; Birch et al., 2016). Several transition-based AMR parsers have been proposed: CAMR assumes syntactically parsed input, processing dependency trees into AMR (Wang et al., 2015a,b, 2016; Goodman et al., 2016). In contrast, the parsers of Damonte et al. (2017) and Zhou et al. (2016) do not require syntactic pre-processing. Damonte et al. (2017) perform concept identification using a simple heuristic selecting the most frequent graph for each token, and Zhou et al.",
      "startOffset" : 8,
      "endOffset" : 1248
    }, {
      "referenceID" : 7,
      "context" : ", 2015; Artzi et al., 2015), which, like UCCA, abstract away from syntactic distinctions and represent meaning directly, using OntoNotes predicates (Weischedel et al., 2013). Events in AMR may also be evoked by non-verbal predicates, including possessive constructions. Unlike in UCCA, the alignment between AMR concepts and the text is not explicitly marked. While sharing much of this work’s motivation, not anchoring the representation in the text complicates the parsing task, as it requires the alignment to be automatically (and imprecisely) detected. Indeed, despite considerable technical effort (Flanigan et al., 2014; Pourdamghani et al., 2014; Werling et al., 2015), concept identification is only about 80%–90% accurate. Furthermore, anchoring allows breaking down sentences into semantically meaningful sub-spans, which is useful for many applications (Fernández-González and Martins, 2015; Birch et al., 2016). Several transition-based AMR parsers have been proposed: CAMR assumes syntactically parsed input, processing dependency trees into AMR (Wang et al., 2015a,b, 2016; Goodman et al., 2016). In contrast, the parsers of Damonte et al. (2017) and Zhou et al. (2016) do not require syntactic pre-processing. Damonte et al. (2017) perform concept identification using a simple heuristic selecting the most frequent graph for each token, and Zhou et al. (2016) perform concept identification and parsing jointly.",
      "startOffset" : 8,
      "endOffset" : 1377
    }, {
      "referenceID" : 33,
      "context" : "Despite the recent diversity of semantic parsing work, the effectiveness of different approaches for structurally and semantically different schemes is not well-understood (Kuhlmann and Oepen, 2016).",
      "startOffset" : 172,
      "endOffset" : 198
    }, {
      "referenceID" : 32,
      "context" : "Future work will explore different target representations and conversion procedures (Kong et al., 2015), to compare different representations, suggesting ways for a data-driven design of semantic annotation.",
      "startOffset" : 84,
      "endOffset" : 103
    }, {
      "referenceID" : 9,
      "context" : "A parser for UCCA will enable using the framework for new tasks, in addition to existing applications such as machine translation evaluation (Birch et al., 2016).",
      "startOffset" : 141,
      "endOffset" : 161
    }, {
      "referenceID" : 39,
      "context" : "We believe UCCA’s merits in providing a cross-linguistically applicable, broad-coverage annotation will support ongoing efforts to incorporate deeper semantic structures into various applications, such as sentence simplification (Narayan and Gardent, 2014) and summarization (Liu et al.",
      "startOffset" : 229,
      "endOffset" : 256
    }, {
      "referenceID" : 34,
      "context" : "We believe UCCA’s merits in providing a cross-linguistically applicable, broad-coverage annotation will support ongoing efforts to incorporate deeper semantic structures into various applications, such as sentence simplification (Narayan and Gardent, 2014) and summarization (Liu et al., 2015).",
      "startOffset" : 275,
      "endOffset" : 293
    } ],
    "year" : 2017,
    "abstractText" : "We present the first parser for UCCA, a cross-linguistically applicable framework for semantic representation, which builds on extensive typological work, and supports rapid annotation. UCCA poses a challenge for existing parsing techniques, as it exhibits reentrancy (resulting in DAG structures), discontinuous structures and non-terminal nodes corresponding to complex semantic units. To our knowledge, the conjunction of these formal properties is not supported by any existing parser. Our transition-based parser, which uses a novel transition set and features based on bidirectional LSTMs, has value not just for UCCA parsing: its ability to handle more general graph structures will inform the development of parsers for other semantic DAG structures, and in languages that frequently use discontinuous structures.",
    "creator" : "LaTeX with hyperref package"
  }
}