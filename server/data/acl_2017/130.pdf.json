{
  "name" : "130.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Enriching Complex Networks with Word Embeddings for Detecting Mild Cognitive Impairment from Speech Transcripts",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "1 000\n011\n012\n013\n014\n015\n016\n017\n018\n019\n020\n021\n022\n023\n024\n025\n026\n027\n028\n029\n030\n031\n032\n033\n034\n035\n036\n037\n038\n039\n040\n041\n042\n043\n044\n045\n046\n047\n048\n049\n061\n062\n063\n064\n065\n066\n067\n068\n069\n070\n071\n072\n073\n074\n075\n076\n077\n078\n079\n080\n081\n082\n083\n084\n085\n086\n087\n088\n089\n090\n091\n092\n093\n094\n095\n096\n097\n098\n099\nMild Cognitive Impairment (MCI) is a mental disorder difficult to diagnose. Although language impairment is an important marker it is frequently undervalued in cognitive assessments. Linguistic features, mainly from parsers, have been used to detect MCI. However, MCI disfluencies produce agrammatical speech impacting in parsing results; manually correcting transcripts of patient’s speech is not a solution to large scale assessments. In this paper, we use complex network features to automatically identifying MCI in transcripts, using several classification algorithms, as it a lightweight and language independent representation. We modeled transcripts into complex networks and enriched them with word embeddings to better represent short texts produced in assessments. We evaluate our model in three datasets: one from the DementiaBank; Cinderella and Arizona-Battery in Portuguese were produced by assessments applied at University of São Paulo Medical School. The results show that complex networks are suitable to detect MCI and outperform linguistic features in all datasets. We also combined the classifiers through ensemble and multi-view learning. The ensemble of algorithms and multi-view method achieved 10% of improvement in Cinderella dataset compared to the best individual classifier. For the Arizona dataset, the multi-view achieved the highest accuracy (80%), a 4.71% of improvement."
    }, {
      "heading" : "1 Introduction",
      "text" : "Mild Cognitive Impairment (MCI) can affect one or multiple cognitive domains (e.g. memory, language, visuospatial skills and the executive function), and may represent a pre-clinical stage of Alzheimer’s disease (AD). The impairment that affects memory, referred to as amnestic MCI, is the most frequent, with the highest conversion rate for AD, at 15% a year versus 1 to 2% for the general population. Since dementias are chronic and progressive diseases, their early diagnosis ensures a greater chance of success to engage patients in non-pharmacological treatment strategies such as cognitive training, physical activity and socialization (Teixeira et al., 2012).\nLanguage is one of the most efficient information sources for assessing cognitive functions. Changes in language usage are frequent in patients with dementia and are normally first recognized by the patients themselves or their family members. Therefore, the automatic analysis of discourse production is promising for diagnosing MCI at early stages, which may address potentially reversible factors (Muangpaisan et al., 2012). Proposals to detect language-related impairment in dementias include machine learning (Jarrold et al., 2010; Roark et al., 2011; Fraser et al., 2014, 2015), magnetic resonance imaging (Dyrba et al., 2015), and data screening tests added to demographic information (Weakley et al., 2015). The discourse production (mainly narratives) is attractive because it allows for the analysis of linguistic microstructures, including phonetic-phonological, morphosyntactic and semantic-lexical components, as well as semanticpragmatic macrostructures.\nAutomated discourse analysis based on Natural Language Processing (NLP) resources and tools to diagnose dementias via machine learning meth-\n2\n101\n102\n103\n104\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n123\n124\n125\n126\n127\n128\n129\n130\n131\n132\n133\n134\n135\n136\n137\n138\n139\n140\n141\n142\n143\n144\n145\n146\n147\n148\n149\n150\n151\n152\n153\n154\n155\n156\n157\n158\n159\n160\n161\n162\n163\n164\n165\n166\n167\n168\n169\n170\n171\n172\n173\n174\n175\n176\n177\n178\n179\n180\n181\n182\n183\n184\n185\n186\n187\n188\n189\n190\n191\n192\n193\n194\n195\n196\n197\n198\n199\nods have been used for the English language (Lehr et al., 2012; Jarrold et al., 2014; Orimaye et al., 2014; Fraser et al., 2015; Davy et al., 2016) and for Brazilian Portuguese (Aluı́sio et al., 2016). A variety of features are required for this analysis, including Part-of-Speech (PoS), syntactic complexity, lexical diversity and acoustics features. Producing robust tools to extract these features is extremely difficult because speech transcripts used in neuropsychological evaluations contain disfluencies (repetitions, revisions, paraphasias) and patient’s comments about the task being evaluated. Another problem in using linguistic knowledge is the high dependence on manually created resources, such as hand-crafted linguistic rules and/or annotated corpora. Even when traditional statistical techniques (Bag of Words (BoW) or ngrams) are applied they also have problems to deal with disfluencies.\nAn approach applied successfully to several areas of NLP (Mihalcea and Radev, 2011), which may suffer less from the problems mentioned above, relies on the use of complex networks and graph theory. The word adjacency network model (i Cancho and Solé, 2001; Roxas and Tapang, 2010; Amancio et al., 2012a; Amancio, 2015b) has provided good results in text classification (de Arruda et al., 2016) and related tasks, namely author detection (Amancio, 2015a), identification of literary movements (Amancio et al., 2012c), authenticity verification (Amancio et al., 2013) and sense discrimination (Amancio et al., 2012b).\nIn this paper, we show that speech transcripts (narratives or descriptions) can be modeled into complex networks that are enriched with word embeddings. We modeled narratives and short descriptions into complex networks and enriched them with word embeddings to better represent short texts produced in these assessments. When applied to a machine learning classifier, the complex network features were able to distinguish between control participants and mild cognitive impairment participants. Discrimination of the two classes could be improved by combining complex networks with linguistic and traditional statistical features; we also identified the best scenario for application of network features extracted from transcripts of neuropsychological assessments."
    }, {
      "heading" : "2 Related Work",
      "text" : "Detection of memory impairment has been based on linguistic, acoustic, and demographic features, in addition to scores of neuropsychological tests. Linguistic and acoustic features were used to automatically detect aphasia (Fraser et al., 2014); and AD (Fraser et al., 2015) or dementia (Orimaye et al., 2014) in public corpora of DementiaBank. Other studies distinguished differents types of dementia (Garrard et al., 2014; Jarrold et al., 2014), in which speech samples were elicited using the Picnic picture of the Western Aphasia Battery. Davy et al. (2016) also used the Picnic scene for detecting MCI, where the subjects were asked to write (by hand) a detailed description of the scene.\nAs for automatic detection of MCI in narrative speech, Roark et al. (2011) extracted speech features and linguistic complexity measures of speech samples obtained with the Wechsler Logical Memory (WLM) subtest (Wechsler et al., 1997), and Lehr et al. (2012) fully automatized the WLM subtest. Some studies used short animated films to evaluate immediate and delayed recall in MCI patients which were asked to talk about the first film shown, then about their previous day, and finally about another film shown last. Tóth et al. (2015) adopted automatic speech recognition (ASR) to extract a phonetic level segmentation, which they used to calculate acoustic features. Vincze et al. (2016) used speech, morphological, semantic, and demographic features collected from their speech transcripts to automatically identify patients suffering from MCI.\nFor the Portuguese language, machine learning algorithms were used to identify subjects with AD and MCI. (Aluı́sio et al., 2016) used a variety of linguistic metrics, such as syntactic complexity, idea density (da Cunha et al., 2015), and text cohesion through latent semantics. PLN tools with high precision are needed to compute these metrics, which is a problem for Portuguese since there is no robust dependency or constituency parser. Therefore, the transcriptions had to be manually revised; they were segmented in sentences, following a semantic-structural criterion and capitalization was added afterwards. The authors also removed disfluencies and inserted omitted subjects when they were hidden, in order to reduce parsing errors. This process is obviously expensive, which has motivated us to use complex networks in the\n3\n201\n202\n203\n204\n205\n206\n207\n208\n209\n210\n211\n212\n213\n214\n215\n216\n217\n218\n219\n220\n221\n222\n223\n224\n225\n226\n227\n228\n229\n230\n231\n232\n233\n234\n235\n236\n237\n238\n239\n240\n241\n242\n243\n244\n245\n246\n247\n248\n249\n262\n263\n264\n265\n266\n267\n268\n269\n270\n271\n272\n273\n274\n275\n276\n277\n278\n279\n280\n281\n282\n283\n284\n285\n286\n287\n288\n289\n290\n291\n292\n293\n294\n295\n296\n297\n298\n299\npresent study to model transcriptions and avoid a manual preprocessing step."
    }, {
      "heading" : "3 Modeling and Characterizing Texts as Complex Networks",
      "text" : "The theory and concepts of complex networks have been used in several NLP tasks (Mihalcea and Radev, 2011; Cong and Liu, 2014), such as text classification (de Arruda et al., 2016), summarization (Antiqueira et al., 2009; Amancio et al., 2012a) and word sense disambiguation (Silva and Amancio, 2012). In this study, we used the word co-occurrence model (also called the word adjacency model) with a small modification because most of the syntactical relations occur among neighbouring words (i Cancho et al., 2004). Each distinct word becomes a node and words that are adjacent in the text are connected by an edge. Mathematically, a network is defined as an undirected graph G = {V,E}, formed by a set V = {v1, v2, ..., vn} of nodes (words) and a set E = {e1, e2, ..., em} of edges (co-occurrence) that are represented by an adjacency matrix A, whose elementsAij are equal to 1 whenever there is an edge connecting nodes (words) i and j, and equal to 0 otherwise.\nBefore modeling texts into complex networks, it is often necessary to do some preprocessing in the raw text. Preprocessing starts with tokenization where each document/text is divided into tokens (meaningful elements, e.g.: words and punctuation marks) and then stopwords and punctuation marks are removed, since they have little semantic meaning. One last step we decided to eliminate from the preprocessing pipeline is lemmatization, which transforms each word into its canonical form. This decision was made based on two factors: first, recent work has shown that lemmatization has little or no influence when network modeling is adopted in related tasks (Machicao et al., 2016). Second, the lemmatization process requires part-of-speech (POS) tagging that may introduce undesirable noises/errors in the text, since the texts in our work are transcriptions containing disfluencies.\nAnother problem with transcriptions in our work is their size. As demonstrated by Amancio (2015c), the classification of small texts using networks can be impaired, since short texts have almost linear networks, and the topological measures of these networks have little or no informa-\ntion relevant to classification. To solve this problem, we adapted the approach of modeling networks with word embeddings proposed by Perozzi et al. (2014) to enrich the networks with semantic information. In this process of word embedding, language networks are generated from continuous word representations, where each word is represented by a dense, real-valued vector obtained by trainning neural networks in the language model task (or variations, such as context prediction) (Bengio et al., 2003; Collobert et al., 2011; Mikolov et al., 2013a,b). This structure is known to capture syntatic and semantic information (Mikolov et al., 2013a,b). Perozzi et al. (2014), in particular, takes advantage of word embeddings to build networks where each word is a vertice and edges are defined by similarity between words established by the proximity of the word vectors.\nFollowing this methodology, in our model we added new edges to the co-occurrence networks considering similarities between words, that is, for all pairs of words in the text that were unconnected, an edge was created if their vectors (from word embedding) had a cosine similarity higher than a given threshold. Figure 1 shows an example of a co-occurrence network enriched by similarity links (the dotted edges). The gain in information by enriching a co-occurrence network with seman-\n4\n301\n302\n303\n304\n305\n306\n307\n308\n309\n310\n311\n312\n313\n314\n315\n316\n317\n318\n319\n320\n321\n322\n323\n324\n325\n326\n327\n328\n329\n330\n331\n332\n333\n334\n335\n336\n337\n338\n339\n340\n341\n342\n343\n344\n345\n346\n347\n348\n349\n350\n351\n352\n353\n354\n355\n356\n361\n362\n363\n364\n365\n366\n367\n368\n369\n370\n371\n372\n373\n374\n375\n376\n377\n378\n379\n380\n381\n382\n383\n384\n385\n386\n387\n388\n389\n390\n391\n392\n393\n394\n395\n396\n397\n398\n399\n(a) (b)\nFigure 2: Example of (a) co-occurrence network created for a transcript of the Cookie Theft dataset (see Supplementary Information, Section A1) and (b) the same co-occurrence network enriched with semantic information. Note that (b) is a more informative network than (a), since (a) is practically a linear network.\ntic information is readily apparent in Figure 2."
    }, {
      "heading" : "4 Datasets, Features and Methods",
      "text" : ""
    }, {
      "heading" : "4.1 Datasets",
      "text" : "The datasets consisted of: (i) transcribed samples, manually segmented of the DementiaBank1 and Cinderella story and (ii) transcribed samples of ABCD battery which were automatically segmented, since we are working towards a fully automated system to detect MCI in transcripts. The first dataset is composed of short English descriptions, while the second contains longer Brazilian Portuguese narratives. A third dataset had very short narratives, also in Portuguese. Below, we describe in more detail the datasets, participants, and the task in which they were used."
    }, {
      "heading" : "4.1.1 The Cookie Theft Picture Description Dataset",
      "text" : "The clinical dataset used for English was created during a longitudinal study conducted by the University of Pittsburgh School of Medicine on Alzheimer’s and related dementia, funded by the National Institute of Aging. To be eligible for inclusion in the study, all participants were required to be above 44 years of age, have at least 7 years of education, no history of nervous system disorders or be taking neuroleptic medication, have an initial Mini-Mental State Exam (MMSE) score of 10 or greater, and be able to give informed consent. The dataset contains transcripts of verbal interviews with AD and related Dementia patients,\n1https://talkbank.org/DementiaBank/\nincluding those with MCI (for more detail, see (Becker et al., 1994)).\nWe used 43 transcripts of patients with MCI, sampled from 326 people diagnosed with probable AD; 21 with possible AD. Table 1 shows the demographic information for the two diagnostic groups.\nFor this dataset, interviews were conducted in English and narrative speech was elicited using the Cookie Theft picture (Goodglass et al., 2001) (Figure 3 from Goodglass et al. (2001) in Section A.1). During the interview, patients were given the picture and were told to discuss everything they could see happening in the picture. The patients’ verbal utterances were recorded and then transcribed into the CHAT (Codes for the Human Analysis of Transcripts) transcription format (MacWhinney, 2000).\nWe extracted the word-level transcript patient sentences from the CHAT files and discarded the annotation, as our goal was to create a fully automated system that does not require the input of a human annotator. We automatically removed filled pauses such as uh, um , er , and ah (e.g. uh it seems to be summer out), short false starts (e.g. just t the ones ), and repetition (e.g. mother’s finished certain of the the dishes ), like (Fraser et al., 2015). The Control group has an average of 9.58 sentences per narrative, with each sentence having an average of 9.18 words; as for the MCI group, it has an average of 10.97 sentences per narrative, with 10.33 words per sentence in average."
    }, {
      "heading" : "4.1.2 The Cinderella Narrative Dataset",
      "text" : "The dataset examined in this study included 20 subjects with MCI and 20 subjects without MCI for control, as diagnosed at the Medical School of the University of São Paulo (FMUSP). Table 2 shows the demographic information of the two diagnostic groups, which were also used in (Aluı́sio et al., 2016).\nThe criteria used to diagnose MCI came from (Petersen, 2004). Diagnostics were done by a multidisciplinary team with psychiatrists, geria-\n5\n401\n402\n403\n404\n405\n406\n407\n408\n409\n410\n411\n412\n413\n414\n415\n416\n417\n418\n419\n420\n421\n422\n423\n424\n425\n426\n427\n428\n429\n430\n431\n432\n433\n434\n435\n436\n437\n438\n439\n440\n441\n442\n443\n444\n445\n446\n447\n448\n449\n450\n451\n452\n453\n454\n455\n456\n457\n458\n459\n460\n461\n462\n463\n464\n465\n466\n467\n468\n469\n470\n471\n472\n473\n474\n475\n476\n477\n478\n479\n480\n481\n482\n483\n484\n485\n486\n487\n488\n489\n490\n491\n492\n493\n494\n495\n496\n497\n498\n499\nDemographic Control MCI Avg. Age (SD) 74.8 (11.3) 73.3 (5.9) Avg. Years of 11.4 (2.6) 10.8 (4.5)Education (SD)\nNo. of Male/Female 27/16 29/14\nTable 2: Demographic information of participants in the Cinderella dataset. The Avg. Education is given in years.\ntricians, neurologists, neuropsychologists, speech pathologists, and occupational therapists, by a criterion of consensus. Inclusion criteria for the control group were elderly people with no cognitive deficits and preservation of functional capacity in everyday life. The exclusion criteria for the normal group were: poorly controlled clinical diseases, sensitive deficits that are not being compensated for and interfere with the performance in tests, other neurological or psychiatric diagnoses that are associated with dementia or cognitive deficits and use of medications in doses that affect cognition.\nSpeech narrative samples were elicited by having participants tell the Cinderella story; participants were given as much time as they needed to examine a picture book illustrating the story (Figure 4 in Section A). When each participant had finished looking at the pictures, the examiner asked the subject to tell the story in their own words, as in (Saffran et al., 1989). The time was recorded, but there was no limit imposed to the narrative length. If the participant had difficulty initiating, continuing speech, or presenting a long pause, an evaluator used a stimulus question “What happens next ?”, seeking to encourage the participant to continue his/her narrative. When the subject was unable to proceed with the narrative, the examiner asked if he/she had finalized the story and had something to add. Each speech sample was recorded and then manually transcribed at the word level following the NURC/SP N. 338 EF and 331 D2 transcription norms.\nOther tests were applied after the narrative in the following sequence: phonemic verbal fluency test, action verbal fluency, Camel and Cactus test (Bozeat et al., 2000), and Boston Naming test (Kaplan et al., 2001), in order to diagnose the groups.\nSince our goal was to create a fully automated system that did not require the input of a human annotator, we segmented sentences to simulate a high-quality ASR transcript with sentence seg-\nmentation, and we automatically removed the disfluencies following the same guidelines of TalkBank project2. However, other disfluencies (revisions, elaboration, paraphasias and comments about the task) were kept. The Control group has an average of 30.80 sentences per narrative, and each sentence averages 12.17 words; as for the MCI group, it has an average of 29.90 sentences per narrative, and each sentence averages 13.03 words.\nWe also evaluated a different version of this dataset used in Aluı́sio et al. (2016), where narratives were manually revised to improve parsing results: agramatical sentences and all the patients’ comments not related to the story were removed, and omitted subjects were inserted. In this dataset, the Control group has an average of 45.10 sentences per narrative, and each sentence averages 8.17 words. The MCI group has an average of 31.40 sentences per narrative, with each sentence averaging 10.91 words."
    }, {
      "heading" : "4.1.3 The Arizona Battery for Communication Disorders of Dementia (ABCD) Dataset",
      "text" : "The ABCD dataset examined included 23 subjects with MCI and 20 subjects without MCI for control, as diagnosed at the Medical School of the University of São Paulo (FMUSP). MCI subjects produced 46 narratives and the controls 39 ones. We used the automatic sentence segmentation method referred to as DeepBond (Treviso et al., 2017). Table 3 shows the demographic information. The Control group has an average of 5.23 sentences per narrative, with 11 words per sentence in average, and the MCI group has an average of 4.95 sentences per narrative, with an average of 12.04 words per sentence. Interviews were conducted in Portuguese and the subject listened to the examiner read a brief narrative. The subject then retold the narrative to the examiner twice: once immediately upon hearing it and again after a 30-minute delay (Bayles and Tomoeda, 1991). Each speech sample was recorded and then manually transcribed at the word level following the NURC/SP N. 338 EF and 331 D2 transcription norms."
    }, {
      "heading" : "4.2 Features",
      "text" : "Features of three distinct natures were used for classifying the transcribed texts: topological met-\n2https://talkbank.org/\n6\n501\n502\n503\n504\n505\n506\n507\n508\n509\n510\n511\n512\n513\n514\n515\n516\n517\n518\n519\n520\n521\n522\n523\n524\n525\n526\n527\n528\n529\n530\n531\n532\n533\n534\n535\n536\n537\n538\n539\n540\n541\n542\n543\n544\n545\n546\n547\n548\n549\n550\n551\n552\n553\n554\n555\n556\n557\n558\n559\n560\n561\n562\n563\n564\n565\n566\n567\n568\n569\n570\n571\n572\n573\n574\n575\n576\n577\n578\n579\n580\n581\n582\n583\n584\n585\n586\n587\n588\n589\n590\n591\n592\n593\n594\n595\n596\n597\n598\n599\nDemographic Control MCI Avg. Age (SD) 61 (7.5) 72,0 (7.4) Avg. Years of 16 (7.6) 13.3 (4.2)Education (SD)\nNo. of Male/Female 6/14 16/7\nTable 3: Demographic information of participants in the ABCD dataset. The Avg. Education is given in years.\nrics of co-occurrence networks, linguistic features and statistics of bag of words representation."
    }, {
      "heading" : "4.2.1 Topological Characterization of Networks",
      "text" : "Each transcription was mapped into a cooccurrence network, and then enriched via word embedding using the cosine similarity of words. Since the occurrence of out-of-vocabulary words is common in texts, we used the method proposed by (Bojanowski et al., 2016) to generate word embeddings. This method extends the skipgram model to use character-level information, with each word being represented as a bag of character n-grams. It provides some improvement in comparison with the traditional skip-gram model in syntactic evaluation (Mikolov et al., 2013b) but not for the semantic evaluation.\nOnce the network has been enriched with semantic information, we characterize its topology using the following ten measurements:\n1. PageRank: is a centrality measurement that reflects the relevance of a node based on its connections to other relevant nodes (Brin and Page, 1998);\n2. Betweenness: is a centrality measurement that considers a node as relevant if it is highly accessed via shortest paths. The betweenness of a node v is defined as the fraction of shortest paths going through node v;\n3. Eccentricity: of a node is calculated by measuring the shortest distance from the node to all other vertices in the graph and taking the maximum;\n4. Eigenvector centrality: is a measurement that defines the importance of a node based on its connectivity to high-rank nodes;\n5. Average Degree of the Neighbors of a Node: is the average of the degrees of all its direct neighbors;\n6. Average Shortest Path Length of a Node: is the average distance between this node and all other nodes of the network;\n7. Degree: is the number of edges connected to the node;\n8. Assortativity Degree: or degree correlation measures the tendency of nodes to connect to other nodes that have similar degree;\n9. Diameter: is defined as the maximum shortest path;\n10. Clustering Coefficient: measures the probability that two neighbors of a node are connected.\nMost of the measurements described above are local measurements, i.e. each node i possesses a value Xi, so we calculate the average µ(X), standard deviation σ(X) and skewness γ(X) for each measurement (Amancio, 2015b)."
    }, {
      "heading" : "4.2.2 Linguistic Features",
      "text" : "Linguistic features for classification of neuropsychological assessments have been utilized in several works (Roark et al., 2011; Jarrold et al., 2014; Fraser et al., 2014; Orimaye et al., 2014; Fraser et al., 2015; Vincze et al., 2016; Davy et al., 2016). We used the Coh-Metrix3(Graesser et al., 2004) tool to extract features of English transcripts, resulting in 106 features. The metrics are divided into eleven categories: Descriptive, Text Easability Principal Component, Referential Cohesion, Latent Semantic Analysis (LSA), Lexical Diversity, Connectives, Situation Model, Syntactic Complexity, Syntactic Pattern Density, Word Information, Readability (Flesch Reading Ease, Flesch-Kincaid Grade Level, Coh-Metrix L2 Readability).\nFor Portuguese, Coh-Metrix-Dementia (Aluı́sio et al., 2016) was used. The metrics affected by constituency and dependency parsing were not used because they are not robust to deal with disfluencies. Metrics based on manual annotation (such as proportion short pauses, mean pause duration, mean number of empty words, and others) were also discarded. The metrics of Coh-MetrixDementia are divided into twelve categories: Ambiguity, Anaphoras, Basic Counts, Connectives,\n3cohmetrix.com\n7\n601\n602\n603\n604\n605\n606\n607\n608\n609\n610\n611\n612\n613\n614\n615\n616\n617\n618\n619\n620\n621\n622\n623\n624\n625\n626\n627\n628\n629\n630\n631\n632\n633\n634\n635\n636\n637\n638\n639\n640\n641\n642\n643\n644\n645\n646\n647\n648\n649\n650\n651\n652\n653\n654\n655\n656\n657\n658\n659\n660\n661\n662\n663\n664\n665\n666\n667\n668\n669\n670\n671\n672\n673\n674\n675\n676\n677\n678\n679\n680\n681\n682\n683\n684\n685\n686\n687\n688\n689\n690\n691\n692\n693\n694\n695\n696\n697\n698\n699\nCo-reference Measures, Content Word Frequencies, Hypernyms, Logic Operators, Latent Semantic Analysis, Semantic Density, Syntactical Complexity, and Tokens. The metrics used are shown in detail in Section A.2. In total, 58 metrics were used, from the 73 available in the website4."
    }, {
      "heading" : "4.2.3 Bag of Words",
      "text" : "The representation of text collections under the Bag-of-Words (BoW) assumption (i.e., with no information relating to word order) has been a robust solution for text classification by capturing word content- and frequency-specific differences that are relevant to the categories under investigation (Joachims, 1998; Drucker et al., 1999). In this methodology, transcripts are represented by a table in which the columns represent the terms (or existing words) in the transcripts and the values represent frequency of a term in a document, such as binary weights, term frequency (tf) or term frequency – inverse document frequency (tf–idf) (Salton, 1989). In this work term frequency was used."
    }, {
      "heading" : "4.3 Classification Algorithms",
      "text" : "In order to quantify the ability of the topological characterization of networks, linguistic metrics and BoW features to distinguish subjects with MCI from those without, we employed four machine learning algorithms to induce classifiers from a training set. The techniques are Gaussian Naive Bayes (GaussianNB), k-Nearest Neighbor (K-NN), Support Vector Machine (SVM), linear and radial bases functions (RBF), and Random Forest (RF). We also combine these classifiers through ensemble and multi-view learning. In ensemble learning, multiple models/classifiers are generated and combined using, e.g. majority vote or average of class probabilities, to produce a single result (Zhou, 2012). In multi-view learning, multiple classifiers are trained in different feature spaces and thus combined to produce a single result. This approach is an elegant solution rather than combining all features in the same vector or space, primarily because the combination is not a straightforward step, which can lead to noise insertion, since the data have different natures. Secondly, using different classifiers for each feature space allows different weights to be given for each type of feature, weights that can be learned by a\n4http://143.107.183.175:22380\nregression method to improve the model. This approach has been successful for NLP (Collobert et al., 2011), sentiment classification (Xia et al., 2011) and pedestrian detection in images (Oliveira et al., 2010; Kim et al., 2016)."
    }, {
      "heading" : "5 Experiments and Results",
      "text" : "All experiments were conducted using the Scikitlearn5 (Pedregosa et al., 2011), with classifiers evaluated on the basis of classification accuracy or the total proportion of narratives which were correctly classified. The evaluation was performed using 5-fold cross validation, and the threshold parameter was optimized with best values being 0.7 in Cookie Theft dataset and 0.4 in both Cinderella and ABCD dataset.\nWe trained the model proposed by Bojanowski et al. (2016) with default parametrs (100 dimensional embeddings, 5 size of the context window, 5 number of epochs). The accuracy in classification is given in Tables 4, 5, 6, and 7. CN, CNE, LM, and BoW denote, respectively, complex networks, complex network enriched with embeddings, linguistic metrics and Bag-of-Words, and CNE-LM, CNE-BoW, LM-BoW and CNE-LM-BoW refer to combinations of the feature spaces (multiview learning), using the majority vote. Cells with the – sign mean that it is not possible to apply majority voting. The last line represents the use of an ensemble of machine learning algorithms, in which the combination used was the majority voting in both ensemble and multiview learning.\nThe results for the three datasets show that characterizing transcriptions into complexity networks is competitive with other traditional methods, such as with the use of linguistic metrics. In fact, among the three types of features, using enriched networks (CNE) provided the highest accuracies, and in general CNE is better than using only complex networks. SVM gives better accuracy in most cases compared to other machine learning algorithms. As for ensemble and multi-view learnings there are some good results. For the Cookie Theft dataset, multi-view learning achieved the highest accuracy (65% of accuracy for narrative texts, a 2.3% of improvement compared to the best individual classifier). The ensemble of algorithms and multi-view CNE-LM achieved the highest accuracy in Cinderella dataset (75% of accuracy for narrative texts, a 10% of improvement compared\n5http://scikit-learn.org\n8\n701\n702\n703\n704\n705\n706\n707\n708\n709\n710\n711\n712\n713\n714\n715\n716\n717\n718\n719\n720\n721\n722\n723\n724\n725\n726\n727\n728\n729\n730\n731\n732\n733\n734\n735\n736\n737\n738\n739\n740\n741\n742\n743\n744\n745\n746\n747\n748\n749\n750\n751\n752\n753\n754\n755\n756\n757\n758\n759\n760\n761\n762\n763\n764\n765\n766\n767\n768\n769\n770\n771\n772\n773\n774\n775\n776\n777\n778\n779\n780\n781\n782\n783\n784\n785\n786\n787\n788\n789\n790\n791\n792\n793\n794\n795\n796\n797\n798\n799\nClassifier CN CNE LM BoW CNE-LM CNE-BoW LM-BoW CNE-LM-BoW\nSVM-Linear 0.5250 0.5542 0.5694 0.5917 – – – 0.6056 SVM-RBF 0.5694 0.6264 0.5806 0.6014 – – – 0.6500 KNN 0.5903 0.6167 0.4611 0.5792 – – – 0.5903 RF 0.5222 0.4778 0.4569 0.4889 – – – 0.5000 G-NB 0.5125 0.4861 0.5694 0.5583 – – – 0.5000 Ensemble 0.5625 0.6042 0.5458 0.5806 0.5000 0.5625 0.5000 0.6500\nTable 4: Classification accuracy achieved on Cookie Theft dataset.\nClassifier CN CNE LM BoW CNE-LM CNE-BoW LM-BoW CNE-LM-BoW\nSVM-Linear 0.5250 0.6000 0.5250 0.5000 – – – 0.5250 SVM-RBF 0.5750 0.6500 0.4750 0.3750 – – – 0.5000 KNN 0.4750 0.5000 0.4750 0.3750 – – – 0.3750 RF 0.5500 0.5750 0.4750 0.4500 – – – 0.5250 G-NB 0.4750 0.5250 0.4750 0.5500 – – – 0.5250 Ensemble 0.5250 0.6000 0.5000 0.3750 0.7500 0.5000 0.3750 0.4750\nTable 5: Classification accuracy achieved on Cinderella dataset.\nClassifier CNE LM BoW CNE-BoW\nSVM-Linear 0.6500 0.6250 0.5250 – SVM-RBF 0.6750 0.7250 0.5500 – KNN 0.4750 0.5500 0.5000 – RF 0.4750 0.5750 0.4500 – G-NB 0.6500 0.6000 0.4500 – Ensemble 0.6000 0.6750 0.4500 0.7500\nTable 6: Classification accuracy achieved on Cinderella dataset manually processed to revise agrammatical sentences.\nClassifier CNE LM BoW CNE-LM-BoW\nSVM-Linear 0.7173 0.5904 0.7547 0.8018 SVM-RBF 0.6436 0.6819 0.5413 0.6583 KNN 0.6208 0.7056 0.5881 0.7171 RF 0.4921 0.6813 0.6265 0.6252 G-NB 0.5722 0.5744 0.6257 0.6450 Ensemble 0.6783 0.7056 0.6964 0.7636\nTable 7: Classification accuracy achieved on ABCD dataset\nto the best individual classifier). For the ABCD dataset, multi-view CNE-LM-BoW achieved the highest accuracy (80% of accuracy for narrative texts, a 4.71% of improvement compared to the best individual classifier). Somewhat surprising were the results of SVM with linear kernel in BoW feature space (75% of accuracy)."
    }, {
      "heading" : "6 Conclusions and Future Work",
      "text" : "In this study, we employed metrics of topological properties of CN in a machine learning classification approach to distinguish between healthy\ncontrols and patients with MCI. To the best of our knowledge, these metrics have never been used before to detect MCI in speech transcripts; CN were enriched with word embeddings to better represent short texts produced in neuropsychological assessments. We have shown that the topological properties of CN outperfom traditionally linguistic metrics, in individual classifiers results. Linguistic features depend on grammatical texts to present good results, as can be seen in the results of Cinderella dataset manually processed (Table 6). Furthermore, we found that combining machine and multi-view learning can improve accuracy. The accuracies found here are comparable to the values reported by other authors, ranging from 60% to 85% (Prud’hommeaux and Roark, 2011; Lehr et al., 2012; Tóth et al., 2015; Vincze et al., 2016), which means that it is not easy to distinguish between healthy subjects and those with cognitive impairments. The comparison with our results is not straightforward, though, because the databases used in the studies are different. There is a clear need of publicly available datasets to compare different methods, which would allow for optimizing detection of MCI in elderly people.\nAs future work, we intend to explore other methods to enrich CN, such as Recurrent Language Model language, and other metrics to characterize an adjacency network. The pursue of these strategies is relevant because language is one of the most efficient information sources for assessing cognitive functions, commonly used in neuropsychological assessments.\n9\n801\n802\n803\n804\n805\n806\n807\n808\n809\n810\n811\n812\n813\n814\n815\n816\n817\n818\n819\n820\n821\n822\n823\n824\n825\n826\n827\n828\n829\n830\n831\n832\n833\n834\n835\n836\n837\n838\n839\n840\n841\n842\n843\n844\n845\n846\n847\n848\n849\n850\n851\n852\n853\n854\n855\n856\n857\n858\n859\n860\n861\n862\n863\n864\n865\n866\n867\n868\n869\n870\n871\n872\n873\n874\n875\n876\n877\n878\n879\n880\n881\n882\n883\n884\n885\n886\n887\n888\n889\n890\n891\n892\n893\n894\n895\n896\n897\n898\n899"
    }, {
      "heading" : "A Supplementary Material",
      "text" : "A.1 Example of transcription\nBelow follows an example of a transcript of the Cookie Theft dataset.\nYou just want me to start talking ? Well the little girl is asking her brother we ’ll say for a cookie . Now he ’s getting the cookie one for him and one for her . He unbalances the step the little stool and he ’s about to fall . And the lid ’s off the cookie jar . And the mother is drying the dishes abstractly so she ’s left the water running in the sink and it\nis spilling onto the floor . And there are two there ’s look like two cups and a plate on the sink and board . And that boy ’s wearing shorts and the little girl is in a short skirt . And the mother has an apron on . And she ’s standing at the window . The window ’s opened . It must be summer or spring . And the curtains are pulled back . And they have a nice walk around their house . And there ’s this nice shrubbery it appears and grass . And there ’s a big picture window in the background that has the drapes pulled off . There ’s a not pulled off but pulled aside . And there ’s a tree in the background . And the house with the kitchen has a lot of cupboard space under the sink board and under the cabinet from which the cookie you know cookies are being removed .\nA.2 Cohmetrix-Dementia metrics\n1. Ambiguity: verb ambiguity, noun ambiguity, adjective ambiguity, adverb ambiguity;\n2. Anaphoras: adjacent anaphoric references, anaphoric references;\n3. Basic Counts: Flesch index, number of word, number of sentences, number of paragraphs, words per sentence, sentences per paragraph, syllables per content word, verb incidence, noun incidence, adjective incidence, adverb incidence, pronoun incidence, content word incidence, function word incidence;\n4. Connectives: connectives incidence, additive positive connectives incidence, additive negative connectives incidence, temporal positive connectives incidence, temporal negative connectives incidence, casual positive connectives incidence, casual negative connectives incidence, logical positive connectives incidence, logical negative connectives incidence;\n5. Co-reference Measures: adjacent argument overlap, argument overlap, adjacent stem overlap, stem overlap, adjacent content word overlap;\n6. Content Word Frequencies: Content words frequency, minimum among content words frequency;\n7. Hypernyms: Mean hypernyms per verb;\n1200\n1201\n1202\n1203\n1204\n1205\n1206\n1207\n1208\n1209\n1210\n1211\n1212\n1213\n1214\n1215\n1216\n1217\n1218\n1219\n1220\n1221\n1222\n1223\n1224\n1225\n1226\n1227\n1228\n1229\n1230\n1231\n1232\n1233\n1234\n1235\n1236\n1237\n1238\n1239\n1240\n1241\n1242\n1243\n1244\n1245\n1246\n1247\n1248\n1249\n1250\n1251\n1252\n1253\n1254\n1255\n1256\n1257\n1258\n1259\n1260\n1261\n1262\n1263\n1264\n1265\n1266\n1267\n1268\n1269\n1270\n1271\n1272\n1273\n1274\n1275\n1276\n1277\n1278\n1279\n1280\n1281\n1282\n1283\n1284\n1285\n1286\n1287\n1288\n1289\n1290\n1291\n1292\n1293\n1294\n1295\n1296\n1297\n1298\n1299\n8. Logic Operators: Logic operators incidence, and incidence, or incidence, if incidence, negation incidence;\n9. Latent Semantic Analysis (LSA): Average and standard deviation similarity between pairs of adjacent sentences in the text, Average and standard deviation similarity between all sentence pairs in the text, Average and standard deviation similarity between pairs of adjacent paragraphs in the text, Givenness average and standard deviation of each sentence in the text;\n10. Semantic Density: content density;\n11. Syntactical Complexity: only cross entropy;\n12. Tokens: personal pronouns incidence, typetoken ratio, Brunet index, Honoré Statistics."
    } ],
    "references" : [ {
      "title" : "Evaluating progression of alzheimer’s disease by regression and classification methods in a narrative language test in portuguese",
      "author" : [ "Sandra M. Aluı́sio", "Andre L. da Cunha", "Carolina Scarton" ],
      "venue" : null,
      "citeRegEx" : "Aluı́sio et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Aluı́sio et al\\.",
      "year" : 2016
    }, {
      "title" : "Authorship recognition via fluctuation analysis of network topology and word intermittency",
      "author" : [ "Diego R. Amancio." ],
      "venue" : "Journal of Statistical Mechanics: Theory and Experiment 2015(3):P03005. https://doi.org/10.1088/1742-",
      "citeRegEx" : "Amancio.,? 2015a",
      "shortCiteRegEx" : "Amancio.",
      "year" : 2015
    }, {
      "title" : "A complex network approach to stylometry",
      "author" : [ "Diego R. Amancio." ],
      "venue" : "PloS one 10(8):e0136076. https://doi.org/10.1371/journal.pone.0136076.",
      "citeRegEx" : "Amancio.,? 2015b",
      "shortCiteRegEx" : "Amancio.",
      "year" : 2015
    }, {
      "title" : "Probing the topological properties of complex networks modeling short written texts",
      "author" : [ "Diego R. Amancio." ],
      "venue" : "PloS one 10(2):1–17. https://doi.org/10.1371/journal.pone.0118394.",
      "citeRegEx" : "Amancio.,? 2015c",
      "shortCiteRegEx" : "Amancio.",
      "year" : 2015
    }, {
      "title" : "Probing the statistical properties of unknown texts: Application to the voynich manuscript",
      "author" : [ "Diego R. Amancio", "Eduardo G. Altmann", "Diego Rybski", "Osvaldo N. Oliveira Jr.", "Luciano da F. Costa." ],
      "venue" : "PLOS ONE 8(7):1–10.",
      "citeRegEx" : "Amancio et al\\.,? 2013",
      "shortCiteRegEx" : "Amancio et al\\.",
      "year" : 2013
    }, {
      "title" : "Extractive summarization using complex networks and syntactic dependency",
      "author" : [ "Diego R. Amancio", "Maria G.V. Nunes", "Osvaldo N. Oliveira Jr", "Luciano F. Costa." ],
      "venue" : "Physica A: Statistical Mechanics and its Applications 391(4):1855–1864.",
      "citeRegEx" : "Amancio et al\\.,? 2012a",
      "shortCiteRegEx" : "Amancio et al\\.",
      "year" : 2012
    }, {
      "title" : "Unveiling the relationship between complex networks metrics and word senses",
      "author" : [ "Diego R. Amancio", "O.N. Oliveira Jr.", "Luciano da F. Costa." ],
      "venue" : "EPL (Europhysics Letters) 98(1):18002. https://doi.org/10.1209/0295-5075/98/18002.",
      "citeRegEx" : "Amancio et al\\.,? 2012b",
      "shortCiteRegEx" : "Amancio et al\\.",
      "year" : 2012
    }, {
      "title" : "Identification of literary movements using complex networks to represent texts",
      "author" : [ "Diego R. Amancio", "Osvaldo N. Oliveira Jr", "Luciano F. Costa." ],
      "venue" : "New Journal of Physics 14(4):043029. https://doi.org/10.1088/1367-2630/14/4/043029.",
      "citeRegEx" : "Amancio et al\\.,? 2012c",
      "shortCiteRegEx" : "Amancio et al\\.",
      "year" : 2012
    }, {
      "title" : "A complex network approach to text summarization",
      "author" : [ "Lucas Antiqueira", "O.N. Oliveira Jr.", "Luciano da Fontoura Costa", "Maria das Graças Volpe Nunes." ],
      "venue" : "Information Sciences 179(5):584 – 599.",
      "citeRegEx" : "Antiqueira et al\\.,? 2009",
      "shortCiteRegEx" : "Antiqueira et al\\.",
      "year" : 2009
    }, {
      "title" : "ABCD: Arizona Battery for Communication Disorders of Dementia",
      "author" : [ "Kathryn Bayles", "CK Tomoeda." ],
      "venue" : "Tucson, AZ: Canyonlands Publishing.",
      "citeRegEx" : "Bayles and Tomoeda.,? 1991",
      "shortCiteRegEx" : "Bayles and Tomoeda.",
      "year" : 1991
    }, {
      "title" : "The natural history of alzheimer’s disease",
      "author" : [ "James T. Becker", "François Boiler", "Oscar L. Lopez", "Judith Saxton", "Karen L. McGonigle" ],
      "venue" : null,
      "citeRegEx" : "Becker et al\\.,? \\Q1994\\E",
      "shortCiteRegEx" : "Becker et al\\.",
      "year" : 1994
    }, {
      "title" : "A neural probabilistic language model",
      "author" : [ "Yoshua Bengio", "Réjean Ducharme", "Pascal Vincent", "Christian Jauvin." ],
      "venue" : "journal of machine learning research 3(Feb):1137–1155.",
      "citeRegEx" : "Bengio et al\\.,? 2003",
      "shortCiteRegEx" : "Bengio et al\\.",
      "year" : 2003
    }, {
      "title" : "Enriching word vectors with subword information",
      "author" : [ "Piotr Bojanowski", "Edouard Grave", "Armand Joulin", "Tomas Mikolov." ],
      "venue" : "arXiv preprint arXiv:1607.04606 .",
      "citeRegEx" : "Bojanowski et al\\.,? 2016",
      "shortCiteRegEx" : "Bojanowski et al\\.",
      "year" : 2016
    }, {
      "title" : "Non-verbal semantic impairment in semantic dementia",
      "author" : [ "Sasha Bozeat", "Matthew A. Ralph", "Karalyn Patterson", "Peter Garrard", "John R. Hodges." ],
      "venue" : "Neuropsychologia 38(9):1207–1215. https://doi.org/10.1016/S0028-3932(00)00034-8.",
      "citeRegEx" : "Bozeat et al\\.,? 2000",
      "shortCiteRegEx" : "Bozeat et al\\.",
      "year" : 2000
    }, {
      "title" : "The anatomy of a large-scale hypertextual web search engine",
      "author" : [ "Sergey Brin", "Lawrence Page." ],
      "venue" : "International Conference on World Wide Web. Elsevier, pages 107–117.",
      "citeRegEx" : "Brin and Page.,? 1998",
      "shortCiteRegEx" : "Brin and Page.",
      "year" : 1998
    }, {
      "title" : "Natural language processing (almost) from scratch",
      "author" : [ "Ronan Collobert", "Jason Weston", "Léon Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa." ],
      "venue" : "Journal of Machine Learning Research 12(Aug):2493–2537.",
      "citeRegEx" : "Collobert et al\\.,? 2011",
      "shortCiteRegEx" : "Collobert et al\\.",
      "year" : 2011
    }, {
      "title" : "Approaching human language with complex networks",
      "author" : [ "Jin Cong", "Haitao Liu." ],
      "venue" : "Physics of Life Reviews 11(4):598 – 618. https://doi.org/10.1016/j.plrev.2014.04.004.",
      "citeRegEx" : "Cong and Liu.,? 2014",
      "shortCiteRegEx" : "Cong and Liu.",
      "year" : 2014
    }, {
      "title" : "Automatic proposition extraction from dependency trees: Helping early prediction of alzheimer’s disease from narratives",
      "author" : [ "Andre L. da Cunha", "Lucilene B. de Sousa", "Letı́cia L. Mansur", "Sandra M. Aluı́sio" ],
      "venue" : null,
      "citeRegEx" : "Cunha et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Cunha et al\\.",
      "year" : 2015
    }, {
      "title" : "Towards automatic detection of abnormal cognitive decline and dementia through linguistic analysis",
      "author" : [ "Weissenbacher Davy", "Johnson A. Travis", "Wojtulewicz Laura", "Dueck Amylou", "Locke Dona", "Caselli Richard", "Gonzalez Graciela" ],
      "venue" : null,
      "citeRegEx" : "Davy et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Davy et al\\.",
      "year" : 2016
    }, {
      "title" : "Using complex networks for text classification: Discriminating informative and imaginative documents",
      "author" : [ "Henrique F. de Arruda", "Luciano F. Costa", "Diego R. Amancio." ],
      "venue" : "EPL (Europhysics Letters) 113(2):28007. https://doi.org/10.1209/0295-",
      "citeRegEx" : "Arruda et al\\.,? 2016",
      "shortCiteRegEx" : "Arruda et al\\.",
      "year" : 2016
    }, {
      "title" : "Support vector machines for spam categorization",
      "author" : [ "Harris Drucker", "Donghui Wu", "Vladimir N. Vapnik." ],
      "venue" : "Institute of Electrical and Electronics Engineers Transactions on Neural networks 10(5):1048– 1054. https://doi.org/10.1109/72.788645.",
      "citeRegEx" : "Drucker et al\\.,? 1999",
      "shortCiteRegEx" : "Drucker et al\\.",
      "year" : 1999
    }, {
      "title" : "Predicting prodromal alzheimer’s disease in subjects with mild cognitive impairment",
      "author" : [ "Martin Dyrba", "Frederik Barkhof", "Andreas Fellgiebel", "Massimo Filippi", "Lucrezia Hausner", "Karlheinz Hauenstein", "Thomas Kirste", "Stefan J. Teipel" ],
      "venue" : null,
      "citeRegEx" : "Dyrba et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Dyrba et al\\.",
      "year" : 2015
    }, {
      "title" : "Automated classification of primary progressive aphasia subtypes from narrative speech transcripts",
      "author" : [ "Kathleen C. Fraser", "Jed A. Meltzer", "Naida L. Graham", "Carol Leonard", "Graeme Hirst", "Sandra E. Black", "Elizabeth Rochon." ],
      "venue" : "Cortex 55:43–60.",
      "citeRegEx" : "Fraser et al\\.,? 2014",
      "shortCiteRegEx" : "Fraser et al\\.",
      "year" : 2014
    }, {
      "title" : "Linguistic features identify alzheimer’s disease in narrative speech",
      "author" : [ "Kathleen C. Fraser", "Jed A. Meltzer", "Frank Rudzicz." ],
      "venue" : "Journal of Alzheimer’s Disease 49(2):407–422. https://doi.org/10.3233/JAD-150520.",
      "citeRegEx" : "Fraser et al\\.,? 2015",
      "shortCiteRegEx" : "Fraser et al\\.",
      "year" : 2015
    }, {
      "title" : "Machine learning approaches to diagnosis and laterality effects in semantic dementia discourse",
      "author" : [ "Peter Garrard", "Vassiliki Rentoumi", "Benno Gesierich", "Bruce Miller", "Maria L. Gorno-Tempini." ],
      "venue" : "Cortex 55:122–129.",
      "citeRegEx" : "Garrard et al\\.,? 2014",
      "shortCiteRegEx" : "Garrard et al\\.",
      "year" : 2014
    }, {
      "title" : "The Assessment of Aphasia and Related Disorders",
      "author" : [ "Harold Goodglass", "Edith Kaplan", "Barbara Barresi." ],
      "venue" : "The Assessment of Aphasia and Related Disorders. Lippincott Williams & Wilkins.",
      "citeRegEx" : "Goodglass et al\\.,? 2001",
      "shortCiteRegEx" : "Goodglass et al\\.",
      "year" : 2001
    }, {
      "title" : "Coh-metrix: Analysis of text on cohesion and language",
      "author" : [ "Arthur C. Graesser", "Danielle S. McNamara", "Max M. Louwerse", "Zhiqiang Cai." ],
      "venue" : "Behavior research methods, instruments, & computers 36(2):193–202.",
      "citeRegEx" : "Graesser et al\\.,? 2004",
      "shortCiteRegEx" : "Graesser et al\\.",
      "year" : 2004
    }, {
      "title" : "Patterns in syntactic dependency networks",
      "author" : [ "Ramon F. i Cancho", "Ricard V. Solé", "Reinhard Köhler." ],
      "venue" : "Physical Review E 69(5):051915. https://doi.org/10.1103/PhysRevE.69.051915.",
      "citeRegEx" : "Cancho et al\\.,? 2004",
      "shortCiteRegEx" : "Cancho et al\\.",
      "year" : 2004
    }, {
      "title" : "The small world of human language",
      "author" : [ "Ramon F. i Cancho", "Richard V. Solé." ],
      "venue" : "Proceedings of the Royal Society of London B: Biological Sciences 268(1482):2261–2265. https://doi.org/10.1098/rspb.2001.1800.",
      "citeRegEx" : "Cancho and Solé.,? 2001",
      "shortCiteRegEx" : "Cancho and Solé.",
      "year" : 2001
    }, {
      "title" : "Aided diagnosis of dementia type through computer-based analysis of spontaneous speech",
      "author" : [ "William L. Jarrold", "Bart Peintner", "David Wilkins", "Dimitra Vergryi", "Colleen Richey", "Maria L. GornoTempini", "Jennifer Ogar." ],
      "venue" : "Proceedings of the",
      "citeRegEx" : "Jarrold et al\\.,? 2014",
      "shortCiteRegEx" : "Jarrold et al\\.",
      "year" : 2014
    }, {
      "title" : "Language analytics for assessing brain health: Cognitive impairment, depression and presymptomatic alzheimer’s disease",
      "author" : [ "William L. Jarrold", "Bart Peintner", "Eric Yeh", "Ruth Krasnow", "Harold S. Javitz", "Gary E. Swan." ],
      "venue" : "Yiyu Yao,",
      "citeRegEx" : "Jarrold et al\\.,? 2010",
      "shortCiteRegEx" : "Jarrold et al\\.",
      "year" : 2010
    }, {
      "title" : "Text categorization with support vector machines: Learning with many relevant features",
      "author" : [ "Thorsten Joachims." ],
      "venue" : "Proceedings of the 10th European Conference on Machine Learning. Springer, pages 137–142. https://doi.org/10.1007/BFb0026683.",
      "citeRegEx" : "Joachims.,? 1998",
      "shortCiteRegEx" : "Joachims.",
      "year" : 1998
    }, {
      "title" : "Boston naming test",
      "author" : [ "Edith Kaplan", "Harold Googlass", "Sandra Weintrab." ],
      "venue" : "Lippincott Williams & Wilkins.",
      "citeRegEx" : "Kaplan et al\\.,? 2001",
      "shortCiteRegEx" : "Kaplan et al\\.",
      "year" : 2001
    }, {
      "title" : "A design framework for hierarchical ensemble of multiple feature extractors and multiple classifiers",
      "author" : [ "Kyounghoon Kim", "Helin Lin", "Jin Young Choi", "Kiyoung Choi." ],
      "venue" : "Pattern Recognition 52:1–16. https://doi.org/10.1016/j.patcog.2015.11.006.",
      "citeRegEx" : "Kim et al\\.,? 2016",
      "shortCiteRegEx" : "Kim et al\\.",
      "year" : 2016
    }, {
      "title" : "Fully automated neuropsychological assessment for detecting mild cognitive impairment",
      "author" : [ "Maider Lehr", "Emily T. Prud’hommeaux", "Izhak Shafran", "Brian Roark" ],
      "venue" : "In Proceedings of the 13th Annual Conference of the International Speech Communi-",
      "citeRegEx" : "Lehr et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Lehr et al\\.",
      "year" : 2012
    }, {
      "title" : "Authorship attribution based on life-like network automata",
      "author" : [ "Jeaneth Machicao", "Edilson A. Corrêa Jr", "Gisele H.B. Miranda", "Diego R. Amancio", "Odemir M. Bruno." ],
      "venue" : "arXiv preprint arXiv:1610.06498 .",
      "citeRegEx" : "Machicao et al\\.,? 2016",
      "shortCiteRegEx" : "Machicao et al\\.",
      "year" : 2016
    }, {
      "title" : "The CHILDES Project: Tools for analyzing talk",
      "author" : [ "Brian MacWhinney." ],
      "venue" : "Lawrence Erlbaum Associates, 3 edition.",
      "citeRegEx" : "MacWhinney.,? 2000",
      "shortCiteRegEx" : "MacWhinney.",
      "year" : 2000
    }, {
      "title" : "Graphbased natural language processing and information retrieval",
      "author" : [ "Rada Mihalcea", "Dragomir Radev." ],
      "venue" : "Cambridge University Press.",
      "citeRegEx" : "Mihalcea and Radev.,? 2011",
      "shortCiteRegEx" : "Mihalcea and Radev.",
      "year" : 2011
    }, {
      "title" : "Exploiting similarities among languages for machine translation",
      "author" : [ "Tomas Mikolov", "Quoc V. Le", "Ilya Sutskever." ],
      "venue" : "arXiv preprint arXiv:1309.4168 .",
      "citeRegEx" : "Mikolov et al\\.,? 2013a",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2013
    }, {
      "title" : "Distributed representations of words and phrases and their compositionality",
      "author" : [ "Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S. Corrado", "Jeff Dean." ],
      "venue" : "Proceedings of the 27th Annual Conference on Neural Information Processing Systems.",
      "citeRegEx" : "Mikolov et al\\.,? 2013b",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2013
    }, {
      "title" : "On exploration of classifier ensemble synergism in pedestrian detection",
      "author" : [ "Luciano Oliveira", "Urbano Nunes", "Paulo Peixoto." ],
      "venue" : "Institute of Electrical and Electronics Engineers Transactions on Intelligent Transportation Systems 11(1):16–27.",
      "citeRegEx" : "Oliveira et al\\.,? 2010",
      "shortCiteRegEx" : "Oliveira et al\\.",
      "year" : 2010
    }, {
      "title" : "Learning predictive linguistic features for alzheimer’s disease and related dementias using verbal utterances",
      "author" : [ "Sylvester O. Orimaye", "Jojo Wong", "K. Jennifer Golden." ],
      "venue" : "Proceedings of the 1st Workshop on Computational Linguis-",
      "citeRegEx" : "Orimaye et al\\.,? 2014",
      "shortCiteRegEx" : "Orimaye et al\\.",
      "year" : 2014
    }, {
      "title" : "Inducing language networks from continuous space word representations",
      "author" : [ "Bryan Perozzi", "Rami Al-Rfou", "Vivek Kulkarni", "Steven Skiena." ],
      "venue" : "Proceedings of the 5th Workshop on Complex Networks CompleNet 2014, Springer, pages 261–273.",
      "citeRegEx" : "Perozzi et al\\.,? 2014",
      "shortCiteRegEx" : "Perozzi et al\\.",
      "year" : 2014
    }, {
      "title" : "Mild cognitive impairment as a diagnostic entity",
      "author" : [ "Ronald C. Petersen." ],
      "venue" : "Journal of internal medicine 256(3):183–194. https://doi.org/10.1111/j.13652796.2004.01388.x.",
      "citeRegEx" : "Petersen.,? 2004",
      "shortCiteRegEx" : "Petersen.",
      "year" : 2004
    }, {
      "title" : "Alignment of spoken narratives for automated neuropsychological assessment",
      "author" : [ "Emily T. Prud’hommeaux", "Brian Roark" ],
      "venue" : "In Proceedings of Workshop on Automatic Speech Recognition & Understanding,ASRU",
      "citeRegEx" : "Prud.hommeaux and Roark.,? \\Q2011\\E",
      "shortCiteRegEx" : "Prud.hommeaux and Roark.",
      "year" : 2011
    }, {
      "title" : "Spoken language derived measures for detecting mild cognitive impairment",
      "author" : [ "Brian Roark", "Margaret Mitchell", "John-Paul Hosom", "Kristy Hollingshead", "Jeffrey Kaye." ],
      "venue" : "Transactions on Audio, Speech, and Language Processing, Institute of Elec-",
      "citeRegEx" : "Roark et al\\.,? 2011",
      "shortCiteRegEx" : "Roark et al\\.",
      "year" : 2011
    }, {
      "title" : "Prose and poetry classification and boundary detection using word adjacency network analysis",
      "author" : [ "Ranzivelle M. Roxas", "Giovanni Tapang." ],
      "venue" : "International Journal of Modern Physics C 21(04):503– 512. https://doi.org/10.1142/S0129183110015257.",
      "citeRegEx" : "Roxas and Tapang.,? 2010",
      "shortCiteRegEx" : "Roxas and Tapang.",
      "year" : 2010
    }, {
      "title" : "The quantitative analysis of agrammatic production: Procedure and data",
      "author" : [ "Eleanor M. Saffran", "Rita S. Berndt", "Myrna F. Schwartz." ],
      "venue" : "Brain and language 37(3):440–479. https://doi.org/10.1016/0093-934X(89)90030-8.",
      "citeRegEx" : "Saffran et al\\.,? 1989",
      "shortCiteRegEx" : "Saffran et al\\.",
      "year" : 1989
    }, {
      "title" : "Automatic text processing: The transformation, analysis, and retrieval of",
      "author" : [ "Gerard Salton." ],
      "venue" : "Reading: Addison-Wesley .",
      "citeRegEx" : "Salton.,? 1989",
      "shortCiteRegEx" : "Salton.",
      "year" : 1989
    }, {
      "title" : "Word sense disambiguation via high order of learning in complex networks",
      "author" : [ "Thiago C. Silva", "Diego R. Amancio." ],
      "venue" : "EPL (Europhysics Letters) 98(5):58001.",
      "citeRegEx" : "Silva and Amancio.,? 2012",
      "shortCiteRegEx" : "Silva and Amancio.",
      "year" : 2012
    }, {
      "title" : "Non-pharmacological interventions on cognitive functions in older people with mild cognitive impairment (mci)",
      "author" : [ "Camila V. Teixeira", "Lilian T. Gobbi", "Danilla I. Corazza", "Florindo Stella", "José L. Costa", "Sebastião Gobbi" ],
      "venue" : null,
      "citeRegEx" : "Teixeira et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Teixeira et al\\.",
      "year" : 2012
    }, {
      "title" : "Automatic detection of mild cognitive impairment from spontaneous speech using asr",
      "author" : [ "László Tóth", "Gábor Gosztolya", "Veronika Vincze", "Ildikó Hoffmann", "Gréta Szatlóczki." ],
      "venue" : "Proceedings of the 16th Annual Conference of the International Speech",
      "citeRegEx" : "Tóth et al\\.,? 2015",
      "shortCiteRegEx" : "Tóth et al\\.",
      "year" : 2015
    }, {
      "title" : "Sentence segmentation in narrative transcripts from neuropsycological tests using recurrent convolutional neural networks",
      "author" : [ "Marcos Vinı́cius Treviso", "Christopher Shulby", "Sandra Maria Aluı́sio" ],
      "venue" : "In Proceedings of the 15th Conference of the European",
      "citeRegEx" : "Treviso et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Treviso et al\\.",
      "year" : 2017
    }, {
      "title" : "Detecting mild cognitive impairment by exploiting linguistic information from transcripts",
      "author" : [ "Veronika Vincze", "Gábor Gosztolya", "László Tóth", "Ildikó Hoffmann", "Gréta Szatlóczki." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association Computer",
      "citeRegEx" : "Vincze et al\\.,? 2016",
      "shortCiteRegEx" : "Vincze et al\\.",
      "year" : 2016
    }, {
      "title" : "Neuropsychological test selection for cognitive impairment classification: A machine learning approach",
      "author" : [ "Alyssa Weakley", "Jennifer A. Williams", "Maureen Schmitter-Edgecombe", "Diane J. Cook." ],
      "venue" : "Journal of clinical and",
      "citeRegEx" : "Weakley et al\\.,? 2015",
      "shortCiteRegEx" : "Weakley et al\\.",
      "year" : 2015
    }, {
      "title" : "Wechsler memory scale (WMS-III)",
      "author" : [ "David Wechsler" ],
      "venue" : "Psychological Corporation.",
      "citeRegEx" : "Wechsler,? 1997",
      "shortCiteRegEx" : "Wechsler",
      "year" : 1997
    }, {
      "title" : "Ensemble of feature sets and classification algorithms for sentiment classification",
      "author" : [ "Rui Xia", "Chengqing Zong", "Shoushan Li." ],
      "venue" : "Information Sciences 181(6):1138–1152. https://doi.org/10.1016/j.ins.2010.11.023.",
      "citeRegEx" : "Xia et al\\.,? 2011",
      "shortCiteRegEx" : "Xia et al\\.",
      "year" : 2011
    }, {
      "title" : "Ensemble methods: foundations and algorithms",
      "author" : [ "Zhi-Hua Zhou." ],
      "venue" : "Chapman & Hall/CRC, 1st edition.",
      "citeRegEx" : "Zhou.,? 2012",
      "shortCiteRegEx" : "Zhou.",
      "year" : 2012
    } ],
    "referenceMentions" : [ {
      "referenceID" : 50,
      "context" : "Since dementias are chronic and progressive diseases, their early diagnosis ensures a greater chance of success to engage patients in non-pharmacological treatment strategies such as cognitive training, physical activity and socialization (Teixeira et al., 2012).",
      "startOffset" : 239,
      "endOffset" : 262
    }, {
      "referenceID" : 30,
      "context" : "Proposals to detect language-related impairment in dementias include machine learning (Jarrold et al., 2010; Roark et al., 2011; Fraser et al., 2014, 2015), magnetic resonance imaging (Dyrba et al.",
      "startOffset" : 86,
      "endOffset" : 155
    }, {
      "referenceID" : 45,
      "context" : "Proposals to detect language-related impairment in dementias include machine learning (Jarrold et al., 2010; Roark et al., 2011; Fraser et al., 2014, 2015), magnetic resonance imaging (Dyrba et al.",
      "startOffset" : 86,
      "endOffset" : 155
    }, {
      "referenceID" : 21,
      "context" : ", 2014, 2015), magnetic resonance imaging (Dyrba et al., 2015), and data screening tests added to demographic information (Weakley et al.",
      "startOffset" : 42,
      "endOffset" : 62
    }, {
      "referenceID" : 54,
      "context" : ", 2015), and data screening tests added to demographic information (Weakley et al., 2015).",
      "startOffset" : 67,
      "endOffset" : 89
    }, {
      "referenceID" : 34,
      "context" : "ods have been used for the English language (Lehr et al., 2012; Jarrold et al., 2014; Orimaye et al., 2014; Fraser et al., 2015; Davy et al., 2016) and for Brazilian Portuguese (Aluı́sio et al.",
      "startOffset" : 44,
      "endOffset" : 147
    }, {
      "referenceID" : 29,
      "context" : "ods have been used for the English language (Lehr et al., 2012; Jarrold et al., 2014; Orimaye et al., 2014; Fraser et al., 2015; Davy et al., 2016) and for Brazilian Portuguese (Aluı́sio et al.",
      "startOffset" : 44,
      "endOffset" : 147
    }, {
      "referenceID" : 41,
      "context" : "ods have been used for the English language (Lehr et al., 2012; Jarrold et al., 2014; Orimaye et al., 2014; Fraser et al., 2015; Davy et al., 2016) and for Brazilian Portuguese (Aluı́sio et al.",
      "startOffset" : 44,
      "endOffset" : 147
    }, {
      "referenceID" : 23,
      "context" : "ods have been used for the English language (Lehr et al., 2012; Jarrold et al., 2014; Orimaye et al., 2014; Fraser et al., 2015; Davy et al., 2016) and for Brazilian Portuguese (Aluı́sio et al.",
      "startOffset" : 44,
      "endOffset" : 147
    }, {
      "referenceID" : 18,
      "context" : "ods have been used for the English language (Lehr et al., 2012; Jarrold et al., 2014; Orimaye et al., 2014; Fraser et al., 2015; Davy et al., 2016) and for Brazilian Portuguese (Aluı́sio et al.",
      "startOffset" : 44,
      "endOffset" : 147
    }, {
      "referenceID" : 0,
      "context" : ", 2016) and for Brazilian Portuguese (Aluı́sio et al., 2016).",
      "startOffset" : 37,
      "endOffset" : 60
    }, {
      "referenceID" : 37,
      "context" : "An approach applied successfully to several areas of NLP (Mihalcea and Radev, 2011), which may suffer less from the problems mentioned above, relies on the use of complex networks and graph theory.",
      "startOffset" : 57,
      "endOffset" : 83
    }, {
      "referenceID" : 46,
      "context" : "The word adjacency network model (i Cancho and Solé, 2001; Roxas and Tapang, 2010; Amancio et al., 2012a; Amancio, 2015b) has provided good results in text classification (de Arruda et al.",
      "startOffset" : 33,
      "endOffset" : 121
    }, {
      "referenceID" : 5,
      "context" : "The word adjacency network model (i Cancho and Solé, 2001; Roxas and Tapang, 2010; Amancio et al., 2012a; Amancio, 2015b) has provided good results in text classification (de Arruda et al.",
      "startOffset" : 33,
      "endOffset" : 121
    }, {
      "referenceID" : 2,
      "context" : "The word adjacency network model (i Cancho and Solé, 2001; Roxas and Tapang, 2010; Amancio et al., 2012a; Amancio, 2015b) has provided good results in text classification (de Arruda et al.",
      "startOffset" : 33,
      "endOffset" : 121
    }, {
      "referenceID" : 1,
      "context" : ", 2016) and related tasks, namely author detection (Amancio, 2015a), identification of literary movements (Amancio et al.",
      "startOffset" : 51,
      "endOffset" : 67
    }, {
      "referenceID" : 7,
      "context" : ", 2016) and related tasks, namely author detection (Amancio, 2015a), identification of literary movements (Amancio et al., 2012c), authenticity verification (Amancio et al.",
      "startOffset" : 106,
      "endOffset" : 129
    }, {
      "referenceID" : 4,
      "context" : ", 2012c), authenticity verification (Amancio et al., 2013) and sense discrimination (Amancio et al.",
      "startOffset" : 36,
      "endOffset" : 58
    }, {
      "referenceID" : 6,
      "context" : ", 2013) and sense discrimination (Amancio et al., 2012b).",
      "startOffset" : 33,
      "endOffset" : 56
    }, {
      "referenceID" : 22,
      "context" : "Linguistic and acoustic features were used to automatically detect aphasia (Fraser et al., 2014); and AD (Fraser et al.",
      "startOffset" : 75,
      "endOffset" : 96
    }, {
      "referenceID" : 23,
      "context" : ", 2014); and AD (Fraser et al., 2015) or dementia (Orimaye et al.",
      "startOffset" : 16,
      "endOffset" : 37
    }, {
      "referenceID" : 41,
      "context" : ", 2015) or dementia (Orimaye et al., 2014) in public corpora of DementiaBank.",
      "startOffset" : 20,
      "endOffset" : 42
    }, {
      "referenceID" : 24,
      "context" : "Other studies distinguished differents types of dementia (Garrard et al., 2014; Jarrold et al., 2014), in which speech samples were elicited using the Picnic picture of the Western Aphasia Battery.",
      "startOffset" : 57,
      "endOffset" : 101
    }, {
      "referenceID" : 29,
      "context" : "Other studies distinguished differents types of dementia (Garrard et al., 2014; Jarrold et al., 2014), in which speech samples were elicited using the Picnic picture of the Western Aphasia Battery.",
      "startOffset" : 57,
      "endOffset" : 101
    }, {
      "referenceID" : 0,
      "context" : "(Aluı́sio et al., 2016) used a variety of linguistic metrics, such as syntactic complexity, idea density (da Cunha et al.",
      "startOffset" : 0,
      "endOffset" : 23
    }, {
      "referenceID" : 16,
      "context" : "Davy et al. (2016) also used the Picnic scene for detecting MCI, where the subjects were asked to write (by hand) a detailed description of the scene.",
      "startOffset" : 0,
      "endOffset" : 19
    }, {
      "referenceID" : 16,
      "context" : "Davy et al. (2016) also used the Picnic scene for detecting MCI, where the subjects were asked to write (by hand) a detailed description of the scene. As for automatic detection of MCI in narrative speech, Roark et al. (2011) extracted speech features and linguistic complexity measures of speech samples obtained with the Wechsler Logical Memory (WLM) subtest (Wechsler et al.",
      "startOffset" : 0,
      "endOffset" : 226
    }, {
      "referenceID" : 16,
      "context" : "Davy et al. (2016) also used the Picnic scene for detecting MCI, where the subjects were asked to write (by hand) a detailed description of the scene. As for automatic detection of MCI in narrative speech, Roark et al. (2011) extracted speech features and linguistic complexity measures of speech samples obtained with the Wechsler Logical Memory (WLM) subtest (Wechsler et al., 1997), and Lehr et al. (2012) fully automatized the WLM subtest.",
      "startOffset" : 0,
      "endOffset" : 409
    }, {
      "referenceID" : 16,
      "context" : "Davy et al. (2016) also used the Picnic scene for detecting MCI, where the subjects were asked to write (by hand) a detailed description of the scene. As for automatic detection of MCI in narrative speech, Roark et al. (2011) extracted speech features and linguistic complexity measures of speech samples obtained with the Wechsler Logical Memory (WLM) subtest (Wechsler et al., 1997), and Lehr et al. (2012) fully automatized the WLM subtest. Some studies used short animated films to evaluate immediate and delayed recall in MCI patients which were asked to talk about the first film shown, then about their previous day, and finally about another film shown last. Tóth et al. (2015) adopted automatic speech recognition (ASR) to extract a phonetic level segmentation, which they used to calculate acoustic features.",
      "startOffset" : 0,
      "endOffset" : 686
    }, {
      "referenceID" : 16,
      "context" : "Davy et al. (2016) also used the Picnic scene for detecting MCI, where the subjects were asked to write (by hand) a detailed description of the scene. As for automatic detection of MCI in narrative speech, Roark et al. (2011) extracted speech features and linguistic complexity measures of speech samples obtained with the Wechsler Logical Memory (WLM) subtest (Wechsler et al., 1997), and Lehr et al. (2012) fully automatized the WLM subtest. Some studies used short animated films to evaluate immediate and delayed recall in MCI patients which were asked to talk about the first film shown, then about their previous day, and finally about another film shown last. Tóth et al. (2015) adopted automatic speech recognition (ASR) to extract a phonetic level segmentation, which they used to calculate acoustic features. Vincze et al. (2016) used speech, morphological, semantic, and demographic features collected from their speech transcripts to automatically identify patients suffering from MCI.",
      "startOffset" : 0,
      "endOffset" : 840
    }, {
      "referenceID" : 37,
      "context" : "The theory and concepts of complex networks have been used in several NLP tasks (Mihalcea and Radev, 2011; Cong and Liu, 2014), such as text classification (de Arruda et al.",
      "startOffset" : 80,
      "endOffset" : 126
    }, {
      "referenceID" : 16,
      "context" : "The theory and concepts of complex networks have been used in several NLP tasks (Mihalcea and Radev, 2011; Cong and Liu, 2014), such as text classification (de Arruda et al.",
      "startOffset" : 80,
      "endOffset" : 126
    }, {
      "referenceID" : 8,
      "context" : ", 2016), summarization (Antiqueira et al., 2009; Amancio et al., 2012a) and word sense disambiguation (Silva and Amancio, 2012).",
      "startOffset" : 23,
      "endOffset" : 71
    }, {
      "referenceID" : 5,
      "context" : ", 2016), summarization (Antiqueira et al., 2009; Amancio et al., 2012a) and word sense disambiguation (Silva and Amancio, 2012).",
      "startOffset" : 23,
      "endOffset" : 71
    }, {
      "referenceID" : 49,
      "context" : ", 2012a) and word sense disambiguation (Silva and Amancio, 2012).",
      "startOffset" : 39,
      "endOffset" : 64
    }, {
      "referenceID" : 35,
      "context" : "This decision was made based on two factors: first, recent work has shown that lemmatization has little or no influence when network modeling is adopted in related tasks (Machicao et al., 2016).",
      "startOffset" : 170,
      "endOffset" : 193
    }, {
      "referenceID" : 1,
      "context" : ", 2009; Amancio et al., 2012a) and word sense disambiguation (Silva and Amancio, 2012). In this study, we used the word co-occurrence model (also called the word adjacency model) with a small modification because most of the syntactical relations occur among neighbouring words (i Cancho et al., 2004). Each distinct word becomes a node and words that are adjacent in the text are connected by an edge. Mathematically, a network is defined as an undirected graph G = {V,E}, formed by a set V = {v1, v2, ..., vn} of nodes (words) and a set E = {e1, e2, ..., em} of edges (co-occurrence) that are represented by an adjacency matrix A, whose elementsAij are equal to 1 whenever there is an edge connecting nodes (words) i and j, and equal to 0 otherwise. Before modeling texts into complex networks, it is often necessary to do some preprocessing in the raw text. Preprocessing starts with tokenization where each document/text is divided into tokens (meaningful elements, e.g.: words and punctuation marks) and then stopwords and punctuation marks are removed, since they have little semantic meaning. One last step we decided to eliminate from the preprocessing pipeline is lemmatization, which transforms each word into its canonical form. This decision was made based on two factors: first, recent work has shown that lemmatization has little or no influence when network modeling is adopted in related tasks (Machicao et al., 2016). Second, the lemmatization process requires part-of-speech (POS) tagging that may introduce undesirable noises/errors in the text, since the texts in our work are transcriptions containing disfluencies. Another problem with transcriptions in our work is their size. As demonstrated by Amancio (2015c), the classification of small texts using networks can be impaired, since short texts have almost linear networks, and the topological measures of these networks have little or no informa1 2",
      "startOffset" : 8,
      "endOffset" : 1735
    }, {
      "referenceID" : 38,
      "context" : "To solve this problem, we adapted the approach of modeling networks with word embeddings proposed by Perozzi et al. (2014) to enrich the networks with semantic information.",
      "startOffset" : 101,
      "endOffset" : 123
    }, {
      "referenceID" : 11,
      "context" : "In this process of word embedding, language networks are generated from continuous word representations, where each word is represented by a dense, real-valued vector obtained by trainning neural networks in the language model task (or variations, such as context prediction) (Bengio et al., 2003; Collobert et al., 2011; Mikolov et al., 2013a,b). This structure is known to capture syntatic and semantic information (Mikolov et al., 2013a,b). Perozzi et al. (2014), in particular, takes advantage of word embeddings to build networks where each word is a vertice and edges are defined by similarity between words established by the proximity of the word vectors.",
      "startOffset" : 277,
      "endOffset" : 466
    }, {
      "referenceID" : 10,
      "context" : "org/DementiaBank/ including those with MCI (for more detail, see (Becker et al., 1994)).",
      "startOffset" : 65,
      "endOffset" : 86
    }, {
      "referenceID" : 25,
      "context" : "For this dataset, interviews were conducted in English and narrative speech was elicited using the Cookie Theft picture (Goodglass et al., 2001) (Figure 3 from Goodglass et al.",
      "startOffset" : 120,
      "endOffset" : 144
    }, {
      "referenceID" : 36,
      "context" : "The patients’ verbal utterances were recorded and then transcribed into the CHAT (Codes for the Human Analysis of Transcripts) transcription format (MacWhinney, 2000).",
      "startOffset" : 148,
      "endOffset" : 166
    }, {
      "referenceID" : 23,
      "context" : "mother’s finished certain of the the dishes ), like (Fraser et al., 2015).",
      "startOffset" : 52,
      "endOffset" : 73
    }, {
      "referenceID" : 23,
      "context" : "For this dataset, interviews were conducted in English and narrative speech was elicited using the Cookie Theft picture (Goodglass et al., 2001) (Figure 3 from Goodglass et al. (2001) in Section A.",
      "startOffset" : 121,
      "endOffset" : 184
    }, {
      "referenceID" : 0,
      "context" : "Table 2 shows the demographic information of the two diagnostic groups, which were also used in (Aluı́sio et al., 2016).",
      "startOffset" : 96,
      "endOffset" : 119
    }, {
      "referenceID" : 43,
      "context" : "The criteria used to diagnose MCI came from (Petersen, 2004).",
      "startOffset" : 44,
      "endOffset" : 60
    }, {
      "referenceID" : 47,
      "context" : "When each participant had finished looking at the pictures, the examiner asked the subject to tell the story in their own words, as in (Saffran et al., 1989).",
      "startOffset" : 135,
      "endOffset" : 157
    }, {
      "referenceID" : 13,
      "context" : "Other tests were applied after the narrative in the following sequence: phonemic verbal fluency test, action verbal fluency, Camel and Cactus test (Bozeat et al., 2000), and Boston Naming test (Kaplan et al.",
      "startOffset" : 147,
      "endOffset" : 168
    }, {
      "referenceID" : 32,
      "context" : ", 2000), and Boston Naming test (Kaplan et al., 2001), in order to diagnose the groups.",
      "startOffset" : 32,
      "endOffset" : 53
    }, {
      "referenceID" : 0,
      "context" : "We also evaluated a different version of this dataset used in Aluı́sio et al. (2016), where narratives were manually revised to improve parsing results: agramatical sentences and all the patients’ comments not related to the story were removed, and omitted subjects were inserted.",
      "startOffset" : 62,
      "endOffset" : 85
    }, {
      "referenceID" : 52,
      "context" : "We used the automatic sentence segmentation method referred to as DeepBond (Treviso et al., 2017).",
      "startOffset" : 75,
      "endOffset" : 97
    }, {
      "referenceID" : 9,
      "context" : "The subject then retold the narrative to the examiner twice: once immediately upon hearing it and again after a 30-minute delay (Bayles and Tomoeda, 1991).",
      "startOffset" : 128,
      "endOffset" : 154
    }, {
      "referenceID" : 12,
      "context" : "Since the occurrence of out-of-vocabulary words is common in texts, we used the method proposed by (Bojanowski et al., 2016) to generate word embeddings.",
      "startOffset" : 99,
      "endOffset" : 124
    }, {
      "referenceID" : 39,
      "context" : "It provides some improvement in comparison with the traditional skip-gram model in syntactic evaluation (Mikolov et al., 2013b) but not for the semantic evaluation.",
      "startOffset" : 104,
      "endOffset" : 127
    }, {
      "referenceID" : 14,
      "context" : "PageRank: is a centrality measurement that reflects the relevance of a node based on its connections to other relevant nodes (Brin and Page, 1998);",
      "startOffset" : 125,
      "endOffset" : 146
    }, {
      "referenceID" : 2,
      "context" : "each node i possesses a value Xi, so we calculate the average μ(X), standard deviation σ(X) and skewness γ(X) for each measurement (Amancio, 2015b).",
      "startOffset" : 131,
      "endOffset" : 147
    }, {
      "referenceID" : 45,
      "context" : "2 Linguistic Features Linguistic features for classification of neuropsychological assessments have been utilized in several works (Roark et al., 2011; Jarrold et al., 2014; Fraser et al., 2014; Orimaye et al., 2014; Fraser et al., 2015; Vincze et al., 2016; Davy et al., 2016).",
      "startOffset" : 131,
      "endOffset" : 277
    }, {
      "referenceID" : 29,
      "context" : "2 Linguistic Features Linguistic features for classification of neuropsychological assessments have been utilized in several works (Roark et al., 2011; Jarrold et al., 2014; Fraser et al., 2014; Orimaye et al., 2014; Fraser et al., 2015; Vincze et al., 2016; Davy et al., 2016).",
      "startOffset" : 131,
      "endOffset" : 277
    }, {
      "referenceID" : 22,
      "context" : "2 Linguistic Features Linguistic features for classification of neuropsychological assessments have been utilized in several works (Roark et al., 2011; Jarrold et al., 2014; Fraser et al., 2014; Orimaye et al., 2014; Fraser et al., 2015; Vincze et al., 2016; Davy et al., 2016).",
      "startOffset" : 131,
      "endOffset" : 277
    }, {
      "referenceID" : 41,
      "context" : "2 Linguistic Features Linguistic features for classification of neuropsychological assessments have been utilized in several works (Roark et al., 2011; Jarrold et al., 2014; Fraser et al., 2014; Orimaye et al., 2014; Fraser et al., 2015; Vincze et al., 2016; Davy et al., 2016).",
      "startOffset" : 131,
      "endOffset" : 277
    }, {
      "referenceID" : 23,
      "context" : "2 Linguistic Features Linguistic features for classification of neuropsychological assessments have been utilized in several works (Roark et al., 2011; Jarrold et al., 2014; Fraser et al., 2014; Orimaye et al., 2014; Fraser et al., 2015; Vincze et al., 2016; Davy et al., 2016).",
      "startOffset" : 131,
      "endOffset" : 277
    }, {
      "referenceID" : 53,
      "context" : "2 Linguistic Features Linguistic features for classification of neuropsychological assessments have been utilized in several works (Roark et al., 2011; Jarrold et al., 2014; Fraser et al., 2014; Orimaye et al., 2014; Fraser et al., 2015; Vincze et al., 2016; Davy et al., 2016).",
      "startOffset" : 131,
      "endOffset" : 277
    }, {
      "referenceID" : 18,
      "context" : "2 Linguistic Features Linguistic features for classification of neuropsychological assessments have been utilized in several works (Roark et al., 2011; Jarrold et al., 2014; Fraser et al., 2014; Orimaye et al., 2014; Fraser et al., 2015; Vincze et al., 2016; Davy et al., 2016).",
      "startOffset" : 131,
      "endOffset" : 277
    }, {
      "referenceID" : 26,
      "context" : "We used the Coh-Metrix3(Graesser et al., 2004) tool to extract features of English transcripts, resulting in 106 features.",
      "startOffset" : 23,
      "endOffset" : 46
    }, {
      "referenceID" : 0,
      "context" : "For Portuguese, Coh-Metrix-Dementia (Aluı́sio et al., 2016) was used.",
      "startOffset" : 36,
      "endOffset" : 59
    }, {
      "referenceID" : 31,
      "context" : ", with no information relating to word order) has been a robust solution for text classification by capturing word content- and frequency-specific differences that are relevant to the categories under investigation (Joachims, 1998; Drucker et al., 1999).",
      "startOffset" : 215,
      "endOffset" : 253
    }, {
      "referenceID" : 20,
      "context" : ", with no information relating to word order) has been a robust solution for text classification by capturing word content- and frequency-specific differences that are relevant to the categories under investigation (Joachims, 1998; Drucker et al., 1999).",
      "startOffset" : 215,
      "endOffset" : 253
    }, {
      "referenceID" : 48,
      "context" : "In this methodology, transcripts are represented by a table in which the columns represent the terms (or existing words) in the transcripts and the values represent frequency of a term in a document, such as binary weights, term frequency (tf) or term frequency – inverse document frequency (tf–idf) (Salton, 1989).",
      "startOffset" : 300,
      "endOffset" : 314
    }, {
      "referenceID" : 57,
      "context" : "majority vote or average of class probabilities, to produce a single result (Zhou, 2012).",
      "startOffset" : 76,
      "endOffset" : 88
    }, {
      "referenceID" : 15,
      "context" : "This approach has been successful for NLP (Collobert et al., 2011), sentiment classification (Xia et al.",
      "startOffset" : 42,
      "endOffset" : 66
    }, {
      "referenceID" : 56,
      "context" : ", 2011), sentiment classification (Xia et al., 2011) and pedestrian detection in images (Oliveira et al.",
      "startOffset" : 34,
      "endOffset" : 52
    }, {
      "referenceID" : 40,
      "context" : ", 2011) and pedestrian detection in images (Oliveira et al., 2010; Kim et al., 2016).",
      "startOffset" : 43,
      "endOffset" : 84
    }, {
      "referenceID" : 33,
      "context" : ", 2011) and pedestrian detection in images (Oliveira et al., 2010; Kim et al., 2016).",
      "startOffset" : 43,
      "endOffset" : 84
    }, {
      "referenceID" : 12,
      "context" : "We trained the model proposed by Bojanowski et al. (2016) with default parametrs (100 dimensional embeddings, 5 size of the context window, 5 number of epochs).",
      "startOffset" : 33,
      "endOffset" : 58
    }, {
      "referenceID" : 44,
      "context" : "The accuracies found here are comparable to the values reported by other authors, ranging from 60% to 85% (Prud’hommeaux and Roark, 2011; Lehr et al., 2012; Tóth et al., 2015; Vincze et al., 2016), which means that it is not easy to distinguish between healthy subjects and those with cognitive impairments.",
      "startOffset" : 106,
      "endOffset" : 196
    }, {
      "referenceID" : 34,
      "context" : "The accuracies found here are comparable to the values reported by other authors, ranging from 60% to 85% (Prud’hommeaux and Roark, 2011; Lehr et al., 2012; Tóth et al., 2015; Vincze et al., 2016), which means that it is not easy to distinguish between healthy subjects and those with cognitive impairments.",
      "startOffset" : 106,
      "endOffset" : 196
    }, {
      "referenceID" : 51,
      "context" : "The accuracies found here are comparable to the values reported by other authors, ranging from 60% to 85% (Prud’hommeaux and Roark, 2011; Lehr et al., 2012; Tóth et al., 2015; Vincze et al., 2016), which means that it is not easy to distinguish between healthy subjects and those with cognitive impairments.",
      "startOffset" : 106,
      "endOffset" : 196
    }, {
      "referenceID" : 53,
      "context" : "The accuracies found here are comparable to the values reported by other authors, ranging from 60% to 85% (Prud’hommeaux and Roark, 2011; Lehr et al., 2012; Tóth et al., 2015; Vincze et al., 2016), which means that it is not easy to distinguish between healthy subjects and those with cognitive impairments.",
      "startOffset" : 106,
      "endOffset" : 196
    } ],
    "year" : 2017,
    "abstractText" : "Mild Cognitive Impairment (MCI) is a mental disorder difficult to diagnose. Although language impairment is an important marker it is frequently undervalued in cognitive assessments. Linguistic features, mainly from parsers, have been used to detect MCI. However, MCI disfluencies produce agrammatical speech impacting in parsing results; manually correcting transcripts of patient’s speech is not a solution to large scale assessments. In this paper, we use complex network features to automatically identifying MCI in transcripts, using several classification algorithms, as it a lightweight and language independent representation. We modeled transcripts into complex networks and enriched them with word embeddings to better represent short texts produced in assessments. We evaluate our model in three datasets: one from the DementiaBank; Cinderella and Arizona-Battery in Portuguese were produced by assessments applied at University of São Paulo Medical School. The results show that complex networks are suitable to detect MCI and outperform linguistic features in all datasets. We also combined the classifiers through ensemble and multi-view learning. The ensemble of algorithms and multi-view method achieved 10% of improvement in Cinderella dataset compared to the best individual classifier. For the Arizona dataset, the multi-view achieved the highest accuracy (80%), a 4.71% of improvement.",
    "creator" : "LaTeX with hyperref package"
  }
}