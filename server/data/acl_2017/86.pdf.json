{
  "name" : "86.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "A Syntactic Neural Model for General-Purpose Code Generation",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "1 000\n011\n012\n013\n014\n015\n016\n017\n018\n019\n020\n021\n022\n023\n024\n025\n026\n027\n028\n029\n030\n031\n032\n033\n034\n035\n036\n037\n038\n039\n040\n041\n042\n043\n044\n045\n046\n047\n048\n049\n061\n062\n063\n064\n065\n066\n067\n068\n069\n070\n071\n072\n073\n074\n075\n076\n077\n078\n079\n080\n081\n082\n083\n084\n085\n086\n087\n088\n089\n090\n091\n092\n093\n094\n095\n096\n097\n098\n099"
    }, {
      "heading" : "1 Introduction",
      "text" : "Every programmer has experienced the situation where they know what they want to do, but do not have the ability to turn it into a concrete implementation. For example, a Python programmer may want to “sort my list in descending order,” but not be able to come up with the proper syntax sorted(my list, reverse=True) to realize his intention. To resolve this impasse, it is common for programmers to search the web in natural language (NL), find an answer, and modify it into the desired form (Brandt et al., 2009, 2010). However, this is time-consuming, and thus the software engineering literature is ripe with methods to directly generate code from NL descriptions, mostly with hand-engineered methods highly tailored to specific programming languages (Balzer, 1985; Little and Miller, 2009; Gvero and Kuncak, 2015).\nIn parallel, the NLP community has developed methods for data-driven semantic parsing, which attempt to map NL to structured logical forms executable by computers. These logical forms can be general-purpose meaning representations (Clark and Curran, 2007; Banarescu et al., 2013), formalisms for querying knowledge bases (Tang and Mooney, 2001; Zettlemoyer and Collins, 2005; Berant et al., 2013) and instructions for robots or personal assistants (Artzi and Zettlemoyer, 2013; Quirk et al., 2015), among others. While these methods have the advantage of being learnable from data, compared to the programming languages (PLs) in use by programmers, the domainspecific languages targeted by these works have a schema and syntax that is relatively simple.\nRecently, Ling et al. (2016) have proposed a data-driven code generation method for high-level, general-purpose PLs like Python and Java. This work treats code generation as a sequence-tosequence modeling problem, and introduce methods to generate words from character-level models, and copy variable names from input descriptions. However, unlike most work in semantic parsing, it does not consider the fact that code has to be well-defined programs in the target syntax.\nIn this work, we propose a data-driven syntaxbased neural network model tailored for generation of general-purpose PLs like Python. In order to capture the strong underlying syntax of the PL, we define a model that transduces an NL statement into an Abstract Syntax Tree (AST; Fig. 1(a), § 2) for the target PL. ASTs can be deterministically generated for all well-formed programs using standard parsers provided by the PL, and thus give us a way to obtain syntax information with minimal engineering. Once we generate an AST, we can use deterministic generation tools to convert the AST into surface code. We hypothesize that such a structured approach has two benefits.\n2\n101\n102\n103\n104\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n123\n124\n125\n126\n127\n128\n129\n130\n131\n132\n133\n134\n135\n136\n137\n138\n139\n140\n141\n142\n143\n144\n145\n146\n147\n148\n149\n150\n151\n152\n153\n154\n155\n156\n157\n158\n159\n160\n161\n162\n163\n164\n165\n166\n167\n168\n169\n170\n171\n172\n173\n174\n175\n176\n177\n178\n179\n180\n181\n182\n183\n184\n185\n186\n187\n188\n189\n190\n191\n192\n193\n194\n195\n196\n197\n198\n199\nProduction Rule Role Explanation Call 7→ expr[func] expr*[args] keyword*[keywords] Function Call . func: the function to be invoked . args: arguments list . keywords: keyword arguments list If 7→ expr[test] stmt*[body] stmt*[orelse] If Statement . test: condition expression . body: statements inside the If clause . orelse: elif or else statements For 7→ expr[target] expr*[iter] stmt*[body] For Loop . target: iteration variable . iter: enumerable to iterate over . body: loop body . orelse: else statementsstmt*[orelse] FunctionDef 7→ identifier[name] arguments*[args] Function Def. . name: function name . args: function arguments\n. body: function bodystmt*[body]\nTable 1: Example production rules for common Python statements (Python Software Foundation, 2016)\nFirst, we hypothesize that structure can be used to constrain our hypothesis space, ensuring generation of well-formed code. To this end, we propose a syntax-driven neural code generation model. The backbone of our approach is a grammar model (§ 3) which formalizes the generation story of a derivation AST into sequential application of actions that either apply production rules (§ 3.1), or emit terminal tokens (§ 3.2). The underlying syntax is therefore encoded in the grammar model a priori as the set of possible actions. Our approach frees the model from recovering the underlying grammar from limited training data, and instead enables the system to focus on learning the compositionality among existing grammar rules. Xiao et al. (2016) have noted that this imposition of structure on neural models is useful for semantic parsing, and we expect this to be even more important for general-purpose PLs where the syntax trees are larger and more complex.\nSecond, we hypothesize that structural information helps to model information flow within the network, which naturally reflects the recursive structure of PLs. To test this, we extend a standard recurrent neural network (RNN) decoder to allow for additional neural connections which reflect the recursive structure of an AST (§ 4.2). As an example, when expanding the node ? in Fig. 1(a), we make use of the information from both its parent and left sibling (the dashed rectangle). This enables us to locally pass information of relevant code segments via neural network connections, resulting in more confident predictions.\nExperiments (§ 5) on two Python code generation tasks show 11.7% and 9.3% absolute improvements in accuracy against the state-of-the-art system (Ling et al., 2016). Our model also gives competitive performance on a standard semantic parsing benchmark."
    }, {
      "heading" : "2 The Code Generation Problem",
      "text" : "Given an NL description x, our task is to generate the code snippet c in a modern PL based on the in-\ntent of x. We attack this problem by first generating the underlying AST. We define a probabilistic grammar model of generating an AST y given x: p(y|x). The best-possible AST ŷ is then given by\nŷ = argmax y\np(y|x). (1)\nŷ is then deterministically converted to the corresponding surface code c.1 While this paper uses examples from Python code, our method is PLagnostic.\nBefore detailing our approach, we first present a brief introduction of the Python AST and its underlying grammar. The Python abstract grammar contains a set of production rules, and an AST is generated by applying several production rules composed of a head node and multiple child nodes. For instance, the first rule in Tab. 1 is used to generate the function call sorted(·) in Fig. 1(a). It consists of a head node of type Call, and three child nodes of type expr, expr* and keyword*, respectively. Labels of each node are noted within brackets. In an AST, non-terminal nodes sketch the general structure of the target code, while terminal nodes can be categorized into two types: operation terminals and variable terminals. Operation terminals correspond to basic arithmetic operations like AddOp.Variable terminal nodes store values for variables and constants of built-in data types2. For instance, all terminal nodes in Fig. 1(a) are variable terminal nodes."
    }, {
      "heading" : "3 Grammar Model",
      "text" : "Before detailing our neural code generation method, we first introduce the grammar model at its core. Our probabilistic grammar model defines the generative story of a derivation AST. We factorize the generation process of an AST into sequential application of actions of two types:\n• APPLYRULE[r] applies a production rule r to the current derivation tree;\n1We use astor library to convert ASTs into Python code. 2bool, float, int, str.\n3\n201\n202\n203\n204\n205\n206\n207\n208\n209\n210\n211\n212\n213\n214\n215\n216\n217\n218\n219\n220\n221\n222\n223\n224\n225\n226\n227\n228\n229\n230\n231\n232\n233\n234\n235\n236\n237\n238\n239\n240\n241\n242\n243\n244\n245\n246\n247\n248\n249\n250\n251\n252\n253\n254\n255\n256\n257\n258\n259\n260\n261\n262\n263\n264\n265\n266\n267\n268\n269\n270\n271\n272\n273\n274\n275\n276\n277\n278\n279\n280\n281\n282\n283\n284\n285\n286\n287\n288\n289\n290\n291\n292\n293\n294\n295\n296\n297\n298\n299\nExpr\nroot\nexpr[value]\nCall\nexpr*[args] keyword*[keywords]\nName\nstr(sorted)\nexpr[func]\nexpr\nName\nstr(my_list)\nkeyword\nstr(reverse) expr[value]\nName\nstr(True)\n( _ , = )\n⋆\nt1\nt2\nt3\nt4\nt5\nt6\nt7\nt8\nt9\nt10\nt11\nt12\nt14\nroot ↦ Expr\nExpr ↦ expr[value]\nexpr ↦ Call\nexpr ↦ Name\nName ↦ str\n[sorted]\n[</n>]\nexpr* ↦ expr\nexpr ↦ Name\nName ↦ str\n[my_list]\nkeyword* ↦ keyword\nCall ↦ expr[func]  expr*[args]  keyword*[keywords]\nAction Flow Parent Feeding\nti Apply Rule\nti Generate Token\nti GenToken with Copyt13 [</n>]\nt1\nt2\nt3\nt4\nt5\nt6t7t8\nt4\nt9\nt10\nt11 t12 t13\nt4\nt14\nt15 t16 t17 t16\nt18\nt19 t20 t21\nt0\n(a) (b)\n_ Input: Code:\n. . .\nFigure 1: (a) the Abstract Syntax Tree (AST) for the given example code. Dashed nodes denote terminals. Nodes are labeled with time steps during which they are generated. (b) the action sequence (up to t14) used to generate the AST in (a)\n• GENTOKEN[v] populates a variable terminal node by appending a terminal token v.\nFig. 1(b) shows the generation process of the target AST in Fig. 1(a). Each node in Fig. 1(b) indicates an action. Action nodes are connected by solid arrows which depict the chronological order of the action flow. The generation proceeds in depth-first, left-to-right order (dotted arrows represent parent feeding, explained in § 4.2.1).\nFormally, under our grammar model, the probability of generating an AST y is factorized as:\np(y|x) = T∏ t=1 p(at|x, a<t), (2)\nwhere at is the action taken at time step t, and a<t is the sequence of actions before t. We will explain how to compute Eq. (2) in § 4. Put simply, the generation process begins from a root node at t0, and proceeds by the model choosing APPLYRULE actions to generate the overall program structure from a closed set of grammar rules, then at leaves of the tree corresponding to variable terminals, the model switches to GENTOKEN actions to generate variables or constants from the open set. We describe this process in detail below."
    }, {
      "heading" : "3.1 APPLYRULE Actions",
      "text" : "APPLYRULE actions generate program structure, expanding the current node (the frontier node at time step t: nft) in a depth-first, left-to-right traversal of the tree. Given a fixed set of production rules, APPLYRULE chooses a rule r from the subset that has a head matching the type of nft , and uses r to expand nft by appending all child nodes specified by the selected production. As an\nexample, in Fig. 1(b), the rule Call 7→ expr. . . expands the frontier node Call at time step t4, and its three child nodes expr, expr* and keyword* are added to the derivation.\nAPPLYRULE actions grow the derivation AST by appending nodes. When a variable terminal node (e.g., str) is added to the derivation and becomes the frontier node, the grammar model then switches to GENTOKEN actions to populate the variable terminal with tokens.\nUnary Closure Sometimes, generating an AST requires applying a chain of unary productions. For instance, it takes three time steps (t9 − t11) to generate the sub-structure expr* 7→ expr 7→ Name 7→ str in Fig. 1(a). This can be effectively reduced to one step of APPLYRULE action by taking the closure of the chain of unary productions and merging them into a single rule: expr* 7→∗ str. Unary closures reduce the number of actions needed, but would potentially increase the size of the grammar. In our experiments we tested our model both with and without unary closures (§ 5)."
    }, {
      "heading" : "3.2 GENTOKEN Actions",
      "text" : "Once we reach a frontier node nft that corresponds to a variable type (e.g., str), GENTOKEN actions are used to fill this node with values. For generalpurpose PLs like Python, variables and constants have values with one or multiple tokens. For instance, a node that stores the name of a function (e.g., sorted) has a single token, while a node that denotes a string constant (e.g., a=‘hello world’) could have multiple tokens. Our model copes with both scenarios by firing GENTOKEN actions at one or more time steps. At each time\n4\n301\n302\n303\n304\n305\n306\n307\n308\n309\n310\n311\n312\n313\n314\n315\n316\n317\n318\n319\n320\n321\n322\n323\n324\n325\n326\n327\n328\n329\n330\n331\n332\n333\n334\n335\n336\n337\n338\n339\n340\n341\n342\n343\n344\n345\n346\n347\n348\n349\n363\n364\n365\n366\n367\n368\n369\n370\n371\n372\n373\n374\n375\n376\n377\n378\n379\n380\n381\n382\n383\n384\n385\n386\n387\n388\n389\n390\n391\n392\n393\n394\n395\n396\n397\n398\n399\nstep, GENTOKEN appends one terminal token to the current frontier variable node. A special </n> token is used to “close” the node. The grammar model then proceeds to the new frontier node.\nTerminal tokens can be generated from a predefined vocabulary, or be directly copied from the input NL. This is motivated by the observation that the input description often contains out-ofvocabulary (OOV) variable names or literal values that are directly used in the target code. For instance, in our running example the variable name my list can be directly copied from the the input at t12. We give implementation details in § 4.2.2."
    }, {
      "heading" : "4 Estimating Action Probabilities",
      "text" : "We estimate action probabilities in Eq. (2) using attentional neural encoder-decoder models with an information flow structured by the syntax trees."
    }, {
      "heading" : "4.1 Encoder",
      "text" : "For an NL description x consisting of n words {wi}ni=1, the encoder computes a context sensitive embedding hi for each wi using a bidirectional Long Short-Term Memory (LSTM) network (Hochreiter and Schmidhuber, 1997), similar to the setting in (Bahdanau et al., 2014). See supplementary materials for detailed equations."
    }, {
      "heading" : "4.2 Decoder",
      "text" : "The decoder uses a RNN to model the sequential generation process of an AST defined as Eq. (2). Each action step in the grammar model naturally grounds to a time step in the decoder RNN. Therefore, the action sequence in Fig. 1(b) can be interpreted as unrolling RNN time steps, with solid arrows indicating RNN connections. The RNN maintains an internal state to track the generation process (§ 4.2.1), which will then be used to compute action probabilities p(at|x, a<t) (§ 4.2.2)."
    }, {
      "heading" : "4.2.1 Tracking Generation States",
      "text" : "Our implementation of the decoder resembles a vanilla LSTM, with additional neural connections (parent feeding, Fig. 1(b)) to reflect the topological structure of an AST. The decoder’s internal hidden state at time step t, st, is given by:\nst = fLSTM([at−1 : ct : pt : nft ], st−1), (3) where fLSTM(·) is the LSTM update function. [:] denotes vector concatenation. st will then be used to compute action probabilities p(at|x, a<t) in Eq. (2). Here, at−1 is the embedding of the previous action. ct is a context vector retrieved from\ninput encodings {hi} via soft attention. pt is a vector that encodes the information of the parent action. nft denotes the node type embedding of the current frontier node nft\n3. Intuitively, feeding the decoder the information of nft helps the model to keep track of the frontier node to expand. Action Embedding at We maintain two action embedding matrices, WR and WG. Each row in WR (WG) corresponds to an embedding vector for an action APPLYRULE[r] (GENTOKEN[v]). Context Vector ct The decoder RNN uses soft attention to retrieve a context vector ct from the input encodings {hi} pertain to the prediction of the current action. We follow Bahdanau et al. (2014) and use a Deep Neural Network (DNN) with a single hidden layer to compute attention weights. Parent Feeding pt Our decoder RNN uses additional neural connections to directly pass information from parent actions. For instance, when computing s9, the information from its parent action step t4 will be used. Formally, we define the parent action step pt as the time step at which the frontier node nft is generated. As an example, for t9, its parent action step p9 is t4, since nf9 is the node ?, which is generated at t4 by the APPLYRULE[Call7→. . .] action.\nWe model parent information pt from two sources: (1) the hidden state of parent action spt , and (2) the embedding of parent action apt . pt is the concatenation. The parent feeding schema enables the model to utilize the information of parent code segments to make more confident predictions. Similar approaches of injecting parent information were also explored in the SEQ2TREE model in Dong and Lapata (2016)4.\n3We maintain an embedding for each node type. 4SEQ2TREE generates tree-structured outputs by condi-\n5\n401\n402\n403\n404\n405\n406\n407\n408\n409\n410\n411\n412\n413\n414\n415\n416\n417\n418\n419\n420\n421\n422\n423\n424\n425\n426\n427\n428\n429\n430\n431\n432\n433\n434\n435\n436\n437\n438\n439\n440\n441\n442\n443\n444\n445\n446\n447\n448\n449\n465\n466\n467\n468\n469\n470\n471\n472\n473\n474\n475\n476\n477\n478\n479\n480\n481\n482\n483\n484\n485\n486\n487\n488\n489\n490\n491\n492\n493\n494\n495\n496\n497\n498\n499"
    }, {
      "heading" : "4.2.2 Calculating Action Probabilities",
      "text" : "In this section we explain how action probabilities p(at|x, a<t) are computed based on st. APPLYRULE The probability of applying rule r as the current action at is given by a softmax5:\np(at = APPLYRULE[r]|x, a<t) = softmax(WR · g(st))ᵀ · e(r) (4)\nwhere g(·) is a non-linearity tanh(W ·st+b), and e(r) the one-hot vector for rule r. GENTOKEN As in § 3.2, a token v can be generated from a predefined vocabulary or copied from the input, defined as the marginal probability:\np(at = GENTOKEN[v]|x, a<t) = p(gen|x, a<t)p(v|gen, x, a<t) + p(copy|x, a<t)p(v|copy, x, a<t).\nThe selection probabilities p(gen|·) and p(copy|·) are given by softmax(WS · st). The probability of generating v from the vocabulary, p(v|gen, x, a<t), is defined similarly as Eq. (4), except that we use the embedding matrix of GENTOKEN, WG. To model the copy probability, we follow recent advances in modeling copying mechanism in neural networks (Gu et al., 2016; Jia and Liang, 2016; Ling et al., 2016), and use a pointer network (Vinyals et al., 2015) to compute the probability of copying the i-th word from the input by attending to input representations {hi}:\np(wi|copy, x, a<t) = exp(ω(hi, st, ct))∑n\ni′=1 exp(ω(hi′ , st, ct)) ,\nwhere ω(·) is a DNN with a single hidden layer."
    }, {
      "heading" : "4.3 Training and Inference",
      "text" : "Given a dataset of pairs of NL descriptions xi and code snippets ci, we parse ci into its AST yi and decompose yi into a sequence of oracle actions under the grammar model. The model is then optimized by maximizing the log-likelihood of the oracle action sequence. At inference time, we use beam search to approximate the best AST ŷ in Eq. (1). See supplementary materials for the pseudo-code of the inference algorithm."
    }, {
      "heading" : "5 Experimental Evaluation",
      "text" : ""
    }, {
      "heading" : "5.1 Datasets and Metrics",
      "text" : "HEARTHSTONE (HS) dataset (Ling et al., 2016) is a collection of Python classes that implement\ntioning on the hidden states of parent non-terminals, while our parent feeding uses the states of parent actions.\n5We do not show bias terms for all softmax equations.\ncards for the card game HearthStone. Each card comes with a set of fields (e.g., name, cost, and description), which we concatenate to create the input sequence. This dataset is relatively difficult: input descriptions are short, while the target code is in complex class structures, with each AST having 137 nodes on average. DJANGO dataset (Oda et al., 2015) is a collection of lines of code from the Django web framework, each with a manually annotated NL description. Compared with the HS dataset where card implementations are somewhat homogenous, examples in DJANGO are more diverse, spanning a wide variety of real-world use cases like string manipulation, IO operations, and exception handling. IFTTT dataset (Quirk et al., 2015) is a domainspecific benchmark that provides an interesting side comparison. Different from HS and DJANGO which are in a general-purpose PL, programs in IFTTT are written in a domain-specific language used by the IFTTT task automation App. Users of the App write simple instructions (e.g., If Instagram.AnyNewPhotoByYou Then Dropbox.AddFileFromURL) with NL descriptions (e.g., “Autosave your Instagram photos to Dropbox”). Each statement inside the If or Then clause consists of a channel (e.g., Dropbox) and a function (e.g., AddFileFromURL)6. This simple structure results in much more concise ASTs (7 nodes on average). Because all examples are created by ordinary Apps users, the dataset is highly noisy, with input NL very loosely con-\n6Like Beltagy and Quirk (2016), we strip function parameters since they are mostly specific to users.\n6\n501\n502\n503\n504\n505\n506\n507\n508\n509\n510\n511\n512\n513\n514\n515\n516\n517\n518\n519\n520\n521\n522\n523\n524\n525\n526\n527\n528\n529\n530\n531\n532\n533\n534\n535\n536\n537\n538\n539\n540\n541\n542\n543\n544\n545\n546\n547\n548\n549\n564\n565\n566\n567\n568\n569\n570\n571\n572\n573\n574\n575\n576\n577\n578\n579\n580\n581\n582\n583\n584\n585\n586\n587\n588\n589\n590\n591\n592\n593\n594\n595\n596\n597\n598\n599\nnected to target ASTs. The authors thus provide a high-quality filtered test set, where each example is verified by at least three annotators. We use this set for evaluation. Also note IFTTT’s grammar has more productions (Tab. 2), but this does not imply that its grammar is more complex. This is because for HS and DJANGO terminal tokens are generated by GENTOKEN actions, but for IFTTT, all the code is generated directly by APPLYRULE actions. Metrics As is standard in semantic parsing, we measure accuracy, the fraction of correctly generated examples. However, because generating an exact match for complex code structures is nontrivial, we follow Ling et al. (2016), and use tokenlevel BLEU-4 with as a secondary metric, defined as the averaged smoothed BLEU (Lin and Och, 2004) scores over all examples."
    }, {
      "heading" : "5.2 Setup",
      "text" : "Preprocessing All input descriptions are tokenized using NLTK. We perform simple canonicalization for DJANGO, such as replacing quoted strings in the inputs with place holders. See supplementary materials for details. We extract unary closures whose frequency is larger than a threshold k (k = 30 for HS and 50 for DJANGO). Configuration The size of all embeddings is 128, except for node type embeddings, which is 64. The dimensions of RNN states and hidden layers are 256 and 50, respectively. Since our datasets are relatively small for a data-hungry neural model, we impose strong regularization using recurrent dropouts (Gal and Ghahramani, 2016), together with standard dropout layers added to the inputs and outputs of the decoder RNN. We validate the dropout probability from {0, 0.2, 0.3, 0.4}. For decoding, we use a beam size of 15."
    }, {
      "heading" : "5.3 Results",
      "text" : "Evaluation results for Python code generation tasks are listed in Tab. 3. Numbers for our systems are averaged over three runs. We compare primarily with two approaches: (1) Latent Predictor Network (LPN), a state-of-the-art sequenceto-sequence code generation model (Ling et al., 2016), and (2) SEQ2TREE, a neural semantic parsing model (Dong and Lapata, 2016). SEQ2TREE generates trees one node at a time, and the target grammar is not explicitly modeled a priori, but implicitly learned from data. We test both the original SEQ2TREE model released by the authors and our revised one (SEQ2TREE–UNK) that uses unknown word replacement to handle rare\nwords (Luong et al., 2015). For completeness, we also compare with a strong neural machine translation (NMT) system (Neubig, 2015) using a standard encoder-decoder architecture with attention and unknown word replacement, and include numbers from other baselines used in Ling et al. (2016). On the HS dataset, which has relatively large ASTs, we use unary closure for our model and SEQ2TREE, and for DJANGO we do not.\nSystem Comparison As in Tab. 3, our model registers 11.7% and 9.3% absolute improvements over LPN in accuracy on HS and DJANGO. This boost in performance strongly indicates the importance of modeling grammar in code generation. For the baselines, we find LPN outperforms others in most cases. We also note that SEQ2TREE achieves a decent accuracy of 13.6% on HS, which is due to the effect of unknown word replacement, since we only achieved 1.5% without it. A closer comparison with SEQ2TREE is insightful for understanding the advantage of our syntax-driven approach, since both SEQ2TREE and our system output ASTs: (1) SEQ2TREE predicts one node each time step, and requires additional “dummy” nodes to mark the boundary of a subtree. The sheer number of nodes in target ASTs makes the prediction process error-prone. In contrast, the APPLYRULE actions of our grammar model allows for generating multiple nodes at a single time step. Empirically, we found that in HS, SEQ2TREE takes more than 300 time steps on average to generate a target AST, while our model takes only 170 steps. (2) SEQ2TREE does not directly use productions in the grammar, which possibly leads to grammat-\n7\n601\n602\n603\n604\n605\n606\n607\n608\n609\n610\n611\n612\n613\n614\n615\n616\n617\n618\n619\n620\n621\n622\n623\n624\n625\n626\n627\n628\n629\n630\n631\n632\n633\n634\n635\n636\n637\n638\n639\n640\n641\n642\n643\n644\n645\n646\n647\n648\n649\n661\n662\n663\n664\n665\n666\n667\n668\n669\n670\n671\n672\n673\n674\n675\n676\n677\n678\n679\n680\n681\n682\n683\n684\n685\n686\n687\n688\n689\n690\n691\n692\n693\n694\n695\n696\n697\n698\n699\n0 10 20 30 40 50 Reference AST Size (# nodes)\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nP e rf\no rm\na n ce\nBLEU acc\nFigure 3: Performance w.r.t reference AST size on DJANGO\n50 100 150 200 250 Reference AST Size (# nodes)\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nP e rf\no rm\na n ce\nBLEU acc\nFigure 4: Performance w.r.t reference AST size on HS\nically incorrect ASTs and thus empty code outputs. We observe that the ratio of grammatically incorrect ASTs predicted by SEQ2TREE on HS and DJANGO are 21.2% and 10.9%, respectively, while our system guarantees grammaticality. Ablation Study We also ablated our bestperforming models to analyze the contribution of each component. “–frontier embed.” removes the frontier node embedding nft from the decoder RNN inputs (Eq. (3)). This yields worse results on DJANGO while gives slight improvements in accuracy on HS. This is probably because that the grammar of HS has fewer node types, and thus the RNN is able to keep track of nft without depending on its embedding. Next, “–parent feed.” removes the parent feeding mechanism. The accuracy drops significantly on HS, with a marginal deterioration on DJANGO. This result is interesting because it suggests that parent feeding is more important when the ASTs are larger, which will be the case when handling more complicated code generation tasks like HS. Finally, removing the pointer network (“–copy terminals”) in GENTOKEN actions gives poor results, indicating that it is important to directly copy variable names and values from the input.\nThe results with and without unary closure demonstrate that, interestingly, it is effective on HS but not on DJANGO. We conjecture that this is because on HS it significantly reduces the number of actions from 173 to 142 (c.f., Tab. 2), with the number of productions in the grammar remaining unchanged. In contrast, DJANGO has a broader domain, and thus unary closure results in more productions in the grammar (237 for DJANGO vs. 100 for HS), increasing sparsity. Performance by the size of AST We further investigate our model’s performance w.r.t. the size\nof the gold-standard ASTs in Figs. 3 and 4. Not surprisingly, the performance drops when the size of the reference ASTs increases. Additionally, on the HS dataset, the BLEU score still remains at around 50 even when the size of ASTs grows to 200, indicating that our proposed syntax-driven approach is robust for long code segments. Domain Specific Code Generation Although this is not the focus of our work, evaluation on IFTTT brings us closer to a standard semantic parsing setting, which helps to investigate similarities and differences between generation of more complicated general-purpose code and and more limiteddomain simpler code. Tab. 4 shows the results, following the evaluation protocol in (Beltagy and Quirk, 2016) for accuracies at both channel and full parse tree (channel + function) levels. Our full model performs on par with existing neural network-based methods, while outperforming other neural models in full tree accuracy (82.0%). This score is close to the best classical method (LR), which is based on a logistic regression model with rich hand-engineered features (e.g., brown clusters and paraphrase). Also note that the performance between NMT and other neural models is much closer compared with the results in Tab. 3. This suggests that general-purpose code generation is more challenging than the simpler IFTTT setting, and therefore modeling structural information is more helpful. Case Studies Finally, we present output examples in Tab. 5. On HS, we observe that most of the time our model gives correct predictions by filling learned code templates from training data with arguments (e.g., cost) copied from input. However, we do find interesting examples indicating that the model learns to generalize beyond trivial copy-\n8\n701\n702\n703\n704\n705\n706\n707\n708\n709\n710\n711\n712\n713\n714\n715\n716\n717\n718\n719\n720\n721\n722\n723\n724\n725\n726\n727\n728\n729\n730\n731\n732\n733\n734\n735\n736\n737\n738\n739\n740\n741\n742\n743\n744\n745\n746\n747\n748\n749\n750\n751\n752\n753\n754\n755\n756\n757\n758\n759\n760\n761\n762\n763\n764\n765\n766\n767\n768\n769\n770\n771\n772\n773\n774\n775\n776\n777\n778\n779\n780\n781\n782\n783\n784\n785\n786\n787\n788\n789\n790\n791\n792\n793\n794\n795\n796\n797\n798\n799\ninput <name> Brawl </name> <cost> 5 </cost> <desc> Destroy all minions except one (chosen randomly) </desc> <rarity> Epic </rarity> ... pred. class Brawl(SpellCard): def init (self): super(). init (’Brawl’, 5, CHARACTER CLASS.\nWARRIOR, CARD RARITY.EPIC) def use(self, player, game): super().use(player, game) targets = copy.copy(game.other player.minions) targets.extend(player.minions) for minion in targets: minion.die(self) A\nref. minions = copy.copy(player.minions) minions.extend(game.other player.minions) if len(minions) > 1: survivor = game.random choice(minions) for minion in minions: if minion is not survivor: minion.die(self) B\ninput join app config.path and string ’locale’ into a file path, substitute it for localedir. pred. localedir = os.path.join( app config.path, ’locale’) 3\ninput self.plural is an lambda function with an argument n, which returns result of boolean expression n not equal to integer 1 pred. self.plural = lambda n: len(n) 7 ref. self.plural = lambda n: int(n!=1)\nTable 5: Predicted examples from HS (1st) and DJANGO. Copied contents (copy probability > 0.9) are highlighted.\ning. For instance, the first example is one that our model predicted wrong — it generated code block A instead of the gold B (it also missed a function definition not shown here). However, we find that the block A actually conveys part of the input intent by destroying all, not some, of the minions. Since we are unable to find code block A in the training data, it is clear that the model has learned to generalize to some extent from multiple training card examples with similar semantics or structure.\nThe next two examples are from DJANGO. The first one shows that the model learns the usage of common API calls (e.g., os.path.join), and how to populate the arguments by copying from inputs. The second example illustrates the difficulty of generating code with complex nested structures like lambda functions, a scenario worth further investigation in future studies. More examples are attached in supplementary materials."
    }, {
      "heading" : "6 Related Work",
      "text" : "Code Generation and Analysis Most existing works on code generation focus on generating code for domain specific languages (DSLs) (Kushman and Barzilay, 2013; Raza et al., 2015; Manshadi et al., 2013), with neural network-based approaches recently explored (Parisotto et al., 2016; Balog et al., 2016). For general-purpose code gen-\neration, besides the general framework of Ling et al. (2016), existing methods often use language and task-specific rules and strategies (Lei et al., 2013; Raghothaman et al., 2016). A similar line is to use NL queries for code retrieval (Wei et al., 2015; Allamanis et al., 2015). The reverse task of generating NL summaries from source code has also been explored (Oda et al., 2015; Iyer et al., 2016). Finally, there are probabilistic models of source code (Maddison and Tarlow, 2014; Nguyen et al., 2013). The most relevant work is Allamanis et al. (2015), which uses a factorized model to measure semantic relatedness between NL and ASTs for code retrieval, while our model tackles the more challenging generation task. Semantic Parsing Our work is related to the general topic of semantic parsing, where the target logical forms can be viewed as DSLs. The parsing process is often guided by grammatical formalisms like combinatory categorical grammars (Kwiatkowski et al., 2013; Artzi et al., 2015), dependency-based syntax (Liang et al., 2011; Pasupat and Liang, 2015) or task-specific formalisms (Clarke et al., 2010; Yih et al., 2015; Krishnamurthy et al., 2016; Misra et al., 2015; Mei et al., 2016). Recently, there are efforts in designing neural network-based semantic parsers (Misra and Artzi, 2016; Dong and Lapata, 2016; Neelakantan et al., 2016). Several approaches have be proposed to utilize grammar knowledge in a neural parser, such as augmenting the training data by generating examples guided by the grammar (Kociský et al., 2016; Jia and Liang, 2016). Liang et al. (2016) used a neural decoder which constrains the space of next valid tokens in the query language for question answering. Finally, the structured prediction approach proposed by Xiao et al. (2016) is closely related to our model in using the underlying grammar as prior knowledge to constrain the generation process of derivation trees, while our method is based on a unified grammar model which jointly captures production rule application and terminal symbol generation, and scales to general purpose code generation tasks."
    }, {
      "heading" : "7 Conclusion",
      "text" : "This paper proposes a syntax-driven neural code generation approach that generates an abstract syntax tree by sequentially applying actions from a grammar model. Experiments on both code generation and semantic parsing tasks demonstrate the effectiveness of our proposed approach.\n9\n801\n802\n803\n804\n805\n806\n807\n808\n809\n810\n811\n812\n813\n814\n815\n816\n817\n818\n819\n820\n821\n822\n823\n824\n825\n826\n827\n828\n829\n830\n831\n832\n833\n834\n835\n836\n837\n838\n839\n840\n841\n842\n843\n844\n845\n846\n847\n848\n849\n850\n851\n852\n853\n854\n855\n856\n857\n858\n859\n860\n861\n862\n863\n864\n865\n866\n867\n868\n869\n870\n871\n872\n873\n874\n875\n876\n877\n878\n879\n880\n881\n882\n883\n884\n885\n886\n887\n888\n889\n890\n891\n892\n893\n894\n895\n896\n897\n898\n899"
    } ],
    "references" : [ {
      "title" : "Bimodal modelling of source code and natural language",
      "author" : [ "Miltiadis Allamanis", "Daniel Tarlow", "Andrew D. Gordon", "Yi Wei." ],
      "venue" : "Proceedings of ICML. volume 37, pages 2123–2132.",
      "citeRegEx" : "Allamanis et al\\.,? 2015",
      "shortCiteRegEx" : "Allamanis et al\\.",
      "year" : 2015
    }, {
      "title" : "Tree-structured decoding with doubly recurrent neural networks",
      "author" : [ "David Alvarez-Melis", "Tommi S. Jaakkola." ],
      "venue" : "Proceedings of ICLR.",
      "citeRegEx" : "Alvarez.Melis and Jaakkola.,? 2017",
      "shortCiteRegEx" : "Alvarez.Melis and Jaakkola.",
      "year" : 2017
    }, {
      "title" : "Broad-coverage CCG semantic parsing with AMR",
      "author" : [ "Yoav Artzi", "Kenton Lee", "Luke Zettlemoyer." ],
      "venue" : "Proceedings of EMNLP. pages 1699–1710.",
      "citeRegEx" : "Artzi et al\\.,? 2015",
      "shortCiteRegEx" : "Artzi et al\\.",
      "year" : 2015
    }, {
      "title" : "Weakly supervised learning of semantic parsers for mapping instructions to actions",
      "author" : [ "Yoav Artzi", "Luke Zettlemoyer." ],
      "venue" : "Transaction of ACL 1(1):49–",
      "citeRegEx" : "Artzi and Zettlemoyer.,? 2013",
      "shortCiteRegEx" : "Artzi and Zettlemoyer.",
      "year" : 2013
    }, {
      "title" : "Neural machine translation by jointly learning to align and translate",
      "author" : [ "Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio." ],
      "venue" : "CoRR abs/1409.0473.",
      "citeRegEx" : "Bahdanau et al\\.,? 2014",
      "shortCiteRegEx" : "Bahdanau et al\\.",
      "year" : 2014
    }, {
      "title" : "Deepcoder: Learning to write programs",
      "author" : [ "Matej Balog", "Alexander L. Gaunt", "Marc Brockschmidt", "Sebastian Nowozin", "Daniel Tarlow." ],
      "venue" : "CoRR abs/1611.01989.",
      "citeRegEx" : "Balog et al\\.,? 2016",
      "shortCiteRegEx" : "Balog et al\\.",
      "year" : 2016
    }, {
      "title" : "A 15 year perspective on automatic programming",
      "author" : [ "Robert Balzer." ],
      "venue" : "IEEE Trans. Software Eng. 11(11):1257–1268.",
      "citeRegEx" : "Balzer.,? 1985",
      "shortCiteRegEx" : "Balzer.",
      "year" : 1985
    }, {
      "title" : "Abstract meaning representation for sembanking",
      "author" : [ "Laura Banarescu", "Claire Bonial", "Shu Cai", "Madalina Georgescu", "Kira Griffitt", "Ulf Hermjakob", "Kevin Knight", "Philipp Koehn", "Martha Palmer", "Nathan Schneider." ],
      "venue" : "Proceedings of the 7th Linguis-",
      "citeRegEx" : "Banarescu et al\\.,? 2013",
      "shortCiteRegEx" : "Banarescu et al\\.",
      "year" : 2013
    }, {
      "title" : "Improved semantic parsers for if-then statements",
      "author" : [ "I. Beltagy", "Chris Quirk." ],
      "venue" : "Proceedings of ACL.",
      "citeRegEx" : "Beltagy and Quirk.,? 2016",
      "shortCiteRegEx" : "Beltagy and Quirk.",
      "year" : 2016
    }, {
      "title" : "Semantic parsing on freebase from question-answer pairs",
      "author" : [ "Jonathan Berant", "Andrew Chou", "Roy Frostig", "Percy Liang." ],
      "venue" : "Proceedings of EMNLP. pages 1533–1544.",
      "citeRegEx" : "Berant et al\\.,? 2013",
      "shortCiteRegEx" : "Berant et al\\.",
      "year" : 2013
    }, {
      "title" : "Example-centric programming: integrating web search into the development environment",
      "author" : [ "Joel Brandt", "Mira Dontcheva", "Marcos Weskamp", "Scott R. Klemmer." ],
      "venue" : "Proceedings of CHI. pages 513– 522.",
      "citeRegEx" : "Brandt et al\\.,? 2010",
      "shortCiteRegEx" : "Brandt et al\\.",
      "year" : 2010
    }, {
      "title" : "Two studies of opportunistic programming: interleaving web foraging, learning, and writing code",
      "author" : [ "Joel Brandt", "Philip J. Guo", "Joel Lewenstein", "Mira Dontcheva", "Scott R. Klemmer." ],
      "venue" : "Proceedings of CHI. pages 1589–1598.",
      "citeRegEx" : "Brandt et al\\.,? 2009",
      "shortCiteRegEx" : "Brandt et al\\.",
      "year" : 2009
    }, {
      "title" : "Widecoverage efficient statistical parsing with CCG and log-linear models",
      "author" : [ "Stephen Clark", "James R. Curran." ],
      "venue" : "Computational Linguistics 33(4):493–552.",
      "citeRegEx" : "Clark and Curran.,? 2007",
      "shortCiteRegEx" : "Clark and Curran.",
      "year" : 2007
    }, {
      "title" : "Driving semantic parsing from the world’s response",
      "author" : [ "James Clarke", "Dan Goldwasser", "Ming-Wei Chang", "Dan Roth." ],
      "venue" : "Proceedings of CoNLL. pages 18–27.",
      "citeRegEx" : "Clarke et al\\.,? 2010",
      "shortCiteRegEx" : "Clarke et al\\.",
      "year" : 2010
    }, {
      "title" : "Language to logical form with neural attention",
      "author" : [ "Li Dong", "Mirella Lapata." ],
      "venue" : "Proceedings of ACL.",
      "citeRegEx" : "Dong and Lapata.,? 2016",
      "shortCiteRegEx" : "Dong and Lapata.",
      "year" : 2016
    }, {
      "title" : "A theoretically grounded application of dropout in recurrent neural networks",
      "author" : [ "Yarin Gal", "Zoubin Ghahramani." ],
      "venue" : "Proceedings of NIPS. pages 1019–1027.",
      "citeRegEx" : "Gal and Ghahramani.,? 2016",
      "shortCiteRegEx" : "Gal and Ghahramani.",
      "year" : 2016
    }, {
      "title" : "Incorporating copying mechanism in sequence-to-sequence learning",
      "author" : [ "Jiatao Gu", "Zhengdong Lu", "Hang Li", "Victor O.K. Li." ],
      "venue" : "Proceedings of ACL.",
      "citeRegEx" : "Gu et al\\.,? 2016",
      "shortCiteRegEx" : "Gu et al\\.",
      "year" : 2016
    }, {
      "title" : "Interactive synthesis using free-form queries",
      "author" : [ "Tihomir Gvero", "Viktor Kuncak." ],
      "venue" : "Proceedings of ICSE. pages 689–692.",
      "citeRegEx" : "Gvero and Kuncak.,? 2015",
      "shortCiteRegEx" : "Gvero and Kuncak.",
      "year" : 2015
    }, {
      "title" : "Long short-term memory",
      "author" : [ "Sepp Hochreiter", "Jürgen Schmidhuber." ],
      "venue" : "Neural Computation 9(8):1735–1780.",
      "citeRegEx" : "Hochreiter and Schmidhuber.,? 1997",
      "shortCiteRegEx" : "Hochreiter and Schmidhuber.",
      "year" : 1997
    }, {
      "title" : "Summarizing source code using a neural attention model",
      "author" : [ "Srinivasan Iyer", "Ioannis Konstas", "Alvin Cheung", "Luke Zettlemoyer." ],
      "venue" : "Proceedings of ACL.",
      "citeRegEx" : "Iyer et al\\.,? 2016",
      "shortCiteRegEx" : "Iyer et al\\.",
      "year" : 2016
    }, {
      "title" : "Data recombination for neural semantic parsing",
      "author" : [ "Robin Jia", "Percy Liang." ],
      "venue" : "Proceedings of ACL.",
      "citeRegEx" : "Jia and Liang.,? 2016",
      "shortCiteRegEx" : "Jia and Liang.",
      "year" : 2016
    }, {
      "title" : "Semantic parsing with semi-supervised sequential autoencoders",
      "author" : [ "Tomás Kociský", "Gábor Melis", "Edward Grefenstette", "Chris Dyer", "Wang Ling", "Phil Blunsom", "Karl Moritz Hermann." ],
      "venue" : "Proceedings of EMNLP. pages 1078–1087.",
      "citeRegEx" : "Kociský et al\\.,? 2016",
      "shortCiteRegEx" : "Kociský et al\\.",
      "year" : 2016
    }, {
      "title" : "Semantic parsing to probabilistic programs for situated question answering",
      "author" : [ "Jayant Krishnamurthy", "Oyvind Tafjord", "Aniruddha Kembhavi." ],
      "venue" : "Proceedings of EMNLP. pages 160–170.",
      "citeRegEx" : "Krishnamurthy et al\\.,? 2016",
      "shortCiteRegEx" : "Krishnamurthy et al\\.",
      "year" : 2016
    }, {
      "title" : "Using semantic unification to generate regular expressions from natural language",
      "author" : [ "Nate Kushman", "Regina Barzilay." ],
      "venue" : "Proceedings of NAACL. pages 826–836.",
      "citeRegEx" : "Kushman and Barzilay.,? 2013",
      "shortCiteRegEx" : "Kushman and Barzilay.",
      "year" : 2013
    }, {
      "title" : "Scaling semantic parsers with on-the-fly ontology matching",
      "author" : [ "Tom Kwiatkowski", "Eunsol Choi", "Yoav Artzi", "Luke S. Zettlemoyer." ],
      "venue" : "Proceedings of the EMNLP. pages 1545–1556.",
      "citeRegEx" : "Kwiatkowski et al\\.,? 2013",
      "shortCiteRegEx" : "Kwiatkowski et al\\.",
      "year" : 2013
    }, {
      "title" : "From natural language specifications to program input parsers",
      "author" : [ "Tao Lei", "Fan Long", "Regina Barzilay", "Martin C. Rinard." ],
      "venue" : "Proceedings of ACL. pages 1294–1303.",
      "citeRegEx" : "Lei et al\\.,? 2013",
      "shortCiteRegEx" : "Lei et al\\.",
      "year" : 2013
    }, {
      "title" : "Neural symbolic machines: Learning semantic parsers on freebase with weak supervision",
      "author" : [ "Chen Liang", "Jonathan Berant", "Quoc Le", "Kenneth D. Forbus", "Ni Lao." ],
      "venue" : "CoRR abs/1611.00020.",
      "citeRegEx" : "Liang et al\\.,? 2016",
      "shortCiteRegEx" : "Liang et al\\.",
      "year" : 2016
    }, {
      "title" : "Learning dependency-based compositional semantics",
      "author" : [ "Percy Liang", "Michael I. Jordan", "Dan Klein." ],
      "venue" : "Proceedings of ACL. pages 590–599.",
      "citeRegEx" : "Liang et al\\.,? 2011",
      "shortCiteRegEx" : "Liang et al\\.",
      "year" : 2011
    }, {
      "title" : "Orange: a method for evaluating automatic evaluation metrics for machine translation",
      "author" : [ "Chin-Yew Lin", "Franz Josef Och." ],
      "venue" : "Proceedings of Coling 2004. pages 501–507.",
      "citeRegEx" : "Lin and Och.,? 2004",
      "shortCiteRegEx" : "Lin and Och.",
      "year" : 2004
    }, {
      "title" : "Latent predictor networks for code generation",
      "author" : [ "Wang Ling", "Phil Blunsom", "Edward Grefenstette", "Karl Moritz Hermann", "Tomás Kociský", "Fumin Wang", "Andrew Senior." ],
      "venue" : "Proceedings of ACL.",
      "citeRegEx" : "Ling et al\\.,? 2016",
      "shortCiteRegEx" : "Ling et al\\.",
      "year" : 2016
    }, {
      "title" : "Keyword programming in java",
      "author" : [ "Greg Little", "Robert C. Miller." ],
      "venue" : "Autom. Softw. Eng. 16(1):37–71.",
      "citeRegEx" : "Little and Miller.,? 2009",
      "shortCiteRegEx" : "Little and Miller.",
      "year" : 2009
    }, {
      "title" : "Addressing the rare word problem in neural machine translation",
      "author" : [ "Thang Luong", "Ilya Sutskever", "Quoc V. Le", "Oriol Vinyals", "Wojciech Zaremba." ],
      "venue" : "Proceedings of ACL. pages 11–19.",
      "citeRegEx" : "Luong et al\\.,? 2015",
      "shortCiteRegEx" : "Luong et al\\.",
      "year" : 2015
    }, {
      "title" : "Structured generative models of natural source code",
      "author" : [ "Chris J. Maddison", "Daniel Tarlow." ],
      "venue" : "Proceedings of ICML. volume 32, pages 649–657.",
      "citeRegEx" : "Maddison and Tarlow.,? 2014",
      "shortCiteRegEx" : "Maddison and Tarlow.",
      "year" : 2014
    }, {
      "title" : "Integrating programming by example and natural language programming",
      "author" : [ "Mehdi Hafezi Manshadi", "Daniel Gildea", "James F. Allen." ],
      "venue" : "Proceedings of AAAI.",
      "citeRegEx" : "Manshadi et al\\.,? 2013",
      "shortCiteRegEx" : "Manshadi et al\\.",
      "year" : 2013
    }, {
      "title" : "Listen, attend, and walk: Neural mapping of navigational instructions to action sequences",
      "author" : [ "Hongyuan Mei", "Mohit Bansal", "Matthew R. Walter." ],
      "venue" : "Proceedings of AAAI. pages 2772–2778.",
      "citeRegEx" : "Mei et al\\.,? 2016",
      "shortCiteRegEx" : "Mei et al\\.",
      "year" : 2016
    }, {
      "title" : "Neural shiftreduce CCG semantic parsing",
      "author" : [ "Dipendra K. Misra", "Yoav Artzi." ],
      "venue" : "Proceedings of EMNLP.",
      "citeRegEx" : "Misra and Artzi.,? 2016",
      "shortCiteRegEx" : "Misra and Artzi.",
      "year" : 2016
    }, {
      "title" : "Environment-driven lexicon induction for high-level instructions",
      "author" : [ "Dipendra Kumar Misra", "Kejia Tao", "Percy Liang", "Ashutosh Saxena." ],
      "venue" : "Proceedings of ACL. pages 992–1002.",
      "citeRegEx" : "Misra et al\\.,? 2015",
      "shortCiteRegEx" : "Misra et al\\.",
      "year" : 2015
    }, {
      "title" : "Neural programmer: Inducing latent programs with gradient descent",
      "author" : [ "Arvind Neelakantan", "Quoc V. Le", "Ilya Sutskever." ],
      "venue" : "Proceedings of ICLR.",
      "citeRegEx" : "Neelakantan et al\\.,? 2016",
      "shortCiteRegEx" : "Neelakantan et al\\.",
      "year" : 2016
    }, {
      "title" : "lamtram: A toolkit for language and translation modeling using neural networks",
      "author" : [ "Graham Neubig." ],
      "venue" : "http://www.github.com/neubig/lamtram.",
      "citeRegEx" : "Neubig.,? 2015",
      "shortCiteRegEx" : "Neubig.",
      "year" : 2015
    }, {
      "title" : "A statistical semantic language model for source code",
      "author" : [ "Tung Thanh Nguyen", "Anh Tuan Nguyen", "Hoan Anh Nguyen", "Tien N. Nguyen." ],
      "venue" : "Proceedings of ACM SIGSOFT . pages 532–542.",
      "citeRegEx" : "Nguyen et al\\.,? 2013",
      "shortCiteRegEx" : "Nguyen et al\\.",
      "year" : 2013
    }, {
      "title" : "Learning to generate pseudo-code from source code using statistical machine translation (T)",
      "author" : [ "Yusuke Oda", "Hiroyuki Fudaba", "Graham Neubig", "Hideaki Hata", "Sakriani Sakti", "Tomoki Toda", "Satoshi Nakamura." ],
      "venue" : "Proceedings of ASE. pages",
      "citeRegEx" : "Oda et al\\.,? 2015",
      "shortCiteRegEx" : "Oda et al\\.",
      "year" : 2015
    }, {
      "title" : "Neuro-symbolic program synthesis",
      "author" : [ "Emilio Parisotto", "Abdel-rahman Mohamed", "Rishabh Singh", "Lihong Li", "Dengyong Zhou", "Pushmeet Kohli." ],
      "venue" : "CoRR abs/1611.01855.",
      "citeRegEx" : "Parisotto et al\\.,? 2016",
      "shortCiteRegEx" : "Parisotto et al\\.",
      "year" : 2016
    }, {
      "title" : "Compositional semantic parsing on semi-structured tables",
      "author" : [ "Panupong Pasupat", "Percy Liang." ],
      "venue" : "Proceedings of ACL. pages 1470–1480.",
      "citeRegEx" : "Pasupat and Liang.,? 2015",
      "shortCiteRegEx" : "Pasupat and Liang.",
      "year" : 2015
    }, {
      "title" : "Python abstract grammar",
      "author" : [ "Python Software Foundation." ],
      "venue" : "https://docs.python.org/2/library/ast.html.",
      "citeRegEx" : "Foundation.,? 2016",
      "shortCiteRegEx" : "Foundation.",
      "year" : 2016
    }, {
      "title" : "Language to code: Learning semantic parsers for if-this-then-that recipes",
      "author" : [ "Chris Quirk", "Raymond J. Mooney", "Michel Galley." ],
      "venue" : "Proceedings of ACL. pages 878–888.",
      "citeRegEx" : "Quirk et al\\.,? 2015",
      "shortCiteRegEx" : "Quirk et al\\.",
      "year" : 2015
    }, {
      "title" : "SWIM: synthesizing what i mean: code search and idiomatic snippet synthesis",
      "author" : [ "Mukund Raghothaman", "Yi Wei", "Youssef Hamadi." ],
      "venue" : "Proceedings of ICSE. pages 357–367.",
      "citeRegEx" : "Raghothaman et al\\.,? 2016",
      "shortCiteRegEx" : "Raghothaman et al\\.",
      "year" : 2016
    }, {
      "title" : "Compositional program synthesis from natural language and examples",
      "author" : [ "Mohammad Raza", "Sumit Gulwani", "Natasa MilicFrayling." ],
      "venue" : "Proceedings of IJCAI. pages 792–800.",
      "citeRegEx" : "Raza et al\\.,? 2015",
      "shortCiteRegEx" : "Raza et al\\.",
      "year" : 2015
    }, {
      "title" : "Using multiple clause constructors in inductive logic programming for semantic parsing",
      "author" : [ "Lappoon R. Tang", "Raymond J. Mooney." ],
      "venue" : "Proceedings of ECML. pages 466–477.",
      "citeRegEx" : "Tang and Mooney.,? 2001",
      "shortCiteRegEx" : "Tang and Mooney.",
      "year" : 2001
    }, {
      "title" : "Pointer networks",
      "author" : [ "Oriol Vinyals", "Meire Fortunato", "Navdeep Jaitly." ],
      "venue" : "Proceedings of NIPS. pages 2692–2700.",
      "citeRegEx" : "Vinyals et al\\.,? 2015",
      "shortCiteRegEx" : "Vinyals et al\\.",
      "year" : 2015
    }, {
      "title" : "Building bing developer assistant",
      "author" : [ "Yi Wei", "Nirupama Chandrasekaran", "Sumit Gulwani", "Youssef Hamadi." ],
      "venue" : "Technical report. https://www.microsoft.com/enus/research/publication/building-bing-developer-",
      "citeRegEx" : "Wei et al\\.,? 2015",
      "shortCiteRegEx" : "Wei et al\\.",
      "year" : 2015
    }, {
      "title" : "Sequence-based structured prediction for semantic parsing",
      "author" : [ "Chunyang Xiao", "Marc Dymetman", "Claire Gardent." ],
      "venue" : "Proceedings of ACL.",
      "citeRegEx" : "Xiao et al\\.,? 2016",
      "shortCiteRegEx" : "Xiao et al\\.",
      "year" : 2016
    }, {
      "title" : "Semantic parsing via staged query graph generation: Question answering with knowledge base",
      "author" : [ "Wen-tau Yih", "Ming-Wei Chang", "Xiaodong He", "Jianfeng Gao." ],
      "venue" : "Proceedings of ACL. pages 1321–1331.",
      "citeRegEx" : "Yih et al\\.,? 2015",
      "shortCiteRegEx" : "Yih et al\\.",
      "year" : 2015
    }, {
      "title" : "Learning to map sentences to logical form structured classification with probabilistic categorial grammars",
      "author" : [ "Luke Zettlemoyer", "Michael Collins." ],
      "venue" : "Proceedings of UAI. pages 658–666.",
      "citeRegEx" : "Zettlemoyer and Collins.,? 2005",
      "shortCiteRegEx" : "Zettlemoyer and Collins.",
      "year" : 2005
    } ],
    "referenceMentions" : [ {
      "referenceID" : 6,
      "context" : "However, this is time-consuming, and thus the software engineering literature is ripe with methods to directly generate code from NL descriptions, mostly with hand-engineered methods highly tailored to specific programming languages (Balzer, 1985; Little and Miller, 2009; Gvero and Kuncak, 2015).",
      "startOffset" : 233,
      "endOffset" : 296
    }, {
      "referenceID" : 30,
      "context" : "However, this is time-consuming, and thus the software engineering literature is ripe with methods to directly generate code from NL descriptions, mostly with hand-engineered methods highly tailored to specific programming languages (Balzer, 1985; Little and Miller, 2009; Gvero and Kuncak, 2015).",
      "startOffset" : 233,
      "endOffset" : 296
    }, {
      "referenceID" : 17,
      "context" : "However, this is time-consuming, and thus the software engineering literature is ripe with methods to directly generate code from NL descriptions, mostly with hand-engineered methods highly tailored to specific programming languages (Balzer, 1985; Little and Miller, 2009; Gvero and Kuncak, 2015).",
      "startOffset" : 233,
      "endOffset" : 296
    }, {
      "referenceID" : 12,
      "context" : "These logical forms can be general-purpose meaning representations (Clark and Curran, 2007; Banarescu et al., 2013), formalisms for querying knowledge bases (Tang and Mooney, 2001; Zettlemoyer and Collins, 2005; Berant et al.",
      "startOffset" : 67,
      "endOffset" : 115
    }, {
      "referenceID" : 7,
      "context" : "These logical forms can be general-purpose meaning representations (Clark and Curran, 2007; Banarescu et al., 2013), formalisms for querying knowledge bases (Tang and Mooney, 2001; Zettlemoyer and Collins, 2005; Berant et al.",
      "startOffset" : 67,
      "endOffset" : 115
    }, {
      "referenceID" : 47,
      "context" : ", 2013), formalisms for querying knowledge bases (Tang and Mooney, 2001; Zettlemoyer and Collins, 2005; Berant et al., 2013) and instructions for robots or personal assistants (Artzi and Zettlemoyer, 2013; Quirk et al.",
      "startOffset" : 49,
      "endOffset" : 124
    }, {
      "referenceID" : 52,
      "context" : ", 2013), formalisms for querying knowledge bases (Tang and Mooney, 2001; Zettlemoyer and Collins, 2005; Berant et al., 2013) and instructions for robots or personal assistants (Artzi and Zettlemoyer, 2013; Quirk et al.",
      "startOffset" : 49,
      "endOffset" : 124
    }, {
      "referenceID" : 9,
      "context" : ", 2013), formalisms for querying knowledge bases (Tang and Mooney, 2001; Zettlemoyer and Collins, 2005; Berant et al., 2013) and instructions for robots or personal assistants (Artzi and Zettlemoyer, 2013; Quirk et al.",
      "startOffset" : 49,
      "endOffset" : 124
    }, {
      "referenceID" : 3,
      "context" : ", 2013) and instructions for robots or personal assistants (Artzi and Zettlemoyer, 2013; Quirk et al., 2015), among others.",
      "startOffset" : 59,
      "endOffset" : 108
    }, {
      "referenceID" : 44,
      "context" : ", 2013) and instructions for robots or personal assistants (Artzi and Zettlemoyer, 2013; Quirk et al., 2015), among others.",
      "startOffset" : 59,
      "endOffset" : 108
    }, {
      "referenceID" : 3,
      "context" : ", 2013) and instructions for robots or personal assistants (Artzi and Zettlemoyer, 2013; Quirk et al., 2015), among others. While these methods have the advantage of being learnable from data, compared to the programming languages (PLs) in use by programmers, the domainspecific languages targeted by these works have a schema and syntax that is relatively simple. Recently, Ling et al. (2016) have proposed a data-driven code generation method for high-level, general-purpose PLs like Python and Java.",
      "startOffset" : 60,
      "endOffset" : 394
    }, {
      "referenceID" : 29,
      "context" : "3% absolute improvements in accuracy against the state-of-the-art system (Ling et al., 2016).",
      "startOffset" : 73,
      "endOffset" : 92
    }, {
      "referenceID" : 49,
      "context" : "Xiao et al. (2016) have noted that this imposition of structure on neural models is useful for semantic parsing, and we expect this to be even more important for general-purpose PLs where the syntax trees are larger and more complex.",
      "startOffset" : 0,
      "endOffset" : 19
    }, {
      "referenceID" : 18,
      "context" : "1 Encoder For an NL description x consisting of n words {wi}i=1, the encoder computes a context sensitive embedding hi for each wi using a bidirectional Long Short-Term Memory (LSTM) network (Hochreiter and Schmidhuber, 1997), similar to the setting in (Bahdanau et al.",
      "startOffset" : 191,
      "endOffset" : 225
    }, {
      "referenceID" : 4,
      "context" : "1 Encoder For an NL description x consisting of n words {wi}i=1, the encoder computes a context sensitive embedding hi for each wi using a bidirectional Long Short-Term Memory (LSTM) network (Hochreiter and Schmidhuber, 1997), similar to the setting in (Bahdanau et al., 2014).",
      "startOffset" : 253,
      "endOffset" : 276
    }, {
      "referenceID" : 4,
      "context" : "We follow Bahdanau et al. (2014) and use a Deep Neural Network (DNN) with a single hidden layer to compute attention weights.",
      "startOffset" : 10,
      "endOffset" : 33
    }, {
      "referenceID" : 4,
      "context" : "We follow Bahdanau et al. (2014) and use a Deep Neural Network (DNN) with a single hidden layer to compute attention weights. Parent Feeding pt Our decoder RNN uses additional neural connections to directly pass information from parent actions. For instance, when computing s9, the information from its parent action step t4 will be used. Formally, we define the parent action step pt as the time step at which the frontier node nft is generated. As an example, for t9, its parent action step p9 is t4, since nf9 is the node ?, which is generated at t4 by the APPLYRULE[Call7→. . .] action. We model parent information pt from two sources: (1) the hidden state of parent action spt , and (2) the embedding of parent action apt . pt is the concatenation. The parent feeding schema enables the model to utilize the information of parent code segments to make more confident predictions. Similar approaches of injecting parent information were also explored in the SEQ2TREE model in Dong and Lapata (2016)4.",
      "startOffset" : 10,
      "endOffset" : 1003
    }, {
      "referenceID" : 16,
      "context" : "To model the copy probability, we follow recent advances in modeling copying mechanism in neural networks (Gu et al., 2016; Jia and Liang, 2016; Ling et al., 2016), and use a pointer network (Vinyals et al.",
      "startOffset" : 106,
      "endOffset" : 163
    }, {
      "referenceID" : 20,
      "context" : "To model the copy probability, we follow recent advances in modeling copying mechanism in neural networks (Gu et al., 2016; Jia and Liang, 2016; Ling et al., 2016), and use a pointer network (Vinyals et al.",
      "startOffset" : 106,
      "endOffset" : 163
    }, {
      "referenceID" : 29,
      "context" : "To model the copy probability, we follow recent advances in modeling copying mechanism in neural networks (Gu et al., 2016; Jia and Liang, 2016; Ling et al., 2016), and use a pointer network (Vinyals et al.",
      "startOffset" : 106,
      "endOffset" : 163
    }, {
      "referenceID" : 48,
      "context" : ", 2016), and use a pointer network (Vinyals et al., 2015) to compute the probability of copying the i-th word from the input by attending to input representations {hi}: p(wi|copy, x, a<t) = exp(ω(hi, st, ct)) ∑n i′=1 exp(ω(hi′ , st, ct)) ,",
      "startOffset" : 35,
      "endOffset" : 57
    }, {
      "referenceID" : 29,
      "context" : "1 Datasets and Metrics HEARTHSTONE (HS) dataset (Ling et al., 2016) is a collection of Python classes that implement",
      "startOffset" : 48,
      "endOffset" : 67
    }, {
      "referenceID" : 40,
      "context" : "DJANGO dataset (Oda et al., 2015) is a collection of lines of code from the Django web framework, each with a manually annotated NL description.",
      "startOffset" : 15,
      "endOffset" : 33
    }, {
      "referenceID" : 44,
      "context" : "IFTTT dataset (Quirk et al., 2015) is a domainspecific benchmark that provides an interesting side comparison.",
      "startOffset" : 14,
      "endOffset" : 34
    }, {
      "referenceID" : 8,
      "context" : "Like Beltagy and Quirk (2016), we strip function parameters since they are mostly specific to users.",
      "startOffset" : 5,
      "endOffset" : 30
    }, {
      "referenceID" : 28,
      "context" : "(2016), and use tokenlevel BLEU-4 with as a secondary metric, defined as the averaged smoothed BLEU (Lin and Och, 2004) scores over all examples.",
      "startOffset" : 100,
      "endOffset" : 119
    }, {
      "referenceID" : 15,
      "context" : "Since our datasets are relatively small for a data-hungry neural model, we impose strong regularization using recurrent dropouts (Gal and Ghahramani, 2016), together with standard dropout layers added to the inputs and outputs of the decoder RNN.",
      "startOffset" : 129,
      "endOffset" : 155
    }, {
      "referenceID" : 29,
      "context" : "We compare primarily with two approaches: (1) Latent Predictor Network (LPN), a state-of-the-art sequenceto-sequence code generation model (Ling et al., 2016), and (2) SEQ2TREE, a neural semantic parsing model (Dong and Lapata, 2016).",
      "startOffset" : 139,
      "endOffset" : 158
    }, {
      "referenceID" : 14,
      "context" : ", 2016), and (2) SEQ2TREE, a neural semantic parsing model (Dong and Lapata, 2016).",
      "startOffset" : 59,
      "endOffset" : 82
    }, {
      "referenceID" : 26,
      "context" : "However, because generating an exact match for complex code structures is nontrivial, we follow Ling et al. (2016), and use tokenlevel BLEU-4 with as a secondary metric, defined as the averaged smoothed BLEU (Lin and Och, 2004) scores over all examples.",
      "startOffset" : 96,
      "endOffset" : 115
    }, {
      "referenceID" : 29,
      "context" : "†Results previously reported in Ling et al. (2016).",
      "startOffset" : 32,
      "endOffset" : 51
    }, {
      "referenceID" : 31,
      "context" : "words (Luong et al., 2015).",
      "startOffset" : 6,
      "endOffset" : 26
    }, {
      "referenceID" : 38,
      "context" : "For completeness, we also compare with a strong neural machine translation (NMT) system (Neubig, 2015) using a standard encoder-decoder architecture with attention and unknown word replacement, and include numbers from other baselines used in Ling et al.",
      "startOffset" : 88,
      "endOffset" : 102
    }, {
      "referenceID" : 29,
      "context" : "For completeness, we also compare with a strong neural machine translation (NMT) system (Neubig, 2015) using a standard encoder-decoder architecture with attention and unknown word replacement, and include numbers from other baselines used in Ling et al. (2016). On the HS dataset, which has relatively large ASTs, we use unary closure for our model and SEQ2TREE, and for DJANGO we do not.",
      "startOffset" : 243,
      "endOffset" : 262
    }, {
      "referenceID" : 44,
      "context" : "the size CHANNEL FULL TREE Classical Methods posclass (Quirk et al., 2015) 81.",
      "startOffset" : 54,
      "endOffset" : 74
    }, {
      "referenceID" : 8,
      "context" : "0 LR (Beltagy and Quirk, 2016) 88.",
      "startOffset" : 5,
      "endOffset" : 30
    }, {
      "referenceID" : 8,
      "context" : "7 NN (Beltagy and Quirk, 2016) 88.",
      "startOffset" : 5,
      "endOffset" : 30
    }, {
      "referenceID" : 14,
      "context" : "3 SEQ2TREE (Dong and Lapata, 2016) 89.",
      "startOffset" : 11,
      "endOffset" : 34
    }, {
      "referenceID" : 1,
      "context" : "2 (Alvarez-Melis and Jaakkola, 2017)",
      "startOffset" : 2,
      "endOffset" : 36
    }, {
      "referenceID" : 8,
      "context" : "4 shows the results, following the evaluation protocol in (Beltagy and Quirk, 2016) for accuracies at both channel and full parse tree (channel + function) levels.",
      "startOffset" : 58,
      "endOffset" : 83
    }, {
      "referenceID" : 23,
      "context" : "6 Related Work Code Generation and Analysis Most existing works on code generation focus on generating code for domain specific languages (DSLs) (Kushman and Barzilay, 2013; Raza et al., 2015; Manshadi et al., 2013), with neural network-based approaches recently explored (Parisotto et al.",
      "startOffset" : 145,
      "endOffset" : 215
    }, {
      "referenceID" : 46,
      "context" : "6 Related Work Code Generation and Analysis Most existing works on code generation focus on generating code for domain specific languages (DSLs) (Kushman and Barzilay, 2013; Raza et al., 2015; Manshadi et al., 2013), with neural network-based approaches recently explored (Parisotto et al.",
      "startOffset" : 145,
      "endOffset" : 215
    }, {
      "referenceID" : 33,
      "context" : "6 Related Work Code Generation and Analysis Most existing works on code generation focus on generating code for domain specific languages (DSLs) (Kushman and Barzilay, 2013; Raza et al., 2015; Manshadi et al., 2013), with neural network-based approaches recently explored (Parisotto et al.",
      "startOffset" : 145,
      "endOffset" : 215
    }, {
      "referenceID" : 41,
      "context" : ", 2013), with neural network-based approaches recently explored (Parisotto et al., 2016; Balog et al., 2016).",
      "startOffset" : 64,
      "endOffset" : 108
    }, {
      "referenceID" : 5,
      "context" : ", 2013), with neural network-based approaches recently explored (Parisotto et al., 2016; Balog et al., 2016).",
      "startOffset" : 64,
      "endOffset" : 108
    }, {
      "referenceID" : 25,
      "context" : "(2016), existing methods often use language and task-specific rules and strategies (Lei et al., 2013; Raghothaman et al., 2016).",
      "startOffset" : 83,
      "endOffset" : 127
    }, {
      "referenceID" : 45,
      "context" : "(2016), existing methods often use language and task-specific rules and strategies (Lei et al., 2013; Raghothaman et al., 2016).",
      "startOffset" : 83,
      "endOffset" : 127
    }, {
      "referenceID" : 49,
      "context" : "A similar line is to use NL queries for code retrieval (Wei et al., 2015; Allamanis et al., 2015).",
      "startOffset" : 55,
      "endOffset" : 97
    }, {
      "referenceID" : 0,
      "context" : "A similar line is to use NL queries for code retrieval (Wei et al., 2015; Allamanis et al., 2015).",
      "startOffset" : 55,
      "endOffset" : 97
    }, {
      "referenceID" : 40,
      "context" : "The reverse task of generating NL summaries from source code has also been explored (Oda et al., 2015; Iyer et al., 2016).",
      "startOffset" : 84,
      "endOffset" : 121
    }, {
      "referenceID" : 19,
      "context" : "The reverse task of generating NL summaries from source code has also been explored (Oda et al., 2015; Iyer et al., 2016).",
      "startOffset" : 84,
      "endOffset" : 121
    }, {
      "referenceID" : 32,
      "context" : "Finally, there are probabilistic models of source code (Maddison and Tarlow, 2014; Nguyen et al., 2013).",
      "startOffset" : 55,
      "endOffset" : 103
    }, {
      "referenceID" : 39,
      "context" : "Finally, there are probabilistic models of source code (Maddison and Tarlow, 2014; Nguyen et al., 2013).",
      "startOffset" : 55,
      "endOffset" : 103
    }, {
      "referenceID" : 24,
      "context" : "The parsing process is often guided by grammatical formalisms like combinatory categorical grammars (Kwiatkowski et al., 2013; Artzi et al., 2015), dependency-based syntax (Liang et al.",
      "startOffset" : 100,
      "endOffset" : 146
    }, {
      "referenceID" : 2,
      "context" : "The parsing process is often guided by grammatical formalisms like combinatory categorical grammars (Kwiatkowski et al., 2013; Artzi et al., 2015), dependency-based syntax (Liang et al.",
      "startOffset" : 100,
      "endOffset" : 146
    }, {
      "referenceID" : 27,
      "context" : ", 2015), dependency-based syntax (Liang et al., 2011; Pasupat and Liang, 2015) or task-specific formalisms (Clarke et al.",
      "startOffset" : 33,
      "endOffset" : 78
    }, {
      "referenceID" : 42,
      "context" : ", 2015), dependency-based syntax (Liang et al., 2011; Pasupat and Liang, 2015) or task-specific formalisms (Clarke et al.",
      "startOffset" : 33,
      "endOffset" : 78
    }, {
      "referenceID" : 13,
      "context" : ", 2011; Pasupat and Liang, 2015) or task-specific formalisms (Clarke et al., 2010; Yih et al., 2015; Krishnamurthy et al., 2016; Misra et al., 2015; Mei et al., 2016).",
      "startOffset" : 61,
      "endOffset" : 166
    }, {
      "referenceID" : 51,
      "context" : ", 2011; Pasupat and Liang, 2015) or task-specific formalisms (Clarke et al., 2010; Yih et al., 2015; Krishnamurthy et al., 2016; Misra et al., 2015; Mei et al., 2016).",
      "startOffset" : 61,
      "endOffset" : 166
    }, {
      "referenceID" : 22,
      "context" : ", 2011; Pasupat and Liang, 2015) or task-specific formalisms (Clarke et al., 2010; Yih et al., 2015; Krishnamurthy et al., 2016; Misra et al., 2015; Mei et al., 2016).",
      "startOffset" : 61,
      "endOffset" : 166
    }, {
      "referenceID" : 36,
      "context" : ", 2011; Pasupat and Liang, 2015) or task-specific formalisms (Clarke et al., 2010; Yih et al., 2015; Krishnamurthy et al., 2016; Misra et al., 2015; Mei et al., 2016).",
      "startOffset" : 61,
      "endOffset" : 166
    }, {
      "referenceID" : 34,
      "context" : ", 2011; Pasupat and Liang, 2015) or task-specific formalisms (Clarke et al., 2010; Yih et al., 2015; Krishnamurthy et al., 2016; Misra et al., 2015; Mei et al., 2016).",
      "startOffset" : 61,
      "endOffset" : 166
    }, {
      "referenceID" : 35,
      "context" : "Recently, there are efforts in designing neural network-based semantic parsers (Misra and Artzi, 2016; Dong and Lapata, 2016; Neelakantan et al., 2016).",
      "startOffset" : 79,
      "endOffset" : 151
    }, {
      "referenceID" : 14,
      "context" : "Recently, there are efforts in designing neural network-based semantic parsers (Misra and Artzi, 2016; Dong and Lapata, 2016; Neelakantan et al., 2016).",
      "startOffset" : 79,
      "endOffset" : 151
    }, {
      "referenceID" : 37,
      "context" : "Recently, there are efforts in designing neural network-based semantic parsers (Misra and Artzi, 2016; Dong and Lapata, 2016; Neelakantan et al., 2016).",
      "startOffset" : 79,
      "endOffset" : 151
    }, {
      "referenceID" : 21,
      "context" : "Several approaches have be proposed to utilize grammar knowledge in a neural parser, such as augmenting the training data by generating examples guided by the grammar (Kociský et al., 2016; Jia and Liang, 2016).",
      "startOffset" : 167,
      "endOffset" : 210
    }, {
      "referenceID" : 20,
      "context" : "Several approaches have be proposed to utilize grammar knowledge in a neural parser, such as augmenting the training data by generating examples guided by the grammar (Kociský et al., 2016; Jia and Liang, 2016).",
      "startOffset" : 167,
      "endOffset" : 210
    }, {
      "referenceID" : 3,
      "context" : ", 2016; Balog et al., 2016). For general-purpose code generation, besides the general framework of Ling et al. (2016), existing methods often use language and task-specific rules and strategies (Lei et al.",
      "startOffset" : 8,
      "endOffset" : 118
    }, {
      "referenceID" : 0,
      "context" : ", 2015; Allamanis et al., 2015). The reverse task of generating NL summaries from source code has also been explored (Oda et al., 2015; Iyer et al., 2016). Finally, there are probabilistic models of source code (Maddison and Tarlow, 2014; Nguyen et al., 2013). The most relevant work is Allamanis et al. (2015), which uses a factorized model to measure semantic relatedness between NL and ASTs for code retrieval, while our model tackles the more challenging generation task.",
      "startOffset" : 8,
      "endOffset" : 311
    }, {
      "referenceID" : 0,
      "context" : ", 2015; Allamanis et al., 2015). The reverse task of generating NL summaries from source code has also been explored (Oda et al., 2015; Iyer et al., 2016). Finally, there are probabilistic models of source code (Maddison and Tarlow, 2014; Nguyen et al., 2013). The most relevant work is Allamanis et al. (2015), which uses a factorized model to measure semantic relatedness between NL and ASTs for code retrieval, while our model tackles the more challenging generation task. Semantic Parsing Our work is related to the general topic of semantic parsing, where the target logical forms can be viewed as DSLs. The parsing process is often guided by grammatical formalisms like combinatory categorical grammars (Kwiatkowski et al., 2013; Artzi et al., 2015), dependency-based syntax (Liang et al., 2011; Pasupat and Liang, 2015) or task-specific formalisms (Clarke et al., 2010; Yih et al., 2015; Krishnamurthy et al., 2016; Misra et al., 2015; Mei et al., 2016). Recently, there are efforts in designing neural network-based semantic parsers (Misra and Artzi, 2016; Dong and Lapata, 2016; Neelakantan et al., 2016). Several approaches have be proposed to utilize grammar knowledge in a neural parser, such as augmenting the training data by generating examples guided by the grammar (Kociský et al., 2016; Jia and Liang, 2016). Liang et al. (2016) used a neural decoder which constrains the space of next valid tokens in the query language for question answering.",
      "startOffset" : 8,
      "endOffset" : 1347
    }, {
      "referenceID" : 0,
      "context" : ", 2015; Allamanis et al., 2015). The reverse task of generating NL summaries from source code has also been explored (Oda et al., 2015; Iyer et al., 2016). Finally, there are probabilistic models of source code (Maddison and Tarlow, 2014; Nguyen et al., 2013). The most relevant work is Allamanis et al. (2015), which uses a factorized model to measure semantic relatedness between NL and ASTs for code retrieval, while our model tackles the more challenging generation task. Semantic Parsing Our work is related to the general topic of semantic parsing, where the target logical forms can be viewed as DSLs. The parsing process is often guided by grammatical formalisms like combinatory categorical grammars (Kwiatkowski et al., 2013; Artzi et al., 2015), dependency-based syntax (Liang et al., 2011; Pasupat and Liang, 2015) or task-specific formalisms (Clarke et al., 2010; Yih et al., 2015; Krishnamurthy et al., 2016; Misra et al., 2015; Mei et al., 2016). Recently, there are efforts in designing neural network-based semantic parsers (Misra and Artzi, 2016; Dong and Lapata, 2016; Neelakantan et al., 2016). Several approaches have be proposed to utilize grammar knowledge in a neural parser, such as augmenting the training data by generating examples guided by the grammar (Kociský et al., 2016; Jia and Liang, 2016). Liang et al. (2016) used a neural decoder which constrains the space of next valid tokens in the query language for question answering. Finally, the structured prediction approach proposed by Xiao et al. (2016) is closely related to our model in using the underlying grammar as prior knowledge to constrain the generation process of derivation trees, while our method is based on a unified grammar model which jointly captures production rule application and terminal symbol generation, and scales to general purpose code generation tasks.",
      "startOffset" : 8,
      "endOffset" : 1538
    } ],
    "year" : 2017,
    "abstractText" : "We consider the problem of parsing natural language descriptions into source code written in a general-purpose programming language like Python. Existing datadriven methods treat this problem as a language generation task without considering the underlying syntax of the target programming language. Informed by previous work in semantic parsing, in this paper we propose a novel neural architecture powered by a grammar model to explicitly capture the target syntax as prior knowledge. Experiments find this an effective way to scale up to generation of complex programs from natural language descriptions, achieving state-of-the-art results that well outperform previous code generation and semantic parsing approaches.",
    "creator" : "LaTeX with hyperref package"
  }
}