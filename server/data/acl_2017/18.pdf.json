{
  "name" : "18.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Attention-over-Attention Neural Networks for Reading Comprehension",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "1 000\n011\n012\n013\n014\n015\n016\n017\n018\n019\n020\n021\n022\n023\n024\n025\n026\n027\n028\n029\n030\n031\n032\n033\n034\n035\n036\n037\n038\n039\n040\n041\n042\n043\n044\n045\n046\n047\n048\n049\n061\n062\n063\n064\n065\n066\n067\n068\n069\n070\n071\n072\n073\n074\n075\n076\n077\n078\n079\n080\n081\n082\n083\n084\n085\n086\n087\n088\n089\n090\n091\n092\n093\n094\n095\n096\n097\n098\n099"
    }, {
      "heading" : "1 Introduction",
      "text" : "To read and comprehend the human languages are challenging tasks for the machines, which requires that the understanding of natural languages and the ability to do reasoning over various clues. Reading comprehension is a general problem in the real world, which aims to read and comprehend a given article or context, and answer the questions based on it. Recently, the cloze-style reading comprehension problem has become a popular task in the community. The cloze-style query (Taylor, 1953) is a problem that to fill in an appropriate word in the given sentences while taking the context information into account.\nTo teach the machine to do cloze-style reading comprehensions, large-scale training data is nec-\nessary for learning relationships between the given document and query. To create large-scale training data for neural networks, Hermann et al. (2015) released the CNN/Daily Mail news dataset, where the document is formed by the news articles and the queries are extracted from the summary of the news. Hill et al. (2015) released the Children’s Book Test dataset afterwards, where the training samples are generated from consecutive 20 sentences from books, and the query is formed by 21st sentence. Following these datasets, a vast variety of neural network approaches have been proposed (Kadlec et al., 2016; Cui et al., 2016; Chen et al., 2016; Dhingra et al., 2016; Sordoni et al., 2016; Trischler et al., 2016), and most of them stem from the attention-based neural network (Bahdanau et al., 2014), which has become a stereotype in most of the NLP tasks and is wellknown by its capability of learning the “importance” distribution over the inputs.\nIn this paper, we present a novel neural network architecture, called attention-over-attention model. As we can understand the meaning literally, our model aims to place another attention mechanism over the existing document-level attention. Unlike the previous works, that are using heuristic merging functions (Cui et al., 2016), or setting various pre-defined non-trainable terms (Trischler et al., 2016), our model could automatically generate an “attended attention” over various document-level attentions, and make a mutual look not only from query-to-document but also document-to-query, which will benefit from the interactive information.\nTo sum up, the main contributions of our work are listed as follows.\n• To our knowledge, this is the first time that the mechanism of nesting another attention over the existing attentions is proposed, i.e.\n2\n101\n102\n103\n104\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n123\n124\n125\n126\n127\n128\n129\n130\n131\n132\n133\n134\n135\n136\n137\n138\n139\n140\n141\n142\n143\n144\n145\n146\n147\n148\n149\n150\n151\n152\n153\n154\n155\n156\n157\n158\n159\n160\n161\n162\n163\n164\n165\n166\n167\n168\n169\n170\n171\n172\n173\n174\n175\n176\n177\n178\n179\n180\n181\n182\n183\n184\n185\n186\n187\n188\n189\n190\n191\n192\n193\n194\n195\n196\n197\n198\n199\nattention-over-attention mechanism.\n• Unlike the previous works on introducing complex architectures or many non-trainable hyper-parameters to the model, our model is much more simple but outperforms various state-of-the-art systems by a large margin.\n• We also propose an N-best re-ranking strategy to re-score the candidates in various aspects and further improve the performance."
    }, {
      "heading" : "2 Cloze-style Reading Comprehension",
      "text" : "In this section, we will give a brief introduction to the cloze-style reading comprehension task at the beginning. And then, several existing public datasets will be described in detail."
    }, {
      "heading" : "2.1 Task Description",
      "text" : "Formally, a general Cloze-style reading comprehension problem can be illustrated as a triple:\n〈D,Q,A〉\nThe triple consists of a documentD, a queryQ and the answer to the queryA. Note that the answer is usually a single word in the document, which requires the human to exploit context information in both document and query. The type of the answer word varies from predicting a preposition given a fixed collocation to identifying a named entity from a factual illustration."
    }, {
      "heading" : "2.2 Existing Public Datasets",
      "text" : "Large-scale training data is essential for training neural networks. Several public datasets for the cloze-style reading comprehension has been released. Here, we introduce two representative and widely-used datasets. CNN/Daily Mail.1 Hermann et al. (2015) have firstly published two datasets: CNN and Daily Mail news data. They construct these datasets with web-crawled CNN and Daily Mail news data. One of the characteristics of these datasets is that the news article is often associated with a summary. So they first regard the main body of the news article as the Document, and the Query is formed by the summary of the article, where one entity word is replaced by a special placeholder to indicate the missing word. The replaced entity word\n1The pre-processed CNN and Daily Mail datasets are available at http://cs.nyu.edu/˜kcho/DMQA/\nwill be the Answer of the Query. Apart from releasing the dataset, they also proposed a methodology that anonymizes the named entity tokens in the data, and these tokens are also re-shuffle in each sample. The motivation is that the news articles are containing limited named entities, which are usually celebrities, and the world knowledge can be learned from the dataset. So this methodology aims to exploit general relationships between anonymized named entities within a single document rather than the common knowledge. The following research on these datasets showed that the entity word anonymization is not that effective than expected (Chen et al., 2016). Children’s Book Test. 2 There was also a dataset called the Children’s Book Test (CBTest) released by Hill et al. (2015), which is built on the children’s book story through Project Gutenberg. Different from the CNN/Daily Mail datasets, there is no summary available in the children’s book. So they proposed another way to extract query from the original data. The document is composed of 20 consecutive sentences in the story, and the 21st sentence is regarded as the query, where one word is blanked with a special placeholder. In the CBTest datasets, there are four types of sub-datasets available which are classified by the part-of-speech tag of the answer word, containing Named Entities (NE), Common Nouns (CN), Verbs and Prepositions. In their studies, they have found that the answering of verbs and prepositions are relatively less dependent on the content of document, and the humans can even do preposition blank-filling without the presence of the document. As the aim of reading comprehension is to exploit relations between document and query, most of the following studies are only focusing on the NE and CN datasets."
    }, {
      "heading" : "3 Attention-over-Attention Reader",
      "text" : "In this section, we will give a detailed introduction to the proposed Attention-over-Attention Reader (AoA Reader). Our model is primarily motivated by Kadlec et al., (2016), which aims to directly estimate the answer from the document-level attention instead of calculating blended representations of the document. As previous studies by Cui et al. (2016) showed that the further investigation\n2The CBTest datasets are available at http: //www.thespermwhale.com/jaseweston/babi/ CBTest.tgz\n3\n201\n202\n203\n204\n205\n206\n207\n208\n209\n210\n211\n212\n213\n214\n215\n216\n217\n218\n219\n220\n221\n222\n223\n224\n225\n226\n227\n228\n229\n230\n231\n232\n233\n234\n235\n236\n237\n238\n239\n240\n241\n242\n243\n244\n245\n246\n247\n248\n249\n251\n252\n253\n254\n255\n256\n257\n258\n259\n260\n261\n262\n263\n264\n265\n266\n267\n268\n269\n270\n271\n272\n273\n274\n275\n276\n277\n278\n279\n280\n281\n282\n283\n284\n285\n286\n287\n288\n289\n290\n291\n292\n293\n294\n295\n296\n297\n298\n299\nDocument\nQuery\n!(“$%&'”|*,,) = / 01 = 02 + 04\n1∈7(“89:;”,<) Mary\nsits\nbeside\nhim ...\nhe\nloves\nMary\nhe\nloves\nX\ndot product\nColumn-wise softmax\nRow-wise softmax\nColumn-wise Average\ndot product\nEmbedding Layer\nbi-GRU Layer\nIndividual ATT Layer\nATT-over-ATT Layer\nSum ATT Layer\nFigure 1: Neural network architecture of the proposed Attention-over-Attention Reader (AoA Reader).\nof query representation is necessary, and it should be paid more attention to utilizing the information of query. In this paper, we propose a novel work that placing another attention over the primary attentions, to indicate the “importance” of each attentions.\nNow, we will give a formal description of our proposed model. When a cloze-style training triple 〈D,Q,A〉 is given, the proposed model will be constructed in the following steps.\nContextual Embedding. We first transform every word in the documentD and queryQ into one-hot representations and then convert them into continuous representations with a shared embedding matrix We. The motivation of using shared embedding weights is that the length of the query is shorter than the document, and thus the embedding weights will not be fully learned by only using a small amount of training data. By embedding sharing, both the document and query can participate in the learning of embedding and both of them will benefit from this mechanism. After that, we use two bi-directional RNNs to get contextual representations of the document and query individually, where the representation of each word\nis formed by concatenating the forward and backward hidden states. After making a trade-off between model performance and training complexity, we choose the Gated Recurrent Unit (GRU) (Cho et al., 2014) as recurrent unit implementation.\ne(x) =We · x, where x ∈ D,Q (1) −−−→ hs(x) = −−−→ GRU(e(x)) (2)\n←−−− hs(x) = ←−−− GRU(e(x)) (3)\nhs(x) = [ −−−→ hs(x); ←−−− hs(x)] (4)\nWe take hdoc ∈ R|D|∗2d and hquery ∈ R|Q|∗2d to denote the contextual representations of document and query, where d is the dimension of GRU (oneway). Pair-wise Matching Score. After obtaining the contextual embeddings of the document hdoc and query hquery, we calculate a pair-wise matching matrix, which indicates the pair-wise matching degree of one document word and one query word. Formally, when given ith word of the document and jth word of query, we can compute a matching score by their dot product.\nM(i, j) = hdoc(i) T · hquery(j) (5)\n4\n301\n302\n303\n304\n305\n306\n307\n308\n309\n310\n311\n312\n313\n314\n315\n316\n317\n318\n319\n320\n321\n322\n323\n324\n325\n326\n327\n328\n329\n330\n331\n332\n333\n334\n335\n336\n337\n338\n339\n340\n341\n342\n343\n344\n345\n346\n347\n348\n349\n351\n352\n353\n354\n355\n356\n357\n358\n359\n360\n361\n362\n363\n364\n365\n366\n367\n368\n369\n370\n371\n372\n373\n374\n375\n376\n377\n378\n379\n380\n381\n382\n383\n384\n385\n386\n387\n388\n389\n390\n391\n392\n393\n394\n395\n396\n397\n398\n399\nIn this way, we can calculate every pair-wise matching score between each document and query word, forming a matrix M ∈ R|D|∗|Q|, where the value of ith row and jth column is filled by M(i, j). Individual Attentions. After getting the pair-wise matching matrixM , we apply a column-wise softmax function to get probability distributions in each column, where each column is an individual document-level attention when considering a single query word. We denote α(t) ∈ R|D| as the document-level attention regarding query word at time t, which can be seen as a query-to-document attention.\nα(t) = softmax(M(1, t), ...,M(|D|, t)) (6) α = [α(1), α(2), ..., α(|Q|)] (7)\nAttention-over-Attention. Instead of using naive heuristics (such as summing or averaging) to combine these individual attentions into a final attention, we introduce another attention mechanism to automatically decide the importance of each individual attention.\nFirst, we calculate a reversed attention, that is, for every document word at time t, we calculate the “importance” distribution on the query, to indicate which query words are more important given a single document word. We apply a row-wise softmax function to the pair-wise matching matrix M to get query-level attentions. We denote β(t) ∈ R|Q| as the query-level attention regarding document word at time t, which can be seen as a document-to-query attention.\nβ(t) = softmax(M(t, 1), ...,M(t, |Q|)) (8)\nSo far, we have obtained both query-todocument attention α and document-to-query attention β. Our motivation is to exploit mutual information between the document and query. However, most of the previous works are only relying on query-to-document attention, that is, only calculate one document-level attention when considering the whole query.\nThen we average all the β(t) to get an averaged query-level attention β. Note that, we do not apply another softmax to the β, because averaging individual attentions do not break the normalizing condition.\nβ = 1\nn |D|∑ t=1 β(t) (9)\nFinally, we calculate dot product of α and β to get the “attended document-level attention” s ∈ R|D|, i.e. the attention-over-attention mechanism. Intuitively, this operation is calculating a weighted sum of each individual document-level attention α(t) when looking at query word at time t. In this way, the contributions by each query word can be learned explicitly, and the final decision (document-level attention) is made through the voted result by the importance of each query word.\ns = αTβ (10)\nFinal Predictions. Following Kadlec et al. (2016), we use sum attention mechanism to get aggregated results. Note that the final output should be reflected in the vocabulary space V , rather than document-level attention |D|, which will make a significant difference in the performance, though Kadlec et al. (2016) did not illustrate this clearly.\nP (w|D,Q) = ∑\ni∈I(w,D)\nsi, w ∈ V (11)\nwhere I(w,D) indicate the positions that word w appear in the document D. As the training objectives, we seek to maximize the log-likelihood of the correct answer.\nL = ∑ i log(p(x)) , x ∈ A (12)\nThe proposed neural network architecture is depicted in Figure 1. Note that, as our model mainly adds limited steps of calculations to the AS Reader (Kadlec et al., 2016) and do not employ any additional weights, the computational complexity is similar to the AS Reader."
    }, {
      "heading" : "4 N-best Re-ranking Strategy",
      "text" : "Intuitively, when we do cloze-style reading comprehensions, we often refill the candidate into the blank of the query to double-check its appropriateness, fluency and grammar to see if the candidate we choose is the most suitable one. If we do find some problems in the candidate we choose, we will choose the second possible candidate and do some checking again.\nTo mimic the process of double-checking, we propose to use N-best re-ranking strategy after generating answers from our neural networks. The procedure can be illustrated as follows. N-best decoding. Instead of only picking the candidate that has the highest possibility as answer,\n5\n401\n402\n403\n404\n405\n406\n407\n408\n409\n410\n411\n412\n413\n414\n415\n416\n417\n418\n419\n420\n421\n422\n423\n424\n425\n426\n427\n428\n429\n430\n431\n432\n433\n434\n435\n436\n437\n438\n439\n440\n441\n442\n443\n444\n445\n446\n447\n448\n449\n461\n462\n463\n464\n465\n466\n467\n468\n469\n470\n498\n499\nCNN News CBT NE CBT CN Train Valid Test Train Valid Test Train Valid Test\n# Query 380,298 3,924 3,198 108,719 2,000 2,500 120,769 2,000 2,500 Max # candidates 527 187 396 10 10 10 10 10 10 Avg # candidates 26 26 25 10 10 10 10 10 10 Avg # tokens 762 763 716 433 412 424 470 448 461 Vocabulary 118,497 53,063 53,185\nwe can also extract follow-up candidates in the decoding process, which forms an N-best list. Refill the candidate into query. As a characteristic of the cloze-style problem, each candidate can be refilled into the blank of the query to form a complete sentence. This allows us to check the candidate according to its context. Feature scoring. The candidate sentences can be scored in many aspects. In this paper, we exploit three features to score the N-best list.\n• Global N-gram LM: This is a fundamental metric in scoring sentence, which aims to evaluate its fluency. This model is trained on the document part of training data.\n• Local N-gram LM: Different from global LM, the local LM aims to explore the information with the given document, so the statistics are obtained from the test-time document. It should be noted that the local LM is trained sample-by-sample, it is not trained on the entire test set, which is not legal in the real test case. This model is useful when there are many unknown words in the test sample.\n• Word-class LM: Similar to global LM, the word-class LM is also trained on the document part of training data, but the words are converted to its word class ID. The word class can be obtained by using clustering methods. In this paper, we simply utilized the mkcls tool for generating 1000 word classes (Josef Och, 1999).\nWeight Tuning. To tune the weights among these features, we adopt the K-best MIRA algorithm (Cherry and Foster, 2012) to automatically optimize the weights on the validation set, which is widely used in statistical machine translation tuning procedure.\nRe-scoring and Re-ranking. After getting the weights of each feature, we calculate the weighted sum of each feature in the N-best sentences and then choose the candidate that has the lowest cost as the final answer."
    }, {
      "heading" : "5 Experiments",
      "text" : ""
    }, {
      "heading" : "5.1 Experimental Setups",
      "text" : "The general settings of our neural network model are listed below in detail.\n6\n501\n502\n503\n504\n505\n506\n507\n508\n509\n510\n511\n512\n513\n514\n515\n516\n517\n518\n519\n520\n521\n522\n523\n524\n525\n526\n527\n528\n529\n530\n531\n532\n533\n534\n535\n536\n537\n538\n539\n540\n541\n542\n543\n544\n545\n546\n547\n548\n549\n551\n552\n553\n554\n555\n556\n557\n558\n559\n560\n561\n562\n563\n564\n565\n566\n567\n568\n569\n570\n571\n572\n573\n574\n575\n576\n577\n578\n579\n580\n581\n582\n583\n584\n585\n586\n587\n588\n589\n590\n591\n592\n593\n594\n595\n596\n597\n598\n599\nCNN News CBTest NE CBTest CN Valid Test Valid Test Valid Test\nDeep LSTM Reader (Hermann et al., 2015) 55.0 57.0 - - - - Attentive Reader (Hermann et al., 2015) 61.6 63.0 - - - - Human (context+query) (Hill et al., 2015) - - - 81.6 - 81.6 MemNN (window + self-sup.) (Hill et al., 2015) 63.4 66.8 70.4 66.6 64.2 63.0 AS Reader (Kadlec et al., 2016) 68.6 69.5 73.8 68.6 68.8 63.4 CAS Reader (Cui et al., 2016) 68.2 70.0 74.2 69.2 68.2 65.7 Stanford AR (Chen et al., 2016) 72.4 72.4 - - - - GA Reader (Dhingra et al., 2016) 73.0 73.8 74.9 69.0 69.0 63.9 Iterative Attention (Sordoni et al., 2016) 72.6 73.3 75.2 68.6 72.1 69.2 EpiReader (Trischler et al., 2016) 73.4 74.0 75.3 69.7 71.5 67.4 AoA Reader 73.1 74.4 77.8 72.0 72.2 69.4 AoA Reader + Reranking - - 79.6 74.0 75.7 73.1 MemNN (Ensemble) 66.2 69.4 - - - - AS Reader (Ensemble) 73.9 75.4 74.5 70.6 71.1 68.9 GA Reader (Ensemble) 76.4 77.4 75.5 71.9 72.1 69.4 EpiReader (Ensemble) - - 76.6 71.8 73.6 70.6 Iterative Attention (Ensemble) 74.5 75.7 76.9 72.0 74.1 71.0 AoA Reader (Ensemble) - - 78.9 74.5 74.7 70.8 AoA Reader (Ensemble + Reranking) - - 80.3 75.6 77.0 74.1\nTable 3: Results on the CNN news, CBTest NE and CN datasets. The best baseline results are depicted in italics, and the overall best results are in bold face.\nDimensions of embedding and hidden layer for each task are listed in Table 2. In re-ranking step, all language models are 8-gram, and trained by SRILM toolkit (Stolcke, 2002). The results are reported with the best model, which is selected by the performance of validation set. The ensemble model is made up of four best models, which are trained using different random seed. Implementation is done with Theano (Theano Development Team, 2016) and Keras (Chollet, 2015), and all models are trained on Tesla K40 GPU."
    }, {
      "heading" : "5.2 Overall Results",
      "text" : "Our experiments are carried out on public datasets: CNN news datasets (Hermann et al., 2015) and CBTest NE/CN datasets (Hill et al., 2015). The statistics of these datasets are listed in Table 1, and the experimental results are given in Table 3.\nAs we can see that, our AoA Reader outperforms state-of-the-art systems by a large margin, where 2.3% and 2.0% absolute improvements over EpiReader in CBTest NE and CN test sets, which demonstrate the effectiveness of our model. Also by adding additional features in the re-ranking step, there is another significant boost 2.0% to\n3.7% over AoA Reader in CBTest NE/CN test sets. We have also found that our single model could stay on par with the previous best ensemble system, and even we have an absolute improvement of 0.9% beyond the best ensemble model (Iterative Attention) in the CBTest NE validation set. When it comes to ensemble model, our AoA Reader also shows significant improvements over previous best ensemble models by a large margin and set up a new state-of-the-art system.\nTo investigate the effectiveness of employing attention-over-attention mechanism, we also compared our model to CAS Reader, which used predefined merging heuristics, such as sum or avg etc. Instead of using pre-defined merging heuristics, and letting the model explicitly learn the weights between individual attentions results in a significant boost in the performance, where 4.1% and 3.7% improvements can be made in CNN validation and test set against CAS Reader."
    }, {
      "heading" : "5.3 Effectiveness of Re-ranking Strategy",
      "text" : "As we have seen that the re-ranking approach is effective in cloze-style reading comprehension task. To have a thorough investigation in the re-ranking\n7\n601\n602\n603\n604\n605\n606\n607\n608\n609\n610\n611\n612\n613\n614\n615\n616\n617\n618\n619\n620\n621\n622\n623\n624\n625\n626\n627\n628\n629\n630\n631\n632\n633\n634\n635\n636\n637\n638\n639\n640\n641\n642\n643\n644\n645\n646\n647\n648\n649\n651\n652\n653\n654\n655\n656\n657\n658\n659\n660\n661\n662\n663\n664\n665\n666\n667\n668\n669\n670\n671\n672\n673\n674\n675\n676\n677\n678\n679\n680\n681\n682\n683\n684\n685\n686\n687\n688\n689\n690\n691\n692\n693\n694\n695\n696\n697\n698\n699\nCBTest NE CBTest CN Valid Test Valid Test\nAoA Reader 77.8 72.0 72.2 69.4 +Global LM 78.3 72.6 73.9 71.2 +Local LM 79.4 73.8 74.7 71.7 +Word-class LM 79.6 74.0 75.7 73.1\nTable 4: Detailed results of 5-best re-ranking on CBTest NE/CN datasets. Each row includes all of the features from previous rows. LMglobal denotes the global LM, LMlocal denotes the local LM, LMwc denotes the word-class LM.\nstep, we listed the detailed improvements while adding each feature mentioned in Section 4.\nFrom the results in Table 4, we found that the NE and CN category both benefit a lot from the re-ranking features, but the proportions are quite different. Generally speaking, in NE category, the performance is mainly boosted by the LMlocal feature. However, on the contrary, the CN category benefit from LMglobal and LMwc rather than the LMlocal.\nCBTest NE CBTest CN\nNN 0.64 0.20 Global LM 0.16 0.10 Word-class LM 0.04 0.39 Local LM 0.16 0.31 RATIO η 1.25 1.58\nTable 5: Weight of each feature in N-best reranking step. NN denotes the feature (probability) produced by baseline neural network model.\nAlso, we listed the weights of each feature in Table 5. The LMglobal and LMwc are all trained by training set, which can be seen as Global Feature. However, the LMlocal is only trained within the respective document part of test sample, which can be seen as Local Feature.\nη = LMglobal + LMwc\nLMlocal (13)\nWe calculated the ratio between the global and local features and found that the NE category is much more dependent on local features than CN category. Because it is much more likely to meet a new named entity than a common noun in the test phase, so adding the local LM provides much more information than that of common\nnoun. However, on the contrary, answering common noun requires less local information, which can be learned in the training data relatively."
    }, {
      "heading" : "6 Quantitative Analysis",
      "text" : "In this section, we will give a quantitative analysis to our AoA Reader. The following analyses are carried out on CBTest NE dataset. First, we investigate the relations between the length of the document and corresponding accuracy. The result is depicted in Figure 2.\nAs we can see that the AoA Reader shows consistent improvements over AS Reader on the different length of the document. Especially, when the length of document exceeds 700, the improvements become larger, indicating that the AoA Reader is more capable of handling long documents.\n18 486 758 525 370 262 61\nAoA Reader AS Reader\nAc cu\nra cy\n0.65\n0.70\n0.75\n0.80\n0.85\n0.90\nLength of Document 100 200 300 400 500 600 700 800\nFigure 2: Test accuracy against the length of the document. The bar below the figure indicates the number of samples in each interval.\nFurthermore, we also investigate if the model tends to choose a high-frequency candidate than a lower one, which is shown in Figure 3. Not surprisingly, we found that both models do a good job when the correct answer appear much frequent in the document than the other candidates. This is because that the correct answer that has the highest frequency among the candidates takes up over 40% of the test set (1071 out of 2500). But interestingly we have also found that, when the frequency rank of correct answer exceeds 7 (less frequent among candidates), these models also give a relatively high performance. Empirically, we think that these models tend to choose extreme cases in terms of candidate frequency (either too\n8\n701\n702\n703\n704\n705\n706\n707\n708\n709\n710\n711\n712\n713\n714\n715\n716\n717\n718\n719\n720\n721\n722\n723\n724\n725\n726\n727\n728\n729\n730\n731\n732\n733\n734\n735\n736\n737\n738\n739\n740\n741\n742\n743\n744\n745\n746\n747\n748\n749\n751\n752\n753\n754\n755\n756\n757\n758\n759\n760\n761\n762\n763\n764\n765\n766\n767\n768\n769\n770\n771\n772\n773\n774\n775\n776\n777\n778\n779\n780\n781\n782\n783\n784\n785\n786\n787\n788\n789\n790\n791\n792\n793\n794\n795\n796\n797\n798\n799\n1071 588 354 264 127 59 28 8 1 1\nAoA Reader AS Reader\nAc cu\nra cy\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1.0\nRank of the answer 1 2 3 4 5 6 7 8 9 10\nFigure 3: Test accuracy against the frequency rank of the answer. The bar below the figure indicates the number of samples in each rank.\nhigh or too low). One possible reason is that the model is hard to choose a candidate that has a neutral frequency as the correct answer, because of its ambiguity (neutral choices are hard to made)."
    }, {
      "heading" : "7 Related Work",
      "text" : "Cloze-style reading comprehension tasks have been widely investigated in recent studies. We will take a brief revisit to the related works.\nHermann et al. (2015) have proposed a method for obtaining large quantities of 〈D,Q,A〉 triples through news articles and its summary. Along with the release of cloze-style reading comprehension dataset, they also proposed an attention-based neural network to handle this task. Experimental results showed that the proposed neural network is effective than traditional baselines.\nHill et al. (2015) released another dataset, which stems from the children’s books. Different from Hermann et al. (2015)’s work, the document and query are all generated from the raw story without any summary, which is much more general than previous work. To handle the reading comprehension task, they proposed a window-based memory network, and self-supervision heuristics is also applied to learn hard-attention.\nUnlike previous works, that using blended representations of document and query to estimate the answer, Kadlec et al. (2016) proposed a simple model that directly pick the answer from the document, which is motivated by the Pointer Network (Vinyals et al., 2015). A restriction of this model is that the answer should be a single word\nand appear in the document. Results on various public datasets showed that the proposed model is effective than previous works.\nLiu et al. (2016) proposed to exploit reading comprehension models to other tasks. They first applied the reading comprehension model into Chinese zero pronoun resolution task with automatically generated large-scale pseudo training data. The experimental results on OntoNotes 5.0 data showed that their method significantly outperforms various state-of-the-art systems.\nOur work is primarily inspired by Cui et al. (2016) and Kadlec et al. (2016) , where the latter model is widely applied to many follow-up works (Sordoni et al., 2016; Trischler et al., 2016; Cui et al., 2016). Unlike the CAS Reader (Cui et al., 2016), we do not assume any heuristics to our model, such as using merge functions: sum, avg etc. We used a mechanism called “attentionover-attention” to explicitly calculate the weights between different individual document-level attentions, and get the final attention by computing the weighted sum of them. Also, we find that our model is typically general and simple than the recently proposed model, and brings significant improvements over these cutting edge systems."
    }, {
      "heading" : "8 Conclusion",
      "text" : "We present a novel neural architecture, called attention-over-attention reader, to tackle the clozestyle reading comprehension task. The proposed AoA Reader aims to compute the attentions not only for the document but also the query side, which will benefit from the mutual information. Then a weighted sum of attention is carried out to get an attended attention over the document for the final predictions. Among several public datasets, our model could give consistent and significant improvements over various state-of-theart systems by a large margin.\nThe future work will be carried out in the following aspects. We believe that our model is general and may apply to other tasks as well, so firstly we are going to fully investigate the usage of this architecture in other tasks. Also, we are interested to see that if the machine really “comprehend” our language by utilizing neural networks approaches, but not only serve as a “document-level” language model. In this context, we are planning to investigate the problems that need comprehensive reasoning over several sentences.\n9\n801\n802\n803\n804\n805\n806\n807\n808\n809\n810\n811\n812\n813\n814\n815\n816\n817\n818\n819\n820\n821\n822\n823\n824\n825\n826\n827\n828\n829\n830\n831\n832\n833\n834\n835\n836\n837\n838\n839\n840\n841\n842\n843\n844\n845\n846\n847\n848\n849\n850\n851\n852\n853\n854\n855\n856\n857\n858\n859\n860\n861\n862\n863\n864\n865\n866\n867\n868\n869\n870\n871\n872\n873\n874\n875\n876\n877\n878\n879\n880\n881\n882\n883\n884\n885\n886\n887\n888\n889\n890\n891\n892\n893\n894\n895\n896\n897\n898\n899"
    } ],
    "references" : [ {
      "title" : "Neural machine translation by jointly learning to align and translate",
      "author" : [ "Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio." ],
      "venue" : "arXiv preprint arXiv:1409.0473 .",
      "citeRegEx" : "Bahdanau et al\\.,? 2014",
      "shortCiteRegEx" : "Bahdanau et al\\.",
      "year" : 2014
    }, {
      "title" : "A thorough examination of the cnn/daily mail reading comprehension task",
      "author" : [ "Danqi Chen", "Jason Bolton", "Christopher D. Manning." ],
      "venue" : "Association for Computational Linguistics (ACL).",
      "citeRegEx" : "Chen et al\\.,? 2016",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2016
    }, {
      "title" : "Batch tuning strategies for statistical machine translation",
      "author" : [ "Colin Cherry", "George Foster." ],
      "venue" : "Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Lan-",
      "citeRegEx" : "Cherry and Foster.,? 2012",
      "shortCiteRegEx" : "Cherry and Foster.",
      "year" : 2012
    }, {
      "title" : "Learning phrase representations using rnn encoder–decoder for statistical machine translation",
      "author" : [ "Kyunghyun Cho", "Bart van Merrienboer", "Caglar Gulcehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio." ],
      "venue" : "Proceedings of",
      "citeRegEx" : "Cho et al\\.,? 2014",
      "shortCiteRegEx" : "Cho et al\\.",
      "year" : 2014
    }, {
      "title" : "Keras",
      "author" : [ "François Chollet." ],
      "venue" : "https://github. com/fchollet/keras.",
      "citeRegEx" : "Chollet.,? 2015",
      "shortCiteRegEx" : "Chollet.",
      "year" : 2015
    }, {
      "title" : "Consensus attention-based neural networks for chinese reading comprehension",
      "author" : [ "Yiming Cui", "Ting Liu", "Zhipeng Chen", "Shijin Wang", "Guoping Hu." ],
      "venue" : "Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics:",
      "citeRegEx" : "Cui et al\\.,? 2016",
      "shortCiteRegEx" : "Cui et al\\.",
      "year" : 2016
    }, {
      "title" : "Gated-attention readers for text comprehension",
      "author" : [ "Bhuwan Dhingra", "Hanxiao Liu", "William W Cohen", "Ruslan Salakhutdinov." ],
      "venue" : "arXiv preprint arXiv:1606.01549 .",
      "citeRegEx" : "Dhingra et al\\.,? 2016",
      "shortCiteRegEx" : "Dhingra et al\\.",
      "year" : 2016
    }, {
      "title" : "Teaching machines to read and comprehend",
      "author" : [ "Karl Moritz Hermann", "Tomas Kocisky", "Edward Grefenstette", "Lasse Espeholt", "Will Kay", "Mustafa Suleyman", "Phil Blunsom." ],
      "venue" : "Advances in Neural Information Processing Systems. pages 1684–",
      "citeRegEx" : "Hermann et al\\.,? 2015",
      "shortCiteRegEx" : "Hermann et al\\.",
      "year" : 2015
    }, {
      "title" : "The goldilocks principle: Reading children’s books with explicit memory representations",
      "author" : [ "Felix Hill", "Antoine Bordes", "Sumit Chopra", "Jason Weston." ],
      "venue" : "arXiv preprint arXiv:1511.02301 .",
      "citeRegEx" : "Hill et al\\.,? 2015",
      "shortCiteRegEx" : "Hill et al\\.",
      "year" : 2015
    }, {
      "title" : "An efficient method for determining bilingual word classes",
      "author" : [ "Franz Josef Och." ],
      "venue" : "Ninth Conference of the European Chapter of the Association for Computational Linguistics. http://aclweb.org/anthology/E99-1010.",
      "citeRegEx" : "Och.,? 1999",
      "shortCiteRegEx" : "Och.",
      "year" : 1999
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "Diederik Kingma", "Jimmy Ba." ],
      "venue" : "arXiv preprint arXiv:1412.6980 .",
      "citeRegEx" : "Kingma and Ba.,? 2014",
      "shortCiteRegEx" : "Kingma and Ba.",
      "year" : 2014
    }, {
      "title" : "Generating and exploiting large-scale pseudo training data for zero pronoun resolution",
      "author" : [ "Ting Liu", "Yiming Cui", "Qingyu Yin", "Shijin Wang", "Weinan Zhang", "Guoping Hu." ],
      "venue" : "arXiv preprint arXiv:1606.01603 .",
      "citeRegEx" : "Liu et al\\.,? 2016",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2016
    }, {
      "title" : "On the difficulty of training recurrent neural networks",
      "author" : [ "Razvan Pascanu", "Tomas Mikolov", "Yoshua Bengio." ],
      "venue" : "ICML (3) 28:1310–1318.",
      "citeRegEx" : "Pascanu et al\\.,? 2013",
      "shortCiteRegEx" : "Pascanu et al\\.",
      "year" : 2013
    }, {
      "title" : "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks",
      "author" : [ "Andrew M Saxe", "James L McClelland", "Surya Ganguli." ],
      "venue" : "arXiv preprint arXiv:1312.6120 .",
      "citeRegEx" : "Saxe et al\\.,? 2013",
      "shortCiteRegEx" : "Saxe et al\\.",
      "year" : 2013
    }, {
      "title" : "Iterative alternating neural attention for machine reading",
      "author" : [ "Alessandro Sordoni", "Phillip Bachman", "Yoshua Bengio." ],
      "venue" : "arXiv preprint arXiv:1606.02245 .",
      "citeRegEx" : "Sordoni et al\\.,? 2016",
      "shortCiteRegEx" : "Sordoni et al\\.",
      "year" : 2016
    }, {
      "title" : "Dropout: a simple way to prevent neural networks from overfitting",
      "author" : [ "Nitish Srivastava", "Geoffrey E Hinton", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan Salakhutdinov." ],
      "venue" : "Journal of Machine Learning Research 15(1):1929–1958.",
      "citeRegEx" : "Srivastava et al\\.,? 2014",
      "shortCiteRegEx" : "Srivastava et al\\.",
      "year" : 2014
    }, {
      "title" : "Srilm — an extensible language modeling toolkit",
      "author" : [ "Andreas Stolcke." ],
      "venue" : "Proceedings of the 7th International Conference on Spoken Language Processing (ICSLP 2002). pages 901–904.",
      "citeRegEx" : "Stolcke.,? 2002",
      "shortCiteRegEx" : "Stolcke.",
      "year" : 2002
    }, {
      "title" : "Cloze procedure: a new tool for measuring readability",
      "author" : [ "Wilson L Taylor." ],
      "venue" : "Journalism and Mass Communication Quarterly 30(4):415.",
      "citeRegEx" : "Taylor.,? 1953",
      "shortCiteRegEx" : "Taylor.",
      "year" : 1953
    }, {
      "title" : "Theano: A Python framework for fast computation of mathematical expressions",
      "author" : [ "Theano Development Team." ],
      "venue" : "arXiv e-prints abs/1605.02688. http://arxiv.org/abs/1605.02688.",
      "citeRegEx" : "Team.,? 2016",
      "shortCiteRegEx" : "Team.",
      "year" : 2016
    }, {
      "title" : "Natural language comprehension with the epireader",
      "author" : [ "Adam Trischler", "Zheng Ye", "Xingdi Yuan", "Kaheer Suleman." ],
      "venue" : "arXiv preprint arXiv:1606.02270 .",
      "citeRegEx" : "Trischler et al\\.,? 2016",
      "shortCiteRegEx" : "Trischler et al\\.",
      "year" : 2016
    }, {
      "title" : "Pointer networks",
      "author" : [ "Oriol Vinyals", "Meire Fortunato", "Navdeep Jaitly." ],
      "venue" : "Advances in Neural Information Processing Systems. pages 2692–2700.",
      "citeRegEx" : "Vinyals et al\\.,? 2015",
      "shortCiteRegEx" : "Vinyals et al\\.",
      "year" : 2015
    } ],
    "referenceMentions" : [ {
      "referenceID" : 17,
      "context" : "The cloze-style query (Taylor, 1953) is a problem that to fill in an appropriate word in the given sentences while taking the context information into account.",
      "startOffset" : 22,
      "endOffset" : 36
    }, {
      "referenceID" : 5,
      "context" : "Following these datasets, a vast variety of neural network approaches have been proposed (Kadlec et al., 2016; Cui et al., 2016; Chen et al., 2016; Dhingra et al., 2016; Sordoni et al., 2016; Trischler et al., 2016), and most of them stem from the attention-based neural network (Bahdanau et al.",
      "startOffset" : 89,
      "endOffset" : 215
    }, {
      "referenceID" : 1,
      "context" : "Following these datasets, a vast variety of neural network approaches have been proposed (Kadlec et al., 2016; Cui et al., 2016; Chen et al., 2016; Dhingra et al., 2016; Sordoni et al., 2016; Trischler et al., 2016), and most of them stem from the attention-based neural network (Bahdanau et al.",
      "startOffset" : 89,
      "endOffset" : 215
    }, {
      "referenceID" : 6,
      "context" : "Following these datasets, a vast variety of neural network approaches have been proposed (Kadlec et al., 2016; Cui et al., 2016; Chen et al., 2016; Dhingra et al., 2016; Sordoni et al., 2016; Trischler et al., 2016), and most of them stem from the attention-based neural network (Bahdanau et al.",
      "startOffset" : 89,
      "endOffset" : 215
    }, {
      "referenceID" : 14,
      "context" : "Following these datasets, a vast variety of neural network approaches have been proposed (Kadlec et al., 2016; Cui et al., 2016; Chen et al., 2016; Dhingra et al., 2016; Sordoni et al., 2016; Trischler et al., 2016), and most of them stem from the attention-based neural network (Bahdanau et al.",
      "startOffset" : 89,
      "endOffset" : 215
    }, {
      "referenceID" : 19,
      "context" : "Following these datasets, a vast variety of neural network approaches have been proposed (Kadlec et al., 2016; Cui et al., 2016; Chen et al., 2016; Dhingra et al., 2016; Sordoni et al., 2016; Trischler et al., 2016), and most of them stem from the attention-based neural network (Bahdanau et al.",
      "startOffset" : 89,
      "endOffset" : 215
    }, {
      "referenceID" : 0,
      "context" : ", 2016), and most of them stem from the attention-based neural network (Bahdanau et al., 2014), which has become a stereotype in most of the NLP tasks and is wellknown by its capability of learning the “importance” distribution over the inputs.",
      "startOffset" : 71,
      "endOffset" : 94
    }, {
      "referenceID" : 5,
      "context" : "Unlike the previous works, that are using heuristic merging functions (Cui et al., 2016), or setting various pre-defined non-trainable terms (Trischler et al.",
      "startOffset" : 70,
      "endOffset" : 88
    }, {
      "referenceID" : 19,
      "context" : ", 2016), or setting various pre-defined non-trainable terms (Trischler et al., 2016), our model could automatically generate an “attended attention” over various document-level attentions, and make a mutual look not only from query-to-document but also document-to-query, which will benefit from the interactive information.",
      "startOffset" : 60,
      "endOffset" : 84
    }, {
      "referenceID" : 3,
      "context" : "To create large-scale training data for neural networks, Hermann et al. (2015) released the CNN/Daily Mail news dataset, where the document is formed by the news articles and the queries are extracted from the summary of the news.",
      "startOffset" : 57,
      "endOffset" : 79
    }, {
      "referenceID" : 3,
      "context" : "To create large-scale training data for neural networks, Hermann et al. (2015) released the CNN/Daily Mail news dataset, where the document is formed by the news articles and the queries are extracted from the summary of the news. Hill et al. (2015) released the Children’s Book Test dataset afterwards, where the training samples are generated from consecutive 20 sentences from books, and the query is formed by 21st sentence.",
      "startOffset" : 57,
      "endOffset" : 250
    }, {
      "referenceID" : 7,
      "context" : "1 Hermann et al. (2015) have firstly published two datasets: CNN and Daily Mail news data.",
      "startOffset" : 2,
      "endOffset" : 24
    }, {
      "referenceID" : 1,
      "context" : "The following research on these datasets showed that the entity word anonymization is not that effective than expected (Chen et al., 2016).",
      "startOffset" : 119,
      "endOffset" : 138
    }, {
      "referenceID" : 1,
      "context" : "The following research on these datasets showed that the entity word anonymization is not that effective than expected (Chen et al., 2016). Children’s Book Test. 2 There was also a dataset called the Children’s Book Test (CBTest) released by Hill et al. (2015), which is built on the children’s book story through Project Gutenberg.",
      "startOffset" : 120,
      "endOffset" : 261
    }, {
      "referenceID" : 5,
      "context" : "As previous studies by Cui et al. (2016) showed that the further investigation",
      "startOffset" : 23,
      "endOffset" : 41
    }, {
      "referenceID" : 3,
      "context" : "After making a trade-off between model performance and training complexity, we choose the Gated Recurrent Unit (GRU) (Cho et al., 2014) as recurrent unit implementation.",
      "startOffset" : 117,
      "endOffset" : 135
    }, {
      "referenceID" : 2,
      "context" : "To tune the weights among these features, we adopt the K-best MIRA algorithm (Cherry and Foster, 2012) to automatically optimize the weights on the validation set, which is widely used in statistical machine translation tuning procedure.",
      "startOffset" : 77,
      "endOffset" : 102
    }, {
      "referenceID" : 15,
      "context" : "1 (Srivastava et al., 2014).",
      "startOffset" : 2,
      "endOffset" : 27
    }, {
      "referenceID" : 13,
      "context" : "• Hidden Layer: Internal weights of GRUs are initialized with random orthogonal matrices (Saxe et al., 2013).",
      "startOffset" : 89,
      "endOffset" : 108
    }, {
      "referenceID" : 10,
      "context" : "• Optimization: We adopted ADAM optimizer for weight updating (Kingma and Ba, 2014), with an initial learning rate of 0.",
      "startOffset" : 62,
      "endOffset" : 83
    }, {
      "referenceID" : 12,
      "context" : "As the GRU units still suffer from the gradient exploding issues, we set the gradient clipping threshold to 5 (Pascanu et al., 2013).",
      "startOffset" : 110,
      "endOffset" : 132
    }, {
      "referenceID" : 7,
      "context" : "Deep LSTM Reader (Hermann et al., 2015) 55.",
      "startOffset" : 17,
      "endOffset" : 39
    }, {
      "referenceID" : 7,
      "context" : "0 - - - Attentive Reader (Hermann et al., 2015) 61.",
      "startOffset" : 25,
      "endOffset" : 47
    }, {
      "referenceID" : 8,
      "context" : "0 - - - Human (context+query) (Hill et al., 2015) - - - 81.",
      "startOffset" : 30,
      "endOffset" : 49
    }, {
      "referenceID" : 8,
      "context" : ") (Hill et al., 2015) 63.",
      "startOffset" : 2,
      "endOffset" : 21
    }, {
      "referenceID" : 5,
      "context" : "4 CAS Reader (Cui et al., 2016) 68.",
      "startOffset" : 13,
      "endOffset" : 31
    }, {
      "referenceID" : 1,
      "context" : "7 Stanford AR (Chen et al., 2016) 72.",
      "startOffset" : 14,
      "endOffset" : 33
    }, {
      "referenceID" : 6,
      "context" : "4 - - - GA Reader (Dhingra et al., 2016) 73.",
      "startOffset" : 18,
      "endOffset" : 40
    }, {
      "referenceID" : 14,
      "context" : "9 Iterative Attention (Sordoni et al., 2016) 72.",
      "startOffset" : 22,
      "endOffset" : 44
    }, {
      "referenceID" : 19,
      "context" : "2 EpiReader (Trischler et al., 2016) 73.",
      "startOffset" : 12,
      "endOffset" : 36
    }, {
      "referenceID" : 16,
      "context" : "In re-ranking step, all language models are 8-gram, and trained by SRILM toolkit (Stolcke, 2002).",
      "startOffset" : 81,
      "endOffset" : 96
    }, {
      "referenceID" : 4,
      "context" : "Implementation is done with Theano (Theano Development Team, 2016) and Keras (Chollet, 2015), and all models are trained on Tesla K40 GPU.",
      "startOffset" : 77,
      "endOffset" : 92
    }, {
      "referenceID" : 7,
      "context" : "Our experiments are carried out on public datasets: CNN news datasets (Hermann et al., 2015) and CBTest NE/CN datasets (Hill et al.",
      "startOffset" : 70,
      "endOffset" : 92
    }, {
      "referenceID" : 8,
      "context" : ", 2015) and CBTest NE/CN datasets (Hill et al., 2015).",
      "startOffset" : 34,
      "endOffset" : 53
    }, {
      "referenceID" : 20,
      "context" : "(2016) proposed a simple model that directly pick the answer from the document, which is motivated by the Pointer Network (Vinyals et al., 2015).",
      "startOffset" : 122,
      "endOffset" : 144
    }, {
      "referenceID" : 14,
      "context" : "(2016) , where the latter model is widely applied to many follow-up works (Sordoni et al., 2016; Trischler et al., 2016; Cui et al., 2016).",
      "startOffset" : 74,
      "endOffset" : 138
    }, {
      "referenceID" : 19,
      "context" : "(2016) , where the latter model is widely applied to many follow-up works (Sordoni et al., 2016; Trischler et al., 2016; Cui et al., 2016).",
      "startOffset" : 74,
      "endOffset" : 138
    }, {
      "referenceID" : 5,
      "context" : "(2016) , where the latter model is widely applied to many follow-up works (Sordoni et al., 2016; Trischler et al., 2016; Cui et al., 2016).",
      "startOffset" : 74,
      "endOffset" : 138
    }, {
      "referenceID" : 5,
      "context" : "Unlike the CAS Reader (Cui et al., 2016), we do not assume any heuristics to our model, such as using merge functions: sum, avg etc.",
      "startOffset" : 22,
      "endOffset" : 40
    }, {
      "referenceID" : 6,
      "context" : "Hermann et al. (2015) have proposed a method for obtaining large quantities of 〈D,Q,A〉 triples through news articles and its summary.",
      "startOffset" : 0,
      "endOffset" : 22
    }, {
      "referenceID" : 6,
      "context" : "Hermann et al. (2015) have proposed a method for obtaining large quantities of 〈D,Q,A〉 triples through news articles and its summary. Along with the release of cloze-style reading comprehension dataset, they also proposed an attention-based neural network to handle this task. Experimental results showed that the proposed neural network is effective than traditional baselines. Hill et al. (2015) released another dataset, which stems from the children’s books.",
      "startOffset" : 0,
      "endOffset" : 398
    }, {
      "referenceID" : 6,
      "context" : "Hermann et al. (2015) have proposed a method for obtaining large quantities of 〈D,Q,A〉 triples through news articles and its summary. Along with the release of cloze-style reading comprehension dataset, they also proposed an attention-based neural network to handle this task. Experimental results showed that the proposed neural network is effective than traditional baselines. Hill et al. (2015) released another dataset, which stems from the children’s books. Different from Hermann et al. (2015)’s work, the document and query are all generated from the raw story without any summary, which is much more general than previous work.",
      "startOffset" : 0,
      "endOffset" : 500
    }, {
      "referenceID" : 6,
      "context" : "Hermann et al. (2015) have proposed a method for obtaining large quantities of 〈D,Q,A〉 triples through news articles and its summary. Along with the release of cloze-style reading comprehension dataset, they also proposed an attention-based neural network to handle this task. Experimental results showed that the proposed neural network is effective than traditional baselines. Hill et al. (2015) released another dataset, which stems from the children’s books. Different from Hermann et al. (2015)’s work, the document and query are all generated from the raw story without any summary, which is much more general than previous work. To handle the reading comprehension task, they proposed a window-based memory network, and self-supervision heuristics is also applied to learn hard-attention. Unlike previous works, that using blended representations of document and query to estimate the answer, Kadlec et al. (2016) proposed a simple model that directly pick the answer from the document, which is motivated by the Pointer Network (Vinyals et al.",
      "startOffset" : 0,
      "endOffset" : 921
    }, {
      "referenceID" : 6,
      "context" : "Hermann et al. (2015) have proposed a method for obtaining large quantities of 〈D,Q,A〉 triples through news articles and its summary. Along with the release of cloze-style reading comprehension dataset, they also proposed an attention-based neural network to handle this task. Experimental results showed that the proposed neural network is effective than traditional baselines. Hill et al. (2015) released another dataset, which stems from the children’s books. Different from Hermann et al. (2015)’s work, the document and query are all generated from the raw story without any summary, which is much more general than previous work. To handle the reading comprehension task, they proposed a window-based memory network, and self-supervision heuristics is also applied to learn hard-attention. Unlike previous works, that using blended representations of document and query to estimate the answer, Kadlec et al. (2016) proposed a simple model that directly pick the answer from the document, which is motivated by the Pointer Network (Vinyals et al., 2015). A restriction of this model is that the answer should be a single word and appear in the document. Results on various public datasets showed that the proposed model is effective than previous works. Liu et al. (2016) proposed to exploit reading comprehension models to other tasks.",
      "startOffset" : 0,
      "endOffset" : 1277
    }, {
      "referenceID" : 5,
      "context" : "Our work is primarily inspired by Cui et al. (2016) and Kadlec et al.",
      "startOffset" : 34,
      "endOffset" : 52
    }, {
      "referenceID" : 5,
      "context" : "Our work is primarily inspired by Cui et al. (2016) and Kadlec et al. (2016) , where the latter model is widely applied to many follow-up works (Sordoni et al.",
      "startOffset" : 34,
      "endOffset" : 77
    } ],
    "year" : 2017,
    "abstractText" : "Cloze-style reading comprehension is a representative problem in mining relationship between document and query. In this paper, we present a simple but novel model called attention-over-attention reader for better solving cloze-style reading comprehension task. Our model aims to place another attention mechanism over the document-level attention and induces “attended attention” for final answer predictions. One advantage of our model is that it is simpler than related works while giving excellent performance. We also propose an N-best re-ranking strategy to double check the validity of the candidates and further improve the performance. Experimental results show that the proposed methods significantly outperform various state-of-the-art systems by a large margin in public datasets, such as CNN and Children’s Book Test.",
    "creator" : "LaTeX with hyperref package"
  }
}