{
  "name" : "1203.3502.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "The Cost of Troubleshooting Cost Clusters with Inside Information",
    "authors" : [ "Thorsten J. Ottosen", "Finn V. Jensen" ],
    "emails" : [ "nesotto@cs.aau.dk,", "fvj@cs.aau.dk" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Decision theoretical troubleshooting is about minimizing the expected cost of solving a certain problem like repairing a complicated man-made device. In this paper we consider situations where you have to take apart some of the device to get access to certain clusters and actions. Specifically, we investigate troubleshooting with independent actions in a tree of clusters where actions inside a cluster cannot be performed before the cluster is opened. The problem is non-trivial because there is a cost associated with opening and closing a cluster. Troubleshooting with independent actions and no clusters can be solved in O(n · lg n) time (n being the number of actions) by the well-known ”P-over-C” algorithm due to Kadane and Simon, but an efficient and optimal algorithm for a tree cluster model has not yet been found. In this paper we describe a ”bottom-up P-over-C” O(n · lg n) time algorithm and show that it is optimal when the clusters do not need to be closed to test whether the actions solved the problem."
    }, {
      "heading" : "1 INTRODUCTION",
      "text" : "In decision theoretical troubleshooting we are faced with a problem that needs to be solved by applying solution actions and by posing questions that gather information about the problem. The premise is that after each action we can cost free observe whether the problem was solved. The domain is assumed to be uncertain, that is, solution actions may be imperfect and information might be non-conclusive. Given a model that describes the uncertainty and the cost of actions and questions, the goal is to compute a strategy for solving the problem with the lowest expected cost.\nIf the model has the following assumptions:\n(a) the problem is due to a single fault,\n(b) different actions address different faults,\n(c) costs do not depend on the previous history, and\n(d) there are no questions,\nthen the problem is solvable in O(n · lg n) time where n is the number of actions. This algorithm is the wellknown ”P-over-C” algorithm by (Kadane and Simon, 1977) which was first brought into a troubleshooting context by (Kalagnanam and Henrion, 1990). Furthermore, if any of the above assumptions are relaxed without restrictions, the problem becomes NP-hard (Vomlelová, 2003). If assumption (a) is replaced with an assumption about multiple independent faults, an O(n·lg n) P-over-C-like algorithm also exists (Srinivas, 1995). Troubleshooting without assumption (b) can also be somewhat simplified due to the dependency set algorithm of (Koca and Bilgic, 2004).\n(Langseth and Jensen, 2001) proposed to relax assumption (c) slightly by considering a model where the actions can be partitioned into a flat set of socalled cost clusters (see Figure 1). The idea is that in order to access an action in a bottom level cluster Ki, you need to pay an additional cost Coi and to close the cluster you have to pay an additional cost Cci . Thereby it is possible to model e.g. the repair of complex manmade devices where you need to take apart some of the equipment to perform certain actions. If we can determine whether an action has solved the problem without assembling the cluster first, Langseth and Jensen said that the cluster has inside information; otherwise the cluster is without inside information. They furthermore describe heuristics for both problems. In this paper we present a proof of correctness of their algorithm for the problem with inside information. We furthermore extend the model to a tree of clusters and give an O(n · lg n) time algorithm that is proved optimal. (Warnquist et al., 2008) describe a slightly more general cost cluster framework, but they do not address the issue of finding an efficient algorithm."
    }, {
      "heading" : "2 PRELIMINARIES",
      "text" : "In this paper we shall examine troubleshooting problems where the following model parameters are given. F = {f1, . . . , fm} is a set of faults describing the possible causes to the problem. For each fault f ∈ F , we have a probability P(f) describing how likely it is that f is present when troubleshooting begins. A = {α1, . . . , αn} is a set of actions that can potentially solve the problem. Each action α has two possible outcomes, namely ”α = yes” (the problem was fixed) and ”α = no” (the action failed to fix the problem). Each action α has a positive cost Cα describing the resources required to perform the action. Finally, each action has an associated success probability P(α = yes | f), the probability of solving the problem by performing the action when f is present.\nThe set of actions A can be partitioned into `+1 clusters K,K1, . . . ,K` where cluster K is the top-level cluster and the remaining are bottom-level clusters. The cost of opening a cluster Ki is Coi and the cost of closing it again is Cci . We define CKi = C o i +C c i . An action α belongs to cluster K(α).\nDuring the course of troubleshooting we gather evidence εi meaning that the first i actions failed to solve the problem, and we have by assumption P ( ε0 )\n= 1 because the device is faulty. We also write εx:y as shorthand for ⋃y i=x{αi = no}. FA(ε) is the set of free actions consisting of all actions (excluding those already performed) from open clusters given evidence ε. CA(ε) is the set of confined actions consisting of all actions from closed clusters. Note that we have FA(ε) ∪ CA(ε) ⊆ A and FA(ε) ∩ CA(ε) = ∅ for all evidence ε. By performing an action α from CA(ε) we pay the cost CK(α) because at this point we are certain that we must both open and close the cluster. In that case α is called an opening action (for K(α)), and all remaining actions of K(α) are released by removing them from CA(ε) and adding them to FA(ε). The\nconditional cost Cα(ε) of an action α given evidence ε is given by Cα + CK(α) if α ∈ CA(ε) and by Cα if α ∈ FA(ε).\nThroughout this paper we uphold the following simplifying assumptions about the model:\n1 (The single fault assumption). Initially the problem is known to exist and it is due to the presence of a single fault from F .\n2 (The idempotent action assumption). Repeating a failed action will not fix the problem.\n3 (The carefulness assumption). By performing an action or testing the system, we never introduce new faults.\n4 (The independent actions assumption). Different actions address different faults.\n5 (The costless system test assumption). Checking whether the problem still exists after performing an action can be done at a negligible cost.\n6 (The inside information assumption). All clusters have inside information.\nDue to the single-fault assumption we may compute the repair probability of an action given evidence ε as P(α = yes |ε) = ∑ f∈F P(α = yes | f) · P(f |ε). In a few places we shall abbreviate P(α = yes |ε) with P(α |ε). Due to the independent actions assumption P(α) /P(β) = P(α |ε) /P(β |ε) for all evidence ε not involving α or β. We shall therefore abbreviate the initial repair probability P(α = yes) as Pα .\nA troubleshooting sequence is a sequence of actions s = 〈α1, . . . , αn〉 prescribing the process of repeatedly performing the next action until the problem is fixed or the last action has been performed. We shall write s[k,m] for the subsequence 〈αk, . . . , αm〉 and s(k,m) for the subsequence 〈αk+1, . . . , αm−1〉. The index of an opening action in a troubleshooting sequence s is called an opening index, and the set of all opening indices for s is denoted Z with Z ⊆ {1, . . . , n}, |Z| = `. To measure the quality of a given sequence we use the following definition.\nDefinition 1. Let s = 〈α1, . . . , αn〉 be a troubleshooting sequence. Then the expected cost of repair (ECR) of s is given by\nECR (s) = n∑ i=1 P ( εi−1 ) · Cαi(εi−1) .\nFormally, our optimization problem is to find a troubleshooting sequence with minimal ECR. Without cost clusters, the problem is easily solved due to the theorem below.\nTheorem 1 (Kadane and Simon (1977)). Let s = 〈α1, . . . , αn〉 be a troubleshooting sequences in a model without cost clusters. Then s is optimal if and only if\nPαi Cαi ≥ Pαi Cαi for i ∈ {1, . . . , n− 1} .\nIf costs are not conditional and actions are independent, the lemma below leads directly to the ”P-over-C” algorithm.\nLemma 1 (Jensen et al. (2001)). Let s be a troubleshooting sequence and let αx and αx+1 be two adjacent actions in s. If s is optimal then\nCαx(ε x−1) +\n( 1− P ( αx |εx−1 )) · Cαx+1(εx) ≤\nCαx+1(ε x−1) +( 1− P ( αx+1 |εx−1 )) · Cαx(εx−1, αa+1 = no) .\nWith assumption 1, 3, 4, and 5 we may simplify computations and notation somewhat because of the following result.\nProposition 1. Let s = 〈α1, . . . , αn〉 be a troubleshooting sequence. Then the ECR of s may be computed as\nECR (s) = n∑ i=1 Cαi(ε i−1) · 1− i−1∑ j=1 Pαj  , where 1− ∑i−1 j=1 Pαj = P ( εi−1 ) .\nThis easy computation of the probabilities can be dated back to (Kalagnanam and Henrion, 1990) and (Heckerman et al., 1995).\nThus, due to our assumptions, we may completely ignore F , P(f), and P(α = yes|f) once the repair probabilities have been computed. Therefore, we mainly use Pα in the rest of this paper.\nUsing the set of opening indices Z, we can rewrite the definition of ECR of a sequence s to\nECR (s) = ∑ i=1 Cαi · 1− i−1∑ j=1 Pαj  + ∑ z∈Z CK(αz) · 1− z−1∑ j=1 Pαj\n (1) where we have decomposed the terms into those that rely on the cost of performing actions and those that rely on the cost of opening and closing a cluster. We define the efficiency of an action α given evidence ε as ef(α |ε) = Pα/Cα(ε), and we write ef(α) for the unconditional efficiency Pα/Cα . Finally, the cluster efficiency of an opening action is cef(α) = Pα\nCα+CK(α) .\nLemma 2. Let s = 〈α1, . . . , αn〉 be an optimal troubleshooting sequence with opening indices zi ∈ Z. Then the ` + 1 subsequences s[α1, αz1), s[αzi , αzi+1) ∀i ∈ {1, . . . , ` − 1}, and s[αz` , αn] are ordered with respect to descending efficiency.\nProof. Between opening indices the costs are not conditional, and so we must sort by descending ef(·) to be optimal.\nWe have now established that given the opening index for each cluster, it is a simple task of merging ordered sequences to establish an optimal sequence. The difficult part is to determine the opening indices."
    }, {
      "heading" : "3 THE EXTENDED P-OVER-C ALGORITHM",
      "text" : "The standard ”P-over-C” algorithm works by sorting the actions based on descending efficiency. The extended algorithm works in a similar manner, but it also considers the efficiency of a cluster: if a cluster is more efficient than all remaining actions and clusters, we should perform some actions from that cluster first.\nDefinition 2. The efficiency of a cluster K is defined as\nef(K) = max M⊆K\n∑ α∈M Pα\nCK + ∑ α∈M Cα\nand the largest set M ⊆ K that maximizes the efficiency is called the maximizing set of K. The sequence of actions found by sorting the actions of the maximizing set by descending efficiency is called the maximizing sequence of K.\nIt turns out that it is quite easy to calculate the efficiency of a cluster. The following result is a slightly more informative version of the one from (Langseth and Jensen, 2001):\nLemma 3. Let K be a cluster. Then the maximizing set M can be found by including the most efficient actions of K until ef(K) starts decreasing. Furthermore, all actions α in the maximizing set M have ef(α) ≥ ef(K) and all actions β ∈ K \\ M have ef(β) < ef(K).\nThe algorithm is described in Algorithm 1. If n denotes the total number of actions, we can see that line 2 takes at most O(n · lg n) time. Once the actions have been sorted, line 3-6 takes at most O(n) time. The loop in line 7-20 can be implemented to run in at most O(n · lg(`+ 1)) time by using a priority queue for the most efficient element of A and the most efficient element of each cluster. Thus the algorithm has O(n·lg n) worst case running time. In the next section we prove that the algorithm returns an optimal sequence.\nAlgorithm 1 The extended P-over-C algorithm (Langseth and Jensen, 2001)\n1: function ExtendedPOverC(K,K1, . . . ,K`) 2: Sort actions of K and all Ki by descending ef(·) 3: Calculate ef(Ki) and maximizing sets Mi 4: for all i ∈ {1, . . . , `} 5: Let Kclosed = {Ki | i ∈ {1, . . . , `}} 6: Let A = {α | α ∈ K or α ∈ Ki \\Mi for some i} 7: Let s = 〈〉 8: repeat 9: Let β be the most efficient action in A\n10: or cluster in Kclosed 11: if β is an action then 12: Add action β to s 13: Set A = A \\ {β} 14: else 15: Add all actions of the maximizing set 16: of cluster β to s in order of 17: descending efficiency 18: Set Kclosed = Kclosed \\ {β} 19: end if 20: until Kclosed = ∅ and A = ∅ 21: Return s 22: end function\nExample 1. We consider a model with three clusters, where Kα is the root cluster and Kβ and Kγ are the bottom-level clusters. We have CKβ = 2 and CKγ = 1, and the following model parameters:\nP C ef(·) cluster ef(K) α1 0.14 1 0.14 Kα α2 0.11 1 0.11 Kα β1 0.20 1 0.067 Kβ 0.075 β2 0.10 1 0.033 Kβ γ1 0.25 1 0.125 Kγ 0.15 γ2 0.20 1 0.10 Kγ\nThe maximizing set for Kβ is {β1, β2} and for Kγ it is {γ1, γ2}, and from this the cluster efficiencies have been calculated. Algorithm 1 returns the sequence s = 〈γ1, γ2, α1, α2, , β1, β2〉 which has ECR\nECR (s) = 2+0.75+0.55+0.41+0.30·3+0.10 = 4.71 .\nIf we followed the simple P-over-C algorithm we would get the sequence s2 = 〈α1, γ1, α2, γ2, β1, β2〉 with ECR\nECR ( s2 ) = 1+0.86·2+0.61+0.50+0.30·3+0.10 = 4.83 ."
    }, {
      "heading" : "4 CORRECTNESS OF THE ALGORITHM",
      "text" : "We start with a proof of Lemma 3:\nProof. We shall use the fact that for positive reals we have\na+ b c+ d ⊗ a c ⇔ b d ⊗ a c\nfor any weak order ⊗ (e.g. ≥ and ≤). Let M consist of actions in K such that ef(M) is maximized. Then ef(M) equals∑\nα∈M Pα CK + ∑ α∈M Cα =\n∑ α∈M\\{β} Pα + Pβ\nCK + ∑ α∈M\\{β}Cα + Cβ\n= SP + Pβ SC + Cβ = P C\nwhere β is chosen arbitrarily. Let furthermore γ ∈ K \\M. We shall prove\nPβ Cβ ≥ P C > Pγ Cγ\nwhich implies the theorem. We first prove the leftmost inequality. Because ef(M) is maximal we have\nSP + Pβ SC + Cβ ≥ SP SC which is equivalent to Pβ Cβ ≥ SP SC\nwhich again is equivalent to\nPβ Cβ ≥ SP + Pβ SC + Cβ .\nThe second inequality is proved similarly.\nWhen we look at opening indices we get the following result.\nLemma 4. Let s = 〈. . . , αx, αx+1, . . .〉 be an optimal troubleshooting sequence, and let Z be the opening indices of s. Then\ncef(αx) ≥ ef(αx+1) if x ∈ Z, αx+1 ∈ FA(εx−1) ef(αx) ≥ cef(αx+1) if αx ∈ FA(εx−1), x+ 1 ∈ Z cef(αx) ≥ cef(αx+1) if x ∈ Z, x+ 1 ∈ Z\nProof. Apply Lemma 1 and do some pencil pushing. For example, case 1: x ∈ Z and αx+1 ∈ FA(εx−1). In this case we have\nCαx + CK(αx) + ( 1− P ( αx |εx−1 )) · Cαx+1 ≤\nCαx+1 + ( 1− P ( αx+1 |εx−1 )) · ( Cαx + CK(αx) ) m\nP ( αx+1 |εx−1 ) [ Cαx + CK(αx) ] ≤ P ( αx |εx−1 ) Cαx+1\nm ef(αx+1) ≤ cef(αx)\nbecause P(αx) ≥ P(αx+1) ⇔ P(αx |ε) ≥ P(αx+1 |ε) for independent actions.\nDefinition 3. Let s[x, y] be a subsequence of a troubleshooting sequence s. Then the efficiency of s[x, y] is given by\nef(s[x, y]) = ∑y i=x Pαi∑y\ni=x Cαi(ε i−1)\nDefinition 4. Let s = 〈. . . , αx, . . . , αy, . . .〉 be a troubleshooting sequence. If all actions of the subsequence s[x, y] belong to the same cluster, we say that the subsequence is regular. If furthermore s[x, y] is as long as possible while not breaking regularity, we say that the subsequence is a maximal regular subsequence.\nRemark. Any troubleshooting sequence can be partitioned into a sequence of regular subsequences, and if all the subsequences are maximal, this partition is unique.\nLemma 5. Let s be an optimal troubleshooting sequence, and let s[x, x + k] and s[y, y + `] (with y = x + k + 1) be two adjacent regular subsequences such that K(αx) 6= K(αy) or such that neither x nor y is an opening index. Then\nef(s[x, x+ k]) ≥ ef(s[y, y + `])\nProof. We consider the sequence\ns2 = 〈. . . , αx−1, αy, . . . , αy+`, αx, . . . , αx+k, . . .〉\nwhich is equal to s except that the two regular sequences have been swapped. Since s is optimal we have ECR (s) − ECR ( s2 ) ≤ 0. Because the subsequences are regular and belong to different clusters or do not contain opening indices, the costs are the same in the two sequences in both s and s2. Therefore, we get that the terms of ECR (s)− ECR ( s2 ) equal\nCαx(ε x−1) ·\n[ P ( εx−1 ) − P ( εx−1, εy:y+` )] ...\nCαx+k(ε x+k−1) ·\n[ P ( εx+k−1 ) − P ( εx+k−1, εy:y+` )] Cαy(ε y−1) · [ P ( εy−1 ) − P ( εx−1\n)] ...\nCαy+`(ε y+`−1) ·\n[ P ( εy+`−1 ) − P ( εx−1, εy:y+`−1 )] since the remaining terms cancel out. Now observe that\nP ( εx+i−1 ) − P ( εx+i−1, εy:y+` ) =\n1− x+i−1∑ j=1 Pαj − 1− x+i−1∑ j=1 Pαj − y+∑̀ j=y Pαj  = y+∑̀ j=y Pαj\nand, similarly, P ( εy+i−1 ) − P ( εx−1, εy:y+i−1 ) = 1− y+i−1∑ j=1 Pαj − 1− x−1∑ j=1 Pαj − y+i−1∑ j=y Pαj  = − x+k∑ j=x Pαj\nSo ECR (s)− ECR ( s2 ) ≤ 0 is equivalent to[\nx+k∑ i=x Cαi(ε i−1) ] · y+∑̀ j=y Pαj ≤ y+∑̀ i=y Cαi(ε i−1)  · x+k∑ j=x Pαj\nwhich yields the result.\nLemma 6. There exists an optimal troubleshooting sequence s where for each opening index x ∈ Z, there is a maximal regular subsequence s[x, x+j] (j ≥ 0) that contains the maximizing sequence for cluster K(αx).\nProof. Let s be an optimal troubleshooting sequence, and let x be an opening index. Let s[x, x + j] be a maximal regular subsequence and assume that it does not contain the maximizing set. Then there exists αy ∈ K(αx) with y > x+ j + 1 such that\nef(αy) > ef(s[x, x+ j])\nObserve that the subsequence s[x, y − 1] can be partitioned into m > 1, say, maximal regular subsequences s1, . . . , sm with s1 = s[x, x+ j]. By Lemma 5 we have\nef(αy) > ef(s1) ≥ ef(s2) ≥ · · · ≥ ef(sm) ≥ ef(αy)\nwhere the last inequality follows by the fact that αy is not an opening action (so we avoid ≥ cef(αy)). This situation is clearly impossible. Therefore s[x, x + j] must contain the maximizing set. By Lemma 2, it must also contain a maximizing sequence.\nRemark. In the above proof there is a technicality that we did not consider: there might be equality between the efficiency of an action in the maximizing sequence, the efficiency of the maximizing sequence, and one or more free actions. This problem can always be solved by rearranging the actions, and so for all proofs we shall ignore such details for the sake of clarity.\nFinally, we have the following theorem:\nTheorem 2. Algorithm 1 returns an optimal troubleshooting sequence.\nProof. By Lemma 5 we know that an optimal sequence can be partitioned into a sequence of maximal regular subsequences which is sorted by descending efficiency. If we consider Lemma 6 too, then we know that we should open the clusters in order of highest efficiency and perform at least all actions in their maximizing sequences as computed by Lemma 3. By Lemma 2 we know that the order of actions in the maximizing sequences is the optimal one. By Lemma 5 we also know that all free actions α with ef(α) > ef(K) must be performed before opening the cluster, and all free actions with ef(α) < ef(K) must be performed after opening the cluster and performing all the actions in its maximizing sequence."
    }, {
      "heading" : "5 THE TREE CLUSTER MODEL",
      "text" : "In this section we shall investigate an extension of the flat cluster model where the clusters can be arranged as a tree. We call such a model for a tree cluster model, and an example is given in Figure 2. In the tree cluster model, the ECR does not admit the simple decomposition of Equation 1. The complication is that several clusters might need to be opened before performing an action in a deeply nested cluster. We therefore call troubleshooting sequences in the tree cluster model for tree troubleshooting sequences. Unfortunately, it is easy to construct examples that show that Algorithm 1 will not yield optimal tree troubleshooting sequences. Therefore, we shall present a new algorithm that solves the tree cluster model in O(n · lg n) time.\nFirst we need some additional definitions. The conditional cost Cα(ε) of α ∈ Ki will now depend on how many clusters that have been opened on the path from the root K to Ki. We therefore let AK(Ki |ε) denote the set of ancestor clusters that needs to be opened on the path from the root K to Ki given evidence ε. We then define\nCKi(ε) = ∑\nK∈AK(Ki |ε)\nCK , Cα(ε) = Cα + CK(α)(ε)\nGiven this, Definition 1 is still valid for tree troubleshooting sequences.\nA single action is called an atomic action. A compound action consists of opening a cluster K and a sequence of actions in which each action may be either atomic or compound. Note that we shall usually not distinguish syntactically between atomic and compound actions. Also note that a compound action corresponds to a subsequence where the first action is an opening action, and the efficiency of a compound action is simply defined as the efficiency of the corresponding subsequence. If T is a tree cluster model and K is an arbitrary cluster in T , then the subtree model induced by K, denoted TK , is a new tree cluster model containing exactly the clusters in the subtree rooted at K, and with K as the open root cluster. If the induced subtree model is a flat cluster model, we call it a flat subtree model.\nDefinition 5. Let TK = {K,K1, . . . ,K`} be a flat subtree model. Then the absorbtion of K1, . . . ,K` into K is a new cluster K↑ containing\n1. for each child cluster Ki, a compound action induced by the maximizing sequence for Ki, and\n2. all remaining actions from K,K1,. . . ,K`.\nNote that in K↑ all the actions in a child cluster Ki that are not contained in the newly generated compound action will have a lower efficiency than the compound action for Ki. Definition 6. Let T be a tree cluster model, and let K be any cluster in T . Then TK may be transformed into a single cluster K↑ by repeated absorbtion into the root cluster of flat subtree models. The resulting cluster K↑ is called the model induced by absorbtion into K. Remark. By construction, the compound actions in a model induced by absorbtion into the root cluster K will only contain actions from the subtrees rooted at a child of K.\nWith these definitions we can now present Algorithm 2. The algorithm works in a bottom-up fashion, basically merging leaf clusters into their parents (absorbtion) until the tree is reduced to a single cluster. Then an optimal sequence is constructed by unfolding compound actions when they are most efficient.\nThe algorithm can be made to run in O(n · lg n) time by the following argument. Sort the actions of all clusters in the tree T—this takes at most O(n · lg n) time. During absorbtion, it is important to avoid merging all actions of the child clusters into the parent cluster. Instead, we merge only the compound actions into the parent cluster (takes O(` · lg n) time overall), and create a priority queue holding the most efficient remaining action of each child cluster. When creating a compound action for a parent cluster, we then\nAlgorithm 2 The bottom-up P-over-C algorithm\nfunction BottomUpPOverC(T ) Input: a cluster tree T with root K Compute the model K↑ induced by absorbtion\ninto K (see Definition 6) Let s = 〈〉 while K↑ 6= ∅ do\nLet β be the most efficient action in K↑ if β is an atomic action then\nAdd action β to s else\nAdd all actions of β to s in the order prescribed by β\nend if Set K↑ = K↑ \\ {β}\nend while Return s end function\nuse actions from the priority queue as needed, and update the priority queue whenever an action is taken out. Therefore, creating all the compound actions can never take more than O(n · lg `) time. As the absorbtion process moves towards the root, we are forced to merge priority queues from different subtrees. A simple induction argument can establish that it takes at most O(` · lg `) time to merge all these priority queues.\nIn the following we shall prove that Algorithm 2 computes an optimal tree troubleshooting sequence. The first two lemmas are minor generalizations of previous lemmas, and the proofs are almost identical.\nLemma 7. Lemma 2 generalizes to tree troubleshooting sequences.\nLemma 8. Lemma 5 generalizes to subsequences of actions that consists of (i) only free actions, or (ii) actions from the same subtree.\nNext we shall investigate the special properties of the compound actions generated by the absorbtion process.\nDefinition 7. Let T be a tree cluster model, and let K be any non-leaf cluster in T . A maximizing compound action α̂ for K in T is defined as any most efficient compound action in the model induced by absorbtion into K. Lemma 9. Let T be a tree cluster model, and let K be any non-leaf cluster in T . Let TK be the subtree model induced by K, and let α̂ be a maximizing compound action for K in T . Then\nef(α̂) ≥ ef(β)\nwhere β is any possible compound action in TK not including actions from K.\nProof. We proceed by induction. Basis is a flat cluster model T = {K,K1, . . . ,K`} with compound actions β̂1, . . . , β̂` of K and α̂ = maxi β̂i. Let β be any compound action including actions from clusters in T \\ {K}, and assume that ef(β) > ef(α̂). We shall use the fact\nn min i Pi Ci ≤ ∑n i Pi∑n i Ci ≤ nmax i Pi Ci\n(2)\n(which is also known as Cauchy’s third inequality). Then by Equation 2, β cannot be formed by any combination of the β̂i’s as this would not increase the efficiency. Therefore β must be formed by either a strict subset or a strict superset of one of the β̂i’s. If β is a subset of any β̂i, then the maximality of β̂i leads to a contradiction. If β is a superset of any β̂i, then it will include subsets of actions from a set of clusters with subscripts I ⊆ {1, . . . , `}. Let us denote the subsets from each Ki as βi. We then have\nef(β) = ∑ i∈I Pβi∑ i∈I Cβi ≤ max i∈I Pβi Cβi ≤ max i∈{1,...,`} Pβ̂i Cβ̂i = ef(α̂)\nwhere the first inequality follows by Equation 2, the second follows by the definition of compound actions formed during absorbtion, and the last equality is by definition of a maximizing compound action. Since the sets βi were chosen arbitrarily, we get a contradiction. Hence in all cases ef(α̂) ≥ ef(β).\nInduction step: we assume the Lemma is true for all children Ki, . . . ,K` of an arbitrary cluster K where the children have maximizing compound actions β̂1, . . . , β̂`. A similar argument as above then shows that the lemma is true for K as well.\nLemma 10. Let T be a tree cluster model with root cluster K. Then there exists an optimal tree troubleshooting sequence s that contains (as subsequences) all the compound actions of the model induced by absorbtion into K. Furthermore, the compound actions in s are ordered by descending efficiency.\nProof. Let s = 〈α1, . . . , αx, . . . , αx+k, . . .〉 be an optimal tree troubleshooting sequence and let αx be an opening action, and let s[x, x + k], k ≥ x be the sequence of maximal length of actions from the same subtree. Let furthermore s[x, x+ k] be the first subsequence that contradicts the lemma, that is, s[x, x+ k] does not contain the compound action α̂ for the cluster K(αx). Then there exists an atomic action αy ∈ α̂ (with y > x + k + 1) such that αy 6∈ s[x, x + k]. We then have\nef(αy) > ef(α̂) > ef(s[x, x+ k])\nbecause all atomic actions in a compound action are more efficient than the compound action itself, and because α̂ is the most efficient compound action in the\nsubtree rooted at K(αx) (Lemma 9). We can then partition the actions between αx+k and αy into m > 1, say, subsequences (of maximal length) s1, . . . , sm. If one (or more) of these subsequence is more efficient than αy, we immediately get a contradiction to optimality of s because such a subsequence can be moved before s[x, x + k] (Lemma 8). So we can assume that all the m subsequences are less efficient than αy. Then by successive application of Lemma 8 we can decrease the ECR by moving αy to position x + k + 1. However, this again contradicts that s was optimal. Hence s[x, x+ k] must contain α̂.\nBy Lemma 8 it follows that the order of the compound actions must be by descending efficiency.\nTheorem 3. Algorithm 5 returns an optimal troubleshooting sequence.\nProof. By Lemma 10 we only need to establish the order of the free actions between compound actions. By Lemma 8 it follows that any compound action is preceeded by more efficient free actions and followed by less efficient free actions."
    }, {
      "heading" : "6 CONCLUSION",
      "text" : "We have presented an algorithm, which in O(n · lg n) time (n being the number of actions) provides an optimal troubleshooting sequence for scenarios where the cost clusters form a tree and have inside information. This is a useful result on its own, but there is more to it.\nWhen evaluating algorithms for troubleshooting, you must distinguish between off-line and on-line activity. If your task is off-line, the time complexity of your algorithm may not be particularly important as long as the result can be stored easily (like for example an optimal action sequence). However, if the decision support system is flexible, it must allow the user to interact with the recommendations and have the system calculate an optimal next action based on alternative information.\nFurthermore, for many scenarios you will request online calculation of an optimal sequence; for example when the model includes questions and tests. For this kind of scenario, a direct representation of an optimal strategy may require too much space. Therefore, a myopic question heuristic usually relies on optimal sequences of actions calculated on-line.\nFinally, our results imply a major improvement for offline methods like AO∗ because the search tree can now be extensively pruned. This is because all subtrees that consist entirely of actions can be replaced with a single sequence of actions."
    }, {
      "heading" : "7 ACKNOWLEDGEMENTS",
      "text" : "We would like to thank the three anonymous reviewers for their excellent feedback. Thanks also go to Sven Skyum for help with Lemma 3."
    } ],
    "references" : [ {
      "title" : "Decision-theoretic troubleshooting",
      "author" : [ "D. Heckerman", "J.S. Breese", "K. Rommelse" ],
      "venue" : "Communications of the ACM,",
      "citeRegEx" : "Heckerman et al\\.,? \\Q1995\\E",
      "shortCiteRegEx" : "Heckerman et al\\.",
      "year" : 1995
    }, {
      "title" : "The SACSO methodology for troubleshooting complex systems",
      "author" : [ "F.V. Jensen", "U. Kjærulff", "B. Kristiansen", "C. Skaanning", "J. Vomlel", "M. Vomlelová" ],
      "venue" : "Artificial Intelligence for Engineering Design, Analysis and Manufacturing,",
      "citeRegEx" : "Jensen et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Jensen et al\\.",
      "year" : 2001
    }, {
      "title" : "Optimal strategies for a class of constrained sequential problems",
      "author" : [ "J. Kadane", "H. Simon" ],
      "venue" : "The Annals of Statistics,",
      "citeRegEx" : "Kadane and Simon.,? \\Q1977\\E",
      "shortCiteRegEx" : "Kadane and Simon.",
      "year" : 1977
    }, {
      "title" : "A comparison of decision analysis and expert rules for sequential diagnosis",
      "author" : [ "J. Kalagnanam", "M. Henrion" ],
      "venue" : "In UAI ’88: Proceedings of the Fourth Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "Kalagnanam and Henrion.,? \\Q1990\\E",
      "shortCiteRegEx" : "Kalagnanam and Henrion.",
      "year" : 1990
    }, {
      "title" : "A troubleshooting approach with dependent actions",
      "author" : [ "E. Koca", "T. Bilgic" ],
      "venue" : "ECAI 2004: 16th European Conference on Artificial Intelligence,",
      "citeRegEx" : "Koca and Bilgic.,? \\Q2004\\E",
      "shortCiteRegEx" : "Koca and Bilgic.",
      "year" : 2004
    }, {
      "title" : "Heuristics for two extensions of basic troubleshooting",
      "author" : [ "H. Langseth", "F.V. Jensen" ],
      "venue" : "In Proceedings of the Seventh Scandinavian Conference on Artificial Intelligence,",
      "citeRegEx" : "Langseth and Jensen.,? \\Q2001\\E",
      "shortCiteRegEx" : "Langseth and Jensen.",
      "year" : 2001
    }, {
      "title" : "Complexity of decision-theoretic troubleshooting",
      "author" : [ "M. Vomlelová" ],
      "venue" : "Int. J. Intell. Syst.,",
      "citeRegEx" : "Vomlelová.,? \\Q2003\\E",
      "shortCiteRegEx" : "Vomlelová.",
      "year" : 2003
    }, {
      "title" : "Troubleshooting when action costs are dependent with application to a truck engine",
      "author" : [ "H. Warnquist", "M. Nyberg", "P. Säby" ],
      "venue" : "In Proceeding of the Tenth Scandinavian Conference on Artificial Intelligence,",
      "citeRegEx" : "Warnquist et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Warnquist et al\\.",
      "year" : 2008
    } ],
    "referenceMentions" : [ {
      "referenceID" : 2,
      "context" : "This algorithm is the wellknown ”P-over-C” algorithm by (Kadane and Simon, 1977) which was first brought into a troubleshooting context by (Kalagnanam and Henrion, 1990).",
      "startOffset" : 56,
      "endOffset" : 80
    }, {
      "referenceID" : 3,
      "context" : "This algorithm is the wellknown ”P-over-C” algorithm by (Kadane and Simon, 1977) which was first brought into a troubleshooting context by (Kalagnanam and Henrion, 1990).",
      "startOffset" : 139,
      "endOffset" : 169
    }, {
      "referenceID" : 6,
      "context" : "Furthermore, if any of the above assumptions are relaxed without restrictions, the problem becomes NP-hard (Vomlelová, 2003).",
      "startOffset" : 107,
      "endOffset" : 124
    }, {
      "referenceID" : 4,
      "context" : "Troubleshooting without assumption (b) can also be somewhat simplified due to the dependency set algorithm of (Koca and Bilgic, 2004).",
      "startOffset" : 110,
      "endOffset" : 133
    }, {
      "referenceID" : 5,
      "context" : "(Langseth and Jensen, 2001) proposed to relax assumption (c) slightly by considering a model where the actions can be partitioned into a flat set of socalled cost clusters (see Figure 1).",
      "startOffset" : 0,
      "endOffset" : 27
    }, {
      "referenceID" : 7,
      "context" : "(Warnquist et al., 2008) describe a slightly more general cost cluster framework, but they do not address the issue of finding an efficient algorithm.",
      "startOffset" : 0,
      "endOffset" : 24
    }, {
      "referenceID" : 2,
      "context" : "Theorem 1 (Kadane and Simon (1977)).",
      "startOffset" : 11,
      "endOffset" : 35
    }, {
      "referenceID" : 1,
      "context" : "Lemma 1 (Jensen et al. (2001)).",
      "startOffset" : 9,
      "endOffset" : 30
    }, {
      "referenceID" : 3,
      "context" : "This easy computation of the probabilities can be dated back to (Kalagnanam and Henrion, 1990) and (Heckerman et al.",
      "startOffset" : 64,
      "endOffset" : 94
    }, {
      "referenceID" : 0,
      "context" : "This easy computation of the probabilities can be dated back to (Kalagnanam and Henrion, 1990) and (Heckerman et al., 1995).",
      "startOffset" : 99,
      "endOffset" : 123
    }, {
      "referenceID" : 5,
      "context" : "The following result is a slightly more informative version of the one from (Langseth and Jensen, 2001): Lemma 3.",
      "startOffset" : 76,
      "endOffset" : 103
    }, {
      "referenceID" : 5,
      "context" : "Algorithm 1 The extended P-over-C algorithm (Langseth and Jensen, 2001)",
      "startOffset" : 44,
      "endOffset" : 71
    } ],
    "year" : 2010,
    "abstractText" : "Decision theoretical troubleshooting is about minimizing the expected cost of solving a certain problem like repairing a complicated man-made device. In this paper we consider situations where you have to take apart some of the device to get access to certain clusters and actions. Specifically, we investigate troubleshooting with independent actions in a tree of clusters where actions inside a cluster cannot be performed before the cluster is opened. The problem is non-trivial because there is a cost associated with opening and closing a cluster. Troubleshooting with independent actions and no clusters can be solved in O(n · lg n) time (n being the number of actions) by the well-known ”P-over-C” algorithm due to Kadane and Simon, but an efficient and optimal algorithm for a tree cluster model has not yet been found. In this paper we describe a ”bottom-up P-over-C” O(n · lg n) time algorithm and show that it is optimal when the clusters do not need to be closed to test whether the actions solved the problem.",
    "creator" : "TeX"
  }
}