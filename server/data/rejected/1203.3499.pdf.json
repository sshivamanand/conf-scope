{
  "name" : "1203.3499.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "A Delayed Column Generation Strategy for Exact k-Bounded MAP Inference in Markov Logic Networks",
    "authors" : [ "Mathias Niepert" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "The paper introduces k-bounded MAP inference, a parameterization of MAP inference in Markov logic networks. k-Bounded MAP states are MAP states with at most k active ground atoms of hidden (non-evidence) predicates. We present a novel delayed column generation algorithm and provide empirical evidence that the algorithm efficiently computes k-bounded MAP states for meaningful real-world graph matching problems. The underlying idea is that, instead of solving one large optimization problem, it is often more efficient to tackle several small ones."
    }, {
      "heading" : "1 Introduction",
      "text" : "Graph matching instances are at the core of many problems in areas such as computational biology, computer vision, and knowledge representation. The problem of aligning protein-protein interaction networks [13] and the problem of matching different heterogeneous ontologies [1] are only two of numerous instances. In several of these cases, the alignment can be derived by computing a MAP state in a probabilistic network whose variables model the potential correspondences [4]. Given an assignment to the observable variables, a (marginal) MAP query attempts to find an assignment to the set of non-evidence (hidden) variables whose score is maximal [3].\nWe are specifically concerned with computing MAP states in Markov logic networks [5] (MLN) a probabilistic logic which combines the ideas of Markov networks with those of first-order logic. Several scenarios make it necessary to perform exact inference, especially if only those solutions are acceptable that are consistent with respect to the hard formulae of the MLN. Unfortunately, exact MAP inference is NP-hard. In several scenarios, however, it is sufficient\nto compute a MAP state with at most k active ground atoms. For instance, consider a matching problem where one is interested in the top k consistent correspondences between the nodes of two or more graphs. In other cases, one might know a-priori that only a small fraction of the ground atoms of hidden predicates will be active in a MAP state. This is true for several matching problems where the final alignment is required to be one-to-one and functional. Motivated by these observations, this paper introduces k-bounded MAP inference. k-Bounded MAP states are MAP states with at most k active ground atoms of hidden predicates. Compare this to the different m-best MAP problem [2] which aims at finding the m most probable MAP states. We present a novel algorithm combining integer linear programming (ILP) with a form of delayed column generation. Similar to dynamic programming approaches [3] the algorithm inductively builds larger solutions bottom-up from smaller ones. In each iteration, the algorithm solves a restricted version of the original MAP problem (the restricted master problem) and then checks whether the current solution is optimal or if additional variables need to be included in the formulation of the ILP. The latter is the so-called pricing problem or subproblem. We present several technical results concerning the different parts of the algorithm and experimentally evaluate the approach using an established benchmark dataset for ontology matching.\nIn Section 2 we discuss some concepts such as Markov logic, MAP inference, and the translation to an ILP problem. In Section 3, we define k-bounded MAP inference for ML and describe the column generation framework. In Section 4 we introduce the column generation algorithm for exact k-bounded MAP inference that we use for our experiments. In Section 5 we present several experimental results supporting our claim that the presented approach efficiently solves MAP inference problems of meaningful real-world applications. In Section 6 we conclude the paper with a brief summary and outlook to future research."
    }, {
      "heading" : "2 Foundations",
      "text" : "In the following we introduce some foundational concepts such as Markov logic (ML) and integer linear programming (ILP). There is a trade-off between the technical density of the paper and exhaustiveness in defining the formalisms. For well-known concepts such as Markov logic and integer linear programming we omit some technical details and refer the reader to the respective literature on these topics."
    }, {
      "heading" : "2.1 Markov Logic",
      "text" : "Markov logic combines first-order logic and undirected probabilistic graphical models [5]. A Markov logic network (MLN) is a set of first-order formulae with weights. Intuitively, the more evidence we have that a formula is true the higher the weight of this formula. To simplify the presentation of the technical parts we do not include functions. In addition, we assume that all (ground) formulae of a Markov logic network are in clausal form and use the terms formula and clause interchangeably.\nSyntax A signature is a triple S = (O,H,C) with O a finite set of observable predicate symbols, H a finite set of hidden predicate symbols, and C a finite set of constants. A Markov logic network (MLN) is a set of pairs {(Fi, wi)} with each Fi being a function-free first-order formula built using predicates from O ∪H and each wi ∈ R a real-valued weight associated with formula Fi. We can represent hard constraints using large weights.\nSemantics Let M = (Fi, wi) be a Markov logic network with signature S = (O,H,C). A grounding of a first-order formula F is generated by substituting each occurrence of every variable in F with constants in C. Existentially quantified formulae are substituted by the disjunctions of their groundings over the finite set of constants. A formula that does not contain any variables is ground. A formula that consists of a single predicate is an atom. Note that Markov logic makes several assumptions such as (a) different constants refer to different objects and (b) the only objects in the domain are those representable using the constants [5]. A set of ground atoms is a possible world. We say that a possible world W satisfies a formula F , and write W |= F , if F is true in W . Let GCF be the set of all possible groundings of formula F with respect to C. We say that W satisfies GCF , and write W |= G C F , if F satisfies every formula in GCF . Let W be the set of all possible worlds with respect to S. Then, the probabil-\nity of a possible world W is given by\np(W ) = 1\nZ exp\n\n \n∑\n(Fi,wi)\n∑\nG∈GC Fi : W |=G\nwi\n\n  .\nHere, Z is a normalization constant. The score sW of a possible world W is the sum of the weights of the ground formulae implied by W\nsW = ∑\n(Fi,wi)\n∑\nG∈GC Fi : W |=G\nwi. (1)"
    }, {
      "heading" : "2.2 MAP Inference and ILP",
      "text" : "If we want to determine the most probable state of a MLN, we need to compute the set of ground atoms of the hidden predicates that maximizes the probability given both the ground atoms of observable predicates and all ground formulae. This is an instance of MAP (maximum a-posteriori) inference in the ground Markov logic network. Let O be the set of all ground atoms of observable predicates and H be the set of all ground atoms of hidden predicates both with respect to C. We make the closed world assumption with respect to the observable predicates. Assume that we are given a set O′ ⊆ O of ground atoms of observable predicates. In order to find the most probable state of the MLN we have to compute\nargmax H′⊆H\n∑\n(Fi,wi)\n∑\nG∈GC Fi : O′∪H′|=G\nwi.\nIn this paper, every H′ ⊆ H is called a state. It is the set of active ground atoms of hidden predicates. Markov logic is by definition a declarative language, separating the formulation of a problem instance from the algorithm used for probabilistic inference. MAP inference in Markov logic networks is essentially equivalent to the weighted MAX-SAT problem and, therefore, NP-hard. Integer linear programming (ILP) is an effective method for solving exact MAP inference in undirected graphical models [7, 12] and specifically in Markov logic networks [6]. ILP is concerned with optimizing a linear objective function over a finite number of integer variables, subject to a set of linear constraints over these variables [8]. We omit the formal details of the ILP representation of a MAP problem and refer the reader to [6].\nExample 2.1. The running example of this paper is a small instance of the ontology alignment problem which involves both soft and hard formulae. ML was successfully applied to ontology matching problems [4]. Let O1 and O2 be the two ontologies in Figure 1 with the (a-priori computed) string similarities between the concept labels given in Table 1.\nLet S = (O,H,C) be the signature of a MLN M with O = {sub1, sub2, dis1, dis2}, H = {map}, and C = {a1, b1, c1, a2, b2}. Here, the observable predicates model the subsumption and disjointness relationships between concepts C in the two ontologies and map is the hidden predicate modeling the sought-after matching correspondences. We also assume that the predicates are typed meaning that, for instance, valid groundings of map(x, y) are those with x ∈ {a1, b1, c1} and y ∈ {a2, b2}. Furthermore, let us assume that the MLN M includes the following formula with weight w = 10.0:\n∀x, x′, y, y′ : dis1(x, x ′)∧ sub2(y, y′) ⇒ (¬map(x, y)∨¬map(x′, y′))\nThe formula makes those alignments less likely that match concepts x with y and x′ with y′ if x is disjoint with x′ in the first ontology and y′ subsumes y in the second. We also include cardinality formulae with weight 10.0 forcing alignments to be one-to-one and functional:\n∀x, y, z : map(x, y) ∧map(x, z) ⇒ y = z\n∀x, y, z : map(x, y) ∧map(z, y) ⇒ x = z\nIn addition, we add the formulae map(x, y) with weight σ(x, y) for all x ∈ {a1, b1, c1, d1} and y ∈ {a2, b2} where σ(x, y) is the label similarity from Table 1. The observed ground atoms are sub1(c1, a1), dis1(a1, b1), dis1(b1, a1), dis1(b1, c1), dis1(c1, b1) for ontology O1 and sub2(b2, a2) for ontology O2. This results in the following relevant ground formulae for the coherence reducing constraint where each observable predicates has been substituted with its observed value:\n¬map(a1, b2) ∨ ¬map(b1, a2) (2)\n¬map(b1, b2) ∨ ¬map(a1, a2) (3)\n¬map(b1, b2) ∨ ¬map(c1, a2) (4)\n¬map(c1, b2) ∨ ¬map(b1, a2) (5)\nFor instance, the ground formulae (2) is encoded in an ILP by introducing a new binary variable y which is added to the objective function with coefficient 10.0 and, in addition, by introducing the following linear constraints enforcing the value of y to be equivalent to the truth value of the formula:\n−xa,b − y ≤ −1\n−xb,a − y ≤ −1\nxa,b + xb,a + y ≤ 2\nThe binary ILP variables xa,b and xb,a correspond to ground atoms map(a1, b2) and map(b1, a2), respectively. The ILP for our small example includes 19 variables (columns) and 39 linear constraints (12 from the coherence and 27 from the cardinality formulae) which we omit due to space considerations. The preprocessing step of grounding only those clauses that can evaluate to false given the current state of observable variables is similar to the approach presented in [9] and was implicitly used in [6].\n3 k-Bounded MAP Inference\nIn several scenarios it is sufficient to compute a MAP state with Hamming weight at most k, that is, with at most k active ground atoms. For instance, consider a matching problem where one is interested in the top k consistent correspondences between nodes of two or more graph structures. Such matching problems occur, for instance, in the areas of computer vision, computational biology, and knowledge representation as we have seen in the previous example. In other cases, one might know a-priori that only a small fraction of the ground atoms of hidden predicates will be active in a MAP state. For instance, this is true for several matching problems where the final matching is required to be one-to-one and functional. In several of these instances it might be necessary to perform exact inference, especially if only those solutions are acceptable that are consistent with respect to the hard formulae of the MLN. In the following we define k-bounded MAP states and implement k-bounded MAP inference using integer linear programming with a form of delayed column generation.\nDefinition 3.1. Let M = {(Fi, wi)} be a MLN with signature S = (O,H,C). Let O′ ⊆ O be a set of given ground atoms of observable predicates and let Ĥ ⊆ H be a set of ground atoms of hidden predicates. The kbounded MAP state of M with respect to Ĥ is defined as\nargmax H\n′⊆Ĥ |H′|≤k\n∑\n(Fi,wi)\n∑\nG∈GC Fi : O′∪H′|=G\nwi. (6)\nEach k-bounded MAP state with respect to Ĥ of a ground MLN with |H| = N is equivalent to a global MAP state if k = N and Ĥ = H. The underlying idea of our approach is that we compute a state with at most k active ground atoms of hidden predicates and verify optimality using the MAP state with at most k − 1 active ground atoms. The objective is to keep both the number of columns and rows small in the ILP representation. To achieve this, we partition the set of ground atoms of hidden predicates H in two sets: the open ground atoms HO and the closed ground atoms HC of hidden predicates. Intuitively, open ground atoms can potentially be part of the MAP state while closed ground atoms always evaluate to false."
    }, {
      "heading" : "3.1 Procedural Framework",
      "text" : "The proposed k-bounded MAP algorithm starts with a small set of m ≥ 1 open ground atoms of hidden predicates and solves, for each n ≤ k, the n-bounded MAP ILP with respect to the currently open ground atoms HO. This is what is referred to as the restricted master problem (RMP) in mathematical programming. Once we have found an n-bounded state with respect to HO we check for each h ∈ HC whether making h an open ground atom can potentially change the score enough to beat the current solution. This is what is usually called the subproblem of column generation algorithms. The optimality of the current n-bounded state with respect to all ground atoms of hidden predicates H is given when none of the ground atoms in HC needs to be priced out (moved to HO) to enter the basis of the ILP. To compute the k-bounded MAP state with respect to the open ground atoms of hidden predicatesHO we also construct and solve an ILP. The only additional constraint we have to include is the one restricting the number of active ground atoms of hidden predicates to be less than or equal to k. Instead of including all formulae, however, we only need to consider a subset of all ground formulae for the ILP formulation. This is formalized with the following lemma.\nLemma 3.2. Let M be a MLN. Let H be the set of all ground atoms of hidden predicates, let ϕ(Gi) and ϕ(Gi), respectively, be the set of unnegated and negated ground atoms of hidden predicates in ground clause Gi, and let Ĥ ⊆ H. To compute the k-bounded MAP state of M with respect to Ĥ, the ILP formulation only has to include ground clauses Gi for which the following statement holds\nϕ(Gi) ∩ (H \\ Ĥ) = ∅.\nProof. Each ground clause Gi not satisfying the statement holds in every state which is a subset of Ĥ and, therefore, need not be part of the ILP formulation.\nThe closed ground atoms of hidden variables in the set HC = H \\HO are set to false in the ILP formulation. The following example shows how these conditions keep the number of rows and columns small.\nExample 3.3. Let us revisit Example 2.1. Assume that HO = {map(a1, a2),map(b1, b2)} and that we want to compute the 2-bounded MAP state with respect to HO. By Lemma 3.2 we only have to include the ground formula ¬map(b1, b2)∨¬map(a1, a2) in the formulation of the ILP. The other formulae (1),(3), and (4) from Example 2.1 as well as all cardinality formulae always evaluate to true. Instead of 19 variables and 39 rows the ILP here has 3 variables and 3 constraints. The 2-bounded MAP state with respect to HO is {map(a1, a2)}.\nGiven a MLN M and the set of all ground atoms of hidden predicates H, we now have a way to compute, for every 1 ≤ k ≤ |H|, the k-bounded MAP state H′ with respect to a set of open ground atoms HO ⊆ H. When computing the score of such a k-bounded MAP state we only have to add the optimal value of the ILP to the sum of weights of those ground formulae that were excluded by Lemma 3.2. We now need an algorithm to determine whether a k-bounded MAP state H′ with respect to HO ⊂ H is also a k-bounded MAP state with respect to H. This optimality test is crucial as it allows us to move from computing the kbounded MAP state to computing the (k+1)-bounded MAP state. In the remainder of this section we derive some technical results that will facilitate the desired optimality test.\n3.2 k-Bounded MAP Optimality Test\nMost of the following lemmas and definitions are with respect to ground MLNs. Again, we assume that all grounded formulae of a given Markov logic network are in clausal form. To simplify the notation, we will write, for a ground formula Gi, a set of ground atoms of hidden predicates H′, and a set of given ground atoms of observable predicates O′, H′ |= Gi instead of O′ ∪H′ |= Gi since the set of ground atoms of observable predicates is constant for each MAP instance of a MLN. We first introduce a recursively defined function that maps each state to its score.\nLemma 3.4. Let M = {(Gi, wi)} be a ground MLN, let H be the set of all ground atoms of hidden predicates in M, let h ∈ H, and let ϕ(Gi) be the set of negated ground atoms of hidden predicates in ground formula Gi. The score of a set of ground atoms of hidden predicates is given by the following function s : 2H → R\ns(∅) = ∑\n{(Gi,wi) | ϕ(Gi) 6=∅}\nwi (7)\ns(H′ ∪ {h}) = s(H′) + c(H′, h) (8)\nwith c(H′, h) =\n∑\n{(Gi,wi) | H ′ 6|=Gi∧\nH ′∪{h}|=Gi}\nwi − ∑\n{(Gi,wi) | H ′|=Gi∧\nH ′∪{h}6|=Gi}\nwi. (9)\nDefinition 3.5. Let M = {(Gi, wi)} be a ground MLN, let H be the set of all ground atoms of hidden predicates in M, let H′ ⊆ H be a set of ground hidden predicates, and let c : 2H × H → R be the function defined in Lemma 3.4. We say that a function ĉ : H → R k-bounds c relative to H′ if and only if for all A ⊆ H′ with |A| ≤ k and all h ∈ H we have that ĉ(h) ≥ c(A, h).\nBased on this we can state the following theorem.\nTheorem 3.6. Let M = {(Gi, wi)} be a ground MLN, let H be the set of all ground atoms of hidden predicates, let sk be the score of a MAP state with at most k active ground atoms of hidden predicates, let sk+1 be the score of a state H′ ⊆ H with at most k + 1 active ground atoms of hidden predicates, and let ĉ be a function that k-bounds c relative to H. If for all h ∈ H with ĉ(h) > sk+1 − sk, h was an open ground atom before H′ was computed, then H′ is optimal, that is, H′ is a (k+1)-bounded MAP state with respect to H.\nProof. Let us assume that a MAP state with at most k (k ≥ 0) ground atoms of hidden predicates is given and has score sk and that sk+1 is the score of a state H′ with at most k + 1 active ground atoms of hidden predicates. Furthermore, let us assume that for all h ∈ H with ĉ(h) > sk+1 − sk, h was an open ground atom before computing H′ but that H′ is not optimal. Then, there has to exist a state Ĥ with at most k + 1 ground atoms of hidden predicates that is optimal and an h′ ∈ Ĥ with ĉ(h′) ≤ sk+1 − sk. Since H′ is not optimal but Ĥ is optimal, we have s(Ĥ) > sk+1 and we can infer that ĉ(h′) < s(Ĥ)− sk. Then, by Lemma 3.4, we can write ĉ(h′) < s(Ĥ)−sk as ĉ(h′) < s(Ĥ\\{h′})+c(Ĥ\\{h′}, h′)−sk. Hence, ĉ(h′)− c(Ĥ \\ {h′}, h′) < s(Ĥ \\ {h′})− sk. Since ĉ k-bounds c relative to H we know that ĉ(h′)− c(Ĥ \\ {h′}, h′) ≥ 0 and, therefore, s(Ĥ \\ {h′}) > sk. Hence, Ĥ \\ {h′} is a MAP state with at most k ground atoms of hidden predicates and s(Ĥ\\{h′}) > sk, a contradiction to our assumption that sk is an optimal score.\nTheorem 3.6 is the basis of the proposed method for verifying the optimality of a state with at most k + 1 active ground atoms using the optimality of a state with at most k active ground atoms both relative to H. An effective optimality test requires an algorithm computing a function that k-bounds c relative to H for all potential k as tightly as possible. The computation of this function should be efficient\nand avoid the inclusion of many ground formulae. In the next definition we construct a subproblem whose optimal value k-bounds c relative to H.\nDefinition 3.7. Let M = {(Gi, wi)} be a ground MLN, let H be the set of all ground atoms of hidden predicates, let H′ ⊆ H be the set of open ground atoms, let ϕ(Gi) and ϕ(Gi) be the set of unnegated and negated ground atoms in ground formula Gi, let k ∈ N, and let h ∈ H′. The k-subproblem of h relative to H′, which is also an ILP, is constructed as follows:\n1. For each Gi with (a) h ∈ ϕ(Gi); (b) h 6∈ ϕ(Gi); and (c) ϕ(Gi)∩(H\\H′) = ∅ we introduce a binary variable xj with coefficient cj = wi and add the\nlinear constraints equivalent to ¬G̃i ⇔ xj , where G̃i is the clause Gi where all occurrences of h have been removed;\n2. For each Gi with (a) h ∈ ϕ(Gi); (b) h 6∈ ϕ(Gi); and (c) ϕ(Gi)∩(H\\H′) = ∅ we introduce a binary variable xj with coefficient cj = −wi and add the\nlinear constraints equivalent to ¬G̃i ⇔ xj , where G̃i is the clause Gi where all occurrences of h have been removed;\n3. We add one constraint restricting the number of active ground atoms of hidden predicates to be less than or equal to k.\nThe objective of the ILP is then Maximize ∑\nj\ncjxj .\nThe formulation of the subproblem can be adjusted to achieve certain computational goals. For instance, if we wanted to achieve a speed-up of the subproblem computation we could remove the constraint that all variables are integer. The optimal value of the resulting subproblem would then be an upper-bound to the optimal value of the original formulation.\nExample 3.8. We revisit Example 2.1. Assume that we want to compute the 1-subproblem of map(a1, b2) relative to H. map(a1, b2) occurs unnegated only in the ground formula map(a1, b2) with weight 0.55. Hence, by rule (1), we add a new binary variable x1 to the ILP with coefficient 0.55 and no constraint because true ⇔ x1 is equivalent to x1. Ground atom map(a1, b2) occurs negated in the ground formula ¬map(a1, b2) ∨ ¬map(b1, a2) with weight 10.0. Hence, by rule (2), we add a new binary variable x2 with coefficient −10.0 to the ILP and the constraints x2 − xb,a ≤ 0 and xb,a − x2 ≤ 0 which are equivalent to map(b1, a2) ⇔ x2. The same is done for three more cardinality formulae involving map(a1, b2), introducing variables x3, x4, and x5. Finally, we add the constraint xa,a+xb,a+xb,b+xc,a ≤ 1 by rule (3). The optimal value of this ILP is 0.55.\nThe following theorem states the desired optimality of the subproblem.\nTheorem 3.9. Let M = {(Gi, wi)} be a ground MLN, let H be the set of all ground atoms of hidden predicates, let H′ ⊆ H be the set of open ground atoms, let ϕ(Gi) and ϕ(Gi) be the set of unnegated and negated ground atoms in ground formula Gi, let k ∈ N, let h ∈ H, let c be the function from Lemma 3.4, and let oh be the optimal value of the k-subproblem of h relative to H′. Then,\noh = max {A⊆H′, |A|≤k} c(A, h).\nProof sketch. We provide a sketch of the proof by showing that everyA′ ⊆ H′ with |A′| ≤ k corresponds to a feasible solution of the k-subproblem of h relative to H′ with value c(A′, h). Since the ILP variables representing the elements in A′ do not overlap with the variables xj and since |A′| ≤ k we know that every linear constraint is satisfied. For each Gi with h ∈ ϕ(Gi), we have that either (a) the corresponding ILP variable xj is part of the feasible solution or (b) xj is not part of the feasible solution. In case (a) we have A′ 6|= Gi and A′ ∪ {h} |= Gi, and in case (b) we have A′ |= Gi and A′∪{h} |= Gi. Furthermore, for each Gi with h ∈ ϕ(Gi), we have either (a) the corresponding ILP variable xj is part of the feasible solution or (b) xj is not part of the feasible solution. In case (a) we have A′ |= Gi and A′ ∪ {h} 6|= Gi, and in case (b) we have A′ |= Gi and A′ ∪ {h} |= Gi. Furthermore, for any set A′ ⊆ H′ and each ground clause Gi we have A′ 6|= Gi and A′ ∪ {h} |= Gi only if (a) h ∈ ϕ(Gi); (b) h 6∈ ϕ(Gi); and (c) ϕ(Gi) ∩ (H \\H′) = ∅; and for each ground clause Gi we have A\n′ |= Gi and A′ ∪ {h} 6|= Gi only if (a) h ∈ ϕ(Gi); (b) h 6∈ ϕ(Gi); and (c) ϕ(Gi) ∩ (H \\H′) = ∅. Hence, by Lemma 3.4, we conclude that c(A′, h) is the value of the feasible ILP solution corresponding to A′."
    }, {
      "heading" : "4 Algorithm",
      "text" : "Algorithm 1 brings the different components together. First, we need to find a strategy for choosing the m ground atoms of hidden predicates to be priced out (moved to HO in lines 7 and 18). Several alternatives are possible. One is choosing the ground atoms with the m highest optimal values oh of the respective subproblems. In our experiments we used the apriori weights of the individual ground atoms. For each n ≤ k we compute the score sn of the (n-1)-bounded MAP state H′ with respect to the open ground atoms HO (line 12). We then test, for each closed ground atom h ∈ HT, whether it could potentially be part of an n-bounded state with respect to H with higher\nAlgorithm 1 Compute k-bounded MAP state\nRequire: 1 ≤ k,m ≤ |H| 1: Input: MLNM with signature S = (O,H,C) and\nparameter k and m 2: HO ← ∅ 3: HC ← H 4: compute score s0 of MAP state H\n′ with respect to HO subject to |H′| ≤ 0 using Lemma 3.4 (7)\n5: n ← 1 6: sn−1 ← s0 7: move m ground atoms from HC to HO 8: repeat 9: compute score sn of MAP state H ′ with respect\nto HO subject to |H′| ≤ n 10: HT ← HC 11: for all h ∈ HT do 12: compute the optimal value oh of the (n-1)subproblem of h relative to HT ∪HO 13: if oh ≤ sn − sn−1 then 14: HT ← HT \\ {h} 15: end if 16: end for 17: if HT 6= ∅ then 18: move m ground atoms from HC to HO 19: else 20: sn−1 ← sn 21: n ← n+ 1 22: end if 23: until n = k + 1 24: return H′\nscore (line 13). If this is the case, we move m closed ground atoms to the set of open ground atoms (line 18) and repeat the previous steps. Otherwise, the optimality of H′ with respect to H is guaranteed by Theorem 3.6 and Theorem 3.9, and we continue with computing the n+1-bounded MAP state. When constructing the ILPs for (a) the restricted master problem (line 9) and (b) the subproblems (line 12) we have to retrieve ground formulae from the MLN representation each time, which is potentially very time consuming. As proposed similarly in [6], however, this problem can be transformed into a database query evaluation problem. For instance, when we want to retrieve all ground formulae Gi for which h ∈ ϕ(Gi) we can translate this into a conjunctive query over the appropriately indexed relational database.\nExample 4.1. Let us revisit Example 2.1 once more. We first compute the score s0 of the 0-bounded MAP state (line 4). This, of course, is the sum of the weights of ground clauses with at least one negated ground atom (see Equation (7) in Lemma 3.4). Example 2.1 has 13 such ground formulae with weight 10.0. Hence, s0 = 130.0. Here, we choose\nm = 1 and move map(a1, a2) to HO since 0.95 is the highest a-priori weight. We then compute the score s1 of the 1-bounded MAP state with respect to HO = {map(a1, a2)} which is 130.95. For each closed ground atom h we compute the optimal value oh of the 0-subproblem of h relative to HT ∪HO. For each of these oh ≤ s1−s0 = 0.95 and, therefore, {map(a1, a2)} is a 1-bounded MAP state. We move map(b1, b2) to HO since 0.91 is the second highest a-priori weight. When computing the 2-bounded MAP state with respect to HO = {map(a1, a2),map(b1, b2)} the coherence formula (3) causes the result to be {map(a1, a2)} with score 130.95. Since s2 − s1 = 0 the optimality of the current state with respect to H cannot be verified. Hence, map(c1, b2) is moved to HO since 0.64 is the third highest weight. The score of the 2-bounded MAP state with respect to HO is 130.0 + 0.95 + 0.64 and, therefore, s2−s1 = 0.64. For each closed ground atom we compute oh for the 1-subproblem relative to HT ∪ HO. For each of these it is oh ≤ s2 − s1 = 0.64 and, therefore, {map(a1, a2),map(c1, b2)} is a 2-bounded MAP state. In addition, {map(a1, a2),map(c1, b2)} is the global MAP state for the MLN since a one-to-one and functional alignment of O1 and O2 contains at most two ground atoms. Instead of translating the problem into one ILP instance we computed the MAP state by solving several smaller ILP instances."
    }, {
      "heading" : "5 Experiments",
      "text" : "We used the Ontofarm dataset [11] for our experiments. It is the dataset of the OAEI1 conference track and consists of several ontologies modeling the domain of academic conferences. The ontologies were designed by different groups and, therefore, reflect different conceptualizations of the same domain. Reference alignments (gold standard alignments) for seven of these ontologies are made available by the organizers. These 21 alignments contain correspondences between concepts and properties including a large number of non-trivial cases. From the 7 ontologies with reference alignment we chose the EKAW (77 concepts), SIGKDD (49 concepts), ConfTool (38 concepts), and CMT (36 concepts) ontologies. The signature and formulae of the MLN are identical with those introduced in Example 2.1 except that we added additional formulae with weight 0.1 making alignments that match x with y and x′ with y′ more likely if x′ subsumes x in O1 and y ′ subsumes y in O2:\n∀x, x′, y, y′ : sub1(x, x ′) ∧ sub2(y, y ′) ⇒ (map(x, y) ⇒ map(x′, y′)).\nFor the label similarity σ we decided to use a standard lexical similarity measure. Thus, after converting the\n1http://oaei.ontologymatching.org\nconcept names to lowercase and removing delimiters and stop-words, we applied a string similarity measure based on the Levensthein distance. We applied the reasoner Pellet [10] to create the ground MLN formulation and the mixed integer programming solver SCIP2 to solve the ILPs. We then applied our algorithm to compute the k-bounded MAP states for 1 ≤ k ≤ 20 and with parameter m = 10 using the label similarity as pricing criterion. The experiments were conducted on a PC with an AMD Athlon dual core 5400B 1.0 GHz processor and 3 GB RAM. Figure 2 depicts the results for three different matching instances. The ILP dimensions, that is, the number of columns and rows and the accumulative solving times remain small for k ≤ 15. The running time spent on the subproblem ILPs was always less than 10% of the overall computation time. Remarkably, the k-bounded MAP states leading to the respective alignments with the highest F1 scores (the harmonic mean of precision\n2http://scip.zib.de/\nand recall determined using the gold standard) can be computed very efficiently. Table 2 compares the solving times and the ILP dimensions of the column generation algorithm with the näıve approach which constructs the entire ILP with the additional cardinality constraint. The column generation approach is more than 5000 times faster than the näıve approach to compute the top 10 alignment between the ConfOf and EKAW ontologies. The computation times of less than one second, for instance, would allow real-time user interaction with an alignment system."
    }, {
      "heading" : "6 Conclusion",
      "text" : "We presented k-bounded MAP inference and motivated it by use-cases from the areas of computational biology and knowledge representation. It is a useful concept in the context of graph matching problems where one is interested in the top k correspondences between nodes of two or more graph structures. The presented column generation algorithm is tailored to the problem and is especially efficient for instances where (a) a-priori weights are given for ground atoms or (b) it is known a-priori that the number of active ground atoms in a MAP state is small relative to the number of all ground atoms of hidden predicates. Typical instances are one-to-one and functional alignment problems. The approach also lends itself to distributed computing strategies since the individual subproblems are mutually independent. We will try to leverage existing software platforms for distributed computing to implement distributed probabilistic reasoning. The presented algorithm can also be transformed into an approximate inference algorithm by adjusting the optimality test. Future research might be concerned with applying the presented ideas to different graph matching as well as weighted MAX-SAT problems."
    }, {
      "heading" : "Acknowledgments",
      "text" : "Many thanks to Christian Meilicke, Sebastian Riedel, and Heiner Stuckenschmidt for helpful discussions and the anonymous reviewers for valuable feedback."
    } ],
    "references" : [ {
      "title" : "Ontology matching",
      "author" : [ "J. Euzenat", "P. Shvaiko" ],
      "venue" : "Springer Verlag",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "An lp view of the m-best map problem",
      "author" : [ "M. Fromer", "A. Globerson" ],
      "venue" : "In Advances in Neural Information Processing Systems",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2009
    }, {
      "title" : "Probabilistic Graphical Models",
      "author" : [ "D. Koller", "N. Friedman" ],
      "venue" : "MIT Press",
      "citeRegEx" : "3",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "A probabilistic-logical framework for ontology matching",
      "author" : [ "M. Niepert", "C. Meilicke", "H. Stuckenschmidt" ],
      "venue" : "Proceedings of the 24th AAAI Conference on Artificial Intelligence",
      "citeRegEx" : "4",
      "shortCiteRegEx" : null,
      "year" : 2010
    }, {
      "title" : "Markov logic networks",
      "author" : [ "M. Richardson", "P. Domingos" ],
      "venue" : "Machine Learning, 62(1-2):107–136",
      "citeRegEx" : "5",
      "shortCiteRegEx" : null,
      "year" : 2006
    }, {
      "title" : "Improving the accuracy and efficiency of map inference for markov logic",
      "author" : [ "S. Riedel" ],
      "venue" : "Proceedings of the Conference on Uncertainty in Artificial Intelligence, pages 468–475",
      "citeRegEx" : "6",
      "shortCiteRegEx" : null,
      "year" : 2008
    }, {
      "title" : "Integer linear programming inference for conditional random fields",
      "author" : [ "D. Roth", "W. Yih" ],
      "venue" : "Proceedings of the International Conference on Machine Learning, pages 736–743",
      "citeRegEx" : "7",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Theory of Linear and Integer Programming",
      "author" : [ "A. Schrijver" ],
      "venue" : "Wiley & Sons",
      "citeRegEx" : "8",
      "shortCiteRegEx" : null,
      "year" : 1998
    }, {
      "title" : "Speeding up inference in markov logic networks by preprocessing to reduce the size of the resulting grounded network",
      "author" : [ "J. Shavlik", "S. Natarajan" ],
      "venue" : "Proceedings of the 21st International Joint Conference on Artifical intelligence, pages 1951–1956",
      "citeRegEx" : "9",
      "shortCiteRegEx" : null,
      "year" : 2009
    }, {
      "title" : "Pellet: a practical OWL-DL reasoner",
      "author" : [ "E. Sirin", "B. Parsia", "B.C. Grau", "A. Kalyanpur", "Y. Katz" ],
      "venue" : "Journal of Web Semantics, 5(2):51–53",
      "citeRegEx" : "10",
      "shortCiteRegEx" : null,
      "year" : 2007
    }, {
      "title" : "Ontofarm: Towards an experimental collection of parallel ontologies",
      "author" : [ "O. Svab", "V. Svatek", "P. Berka", "D. Rak", "P. Tomasek" ],
      "venue" : "Poster Track of ISWC, Galway, Ireland",
      "citeRegEx" : "11",
      "shortCiteRegEx" : null,
      "year" : 2005
    }, {
      "title" : "Learning Structured Prediction Models: A Large-Margin Approach",
      "author" : [ "B. Taskar" ],
      "venue" : "PhD thesis, Stanford University",
      "citeRegEx" : "12",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "Global alignment of protein-protein interaction networks by graph matching methods",
      "author" : [ "M. Zaslavskiy", "F.R. Bach", "J.-P. Vert" ],
      "venue" : "Bioinformatics, 25(12)",
      "citeRegEx" : "13",
      "shortCiteRegEx" : null,
      "year" : 2009
    } ],
    "referenceMentions" : [ {
      "referenceID" : 12,
      "context" : "The problem of aligning protein-protein interaction networks [13] and the problem of matching different heterogeneous ontologies [1] are only two of numerous instances.",
      "startOffset" : 61,
      "endOffset" : 65
    }, {
      "referenceID" : 0,
      "context" : "The problem of aligning protein-protein interaction networks [13] and the problem of matching different heterogeneous ontologies [1] are only two of numerous instances.",
      "startOffset" : 129,
      "endOffset" : 132
    }, {
      "referenceID" : 3,
      "context" : "In several of these cases, the alignment can be derived by computing a MAP state in a probabilistic network whose variables model the potential correspondences [4].",
      "startOffset" : 160,
      "endOffset" : 163
    }, {
      "referenceID" : 2,
      "context" : "Given an assignment to the observable variables, a (marginal) MAP query attempts to find an assignment to the set of non-evidence (hidden) variables whose score is maximal [3].",
      "startOffset" : 172,
      "endOffset" : 175
    }, {
      "referenceID" : 4,
      "context" : "We are specifically concerned with computing MAP states in Markov logic networks [5] (MLN) a probabilistic logic which combines the ideas of Markov networks with those of first-order logic.",
      "startOffset" : 81,
      "endOffset" : 84
    }, {
      "referenceID" : 1,
      "context" : "Compare this to the different m-best MAP problem [2] which aims at finding the m most probable MAP states.",
      "startOffset" : 49,
      "endOffset" : 52
    }, {
      "referenceID" : 2,
      "context" : "Similar to dynamic programming approaches [3] the algorithm inductively builds larger solutions bottom-up from smaller ones.",
      "startOffset" : 42,
      "endOffset" : 45
    }, {
      "referenceID" : 4,
      "context" : "Markov logic combines first-order logic and undirected probabilistic graphical models [5].",
      "startOffset" : 86,
      "endOffset" : 89
    }, {
      "referenceID" : 4,
      "context" : "Note that Markov logic makes several assumptions such as (a) different constants refer to different objects and (b) the only objects in the domain are those representable using the constants [5].",
      "startOffset" : 191,
      "endOffset" : 194
    }, {
      "referenceID" : 6,
      "context" : "Integer linear programming (ILP) is an effective method for solving exact MAP inference in undirected graphical models [7, 12] and specifically in Markov logic networks [6].",
      "startOffset" : 119,
      "endOffset" : 126
    }, {
      "referenceID" : 11,
      "context" : "Integer linear programming (ILP) is an effective method for solving exact MAP inference in undirected graphical models [7, 12] and specifically in Markov logic networks [6].",
      "startOffset" : 119,
      "endOffset" : 126
    }, {
      "referenceID" : 5,
      "context" : "Integer linear programming (ILP) is an effective method for solving exact MAP inference in undirected graphical models [7, 12] and specifically in Markov logic networks [6].",
      "startOffset" : 169,
      "endOffset" : 172
    }, {
      "referenceID" : 7,
      "context" : "ILP is concerned with optimizing a linear objective function over a finite number of integer variables, subject to a set of linear constraints over these variables [8].",
      "startOffset" : 164,
      "endOffset" : 167
    }, {
      "referenceID" : 5,
      "context" : "We omit the formal details of the ILP representation of a MAP problem and refer the reader to [6].",
      "startOffset" : 94,
      "endOffset" : 97
    }, {
      "referenceID" : 3,
      "context" : "ML was successfully applied to ontology matching problems [4].",
      "startOffset" : 58,
      "endOffset" : 61
    }, {
      "referenceID" : 8,
      "context" : "The preprocessing step of grounding only those clauses that can evaluate to false given the current state of observable variables is similar to the approach presented in [9] and was implicitly used in [6].",
      "startOffset" : 170,
      "endOffset" : 173
    }, {
      "referenceID" : 5,
      "context" : "The preprocessing step of grounding only those clauses that can evaluate to false given the current state of observable variables is similar to the approach presented in [9] and was implicitly used in [6].",
      "startOffset" : 201,
      "endOffset" : 204
    }, {
      "referenceID" : 5,
      "context" : "As proposed similarly in [6], however, this problem can be transformed into a database query evaluation problem.",
      "startOffset" : 25,
      "endOffset" : 28
    }, {
      "referenceID" : 10,
      "context" : "We used the Ontofarm dataset [11] for our experiments.",
      "startOffset" : 29,
      "endOffset" : 33
    }, {
      "referenceID" : 9,
      "context" : "We applied the reasoner Pellet [10] to create the ground MLN formulation and the mixed integer programming solver SCIP to solve the ILPs.",
      "startOffset" : 31,
      "endOffset" : 35
    } ],
    "year" : 2010,
    "abstractText" : "The paper introduces k-bounded MAP inference, a parameterization of MAP inference in Markov logic networks. k-Bounded MAP states are MAP states with at most k active ground atoms of hidden (non-evidence) predicates. We present a novel delayed column generation algorithm and provide empirical evidence that the algorithm efficiently computes k-bounded MAP states for meaningful real-world graph matching problems. The underlying idea is that, instead of solving one large optimization problem, it is often more efficient to tackle several small ones.",
    "creator" : "LaTeX with hyperref package"
  }
}