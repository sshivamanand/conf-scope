{
  "name" : "1206.3318.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "On Local Regret",
    "authors" : [ "Michael Bowling", "Martin Zinkevich" ],
    "emails" : [ "bowling@cs.ualberta.ca", "maz@yahoo-inc.com" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "An online learning task involves repeatedly taking actions and, after an action is chosen, observing the result of that action. This is in contrast to offline learning where the decisions are made based on a fixed batch of training data. As a consequence offline learning typically requires i.i.d. assumptions about how the results of actions are generated (on the training data, and all future data). In online learning, no such assumptions are required. Instead, the metric of performance used is regret: the amount of additional utility that could have been gained if some alternative sequence of actions had been chosen. The set of alternative sequences that are considered defines the notion of regret. Regret is more than just a measure of performance, though, it also guides algorithms. For specific notions of regret, no-regret algorithms exist, for which the total regret is growing at worst sublinearly with time, hence their average regret goes to zero. These guarantees can be made with no i.i.d., or equivalent assumption, on the results of the actions.\nOne traditional drawback of regret concepts is that the number of alternatives considered must be finite. This is typically achieved by assuming the number of available actions is finite, and for practical purposes, small. In offline learning this is not at all the case: offline hypothesis classes are usually very large, if not infinite. There have been attempts to achieve regret guarantees for infinite action spaces, but these have all required assumptions to be made on the action outcomes (e.g., convexity or smoothness). In this work, we propose new notions of regret, specifically for very large or infinite action sets, while avoiding any significant assumptions on the sequence of action outcomes. Instead, the action set is assumed to come equipped with a notion of locality, and regret is redefined to respect this notion of locality. This approach allows the online paradigm with its style of regret guarantees to be applied to previously intractable tasks and hypothesis classes."
    }, {
      "heading" : "2 Background",
      "text" : "For t ∈ {1, 2, . . .}, let at ∈ A be the action at time t, and ut : A→ R be the utility function over actions at time t.\nRequirement 1. For all t, maxa,b∈A |ut(a)− ut(b)| ≤ ∆.\nThe basic building block of regret is the additional utility that could have been gained if some action b was chosen in place of action a: RTa,b = ∑T t=1 1(a t = a) (ut(b)− ut(a)), where 1(condition) is equal to 1 when condition is true\nar X\niv :1\n20 6.\n33 18\nv1 [\ncs .A\nI] 1\n4 Ju\nn 20\nand 0 otherwise. We can use this building block to define the traditional notions of regret.\nRTinternal = max a,b∈A RT,+a,b R T swap = ∑ a∈A max b∈A RT,+a,b (1)\nRTexternal = max b∈A (∑ a∈A RTa,b )+ (2)\nwhere x+ = max(x, 0) so that RT,+a,b = max(R T a,b, 0). Internal regret [Hart and Mas-Colell, 2002] is the maximum utility that could be gained if one action had been chosen in place of some other action. Swap regret [Greenwald and Jafari, 2003] is the maximum utility gained if each action could be replaced by another. External regret [Hannan, 1957], which is the original pioneering concept of regret, is the maximum utility gained by replacing all actions with one particular action. This is the most relaxed of the three concepts, and while the others must concern themselves with |A|2 possible regret values (for all pairs of actions) external regret only need worry about |A| regret values. So although the guarantee is weaker, it is a simpler concept to learn which can make it considerably more attractive. These three regret notions have the following relationships.\nRTinternal ≤ RTswap ≤ |A|RTinternal RTexternal ≤ RTswap (3)"
    }, {
      "heading" : "2.1 Infinite Action Spaces",
      "text" : "This paper considers situations where A is infinite. To keep the notation simple, we will use max operations over actions to mean suprema operations and summations over actions to mean the suprema of the sum over all finite subsets of actions. Since we will be focused on regret over a finite time period, there will only ever be a finite set of actually selected actions and, hence only a finite number of non-zero regrets, RTa,b. The summations over actions will always be thought to be restricted to this finite set.\nNone of the three traditional regret concepts are well-suited to A being infinite. Not only does |A| appear in the regret bounds, but one can demonstrate that it is impossible to have no regret in some infinite cases. Consider A = N and let ut be a step function, so ut(a) = 1 if a > yt for some yt and 0 otherwise. Imagine yt is selected so that Pr[at > yt|u1,...,T−1, a1,...,T−1] ≤ 0.001, which is always possible. Essentially, high utility is always just beyond the largest action selected. Now, consider y∗ = 1 + maxt≤T yt. In expectation 1T ∑T t=1 u\nt(at) ≤ 0.001 while 1 T ∑T t=1 u\nt(y∗) = 1 (i.e., there is large internal and external regret for not having played y∗,) so the average regret cannot approach zero.\nMost attempts to handle infinite action spaces have proceeded by making assumptions on both A and u. For example, if A is a compact, convex subset of Rn and the utilities are convex with bounded gradient on A, then you can minimize regret even though A is infinite [Zinkevich, 2003]. We take an alternative approach where we make use of a notion of locality on the set A, and modify regret concepts to respect this locality. Different notions of locality then result in different notions of regret. Although this typically results in a weaker form of regret for finite sets, it breaks all dependence of regret on the size ofA and allows it to even be applied whenA is infinite and u is an arbitrary (although still bounded) function. Wide range regret methods Lehrer [2003] can also bound regret with respect to a set of (countably) infinite “alternatives”, but unlike our results, their asymptotic bound does not apply uniformly across the set, and uniform finite-time bounds depend upon a finite action space Blum and Mansour [2007]."
    }, {
      "heading" : "3 Local Regret Concepts",
      "text" : "Let G = (V,E) be a directed graph on the set of actions, i.e., V = A. We do not assume A is finite, but we do assume G has bounded out-degree D = maxa∈V |{b : (a, b) ∈ E}|. This graph can be viewed as defining a notion of locality. The semantics of an edge from a to b is that one should consider possibly taking action b in place of action a. Or rather, if there is no edge from a to b then one need not have any regret for not having taken action b when a was taken. By limiting regret only to the edges in this graph, we get the notion of local regret. Just as with traditional regret, which we will now refer to as global regret, we can define different variants of regret.\nRTlocalinternal = max (a,b)∈E RT,+a,b R T localswap = ∑ a∈A max b:(a,b)∈E RT,+a,b (4)\nLocal internal and local swap regret just involve limiting regret to edges in G. Local external regret is more subtle and requires a notion of edge lengths. For all edges (i, j) ∈ E, let c(i, j) > 0 be the edge’s positive length. Define d(a, b) to be the sum of the edge lengths on a shortest path from vertex a to vertex b, and Eb = {(i, j) ∈ E : d(i, j) = c(i, j) + d(j, b)} to be the set of edges that are on any shortest path to vertex b.\nRTlocalexternal = max b∈A  ∑ (i,j)∈Eb RTi,j/D + (5) Global external regret considers changing all actions to some target action, regardless of locality or distance between the actions. In local external regret, only adjacent actions are considered, and so actions are only replaced with actions that take one step toward the target action. The factor of 1/D scales the regret of any one action by the out-degree, which is the maximum number of actions that could be one-step along a shortest path. This keeps local external regret on the same scale as local swap regret.\nIt is easy to see that these concepts hold the same relationships between each other as their global counterparts.\nRTlocalinternal ≤ RTlocalswap ≤ |A|RTlocalinternal (6) RTlocalexternal ≤ RTlocalswap (7)\nMore interestingly, in complete graphs where there is an edge between every pair of actions (all with unit lengths) and so everything is local, we can exactly equate global and local regret.\nTheorem 1. If G is a complete graph with unit edge lengths then,\nRTlocalinternal = R T internal R T localswap = R T swap and R T localexternal = R T external/D. (8)\nProof.\nRTlocalinternal = max (a,b)∈E RT,+a,b = max a,b∈A RT,+a,b = R T internal (9)\nRTlocalswap = ∑ a∈A max b:(a,b)∈E RT,+a,b = ∑ a∈A max b∈A RT,+a,b = R T swap (10)\nRTlocalexternal = max b∈A ∑ (i,j)∈Eb RT,+i,j /D (11)\n= 1/Dmax b∈A ∑ a∈A RT,+a,b = R T external/D (12)\nSo our concepts of local regret match up with global regret when the graph is complete. Of course, we are not really interested in complete graphs, but rather more intricate locality structures with a large or infinite number of vertices, but a small out-degree. Before going on to present algorithms for minimizing local regret, we consider possible graphs for three different online decision tasks to illustrate where the graphs come from and what form they might take.\nExample 1 (Online Max-3SAT). Consider an online version of Max-3SAT. The task is to choose an assignment for n boolean variables: A = {0, 1}n. After an assignment is chosen a clause is observed; the utility is 1 if the clause is satisfied by the chosen assignment, 0 otherwise. Note that |A| = 2n which is computationally intractable for global regret concepts if n is even moderately large. One possible locality graph for this hypothesis class is the hypercube with an edge from a to b if and only if a and b differ on the assignment of exactly one variable (see Figure 1(a)), and all edges have unit lengths. So the out-degree D for this graph is only n. Local regret, then, corresponds to the regret for not having changed the assignment of just one variable. In essence, minimizing this concept of regret is the online equivalent of local search (e.g., WalkSAT [Selman et al., 1993]) on the maximum satisfiability problem, an offline task where all of the clauses are known up front.\nExample 2 (Online Disjunct Learning). Consider a boolean online classification task where input features are boolean vectors x ∈ {0, 1}n and the target y is also boolean. Consider A = {0, 1}n, to be the set of all disjuncts such that a ∈ A corresponds to the disjunct xi1 ∨ xi2 ∨ . . . ∨ xik where i1≤j≤k are all of the k indices of a such that aij = 1. In this online task, one must repeatedly choose a disjunct and then observe an instance which includes a feature vector and the correct response. There is a utility of 1 if the chosen disjunct over the feature vector results in the correct response; 0 otherwise. Although a very different task, the action space A = {0, 1}n is the same as with Online MaxSAT and we can consider the same locality structure as that proposed for disjuncts: a hypercube with unit length edges for adding or removing a single variable to the disjunction (see Figure 1(a)). And as before |A| = 2n while D = n.\nExample 3 (Online Decision Tree Learning). Imagine the same boolean online classification task for learning disjuncts, but the hypothesis class is the set of all possible decision trees. The number of possible decision trees for n boolean variables is more than a staggering 22 n\n, which for any practical purpose is infinite. We can construct a graph structure that mimics the way decision trees are typically constructed offline, such as with C4.5 [Quinlan, 1993]. In the graph G, add an edge from one decision tree to another if and only if the latter can be constructed by choosing any node (internal or leaf) of the former and replacing the subtree rooted at the node with a decision stump or a label. There is one exception: you cannot replace a non-leaf subtree with a stump splitting on the same variable as that of the root of the subtree. See Figure 1(b) for a portion of the graph. Edges that replace a subtree with a label have length 1, while edges replacing a subtree with a stump (being a more complex change) have distance 1.1. So, we have local regret for not having further refined a leaf or collapsing a subtree to a simpler stump or leaf. Notice that the graph edges in this case are not all symmetric (viz., collapsing edges). In essence, this is the online equivalent of tree splitting algorithms. While |A| ≥ 22n , the out-degree is no more than (n + 1)2n+1. The maximum size of the out-degree still appears disconcertingly large, and we will return to this issue in Section 5 where we show how we can exploit the graph structure to further simplify learning."
    }, {
      "heading" : "4 An Algorithm for Local Swap Regret",
      "text" : "We now present an algorithm for minimizing local swap regret, similar to global swap regret algorithms [Hart and Mas-Colell, 2002; Greenwald and Jafari, 2003], but with substantial differences. The algorithm essentially chooses actions according to the stationary distribution of a Markov process on the graph, with the transition probabilities on the edges being proportional to the accumulated regrets. However there are two caveats that are needed for it to handle infinite graphs: it is prevented from playing beyond a particular distance from a designated root vertex, and there is an internal bias towards the actual actions chosen.\nFormally, let root be some designated vertex. Define d1 to be the unweighted shortest path distance between two vertices. Define the level of a vertex as its distance from root: L(v) = d1(root, v). Note that, L(root) = 0, and ∀(i, j) ∈ E, L(j) ≤ L(i) + 1. All of the algorithms in this paper take a parameter L, and will never choose actions at a level greater than L. In addition, the algorithms all maintain values R̃ti,j (which are biased versions of R t i,j) and use these to compute πtj , the probability of choosing action j at time t. These probabilities are always computed according to the following requirement, which is a generalization of [Hart and Mas-Colell, 2002; Greenwald and Jafari, 2003].\nRequirement 2. Given a parameter L, for all t ≤ T , and some R̃t,+i,j let πt+1 be such that (a) ∑ j∈V π t+1 j = 1, and ∀j ∈ V , πt+1j ≥ 0\n(b) ∀j ∈ V such that L(j) > L, πt+1j = 0. (c) ∀j ∈ V such that 1 ≤ L(j) ≤ L, πt+1j = ∑ i:(i,j)∈E(R̃ t,+ i,j /M)π t+1 i + (1− ∑ k:(j,k)∈E R̃ t,+ j,k /M)π t+1 j (d) πt+1root =∑ i:(i,root)∈E(R̃ t,+ i,root/M)π t+1 i + ∑ j:L(j)=L+1 ∑ i:(i,j)∈E(R̃ t,+ i,j /M)π t+1 i + (1− ∑ j:(root,j)∈E R̃ t,+ root,j/M)π t+1 root\n(e) If there exists j ∈ V such that πt+1j > 0 and ∑\nk:(j,k)∈E R̃ t,+ j,k = 0, then for all j ∈ V where πt+1j > 0,∑\nk:(j,k)∈E R̃ t,+ j,k = 0, and we call such a π t+1 degenerate.\nwhere M = max(i,j)∈E R̃ t,+ i,j . These conditions require π t+1 to be the stationary distribution of the transition function whose probabilities on outgoing edges are proportional to their biased positive regret, with the root vertex as the starting state, and all outgoing transitions from vertices in level L going to the root vertex instead.\nDefinition 2. (b, L)-regret matching is the algorithm that initializes R̃0i,j = 0, chooses actions at time t according to a distribution πt that satisfies Requirement 2 and after choosing action i and observing ut updates R̃ti,j = R̃ t−1 i,j + (ut(j)− ut(i)− b) for all j where (i, j) ∈ E, and for all other (k, l) ∈ E where k 6= i, R̃tk,l = R̃t−1k,l . There are two distinguishing factors of our algorithm from [Hart and Mas-Colell, 2002; Greenwald and Jafari, 2003]: R̃ 6= R, and past a certain distance from the root, we loop back. R̃ differs from R by the bias term, b. This term can be thought of as a bias toward the action selected by the algorithm. This is not the same as approaching the negative orthant with a margin for error. This small amount is only applied to the action taken, which is very different from adding a small margin of error to every edge.\nTheorem 3. For any directed graph with maximum out-degree D and any designated vertex root, (∆/(L + 1), L)regret matching, after T steps, will have expected local swap regret no worse than,\n1 T E[RTlocalswap] ≤ ∆ L+ 1 + ∆ √ D|EL|√ T\n(13)\nwhere EL = {(i, j) ∈ E|L(i) ≤ L}. The proof can be found in Appendix A. The overall structure of the proof is similar to [Blackwell, 1956; Hart and Mas-Colell, 2002; Greenwald and Jafari, 2003] with a few significant changes. As with most algorithms based on Blackwell, if there is an action you do not regret taking, playing that action the next round is “safe”. If not, the key quantity in the proof is a flow fi,j = πt+1i R̃ t,+ i,j for each edge. On most of the graph, the incoming flow is equal to the outgoing flow for each node in levels 1 to L. Since all the flow out from the nodes on one level is equal to the flow into the next, the total flow into (and out of) each level is equal. Thus, the flow out of the last level is only 1/(L+ 1) of the total flow on all edges since there are L+ 1 levels, including the root.\nTraditionally, we wish to show that the incoming flow of an action times the utility minus the outgoing flow of an action times the utility summed over all nodes is nonpositive, and then Blackwell’s condition holds. In traditional proofs, for any given node, the flow in and out are equal, so regardless of the utility, they cancel. For our problem, the flow out of the last level is really a flow into the (L+ 1)st level, not the zeroeth level, so the difference in utilities between the zeroeth level and the (L + 1)st level creates a problem. On the other hand, because we subtract b from whatever action we select, we get to subtract b times the total flow. Since exactly 1/(L + 1) fraction of the flow is going into the (L+ 1)st level, these two discrepancies from the traditional approach exactly cancel. The second term of Equation (13) is a result of the traditional Blackwell approach. In the final analysis, we must account for the amount b we subtract from the regret each round. This means that if we get R̃ to approach the negative orthant, we only have bT local swap regret left. This is the first term of Equation (13)."
    }, {
      "heading" : "5 Exploiting Locality Structure",
      "text" : "The local swap regret algorithm in the previous section successfully drops all dependence on the size of the action set and thus can be applied even for infinite action sets. However, the appearance of |EL| in the bound in Theorem 3 is undesirable as |EL| ∈ O(DL), and L is more likely to be 100 than 2, in order to keep the first term of the bound low. The bound, therefore, practically provides little beyond an asymptotic guarantee for even the simplest setting of Example 1. In this section, we will appeal to (i) the structure in the locality graph, and (ii) local external regret to achieve a more practical regret bound and algorithm."
    }, {
      "heading" : "5.1 Cartesian Product Graphs",
      "text" : "We begin by considering the case of G having a very strong structure, where it can be entirely decomposed into a set of product graphs. In this case, we can show that by independently minimizing local regret in the product graphs we can minimize local regret in the full graph.\nTheorem 4. LetG be a Cartesian product of graphs,G = G1⊗ . . .⊗Gk whereGl = (Vl, El). For all l ∈ {1, . . . , k}, define utl : Vl → R, such that utl(al) = ut( 〈 at1, . . . , a t l−1, al, a t l+1, . . . , a t k 〉 ), so utl is a utility function on the lth component of the action at time t assuming the other components remain unchanged. Let E[l] ⊆ E be the set of edges that change only on the lth component, so {E[l]}l=1,...,k forms a partition of E. Let Dl ≤ D be the maximum degree of Gl. Finally, define\nRT,llocalexternal = max b∈Vl  ∑ (i,j)∈Ebl T∑ t=1 1(atl = i)(u t l(j)− utl(i))/Dl + , where Ebl = {(i, j) ∈ E[l] : d(i, bl) = c(i, j) + d(j, bl)}, i.e., it contains the edges that moves the lth component closer to bl. Then, RTlocalexternal ≤ ∑k l=1R T,l localexternal.\nProof.\nRTlocalexternal = max b∈V  ∑ (i,j)∈Eb RTi,j/D + (14) = max\nb∈V  k∑ l=1 ∑ (i,j)∈E[l]∩Eb RTi,j/D + (15) ≤\nk∑ l=1 max b∈V  ∑ (i,j)∈E[l]∩Eb RTi,j/D + (16) Since Dl ≤ D,\n≤ k∑\nl=1\nmax b∈V  ∑ (i,j)∈E[l]∩Eb RTi,j/Dl + (17) =\nk∑ l=1 max b∈V  ∑ (i,j)∈E[l]∩Eb T∑ t=1 1(at = i)(ut(j)− ut(i))/Dl + (18) =\nk∑ l=1 max b∈V  ∑ (i,j)∈Ebl T∑ t=1 1(at = i)(utl(j)− utl(i))/Dl + (19) =\nk∑ l=1 RT,llocalexternal (20)\nThe implication is that we if we apply independent regret minimization to each factor of our product graph, we can minimize local external regret on the full graph. For example, consider the hypercube graphs from Example 1 and 2. By applying n independent external regret algorithms (the component graphs in this case are 2-vertex complete graphs), the overall local external regret for the graph is at most n times bigger than the factors’ regrets, so under regret matching it is bounded by n∆ √ 2/ √ T . Hence, we are able to handle an exponentially large graph (in n) with local external regret only growing linearly (in n). If the component graphs are not complete graphs, then we can simply apply our local swap regret algorithm from the previous section to the graph factors, which minimizes local external regret as well."
    }, {
      "heading" : "5.2 Color Regret",
      "text" : "Cartesian product graphs are a powerful, but not very general structure. We now substantially generalize the product graph structure, which will allow us to achieve a similar simplification for very general graphs, such as the graph on decision trees in Example 3. The key insight of product graphs is that for any vertex b, an edge moves toward b if and only if its corresponding edge in its component graph moves toward bl. In other words, either all of the edges that correspond to some component edge will be included in the external regret sum, or none of the eges will. We can group together these edges and only worry about the regret of the group and not its constituents. We generalize this fact to graphs which do not have a product structure.\nDefinition 5. An edge-coloring C = {Ci}i=1,2,... for an arbitrary graph G with edge lengths is a partition of E: Ci ⊆ E, ⋃ i Ci = E, and Ci ⋂ Cj = ∅. We say that C is admissble if and only if for all b ∈ V , C ∈ C, and (i, j), (i′, j′) ∈ C, d(i, b) = c(i, j) + d(i, b)⇔ d(i′, b) = c(i′, j′) + d(j′, b). In other words, for any arbitrary target, all of the edges with the same color are on a shortest path, or none of the edges are.\nWe now consider treating all of the edges of the same color as a single entity for regret. This gives us the notion of local colored regret.\nRTlocalcolor = ∑ C∈C  ∑ (i,j)∈C RTi,j + (21) Theorem 6. If C is admissible then RTlocalexternal ≤ RTlocalcolor/D. Proof.\nRTlocalexternal = max b∈A  ∑ (i,j)∈Eb RTi,j/D + (22) = max\nb∈A ∑ C∈C ∑ (i,j)∈C∩Eb RTi,j/D + (23) For a particular target b let Cb = {C ∈ C : C ⊆ Eb}, i.e., Cb is the set of colors that reduces the distance to b. Then by C’s admissibility,\nRTlocalexternal = max b∈A  ∑ C∈Cb ∑ (i,j)∈C RTi,j/D + (24) ≤ max\nb∈A ∑ C∈Cb  ∑ (i,j)∈C RTi,j/D + (25) ≤ ∑ C∈C  ∑ (i,j)∈C RTi,j/D\n+ (26) = RTlocalcolor/D (27)\nSo by minimizing local colored regret, we minimize local external regret. The natural extension of our local swap regret algorithm from the previous section results in an algorithm that can minimize local colored regret.\nDefinition 7. (b, L,C)-colored-regret-matching is the algorithm that initializes R̃0C = 0, for all C ∈ C, chooses actions at time t according to a distribution πt that satisfies Requirement 2 with R̃ti,j ≡ R̃tc(i,j), and after choosing action i and observing ut at time t for all C ∈ C updates R̃tC = R̃t−1C + ∑ j:(i,j)∈C(u t(j)− ut(i)− b).\nTheorem 8. For an arbitrary graph G with maximum degree D, arbitrarily chosen vertex root, and edge coloring C, (∆/(L+ 1), L,C)-colored-regret matching applied after T steps will have expected local colored regret no worse than,\n1 T E[RTlocalcolor] ≤ ∆D L+ 1 + ∆ √ D|CL|√ T\nwhere CL = {C ∈ C|∃(i, j) ∈ C s.t. L(i) ≤ L}.\nThe proof is in Appendix B. The consequence of this bound depends upon the number of colors needed for an admissible coloring. Very small admissible colorings are often possible. The hypercube graph needs only 2n colors to give an admissible coloring, which is exponentially smaller than the total number of edges, n2n. We can also find a reasonably tight coloring for our decision tree graph example, despite being a complex asymmetric graph.\nExample 4 (Colored Decision Tree Learning). Reconsider Example 3 and the graph in Figure 1(b). Recall that an edge exists between one decision tree and another if the latter can be constructed from the former by replacing a subtree at any node (internal or leaf) with a label (edge length 1) or a stump (edge length 1.1). We will color this edge with the pair: (i) the sequence of variable assignments that is required to reach the node being replaced, and (ii) the stump or label that replaces it. This coloring is admissible. We can see this fact by considering a color: the sequence of variable assignments and resulting stump or label. If this color is consistent with the target decision tree (i.e., the sequence exists in the target decision tree, and the variable of the added stump matches the variable split on at that point in the target decision tree) then the color must move you closer to the target tree. A formal proof of its admissibility is very involved and can be found in Appendix C."
    }, {
      "heading" : "6 Experimental Results",
      "text" : "The previous section presented algorithms that minimize local swap and local external regret (by minimizing local colored regret). The regret bounds have no dependence on the size of the graph beyond the graph’s degree, and so provide a guarantee even for infinite graphs. We now explore these algorithms’ practicality as well as illustrate the generality of the concepts by applying them to a diverse set of online problems. The first two tasks we examine, online Max-3SAT and online decision tree learning, have not previously been explored in the online setting. The final task, online disjunct learning, has been explored previously, and will help illustrate some drawbacks of local regret.\nIn all three domains we examine two algorithms. The first minimizes local swap regret by applying (∆/(L+1), L)regret matching with L chosen specifically for the problem. This will be labeled “Local Swap”. The second focuses on local external regret by using a tight, admissible edge-coloring and applying (∆/(L + 1), L,C)-colored-regret matching. This will be labeled simply “Local External”."
    }, {
      "heading" : "6.1 Online Max-3SAT",
      "text" : "First, we consider Example 1. We randomly constructed problem instances with n = 20 boolean variables and 201 clauses each with 3 literals. On each timestep, the algorithms selected an assignment of the variables, a clause was chosen at random from the set, and the algorithm received a utility of 1 if the assignment satisfied the clause, 0 otherwise. This was repeated for 1000 timesteps. The locality graph used was the n-dimensional hypercube from Example 1. The admissible coloring used to minimize local external regret was the 2n coloring that has two colors per variable (one for turning the variable on, and one for turning the variable off). In both cases we set L =∞ and b = 0,\nsince the bounds do not depend on L once it exceeds 20. This also achieved the best performance for both algorithms. The average results over 200 randomly constructed sets of clauses are shown in Figure 2, with 95% confidence bars.\nFigure 2 (a) shows the time-averaged colored regret of the two algorithms, to demonstrate how well the algorithms are actually minimizing regret. Both are decreasing over time, while external regret is decreasing much more rapidly. As expected, swap regret may be a stronger concept, but it is more difficult to minimize. The local external regret algorithm after only one time step can have regret for not having made a particular variable assignment, while local swap regret has to observe regret for this assignment from every possible assignment of the other variables to achieve the same result. This is further demonstrated by the number of regret values each algorithm is tracking: local external regret on average had 34 non-zero regret values, while local swap regret had 4200 non-zero regret values. In summary, external regret provides a powerful form of generalization. Figure 2 (b) shows the fraction of the previous 100 clauses that were satisfied. Two baselines are also presented. A random choice of variable assignments can satisfy 78 of the clauses in expectation. We also ran WalkSAT [Selman et al., 1993] offline on the set of 201 clauses, and on average it was able to satisfy all but 4% of the clauses, which gives an offline lower bound for what is possible. Both substantially outperformed random, with the external regret algorithm nearing the performance of the offline WalkSat."
    }, {
      "heading" : "6.2 Online Decision Tree Learning",
      "text" : "Second, we consider Example 3. We took three datasets from the UCI Machine Learning Repository (each with categorical inputs and a large number of instances): nursery, mushroom, and king-rook versus king-pawn [Frank and Asuncion, 2010]. The categorical attributes were transformed into boolean attributes (which simplified the implementation of the locality graphs) by having a separate boolean feature for each attribute value.1 We made the problems online classification tasks by sampling five instances at random (with replacement) for each timestep, with the utility being the number classified correctly by the algorithm’s chosen decision tree. This was repeated for 1000 timesteps, and so the algorithms classified 5,000 instances in total. The locality graph used was the one described in Example 3. The tight coloring used to minimize local external regret was the one described in Example 4. L was set to 3 for local swap regret, and 100 for local external regret, as this achieved the best performance. Even with the far larger graph, the external regret algorithm was observing nearly one-eighth of the number of non-zero regret values observed by the local swap algorithm. The average results over 50 trials are shown in Figure 3(a)-(c) with 95% confidence bars.\nThe graphs show the average fraction of misclassified instances over the previous 100 timesteps. Two baselines are also plotted: the best single label (i.e., the size of the majority class) and the best decision stump. Both regret algorithms substantially improved on the best label, and local external regret was selecting trees substantially better than the best stump. As a further baseline, we ran the batch algorithm C4.5 in an online fashion, by retraining a decision tree after each timestep using all previously observed examples. C4.5’s performance was impressive, learning highly accurate trees after observing only a small fraction of the data. However, C4.5 has no regret guarantees. As with\n1As a result, there were n = 28 features for nursery, 118 features for mushroom, and 74 features for king-rook versus king-pawn.\nany offline algorithm used in an online fashion, there is an implicit assumption that the past and future data instances are i.i.d.. In our experimental setup, the instances were i.i.d., and as a result C4.5 performed very well. To further illustrate this point, we constructed a simple online classification task where instances with identical attributes were provided with alternating labels. The best label (as well as the single best decision tree) has a 50% accuracy. C4.5 when trained on the previously observed instances, misclassifies every single instance. This is shown along with local regret algorithms in Figure 3 (d)."
    }, {
      "heading" : "6.3 Online Disjunct Learning",
      "text" : "Finally, we examine online disjunct learning as described in Example 2. This task has received considerable attention, notably the celebrated Winnow algorithm [Littlestone, 1988], which is guaranteed to make a finite number of mistakes if the instances can be perfectly classified by some disjunction. Furthermore, the number of mistakes Winnow2 makes, when no disjunction captures the instances, can be bounded by the number of attribute errors (i.e., the number of input attributes that must be flipped to make the disjunction satisfy the instance) made by the best disjunction. In these experiments we compare our algorithms’ performance to that of Winnow2.\nWe looked at two learning tasks. In the first, we generated a random disjunction over n = 20 boolean variables, where a variable was independently included in the disjunction with probability 4/n. Instances were created with uniform random assignments to all of the variables, with a label being true if and only if the chosen disjunct is true for the instance’s assignment. In the second case, we chose instances uniformly at random from a constructed set of\n21 instances: one for each variable with that variable (only) set to true and the label being true, and one with all of the variables assigned the value of true and the label being false. We call this task Winnow Killer. For both tasks, the n-dimensional hypercube from Example 1 was used as the locality graph with the 2n coloring as our admissible coloring, and L =∞ and b = 0. The average results over 50 trials are shown in Figure 4, with 95% confience bars.\nThe graphs plot error rates over the previous 100 instances. Three baselines are plotted: randomly assigning a label (guaranteed to get half of the instances correct on expectation), the best disjunct (which makes no mistakes for random disjunctions and makes 121 mistakes on the Winnow Killer task), and Winnow2. Figure 4 (a) shows the results on random disjunctions. Winnow2 is guaranteed to make a finite number of mistakes and indeed its error rate drops to zero quickly. The local regret concepts, though, have difficulties with random disjunctions. The reason can be easily seen for the case of local external regret. Suppose the first instance is labeled true; the algorithm now has regret for all of the variables that were true in that instance (some of these will be in the target disjunction, but many will not). These variables will now be included in the chosen disjunction for a very long time, as the only regret that one can have for not removing them is if their assignment was the sole reason for misclassifying a false instance. In other words, the problem is that there’s no regret for not removing multiple variables simultaneously as this is not a local change. Winnow2, though, also has issues. It performs very poorly in the Winnow Killer task (in fact, if the instances were ordered it could be made to get every instance wrong), as shown in Figure 4 (b). Since the mistake bound for Winnow2 is with respect to the number of attribute errors, a single mistake by the best disjunction can result in n mistakes by Winnow2. A further issue with Winnow is that while its peformance is tied to the performance of disjunctions, its own hypothesis class is not disjunctions but a thresholded linear function, whereas local regret is playing in the same class of hypotheses that it comparing against."
    }, {
      "heading" : "7 Conclusion",
      "text" : "We introduced a new family of regret concepts based on restricting regret to only nearby hypotheses using a locality graph. We then presented algorithms for minimizing these concepts, even when the number of hypotheses are infinite. Further we showed that we can exploit structure in the graph to achieve tighter bounds and better performance. These new regret concepts mimic local search methods, which are common approaches to offline optimization with intractably hard hypothesis spaces. As such, our concepts and algorithms allows us to make online guarantees, with a similar flavor to their offline counterparts, with these hypothesis spaces.\nThere is a number of interesting directions for future work as well as open problems. Admissible colorings can result in radically improved bounds as well as empirical performance. How can such admissible colorings be constructed for general graphs? What graph structures lead to exponentially small admissible colorings compared to the size of the graph? We can easily construct the minimum admissible coloring for graphs that are recursively constructed as Cartesian product of graphs and complete graphs. While such graphs can have exponentially small admissible colorings,\nthey form a very narrow class of structures. What other structures lead to exponentially small admissible colorings? Furthermore, edge lengths can have a significant impact on the size of the minimum admissible coloring. For example, the decision tree graph from Example 3 was carefully constructed to result in a tight coloring, and, in fact, unit length edges over the same graph would result in an exponentially larger admissible coloring. How can edge lengths be defined to allow for small minimum colorings?"
    }, {
      "heading" : "Acknowledgements",
      "text" : "This work was supported by NSERC and Yahoo! Research, where the first author was a visiting scientist at the time the research was conducted."
    }, {
      "heading" : "A Proof for Local Swap Regret",
      "text" : "At its heart, the Hart and Mas-Colell proof for minimizing internal regret relies on the relationship between Markov chains and flows. The Blackwell condition is (roughly speaking) that the probability flow into an action equals the probability flow out of an action. In the variant here, there are two ways to view this flow. Define f such that for all (i, j) ∈ E, fi,j = πt+1i R̃t,+i,j . Implicitly, f depends on the time t, but we supress this as we always refer to a time t. This flow f is similar to the flows in Hart and Mas-Colell as they apply to the Blackwell condition. However, it lacks the conservation of flow property. Thus, we consider a second flow f ′ which satisfies the conservation of flow. To do this, we consider the levels of the graph. To review, root is a distinct vertex, and, L(v) = d1(root, v). If we consider the flow f as starting from the root, it (roughly) goes from level to level outward from the root until it reaches level L. Then, while f flows to level L + 1 and reaches a dead end (violating the conservation property), f ′ is switched, and flows back to the root. In order to make the proof work, we have to bound the difference between f and f ′. Since this difference is mostly on the flow from level L to level L+ 1, we need to bound the fraction of the total flow that is going out of the last level by showing that this flow is less than the flow going from the root to the first level, and it is less than the flow from the first level to the second level, et cetera.\nFirst we show that for nodes on most levels, the flow in equals the flow out.\nLemma 9. If Requirement 2 holds, then for all j ∈ V such that 1 ≤ L(j) ≤ L,∑ i:(i,j)∈E fi,j = ∑ k:(j,k)∈E fj,k\nCorollary 10. By summing over the nodes in level `, for any level 1 ≤ ` ≤ L,∑ (i,j)∈E:L(j)=` fi,j = ∑ (i,j)∈E:L(i)=` fi,j .\nProof. From Requirement 2(c) we know there exists an M > 0 such that:\nπt+1j = ∑\ni:(i,j)∈E\n(Rt,+i,j /M)π t+1 i + 1− ∑ k:(j,k)∈E Rt,+j,k /M πt+1j (28) πt+1j  ∑ k:(j,k)∈E Rt,+j,k /M  = ∑ i:(i,j)∈E\nRt,+i,j π t+1 i /M (29)∑\nk:(j,k)∈E\nπt+1j R t,+ j,k = ∑ i:(i,j)∈E Rt,+i,j π t+1 i (30)\nThe lemma follows by the definition of fi,j .\nIf we want the conservation of flow to hold for all nodes, then we need to define a slightly different flow. We want to say that the flow which is currently exiting the first L levels (specifically between level L and level L+1) is actually flowing back into the root. So, we want to subtract the edgesE′′ = {(i, j) ∈ E : L(j) ≥ L+1∨L(i) ≥ L+1}, and add the edges E′ = {i ∈ V : L(i) = L} × {root}. For any edge e ∈ E′, define f ′i,j = fi,j + ∑ k:L(k)=L+1,(i,k)∈E fi,k., where fi,j = 0 if (i, j) /∈ E. For any edge (i, j) ∈ E\\(E′ ∪ E′′) where L(i),L(j) ≤ L, f ′i,j = fi,j . Define Ẽ = (E ∪ E′\\E′′).\nThus, we now have a flow over a graph (V, Ẽ), but we must prove conservation of flow. Lemma 11. If Requirement 2 holds, for any i ∈ V ,∑j:(i,j)∈Ẽ f ′i,j = ∑j:(j,i)∈Ẽ f ′j,i Proof. For L(i) ∈ {1 . . . L− 1}, this is a direct result of Requirement 2(c). For when L(i) > L, there is no flow out or in, making the result trivial. For L(i) = 0 (when i = root), this is a direct result of Requirement 2(d). For when\nL(i) = L, note that ∑j:(j,i)∈E fj,i = ∑j:(i,j)∈E fi,j , for all j where (j, i) ∈ E, fj,i = f ′j,i, and for all (i, j) ∈ E where L(j) ∈ {1 . . . L}, fi,j = f ′i,j and that the flow ∑ j:(i,j)∈E,L(j)∈{0,L+1} fi,j = f\n′ i,root, so∑\nj:(j,i)∈E\nf ′j,i = ∑\nj:(j,i)∈E\nfj,i (31)\n= ∑\nj:(i,j)∈E\nfi,j (32)\n= ∑\nj:(i,j)∈E,L(j)∈{0,L+1}\nfi,j + ∑\nj:(i,j)∈E,L(j)∈{1...L}\nfi,j (33)\n= f ′i,root + ∑\nj:(i,j)∈E,L(j)∈{1...L}\nf ′i,j (34)\n= ∑\nj:(i,j)∈E\nf ′i,j . (35)\nLemma 12. If Requirement 2 holds, then:∑ (i,j)∈E fi,j ≥ (L+ 1) ∑ (i,j)∈E:L(j)=L+1 fi,j (36)\n∑ (i,j)∈E:L(i)=0 fi,j ≥ ∑ (i,j)∈E:L(j)=L+1 fi,j (37)\nProof. To obtain an intuition, consider the case where all outgoing edges from level j go to level j + 1 (modulo the last level). In this case, the flow from level 0 all goes to level 1, from there goes to level 2, and so forth until it reaches level L and then returns to level 0. Thus, the inflows and outflows of all the levels would be equal. The problem with this is that outgoing edges from level j can go to other nodes in j, or nodes in level j − 1, et cetera. At an intuitive level, a backwards flow would not make more flow through the final level, any more than an eddy would somehow create water at the mouth of a river, and we must simply formally prove this.\nFirst, we define gi,j = ∑ (k,l)∈E:L(k)=i,L(l)=j f ′ i,j , the total flow between levels. By Lemma 11 for all i ∈\nV , ∑\nj f ′ i,j = ∑ j f ′ j,i, so the aggregate flow satisfies the conservation of flow, namely that for all i, ∑L j=0 gi,j =∑L\nj=0 gj,i. Also, if j > i + 1, then gi,j = 0. Define ni = gi,i+1, the flow between one level and the next. Since f , f ′, and g are just different groupings of the total flow throughout the graph, ∑ (i,j)∈E fi,j = ∑ (i,j)∈Ẽ f\n′ i,j =∑L\ni=0 ∑L j=0 gi,j . Since for all i, j ∈ V , f ′i,j ≥ 0, then for all i, j, gi,j ≥ 0. gL,0 + ∑L−1 i=0 ni ≤ ∑ (i,j)∈E fi,j .\nMoreover, n0 = g0,1 = ∑ j:(root,j)∈E f ′ root,j = ∑ j:(root,j)∈E froot,j , and gL,0 ≥ ∑ (i,j)∈E:L(j)=L+1 fi,j . So if we\nprove that for all i, gL,0 ≤ ni, then gL,0 ≤ n0 and that gL,0(L+ 1) ≤ gL,0 + ∑L−1\ni=0 ni, we have proven the lemma. First, we identify this backwards flow. Define δi to be the flow that originates at level i or above and flows back to a lower level. Formally, define δ0 = 0, and δi = ∑\ni′<i,j′≥i gj′,i′ − gL,0. Note that δi ≥ 0. Thus, for all i where 0 < i < L:\nδi − δi+1 =  ∑ i′<i,j′≥i gj′,i′ −  ∑ i′<i+1,j′≥i+1 gj′,i′  (38) δi − δi+1 =\n ∑ i′<i,j′=i gj′,i′ +  ∑ i′<i,j′≥i+1 gj′,i′ −  ∑ i′=i,j′≥i+1 gj′,i′ −  ∑ i′<i,j′≥i+1 gj′,i′  (39) δi − δi+1 =\n ∑ i′<i,j′=i gj′,i′ −  ∑ i′=i,j′≥i+1 gj′,i′  (40) δi − δi+1 =\n(∑ i′<i gi,i′ ) −  ∑ j′≥i+1 gj′,i  (41) δi − δi+1 = ( gi,i +\n∑ i′<i gi,i′\n) − gi,i + ∑ j′≥i+1 gj′,i  (42) δi − δi+1 =\n∑ i′≤i gi,i′ − ∑ j′≥i gj′,i  (43) Since gi,i+1 = ni, and gi−1,i = ni−1,\nδi − δi+1 = (gi,i+1 − ni) +∑ i′≤i gi,i′ − (gi−1,i − ni−1) + ∑ j′≥i gj′,i  (44) δi − δi+1 =\n−ni + ∑ i′≤i+1 gi,i′ − −ni−1 + ∑ j′≥i−1 gj′,i  (45) Since g represents the level graph, gi,i′ = 0 if i′ > i+ 1, or put another way, gj′,i = 0 if j′ < i− 1, so\nδi − δi+1 = ( −ni +\n∑ i′ gi,i′\n) − −ni−1 +∑ j′ gj′,i  (46) δi − δi+1 = ni−1 − ni (47)\nSo, for all 0 ≤ i < L− 1:\nδi+1 − δi+2 = ni − ni+1 (48) ni = δi+1 − δi+2 + ni+1 (49)\nFor n0, note that ∑ i gi,0 = g0,0 + δ1 + gL,0, and ∑\ni g0,i = g0,0 + n0, so g0,0 + δ1 + gL,0 = g0,0 + n0, and gL,0 = n0 − δ1. This is the base case in a recursive proof that for all i < L, gL,0 = ni − δi. If we wish to prove it holds for i+ 1, then we assume it holds for i, or gL,0 = ni − δi. By Equation (49), for i < L− 1:\ngL,0 = (δi+1 − δi+2 + ni+1)− δi (50) = ni+1 − δi+1 (51)\nSince δi ≥ 0, this implies that for i < T , gL,0 ≤ ni, which completes the proof.\nLemma 13. If Requirements 1 and 2 hold, and b = ∆/(L+1), then ∑\n(i,j)∈E R̃ t,+ i,j π t+1 i (u t+1(j)−ut+1(i)− b) ≤ 0.\nProof. First, consider the case where πt is degenerate. Then, whenever πt+1i > 0, we know R t,+ i,j = 0 for all (i, j) ∈ E, and so our sum of interest is exactly 0. Note that, since fi,j = R̃+i,jπt+1i , what we need to prove is:∑ (i,j)∈E fi,j(u t+1(j)− ut+1(i)− b) ≤ 0 (52)\n ∑ (i,j)∈E fi,j(u t+1(j)− ut+1(i)) − b ∑ (i,j)∈E fi,j ≤ 0. (53)\nSuppose πt is not degenerate. We examine Equation (53)’s two summations. Notice that only edges (i, j) where πt+1i > 0 have fi,j 6= 0, and by Requirement 2(e) this is only true if L(i) ≤ L. Also, fi,j > 0 if and only if 0 ≤ L(i) ≤ L and 1 ≤ L(j) ≤ L+ 1 (because level zero has no incoming edges), so:∑\n(i,j)∈E\nfi,j(u t+1(j)− ut+1(i)) = ∑ (i,j)∈E fi,ju t+1(j)− ∑ (i,j)∈E fi,ju t+1(i) (54)\n= L+1∑ `=1 ∑ (i,j)∈E:L(j)=` fi,ju t+1(j)− L∑ `=0 ∑ (i,j)∈E:L(i)=` fi,ju t+1(i). (55)\nRenaming the dummy variables in the second term and then combining:∑ (i,j)∈E fi,j(u t+1(j)− ut+1(i)) = L+1∑ `=1 ∑ (i,j)∈E:L(j)=` fi,ju t+1(j)− L∑ `=0 ∑ (j,k)∈E:L(j)=` fj,ku t+1(j) (56)\n= L∑ `=1  ∑ (i,j)∈E:L(j)=` fi,ju t+1(j)− ∑ (j,k)∈E:L(j)=` fj,ku t+1(j)  +\n∑ (i,j)∈E:L(j)=L+1 fi,ju t+1(j)− ∑ (j,k)∈E:L(j)=0 fj,ku t+1(j). (57)\nFirst, we show that any term between 1 and L is zero. For any 1 ≤ ` ≤ L, by summing over nodes in level `:\n∑ (i,j)∈E:L(j)=` fi,ju t+1(j)− ∑ (j,k)∈E:L(j)=` fj,ku t+1(j) = ∑ j:L(j)=`  ∑ i:(i,j)∈E fi,ju t+1(j)− ∑ k:(j,k)∈E fj,ku t+1(j)  (58)\n= ∑\nj:L(j)=`\nut+1(j)  ∑ i:(i,j)∈E fi,j − ∑ k:(j,k)∈E fj,k  . (59) By Lemma 9, ∑ i:(i,j)∈E fi,j =\n∑ k:(j,k)∈E fj,k, so these terms are zero, leaving:∑\n(i,j)∈E\nfi,j(u t+1(j)− ut+1(i)) = ∑ (i,j)∈E:L(j)=L+1 fi,ju t+1(j)− ∑ (j,k)∈E:L(j)=0 fj,ku t+1(j). (60)\nIf L(j) = 0, then j = root:∑ (i,j)∈E fi,j(u t+1(j)− ut+1(i)) = ∑ (i,j)∈E:L(j)=L+1 fi,ju t+1(j)− ∑ (j,k)∈E:L(j)=0 fj,ku t+1(root). (61)\nMoreover, for any j, ut+1(j)− ut+1(root) ≤ ∆, so:∑ (i,j)∈E fi,j(u t+1(j)− ut+1(i)) ≤ ∑ (i,j)∈E:L(j)=L+1 fi,j(u t+1(root) + ∆)− ∑ (j,k)∈E:L(j)=0 fj,ku t+1(root) (62)\n≤∆ ∑\n(i,j)∈E:L(j)=L+1\nfi,j + u t+1(root)  ∑ (i,j)∈E:L(j)=L+1 fi,j − ∑ (j,k)∈E:L(j)=0 fj,k  . (63)\nBy Lemma 12, Equation (37), the flow into level L + 1 is less than or equal to the flow out of level 0, so the last part is nonpositive and: ∑\n(i,j)∈E\nfi,j(u t+1(j)− ut+1(i)) ≤∆ ∑ (i,j)∈E:L(j)=L+1 fi,j (64)\nFrom Lemm 12, Equation (36), we can show that the second term of Equation (53) equals:\nb ∑\n(i,j)∈E\nfi,j ≥ b(L+ 1) ∑\n(i,j):L(j)=L+1\nfi,j (65)\nPutting Equations (65) and (64) together with the fact that b = ∆/(L+ 1), we get,∑ (i,j)∈E fi,j(u t+1(j)− ut+1(i)− b) ≤ ∆ ∑ (i,j):L(j)=L+1 fi,j − b(L+ 1) ∑ (i,j):L(j)=L+1 fi,j (66)\n≤ (∆− b(L+ 1)) ∑\n(i,j):L(j)=L+1\nfi,j = 0 (67)\nwhich is what we were trying to prove.\nLemma 13 is very close to the Blackwell condition, but not identical, so we sketch a quick variation on a special case of Blackwell’s theorem so we can apply it to our problem.\nFact 14. (a+ b)+ ≤ a+ + b+\nLemma 15. [(a+ b)+]2 ≤ (a+ + b)2\nProof. 1. If a, b ≥ 0: (a+ b)2 ≤ (a+ b)2\n2. If a, b ≤ 0: [(a+ b)+]2 = 0 ≤ (a+ + b)2.\n3. If a ≥ 0, b ≤ 0: if −b ≥ a, then [(a+ b)+]2 = 0 ≤ (a+ + b)2, otherwise [(a+ b)+]2 = (a+ b)2 = (a+ + b)2.\n4. If a ≤ 0, b ≥ 0: then if −a ≥ b, then[(a+ b)+]2 = 0 ≤ (a+ + b)2, otherwise, [(a+ b)+]2 = (a+ b)2 ≤ b2 = (a+ + b)2.\nFact 16. If ai=1...n ≥ 0 then ∑n i=1 ai ≤ √ |n|∑ni=1 a2i .\nFact 17. E [X]2 ≤ E [ X2 ]\nWe restate Theorem 3 from Section 4:\nTheorem 3. For any directed graph with maximum out-degree D and any designated vertex root, (∆/(L + 1), L)regret matching, after T steps, will have expected local swap regret no worse than,\n1 T E[RTlocalswap] ≤ ∆ L+ 1 + ∆ √ D|EL|√ T\n(13)\nwhere EL = {(i, j) ∈ E|L(i) ≤ L}.\nProof.\nE[RTlocalswap] = E ∑ i∈V ( max j:(i,j)∈E T∑ t=1 1(at = i)(ut(j)− ut(i)) )+ (68)\n= E ∑ i∈V ( max j:(i,j)∈E T∑ t=1 1(at = i)(ut(j)− ut(i)− b+ b) )+ (69)\n= E ∑ i∈V ( max j:(i,j)∈E ( R̃Ti,j + T∑ t=1 1(at = i)b ))+ (70) = E\n∑ i∈V (( T∑ t=1 1(at = i)b ) + max j:(i,j)∈E R̃Ti,j )+ (71) ≤ E\n[∑ i∈V (( T∑ t=1 1(at = i)b ) + ( max j:(i,j)∈E R̃Ti,j )+)] (72)\n= E [ bT +\n∑ i∈V max j:(i,j)∈E R̃T,+i,j\n] (73)\n≤ E bT +∑ i∈V ∑ j:(i,j)∈E R̃T,+i,j  (74) = bT +\n∑ (i,j)∈EL E [ R̃T,+i,j ] (75)\nBy Facts 16 and 17,\n≤ bT + |EL| ∑ (i,j)∈EL E [ R̃T,+i,j ]2 12 (76) ≤ bT +\n|EL| ∑ (i,j)∈EL E [ (R̃T,+i,j ) 2 ] 12 (77)\nWe can bound the inner term as follows, using Lemma 15:∑ (i,j)∈EL E [ (R̃T,+i,j ) 2 ] ≤ ∑ (i,j)∈EL E [ (R̃T−1,+i,j + 1(a T = i)(uT (j)− uT (i)− b))2 ]\n(78)\n= ∑\n(i,j)∈EL\nE [( R̃T−1,+i,j )2] + ∑ (i,j)∈EL E [ (1(aT = i)(uT (j)− uT (i)− b))2 ] (79)\n+ ∑\n(i,j)∈EL\nE [ 2R̃T−1,+i,j 1(a T = i)(uT (j)− uT (i)− b) ]\n= ∑\n(i,j)∈EL\nE [( R̃T−1,+i,j )2] + E  ∑ (i,j)∈EL (1(aT = i)(uT (j)− uT (i)− b))2  (80)\n+ 2 ∑\na1,...,T−1,u1,...,T−1 E  ∑ (i,j)∈EL R̃T−1,+i,j π T i (u T (j)− uT (i)− b) ∣∣∣∣a1,...,T−1, u1,...,T−1 × Pr[a1,...,T−1, u1,...,T−1] ) (81)\nBy Lemma 13, ∑\n(i,j)∈EL R̃ T−1,+ i,j π T i (u T (j)− uT (i)− b) ≤ 0 regardless of the previous history.\n∑ (i,j)∈EL E [ (R̃T,+i,j ) 2 ] ≤ ∑ (i,j)∈EL E [( R̃T−1,+i,j )2] + E  ∑ (i,j)∈EL (1(aT = i)(∆− b))2  (82)\n≤ ∑\n(i,j)∈EL\nE [( R̃T−1,+i,j )2] +D(∆− b)2 (83)\n≤ TD(∆− b)2 ≤ TD ( ∆ L\nL+ 1\n)2 (84)\nPutting these two pieces together, we get,\nE[RTlocalswap] ≤ bT + |EL| ∑ (i,j)∈EL E [ (RT,+i,j ) 2 ] 12 (85)\n≤ bT + √ |EL|TD ( ∆ L\nL+ 1\n)2 (86)\n≤ ∆T L+ 1\n+ √ TD|EL|∆ L\nL+ 1 (87)\n1 T E[RTlocalswap] ≤ ∆ L+ 1 + ∆ √ D|EL|√ T\n(88)"
    }, {
      "heading" : "B Proof for Color Regret",
      "text" : "Requirement 3. Let C be a countable (but possibly infinite) set of colors. The edge coloring c : E → C is such that c(i, j) = c(i, k)⇔ j = k.\nWe restate Theorem 8 from Section 5.2:\nTheorem 8. For an arbitrary graph G with maximum degree D, arbitrarily chosen vertex root, and edge coloring C, (∆/(L+ 1), L,C)-colored-regret matching applied after T steps will have expected local colored regret no worse than,\n1 T E[RTlocalcolor] ≤ ∆D L+ 1 + ∆ √ D|CL|√ T\nwhere CL = {C ∈ C|∃(i, j) ∈ C s.t. L(i) ≤ L}. Proof. First, we show that ∑\nc∈C R̃ t,+ c ∑ (i,j)∈E c(i,j)=c πt+1i (u t+1(j)− ut+1(i)− b)) ≤ 0.\n∑ c∈C R̃t,+c ∑\n(i,j)∈E c(i,j)=c\nπt+1i (u t+1(j)− ut+1(i)− b)) = ∑ c∈C ∑ (i,j)∈E c(i,j)=c R̃t,+c π t+1 i (u t+1(j)− ut+1(i)− b)) (89)\n= ∑ c∈C ∑ (i,j)∈E c(i,j)=c R̃t,+i,j π t+1 i (u t+1(j)− ut+1(i)− b)) (90)\nBy Lemma 13:∑ c∈C R̃t,+c ∑\n(i,j)∈E c(i,j)=c\nπt+1i (u t+1(j)− ut+1(i)− b)) = ∑ (i,j)∈E R̃t,+i,j π t+1 i (u t+1(j)− ut+1(i)− b)) ≤ 0 (91)\nNow we can bound our quantity of interest.\nE[RTlocalcolor] = E ∑ c∈C  ∑ (i,j)∈E c(i,j)=c T∑ t=1 1(at = i)(ut(j)− ut(i))  + (92)\n= E ∑ c∈C  ∑ (i,j)∈E c(i,j)=c T∑ t=1 1(at = i)(ut(j)− ut(i)− b+ b)  + (93)\n= E ∑ c∈C R̃Tc +  ∑\n(i,j)∈E c(i,j)=c\nT∑ t=1 1(at = i)b   + (94)\n≤ E ∑ c∈C R̃T,+c +  ∑\n(i,j)∈E c(i,j)=c\nT∑ t=1 1(at = i)b    (95)\n= E ∑ c∈C ∑ (i,j)∈E c(i,j)=c T∑ t=1 1(at = i)b+ ∑ c∈C RT,+c  (96) ≤ E [ bTD +\n∑ c∈C R̃T,+c\n] (97)\n= bTD + ∑ c∈CL E [ R̃T,+c ] (98)\n≤ bTD + ( |CL|\n∑ c∈CL E [ R̃T,+c ]2) 12 (99)\n≤ bTD + ( |CL|\n∑ c∈CL E [ (R̃T,+c ) 2 ]) 12\n(100)\nWe can bound the inner term as follows,∑ c∈CL E [ (R̃T,+c ) 2 ] ≤ ∑ c∈CL E [ (R̃Tc ) 2 ]\n(101)\n= ∑ c∈CL E\n R̃T−1c + ∑\n(i,j)∈E c(i,j)=c\n1(aT = i)(uT (j)− uT (i)− b)  2 (102)\n= ∑ c∈CL E [ (R̃T−1c ) 2 ] + ∑ c∈CL E\n  ∑\n(i,j)∈E c(i,j)=c\n1(aT = i)(uT (j)− uT (i)− b)  2 (103)\n+ ∑ c∈CL E 2R̃T−1c ∑ (i,j)∈E c(i,j)=c 1(aT = i)(uT (j)− uT (i)− b) \n= ∑ c∈CL E [ (R̃T−1c ) 2 ] + ∑ c∈CL E\n  ∑\n(i,j)∈E c(i,j)=c\n1(aT = i)(uT (j)− uT (i)− b)  2 (104)\n+ 2 ∑ c∈CL R̃T−1c ∑\n(i,j)∈E c(i,j)=c\nπTi (u T (j)− uT (i)− b)\n≤ ∑ c∈CL E [ (R̃T−1c ) 2 ] + ∑ c∈CL E\n  ∑\n(i,j)∈E c(i,j)=c\n1(aT = i)(uT (j)− uT (i)− b)  2 (105)\n≤ ∑ c∈CL E [ (R̃T−1c ) 2 ] + (∆− b)2 ∑ c∈CL E\n  ∑\n(i,j)∈E c(i,j)=c\n1(aT = i)  2 (106)\nBecause only one action is taken, and for each color only one edge originating at an action can have that color,∑ (i,j)∈E c(i,j)=c 1(aT = i) ∈ {0, 1}:\n∑ c∈CL E [ (R̃T,+c ) 2 ] ≤ ∑ c∈CL E [ (R̃T−1c ) 2 ] + (∆− b)2 ∑ c∈CL E\n  ∑\n(i,j)∈E c(i,j)=c\n1(aT = i)   (107)\n= ∑ c∈CL E [ (R̃T−1c ) 2 ] +D(∆− b)2 (108)\n≤ TD(∆− b)2 ≤ TD ( ∆ L\nL+ 1\n)2 (109)\nPutting these two pieces together, we get,\nE[RTcolorswap] ≤ bTD + ( |CL| ∑ c∈CL E [ (R̃T,+c ) 2 ]) 12\n(110)\n≤ bTD + √ |CL|TD ( ∆ L\nL+ 1\n)2 (111)\n≤ ∆DT L+ 1\n+ √ TD|EL|∆ L\nL+ 1 (112)\n1 T E[RTcolorswap] ≤ ∆D L+ 1 + ∆ √ D|CL|√ T\n(113)"
    }, {
      "heading" : "C Decision Tree Graphs",
      "text" : "A decision tree is a representation of a hypothesis. Given an instance space where there are a finite number of binary features, a decision tree can represent an arbitrary hypothesis. We describe decision trees recursively: the simplest trees are leaves, which represent constant functions. More complex trees have two subtrees, and a root node labeled with a variable. A subtree cannot have a variable that is referred to in the root.\nWe define Tk(S) recursively, where Tk(S) will be the set of trees of depth k or less over the variable set S. Define the set T0(S) = {true, false}. Define Tk(S) such that:\nTk(S) = Tk−1(S) ⋃ s∈S ({s} × Tk−1(S\\{s})× Tk−1(S\\{s})) (114)\nDefine T ∗(S) = T|S|(S) to be the set of all decision trees over the variables S. Three example decision trees in T ∗({x1, x2}) are (x1, true, false), true, and (x1, (x2, true, false), false). Suppose we have an example x, mapping variables to {true, false}. For any tree t, we can recursively define t(x):\n1. If t ∈ T0, then t(x) = t.\n2. If t ∈ Tk and x(t1) = true, then t(x) = t2(x).\n3. If t ∈ Tk and x(t1) = false, then t(x) = t3(x). Define P = {p ∈ (S × {true, false})|S| : ∀i 6= j, pi,1 6= pj,1} to be the paths in the trees without repeating variables. We can talk about whether a path is in a tree. Define Vp(t) to be a function from T ∗ to S ∪ {true, false, ∅}, where Vp(t) = ∅ if the path p is not present in the tree, and otherwise Vp(t) is the value of the node at the end of the path. Formally,\nV∅(t) = { t if t ∈ T0 t1 otherwise\n(115)\nV(v,l)◦p(t) = ∅ if t ∈ T0 or t1 6= vVp(t2) if t /∈ T0 and t1 = v and l = true Vp(t3) if t /∈ T0 and t1 = v and l = false\n(116)\nGiven a path p ∈ P , a tree t′ ∈ T ∗,define Rp,t′(t) to replace the tree at p with t′ if Vp(t) 6= ∅. Formally:\nR∅,t′(t) = t ′ (117)\nR(v,l)◦p,t′(t) = t if t ∈ T0 or t1 6= v(t1, Rp,t′(t2), t3) if t /∈ T0 and t1 = v and l = true (t1, t2, Rp(t3)) if t /∈ T0 and t1 = v and l = false\n(118)\nConsider the following operations on decision trees:\n1. ReplaceWithNode(p, v, l1, l2) = Rp,(v,l1,l2) (where it applies): If there exists a node or leaf at path p, replace it with a decision stump with variable v, with label l1 on the true branch, and label l2 on the false branch, but only if Vp(t) 6= v.\n2. ReplaceWithLeaf(p, l1) = Rp,l1 : If there exists a node or leaf at path p, replace it with a leaf l1.\nThese operations create the edges between trees: we will determine how to color them later. BecauseReplaceWithNode is a more complex operation, an edge created byReplaceWithNodewill have length 1.1, whereasReplaceWithLeaf will have length 1.0. This weighting is important: otherwise, consider the following sequence of trees:\n(X, true, false) (false)\n(X, false, true)\nIf splitting was the same length as changing leaves, this bizarre path would be a shortest path between (X, true, false) and (X, false, true). In general, when designing this distance function over trees, a critical concern was whether unnecessary reconstruction would be on a shortest path. For example, a shortest path from (X, (Y, true, false), (Z, false, true)) to (X, (Y, false, true), (Z, true, false)) could pass through false, (X, true, false), (X, (Y, false, true), false). But, since replacing something with a decision tree costs slightly more than changing a leaf, we avoid this.\nMore generally, if the decision about whether or not an edge is on the shortest path can be made locally, then this reduces the number of colors required. Thus, massively reconstructing the root because the leaves are wrong is not only counterintuitive, it makes the algorithm slower and more complex.\nWe first hypothesize a shortest path distance function between trees based on these operations, and then we will prove it satisfies the above operations. Note that this function is not symmetric, because the shortest path distance function on a directed graph is not always symmetric.\nGiven two decision trees A and B, a decision node a in A and a decision node b are in structural agreement if they are on the same path p, and they are labeled with the same variable. A decision node in B that does not agree with a decision node in A is in structural disagreement with A. Given a leaf in B that has a parent that is in structural agreement with A, if the leaf is not present in A, it is in leaf disagreement with A.\nDefine d∗s(A,B) to be the structural disagreement distance between A and B, the number of nodes in B that are in structural disagreement with A. Define d∗l (A,B) to be the leaf disagreement distance between A and B, the number of leaves in B in disagreement with A. Define d∗(A,B) = 1.1d∗s(A,B) + d ∗ l (A,B).\nIntuitively, this distance represents the fact that an example shortest path from A to B can be generated by first fixing all label disagreements between A and B, and then applying ReplaceWithNode to create every node in B that is in structural disagreement with A (correctly labeling leaves where appropriate).\nFact 18. If d : V × V → Z+ is the shortest distance function on a completely connected directed graph (V,E), then for any i, j ∈ V where (i, j) /∈ E, there exists a k such that (i, k) ∈ E and d(i, j) = d(i, k) + d(k, j). Theorem 19. d∗ : V × V → Z+ corresponds to the shortest distance function on a completely connected directed graph (V,E) if there exists a ∆ > 0 and a δ = ∆/2 such that the following properties hold:\n1. For all a, b ∈ V , d∗(a, b) = 0 iff a = b. 2. For all a, b ∈ V , d∗(a, b) > δ iff a 6= b. 3. For all a, b ∈ V , if a 6= b there exists a c ∈ V such that d∗(a, c) ≤ ∆ and d∗(a, b) ≥ d∗(a, c) + d∗(c, b). 4. For all a, b, c ∈ V , if d∗(a, c) ≤ ∆, then d∗(a, b) ≤ d∗(a, c) + d∗(c, b).\nProof. Observe that the graph (V,E) with edges E = {(i, j) ∈ V 2 : d∗(i, j) ≤ ∆} where the weight of an edge (i, j) ∈ E is d∗(i, j), is a good candidate for the graph under consideration. We prove this in two steps. We first prove by induction that d(i, j) ≤ d∗(i, j). Then, leveraging this, we prove by induction that d(i, j) = d∗(i, j).\nFirst, we prove that if d∗(i, j) ≤ ∆, then d(i, j) = d∗(i, j). First, observe that if d∗(i, j) = 0, then i = j, so d(i, j) = 0. Secondly, if d∗(i, j) ∈ (0,∆], then there exists an edge (i, j) ∈ E so d(i, j) ≤ d∗(i, j). Since each edge is larger than ∆/2, for any path of length 2 or greater, the length is larger than ∆, so only a direct path can be less than or equal to ∆. This establishes that there is no path between i and j shorter than the direct edge.\nFor any nonnegative integer k, define P (k) to be the property that for any i, j ∈ V , if the distance d∗(i, j) ≤ kδ, the shortest distance between two vertices in this graph d(i, j) is less than or equal to d∗(i, j). This holds for P (0), P (1), and P (2) because of the paragraph above. Now, suppose that P (k) holds for k ≥ 2, we need to establish it holds for P (k + 1). Consider some pair (i, j) ∈ V where d∗(i, j) ∈ (kδ, (k + 1)δ], then i 6= j, and by condition 3, there exists a k where d∗(i, k) ≤ ∆ and d∗(i, j) ≥ d∗(i, k) + d∗(k, j). Since d∗(i, j) ≤ (k + 1)δ and d∗(i, j) > δ, d∗(k, j) < kδ, so d∗(k, j) = d(k, j). From the paragraph above, d(i, k) = d∗(i, k), so d∗(i, j) ≥ d(i, k) + d(k, j), and by the triangle inequality on d, d∗(i, j) ≥ d(i, j).\nThus, since for all (i, j) ∈ V there exists a k where d∗(i, j) ≤ kδ, for all (i, j) ∈ V , d(i, j) ≤ d∗(i, j). Next, we prove that if d(i, j) ≤ ∆, then d(i, j) = d∗(i, j). First, observe that if d(i, j) = 0, then i = j, so d∗(i, j) = 0. Secondly, if (i, j) /∈ E, then the distance between i and j must be greater than ∆, because each edge is larger than ∆/2. Therefore, if d(i, j) ∈ (0,∆] there is a direct edge between i and j with distance d∗(i, j), so d∗(i, j) ≤ ∆, and so by the second paragraph d(i, j) = d∗(i, j).\nDefine Q(k) to be the property for any (i, j) ∈ V , if d(i, j) ≤ kδ then d(i, j) = d∗(i, j). Q(0), Q(1) and Q(2) hold from the above paragraph. Now, suppose that Q(k) holds for some k ≥ 2, we need to establish the property for Q(k + 1). Consider some pair (i, j) ∈ V where d(i, j) ∈ (kδ, (k + 1)δ], then i 6= j, and by condition 18, there exists a k where there exists an edge from i to k and d(i, j) = d(i, k) + d(k, j). Since there exists an edge (i, k), then d(i, k) ≤ ∆ and d(i, k) = d∗(i, k) > δ. Thus, d(k, j) ≤ δ(k + 1) − δ ≤ δk. so d(k, j) = d∗(k, j). Moreover, by condition 4, d∗(i, j) ≤ d∗(i, k) + d∗(k, j) = d(i, j). Thus, since we know that d∗(i, j) ≥ d(i, j), then d∗(i, j) = d(i, j).\nTherefore, since d∗(i, j) = d(i, j), and d is the shortest distance for graph (V,E), then d∗(i, j) is a shortest distance function for a weighted graph.\nLemma 20. For the decision tree metric d∗ above, for any two trees A,B where A 6= B, there exists a tree C such that d∗(A,C) ≤ 1.1 and d∗(A,B) ≥ d∗(A,C) + d∗(C,B).\nProof. If B has a leaf at the root, then set C = B. Suppose that, given A and B, there is label disagreement. Find the a node with label disagreement, and correct all the labels in A to form C. This reduces the number of nodes with label disagreement by one, and the decision node disagreement stays the same.\nSuppose that, given A and B, there no label disagreement, but there is structural disagreement. Then select a node d which has decision node disagreement. Define C to be a tree where we replace node d with the corresponding node in tree B, with leaves that agree with the children of d if d has children, and arbitrary otherwise. This reduces the structural disagreement by one. It does not increase the label disagreement, because if d has children with labels in B, it has those same children in C.\nFinally, if A and B have no label disagreement or structural disagreement, then they are the same tree and have distance 0.\nBefore proving a lower bound, we focus on a particular case. Namely, that changing a correct decision node of a tree to have the wrong variable cannot decrease the distance.\nLemma 21. Given two trees A and B and a subtree S in B, if nS is the number of nodes in agreement with B in the subtree S, and lS is the number of leaves in disagreement with A in S, then lS ≤ nS + 1.\nProof. We prove this by recursion on the size of the subtree S inB. If S is of size 1, then S is a leaf inB, then nS = 0 and lS ≤ 1, so the result holds. Suppose we have proven this for all subtrees S′ of size less than S. If S is rooted at a node in disagreement, then ns = 0 and lS = 0, and the result holds (we don’t need induction for this case). If S is rooted at a node x in agreement, then define Strue to be the subtree of the node down the edge labeled true leaving x, and define Sfalse to be the subtree down the edge labeled false leaving x. |Strue| < |S| and |Sfalse| < |S|, so by induction lStrue ≤ nStrue + 1 and lSfalse ≤ nSfalse + 1. Since x is a node in agreement, lS = lStrue + lSfalse , and therefore:\nlS ≤ nStrue + nSfalse + 1 + 1 (119) (120)\nAgain, since x is a node in agreement, nStrue + nSfalse + 1 = nS , so:\nlS ≤ nS + 1. (121)\nWe will use this fact in several places in the resulting proofs.\nLemma 22. Given two trees A and B which agree on node y, if you change y in A to a node x or leaf to create C, then d∗(A,B) < d∗(C,B) + 1.\nProof. If S is the subtree rooted at y in B, then d∗s(A,B) + nS = d ∗ s(C,B) and d ∗ l (A,B) − lS = d∗l (C,B). By definition, d∗(A,B) = d∗(C,B) + 1.1nS − lS . Since y is in agreement, nS ≥ 1. By Lemma 21, we know that lS ≤ nS + 1, so\nd∗(A,B) = d∗(C,B) + 1.1nS − (nS + 1) (122) d∗(A,B) = d∗(C,B) + 0.1nS + 1 (123)\nSince ns ≥ 1, 0.1ns ≥ 0.1 > 0, so:\nd∗(A,B) < d∗(C,B) + 1 (124)\nLemma 23. For the decision tree metric d∗ above, for any two trees A,B where A 6= B, then for any C such that d∗(A,C) ≤ ∆, d∗(A,B) ≤ d∗(A,C) + d∗(C,B).\nProof. First, observe that C has “one” change from A, which can be that:\n1. C has a decision node splitting on variable x where A had a decision node splitting on variable y.\n2. C has a decision node splitting on variable x where A had a leaf l.\n3. A has a node x that was changed to a leaf.\n4. C has a leaf where A had a node.\nIn the first case, there is a question of whether or not the decision node y exists in B. If so, then the structural disagreement has been reduced by one. However, the leaf disagreement is unchanged or increased by one, so d∗(A,B) ≤ 1.1 +d∗(C,B) = d∗(A,C) +d∗(C,B). If y is not in B, and x is not in B, then d∗(A,B) = d∗(C,B) < 1.1+d∗(C,B) = d∗(A,C)+d∗(C,B). If y is inB, by Lemma 22, then d∗(A,B) < d∗(C,B)+1 < 1.1+d∗(C,B) = d∗(A,C) + d∗(C,B).\nFor the second case, if the new node in C agrees with B, then d∗(A,B) = 1.1 + d∗(C,B). If the leaf in A agreed with B, then d∗(A,B) = d∗(C,B)− 1 < 1.1 + d∗(C,B) = d∗(A,C) + d∗(C,B). If the leaf in A disagreed with B and the new node in C disagrees with B, then d∗(A,B) = d∗(C,B) < 1.1 + d∗(C,B) = d∗(A,C) + d∗(C,B).\nFor the third case, if the new leaf in C agrees with B, then d∗(A,B) = 1 + d∗(C,B) = d∗(A,C) + d∗(C,B). If the node in A agreed with B, then by Lemma 22, d∗(A,C) < d∗(C,B) + 1 = d∗(A,C) + d∗(C,B). If the node in A disagreed with B, and the new leaf in C disagrees with B, then d∗(A,B) = d∗(C,B) < 1 + d∗(C,B) = d∗(A,C) + d∗(C,B).\nFinally, for the fourth case, if the new leaf in C agrees with B, then d∗(A,B) = 1 + d∗(C,B) = d∗(A,C) + d∗(C,B). If the leaf in A agreed with B, then by Lemma 22, d∗(A,C) < d∗(C,B) + 1 = d∗(A,C) + d∗(C,B). If the leaf in A disagreed with B, and the new leaf in C disagrees with B, then there was no change, and this is an illegal transition.\nTheorem 24. The distance d∗ as defined above is the distance function for a graph.\nProof. In order to prove this, we use Theorem 19. First ∆ = 1.1, and δ = 0.55. Observe that by the definition of d∗, if two trees are equal, there is no disagreement, and there is zero distance. Secondly, by the definition of d∗, if there is any difference between two trees A and B, there will be disagreement, and d∗(A,B) ≥ 1. Thus, Condition 1 and Condition 2 are satisfied.\nNow, by Lemma 20, Condition 3 is satistfied. By Lemma 23, Condition 4 is satisfied.\nIn the graph generated from d∗, note that a single label disagreement or a single decision node disagreement results in an edge.\nNow, we have to derive colors.\n1. ReplaceWithNode(p, v, l1, l2): The path, the variable, and the labels form the color. Note that if the tree already has a decision node with label v at path p, this transition is illegal.\n2. ReplaceWithLeaf(p, l1): The path and the leaf form the color.\nLemma 25. ReplaceWithNode(p, v, l1, l2) is on the shortest path to B if\n1. it can be applied to the current tree\n2. the variable v is at the path p in B.\n3. A leaf with the label ¬l1 is not at the path p ◦ (v, true) in B, 4. A leaf with the label ¬l2 is not at the path p ◦ (v, false) in B."
    }, {
      "heading" : "If these rules do not apply, it is not on the shortest path.",
      "text" : "Proof. Suppose that A is our current tree. Suppose that C = Rp,(v,l1,l2)(A). First, we establish that if the conditions are satisfied, the edge is on the shortest path. Note that if v is at the path p in B, and there is a leaf or another decision node at path p in A, then v is in structural disagreement. Therefore, when we replace that node with v, we reduce the structural disagreement. However, we must be careful not to increase leaf disagreement. If, for any nodes of v in B, they are corrected in A, then leaf disagreement will not increase. Therefore, by reducing the structural disagreement by 1, we reduce the distance by 1.1, at a cost of 1.1, meaning the edge is on the shortest path.\nSecondly, we can go through the conditions one by one to realize any violated condition is sufficient. Regarding the first condition: if the operation cannot be applied to the current tree, then by definition it is not on the shortest path.\nRegarding the second condition: if the variable v is not on path p in B, but A and B are in agreement at the path p, then changing the variable to v will not decrease the distance sufficiently, by Lemma 22, so it is not on the shortest path. Secondly, if A does not agee with B on path p, then d∗(A,B) = d∗(C,B), and thus C is not on the shortest path.\nRegard the third and fourth conditions. If the variable v is on the path p in B, but there is some leaf that is a child of v in B that is set incorrectly, then the structural distance is decreased, but the leaf disagreement is increased, so d∗(A,B) = d∗(C,B) + 0.1.\nLemma 26. ReplaceWithLeaf(p, l1) is on the shortest path to B if it applies to the current tree, and if the leaf l1 is at p in B. If these rules do not apply, it is not on the shortest path.\nProof. Suppose that A is the initial tree, and C = Rp,l1(A). If the edge applies, and there is the wrong label or a decision node at p, then the label is in disagreement in A, but not in C. There are no other changes, so d∗(A,B) = d∗(C,B) + 1 = d∗(A,C) + d∗(C,B), and therefore the edge is on a shortest path.\nOn the other hand, if there is no leaf at p in B, or the leaf has another label, then this is not the shortest path. First of all, if the operator does not apply to A, it cannot be on the shortest path. If the label Vp(B) 6= l1, butA andB are in agreement at the path p, then by Lemma 22 d∗(A,B) < d∗(C,B)+1 = d∗(A,C) + d∗(C,B). If Vp(B) 6= l1, and A and B are not in agreement at the path p, then d∗(A,B) = d∗(C,B) < d∗(C,B) + 1.\nThus, we have established our coloring works for decision trees."
    } ],
    "references" : [ {
      "title" : "An analog of the minimax theorem for vector payoffs",
      "author" : [ "D. Blackwell" ],
      "venue" : "Pacific Journal of Mathematics,",
      "citeRegEx" : "Blackwell.,? \\Q1956\\E",
      "shortCiteRegEx" : "Blackwell.",
      "year" : 1956
    }, {
      "title" : "From external to internal regret",
      "author" : [ "A. Blum", "Y. Mansour" ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Blum and Mansour.,? \\Q2007\\E",
      "shortCiteRegEx" : "Blum and Mansour.",
      "year" : 2007
    }, {
      "title" : "A general class of no regret learning algorithms and game-theoretic equilibria",
      "author" : [ "A. Greenwald", "A. Jafari" ],
      "venue" : "In Proceedings of the Sixteenth Annual Conference on Learning Theory,",
      "citeRegEx" : "Greenwald and Jafari.,? \\Q2003\\E",
      "shortCiteRegEx" : "Greenwald and Jafari.",
      "year" : 2003
    }, {
      "title" : "Approximation to bayes risk in repeated plays",
      "author" : [ "J. Hannan" ],
      "venue" : "Contributions to the Theory of Games,",
      "citeRegEx" : "Hannan.,? \\Q1957\\E",
      "shortCiteRegEx" : "Hannan.",
      "year" : 1957
    }, {
      "title" : "A simple adaptive procedure leading to correlated equilibrium",
      "author" : [ "S. Hart", "A. Mas-Colell" ],
      "venue" : null,
      "citeRegEx" : "Hart and Mas.Colell.,? \\Q2002\\E",
      "shortCiteRegEx" : "Hart and Mas.Colell.",
      "year" : 2002
    }, {
      "title" : "A wide range no-regret theorem",
      "author" : [ "E. Lehrer" ],
      "venue" : "Games and Economic Behavior,",
      "citeRegEx" : "Lehrer.,? \\Q2003\\E",
      "shortCiteRegEx" : "Lehrer.",
      "year" : 2003
    }, {
      "title" : "Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm",
      "author" : [ "N. Littlestone" ],
      "venue" : "Machine Learning,",
      "citeRegEx" : "Littlestone.,? \\Q1988\\E",
      "shortCiteRegEx" : "Littlestone.",
      "year" : 1988
    }, {
      "title" : "Programs for Machine Learning",
      "author" : [ "J.R. Quinlan" ],
      "venue" : null,
      "citeRegEx" : "Quinlan.,? \\Q1993\\E",
      "shortCiteRegEx" : "Quinlan.",
      "year" : 1993
    }, {
      "title" : "Local search strategies for satisfiability testing",
      "author" : [ "B. Selman", "H. Kautz", "B. Cohen" ],
      "venue" : null,
      "citeRegEx" : "Selman et al\\.,? \\Q1993\\E",
      "shortCiteRegEx" : "Selman et al\\.",
      "year" : 1993
    }, {
      "title" : "Online convex programming and generalized infinitesimal gradient ascent",
      "author" : [ "M. Zinkevich" ],
      "venue" : "In Twentieth International Conference on Machine Learning,",
      "citeRegEx" : "Zinkevich.,? \\Q2003\\E",
      "shortCiteRegEx" : "Zinkevich.",
      "year" : 2003
    } ],
    "referenceMentions" : [ {
      "referenceID" : 4,
      "context" : "Internal regret [Hart and Mas-Colell, 2002] is the maximum utility that could be gained if one action had been chosen in place of some other action.",
      "startOffset" : 16,
      "endOffset" : 43
    }, {
      "referenceID" : 2,
      "context" : "Swap regret [Greenwald and Jafari, 2003] is the maximum utility gained if each action could be replaced by another.",
      "startOffset" : 12,
      "endOffset" : 40
    }, {
      "referenceID" : 3,
      "context" : "External regret [Hannan, 1957], which is the original pioneering concept of regret, is the maximum utility gained by replacing all actions with one particular action.",
      "startOffset" : 16,
      "endOffset" : 30
    }, {
      "referenceID" : 9,
      "context" : "For example, if A is a compact, convex subset of R and the utilities are convex with bounded gradient on A, then you can minimize regret even though A is infinite [Zinkevich, 2003].",
      "startOffset" : 163,
      "endOffset" : 180
    }, {
      "referenceID" : 1,
      "context" : "Swap regret [Greenwald and Jafari, 2003] is the maximum utility gained if each action could be replaced by another. External regret [Hannan, 1957], which is the original pioneering concept of regret, is the maximum utility gained by replacing all actions with one particular action. This is the most relaxed of the three concepts, and while the others must concern themselves with |A|2 possible regret values (for all pairs of actions) external regret only need worry about |A| regret values. So although the guarantee is weaker, it is a simpler concept to learn which can make it considerably more attractive. These three regret notions have the following relationships. R internal ≤ R swap ≤ |A|R internal R external ≤ R swap (3) 2.1 Infinite Action Spaces This paper considers situations where A is infinite. To keep the notation simple, we will use max operations over actions to mean suprema operations and summations over actions to mean the suprema of the sum over all finite subsets of actions. Since we will be focused on regret over a finite time period, there will only ever be a finite set of actually selected actions and, hence only a finite number of non-zero regrets, R a,b. The summations over actions will always be thought to be restricted to this finite set. None of the three traditional regret concepts are well-suited to A being infinite. Not only does |A| appear in the regret bounds, but one can demonstrate that it is impossible to have no regret in some infinite cases. Consider A = N and let u be a step function, so u(a) = 1 if a > y for some y and 0 otherwise. Imagine y is selected so that Pr[a > yt|u1,...,T−1, a1,...,T−1] ≤ 0.001, which is always possible. Essentially, high utility is always just beyond the largest action selected. Now, consider y∗ = 1 + maxt≤T y. In expectation 1 T ∑T t=1 u (at) ≤ 0.001 while 1 T ∑T t=1 u t(y∗) = 1 (i.e., there is large internal and external regret for not having played y∗,) so the average regret cannot approach zero. Most attempts to handle infinite action spaces have proceeded by making assumptions on both A and u. For example, if A is a compact, convex subset of R and the utilities are convex with bounded gradient on A, then you can minimize regret even though A is infinite [Zinkevich, 2003]. We take an alternative approach where we make use of a notion of locality on the set A, and modify regret concepts to respect this locality. Different notions of locality then result in different notions of regret. Although this typically results in a weaker form of regret for finite sets, it breaks all dependence of regret on the size ofA and allows it to even be applied whenA is infinite and u is an arbitrary (although still bounded) function. Wide range regret methods Lehrer [2003] can also bound regret with respect to a set of (countably) infinite “alternatives”, but unlike our results, their asymptotic bound does not apply uniformly across the set, and uniform finite-time bounds depend upon a finite action space Blum and Mansour [2007].",
      "startOffset" : 13,
      "endOffset" : 2765
    }, {
      "referenceID" : 1,
      "context" : "Wide range regret methods Lehrer [2003] can also bound regret with respect to a set of (countably) infinite “alternatives”, but unlike our results, their asymptotic bound does not apply uniformly across the set, and uniform finite-time bounds depend upon a finite action space Blum and Mansour [2007].",
      "startOffset" : 277,
      "endOffset" : 301
    }, {
      "referenceID" : 8,
      "context" : ", WalkSAT [Selman et al., 1993]) on the maximum satisfiability problem, an offline task where all of the clauses are known up front.",
      "startOffset" : 10,
      "endOffset" : 31
    }, {
      "referenceID" : 7,
      "context" : "5 [Quinlan, 1993].",
      "startOffset" : 2,
      "endOffset" : 17
    }, {
      "referenceID" : 4,
      "context" : "4 An Algorithm for Local Swap Regret We now present an algorithm for minimizing local swap regret, similar to global swap regret algorithms [Hart and Mas-Colell, 2002; Greenwald and Jafari, 2003], but with substantial differences.",
      "startOffset" : 140,
      "endOffset" : 195
    }, {
      "referenceID" : 2,
      "context" : "4 An Algorithm for Local Swap Regret We now present an algorithm for minimizing local swap regret, similar to global swap regret algorithms [Hart and Mas-Colell, 2002; Greenwald and Jafari, 2003], but with substantial differences.",
      "startOffset" : 140,
      "endOffset" : 195
    }, {
      "referenceID" : 4,
      "context" : "These probabilities are always computed according to the following requirement, which is a generalization of [Hart and Mas-Colell, 2002; Greenwald and Jafari, 2003].",
      "startOffset" : 109,
      "endOffset" : 164
    }, {
      "referenceID" : 2,
      "context" : "These probabilities are always computed according to the following requirement, which is a generalization of [Hart and Mas-Colell, 2002; Greenwald and Jafari, 2003].",
      "startOffset" : 109,
      "endOffset" : 164
    }, {
      "referenceID" : 4,
      "context" : "There are two distinguishing factors of our algorithm from [Hart and Mas-Colell, 2002; Greenwald and Jafari, 2003]: R̃ 6= R, and past a certain distance from the root, we loop back.",
      "startOffset" : 59,
      "endOffset" : 114
    }, {
      "referenceID" : 2,
      "context" : "There are two distinguishing factors of our algorithm from [Hart and Mas-Colell, 2002; Greenwald and Jafari, 2003]: R̃ 6= R, and past a certain distance from the root, we loop back.",
      "startOffset" : 59,
      "endOffset" : 114
    }, {
      "referenceID" : 0,
      "context" : "The overall structure of the proof is similar to [Blackwell, 1956; Hart and Mas-Colell, 2002; Greenwald and Jafari, 2003] with a few significant changes.",
      "startOffset" : 49,
      "endOffset" : 121
    }, {
      "referenceID" : 4,
      "context" : "The overall structure of the proof is similar to [Blackwell, 1956; Hart and Mas-Colell, 2002; Greenwald and Jafari, 2003] with a few significant changes.",
      "startOffset" : 49,
      "endOffset" : 121
    }, {
      "referenceID" : 2,
      "context" : "The overall structure of the proof is similar to [Blackwell, 1956; Hart and Mas-Colell, 2002; Greenwald and Jafari, 2003] with a few significant changes.",
      "startOffset" : 49,
      "endOffset" : 121
    }, {
      "referenceID" : 8,
      "context" : "We also ran WalkSAT [Selman et al., 1993] offline on the set of 201 clauses, and on average it was able to satisfy all but 4% of the clauses, which gives an offline lower bound for what is possible.",
      "startOffset" : 20,
      "endOffset" : 41
    }, {
      "referenceID" : 6,
      "context" : "This task has received considerable attention, notably the celebrated Winnow algorithm [Littlestone, 1988], which is guaranteed to make a finite number of mistakes if the instances can be perfectly classified by some disjunction.",
      "startOffset" : 87,
      "endOffset" : 106
    } ],
    "year" : 2012,
    "abstractText" : "Online learning aims to perform nearly as well as the best hypothesis in hindsight. For some hypothesis classes, though, even finding the best hypothesis offline is challenging. In such offline cases, local search techniques are often employed and only local optimality guaranteed. For online decision-making with such hypothesis classes, we introduce local regret, a generalization of regret that aims to perform nearly as well as only nearby hypotheses. We then present a general algorithm to minimize local regret with arbitrary locality graphs. We also show how the graph structure can be exploited to drastically speed learning. These algorithms are then demonstrated on a diverse set of online problems: online disjunct learning, online Max-SAT, and online decision tree learning.",
    "creator" : "TeX"
  }
}