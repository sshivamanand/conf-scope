{
  "name" : "0911.5548.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "A Decision-Optimization Approach to Quantum Mechanics and Game Theory",
    "authors" : [ "Xiaofei Huang" ],
    "emails" : [ "HuangZeng@yahoo.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :0\n91 1.\n55 48\nv2 [\ncs .G\nT ]\n2 D\nec 2\n00 9\nIn physics, discovering more fundamental laws that can be used to derive some existing laws usually gives us a better understanding about nature, e.g., the discovery of Newton’s laws of motion and gravitation for explaining Kepler’s laws of planetary motion. This paper shows that a global optimization algorithm can be used to derive the time-independent Schrödinger equation, one of the most important equations in quantum mechanics. Such a connection suggests that the laws of quantum mechanics might embed a global optimization process such that a dissipative quantum system, caused by the interactions with its environment, tends to evolve towards its ground state of the global energy minimum. Contrary to that, the same system under the laws of classic physics tends to get stuck at one local minimum energy state or another. The former is more deterministic and predictable than the latter in terms of the final result (no dice playing) because an energy function usually has an enormous number of local minima but only one global minimum. In addition to a computational approach to quantum mechanics, the global optimization algorithm also offers an intuitive, direct mechanism to compute the stationary states of a quantum system starting from any random initial states.\nThe global optimization algorithm is defined by the cooperative optimization theory [1]. The theory is for a mathematical understanding of ubiquitous cooperative behaviors in nature and translating them into optimization algorithms. Specifically, given a society with n persons, assume that the objective of person i is described as minimizing a function Ei(x). A simple form of cooperative optimization is defined as an iterative computation of each person’s expected returns described by a function Ψi(xi, t) as follows:\nΨi(xi, t) = ∑\n∼xi\n\ne−Ei(x)/~ ∏\nj 6=i\npj(xj , t− 1)\n\n , for i = 1, 2, . . . , n , (1)\nwhere ∑\n∼xi stands for the summation over all variables except xi. ~ is a constant of a small positive value. pi(xi, t)\nis a probability-like function for picking action xi proportional to (Ψi(xi, t)) α (α > 0), i.e.,\npi(xi, t) = (Ψi(xi, t)) α /Zi(t), where Zi(t) =\n∑\nxi\n(Ψi(xi, t)) α is a normalization factor.\nThe larger the parameter α, the more aggressive each person is at minimizing his own objective function Ei(x). At the same time, the game tends to have more equilibrium points. However, the chance for the society to reach the social (global) optimum is only peaked at a certain value of α, neither too large nor too small. In this case, each person in the game compromises his best action by accepting sub-optimal actions to some degree, different from the case when α → ∞ where only the best action is accepted.\nIn particular, when α = 2, the simple general form (1) in a continuous-time version is\n− ~ ∂ψi(xi, t)\n∂t =\n1\nZi(t) ei(xi)ψi(xi, t), where ei(xi) =\n∑\n∼xi\n\nEi(x) ∏\nj 6=i\n|ψj(xj , t)| 2\n\n . (2)\n2 Following the notation from physics, denote ψi(xi, t) as a vector | ψi(t)〉. Let Hi be a diagonal matrix with diagonal elements as ei(xi). Then the equation (2) becomes\n− ~ d\ndt | ψi(t)〉 =\n1\nZi(t) Hi | ψi(t)〉 . (3)\nThe above equation can be further generalized with a hermitian matrix Hi. The expected return function ψi(xi, t) is also called a wavefunction in physics. It is important to note that the equation (3) is the dual equation of the Schrödinger equation, where −1 is replaced by the imaginary unit i and the normalization factor Zi(t) is not required since the equation is unitary. When the dynamic equation (3) reachs a stationary point (equilibrium), the equation becomes the time-independent Schrödinger equation:\nλi | ψi(xi, t)〉 = Hi | ψi(xi, t)〉 ,\nwhere λi can only be any one of the eigenvalues of Hi. In summary, when the global optimization algorithm (with α = 2) in a continuous-time version reaches any equilibrium point, it falls back to the time-independent Schrödinger equation. The author is convinced that the algorithm is general and can be applied to solve optimization problems from different fields, such as game theory described below.\nLet ui(x) = e−Ei(x)/~ be the utility function for the person i. In this case, the person i tries to maximize his utility function ui(x) instead of minimizing his objective function Ei(x). Both tasks are fully equivalent to each other. In this case, (1) becomes as\nΨi(xi, t) = ∑\n∼xi\n\nui(x) ∏\nj 6=i\npj(xj , t− 1)\n\n , where pi(xi, t) = (Ψi(xi, t)) α /\n∑\nxi\n(Ψi(xi, t)) α . (4)\nBased on Brouwer fixed point theorem, an equilibrium point always exists for the above set of equations for any value of α. This point is also an ǫ-approximate Nash equilibrium [4], where ǫ is inversely proportional to α. An ǫ-approximate Nash equilibrium is a strategy profile such that no other strategy can improve the payoff by more than the value ǫ. In particular, a Nash equilibrium can be viewed as an 0-approximate one.\nWhen α → ∞, the approximation error ǫ is arbitrarily close to zero. In this case, each player in a game only accepts the best action that gives the highest payoff for the player. That is the fundamental principle of rational decision making in classic game theory. The logical justification of this principle seems obvious which shapes the definition of Nash equilibrium more than 50 years ago. However, the understanding of the global optimization algorithm (1) shows that the optimality of this principle is conditional. Often times, compromising it by accepting sub-optimal actions can improve both the overall payoff (equivalently the average individual payoff) and the stability of game playing.\nIn summary, the optimal decision of each player in the classic sense may not lead to a good payoff for the player. At a Nash equilibrium, if every player gives away some payoff by accepting sub-optimal actions to some degree, each of them may actually receive a better, rather than worse return at a new equilibrium point than the original one, which may be counter-intuitive. The experimental results from the prisoner’s dilemma to computer simulated societies show that compromising each individual’s optimal decision can improve the overall payoff (many times everyone’s payoff) and social stability. This study suggests that, for the benefit of everyone in a society (or a financial market), the pursuit of maximal payoff by each individual should be controlled at some level either by voluntary good citizenship or by imposed regulations.\nIn conclusion, decision compromising is a general optimization principle for cooperation. It reveals a global optimization approach to understand quantum mechanics. It also offers a fundamental principle for improving social stability and individual payoffs over the classic profit-maximization principle."
    } ],
    "references" : [ {
      "title" : "Cooperative optimization for solving large scale combinatorial problems",
      "author" : [ "X. Huang" ],
      "venue" : "Theory and Algorithms for Cooperative Systems, Series on Computers and Operations Research, World Scientific, 2004, pp. 117–156.",
      "citeRegEx" : "1",
      "shortCiteRegEx" : null,
      "year" : 2004
    }, {
      "title" : "100 years of quantum mysteries",
      "author" : [ "M. Tegmark", "J.A. Wheeler" ],
      "venue" : "Scientific American, pp. 68–75, February 2001.",
      "citeRegEx" : "2",
      "shortCiteRegEx" : null,
      "year" : 2001
    }, {
      "title" : "Do deeper principles underlie quantum uncertainty and nonlocality?",
      "author" : [ "C. Seife" ],
      "venue" : "Science, vol. 309,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2005
    }, {
      "title" : "Equilibrium points in n-player games",
      "author" : [ "J.F. Nash" ],
      "venue" : "Proceedings of the National Academy of Sciences of the United States of America. Volume",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 1950
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "The global optimization algorithm is defined by the cooperative optimization theory [1].",
      "startOffset" : 84,
      "endOffset" : 87
    } ],
    "year" : 2014,
    "abstractText" : "The fundamental laws of quantum world upsets the logical foundation of classic physics. They are completely counter-intuitive with many bizarre behaviors. However, this paper shows that they may make sense from the perspective of a general decision-optimization principle for cooperation. This principle also offers a generalization of Nash equilibrium, a key concept in game theory, for better payoffs and stability of game playing. In physics, discovering more fundamental laws that can be used to derive some existing laws usually gives us a better understanding about nature, e.g., the discovery of Newton’s laws of motion and gravitation for explaining Kepler’s laws of planetary motion. This paper shows that a global optimization algorithm can be used to derive the time-independent Schrödinger equation, one of the most important equations in quantum mechanics. Such a connection suggests that the laws of quantum mechanics might embed a global optimization process such that a dissipative quantum system, caused by the interactions with its environment, tends to evolve towards its ground state of the global energy minimum. Contrary to that, the same system under the laws of classic physics tends to get stuck at one local minimum energy state or another. The former is more deterministic and predictable than the latter in terms of the final result (no dice playing) because an energy function usually has an enormous number of local minima but only one global minimum. In addition to a computational approach to quantum mechanics, the global optimization algorithm also offers an intuitive, direct mechanism to compute the stationary states of a quantum system starting from any random initial states. The global optimization algorithm is defined by the cooperative optimization theory [1]. The theory is for a mathematical understanding of ubiquitous cooperative behaviors in nature and translating them into optimization algorithms. Specifically, given a society with n persons, assume that the objective of person i is described as minimizing a function Ei(x). A simple form of cooperative optimization is defined as an iterative computation of each person’s expected returns described by a function Ψi(xi, t) as follows: Ψi(xi, t) = ∑",
    "creator" : "LaTeX with hyperref package"
  }
}