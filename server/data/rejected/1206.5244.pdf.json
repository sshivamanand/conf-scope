{
  "name" : "1206.5244.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Search for Choquet-optimal paths under uncertainty",
    "authors" : [ "Lucie Galand", "Patrice Perny" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "Choquet expected utility (CEU) is one of the most sophisticated decision criteria used in decision theory under uncertainty. It provides a generalisation of expected utility enhancing both descriptive and prescriptive possibilities. In this paper, we investigate the use of CEU for path-planning under uncertainty with a special focus on robust solutions. We first recall the main features of the CEU model and introduce some examples showing its descriptive potential. Then we focus on the search for Choquet-optimal paths in multivalued implicit graphs where costs depend on different scenarios. After discussing complexity issues, we propose two different heuristic search algorithms to solve the problem. Finally, numerical experiments are reported, showing the practical efficiency of the proposed algorithms."
    }, {
      "heading" : "1 INTRODUCTION",
      "text" : "An important source of complexity in practical applications of problem solving methods developed in AI is the imperfect knowledge of the real problem to deal with. This is particularly true in path-planning problems where the map is not always the territory. When seeking the optimal path from a given node to a goal node, several uncertainty factors might indeed increase the complexity of the optimization task. Firstly, the consequences of the actions might not be certain, which can be modeled by non-deterministic transitions between states. Secondly, the current state might not be known exactly (partial observability), which requires maintaining beliefs on possible states revised during the search. These problems are widely discussed in the litterature on MDPs and POMDPs, see e.g. Puterman (1994), Kaebling et al. (1999).\nBeside these sources of complexity, the cost transitions between states might also be uncertain. This eventuality has motivated work aimed at revisiting, under uncertainty, the shortest path problem in a state space graph, and its classical resolution with the A∗ algorithm. For example, Wellman and Wurman consider a case where the costs are time dependent and representable by random variables (Wellman et al., 1995). They introduce the SDA∗ algorithm to determine the preferred paths according to the stochastic dominance partial order. Moreover, an extension of this algorithm specifically designed to cope with both uncertainty and multiple criteria is proposed in (Wurman and Wellman, 1996).\nAnother way of introducing uncertainty in costs is to consider a set of plausible scenarios, each bringing a different valuation to transitions and therefore to solution paths. This is the natural formulation when the costs depend on exogenous variables not controlled by the decision maker, these variables having an overall impact on the graph (e.g. transfer times in a city depending on the weather, security of moves depending on enemy positions, asset values depending on market evolution). The introduction of scenarios implicitly defines a family of possible instances of the same problem, all sharing the same feasible solutions, but with different views on the possible costs. In such problems, the aim is to seek for “robust” solutions, i.e. solutions yielding a “reasonable” cost in all plausible instances of the problem. This robustness idea has actively developed in discrete optimization since the publication of the book by Kouvelis and Yu (1997), which considers several criteria imported from decision theory under total uncertainty (e.g. min-max, min-max regret) to define the absolute or relative robustness of a solution. Under these criteria, the shortest path problem becomes NP-hard, as do many other polynomially solvable problems (see e.g., Aron and van Hentenryck (2002) for robust spanning tree problems), thus bringing new algorithmic challenges. In the same vein, alternative models such as Lorenz dominance and\nordered weighted averages have been introduced and justified to model robustness in (Perny and Spanjaard, 2003), as well as a multiobjective search algorithm to determine robust solution paths in state space graphs under total uncertainty.\nOne major limitation of these robustness criteria is overpessimism (worst case analysis) in cost aggregation, making them not sufficiently discriminating. When information about the relative plausibility of scenarios is available, robustness criteria can be refined using models introduced in decision theory under uncertainty and risk to convey pessimism, prudence, riskaversion or uncertainty aversion in the comparisons of acts. This idea is exploited in (Perny et al., 2007) for path-planning under risk (when probabilities of scenarios are known), where a multiobjective heuristic search algorithm is proposed for the determination of optimal solution paths with respect to second-order stochastic dominance, or expected utility for risk-averse agents. However, in some situations, these models do not apply directly, either because the objective probabilities of scenarios are not known, or because observed preferences do not match EU theory with respect to any probabilities. An example of such a problematic situation, inspired by the so-called Ellsberg’s urn example (Ellsberg, 1961), is presented below in the context of path planning:\nExample 1 Consider a problem with 3 scenarios (S = {1, 2, 3}) and assume that objective probabilities of scenarios are imprecisely known and defined by p1 = 1/3 and p2 + p3 = 2/3. Consider now 4 solution paths P1, P2, P3, P4 to reach a goal node from the initial node with the following costs c(Pi, sj):\n1 2 3 P1 0 100 100 P2 100 0 100 P3 0 100 0 P4 100 0 0\nOn the one hand, a decision maker who is averse to uncertainty might prefer P1 to P2 because P1 has probability 1/3 of reaching the goal for free, whereas P2 might have a cost of 100 for sure. On the other hand, the same decision maker might prefer P4 to P3 because P4 has probability 2/3 of reaching the goal for free, whereas P3 might have only probability 1/3. Although such preferences are natural they cannot be described by the EU model. Indeed P1 P2 implies p2 + p3 > p1 + p3 whereas P4 P3 implies p1 > p2. Note that these inequalities are contradictory. This makes it impossible to assume that subjective probabilities are implicitly assigned to states by the decision maker. Trying to reveal them would be meaningless.\nThe impossibility of revealing probabilities through the EU model in some situations has led to the introduction of alternative numerical representations of beliefs in events by a capacity function, a less constraining representation of uncertainty that relaxes the additivity assumption. The standard decision model associated to capacities is based on the use of the Choquet integral, following Schmeidler (1989), who gives the foundations of the Choquet Expected Utility criterion (CEU). Despite its descriptive appeal, until now, CEU has not been considered in the field of path-planning under uncertainty. The aim of this paper is to fill this gap and to complete the previous studies by investigating the potential of CEU in the search of robust paths. The paper is organized as follows. In Section 2 we recall the main features of the CEU model and introduce some examples showing its descriptive potential in the context of search under uncertainty; then we discuss complexity issues concerning the search of Choquetoptimal paths. In Section 3 we propose two different heuristic search algorithms to solve the problem. Finally, numerical experiments are reported in Section 4, showing the practical efficiency of the proposed algorithms."
    }, {
      "heading" : "2 PROBLEM FORMULATION",
      "text" : ""
    }, {
      "heading" : "2.1 Notations and Definitions",
      "text" : "We consider a state space graph G = (N,A) where N is a finite set of nodes (possible states), and A is a set of arcs representing feasible transitions between nodes. Formally, we have A = {(n, n′) : n ∈ N,n′ ∈ S(n)} where S(n) ⊆ N is the set of all successors of node n (nodes that can be reached from n by a feasible elementary transition). We denote P(n, n′) the set of all paths linking n to n′, and P(n,N ′) the set of all paths from n to any node n′ ⊆ N ′ (with N ′ ⊆ N). We call solution path a path from s to a goal node γ ∈ Γ (i.e. a path in P(s,Γ)). Throughout the paper, we assume that there exists at least one finite length solution path. We consider a finite set S = {1, . . . ,m} of possible scenarios, each having possibly a different impact on the transition costs, and a scenariodependent valuation c : A × S → R+ where c(a, s) is the cost of the transition represented by a in scenario s. By abuse of notation, c(a) denotes the cost vector (c(a, 1), . . . , c(a,m)). The costs over a path are assumed to be additive, which allows valuation c to be extended from arcs to paths by setting, for any path P and any scenario s, c(P, s) = ∑ a∈P c(a, s). A cost vector x = (x1, x2, . . . , xm) ∈ Rm+ is associated to each path P in G such that xi = c(P, i), hence, the comparison of paths reduces to the comparison of their associated cost vectors. In the sequel we assume\nthat, for all scenarios, the cost of each solution path is bounded by a positive constant M . Throughout the paper, we will consider a weak preference over paths (or cost vectors), denoted %. For any pair of paths P and P ′ with respective costs x and x′ in Rm+ we will use notation P % P ′ or x % x′ to say P is at least as good as P ′. As usual relation P ∼ P ′ (or x ∼ x′) represents indifference between the two paths and corresponds to P % P ′ and P ′ % P . Finally, relation P P ′ (or x x′) represents strict preference and corresponds to P % P ′ and not(P ′ % P )."
    }, {
      "heading" : "2.2 Capacities and the Choquet Integral",
      "text" : "The Choquet integral (Choquet, 1953) is used in decision theory to generalize the notion of expectation when beliefs in events are represented by a capacity, i.e. a set function v : 2S → [0, 1] such that v(∅) = 0, v(S) = 1 and ∀A,B ∈ 2S such that A ⊆ B, v(A) ≤ v(B). For any event A ⊆ S, v(A) represents the plausibility of event A. The capacity v is said to be convex (or supermodular) when v(A ∪B) + v(A ∩B) ≥ v(A) + v(B) for all A,B ⊆ S, and it is said to be concave (or submodular) when v(A ∪B) + v(A ∩B) ≤ v(A) + v(B) for all A,B ⊆ S. To any capacity v, we can associate a dual capacity v̄ defined by v̄(A) = 1 − v(S \\ A) for all A ⊆ S. It is well known that v̄ is concave if and only if v is convex and vice-versa. When v is concave, we have v(A) + v(S \\ A) ≥ 1, hence v̄(A) ≤ v(A). In this case the core of v̄ defined by core(v̄) = {P ∈ L, v̄(A) ≤ P (A) ≤ v(A)} where L is the set of probability measures on S is known to be non-empty since v̄ is convex (Shapley, 1971). This result will be used in Section 3.\nExample 1 continued Coming back to Example 1, let P be the set of all probability distributions on S = {1, 2, 3} such that P ({1}) = 1/3, the set function defined by v(A) = supP∈P P (A) for all A ⊆ {1, 2, 3} and its dual v̄ are given by:\nA ∅ {1} {2} {3} {1, 2} {1, 3} {2, 3} S v(A) 0 1/3 2/3 2/3 1 1 2/3 1 v̄(A) 0 1/3 0 0 1/3 1/3 2/3 1\nIn this case, it is easy to check that v (resp. v̄) is a concave (resp. convex) capacity. Moreover we have core{v̄} = P.\nThe Choquet integral of a vector x ∈ Rm+ with respect to capacity v is defined by:\nCv(x) = m∑\ni=1\n[ v(X(i))− v(X(i+1) ] x(i) (1)\n= m∑\ni=1\n[ x(i) − x(i−1) ] v(X(i)) (2)\nwhere (.) represents a permutation on {1, . . . ,m} such that 0 = x(0) ≤ x(1) ≤ . . . ≤ x(m), X(i) = {j ∈ S, xj ≥ x(i)} = {(i),(i + 1), . . ., (m)} for i ≤ m and X(m+1) = ∅. Note that X(i+1) ⊂ X(i), hence v(X(i)) ≥ v(X(i+1)) for all i. The Choquet integral generalizes the classical notion of expectation with the following interpretation based on Equation (2): for a given vector x = (x1, . . . , xm), the outcome is at least x(1) with plausibility v(X(1)) = 1, and the outcome might increase from x(1) to x(2) with plausibility v(X(2)); the same applies from x(2) to x(3) with plausibility v(X(3)), and so on. The overall integral is therefore obtained by aggregation of marginal increments x(i) − x(i−1) weighted by plausibilities v(X(i))."
    }, {
      "heading" : "In decision theory, the Choquet integral is often used in maximization problems under the form",
      "text" : "Cv(u(x1), . . . , u(xm)) with utility function u on payoffs to be maximized (CEU criterion, Schmeidler (1989)). In path-planning problems where costs replace payoffs, we need to reformulate the criterion using a disutility function to be minimized. Let w : R+ → [0, 1] be an increasing disutility function on costs such that w(0) = 0 and w(M) = 1. We introduce the Choquet Expected Disutility (CED), a function to be minimized over all feasible vectors x ∈ Rm+ , defined by:\nψwv (x) = Cv(w(x1), . . . , w(xm)) (3)\nNote that CED includes classical expected disutility as a particular case. Indeed, whenever v is additively decomposable, we have v(A) = ∑ i∈A vi for all A ⊆ S, where vi = v({i}). Hence v(X(i))−v(X(i+1)) = v(i) for all i and ψwv (x) = ∑m i=1 v(i)w(x(i)) = ∑m i=1 viw(xi). When used with a non-additive capacity, it offers additional descriptive possibilities. As an illustration, let us continue Example 1.\nExample 1 continued Assume that w(0) = 0, w(100) = 1. We get: ψwv ((0, 100, 100)) = v({2, 3}), ψwv (((100, 0, 100)) = v({1, 3}), ψwv ((0, 100, 0)) = v({2}), ψwv ((100, 0, 0)) = v({1}). If v is the concave capacity introduced above, we get v({2, 3}) = 2/3 < 1 = v({1, 3}) and v(2) = 2/3 > 1/3 = v(1). Hence we get the desired preferences, i.e. (0, 100, 100) (100, 0, 100) and (0, 100, 0) ≺ (100, 0, 0). This example shows that ψwv is compatible with some uncertainty aversion."
    }, {
      "heading" : "2.3 Uncertainty aversion in CEU theory",
      "text" : "Uncertainty aversion means intuitively that smoothing or averaging a cost vector makes the decision maker better off. A useful formalization of this idea is introduced in Chateauneuf and Tallon (2002) through an axiom named “preference for diversification” due to its interpretation in the context of portofolio man-\nagement. This axiom can be reformulate in our framework:\nDefinition 1 A preference % reveals uncertainty aversion if, for any x1, . . . , xn ∈ Rm+ , and α1, . . . , αn ≥ 0 such that for all ∑n i=1 αi = 1, we have:\n[x1 ∼ x2 ∼ . . . ∼ xn]⇒ ∑n\ni=1 αix i % xk, k = 1, . . . , n\nInterestingly enough, it is shown in Chateauneuf and Tallon (2002) that, within CEU theory, the above axiom on preference is equivalent to choosing a concave utility u and a convex capacity v. The direct counterpart of this result in our context (minimization of Choquet expected disutility) says that we should use a convex disutility w and a concave capacity v to exhibit uncertainty aversion with ψwv as defined in Equation (3). For this reason, throughout the paper, we will assume that w is convex and v is concave.\nExample 2 In a two-scenario instance with scenarios having approximatively the same plausibility, consider two solution paths with cost vectors x = (10, 0) and y = (0, 10) respectively. A decision maker averse to uncertainty might be indifferent between x and y, i.e. x ∼ y, but would prefer z = (5, 5) to x and y, i.e. z x and z y. Such preferences are fully consistent with the idea of robustness. Suppose now that we have a convex disutility w defined by ∀t ∈ R+, w(t) = t2/100 and a concave capacity v such that v({1}) = v({2}) = 2/3. Then ψwv (x) = ψ w v (y) = 2/3 > ψ w v (z) = 1/4 which induces the desired preferences. Note that using a concave disutility w such as w(t) = √ t/10 gives ψwv (x) = ψ w v (y) = 0.67 < 0.71 = ψ w v (z), which is not compatible with uncertainty aversion. The same observation can be made with a convex capacity.\nWe are now in position to formulate the central problem of this paper:\nThe ψwv -OPT problem. Instance: a state space graph G = (N,A) as introduced in Subsection 2.1, an initial node s and a set Γ ⊆ N of goal nodes, a finite set of states S, a scenariodependent valuation c : A × S → R+, and a concave capacity v and a convex disutility w. Goal: determine a ψwv -optimal path among all paths in P(s,Γ) where ψwv is defined as in Equation (3)."
    }, {
      "heading" : "2.4 Complexity issues",
      "text" : "If v(A) = 1 for all non-empty A ⊆ S, then ψwv (x) =∑m i=1 [ w(x(i))− w(x(i−1)) ] v(X(i)) = w(x(m)) = maxi∈S w(xi). Hence ψwv -OPT reduces to the minmax search problem, which was proved NP-hard by Murthy and Her (1992). This shows that ψwv -OPT is also NP-hard.\nWe wish to propose a heuristic search algorithms to solve the ψwv -OPT problem. The efficient resolution of shortest-path problems with A∗ in the classical case relies on the Bellman principle that justifies local pruning of sub-optimal subpaths during the search. However, in the case of multiple scenarios the CED model breaks the Bellman principle, as shown by the following example:\nExample 3 Consider an instance with two paths P and P ′ from s to a node n with costs vectors x = (0, 100, 0) and x′ = (100, 0, 0). Consider a Choquet expected disutility criterion ψwv with w(0) = 0, w(100) = 1 and v({1}) = 0.4, v({2}) = 0.5, v({2, 3}) = 0.7, v({1, 3}) = 0.8. Here we have ψwv (x) = 0.5 and ψwv (x\n′) = 0.4 and therefore P ′ P . For search efficiency, we might want to prune P at node n due to the existence of the better subpath P ′. However, it might be a mistake. Assume, for example, that a path P ′′ from n to Γ exists with cost y = (0, 0, 100); we have P ′ ∪ P ′′ ≺ P ∪ P ′′ because ψwv (x′ + y) = ψwv ((100, 0, 100)) = 0.8 > 0.7 = ψ w v ((0, 100, 100)) = ψwv (x+ y).\nSuch a preference reversal shows that, at any node visited during the search, a naive pruning of sub-optimal sub-paths with respect to ψwv might lose the admissibility of the algorithm. A similar violation of the Bellman principle is highlighted in De Cooman and Troffaes (2005), in the general framework of dynamic programming with uncertain gain and imprecise probabilities. It concerns the notion of P -maximinity, a counterpart of ψwv -optimality for imprecise probabilities. The next section presents two admissible algorithms to solve ψwv -OPT."
    }, {
      "heading" : "3 ALGORITHMS",
      "text" : ""
    }, {
      "heading" : "3.1 Optimistic Heuristics for ψwv −OPT",
      "text" : "Before introducing algorithms for the ψwv -OPT problem, we establish an inequality providing an easily computable lower bound for criterion ψwv (x).\nProposition 1 If v is concave then for all P ∈ core(v̄) the following inequality holds: ψwv (x) ≥∑m\ni=1 piw(xi) with pi = P ({i}). Moreover, if w is convex we have: ψwv (x) ≥ w( ∑m i=1 pixi).\nProof. ψwv (x) = ∑m i=1 [ w(x(i))− w(x(i−1)) ] v(X(i))\n≥ ∑m\ni=1\n[ w(x(i))− w(x(i−1)) ] P (X(i)) since inequal-\nities v(X(i)) ≥ P (X(i)) hold for all i (P ∈ core(v̄)). Further, ∑m i=1 [ w(x(i))− w(x(i−1)) ] P (X(i)) =∑m\ni=1[P (X(i)) − P (X(i+1))]w(x(i)) = ∑m\ni=1 p(i)w(x(i)) = ∑m i=1 piw(xi) ≥ w( ∑m i=1 pixi) when w is convex.\nHence, any probability distribution P in core(v̄) can be used to produce a lower bound that can be used as an optimistic heuristic in the search. Among the natural choices for P that give efficient bounds in practice, let us mention Shapley values φi that represent the average marginal contribution of any state i = 1, . . . ,m to events (Shapley, 1971). Shapley values are positive and add up to one. In our context they are defined by:\nφi = ∑\nK⊆S\\{i}\n(m− |K| − 1)!|K|! m! (v̄(K ∪ {i})− v̄(K))\nAnother possible choice among probability laws in core(v̄) is P ∗, the probability distribution maximizing entropy h(P ) = − ∑m i=1 pi log pi over the core(v̄). This propability distribution can easily be obtained using the following greedy algorithm proposed in Jaffray (1995), where p∗i stands for the probability P ∗({i}).\nAlgorithm 1: computing P ∗ with max-entropy Initialization: A← ∅; B ← ∅; while B 6= S do\nA← argmin{v(B∪E)−v(B)|E| , E ⊆ S\\B,E 6= ∅}; for all i ∈ A do\np∗i ← v(B∪A)−v(B)\n|A| ; B ← B ∪A;\nOutput: (p∗1, . . . , p ∗ m)\nExample 1 continued Coming back to Example 1, Algorithm 1 outputs probabilities p∗1 = p ∗ 2 = p ∗ 3 = 1/3. With w(0) = 0 and w(100) = 1 we get the following evaluations for paths.\nxk 1 2 3 ψwv ∑3 i=1 p ∗ i x k i x1 0 100 100 2/3 2/3 x2 100 0 100 1 2/3 x3 0 100 0 2/3 1/3 x4 100 0 0 1/3 1/3\nWe observe that ψwv (x k) ≥ ∑3 i=1 p ∗ i x k i for all k.\nIn Example 1, Shapley values coincide with maximal entropy probabilities but this is not true in the general case.\nWe introduce now two exact algorithms for the ψwv - OPT problem. The first one is based on multiobjective search and the second one is based on a ranking approach with prior scalarization of the problem."
    }, {
      "heading" : "3.2 Multiobjective Search",
      "text" : "The presence of m scenarios in our problem provides m different viewpoints on costs in the state space\ngraph. This clearly points out connections with the field of multiobjective optimization. More precisely, since ψwv (x1, . . . , xm) is increasing in each component, it is clear that ψwv -optimal vectors belong to the Pareto set, i.e., the set of feasible vectors that cannot be improved on a component without being degraded on another. More formally, within a set X ⊆ Rm+ , the Pareto-set is defined by:\nND(X) = {x ∈ X : ∀y ∈ X, y %P x⇒ x %P y}\nwhere %P is the weak Pareto-dominance relation defined on Rm+ by: x %P y ⇐⇒ [∀i ∈ S, xi ≤ yi]. Hence the search for a ψwv -optimal path might be performed with a multiobjective search algorithm. For this reason, we recall now the main features of the MOA∗ algorithm proposed by Stewart and White III (1991) to find the set ND(P(s,Γ)) of non-dominated solution paths in G. Algorithm MOA∗ relies on the same foundations as A∗, adapted to the field of vectorvalued evaluation. In particular, the Bellman principle holds. Thus, any subpath from s to a node n ∈ N of a non-dominated solution path is non-dominated in P(s, n). Hence, the algorithm constructs incrementally the non-dominated solution paths from nondominated subpaths.\nIn a graph valued by cost vectors, there may exist several non-dominated paths to reach a given node n. In MOA∗ these paths are kept in a label attached to the concerned node and all these paths are expanded when the label is developed. The choice of a node n to be developed at the current iteration is based on a vector valued evaluation function that uses a vector-valued heuristic H(n) containing cost vectors underestimating the real costs of any path in P(n,Γ). This set is an optimistic approximation of H∗(n) = ND(P(n,Γ)).\nRecently, a variant of this algorithm was proposed in Mandow and de la Cruz (2005), managing and expanding labels attached to paths rather than nodes. This variant makes it possible to not expand some sub-paths that will lead to dominated paths whereas they would be expanded by MOA∗. To this end, each detected subpath P from s to n, is given a label l = [nl, gl, fl, Pl], where nl = n is the terminal node of P , gl is the cost vector associated to P , fl is the cost vector gl + h(n) where h(n) is a vectorvalued heuristic of H(n), and Pl is the sequence of nodes 〈s, . . . , n〉 forming P . In the sequel, L(n) will denote the set of labels attached to detected paths in ND(P(s, n)). Two sets of labels are mantained to avoid the expansion of a label already expanded: the set of open labels O contains those labels attached to already detected but not expanded subpaths, and the set of closed labels C contains those labels already detected and expanded. The expansion of a label l, at a given step of the search, proceeds as follows: (1)\nmove l from O to C; (2) insert in O new labels of type [n′, gl + c(n, n′), gl + c(n, n′) + h, 〈Pl, n′〉] for all n′ ∈ S(nl) and h ∈ H(n′).\nAt any iteration, the algorithm selects a new nondominated label in O. It stops when there is no remaining label to expand (i.e. O = ∅), which means there is no remaining Pareto-optimal solution paths to explore.\nStarting from this general multiobjective search procedure, we use two pruning rules to focus the search on ψwv -optimal paths.\nRULE 1: at node n, we prune any label l in L(n)∩O such that there exists another label l′ ∈ L(n) such that gl′ %P gl. Indeed, path Pl cannot lead to a nondominated solution path since any extension of Pl with a sub-path P will be dominated by path Pl′∪P . Therefore, Pl cannot lead to a ψwv -optimal solution path either.\nIn order to introduce the second pruning rule, we consider, for any probability vector p = (p1, . . . , pm) ∈ core(v̄), an arc valuation function cp : A → R+ derived from c by setting cp(a) = ∑ i∈S pic(a, i) for all a ∈ A (linear aggregation of costs). Hence Rule 2 can be expressed as follows.\nRULE 2: at node n we discard any label l such that max{ψwv (fl), w(cp(Pl) + h̄(nl))} ≥ ψwv (x∗), where x∗ is the cost vector of the current ψwv -optimal solution path among all already detected solution paths and h̄(n) is an optimistic heuristic on the cost of the best path from n to a goal node with respect to cp.\nRule 2 enables the early elimination of uninteresting labels while keeping admissibility of the algorithm, provided optimisic heuristic are used. Indeed, consider any solution path P = Pl ∪ P ′ that extends Pl. Then the two following cases must be considered. i) ψwv (fl) ≥ ψwv (x∗). Path P has a cost vector g which is Pareto-dominated by fl provided H is admissible, i.e., ∀n ∈ N,∀h∗(n) ∈ H∗(n), ∃h ∈ H(n) such that h(n) %P h∗(n). Thus we have ψwv (g) ≥ ψwv (fl) and therefore ψwv (g) ≥ ψwv (x∗) by transitivity. ii) w(cp(Pl) + h̄(nl)) ≥ ψwv (x∗). By Proposition 1, we have ψwv (g) ≥ w(cp(P )) where g is the cost vector of P ; moreover w(cp(P )) = w(cp(Pl) + cp(P ′)) ≥ w(cp(Pl)+ h̄(nl)) since h̄ is optimistic. Hence ψwv (g) ≥ w(cp(Pl) + h̄(nl)) ≥ ψwv (x∗). In both cases we have ψwv (g) ≥ ψwv (x∗) which proves that P is suboptimal and justifies Rule 2.\nAlgorithm 2 formally presents the resulting search procedure. In this procedure, sol denotes the current ψwv - optimal solution path represented by the pair (cost vector, sequence of nodes), and ND(L) = {l ∈ L : ∀k ∈ L, gk %P gl ⇒ gl %P gk}.\nAlgorithm 2: Choquet-optimization Initialization: C ← ∅; L(s)← ⋃ h∈H(s){[s; (0, . . . , 0);h; 〈s〉)}; O ← {l′ ∈ L(s)}; l← arg mink∈L(s) max{ψwv (fk), w(h̄(s))} ; λ←∞; while [O 6= ∅, ψwv (fl) < λ, w(cp(Pl) + h̄(nl)) < λ] do\nmove l from O to C; if nl ∈ Γ then\nif ψwv (gl) < λ then sol← (gl, Pl); λ← ψwv (gl);\nelse for each node n′ ∈ S(nl) do\nfor each cost vector h(n′) ∈ H(n′) do x← gl + c(nl, n′) + h(n′); if ψwv (x)) < λ then\ncreate label l′ = [n′, gl + c(nl, n′), x, 〈Pl, n′〉]; L(n′)← ND(L(n′) ∪ {l′}); O ← O ⋃ {l′}\nl← argminl′∈O max{ψwv (fl′), w(cp(Pl′) + h̄(nl′)} ; Output: sol"
    }, {
      "heading" : "3.3 The Ranking Approach",
      "text" : "For any path P j in the graph we have cp(P j) = ∑ a∈P j cp(a) = ∑ a∈P j ∑ i∈S pic(a, i) =∑\ni∈S pi ∑ a∈P j c(a, i) = ∑ i∈S pic(P j , i). Let xj be the cost vector of P j defined by xji = c(P j , i) for all i. Then the Choquet expected disutility associated to P j is ψwv (x j) ≥ w( ∑ i∈S pic(P j , i)) by Proposition 1, which is equal to w(cp(P j)). Therefore we have:\nψwv (x j) ≥ w(cp(P j)) (4)\nHence the value of any path in the graph endowed with the scalar valuation cp provides a lower bound on the optimal value of ψwv (x) over feasible vectors x. This statement led us to seek the optimal solution of ψwv -OPT through a ranking algorithm performing the enumeration of k best paths by increasing values cp(P ), i.e. by increasing values of w(cp(P )). Denoting P 1, . . . , P j the first solution paths in the enumeration, we have cp(P 1) ≤ . . . ≤ cp(P j). Suppose that P j is the first of these paths satisfying w(cp(P j)) ≥ ψwv (x∗) where x∗ = argmini=1,...,j ψwv (x\ni) is the cost of the current ψwv -optimal path P\n∗, then Equation (4) implies that all forthcoming paths P k, k > j in the enumeration will satisfy ψwv (x\nk) ≥ w(cp(P k)). Since by construction w(cp(P k)) ≥ w(cp(P j)) ≥ ψwv (x∗), we get ψwv (x\nk) ≥ ψwv (x∗). Therefore P ∗ is a ψwv -optimal solution path and we can stop the enumeration.\nLet us explain now how to rank solution paths from best to worst according to cp. We propose a modified version of A∗ that uses labels attached to paths. To any detected path P with a cost vector x from s to n ∈ N , we assign a label l = [nl, gl, ḡl, Pl] where nl is node n, gl is cost vector x, ḡl is scalar cost cp(P ), and Pl is the sequence of nodes 〈s, . . . , n〉 forming P . After the determination of a first cp-optimal solution path, we have to continue so as to find the second-best solution path and then the following. For that, all detected sub-paths during the search (i.e., all labels) are kept. Therefore, several labels can be attached to a same node. Moreover, in order to favour a depth-first search in the state space graph, only the current most promising label on each node is expanded, until the corresponding solution path is found. To implement this principle, we use the two sets of nodes O (set of open nodes), and C (set of closed nodes). More precisely, set O is the set of already detected nodes having no expanded label. Set C is defined as the set of nodes having exactly one expanded label corresponding to a path which is not part of an already detected solution path.\nThe complete procedure is formalized in Algorithm 3 given below, where L(n) is the set of labels attached to n, sol is the current ψwv -optimal solution path represented by the ordered-pair (cost vector, sequence of nodes), and h̄ : N → R is an optimistic heuristic on the cost of the best path from n to a goal node with respect to cp."
    }, {
      "heading" : "4 NUMERICAL EXPERIMENTS",
      "text" : "We have performed numerical experiments of Algorithms 2 and 3 on path-planning problems, the size of which varies from 1,000 nodes to 3,000 (with arc density of 45%). On each transition, the cost of each scenario is randomly drawn between 0 and 100. For the two algorithms, the tests have been performed with the convex disutility function w(x) = x2, and a concave capacity v1 defined, for all A ⊆ S, as follows: v1(A) = 1 − ( ∑ i/∈A pi)\n2 for a randomly drawn probability distribution (p1, . . . , pm).\nIn Algorithm 2, heuristic H(n) used at node n is the vector h(n) defined by hi(n) = γh∗i (n) where h ∗ i (n) is the cost of the shortest path in P(n,Γ) with respect to scenario i ∈ S and γ is randomly drawn in [0.7; 1). We have tested Algorithm 3 with a heuristic function h̄ at node n, determined by setting h̄(n) = γh̄∗(n) where h̄∗(n) is the cost of the shortest path in P(n,Γ) with respect to cp, and γ is randomly drawn in [0.7; 1).\nWe compare here execution times of Algorithms 2 (A2) and 3 (A3) for two different lower-bounds obtained for the two probability vectors considered in Section 3.2\nAlgorithm 3: Choquet-optimization by ranking Initialization: C ← ∅; O ← {s}; L(n)← ∅, ∀n ∈ N ; l← [s, (0, . . . , 0), 0, 〈s〉]; L(s)← {l}; λ←∞; while O 6= ∅ and w(ḡl + h̄(nl)) < λ do\nremove l from L(nl); remove nl from O and put nl in C; if nl ∈ Γ then\nif ψwv (gl) < λ then sol← (gl, Pl); λ← ψwv (gl); for each node n in Pl do remove n from C; if L(n) 6= ∅ then\nput n in O; else\nfor each node n ∈ S(nl) do l′ ← [n, gl + c(nl, n), ḡl + c̄(nl, n), 〈Pl, n〉]; if ḡ′l + h̄(n) < λ then L(n)← L(n) ∪ {l′}; if n /∈ C then\nput n in O; l← argmin {ḡ′l + h̄(nl′), l′ ∈ ⋃\nn∈O L(n)}; Output: sol\n(maximal entropy (p∗i ) and Shapley values (φi)). The results are given in Table 1. They show the efficiency of the two algorithms. Remark that execution times are slightly better with Algorithm 3 but the difference is not very significant. Moreover, probabilities p∗i used for linear scalarization seem to provide a slightly better bound than φi in most cases. We have performed the same experiments with another capacity v2 defined, for all A ⊆ S, as follows: v2(A) = ∑ E∩A6=∅ ϕ(E) where {ϕ(E), E ⊆ S} are randomly drawn positive Möbius masses adding up to 1, which ensures that v2 is a plausibility function (for more details, see Shafer (1976);\nChateauneuf and Jaffray (1995)). The execution times were similar."
    }, {
      "heading" : "5 FUTURE WORK",
      "text" : "We have shown the potential of the Choquet integral in modelling risk-averse preferences for path-planning under uncertainty. Despite the complexity of the ψwv - OPT problem in the worst case, the experiments show that the two heuristic search algorithms introduced in the paper are very efficient on average. In the future, it might be interesting to investigate the use of the Choquet integral in dynamic decision making problems e.g. decision trees or Markov decision processes. The main problem there is the existence of dynamic inconsistencies induced by the Choquet integral in sequential decision making.\nAnother direction might be to explore the potential of the Choquet integral in multiobjective planning problems. As shown by Grabisch (1996), the descriptive potential of the Choquet integral provides interesting possibilities in the field of multicriteria analysis. We might use the Choquet integral to characterize fine compromise solution paths in state space graphs. The algorithmic material presented here could certainly be adapted to determine Choquet-optimal paths in such multiobjective search problems."
    }, {
      "heading" : "Acknowledgements",
      "text" : "We would like to thank Jean-Yves Jaffray and Judy Goldsmith for fruitful discussions on this work and anonymous reviewers for their useful comments. This work has been supported by the ANR (project PHAC) which is gratefully acknowledged."
    }, {
      "heading" : "I. Aron and P. van Hentenryck (2002). A constraint satisfaction approach to the robust spanning tree with",
      "text" : "interval data. In Proceedings of the Eighteenth Conference on Uncertainty in Artificial Intelligence. 18–25.\nA. Chateauneuf and J. Jaffray (1995). Local-mobius transforms of monotone capacities. In C. Froidevaux and J. Kohlas (eds.), Symbolic and Quantitative Approaches to Reasoning and Uncertainty . SpringerVerlag, 115–124."
    }, {
      "heading" : "A. Chateauneuf and J. Tallon (2002). Diversification, convex preferences and non-empty core in the choquet",
      "text" : "expected utlity model. Economic Theory 19:509–523.\nG. Choquet (1953). Theory of capacities. Annales de l’Institut Fourier 5:131–295."
    }, {
      "heading" : "G. De Cooman and M. C. M. Troffaes (2005). Dynamic",
      "text" : "programming for deterministic discrete-time systems\nwith uncertain gain. International Journal of Approximate Reasoning 39:257–278."
    }, {
      "heading" : "D. Ellsberg (1961). Risk, ambiguity and the Savage",
      "text" : "axioms. Quarterly Journal of Economics 75:643–669."
    }, {
      "heading" : "M. Grabisch (1996). The application of fuzzy integrals",
      "text" : "in multicriteria decision making. European Journal of Operational Research 89:445–456.\nJ.-Y. Jaffray (1995). On the maximum probability which is consistent with a convex capacity. International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems (IJUFKS) 3(1):27–34."
    }, {
      "heading" : "L. Kaebling, M. Littman, and A. Cassandra (1999). Planning and acting in partially observable stochastic",
      "text" : "domains. Artificial Intelligence 101:99–134.\nP. Kouvelis and G. Yu (1997). Robust discrete optimization and its applications. Kluwer Academic Publishers.\nL. Mandow and J. P. de la Cruz (2005). A new approach to multiobjective A∗ search. In Proceedings of IJCAI-05 . Professional Book Center, 218–223."
    }, {
      "heading" : "I. Murthy and S. Her (1992). Solving min-max",
      "text" : "shortest-path problems on a network. Naval Research Logistics 39:669–683."
    }, {
      "heading" : "P. Perny and O. Spanjaard (2003). An axiomatic approach to robustness in search problems with multiple",
      "text" : "scenarios. In Proc. of the 19th conference on Uncertainty in Artificial Intelligence. Acapulco, 469–476."
    }, {
      "heading" : "P. Perny, O. Spanjaard, and L. Storme (2007). State",
      "text" : "space search for risk-averse agents. In Twentieth International Joint Conference on Artificial Intelligence. 2353–2358.\nM. Puterman (1994). Markov decision processes, discrete stochastic dynamic programming . Wiley & Sons."
    }, {
      "heading" : "D. Schmeidler (1989). Integral representation without",
      "text" : "additivity. Prooceedings of the American Mathematical Society 97(2):255–261.\nG. Shafer (1976). A Mathematical Theory of Evidence. Princeton University Press.\nL. Shapley (1971). Cores of convex games. International Journal of Game Theory 1:11–22.\nB. Stewart and C. White III (1991). Multiobjective A*. Journal of the Association for Computing Machinery 38(4):775–814.\nM. Wellman, K. Larson, M. Ford, and P. Wurman (1995). Path planning under time-dependent uncertainty. In Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence. 532–539.\nP. Wurman and M. Wellman (1996). Optimal factory scheduling using stochastic dominance A∗. In Proceedings of the Twelfth Conference on Uncertainty in Artificial Intelligence. 554–563."
    } ],
    "references" : [ {
      "title" : "A constraint satisfaction approach to the robust spanning tree with interval data",
      "author" : [ "I. Aron", "P. van Hentenryck" ],
      "venue" : "Proceedings of the Eighteenth Conference on Uncertainty in Artificial Intelligence. 18–25.",
      "citeRegEx" : "Aron and Hentenryck,? 2002",
      "shortCiteRegEx" : "Aron and Hentenryck",
      "year" : 2002
    }, {
      "title" : "Local-mobius transforms of monotone capacities",
      "author" : [ "A. Chateauneuf", "J. Jaffray" ],
      "venue" : "C. Froidevaux and J. Kohlas (eds.), Symbolic and Quantitative Approaches to Reasoning and Uncertainty . SpringerVerlag, 115–124.",
      "citeRegEx" : "Chateauneuf and Jaffray,? 1995",
      "shortCiteRegEx" : "Chateauneuf and Jaffray",
      "year" : 1995
    }, {
      "title" : "Diversification, convex preferences and non-empty core in the choquet expected utlity model",
      "author" : [ "A. Chateauneuf", "J. Tallon" ],
      "venue" : "Economic Theory 19:509–523.",
      "citeRegEx" : "Chateauneuf and Tallon,? 2002",
      "shortCiteRegEx" : "Chateauneuf and Tallon",
      "year" : 2002
    }, {
      "title" : "Theory of capacities",
      "author" : [ "G. Choquet" ],
      "venue" : "Annales de l’Institut Fourier 5:131–295.",
      "citeRegEx" : "Choquet,? 1953",
      "shortCiteRegEx" : "Choquet",
      "year" : 1953
    }, {
      "title" : "Dynamic programming for deterministic discrete-time systems",
      "author" : [ "G. De Cooman", "M.C.M. Troffaes" ],
      "venue" : null,
      "citeRegEx" : "Cooman and Troffaes,? \\Q2005\\E",
      "shortCiteRegEx" : "Cooman and Troffaes",
      "year" : 2005
    }, {
      "title" : "Risk, ambiguity and the Savage axioms",
      "author" : [ "D. Ellsberg" ],
      "venue" : "Quarterly Journal of Economics 75:643–669.",
      "citeRegEx" : "Ellsberg,? 1961",
      "shortCiteRegEx" : "Ellsberg",
      "year" : 1961
    }, {
      "title" : "The application of fuzzy integrals in multicriteria decision making",
      "author" : [ "M. Grabisch" ],
      "venue" : "European Journal of Operational Research 89:445–456.",
      "citeRegEx" : "Grabisch,? 1996",
      "shortCiteRegEx" : "Grabisch",
      "year" : 1996
    }, {
      "title" : "On the maximum probability which is consistent with a convex capacity",
      "author" : [ "J.-Y. Jaffray" ],
      "venue" : "International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems (IJUFKS) 3(1):27–34.",
      "citeRegEx" : "Jaffray,? 1995",
      "shortCiteRegEx" : "Jaffray",
      "year" : 1995
    }, {
      "title" : "Planning and acting in partially observable stochastic domains",
      "author" : [ "L. Kaebling", "M. Littman", "A. Cassandra" ],
      "venue" : "Artificial Intelligence 101:99–134.",
      "citeRegEx" : "Kaebling et al\\.,? 1999",
      "shortCiteRegEx" : "Kaebling et al\\.",
      "year" : 1999
    }, {
      "title" : "Robust discrete optimization and its applications",
      "author" : [ "P. Kouvelis", "G. Yu" ],
      "venue" : "Kluwer Academic Publishers.",
      "citeRegEx" : "Kouvelis and Yu,? 1997",
      "shortCiteRegEx" : "Kouvelis and Yu",
      "year" : 1997
    }, {
      "title" : "A new approach to multiobjective A∗ search",
      "author" : [ "L. Mandow", "J.P. de la Cruz" ],
      "venue" : "Proceedings of IJCAI-05 . Professional Book Center, 218–223.",
      "citeRegEx" : "Mandow and Cruz,? 2005",
      "shortCiteRegEx" : "Mandow and Cruz",
      "year" : 2005
    }, {
      "title" : "Solving min-max shortest-path problems on a network",
      "author" : [ "I. Murthy", "S. Her" ],
      "venue" : "Naval Research Logistics 39:669–683.",
      "citeRegEx" : "Murthy and Her,? 1992",
      "shortCiteRegEx" : "Murthy and Her",
      "year" : 1992
    }, {
      "title" : "An axiomatic approach to robustness in search problems with multiple scenarios",
      "author" : [ "P. Perny", "O. Spanjaard" ],
      "venue" : "Proc. of the 19th conference on Uncertainty in Artificial Intelligence. Acapulco, 469–476.",
      "citeRegEx" : "Perny and Spanjaard,? 2003",
      "shortCiteRegEx" : "Perny and Spanjaard",
      "year" : 2003
    }, {
      "title" : "State space search for risk-averse agents",
      "author" : [ "P. Perny", "O. Spanjaard", "L. Storme" ],
      "venue" : "Twentieth International Joint Conference on Artificial Intelligence. 2353–2358.",
      "citeRegEx" : "Perny et al\\.,? 2007",
      "shortCiteRegEx" : "Perny et al\\.",
      "year" : 2007
    }, {
      "title" : "Markov decision processes, discrete stochastic dynamic programming",
      "author" : [ "M. Puterman" ],
      "venue" : "Wiley & Sons.",
      "citeRegEx" : "Puterman,? 1994",
      "shortCiteRegEx" : "Puterman",
      "year" : 1994
    }, {
      "title" : "Integral representation without additivity",
      "author" : [ "D. Schmeidler" ],
      "venue" : "Prooceedings of the American Mathematical Society 97(2):255–261.",
      "citeRegEx" : "Schmeidler,? 1989",
      "shortCiteRegEx" : "Schmeidler",
      "year" : 1989
    }, {
      "title" : "A Mathematical Theory of Evidence",
      "author" : [ "G. Shafer" ],
      "venue" : "Princeton University Press.",
      "citeRegEx" : "Shafer,? 1976",
      "shortCiteRegEx" : "Shafer",
      "year" : 1976
    }, {
      "title" : "Cores of convex games",
      "author" : [ "L. Shapley" ],
      "venue" : "International Journal of Game Theory 1:11–22.",
      "citeRegEx" : "Shapley,? 1971",
      "shortCiteRegEx" : "Shapley",
      "year" : 1971
    }, {
      "title" : "Multiobjective A",
      "author" : [ "B. Stewart", "C. White III" ],
      "venue" : "Journal of the Association for Computing Machinery 38(4):775–814.",
      "citeRegEx" : "Stewart and III,? 1991",
      "shortCiteRegEx" : "Stewart and III",
      "year" : 1991
    }, {
      "title" : "Path planning under time-dependent uncertainty",
      "author" : [ "M. Wellman", "K. Larson", "M. Ford", "P. Wurman" ],
      "venue" : "Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence. 532–539.",
      "citeRegEx" : "Wellman et al\\.,? 1995",
      "shortCiteRegEx" : "Wellman et al\\.",
      "year" : 1995
    }, {
      "title" : "Optimal factory scheduling using stochastic dominance A∗",
      "author" : [ "P. Wurman", "M. Wellman" ],
      "venue" : "Proceedings of the Twelfth Conference on Uncertainty in Artificial Intelligence. 554–563.",
      "citeRegEx" : "Wurman and Wellman,? 1996",
      "shortCiteRegEx" : "Wurman and Wellman",
      "year" : 1996
    } ],
    "referenceMentions" : [ {
      "referenceID" : 19,
      "context" : "For example, Wellman and Wurman consider a case where the costs are time dependent and representable by random variables (Wellman et al., 1995).",
      "startOffset" : 121,
      "endOffset" : 143
    }, {
      "referenceID" : 20,
      "context" : "Moreover, an extension of this algorithm specifically designed to cope with both uncertainty and multiple criteria is proposed in (Wurman and Wellman, 1996).",
      "startOffset" : 130,
      "endOffset" : 156
    }, {
      "referenceID" : 13,
      "context" : "Puterman (1994), Kaebling et al.",
      "startOffset" : 0,
      "endOffset" : 16
    }, {
      "referenceID" : 8,
      "context" : "Puterman (1994), Kaebling et al. (1999). Beside these sources of complexity, the cost transitions between states might also be uncertain.",
      "startOffset" : 17,
      "endOffset" : 40
    }, {
      "referenceID" : 9,
      "context" : "This robustness idea has actively developed in discrete optimization since the publication of the book by Kouvelis and Yu (1997), which considers several criteria imported from decision theory under total uncertainty (e.",
      "startOffset" : 106,
      "endOffset" : 129
    }, {
      "referenceID" : 9,
      "context" : "This robustness idea has actively developed in discrete optimization since the publication of the book by Kouvelis and Yu (1997), which considers several criteria imported from decision theory under total uncertainty (e.g. min-max, min-max regret) to define the absolute or relative robustness of a solution. Under these criteria, the shortest path problem becomes NP-hard, as do many other polynomially solvable problems (see e.g., Aron and van Hentenryck (2002) for robust spanning tree problems), thus bringing new algorithmic challenges.",
      "startOffset" : 106,
      "endOffset" : 464
    }, {
      "referenceID" : 12,
      "context" : "ordered weighted averages have been introduced and justified to model robustness in (Perny and Spanjaard, 2003), as well as a multiobjective search algorithm to determine robust solution paths in state space graphs under total uncertainty.",
      "startOffset" : 84,
      "endOffset" : 111
    }, {
      "referenceID" : 13,
      "context" : "This idea is exploited in (Perny et al., 2007) for path-planning under risk (when probabilities of scenarios are known), where a multiobjective heuristic search algorithm is proposed for the determination of optimal solution paths with respect to second-order stochastic dominance, or expected utility for risk-averse agents.",
      "startOffset" : 26,
      "endOffset" : 46
    }, {
      "referenceID" : 5,
      "context" : "An example of such a problematic situation, inspired by the so-called Ellsberg’s urn example (Ellsberg, 1961), is presented below in the context of path planning:",
      "startOffset" : 93,
      "endOffset" : 109
    }, {
      "referenceID" : 3,
      "context" : "The standard decision model associated to capacities is based on the use of the Choquet integral, following Schmeidler (1989), who gives the foundations of the Choquet Expected Utility criterion (CEU).",
      "startOffset" : 80,
      "endOffset" : 126
    }, {
      "referenceID" : 3,
      "context" : "The Choquet integral (Choquet, 1953) is used in decision theory to generalize the notion of expectation when beliefs in events are represented by a capacity, i.",
      "startOffset" : 21,
      "endOffset" : 36
    }, {
      "referenceID" : 17,
      "context" : "In this case the core of v̄ defined by core(v̄) = {P ∈ L, v̄(A) ≤ P (A) ≤ v(A)} where L is the set of probability measures on S is known to be non-empty since v̄ is convex (Shapley, 1971).",
      "startOffset" : 172,
      "endOffset" : 187
    }, {
      "referenceID" : 3,
      "context" : "In decision theory, the Choquet integral is often used in maximization problems under the form Cv(u(x1), . . . , u(xm)) with utility function u on payoffs to be maximized (CEU criterion, Schmeidler (1989)).",
      "startOffset" : 24,
      "endOffset" : 205
    }, {
      "referenceID" : 2,
      "context" : "A useful formalization of this idea is introduced in Chateauneuf and Tallon (2002) through an axiom named “preference for diversification” due to its interpretation in the context of portofolio manGALAND & PERNY 127",
      "startOffset" : 53,
      "endOffset" : 83
    }, {
      "referenceID" : 2,
      "context" : "Interestingly enough, it is shown in Chateauneuf and Tallon (2002) that, within CEU theory, the above axiom on preference is equivalent to choosing a concave utility u and a convex capacity v.",
      "startOffset" : 37,
      "endOffset" : 67
    }, {
      "referenceID" : 11,
      "context" : "Hence ψ v -OPT reduces to the minmax search problem, which was proved NP-hard by Murthy and Her (1992). This shows that ψ v -OPT is also NP-hard.",
      "startOffset" : 81,
      "endOffset" : 103
    }, {
      "referenceID" : 4,
      "context" : "A similar violation of the Bellman principle is highlighted in De Cooman and Troffaes (2005), in the general framework of dynamic programming with uncertain gain and imprecise probabilities.",
      "startOffset" : 66,
      "endOffset" : 93
    }, {
      "referenceID" : 17,
      "context" : ",m to events (Shapley, 1971).",
      "startOffset" : 13,
      "endOffset" : 28
    }, {
      "referenceID" : 7,
      "context" : "This propability distribution can easily be obtained using the following greedy algorithm proposed in Jaffray (1995), where pi stands for the probability P ∗({i}).",
      "startOffset" : 102,
      "endOffset" : 117
    }, {
      "referenceID" : 16,
      "context" : "We have performed the same experiments with another capacity v2 defined, for all A ⊆ S, as follows: v2(A) = ∑ E∩A6=∅ φ(E) where {φ(E), E ⊆ S} are randomly drawn positive Möbius masses adding up to 1, which ensures that v2 is a plausibility function (for more details, see Shafer (1976); GALAND & PERNY 131",
      "startOffset" : 272,
      "endOffset" : 286
    }, {
      "referenceID" : 3,
      "context" : "Another direction might be to explore the potential of the Choquet integral in multiobjective planning problems. As shown by Grabisch (1996), the descriptive potential of the Choquet integral provides interesting possibilities in the field of multicriteria analysis.",
      "startOffset" : 59,
      "endOffset" : 141
    } ],
    "year" : 2009,
    "abstractText" : "Choquet expected utility (CEU) is one of the most sophisticated decision criteria used in decision theory under uncertainty. It provides a generalisation of expected utility enhancing both descriptive and prescriptive possibilities. In this paper, we investigate the use of CEU for path-planning under uncertainty with a special focus on robust solutions. We first recall the main features of the CEU model and introduce some examples showing its descriptive potential. Then we focus on the search for Choquet-optimal paths in multivalued implicit graphs where costs depend on different scenarios. After discussing complexity issues, we propose two different heuristic search algorithms to solve the problem. Finally, numerical experiments are reported, showing the practical efficiency of the proposed algorithms.",
    "creator" : "Adobe InDesign CS2 (4.0.4)"
  }
}