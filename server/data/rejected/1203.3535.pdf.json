{
  "name" : "1203.3535.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Multi-Domain Collaborative Filtering",
    "authors" : [ "Yu Zhang", "Bin Cao", "Dit-Yan Yeung" ],
    "emails" : [ "zhangyu@cse.ust.hk", "caobin@cse.ust.hk", "dyyeung@cse.ust.hk" ],
    "sections" : [ {
      "heading" : null,
      "text" : "Collaborative filtering is an effective recommendation approach in which the preference of a user on an item is predicted based on the preferences of other users with similar interests. A big challenge in using collaborative filtering methods is the data sparsity problem which often arises because each user typically only rates very few items and hence the rating matrix is extremely sparse. In this paper, we address this problem by considering multiple collaborative filtering tasks in different domains simultaneously and exploiting the relationships between domains. We refer to it as a multi-domain collaborative filtering (MCF) problem. To solve the MCF problem, we propose a probabilistic framework which uses probabilistic matrix factorization to model the rating problem in each domain and allows the knowledge to be adaptively transferred across different domains by automatically learning the correlation between domains. We also introduce the link function for different domains to correct their biases. Experiments conducted on several real-world applications demonstrate the effectiveness of our methods when compared with some representative methods."
    }, {
      "heading" : "1 Introduction",
      "text" : "The amount of information available on the Internet is increasing at an astonishing rate, making information search a more and more challenging task. As such, recommendation plays an important role to bring items of potential interest to our attention. Some popular examples include systems for product recommendation in Amazon.com, movie recommendation in Netflix and MovieLens, and reference recommendation in CiteULike. Collaborative filtering (CF) is an effective recommendation approach based on the intuitive idea that the preference of a user can be predicted by\nexploiting the information about other users which share similar interests. In particular, CF techniques exploit past activities of the users, such as their transaction history or product satisfaction expressed in ratings, to predict the future activities of the users. In recent years, CF-based recommendation systems have become increasingly popular because it is generally much easier to collect the past activities of users than their profiles, partially due to privacy considerations.\nAccording to a survey on CF [26], different CF techniques can be classified into three categories: memorybased methods, model-based methods, and hybrid methods. Similar to the idea of nearest neighbor classification, memory-based methods make rating prediction based on the rating behavior of other items and users with similar interests. Some representative methods are [10, 23, 16]. One limitation of memory-based methods is that they require the rating data to be dense so that the similarity values can be estimated accurately. Unfortunately, this requirement is not realistic in many applications. To achieve better prediction performance and overcome the shortcomings of memory-based CF methods, model-based CF methods have been proposed and actively studied. Model-based CF techniques use the rating data to learn a model and then use the learned model to make predictions. Many learning models have been used for CF, such as Bayesian belief networks [4], graphical models [11, 28], and dependency networks [9]. Among all model-based CF methods, matrix factorization methods are perhaps the most popular one in recent years [2, 25, 20, 5, 21, 22, 14, 32, 29]. These methods assume that the user and item features lie in some lowdimensional latent space and then make predictions based on the latent features. With the hope to improve performance further, hybrid CF techniques have been proposed to combine memory-based methods with model-based methods, or utilize additional information such as content information. Some examples are [1, 18, 19, 17, 30, 31, 13].\nEven though CF methods have achieved great successes in recommendation applications, there still exist some problems which limit their performance. A big challenge is\nthe data sparsity problem [26] which means that the rating matrix is extremely sparse. Our focus in this paper is on this data sparsity problem. In particular, we consider a multi-domain CF (MCF) problem which jointly models a collection of rating prediction tasks arising from multiple domains. The MCF problem is particularly suitable for large-scale e-commerce and social networking services which often provide a diverse range of products or services. For example, different product or service categories such as books and electronics naturally constitute different domains. By exploiting the correlation between rating prediction problems in different domains, we can transfer the shared knowledge among similar domains to alleviate the data sparsity problem and therefore improve the rating prediction performance in all domains. Specifically, we propose a probabilistic framework which uses probabilistic matrix factorization (PMF) [21] to model the rating prediction problem in each domain and allows the knowledge to be adaptively transferred across different domains by automatically learning the correlation between domains. We also introduce the link function for different domains to correct their biases. Experiments conducted on several real-world applications demonstrate the effectiveness of our method.\nThe rest of this paper is organized as follows. We present our method in Section 2 and some improvement in Section 3. Some related works are discussed in Section 4. Section 5 reports the experimental results based on some recommendation datasets. Concluding remarks are given in the final section."
    }, {
      "heading" : "2 Multi-Domain Collaborative Filtering",
      "text" : "Let Xi ∈ ℝmi×ni denote the rating matrix for the ith domain, where i = 1, . . . ,K. So for each domain we havemi users and ni items. In total we havem users in all domains. Let Ui ∈ Rd×m and Vi ∈ ℝd×ni denote the latent user and item feature matrices with each column Uij and each column Vik representing the user-specific and item-specific latent feature vectors, respectively.\nWe define the conditional distribution over the observed ratings on the ith domain as p(Xi∣Ui,Vi, i) = m∏ j=1 ni∏ k=1 [ N (Xijk∣(Uij)TVik, 2i ) ]Iijk , (1) where N (m,Σ) denotes the multivariate (or univariate) normal distribution with mean m and covariance matrix (or variance) Σ, Xijk denotes the rating of the jth user on the kth element in Xi, and Iijk is the indicator function which is equal to 1 if the jth user rated the kth item in the ith domain and is 0 otherwise.\nWe place zero-mean spherical Gaussian priors [27] on the\nuser features and item features as\np(Ui∣ i) = m∏ j=1 N (Uij ∣0d, 2i Id) (2)\np(Vi∣ i) = ni∏ k=1 N (Vik∣0d, 2i Id), (3)\nwhere 0d denotes the d× 1 zero vector and Id denotes the d× d identity matrix.\nTo learn the relationships between different domains, we place a matrix-variate normal distribution [8] on U = [vec(U1), . . . , vec(UK)] where vec(⋅) denotes the operator which converts a matrix into a vector in a columnwise manner:\np(U∣Ω) =ℳNmd×K(U∣0md×K , Imd ⊗Ω), (4)\nwhere 0a×b denotes an a × b zero matrix, and ℳN a×b(M,A⊗B) denotes a matrix-variate normal distribution with mean M ∈ ℝa×b, row covariance matrix A ∈ ℝa×a and column covariance matrix B ∈ ℝb×b. The probability density function of the matrix-variate normal distribution is defined as\np(X∣M,A,B) = exp\n( − 1 2 tr ( A−1(X−M)B−1(X−M)T )) (2 )ab/2∣A∣b/2∣B∣a/2 ,\nwhere tr(⋅) and ∣⋅∣ denote the trace and determinant, respectively, of a square matrix. More specifically, here the row covariance matrix Imd models the relationships between user latent features and the column covariance matrix Ω models the relationships between different Ui’s. In other words, Ω models the relationships between domains."
    }, {
      "heading" : "2.1 Parameter Learning",
      "text" : "The log-posterior over {Ui} and {Vi} is given by\nln p({Ui}, {Vi}∣{Xi}, , , ,Ω)\n=− K∑ i=1 1 2 2i m∑ j=1 ni∑ k=1 Iijk ( Xijk − (Uij)TVik )2 −\nK∑ i=1 1 2 2i m∑ j=1 (Uij) TUij − K∑ i=1 1 2 2i ni∑ k=1 (Vik) TVik\n− 1 2 K∑ i=1 (ln 2i m∑ j=1 ni∑ k=1 Iijk)− md 2 K∑ i=1 ln 2i − K∑ i=1 dni 2 ln 2i − 1 2 tr(UΩ−1UT )− md 2 ln ∣Ω∣+ Const,\n(5)\nwhere = ( 1, . . . , K)T , = ( 1, . . . , K)T , and = ( 1, . . . , K)T . We maximize ln p({Ui}, {Vi}∣{Xi}, , , ,Ω) to obtain the maximum a posteriori (MAP) solution of {Ui} and {Vi} and the maximum likelihood estimation (MLE) solution of , , and Ω. We use an alternating\nmethod to minimize J({Ui}, {Vi}, , , ,Ω) = − ln p({Ui}, {Vi}∣{Xi}, , , ,Ω). In what follows, we will present each subproblem separately.\nOptimizing w.r.t. Uij when the other variables are fixed\nThe derivative of J with respect to Uij can be calculated as\n∂J\n∂Uij =\n1\n2i Uij +\n1\n2i ni∑ k=1 Iijk ( Vik(V i k) TUij −XijkVik )\n+ K∑ l=1 Ulj li,\nwhere Ψ = Ω−1 and ij is the (i, j)th element of Ψ. We set the derivative to zero and obtain the analytical solution as\nUij = ( 2i ( 1\n2i + ii)Id + ni∑ k=1 IijkV i k(V i k) T )−1 ⋅\n( ni∑ k=1 IijkX i jkV i k − 2i ∑ l∕=i liU l j ) . (6)\nConsider a special case in which different domains are uncorrelated, which means that Ω and Ψ are diagonal matrices, i.e., Ψij = 0 for i ∕= j. Then the update solution for Uij is Uij = ( 2i ( 1\n2i + ii)Id + ni∑ k=1 IijkV i k(V i k) T )−1 ni∑ k=1 IijkX i jkV i k,\nwhich degenerates to the update solution for single-domain matrix factorization.\nOptimizing w.r.t. Vik when the other variables are fixed\nThe derivative of J with respect to Vik can be calculated as\n∂J\n∂Vik =\n1\n2i Vik +\n1\n2i m∑ j=1 Iijk ( Uij(U i j) TVik −XijkUij ) .\nWe set the derivative to zero and obtain the analytical solution as\nVik = ( 2i 2i Id+ m∑ j=1 IijkU i j(U i j) T )−1 m∑ j=1 IijkX i jkU i j . (7)\nOptimizing w.r.t. Ω when the other variables are fixed\nSince Ω is defined as a covariance matrix, Ω and Ω−1 are symmetric matrices. Then the derivative of J with respect to Ω−1 can be calculated as\n∂J ∂Ω−1 = UTU−mdΩ− 1 2 (UTU−mdΩ)⊙ IK ,\nwhere⊙ denotes the Hadamard product which is the matrix elementwise product. We set the derivative to zero and get\nΣ = 1\n2 (Σ⊙ IK),\nwhere Σ = UTU−mdΩ. Then we have\nΣii = Σii/2 ⇒ Σii = 0 Σij = 0, i ∕= j,\nwhere Σij is the (i, j)th element of Σ. So Σ is a zero matrix and we obtain the analytical solution for Ω as\nΩ = 1\nmd UTU. (8)\nConsidering Eq. (8), the (i, j)th element Ωij of Ω, which corresponds to the covariance between the ith and jth domains, can be computed as\nΩij = 1\nmd\n( vec(Ui) )T vec(Uj),\nwhich is the scaled dot product of vec(Ui) and vec(Uj). Since vec(Ui) is modeled as latent user features in the ith domain, using the dot product to represent covariance matches our intuition.\nOptimizing w.r.t. i when the other variables are fixed\nThe derivative of J with respect to 2i can be calculated as\n∂J ∂ 2i =− 1 2 4i m∑ j=1 ni∑ k=1 Iijk ( Xijk − (Uij)TVik )2 + 1\n2 2i m∑ j=1 ni∑ k=1 Iijk.\nWe set the derivative to zero and obtain the analytical solution as\n2i =\n∑m j=1 ∑ni k=1 I i jk ( Xijk − (Uij)TVik )2 ∑m\nj=1 ∑ni k=1 I i jk\n. (9)\nOptimizing w.r.t. i when the other variables are fixed\nThe derivative of J with respect to 2i can be calculated as\n∂J ∂ 2i = − 1 2 4i m∑ j=1 (Uij) TUij + md 2 2i .\nWe set the derivative to zero and obtain the analytical solution as\n2i = 1\nmd m∑ j=1 (Uij) TUij . (10)\nOptimizing w.r.t. i when the other variables are fixed\nThe derivative of J with respect to 2i can be calculated as\n∂J ∂ 2i = − 1 2 4i ni∑ k=1 (Vik) TVik + dni 2 2i .\nWe set the derivative to zero and obtain the analytical solution as\n2i = 1\ndni ni∑ k=1 (Vik) TVik. (11)"
    }, {
      "heading" : "2.2 Discussions",
      "text" : "To gain more insights into our method, we plug Eqs. (8), (10) and (11) into J({Ui}, {Vi}, , , ,Ω). By ignoring some constant terms, J({Ui}, {Vi}, , , ,Ω) can be reformulated as\nJ({Ui}, {Vi}, , , ,Ω)\n= K∑ i=1 1 2 2i m∑ j=1 ni∑ k=1 Iijk ( Xijk − (Uij)TVik )2 + 1\n2 K∑ i=1 (ln 2i m∑ j=1 ni∑ k=1 Iijk) + md 2 K∑ i=1 ln ( m∑ j=1 (Uij) TUij )\n+ K∑ i=1 dni 2 ln ( ni∑ k=1 (Vik) TVik ) +\n1\n2(md)K−1 ln ∣UTU∣.\n(12)\nThe first term in Eq. (12) measures the empirical loss on the observed ratings, the second term penalizes the complexity of , the third and fifth terms penalize the complexity of {Ui}, and the fourth term penalizes the complexity of {Vi}.\nSince\nln ( m∑\nj=1\n(Uij) TUij\n) = ln tr ( Ui(Ui)T ) ln ( ni∑\nk=1\n(Vik) TVik\n) = ln tr ( Vi(Vi)T ) ,\nwhich are related to the trace norms of Ui and Vi [25], the third and fourth terms in Eq. (12) penalize the ranks of Ui and Vi, respectively [6]. Moreover, according to [7], using the last term in Eq. (12) is to minimize the product of all singular values of Ui which is related to the rank of Ui."
    }, {
      "heading" : "3 Incorporation of Link Function",
      "text" : "In the above model, the likelihood for the ratings is Gaussian as defined in Eq. (1). However, since the ratings are discrete integral values, Gaussian likelihood is not very suitable and hence using it may affect the performance of our model. Here we consider a modification of our model which first transforms the original ratings by a so-called link function and then applies the above model on the transformed ratings. In what follows, we will present this modification in detail.\nThe link function for the ith domain is denoted by gi(⋅; i) which is parameterized by i. We require gi to be monotonically increasing and mapping onto the whole real line; otherwise the probability measure will not be preserved after the transformation. The transformed ratings are denoted by latent variables Zijk = gi(X i jk). Similar to Eq. (1), the\nlikelihood is defined on Zijk as\np(Zi∣Ui,Vi, i) = m∏ j=1 ni∏ k=1 [ N (Zijk∣(Uij)TVik, 2i ) ]Iijk .\nThen, using the Jacobian transformation, we obtain the likelihood on Xi as\np(Xi∣Ui,Vi, i)\n= m∏ j=1 ni∏ k=1 [ N ( gi(X i jk)∣(Uij)TVik, 2i ) g′i(X i jk) ]Iijk , (13)\nwhere g′i(⋅) denotes the derivative function of gi(⋅). For simplicity of discussion, we assume that different domains share the same link function, i.e., gi(⋅) = gj(⋅), ∀i ∕= j. We denote the common link function as g(⋅) which is parameterized by .\nFor parameter learning, we still maximize the log-posterior to get the MAP solution of {Ui} and {Vi} and the MLE solution of the model parameters including , , , Ω and . In this way, both the original model parameters in the above section and the parameters of the link function are learned simultaneously under the same probabilistic framework. We still use an alternating method to optimize the objective function.\nIn detail, the negative log-posterior of the whole data is computed as\nJ1({Ui}, {Vi}, , , ,Ω, )\n= K∑ i=1 1 2 2i m∑ j=1 ni∑ k=1 Iijk ( g(Xijk)− (Uij)TVik )2 +\nK∑ i=1 1 2 2i m∑ j=1 (Uij) TUij + K∑ i=1 1 2 2i ni∑ k=1 (Vik) TVik\n+ 1\n2 K∑ i=1 (ln 2i m∑ j=1 ni∑ k=1 Iijk) + md 2 K∑ i=1 ln 2i\n+ K∑ i=1 dni 2 ln 2i + 1 2 tr(UΩ−1UT ) + md 2 ln ∣Ω∣ − K∑ i=1 m∑ j=1 ni∑ k=1 Iijk ln g ′(Xijk) + Const. (14)\nThe update equations for {Ui}, {Vi}, , and are similar to Eqs. (6)–(11) by replacingXijk with g(X i jk). For the learning of , since there is no analytical update solution, we use a gradient-based method such as the scaled conjugate gradient method1 to update . More specifically, the gradient of J1 with respect to l, the lth element of , is\n1http://www.kyb.tuebingen.mpg.de/bs/ people/carl/code/minimize/minimize.m\ncomputed as\n∂J1 ∂ l = K∑ i=1 1 2i m∑ j=1 ni∑ k=1 Iijk ( g(Xijk)− (Uij)TVik )∂g(Xijk) ∂ l\n− K∑ i=1 m∑ j=1 ni∑ k=1 Iijk ∂ ln g′(Xijk) ∂ l .\nWhen we want to predict the (q, r)th element in Xi, we first predict the latent variable Ziqr as\nZ̃iqr = (U i q) TVir,\nand then the prediction for Xiqr is computed as\nX̃iqr = g −1(Z̃iqr),\nwhere g−1(⋅) denotes the inverse function of g(⋅). When g(⋅) has a simple form, we can easily find the form of g−1(⋅); when g−1(⋅) is not easy to obtain, we can use numerical methods such as the bisection method to find the unique root of the equation g(x) = Z̃iqr due to the monotonic property of g(⋅).\nIn our experiments, we use g(x) = a ln(bx + c) + d (a, b, c > 0, d ∈ ℝ) as the link function. Here g(x) is monotonically increasing and its domain is the set of all real numbers."
    }, {
      "heading" : "4 Related Work",
      "text" : "There is not much previous work on the MCF problem. The most related one is [24] which proposes a collective matrix factorization (CMF) method for CF. For the case of MCF, the collective matrix factorization method requires a common latent user feature matrix U which is shared by all domains. However, in real applications in which different domains have heterogenous properties, this requirement is not very reasonable. Our model can be viewed as a generalization of the collective matrix factorization method where each domain has its own latent user feature matrix and the correlation matrix between different domains is learned to improve the performance of all rating problems in all domains. In this sense, collective matrix factorization can be viewed as a special case of our model by restricting all Ui to be identical. Moreover, a transfer collaborative filtering model was proposed in [15] which aims at improving the performance of a rating problem with very sparse data with the help of another rating problem which has denser rating data. However, the objective of [15] is different from ours. For example, the model in [15] is to improve one rating problem with the help of another rating problem, but in our case, we want to improve the performance of all rating problems in all domains simultaneously. Moreover, the model in [15] seems to work only for problems with two domains while our model can work for two or more domains in the same way."
    }, {
      "heading" : "5 Experiments",
      "text" : "In this section, we report some experiments on two realworld datasets along with our analysis on the results."
    }, {
      "heading" : "5.1 Experimental Settings",
      "text" : "We test the proposed methods on two public-domain recommendation datasets in which the items come from different domains or sub-domains."
    }, {
      "heading" : "5.1.1 Datasets",
      "text" : "We use two commonly used datasets in our experiments including one from movie ratings and one from book ratings. In both datasets, the items can be divided into multiple heterogeneous domains.\n∙ MovieLens2 is a widely used movie recommendation dataset. It contains 100,000 ratings in the scale 1–5. The ratings are given by 943 users on 1,682 movies. Besides the rating information, genre information about movies is also available.\n∙ Book-Crossing3 is a public book ratings dataset. A subset of the data is used in our experiment, consisting of ratings on books with category information available on Amazon.com. The subset contains 56,148 ratings in the scale 1–10 and these ratings are given by 28,503 users on 9,009 books.\nFor the MovieLens dataset, we use the five most popular genres to define the domains, whereas for the BookCrossing dataset, we use the five general book categories. We randomly select 80% of the rating data from each domain to form the training set and the rest for the test set. Each configuration is iterated 10 times in the experiments."
    }, {
      "heading" : "5.1.2 Evaluation Metric",
      "text" : "In this paper, we use root mean squared error (RMSE) as the measure for performance evaluation:\nRMSE =\n√∑ i,j(rij − r̂ij)2\nN , (15)\nwhere rij denotes the ground-truth rating of user i for item j, r̂ij denotes the predicted rating, and the denominator N is the number of ratings tested. The smaller the RMSE score, the better the performance."
    }, {
      "heading" : "5.1.3 Baselines",
      "text" : "We compare our proposed models with the following two methods:\n2http://www.grouplens.org/ 3http://www.informatik.uni-freiburg.de/∼cziegler/BX/\n∙ Independent collaborative filtering using probabilistic matrix factorization (PMF), which treats different rating prediction problems in different domains independently.\n∙ Collective matrix factorization (CMF) model [24], which handles problems involving multiple matrix factorization tasks.\nIn the following, we refer to our proposed method in Section 2 as MCF and the one in Section 3 as MCF-LF."
    }, {
      "heading" : "5.2 Experimental Results",
      "text" : ""
    }, {
      "heading" : "5.2.1 Parameter Setting",
      "text" : "An appealing advantage of our probabilistic model is that it has very few parameters to set. In fact, the only parameter that needs to be set is the latent dimensionality d. Figure 1 shows the effect of the latent dimensionality on the performance of MCF for a subset of the MovieLens dataset. We can see that the performance in terms of RMSE does not change much after d reaches 10. Therefore, we set d to 10 in the following experiments. Other parameters in PMF, CMF, MCF, MCF-LF are randomly generated."
    }, {
      "heading" : "5.2.2 Results",
      "text" : "Table 1 shows the experimental results on the MovieLens dataset. We can see that our proposed models have the best performance. The models that take multiple domains into consideration (CMF, MCF, MCF-LF) perform better than PMF which treats different domains independently. MCF, which can learn the similarities between different rating prediction problems, performs better than CMF, demonstraing the effectiveness of exploiting the relationships between different domains. Comparing MCF with its variant MCF-LF which has the link function, we can conclude that\nthe link function brings about performance improvement consistently over all domains.\nTable 2 shows the experimental results on the BookCrossing dataset. MCF and MCF-LF are also the best among all methods compared. Different from the situation in the MovieLens dataset, the performance of CMF is worse than that of PMF, even though CMF considers multiple domains jointly. The reason can be inferred from the correlation matrix in Table 4. Since some domains are uncorrelated (1st and 4th domains, and 2nd and 4th domains), the assumption in CMF that different domains share the same latent user features seems not very reasonable, making the performance of CMF worse than that of PMF. However, since our methods can take the correlations between different domains into consideration, they can achieve better performance."
    }, {
      "heading" : "5.2.3 Analysis on Correlation Matrix",
      "text" : "Table 3 shows the correlation matrix between five domains learned from the MovieLens dataset, which seems consistent with intuition. For example, the genres ‘Comedy’ and ‘Thriller’ have the smallest correlation while ‘Romance’ and ‘Drama’ have the largest one. For the genre ‘Action’, we can see that the other genres are ranked into order as: ‘Thriller’, ‘Romance’, ‘Drama’, and ‘Comedy’, which matches our intuition.\nTable 4 shows the correlation matrix between five domains learned from the Book-Crossing dataset. Some relations between different domains revealed also seem intuitive. For example, the categories ‘Mystery & Thrillers’ and ‘Business & Investing’ have nearly zero correlation and the same is true for ‘Science Fiction & Fantasy’ and ‘Business & Investing’. Also, categories ‘Science’ and ‘Religion & Spirituality’ have the largest correlation."
    }, {
      "heading" : "6 Conclusion",
      "text" : "In this paper, we have addressed the multi-domain collaborative filtering problem in which multiple rating prediction problems are jointly learned. We propose a probabilis-\ntic model which considers the correlation between different domains when leveraging all rating data together. Experiments conducted on several recommendation datasets demonstrate the effectiveness of our methods.\nAnother way to alleviate the data sparsity problem in CF is to apply active learning [3, 12]. Unlike many conventional machine learning methods which wait passively for labeled data to be provided in order to start the learning process, active learning takes a more active approach by selecting unlabeled data points to query some oracle or domain expert to reduce the labeling cost. For our future work, we are interested in incorporating active learning into our probabilistic model to further boost the learning performance."
    }, {
      "heading" : "Acknowledgements",
      "text" : "This research has been supported by General Research Fund 622209 from the Research Grants Council of Hong Kong."
    } ],
    "references" : [ {
      "title" : "Recommendation as classification: Using social and content-based information in recommendation",
      "author" : [ "C. Basu", "H. Hirsh", "W.W. Cohen" ],
      "venue" : "In Proceedings of the 15th National Conference on Artificial Intelligence,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1998
    }, {
      "title" : "Learning collaborative information filters",
      "author" : [ "D. Billsus", "M.J. Pazzani" ],
      "venue" : "In Proceedings of the 15th International Conference on Machine Learning,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 1998
    }, {
      "title" : "Active collaborative filtering",
      "author" : [ "C. Boutilier", "R. Zemel", "B. Marlin" ],
      "venue" : "In Proceedings of the 19th Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2003
    }, {
      "title" : "Empirical analysis of predictive algorithms for collaborative filtering",
      "author" : [ "J. Breese", "D. Heckerman", "C. Kadie" ],
      "venue" : "In Proceedings of the 14th Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 1998
    }, {
      "title" : "Collaborative prediction using ensembles of maximum margin matrix factorizations",
      "author" : [ "D. DeCoste" ],
      "venue" : "In Proceedings of the 23rd International Conference on Machine Learning,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2006
    }, {
      "title" : "A rank minimization heuristic with application to minimum order system approximation",
      "author" : [ "M. Fazel", "H. Hindi", "S. Boyd" ],
      "venue" : "In Proceedings American Control Conference,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2001
    }, {
      "title" : "Log-det heuristic for matrix rank minimization with applications to hankel and euclidean distance matrices",
      "author" : [ "M. Fazel", "H. Hindi", "S. Boyd" ],
      "venue" : "In Proceedings American Control Conference,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2003
    }, {
      "title" : "Matrix variate distributions",
      "author" : [ "A.K. Gupta", "D.K. Nagar" ],
      "venue" : null,
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2000
    }, {
      "title" : "Dependency networks for collaborative filtering and data visualization",
      "author" : [ "D. Heckerman", "D. Chickering", "C. Meek", "R. Rounthwaite", "C. Kadie" ],
      "venue" : "In Proceedings of the 16th Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2000
    }, {
      "title" : "An algorithmic framework for performing collaborative filtering",
      "author" : [ "J.L. Herlocker", "J.A. Konstan", "A. Borchers", "J. Riedl" ],
      "venue" : "In Proceedings of the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 1999
    }, {
      "title" : "Preference-based graphic models for collaborative filtering",
      "author" : [ "R. Jin", "L. Si", "C. Zhai" ],
      "venue" : "In Proceedings of the 19th Conference in Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2003
    }, {
      "title" : "A bayesian approach toward active learning for collaborative filtering",
      "author" : [ "Rong Jin", "Luo Si" ],
      "venue" : "In Proceedings of the 20th Conference in Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2004
    }, {
      "title" : "Factorization meets the neighborhood: a multifaceted collaborative filtering model",
      "author" : [ "Y. Koren" ],
      "venue" : "In Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2008
    }, {
      "title" : "Non-linear matrix factorization with gaussian processes",
      "author" : [ "N.D. Lawrence", "R. Urtasun" ],
      "venue" : "In Proceedings of the 26th International Conference on Machine Learning,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2009
    }, {
      "title" : "Transfer learning for collaborative filtering via a rating-matrix generative model",
      "author" : [ "B. Li", "Q. Yang", "X. Xue" ],
      "venue" : "In Proceedings of the 26th International Conference on Machine Learning,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2009
    }, {
      "title" : "A collaborative filtering algorithm and evaluation metric that accurately model the user experience",
      "author" : [ "M.R. McLaughlin", "J.L. Herlocker" ],
      "venue" : "In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2004
    }, {
      "title" : "Contentboosted collaborative filtering for improved recommendations",
      "author" : [ "P. Melville", "R.J. Mooney", "R. Nagarajan" ],
      "venue" : "In Proceedings of the 8th National Conference on Artificial intelligence,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2002
    }, {
      "title" : "Collaborative filtering by personality diagnosis: A hybrid memoryand model-based approach",
      "author" : [ "D. Pennock", "E. Horvitz", "S. Lawrence", "C. Giles" ],
      "venue" : "In Proceedings of the 16th Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2000
    }, {
      "title" : "Probabilistic models for unified collaborative and content-based recommendation in sparse-data environments",
      "author" : [ "A. Popescul", "L. Ungar", "D. Pennock", "S. Lawrence" ],
      "venue" : "In Proceedings of the 17th Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2001
    }, {
      "title" : "Fast maximum margin matrix factorization for collaborative prediction",
      "author" : [ "J.D.M. Rennie", "N. Srebro" ],
      "venue" : "In Proceedings of the 22nd International Conference on Machine Learning,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2005
    }, {
      "title" : "Probabilistic matrix factorization",
      "author" : [ "R. Salakhutdinov", "A. Mnih" ],
      "venue" : "Advances in Neural Information Processing Systems",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2007
    }, {
      "title" : "Bayesian probabilistic matrix factorization using Markov chain Monte Carlo",
      "author" : [ "R. Salakhutdinov", "A. Mnih" ],
      "venue" : "In Proceedings of the 25th International Conference on Machine Learning,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2008
    }, {
      "title" : "Itembased collaborative filtering recommendation algorithms",
      "author" : [ "B.M. Sarwar", "G. Karypis", "J.A. Konstan", "J. Riedl" ],
      "venue" : "In Proceedings of the 10th International World Wide Web Conference,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 2001
    }, {
      "title" : "Relational learning via collective matrix factorization",
      "author" : [ "A.P. Singh", "G.J. Gordon" ],
      "venue" : "In Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2008
    }, {
      "title" : "Maximummargin matrix factorization",
      "author" : [ "N. Srebro", "J.D.M. Rennie", "T.S. Jaakkola" ],
      "venue" : "Advances in Neural Information Processing Systems",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2005
    }, {
      "title" : "A survey of collaborative filtering techniques",
      "author" : [ "X. Su", "T.M. Khoshgoftaar" ],
      "venue" : "Advances in Artificial Intelligence,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 2009
    }, {
      "title" : "Probabilistic principal component analysis",
      "author" : [ "M.E. Tipping", "C.M. Bishop" ],
      "venue" : "Journal of the Royal Statistic Society, B,",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 1999
    }, {
      "title" : "Ordinal boltzmann machines for collaborative filtering",
      "author" : [ "T. Truyen", "D. Phung", "S. Venkatesh" ],
      "venue" : "In Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 2009
    }, {
      "title" : "Large-scale collaborative prediction using a nonparametric random effects model",
      "author" : [ "K. Yu", "J.D. Lafferty", "S. Zhu", "Y. Gong" ],
      "venue" : "In Proceedings of the 26th International Conference on Machine Learning,",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 2009
    }, {
      "title" : "Collaborative ensemble learning: Combining collaborative and content-based information filtering via hierarchical bayes",
      "author" : [ "K. Yu", "A. Schwaighofer", "V. Tresp", "W.-Y. Ma", "H. Zhang" ],
      "venue" : "In Proceedings of the 19th Conference on Uncertainty in Artificial Intelligence,",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 2003
    }, {
      "title" : "Probabilistic memory-based collaborative filtering",
      "author" : [ "K. Yu", "A. Schwaighofer", "V. Tresp", "X. Xu", "H.-P. Kriegel" ],
      "venue" : "IEEE Transactions on Knowledge and Data Engeering,",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 2004
    }, {
      "title" : "Fast nonparametric matrix factorization for large-scale collaborative filtering",
      "author" : [ "K. Yu", "S. Zhu", "J.D. Lafferty", "Y. Gong" ],
      "venue" : "In Proceedings of the 32nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,",
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 2009
    } ],
    "referenceMentions" : [ {
      "referenceID" : 25,
      "context" : "According to a survey on CF [26], different CF techniques can be classified into three categories: memorybased methods, model-based methods, and hybrid methods.",
      "startOffset" : 28,
      "endOffset" : 32
    }, {
      "referenceID" : 9,
      "context" : "Some representative methods are [10, 23, 16].",
      "startOffset" : 32,
      "endOffset" : 44
    }, {
      "referenceID" : 22,
      "context" : "Some representative methods are [10, 23, 16].",
      "startOffset" : 32,
      "endOffset" : 44
    }, {
      "referenceID" : 15,
      "context" : "Some representative methods are [10, 23, 16].",
      "startOffset" : 32,
      "endOffset" : 44
    }, {
      "referenceID" : 3,
      "context" : "Many learning models have been used for CF, such as Bayesian belief networks [4], graphical models [11, 28], and dependency networks [9].",
      "startOffset" : 77,
      "endOffset" : 80
    }, {
      "referenceID" : 10,
      "context" : "Many learning models have been used for CF, such as Bayesian belief networks [4], graphical models [11, 28], and dependency networks [9].",
      "startOffset" : 99,
      "endOffset" : 107
    }, {
      "referenceID" : 27,
      "context" : "Many learning models have been used for CF, such as Bayesian belief networks [4], graphical models [11, 28], and dependency networks [9].",
      "startOffset" : 99,
      "endOffset" : 107
    }, {
      "referenceID" : 8,
      "context" : "Many learning models have been used for CF, such as Bayesian belief networks [4], graphical models [11, 28], and dependency networks [9].",
      "startOffset" : 133,
      "endOffset" : 136
    }, {
      "referenceID" : 1,
      "context" : "Among all model-based CF methods, matrix factorization methods are perhaps the most popular one in recent years [2, 25, 20, 5, 21, 22, 14, 32, 29].",
      "startOffset" : 112,
      "endOffset" : 146
    }, {
      "referenceID" : 24,
      "context" : "Among all model-based CF methods, matrix factorization methods are perhaps the most popular one in recent years [2, 25, 20, 5, 21, 22, 14, 32, 29].",
      "startOffset" : 112,
      "endOffset" : 146
    }, {
      "referenceID" : 19,
      "context" : "Among all model-based CF methods, matrix factorization methods are perhaps the most popular one in recent years [2, 25, 20, 5, 21, 22, 14, 32, 29].",
      "startOffset" : 112,
      "endOffset" : 146
    }, {
      "referenceID" : 4,
      "context" : "Among all model-based CF methods, matrix factorization methods are perhaps the most popular one in recent years [2, 25, 20, 5, 21, 22, 14, 32, 29].",
      "startOffset" : 112,
      "endOffset" : 146
    }, {
      "referenceID" : 20,
      "context" : "Among all model-based CF methods, matrix factorization methods are perhaps the most popular one in recent years [2, 25, 20, 5, 21, 22, 14, 32, 29].",
      "startOffset" : 112,
      "endOffset" : 146
    }, {
      "referenceID" : 21,
      "context" : "Among all model-based CF methods, matrix factorization methods are perhaps the most popular one in recent years [2, 25, 20, 5, 21, 22, 14, 32, 29].",
      "startOffset" : 112,
      "endOffset" : 146
    }, {
      "referenceID" : 13,
      "context" : "Among all model-based CF methods, matrix factorization methods are perhaps the most popular one in recent years [2, 25, 20, 5, 21, 22, 14, 32, 29].",
      "startOffset" : 112,
      "endOffset" : 146
    }, {
      "referenceID" : 31,
      "context" : "Among all model-based CF methods, matrix factorization methods are perhaps the most popular one in recent years [2, 25, 20, 5, 21, 22, 14, 32, 29].",
      "startOffset" : 112,
      "endOffset" : 146
    }, {
      "referenceID" : 28,
      "context" : "Among all model-based CF methods, matrix factorization methods are perhaps the most popular one in recent years [2, 25, 20, 5, 21, 22, 14, 32, 29].",
      "startOffset" : 112,
      "endOffset" : 146
    }, {
      "referenceID" : 0,
      "context" : "Some examples are [1, 18, 19, 17, 30, 31, 13].",
      "startOffset" : 18,
      "endOffset" : 45
    }, {
      "referenceID" : 17,
      "context" : "Some examples are [1, 18, 19, 17, 30, 31, 13].",
      "startOffset" : 18,
      "endOffset" : 45
    }, {
      "referenceID" : 18,
      "context" : "Some examples are [1, 18, 19, 17, 30, 31, 13].",
      "startOffset" : 18,
      "endOffset" : 45
    }, {
      "referenceID" : 16,
      "context" : "Some examples are [1, 18, 19, 17, 30, 31, 13].",
      "startOffset" : 18,
      "endOffset" : 45
    }, {
      "referenceID" : 29,
      "context" : "Some examples are [1, 18, 19, 17, 30, 31, 13].",
      "startOffset" : 18,
      "endOffset" : 45
    }, {
      "referenceID" : 30,
      "context" : "Some examples are [1, 18, 19, 17, 30, 31, 13].",
      "startOffset" : 18,
      "endOffset" : 45
    }, {
      "referenceID" : 12,
      "context" : "Some examples are [1, 18, 19, 17, 30, 31, 13].",
      "startOffset" : 18,
      "endOffset" : 45
    }, {
      "referenceID" : 25,
      "context" : "the data sparsity problem [26] which means that the rating matrix is extremely sparse.",
      "startOffset" : 26,
      "endOffset" : 30
    }, {
      "referenceID" : 20,
      "context" : "Specifically, we propose a probabilistic framework which uses probabilistic matrix factorization (PMF) [21] to model the rating prediction problem in each domain and allows the knowledge to be adaptively transferred across different domains by automatically learning the correlation between domains.",
      "startOffset" : 103,
      "endOffset" : 107
    }, {
      "referenceID" : 26,
      "context" : "We place zero-mean spherical Gaussian priors [27] on the user features and item features as",
      "startOffset" : 45,
      "endOffset" : 49
    }, {
      "referenceID" : 7,
      "context" : "To learn the relationships between different domains, we place a matrix-variate normal distribution [8] on U = [vec(U), .",
      "startOffset" : 100,
      "endOffset" : 103
    }, {
      "referenceID" : 24,
      "context" : "which are related to the trace norms of U and V [25], the third and fourth terms in Eq.",
      "startOffset" : 48,
      "endOffset" : 52
    }, {
      "referenceID" : 5,
      "context" : "(12) penalize the ranks of U and V, respectively [6].",
      "startOffset" : 49,
      "endOffset" : 52
    }, {
      "referenceID" : 6,
      "context" : "Moreover, according to [7], using the last term in Eq.",
      "startOffset" : 23,
      "endOffset" : 26
    }, {
      "referenceID" : 23,
      "context" : "The most related one is [24] which proposes a collective matrix factorization (CMF) method for CF.",
      "startOffset" : 24,
      "endOffset" : 28
    }, {
      "referenceID" : 14,
      "context" : "Moreover, a transfer collaborative filtering model was proposed in [15] which aims at improving the performance of a rating problem with very sparse data with the help of another rating problem which has denser rating data.",
      "startOffset" : 67,
      "endOffset" : 71
    }, {
      "referenceID" : 14,
      "context" : "However, the objective of [15] is different from ours.",
      "startOffset" : 26,
      "endOffset" : 30
    }, {
      "referenceID" : 14,
      "context" : "For example, the model in [15] is to improve one rating problem with the help of another rating problem, but in our case, we want to improve the performance of all rating problems in all domains simultaneously.",
      "startOffset" : 26,
      "endOffset" : 30
    }, {
      "referenceID" : 14,
      "context" : "Moreover, the model in [15] seems to work only for problems with two domains while our model can work for two or more domains in the same way.",
      "startOffset" : 23,
      "endOffset" : 27
    }, {
      "referenceID" : 23,
      "context" : "∙ Collective matrix factorization (CMF) model [24], which handles problems involving multiple matrix factorization tasks.",
      "startOffset" : 46,
      "endOffset" : 50
    }, {
      "referenceID" : 2,
      "context" : "Another way to alleviate the data sparsity problem in CF is to apply active learning [3, 12].",
      "startOffset" : 85,
      "endOffset" : 92
    }, {
      "referenceID" : 11,
      "context" : "Another way to alleviate the data sparsity problem in CF is to apply active learning [3, 12].",
      "startOffset" : 85,
      "endOffset" : 92
    } ],
    "year" : 2010,
    "abstractText" : "Collaborative filtering is an effective recommendation approach in which the preference of a user on an item is predicted based on the preferences of other users with similar interests. A big challenge in using collaborative filtering methods is the data sparsity problem which often arises because each user typically only rates very few items and hence the rating matrix is extremely sparse. In this paper, we address this problem by considering multiple collaborative filtering tasks in different domains simultaneously and exploiting the relationships between domains. We refer to it as a multi-domain collaborative filtering (MCF) problem. To solve the MCF problem, we propose a probabilistic framework which uses probabilistic matrix factorization to model the rating problem in each domain and allows the knowledge to be adaptively transferred across different domains by automatically learning the correlation between domains. We also introduce the link function for different domains to correct their biases. Experiments conducted on several real-world applications demonstrate the effectiveness of our methods when compared with some representative methods.",
    "creator" : "TeX"
  }
}