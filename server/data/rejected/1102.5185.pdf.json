{
  "name" : "1102.5185.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ ],
    "emails" : [ "gluzberg@netvision.net.il" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n10 2.\n51 85\nv1 [\ncs .C\nL ]\n2 5\nFe b\n20 11\nWe examine the class of languages that can be defined entirely in terms of provability in an extension of the sorted type theory (Tyn) by embedding the logic of phonologies, without introduction of special types for syntactic entities. This class is proven to precisely coincide with the class of logically closed languages that may be thought of as functions from expressions to sets of logically equivalent Tyn terms. For a specific sub-class of logically closed languages that are described by finite sets of rules or rule schemata, we find effective procedures for building a compact Tyn representation, involving a finite number of axioms or axiom schemata. The proposed formalism is characterized by some useful features unavailable in a two-component architecture of a language model. A further specialization and extension of the formalism with a context type enable effective account of intensional and dynamic semantics."
    }, {
      "heading" : "1 Introduction",
      "text" : "Traditionally higher-order logic representation of natural language semantics (Thomason, 1974) had to be combined with an additional formalism to describe a syntactic structure of a language and a mapping between the two. This two-component architecture of a language model has not essentially changed with the invention and further rapid development of type-logical grammar (Lambek, 1958; Blackburn et al., 1997), i.e. a parallel logical formalism to describe a syntactic structure: in spite of the very close and deep correspondence between the two logics, their internal languages and semantics remain different.\nSeveral theoretical, methodological and technological issues are rooted in the two-component architecture of a language model, out of which it is important to mention here the following.\n1. A language in such a model cannot express anything about another language of the same model nor, of course, about itself. This kind of expressiveness is, however, one of the characteristic capabilities of a natural language.\n2. Lack of lexical robustness. As the semantic interpretation of a sentence in the two-component language model can be composed only from semantic interpretations of all its constituents, such a model fails to interpret an entire sentence if it contains even a single unrecognized (new) word. Some ad hoc add-ins to the formalism are the only known solution of the issue.\n3. Lack of structural (syntactic) robustness. Unlike the semantic logic, which may be universally applicable for a wide variety of languages, the syntactic logic often requires special extensions in order to cover different languages and even specific structures in the same language. Capturing the semantic categories and their relationships in the very formalism (rather than in a concrete language model) makes it principally incapable of modeling language self-learning, that is derivation of new grammar rules from text samples.\nThese, along with some other issues and needs motivated researches for generalizations based on a single logical system, applicable to both semantics and syntactic structure of a language together, such like (Kasper & Rounds, 1986), (King, 1989) and (Richter, 2004). Higher Order Grammar (HOG) (Pollard & Hana, 2003; Pollard, 2004; Pollard, 2006) is probably the most recent implementation of the idea and the first one based entirely on the mainstream classical higher-order logic (HOL), traditionally applied only to the semantics of natural languages. The specific HOL employed in HOG comes in result of the following main steps:\n1. introduction of a phonological base type and a constant denoting operation of concatenation of phonologies;\n2. introduction of abstract syntax entity base types and constructors of derived types, comprising (together with these base types) a type kind SIGN;\n3. introduction of another type kind HIPER for semantic interpretations, which consists of basic types of individuals and propositions and derived types - functional, product and of function to the boolean type;\n4. embedding all the three logics - of phonologies, signs and hyperintensions - into a single HOL with fixing a correspondence between SIGN and HIPER types and adding the two special families of constants denoting functions from signs to phonologies and from signs to semantic interpretations of corresponding types.\nA concrete language is modeled in HOG by adding a set of non-logical axioms to postulate semantics and phonology of specific words and rules of their composition.\nDue to introduction of the phonological type and constants for mapping signs to phonologies, HOG model is certainly better prepared for a formal account of lexical robustness. Also, since directionality in HOG can be handled by the phonological interpretation, it is sufficient for it to have a single universal sign type constructor (implication) that partially addresses the issue of structural robustness. However, as the syntactic and semantic type kinds are fully separated, HOG still cannot address the issue of self-expressiveness.\nAnother important implication of the HOG architecture, as it was noticed in (Gluzberg, 2009), is that semantic interpretation of any sentence or a constituent of it turns out to be represented not by a single HOL term, nor even by a set of some arbitrarily selected terms (in case of ambiguity), but by a whole class of logically equivalent terms, in a precise sense defined in the referenced work. Referring to languages revealing this semantic property as to logically closed languages, one can say that all HOG-defined languages are necessarily logically closed. It was also explained in (Gluzberg, 2009) why the inverse question, i.e. whether any logically closed language can be defined by a HOG with a given set of base SIGN types and type constructors, cannot be answered positively. This result gives another evidence of the limited robustness of the HOG model.\nIn the present work we examine what can be achieved by embedding into a HOL only the logic of phonologies, without introduction of special types for syntactic entities, but with use of non-logical constants of regular functional types to define syntax-to-phonology and syntax-to-semantics interfaces in a concrete language model. As such a language representation is, as well as HOG, entirely based on provability in the single HOL, all the languages it can model are still logically closed. The main result of this work consists of a proof of the inverse statement: any logically closed language can be represented in the proposed HOL framework. This justifies our referring to it as to Universal Higher-Order Grammar. Being fully free of embedded\nsyntactic restrictions and of limitations on types of semantic interpretations, this formalism can efficiently address all the issues with the two-component architecture of a language model mentioned above and therefore may have several theoretical and practical implications.\nThe structure of the paper is as follows. After the introduction in Section 2 of basic notations and some assumptions on the axiomatization of a sorted type theory (Tyn), in Section 3 we define the class of logically closed languages and introduce a few basic operations that act within this class.\nIn Section 4 we define an extension TyAn of Tyn by interpreting one of its base types as symbolic, which is quite similar to the phonological type of HOG, and introduce the notion of Tyn-representability of a language, illustrated with a few preliminary examples.\nThen in Section 5 we prove that classes of Tyn-representable and logically closed languages precisely coincide.\nIn the following sections we give explicit constructions of special Tyn representations for some important sub-classes of logically closed languages that are described by finite sets of rules or rule schemata.\nIn Section 6 we consider so-called lexicons, i.e. finitely generated logically closed languages, define special canonic Tyn representation and prove that a language has a canonic representation if and only if it is a lexicon.\nIn Section 7 a Tyn representation is built for a recursive logically closed grammar (RG), defined as a tuple of logically closed languages linked with each other by a set of relationships expressed by the basic operations introduced in Section 3. As it becomes clear from illustrating examples, the language components of an RG stand for syntactic categories.\nIn Section 8 we consider a further specialization of TyAn by interpreting another base type as a context, similar (though not identical) to ”state of affairs” or ”World” types of (Gallin, 1975) and (Pollard, 2005), respectively. This specialization allows to represent also intensional languages and further define instructive and context-dependent languages. Introduction of a few new language construction operations then allows us to generalize the previous results to context-dependent languages. We demonstrate some important capabilities of this formalism by examples of how it addresses pronoun anaphora resolution.\nIn Section 9 we introduce translation and expression operators that lead to a special language representation, revealing a useful property of partial translation.\nIn Section 10 we conclude by briefly summarizing and discussing the most important implications of the obtained results and outline some open issues."
    }, {
      "heading" : "2 Notations",
      "text" : "Following (Gallin, 1975), we denote by Tyn a sorted type theory with a set of primitive types consisting of the truth type t and individual types e1, e2, ... en of n > 1 different sorts. For the first individual type we will also use a shorter alias e =def e1. For sake of better visibility and compactness we combine the full syntax of Tyn from syntaxes of Ty2 of (Gallin, 1975) and Q0 of (Andrews, 1986) and extend it as follows.\nDerived types\n(i) If α and β are types, then (αβ) or just αβ is a functional type, interpreted as type of functions from α to β. The parenthesis are mandatory only in complex types, in order to express association in an order other than from right to left, for example: et, tee, (et)e are equivalent to (et), (t(ee)), ((et)e). Note that, unlike (Andrews, 1986), we write “from” and “to” types from left to right.\n(ii) If α and β are types, then (α × β) or just α × β is a product type, interpreted as type of pairs of elements from α and β, so that, for example, (α × β)γ is equivalent to αβγ and γ(α × β) to γα × γβ. Repeated product constructors are also associated from right to left, i.e. (α× β × γ) is equivalent to (α× (β × γ)).\nVariables\nx, y, z subscripted by types and optionally superscripted by integer indices stand for variables of corresponding types, for example: yet, x 1 e, x 2 e.\nConstants\nNon-logical constants are written as capital C in bold, subscripted by a type and superscripted by an index, like C0t . We do not assume Tyn to necessarily have a constant Ciα of a given type α for any index i. Rather, we assume the constants to be indexed in such a way that admits expanding Tyn by arbitrarily many new constants of any type. We also use arbitrary letters or words in bold (likeAssert or Empty) as mnemonic aliases for some constant\nthat are assumed to have special semantics or/and satisfy some non-logical axioms in an extension of Tyn. Similar notations may also be introduced for some logical constants, i.e. pure bound terms, like, for example, identity Iαα =def λxαxα.\nTerms\n(i) Variables and constants comprise elementary terms.\n(ii) If Aαβ and Bα are terms of the corresponding types, then application Aαβ Bα is a term of type β denoting (in an interpretation of Tyn) the value of the function denoted by Aαβ at the argument denoted by Bα.\n(iii) If Aβ is a term of type β then lambda abstraction λxαAβ is a term of type αβ denoting a function whose value for any argument is the denotation of Aβ.\n(iv) If Aα and Bα are terms of type α, then Aα = Bα is a term of type t, denoting the identity relation between elements of type α.\n(v) If Aα and Bβ are terms of the corresponding types, then the pair (Aα, Bβ) is a term of type α × β denoting the ordered pair of denotations of Aα and Bβ; repeated operators (, ) are associated from right to left, so that a tuple (A1α1 , A 2 α2 , ...Amαm) denotes the same as\n(A1α1 , (A 2 α2 , (...Amαm)...)).\n(vi) Finally, for a term Aα×β of a type α×β, projections π1Aα×β and π2Aα×β are terms of types α and β respectively, denoting the elements of the pair denoted by Aα×β .\nWe assume an axiomatization of Tyn be a straightforward generalization to case of n > 2 individual types of either the theory denoted as Tyn + D in (Gallin, 1975) or the theory Q0 of (Andrews, 1986). With either choice, for any type α the description operator ι(αt)α and hence the ”if-then-else” constant Cααtα are available with the fundamental properties\n⊢ ι(αt)α λxα(yα = xα) = yα\n⊢ Cααtα xα yα T = xa, ⊢ Cααtα xα yα F = ya.\nAll the usual Boolean connectives, including terms F and T denoting the false and true values, and quantifiers can be defined in Tyn exactly the\nsame way as in Ty2 and Q0. In addition, we will also employ the following notational shortcuts:\nAα 6= Bα =def ∼ (Aα = Bα),\n∼ Aαt =def λxα ∼ (Aαt xα),\nAαt ∨Bαt =def λxα(Aαt xα ∨ Bαt xα),\nAαt ∧Bαt =def λxα(Aαt xα ∧ Bαt xα),\nAαt &Bβt =def λxαλxβ(Aαt xα & Bβt xβ),\nAαt → Bβt =def ∀xα(Aαt xα → Bαt xα),\nAα|Bα =def Cααtα Aα Bα,\nand, for an arbitrary binary operator O:\n(O Bβ) =def λxα(xα O Bβ),\n(Aα O) =def λxβ(Aα O xβ),\n(O) =def λxαλxβ(xα O xβ),\n(an operator sign in such shortcuts might be subscripted by a type, like, for example, (=eet) to denote specifically λxeλye(xe = ye).\nIn the meta-language:\n(i) the ⊢ sign denotes provability in Tyn or an extension of it, specified by a context;\n(ii) the notation Aα(Bβ) stands for the result of substituting all occurrences of a free variable xβ in a term Aα by a term Bβ free for xβ in Aα;\n(iii) if M is a model of Tyn and a - an assignment of variables in this model, then J·KM denotes interpretation of a constant in M and J·KM,a denotes the value of an arbitrary term assigned to it by a in M ;\n(iv) =⇒ and ⇐⇒ express implication and logical equivalence."
    }, {
      "heading" : "3 Logically closed languages",
      "text" : "The two fundamental formalizations of the notion of language with which we deal in this work - α-language and logically closed α-language have been introduced and informally discussed in (Gluzberg, 2009). We reproduce these\nformal definitions here with the current notations for more convenient references.\nDefinition 3.1. Let A be a finite alphabet {a1, a2, ... aN}, let A∗ denote the set of all words over this alphabet and let Tα denote the set of all α-terms of Tyn. An α-language is a relation L ⊂ A ∗ ⊗ Tα.\nReferring to words over alphabet A as “expressions” and α-terms as “αmeanings,” one can say that an α-language is a set of pairs of expressions and their α-meanings. A set of words L ⊂ A∗ can then be considered as a language for the unit type meaning. In general case, the projection of L to A∗ is the set of all valid expressions of L, to which set we refer as to domain of the language and the projection of L to Tα is the set of all meanings L can express, to which set we refer as to range of the language.\nA trivial particular case of an α-language is a singleton {(w,Aα)}, where w ∈ A∗.\nIf L and K are α-languages, then their union L ∪ K is a new α-language that contains all expressions and corresponding meanings of both L and K.\nThe following definitions introduce some further operations to build complex languages from simpler ones.\nDefinition 3.2. If L is an α-language and K is a β-language, then their language concatenation is the α× β-language\nL ∗ K =def {(uv, (Aα, Bβ)) | (u,Aα) ∈ L ∧ (v, Bβ) ∈ K}\nwhere uv denotes concatenation of words u and v.\nDefinition 3.3. For a given α-language L and a relation R ⊂ Tα ⊗ Tβ, the semantic rule application is the β-language\nL ⊲R =def {(w,Bβ) | (w,Aα) ∈ L ∧ (Aα, Bβ) ∈ R}.\nThus, application of a semantic rule cannot extend the domain of a language, but only maps the set of meanings of every its expression to another set (generally of a different type); if the new set turns out to be empty, then the corresponding expression is ”filtered out” from the domain of resulting language. An important example of a semantic rule application is ”folding” product-type meanings of a concatenation of two languages to meanings of a scalar type. Note that a folding rule which also filters out some expressions\nfrom the language concatenation in fact can check an agreement between the concatenated constituents (at the semantic level).\nThe above definition of an α-language seems to provide the most general formalization for the notion of a language whose distinct meanings are understood as syntactically different (although possibly logically equivalent) Tyn terms of a certain type. For example, the representation of Tyn formulas in the Tyn language is itself a t-language. In the application to natural languages, however, a more restricted formalization might be more suitable:\nDefinition 3.4. A logically closed α-language is an α-language L such that whenever (w,Bα) ∈ L, (w,Cα) ∈ L and ⊢ Aα = Bα ∨ Aα = Cα then (w,Aα) ∈ L also. A minimal logically closed α-language L which includes a given arbitrary α-language L is said to be its logical closure.\nThis definition actually captures the two important features of a logically closed α-language:\n1. If an expression w in the language has a meaning Bα, then it also has every meaning Aα logically equivalent to Bα\n2. If an expression w is ambiguous, i.e. has at least two distinct meanings Bα and Cα being not logically equivalent, then it also has every meaning Aα which is provable to be equal either Bα or Cα.\nTherefore, every valid expression of a logically closed language is associated not with a single, nor even with a set of arbitrarily selected terms (in case of ambiguity), but with a whole class of logically equivalent terms. A precise formulation of this interpretation follows.\nDefinition 3.5. A set M ⊂ Tα is said to be logically closed iff whenever Bα ∈ M, Cα ∈ M and\n⊢ Aα = Bα ∨Aα = Cα (3.1)\nthen Aα ∈ M also. A minimal logically closed set M ⊂ Tα which includes an arbitrary set M ⊂ Tα is said to be its logical closure. If in addition, N ⊂ Tα and M = N , we say the two sets M and N be logically equivalent and denote this relation as M ≃ N .\nIt is readily seen that ≃ is an equivalence relation in the power set P(Tα) and therefore a logically closed α-language might be defined equivalently as a function L : A∗ → P(Tα)/ ≃.\nThe simplest non-empty logically closed α-language is a logical singleton\nS = {w} ⊗ {Aα}. (3.2)\nAs it has been shown in (Gluzberg, 2009), any language defined by a Higher Order Grammar (HOG) (Pollard & Hana, 2003; Pollard, 2004; Pollard, 2006) is necessarily logically closed.\nNote that the class of logically closed languages is not closed under the union operation nor under operations of language concatenation and semantic rule applications defined above. Similar operations that act within this class can be defined as follows.\nDefinition 3.6. If L and K are α-languages, then their logical join is an α-language L∪K =def L ∪ K.\nDefinition 3.7. If L is an α-language and K is a β-language, then their logical concatenation is an α× β-language L∗K =def L ∗ K.\nDefinition 3.8. A semantic rule R ⊂ Tα ⊗ Tβ is said to be logically closed if the full image of any logically closed set M ⊂ Tα under the relation R is logically closed.\nThus, a logical join and logical concatenation of arbitrary languages, as well as application of a logically closed semantic rule to any language of the matching type, are all logically closed languages.\nThe following associativity and monotonicity properties follow directly from the above definitions.\nLemma 3.1. For any α-languages K,L, a β-language M and a rule R ⊂ Tα ⊗ Tβ,\n(K∪L) ∗M = K∗M ∪ L∗M,\nM∗(K∪L) = M∗K ∪ M∗L,\n(K∪L) ⊲R = K ⊲R ∪ L ⊲R,\nK ⊂ L =⇒ K∗M ⊂ L∗M,\nK ⊂ L =⇒ M∗K ⊂ M∗L,\nK ⊂ L =⇒ K ⊲R ⊆ L ⊲R.\nDefinition 3.9. A logically closed set M ⊂ Tα is said to be finitely generated if it is the logical closure of a finite set M ⊂ Tα.\nDefinition 3.10. A logically closed semantic rule R ⊂ Tα ⊗ Tβ is said to be finitely ambiguous if for any term Aα, the full image of {Aα} under the relation R is finitely generated.\nAn important class of finitely ambiguous semantic rules is given by the following\nDefinition 3.11. A logically closed semantic rule R ⊂ Tα ⊗ Tβ is said to have a canonic representation in Dα ⊂ Tα if there exists a TyAn term Rαβt such that\n(Aα, Bβ) ∈ R ⇐⇒ ⊢ Rαβt Aα Bβ\nand for any Aα ∈ Dα\n⊢ Rαβt Aα = k∨\ni=1\n(= Biβ),\nwhere the terms B1β , ... B k β as well as the number k may depend on Aα and in the case k = 0 the disjunction is reduced to λxβF. We further qualify a rule with a canonic representation in Dα ⊂ Tα as non-degenerate, degenerate, unambiguous or ambiguous in Dα, if k > 0 for all Aα ∈ Dα, k = 0 for some Aα ∈ Dα, k = 1 for all Aα ∈ Dα or k > 1 for some Aα ∈ Dα, respectively.\nAn important example of a semantic rule with a canonic representation in any domain is given by a particular case where\nRαβt =def λxα(= Fαβ xα)\nwhich is referred to below as a functional semantic rule. Note that a functional rule is both non-degenerate and unambiguous in any domain.\n4 Symbolic type and Tyn-representable\nlanguages\nConsider an extension TyAn of Tyn with the following set of non-logical axioms, where s denotes the primitive type en and As +Bs =def C 0 sss As Bs:\n∀xs((xs +C 0 s = xs) ∧ (C 0 s + xs = xs)), (4.1)\n∀xs∀ys∀zs((xs + ys) + zs = xs + (ys + zs)), (4.2)\n∀xs∀ys∀zs(xs +C i s + ys 6= xs +C j s + zs), for all 1 ≤ i < j ≤ N. (4.3)\nIt is easy to see that these axioms are valid in a model M with the s-domain Ds =def A∗ and interpretation J·KM such that JC0sKM is the empty word ǫ ∈ A∗, JCisKM is ai ∈ A for 1 ≤ i ≤ N , all the rest of the s-constants are interpreted by compound words from A∗ and, finally, the operation (+) is interpreted as the operation of word concatenation. This observation proves the consistency of TyAn and justifies our referring to the type s as symbolic type. Note that formally, with the accuracy up to the additional axiom 4.3, the symbolic type is quite similar to the phonological type of HOG (Pollard, 2006). We use the different term here in order to reflect the additional axiomatic restriction, expressing distinction of the alphabet symbols, significant in any context, and also keeping in mind that generally they may stand for symbols of an arbitrary nature, for example, graphic, as well as phonetic, in which case TyAn might be further extended to accommodate more symbol aggregation operations in addition to the linear concatenation.\nTyAn allows some α-languages to be naturally defined by its terms or possibly by the terms of its extension TyA+n with a set of additional nonlogical constants. Indeed, define the mapping TA : A∗ → Ts as follows\nTA(ǫ) = C 0 s, TA(ai) = C i s, TA(aiw) = C i s + TA(w), (4.4)\nand let ∆ be a consistent set of TyA+n formulas. Then the condition\n∆ ⊢ Lsαt TA(w) Aα\nfor any TyA+n term Lsαt defines an α-language (⊢ here and everywhere below denotes provability in TyA+n ).\nDefinition 4.1. Let TyA+n be an extension of Ty A n , ∆ a consistent set of Ty A+ n formulas and Lsαt a Ty A+ n term. An α-language L is said to be represented by (∆, Lsαt) if for any Ty A n term Aα and w ∈ A ∗\n(w,Aα) ∈ L ⇐⇒ ∆ ⊢ Lsαt TA(w) Aα.\nNote that in the case of a finite set ∆, by the Deduction Theorem, a language represented by (∆, Lsαt) is also represented by (∅, λxsλxα(Dt → Lsαtxsxα)) where Dt is the conjunction of all formulas of ∆ and the variables xs, xα are not free in Dt. In this case we say the language to have a compact Tyn representation or, alternatively, to be represented by a term.\nDefinition 4.2. An α-language L is said to be representable in TyAn , or Tynrepresentable for short, if there exists an extension TyA+n of Ty A n , a consistent set ∆ of TyA+n formulas and a Ty A+ n term Lsαt such that L is represented by (∆, Lsαt).\nHere are a few simple examples of Tyn-representable languages:\n• the term (= TA(w)) &(= Aα) represents a logical singleton (3.2);\n• the term λxs(= C0sα xs) represents an α-language where every word w is a valid expression for the application C0sα TA(w);\n• the term (=sst) represents an s-language that realizes the mapping (4.4), i.e. associates with every word w a single “meaning” TA(w).\nIn case of alphabet A consisting of symbols that can be typed in this paper (including a space), a more convenient notation for mapping TA can be introduced: if w is an arbitrary string of such symbols, let /w/ =def TA(w). Then, by definition 4.1, for arbitrary strings u, v, /u/ + /v/ = /uv/; for example: /c/+/a/+/r/ = /car/. We will make use of this practical notation in some of subsequent sections.\n5 Tyn representation existence theorem\nWe now show that an α-language is Tyn-representable if and only if it is logically closed.\nProposition 5.1. If an α-language L is Tyn-representable, then it is logically closed.\nProof. Let (∆, Lsαt) be a representation of L, w ∈ A∗,\n∆ ⊢ Lsαt TA(w)Bα, ∆ ⊢ Lsαt TA(w) Cα and ⊢ Aα = Bα ∨Aα = Cα.\nFrom this derivation, by the metatheorems\n⊢ At ∨ Bt = (At|Bt)Bt, (5.1)\n⊢ (Pαβ Aα|Pαβ Bα) Ct = Pαβ((Aα|Bα) Ct), (5.2)\nit follows that ⊢ Aα = (Bα|Cα) (Aα = Cα)\nand\n⊢ Lsαt TA(w)Aα = (Lsαt TA(w)Bα | Lsαt TA(w) Cα) (At = Cα).\nThus the first two derivations imply ∆ ⊢ LsαtTA(w)Aα, that is, (w,Aα) ∈ L also.\nLemma 5.2. In any TyAn model, the s-domain Ds contains a subset D ′ s isomorphic to A∗ with respect to concatenation operations and such that JTA(w)KM ∈ D′s for any w ∈ A ∗.\nProof. Let M be a TyAn model and ci =def JC i sKM for i = 0, ... N . Define the mapping VA : A∗ → Ds as follows:\nVA(ǫ) = c0, VA(ai) = ci, VA(ai + w) = ci J+KM VA(w).\nSince axioms 4.1 - 4.3 are valid in M , VA is a one-to-one mapping and\nVA(u+ v) = VA(u) J+KM VA(v).\nThus the full image D′s of A ∗ under this mapping is isomorphic to A∗ and, by Definition 4.4, JTA(w)KM ∈ D′s for any w ∈ A ∗.\nThis lemma actually allows to identify JTA(w)KM with w, J+KM - with word concatenation and the subset D′s - with A ∗ in any TyAn model M .\nLemma 5.3. If M ⊂ Tα is logically closed, A1α ∈ M, ... A k α ∈ M and ⊢ Aα = A1α ... ∨ Aα = A k α, then Aα ∈ M also.\nProof. The proof is by induction on k. For k ≤ 2, the statement follows directly from Definition 3.5. For k > 2, by the metatheorems 5.1, 5.2 and\n⊢ (((Aα|Bα) Ct) = Aα) ∨ (((Aα|Bα) Ct) = Bα),\nwe have ⊢ Aα = Bα ∨Aα = A k α,\nwhere\nBα =def (...(A 1 α| ...|A k−2 α )(Aα = A k−2 α )|A k−1 α )(Aα = A k−1 α )\nand therefore ⊢ Bα = A 1 α ... ∨ Bα = A k−1 α .\nThus, if this implies thatBα ∈ M, then Aα ∈ M also, according to Definition 3.5.\nProposition 5.4. Let an α-language L be logically closed, let the constant C0sαt belong to Ty A+ n , but not to Ty A n , and let ∆L be the minimal set of Ty A+ n formulas such that, whenever (w,Aα) ∈ L, the formula C0sαtTA(w)Aα belongs to ∆L. Then (∆L,C 0 sαt) is a representation of L.\nProof. Consistency of the set ∆L follows from the fact that all its formulas are valid in a model where the constant C0sαt is interpreted by a function taking the true value for all its arguments.\nThe implication (w,Aα) ∈ L =⇒ ∆L ⊢ C 0 sαt TA(w) Aα follows directly from the definition of ∆L. To prove the opposite implication, assume that ∆L ⊢ C0sαt TA(w)Aα and ∆w is the (necessarily finite) subset of axioms from ∆L participating in a proof of this derivation, so that\n∆w ⊢ C 0 sαt TA(w)Aα (5.3)\nas well. Let A1α, ... A k α be all those terms that occur in the formulas C0sαt TA(w) A i α belonging to ∆w. If (w,Aα) 6∈ L, then there exist a Ty A n model M and an assignment of variables a such that JAαKM,a 6= JAiαKM,a for all i = 1, ...k. Indeed, due to the Completeness Theorem, we would otherwise have\n⊢ Aα = A 1 α ... ∨Aα = A k α\nand therefore, by Lemma 5.3 and the assumption of logical closure of L, (w,Aα) ∈ L. Consider an extension M+ of the model M for TyA+n where JC0sαtKM is the function taking the true value for all its arguments except for (w, JAαKM,a) (where w stands for JTA(w)KM , according to Lemma 5.2). All formulas of ∆w are satisfied by the assignment a in M\n+, but C0sαt TA(w)Aα is not. By the Soundness Theorem, this contradicts 5.3 and thus proves that (w,Aα) ∈ L.\nPropositions 5.1 and 5.4 immediately imply\nTheorem 5.5. An α-language is Tyn-representable iff it is logically closed.\nNote that this general result is not constructive in the sense that it does not entail an effective procedure for actually building a Tyn representation for an infinite language that might be defined by a finite set of rules or rule schemata. At the same time, it neither implies the uniqueness of the Tyn representation and thus does not preclude a representation of such a language\nthat may be compact or described by a finite set of axiom schemata. We will find such representations for some important special classes of logically closed languages in the following sections."
    }, {
      "heading" : "6 Lexicons and canonic representation",
      "text" : "Definition 6.1. An α− lexicon is a logically closed α-language which is the logical closure of a finite α-language.\nDefinition 6.2. An α-language is said to have a canonic representation if it is represented by a term Lsαt such that\n⊢ Lsαt = (= A 1 s) &(= A 1 α) ... ∨ (= A l s) &(= A l α)\nwhere all Ais are s-constants and A i α are Tyn terms.\nIn this section we show that any α-lexicon has a canonic representation.\nLemma 6.1. ⊢ TA(u) = TA(v) iff u = v and ⊢ TA(u) 6= TA(v) iff u 6= v.\nProof. According to 4.1 – 4.3, if m = l and i1 = j1, ... il = jl, then\n⊢ Ci1s ... +C il s = C j1 s ... +C jm s\nand if at least one of these conditions does not hold, then\n⊢ Ci1s ... +C il s 6= C j1 s ... +C jm s .\nThis proves both statements.\nLemma 6.2. Let the mapping TAα from the set of α-languages to the power set P(Ts ⊗ Tα) be defined by\nTAα(L) = {(TA(w), Aα) | (w,Aα) ∈ L}.\nThen L is the logical closure of L iff TAα(L) is the logical closure of TAα(L).\nProof. As usual for any closure constructed by a ternary relation, a term belongs to a logical closure iff there exists a finite proof tree where this term is the root, every non-leaf node Aα has a pair of children Bα, Cα that satisfy the relation (3.1) and all leaves belong to the original set. Similarly, a pair\nfrom A∗⊗Tα belongs to the logical closure of an α-language iff there exists a finite proof tree where this pair is the root, every non-leaf node (w,Aα) has a pair of children (w,Bα), (w,Cα) where Bα and Cα satisfy the relation (3.1) and leaves belong to the original language. Replacing every node (w,Aα) of such a tree with (TA(w), Aα) by Lemma 6.1 converts it to a proof tree for the logical closure of TAα(L). Thus if L is the logical closure of L, then TAα(L) is the logical closure of TAα(L). To prove the opposite implication, note that due to the tautology\n⊢ At ∧ Ct ∨ Bt ∧Dt → Ct ∨Dt,\nthe relation\n⊢ As = Bs ∧ Aα = Bα ∨ As = Cs ∧ Aα = Cα\nimplies (3.1). Therefore replacing every node (As, Aα) of a proof tree for the logical closure of TAα(L) with (w,Aα), where w is the expression occurring in the root of the original tree, converts it to a proof tree for L, by Lemma 6.1.\nDefinition 6.3. A set M ⊂ Tα is said to be represented by a term Mαt if Aα ∈ M ⇐⇒ ⊢ MαtAα.\nLemma 6.3. The logical closure M of a finite set M = {A1α, ... A k α} is represented by the term Mαt =def (= A 1 α) ... ∨ (= A k α).\nProof. ⊢ MαtBα and ⊢ MαtCα together with (3.1) imply ⊢ MαtAα by the metatheorem\n⊢ (Aα = Bα ∧MαtBα) → MαtAα\n(also applied to Cα) and the tautology\n⊢ (At ∨Bt) ∧Dt ∧ Et → (At ∧Dt ∨ Bt ∧ Et).\nThus, the set defined by ⊢ MαtAα is logically closed and therefore, according to Definition 3.5, includes M. The opposite inclusion follows directly from Lemma 5.3.\nTheorem 6.4. A logically closed language has a canonic representation iff it is a lexicon.\nProof. Let L = {(w1, A1α), ... (wl, A l α)} and\nLsαt =def (= A 1 s) &(= A 1 α) ... ∨ (= A l s) &(= A l α),\nwhere Ais =def TA(wi). According to Lemma 6.3, the term Lsαt represents the logical closure of TAα(L) and therefore, according to Lemma 6.2, also the logical closure L."
    }, {
      "heading" : "7 Recursive languages and representations",
      "text" : "Given a finite set of lexicons, one can obtain an arbitrarily complex logically closed language by recursively applying the operations of logical join, logical concatenation and application of semantic rules to the initial lexicons. In this section we will see how a compact Tyn representation of such a recursive language can be built.\nDefinition 7.1. Let L1, ...Lm be logically closed languages and let one of the following be true for every 1 ≤ i ≤ m:\n(i) Li is a lexicon and Lisαit is its canonic representation\n(ii) there exist such 1 ≤ j(i) ≤ m and 1 ≤ k(i) ≤ m that Li = Lj(i) ∪Lk(i)\n(iii) there exist such 1 ≤ j(i) ≤ m and 1 ≤ k(i) ≤ m that Li = Lj(i) ∗Lk(i)\n(iv) there exists such 1 ≤ j(i) ≤ m that Li = Lj(i) ⊲Ri, where a logically closed semantic rule Ri has a canonic representation Riαj(i)αit in the\nrange of Lj(i).\nThe full set RG of these conditions comprises a recursive grammar for the languages L1, ...Lm.\nFor a given recursive grammar, letL denote the language tuple (L1, ...Lm), let L0 denote a tuple of lexicons such that L0i =def Li whenever Li is a lexicon and L0i = ∅ otherwise and let L\n′ denote a language tuple such that L′i = ∅ whenever Li is a lexicon and L′i is the right-hand part of the equality in condition (ii), (iii) or (iv) otherwise. Finally, let Ê denote the operator which produces L′ for a given L, so that the recursive grammar can be written as\nL = L0 ∪ ÊL, (7.1)\nwhere ∪ stands for a component-wise logical join of language tuples of the same arity and types.\nProposition 7.1. Equation 7.1 is satisfied by\nL =\n∞⋃\ni=0\nL i, (7.2)\nwhere L i = L0 ∪ ÊLi−1, for all i ≥ 1. (7.3)\nProof. As the operator Ê is a combination of logical joins, logical concatenations and semantic rule applications, it inherits the monotonicity property\nL ⊆ K =⇒ ÊL ⊆ ÊK, (7.4)\nwhere K is a language tuple of the same arity and types as L and ⊆ stands for component-wise inclusion. From this and 7.3, by induction on i it follows that\nL i ⊃ Li−1, for all i ≥ 1.\nTherefore, for any tuple e =def ((w1, Aα1), ...(wm, Aαm)) there exists an index i(e) such that\ne ∈ Ê\n∞⋃\ni=0\nL i =⇒ e ∈ ÊLi(e),\nwhere ∈ stands for component-wise membership. From here, for the tuple L given by 7.2 we have that\ne ∈ L0 ∪ ÊL =⇒ e ∈ L0 ∪ ÊLi(e) = Li(e)+1,\nthat is, L0 ∪ ÊL ⊆ L. On the other hand, from the same property 7.4 we have that L0 ∪ ÊL ⊇ L0 ∪ ÊLi for any i ≥ 0 and therefore L0 ∪ ÊL ⊇ L. Thus, L0 ∪ ÊL = L.\nNote that in the general case, 7.2 might be not a single solution satisfying a recursive grammar. It can, however, be shown to be a subset of any other existing solution. This fact will not be used below and hence needs not be proven here, but we will refer to the solution 7.2 as the minimal one.\nDefinition 7.2. For a given recursive grammar RG, let ∆RG denote the set of m formulas D1t , ...D m t , where\n(i) Dit =def (C i sαit = Lisαit), if Li is a lexicon represented by L i sαit ,\n(ii) Dit =def (C i sαit = C j(i) sαit ∨Ck(i)sαit), if Li = Lj(i) ∪Lk(i),\n(iii) Dit =def (C i sαit = C j(i) sαj(i)t ∗Ck(i)sαk(i)t), if Li = Lj(i) ∗Lk(i), so that αi =def αj(i) × αk(i),\n(iv) Dit =def (C i sαit = C j(i) sαj(i)t ⊲ Riαj(i)αit), if Li = Lj(i) ⊲Ri and Ri is repre-\nsented by Riαj(i)αit,\nall the constants C1sα1t, ... C m sαmt are assumed to exist only in an extension TyA+n , but not in Ty A n , and the Ty A n operators of logical concatenation and semantic rule application are defined as follows:\n(∗(sαt)(sβt)sαβt) =def λxsαtλysβtλxsλxαλxβ∃ys∃zs\n(xs = ys + zs ∧ xsαt ys xα ∧ ysβt zs xβ),\n(⊲(sαt)(αβt)sβt) =def λxsαtλyαβtλxsλxβ∃xα(xsαt xs xα ∧ yαβt xα xβ).\nBelow we will also make use of the TyAn operator of a functional semantic rule application:\n(⇒(sαt)(αβ)sβt) =def λxsαtλyαβ(xsαt ⊲ (λxα(= yαβ xα))).\nNote that every singleton (= A1s) &(= A 1 α) can be equivalently written down as (= A1s) ⇒ A 1 α.\nWe now prove that every language Li of the minimal solution of a recursive grammar RG is represented by (∆RG ,Cisαit). To do so, we introduce the following auxiliary\nDefinition 7.3. An α-language L is said to have a pseudo-canonic representation if it is represented by (∆, Lsαt) such that for any word w ∈ A∗ there exists a finite (may be empty) set {A1α, ... A l α} of Ty A n terms such that\n∆ ⊢ Lsαt TA(w) = l∨\ni=1\n(= Aiα)\nand adding ∆ to TyA+n as new axioms forms a conservative extension of Ty A n (i.e. for any TyAn formula At ⊢ At iff ∆ ⊢ At).\nNote that a canonic representation of an α-lexicon is a particular case of a pseudo-canonic representation.\nLemma 7.2. If ∆ is a consistent set of TyA+n formulas and for any general model M of TyAn and an assignment of variables in that model there exists an extension M+ of M for TyA+n in which ∆ is satisfied by the same assignment of variables, then adding ∆ to TyA+n forms a conservative extension of Ty A n .\nProof. By the Completeness Theorem, if not ⊢ At, then there exists a general TyAn modelM and assignment of variables a by which At is not satisfied inM . If M can be extended to a model M+ for TyA+n where ∆ is still satisfied by a, then by the Soundness Theorem the derivation ∆ ⊢ At is impossible.\nLemma 7.3. The set {A1α, ... A l α} appearing in the first condition of Definition 7.3 generates all meanings of w in the language L.\nProof. If Aa is a Ty A n term and (w,Aα) ∈ L, then ∆ ⊢ Lsαt TA(w) Aa and therefore ∆ ⊢ (Aα = A 1 α) ... ∨ (Aα = A l α),\nwhich implies that ⊢ (Aα = A 1 α) ... ∨ (Aα = A l α).\nThus, by Lemma 6.3, any meaning of w belongs to the logical closure of {A1α, ... A l α}.\nLemma 7.4. In any recursive grammar RG, a lexicon Li with a canonic representation Lisαit also has the pseudo-canonic representation (∆RG , L i sαit ).\nProof. The first condition of Definition 7.3 follows directly from the assumption that Lisαit is a canonic representation.\nNow we prove that the set ∆RG is consistent and also satisfied by a given assignment of variables a in some extension M+ of an arbitrary TyAn model M . Lemma 5.2 and the fact that a recursive grammar is satisfied by some logically closed languages L1, ...Lm allow the extension M+ to be defined as follows: let the function JCisαitKM+ for given arguments w ∈ Ds and v ∈ Dαi take the true value iff w ∈ A∗ and the language Li contains pairs (w,Aαi) such that JAαiKM+,a = v. The conditions (i)-(iv) of Definition 7.2 then imply that every Dit is satisfied by a in such an extended model. By Lemma 7.2, this proves the second condition of Definition 7.3.\nLemma 7.5. If M and N are logical closures of M ∈ Tα and N ∈ Tα respectively, then M∪N = M∪N .\nProof. Every element of M∪N belongs to M∪N because M ⊆ M, N ⊆ N , so a proof tree for any term from M∪N is also a proof tree\nfor M∪N . On the other hand, as every leaf of a proof tree for an element\nof M∪N belongs to either M or N , it can be expanded to a proof tree for the corresponding set and thus the entire tree can be converted to a proof tree for M∪N with the same root, that proves its membership in M∪N .\nProposition 7.6. Let α-languages L and K have pseudo-canonic representations (∆, Lsαt) and (∆, Ksαt) respectively. Then their logical join L∪K is represented by (∆, Lsαt∨Ksαt), which is also a pseudo-canonic representation.\nProof. Let\n∆ ⊢ Lsαt TA(w) = l∨\ni=1\n(= Aiα) and ∆ ⊢ Ksαt TA(w) = k∨\ni=1\n(= Biα).\nThen\n∆ ⊢ (Lsαt ∨Ksαt) TA(w) = l∨\ni=1\n(= Aiα) ∨ k∨\ni=1\n(= Biα).\nThis proves that (∆, Lsαt ∨ Ksαt) is a pseudo-canonic representation and therefore for any TyAn term Aα,\n∆ ⊢ (Lsαt ∨Ksαt) TA(w)Aα ⇐⇒ ⊢ l∨\ni=1\n(Aα = A i α) ∨\nk∨\ni=1\n(Aα = B i α).\nBy Lemmas 7.3, 6.3 and 7.5 this proves that (∆, Lsαt ∨ Ksαt) represents L∪K.\nProposition 7.7. Let an α-language L have a pseudo-canonic representation (∆, Lsαt) and a β-language K have a pseudo-canonic representation (∆, Ksβt). Then the logical concatenation L∗K is represented by (∆, Lsαt ∗Ksβt), which is also a pseudo-canonic representation.\nProof. Let w = h0+ t0 = ... = hl+ tl be all possible splits of a word w into head and tail and\n∆ ⊢ Lsαt TA(hm) = lm∨\ni=1\n(= Am,iα ), ∆ ⊢ Ksβt TA(tm) = km∨\nj=1\n(= Bm,jβ )\n(for m = 0, ... l). Then by axioms 4.1 - 4.3 and metatheorems\n⊢ ∃xα(At ∨ Bt) = ∃xαAt ∨ ∃xαBt, (7.5)\n⊢ ∃xγ(xγ = Aγ ∧ Bt(xγ)) = Bt(Aγ) (7.6)\n(where xγ is not free in Aγ) we have:\n∆ ⊢ (Lsαt ∗Ksβt) TA(w) = l∨\nm=0\nlm∨\ni=1\nkm∨\nj=1\n(= Am,iα ) &(= B m,j β ).\nThis proves that (∆, Lsαt∗Ksβt) is a pseudo-canonic representation and therefore for any TyAn terms Aα, Bβ,\n∆ ⊢ (Lsαt ∗Ksβt) TA(w)AαBβ ⇐⇒ ⊢ l∨\nm=0\nlm∨\ni=1\nkm∨\nj=1\n(Aα = A m,i α ) ∧ (Bβ = B m,j β ).\nBy Definition 3.7 and Lemma 6.3 this proves that (∆, Lsαt ∗Ksβt) represents L∗K.\nProposition 7.8. Let an α-language L have a pseudo-canonic representation (∆, Lsαt) and a rule R ⊂ Tα ⊗ Tβ have a canonic representation Rαβt in the range of L. Then the language L⊲R is represented by (∆, Lsαt ⊲Rαβt), which is also a pseudo-canonic representation.\nProof. Let\n∆ ⊢ Lsαt TA(w) = l∨\ni=1\n(= Aiα)\nand\n⊢ Rαβt A i α =\nki∨\nj=1\n(= Bi,jβ )\n(for i = 1, ...l). Then by metatheorem 7.6 we have\n∆ ⊢ (Lsαt ⊲Rαβt) TA(w) = l∨\ni=1\nki∨\nj=1\n(= Bi,jβ ).\nThis proves that (∆, Lsαt ⊲ Rαβt) is a pseudo-canonic representation and therefore for any TyAn term Bβ ,\n∆ ⊢ (Lsαt ⊲Rαβt) TA(w)Bβ ⇐⇒ ⊢ l∨\ni=1\nki∨\nj=1\n(Bβ = B i,j β ).\nBy Definition 3.3 and Lemma 6.3 this proves that (∆, Lsαt ⊲Rαβt) represents L ⊲R.\nPropositions 7.6 - 7.8 establish that, given some logically closed languages known to have pseudo-canonic representations that share a single common axiom set ∆ and semantic rules that have canonic representations, one can build Tyn representations of their logical joins, logical concatenations and applications of the rules by means of the three corresponding TyAn operators: (∨(sαt)(sαt)sαt), (∗(sαt)(sβt)sαβt) and (⊲(sαt)(αβt)sβt); moreover these representations are also pseudo-canonic and share the same axiom set ∆.\nLemma 7.9. TyAn operators of logical join, logical concatenation and semantic rule application reproduce the associativity and monotonicity properties:\n⊢ (xsαt ∨ ysαt) ∗ zsβt = xsαt ∗ zsβt ∨ ysαt ∗ zsβt,\n⊢ zsβt ∗ (xsαt ∨ ysαt) = zsβt ∗ xsαt ∨ zsβt ∗ ysαt,\n⊢ (xsαt ∨ ysαt) ⊲ zαβt = xsαt ⊲ zαβt ∨ ysαt ⊲ zαβt,\n⊢ (xsαt → ysαt) → (xsαt ∗ zsβt → ysαt ∗ zsβt),\n⊢ (xsαt → ysαt) → (zsβt ∗ xsαt → zsβt ∗ ysαt),\n⊢ (xsαt → ysαt) → (xsαt ⊲ zαβt → ysαt ⊲ zαβt).\nProof. All these properties follow from the definition of operator (∗(sαt)(sβt)sαβt) due to the tautologies\n⊢ (At∨Bt)∧Ct = At∧Ct∨Bt∧Ct, ⊢ Ct∧ (At∨Bt) = Ct∧At∨Ct∧Bt,\n⊢ (At → Bt) → (At∧Ct → Bt∧Ct), ⊢ (At → Bt) → (Ct∧At → Ct∧Bt)\nand the metatheorems 7.5 and\n⊢ ∀xγ(At → Bt) → (∃xγAt → ∃xγBt).\nTheorem 7.10. Every language Li of the minimal solution of a recursive grammar RG is represented by (∆RG ,Cisαit).\nProof. If (using the notations introduced in the proof of Proposition 7.1) e ∈ L, then there exists an index i such that e ∈ Li. As every Li is built from lexicons L0 and L(i−1) by applying logical joins, logical concatenations and semantic rule applications, from Propositions 7.6 - 7.8 it follows (by induction on i) that every component Lij of L\ni has a pseudo-canonic representation (∆RG , L i,j τj ), where for any i > 0\nLi,jτj =def L 0,j τj ∨ Ejτ1...τmτj L i−1,1 τ1 ... Li−1,mτm ,\nτj =def sαjt and terms E j τ1...τmτj stand for TyAn operators corresponding to the operator Ê. On the other hand, from Definition 7.2 we have\n∆RG ⊢ C j τj = L0,jτj ∨ E j τ1...τmτj C1τ1 ...C m τm .\nAs by Lemma 7.9 the terms Ejτ1...τmτj reproduce the monotonicity property of the operator Ê , it follows from this that for all i ≥ 0\n∆RG ⊢ L i,j τj → Cjτj\nand therefore, for every j that\n∆RG ⊢ C j τj TA(wj) Aαj .\nTo prove that, inversely, the above derivations imply e ∈ Li, consider the TyA+n model defined in the proof of Lemma 7.4. As such a model can extend an arbitrary TyAn model, these derivations imply that there exist such terms A′αj that e ′ =def ((w1, A ′ α1 ), ... (wm, A ′ αm\n)) ∈ L and ⊢ A′αj = Aαj . As Lj are logically closed, this implies that e ∈ L also.\nCorollary 7.11. Every language Li of the minimal solution of a recursive grammar RG is represented by the term λxsλxαiDt → C i sαit\n, where Dt is the conjunction of all formulas from ∆RG .\nProof. See the note to Definition 4.1.\nThe significance of these results is that they, in particular, establish a class of non-trivial Tyn-representable languages which turns out to be decidable, in spite of the fact that Tyn is undecidable and hence so are generally\nTyn-representable languages. Indeed, assume all the semantic rules participating in a grammar RG to be non-degenerate. It is easy to see that in this assumption the domain of every language Li is formed by a context-free grammar with the set of terminals being the union of domains of all the lexicons participating in RG and non-terminal symbols corresponding all the Li languages. Therefore, this domain falls into the class of context-free (and hence - recursive) languages of the Chomsky hierarchy. Then, in the additional assumption of decidability of all the RG semantic rules (which holds, for example, for any functional rules), the problem of finding all the logicallyindependent representatives of the meanings of an Li expression also turns out to be decidable, merely by attributing the terminal (leaf) nodes of its syntactic parsing tree with their (lexicon-determined) meanings and inheriting and evaluating the meanings of upper nodes according to the rules, from bottom up to the root node. Furthermore, though discarding the assumption of non-degenerateness of all the RG semantic rules may generally lead to languages Li with domains being context-sensitive (in the classical sense), retaining only the assumption of the rules decidability still preserves the conclusion about decidability of languages Li. In this assumption languages Li can be parsed, for example, by the two-staged process like this:\n1. parse according to the context-free grammar RG obtained from RG by replacing every rule Ri by the trivial non-degenerate rule with the canonic representation Riαj(i)αit =def λxαj(i)λxαiT\n2. attribute the terminal (leaf) nodes of the parsing tree with their (lexicondetermined) meanings and inherit and evaluate the meanings of upper nodes according to the actual rules Ri, or discard the parse if at any node the actual rule degenerates to λxαiF when applied to all incoming meanings.\nTo illustrate the technique of a recursive grammar representation, let us build a very simple English-like grammar from tiny lexicons, consisting of a few countable nouns and transitive verbs, the irregular verb ”be”, a proper\nnoun and two determiners:\nNouns(et)t = (= /builder/) ⇒ Builderet ∨\n(= /house/) ⇒ Houseet ∨\n(= /car/) ⇒ Caret,\nVerbts(eet)t = (= /build/) ⇒ Buildeet ∨\n= (= /sell/) ⇒ Selleet,\nVerbBes(eet)t = (= /be/) ⇒ (=eet),\nNameset = (= /Jack/) ⇒ Jacke,\nDets((et)(et)t)t = (= /a/) ⇒ λyetλzet∃xe(y x ∧ z x) ∨\n(= /every/) ⇒ (→(et)(et)t).\nThe noun phrase can be defined by the axiom\nNPs((et)t)t = Det ∗∗Noun ⇒ I((et)(et)t)(et)(et)t ∨\nName ⇒ λxeλyet(y x)\nand the simple verb phrase (for the object of the third person in the singular number) by the axioms\nVPss(et)t = (Verbt ∗ (= /s/) ∨ ((= /is/) ⇒ /be/) ⊲VerbBe) ∗∗NP ⇒\nλzeetλy(et)tλx 2 e(y λx 1(z x1 x2)) ∨ ((= /does not/) ∗∗Verbt ∨ ((= /is not/) ⇒ /be/) ⊲VerbBe) ∗∗NP ⇒ λzeetλy(et)tλx 2 e(y λx 1(∼ (z x1 x2))),\nwhere (∗∗) =def λxsαtλysβt(x ∗ (= / /) ∗ y)\nrepresents phrase concatenation (with a separating space). Note that the constant VerbBe occurs here as a semantic rule applied to simple s-languages which express the morphology of the verb ”be”. As these languages, as well as the language represented by VerbBe itself are finite lexicons, the results of the applications are lexicons too and hence conditions of the theorem 7.10 still hold for the language we are defining. The compound verb phrase can now be defined by the axioms like\nVPms(et)t = VPs ∗∗(= /and/) ∗∗VPs ⇒ (∧(et)(et)et)) ∨\nVPs ∗ (= /,/) ∗∗VPm ⇒ (∧(et)(et)et),\nVPs(et)t = VPs ∨ VPm\nand the clause – by the axiom\nClstt = NP ∗∗VP ⇒ I((et)t)(et)t.\nFinally, the declarative sentence can be defined by the axiom\nSstt = Cl ∗ (= /./) ∨ (Cl ∗ (= /,/) ∗∗S ∨ Cl ∗∗(= /and/) ∗∗S) ⇒ (∧ttt).\nIf ∆S is the set of the above axioms, then, by propositions 7.6 - 7.8, we will have, for example:\n∆S ⊢ S /Jack builds a house./ ∃xe(Build xe Jack ∧ House xe),\n∆S ⊢ S /Jack sells a car and builds a house./ (∃xe(Sell xe Jack ∧ Car xe) ∧\n∃xe(Build xe Jack ∧ House xe)),\n∆S ⊢ S /Jack does not build a house./ ∼ ∃xe(Build xe Jack ∧ House xe), ∆S ⊢ S /every builder builds a house./ (Builder → λx 2 e∃x 1 e(Build x 1 e x 2 e ∧ House x 1 e), ∆S ⊢ S /Jack is a builder, Jack builds a house./ (∃xe(Builder xe ∧ Jack = xe) ∧\n∃xe(Build xe Jack ∧ House xe)).\nOf course, along with these, the language represented by (∆S,S) also admits semantically infelicitous sentences like, for example, ”a house builds a builder” or ”Jack is a house”. If one would like to make such sentences ungrammatical, i.e. exclude them from the domain of the language represented by (∆S,S), this can be achieved by applying more restrictive relational semantic rules, than those simple functional rules used in the above axioms; such rules must account the animacy categories of nouns, as well as categories of subjects and objects applicable to a verb. Another, less elegant, though practically may be simpler and more efficient solution is to split lexicons and derived languages to semantically homogenous components and allow concatenation of only matching pairs, like, for example:\nClstt = (NPa ∗∗VPa ∨ NPi ∗∗VPi) ⇒ I((et)t)(et)t,\nwhere NPa,NPi are to represent animate and inanimate noun phrases and VPa,VPi to represent verb phrases applicable to animate and inanimate subjects. Note that this approach leads to splitting the verb lexicon to components corresponding different generic sentence frames as defined in (Fellbaum, 1998); in particular, the verbs ”build” and ”sell”, in terms of WordNet, will correspond the frame ”Somebody —-s something” and the verb ”be” will be shared by the frames ”Something —-s something” and ”Somebody —-s somebody”."
    }, {
      "heading" : "8 Context type, instructive and",
      "text" : "context-dependent languages\nIntroduction of an additional sort of individuals in Ty2 of (Gallin, 1975) allowed to accurately interpret in this theory the intensional logic (IL), that implied interpretation of the corresponding type (s in Gallin’s notations, not to be confused with the symbolic type of this work) as a set of possible “states of world” or “states of affairs”. Similarly to this, TyAn with n > 2 admits the same interpretation of one of its primitive types (let it be, for certainty, c =def en−1) and thus turns out to be capable of representing intensional languages, i.e. languages with intensional semantics, as well. In combination with the capabilities provided by the symbolic type, however, a more specific interpretation of type c in TyAn allows to go far beyond this straightforward generalization and achieve also a natural and effective account of those aspects of a language which are usually referenced in literature as dynamic semantics (Kamp, 1981; Heim, 1983; Seuren, 1985; Groenendijk & Stokhof, 1989; Groenendijk & Stokhof, 1990).\nThe basic idea is to extend TyAn with non-logical axioms like\nλxα(Derefαcα Sα (Pcc (Setrefααcc Sα xα yc))) = Iαα (8.1)\nUnsetαcc Sα ◦ Pcc ◦ Setrefααcc Sα xα = Icc, (8.2)\nwhere there could be some restrictions on the structure of terms Sα and Pcc and\n(◦(βγ)(αβ)αγ) =def λzβγλqαβλxα(zβγ (qαβ xα)),\nthat allow to interpret type c as a ”store” (Sabry, 1995) or, in the terminology of programming languages, ”state” and transform a Tyn representation of a language to the state-passing style (SPS) (Wadler, 1992; Sabry, 1995; Jones, 2003). In such a transformation the state actually plays a role of a context, passing ”side effects” of parsing some constituents of an expression to others, as we explore in details below. This justifies our referring to the type c as to context type (and motivates the notation).\nNote that cc-terms like Setrefααcc Sα Vα and Unsetαcc Sα present instructions to ”modify” a context, in the sense defined by the axioms 8.1, 8.2. Proceeding from this observation, one can further assume certain cc-terms to denote instructions whose semantics might not be representable in TyAn , but still could be implemented in a computing or another system. Instructions\nto add or remove a non-logical axiom to or from a set of axioms associated with a context, or verify whether a given formula is provable from this set are important examples of such “meta”-instructions. Although their semantics are not representable within Tyn, they still might be denoted by cc terms, like, say, Asserttcc At, Refutetcc At or Testtcc At, and there could be a computing system capable of evaluating them in some conditions and providing an appropriate feedback in the event of failure. Other unrepresentable instructions might force a system to exchange information with an external environment via input/output devices or even to execute certain physical actions (like robotic ones).\nIt is easy to notice that associating a context with a set of non-logical axioms makes our c type conceptually similar to the World type of (Pollard, 2005). The principal technical (formal) difference is however that the World type in the hyperintensional semantics is defined as a derived subtype of the type of functions from Prop to Bool, while Prop is introduced as a primitive type. Unlike that, in our model, vice-versa, the context type c is introduced as primitive and the propositional type can be defined as the functional type ct (see (Gallin, 1975)). A fundamental theoretical benefit of the hyperintensional semantics is that it admits internalizing (i.e. making representable within the HOL) the entailment relation between propositions, along with the property of a set of propositions to be an ultrafilter, i.e. a maximum consistent set of propositions. However, as the World type is defined just by the ultrafilterhood predicate, i.e., informally saying, assumed to “settle every issue” (Pollard, 2005), it is not obvious whether this theoretical benefit would imply practical benefits in an implementation of this formalism. At the same time, our context type, of course, enforces no assumptions about completeness (and even about consistency) of axioms associated with a context, that seems to be more pragmatic and realistic.\nTo summarize this introductory informal discussion, we can state that, while type s of (Gallin, 1975) and type World of (Pollard, 2005) stand for “states of world”, the similar to them type c of our model stands rather for “states of an individual mind”, which mind is not necessarily complete nor consistent, but, on one hand, still determines interpretation of a text and, on the other hand, is changeable (in particular, extendable) in the process of interpretation.\nMoving on formalism, we first note that a superposition like\nP lcc ◦ P l−1 cc ... ◦ P 1 cc,\nrepresents a sequence of instructions, executed in order from right to left, that is a program, while the identity Icc is the empty sequence, or ”do-nothing” instruction. (Of course an arbitrary cc-term would not invariably represent an executable instruction, but a real implementation should necessarily provide some sort of exception handling, reducing a non-executable instruction to another or possibly do nothing instruction.)\nThus, expressions of a cc-language mean some (either executable or nonexecutable) instructions and therefore a text, i.e. an ordered sequence of such expressions can be treated as a corresponding program. A few obvious features of such an instructive language make it different in principle from a t- and even a ct-language:\n1. an instructive language text meaning captures the order of statements, that is, its semantic interpretation can depend on that order;\n2. it can also capture contradictory or equivalent truth meanings nested in subsequent instructions;\n3. it provides a natural way to distinctly represent declarative, interrogative and imperative semantics.\nGiven an initial context Cc, an instructive language text meaning Pcc determines a new context Pcc Cc depending on both the initial context Cc and the program Pcc which changes it, in the sense that a continuation of the text would already be applied to the new context. However, the program Pcc itself here does not depend on the initial context. Our next step is to employ the context type for building context-dependent languages.\nDefinition 8.1. A context-dependent α-language is a c(c× α)-language.\nGiven a context-dependent α-language L and a context term Cc, the operation of context application\nL ↓ Cc =def L ⊲ CA(Cc),\nwhere the rule CA(Cc) ⊂ Tc(c×α) ⊗ Tc×α is represented by\nCA(cc)(cα)cαt(Cc) =def λxccλycα((= xcc Cc) &(= ycα Cc)),\nand the operation of context instantiation\nL ⇓ Cc =def L ⊲ CI(Cc),\nwhere the rule CI(Cc) ⊂ Tc(c×α) ⊗ Tα is represented by\nCI(cc)(cα)αt(Cc) =def λxccλycα(= ycα Cc),\nproduce a c×α-language and a regular α-language, respectively, that depend on a context Cc. Inversely, given a regular α-language and a term Fαcc, the operation of context raising\nL ⇑ Fαcc =def L ⊲ CR(Fαcc),\nwhere the rule CR(Fαcc) ⊂ Tα ⊗ Tc(c×α) is represented by\nCRα(cc)(cα)t(Fαcc) =def λxα((= Fαcc xα) &(= λxcxα)),\nproduces a context-dependent α-language. Note that for any language and context\n⊢ (L ⇑ λxαIcc) ⇓ Cc = L,\nthat is, raising a regular language by λxαIcc converts it into a contextdependent language which however is essentially equivalent to the original one.\nIt is also noticeable that an instructive, that is a regular cc-language, turns out to be a singular case of a context-dependent unit-type-language. The reason why a context-dependent α-language is required to be of type c(c× α), rather than of a simpler type cα, should become obvious from the following. For sake of brevity we employ notation α =def c(c × α) (for an arbitrary type α) everywhere below.\nDefinition 8.2. Let L be a context-dependent α-language and K - a contextdependent β-language. Then their anaphoric logical concatenation is the context-dependent α× β-language\nL−→∗ K =def L∗K ⊲AC,\nwhere the rule AC ⊂ Tα×β ⊗ Tα×β is represented by the term\nACαβ α×βt =def λx 1 ccλy 1 cαλx 2 ccλy 2 cβ((= x 2 cc ◦ x 1 cc) &(= y 1 cα) &(= y 2 cβ ◦ x 1 cc)),\nand their cataphoric logical concatenation is the context-dependent α × βlanguage\nL←−∗ K =def L∗K ⊲ CC,\nwhere the rule CC ⊂ Tα×β ⊗ Tα×β is represented by the term\nCCαβ α×βt =def λx 1 ccλy 1 cαλx 2 ccλy 2 cβ((= x 1 cc ◦ x 2 cc) &(= y 1 cα ◦ x 2 cc) &(= y 2 cβ)).\nFor informal interpretation of this definition consider the superposition of an anaphoric concatenation with a context application:\n(L−→∗ K) ↓ Cc = (L∗K) ⊲ (CA(Cc) ◦ AC),\nwhere the rule superposition CA(Cc) ◦ AC is represented by the term\nλx1ccλy 1 cαλx 2 ccλy 2 cβ((= x 2 cc (x 1 cc Cc)) &(= y 1 cα Cc) &(= y 2 cβ (x 1 cc Cc))).\nThus, the anaphoric concatenation affects a meaning of the right-hand constituent by a context affected by the left-hand one, while the latter is affected directly by the initial context. Symmetrically, for the cataphoric concatenation, the effective rule superposition is represented by the term\nλx1ccλy 1 cαλx 2 ccλy 2 cβ((= x 1 cc (x 2 cc Cc)) &(= y 1 cα (x 2 cc Cc)) &(= y 2 cβ Cc)),\nthat is, in this case an initial context is passed to the right-hand constituent and the affected context to the left-hand one.\nNote that the construction of type α =def c(c × α) coincides with the construction of the state monad type in functional programming languages (Wadler, 1992; Jones, 2003) and the context raising rule\nCRα(cc)(cα)t(λxαIcc) =def λxα((= Icc) &(= λxcxα))\nprecisely corresponds to the return operator of that monad. It is also easy to verify that the rules ACαβ α×βt and CCαβ α×βt defining operations\n−→∗ and ←−∗ come as results of binding by the corresponding operator of the same monad, in the first case – a meaning (x1cc, y 1 cα) of the left constituent with the operation AKα α×β =def λxα((x 2 cc, λycxα, y 2 cβ) and in the second case – a meaning (x2cc, y 2 cβ) of the second constituent with the symmetric operation\nCKβ α×β =def λxβ((x 1 cc, λycxβ, y 1 cα),\nwhich operations merely combine a monadic-type-meaning of one of the constituents with a regular-type-meaning of the other. Of course, this note is nothing else than a rephrasing of the above informal interpretation of operations −→∗ and ←−∗ , in terms of the state monad.\nAs the new operations −→∗ ,←−∗ , ↓,⇑ and ⇓ are defined as rule applications to regular concatenations or just special rule applications, they also reveal associativity and monotonicity properties:\nLemma 8.1. For any context-dependent α-languages K,L, a context-dependent β-language M, regular α-languages K0,L0 and a context term Cc\n(K∪L)−→∗ M = K−→∗ M ∪ L−→∗ M,\nM−→∗ (K∪L) = M−→∗ K ∪ M−→∗ L,\n(K∪L)←−∗ M = K←−∗ M ∪ L←−∗ M, M←−∗ (K∪L) = M←−∗ K ∪ M←−∗ L,\n(K0 ∪L0) ⇑ Cc = K0 ⇑ Cc ∪ L0 ⇑ Cc,\n(K∪L) ⇓ Cc = K ⇓ Cc ∪ L ⇓ Cc,\nK ⊂ L =⇒ K−→∗ M ⊂ L−→∗ M, K ⊂ L =⇒ M−→∗ K ⊂ M−→∗ L, K ⊂ L =⇒ K←−∗ M ⊂ L←−∗ M, K ⊂ L =⇒ M←−∗ K ⊂ M←−∗ L,\nK0 ⊂ L0 =⇒ K0 ⇑ Cc ⊂ L0 ⇑ Cc,\nK ⊂ L =⇒ K0 ⇓ Cc ⊂ L0 ⇓ Cc.\nProposition 8.2. If a context-dependent α-language L has a pseudo-canonic representation (∆, Lsαt) and a context-dependent β-language K has a pseudocanonic representation (∆, Ksβt), then the concatenations L −→∗ K and L←−∗ K have pseudo-canonic representations (∆, Lsαt −→∗ Ksβt) and ((∆, Lsαt\n←−∗ Ksβt) respectively, where\n(−→∗ (sαt)(sβt)sα×βt) =def λzsαtλzsβtλxsλxccλycαλycβ∃x 1 s∃x 2 s∃x 1 cc∃x 2 cc∃y 2 cβ\n(xs = x 1 s+x 2 s ∧xcc = x 2 cc◦x 1 cc∧ ycβ = y 2 cβ◦x 1 cc∧ zsαtx 1 sx 1 ccycα∧ zsβtx 2 sx 2 ccy 2 cβ),\n(←−∗ (sαt)(sβt)sα×βt) =def λzsαtλzsβtλxsλxccλycαλycβ∃x 1 s∃x 2 s∃x 1 cc∃x 2 cc∃y 1 cα\n(xs = x 1 s+x 2 s ∧xcc = x 1 cc◦x 2 cc∧ ycα = y 1 cα◦x 2 cc∧ zsαtx 1 sx 1 ccy 1 cα∧ zsβtx 2 sx 2 ccycβ).\nProof. The proof follows from Propositions 7.7, 7.8 and Definition 8.2, taking into account that the terms ACαβ α×βt and CCαβ α×βt are canonic representations of the corresponding rules (in any domain).\nProposition 8.3. If a context-dependent α-language L has a pseudo-canonic representation (∆, Lsαt), then a context instantiation L ⇓ Cc has a pseudocanonic representation (∆, Lsαt ⇓ Cc), where\n(⇓(sαt)csαt) =def λz(sαt)csαtλzcλxsλyα∃xcc∃ycα(zsαt xs xcc ycα ∧ yα = ycα zc).\nProof. The proof follows from Proposition 7.6, taking into account that the term CAαcαt(Cc) is a canonic representation (in any domain) of the rule that defines the context instantiation operation.\nProposition 8.4. If an α-language L has a pseudo-canonic representation (∆, Lsαt), than a context raising L ⇑ Fαcc has a pseudo-canonic representation (∆, Lsαt ⇑ Fαcc), where\n(⇑(sαt)(αcc)sαt) =def λzsαtλzαccλxsλxccλxcα∃xα\n(zsαt xs xα ∧ xcc = zαcc xα ∧ xcα = λxcxα).\nProof. Similar to Proposition 8.3, with taking into account that the term CRααt is a canonic representation (in any domain) of the rule that defines the context raising operation.\nLemma 8.5. TyAn operators of logical join, anaphoric or cataphoric concatenations and context instantiation or raising reproduce the associativity and monotonicity properties:\n⊢ (xsαt ∨ ysαt) −→∗ zsβt = xsαt −→∗ zsβt ∨ ysαt −→∗ zsβt, ⊢ zsβt −→∗ (xsαt ∨ ysαt) = zsβt −→∗ xsαt ∨ zsβt −→∗ ysαt, ⊢ (xsαt ∨ ysαt) ←−∗ zsβt = xsαt ←−∗ zsβt ∨ ysαt ←−∗ zsβt, ⊢ zsβt ←−∗ (xsαt ∨ ysαt) = zsβt ←−∗ xsαt ∨ zsβt ←−∗ ysαt, ⊢ (xsαt ∨ ysαt) ⇑ zαcc = xsαt ⇑ zαcc ∨ ysαt ⇑ zαcc,\n⊢ (xsαt ∨ ysαt) ⇓ zc = xsαt ⇓ zc ∨ ysαt ⇓ zc, ⊢ (xsαt → ysαt) → (xsαt −→∗ zsβt → ysαt −→∗ zsβt), ⊢ (xsαt → ysαt) → (zsβt −→∗ xsαt → zsβt −→∗ ysαt), ⊢ (xsαt → ysαt) → (xsαt ←−∗ zsβt → ysαt ←−∗ zsβt), ⊢ (xsαt → ysαt) → (zsβt ←−∗ xsαt → zsβt ←−∗ ysαt), ⊢ (xsαt → ysαt) → (xsαt ⇑ zαcc → ysαt ⇑ zαcc),\n⊢ (xsαt → ysαt) → (xsαt ⇓ zc → ysαt ⇓ zc).\nProof. The proof follows from the definitions of the operators and Lemma 7.9.\nPropositions 8.2 – 8.4 and Lemmas 8.1 and 8.5 show that the main result of Section 7 – Theorem 7.10 – can be generalized in a straightforward manner to the case of a recursive grammar that contains a mix of regular and context-dependent languages and relations involving all seven operations ∪, ∗,−→∗ ,←−∗ , ⊲,⇑ and ⇓.\nLet us see how the sample recursive grammar built in the previous section can be converted to an instructive (and hence context-dependent) language grammar and extended to acquire the two important features: distinction of declarative and interrogative semantics and pronoun dereferencing. To avoid excessive technical complexity and make the example more demonstrative, we will allow pronoun ”he” to appear only on place of a clause subject, referencing the subject of another (previous) clause expressed by a name, and pronoun ”it” only on place of an object, referencing the object of another (previous) affirmative verb phrase. The first can be achieved by defining the subject noun phrase by the axioms like\nSNPs(et)tt = (Det ∗∗Noun ⇒ I((et)(et)t)(et)(et)t) ⇑ λx(et)tIcc ∨\n(Name ⇒ λxeλyet(y x)) ⇑ Setref He(et)t) ∨\nSPron ⇒ (Icc, Deref ((et)t)c(et)t),\nSPron(et)t = (= /he/) ⇒ He(et)t.\nNote that the constant He(et)t here does not denote any specific meaning, but plays role of a symbol to assign a meaning and carry it to a corresponding reference.\nAccurate treatment of the pronoun on place of an object (which we want to be capable of referencing an arbitrarily expressed object of another verb phrase) requires a more sophisticated technique. First, we specialize the type of the object noun phrase to (eet)et and define it by the axioms\nONP s(eet)ett = (NP ⇒ O) ⇑ λx(eet)etIcc ∨ (8.3)\nOPron ⇒ (Icc,Deref ((eet)et)c(eet)et),\nOPron(eet)et = (= /it/) ⇒ It(eet)et,\nwhere NP is defined the same way as in the previous section and\nO((et)t)(eet)et =def λn(et)tλveetλye(n λxe(v x y))\nsimply maps its (et)t meaning to (eet)et. Note that these definitions do not yet provide setting the It reference. This is because in general case it should be dereferenced to a meaning determined not only by the object noun phrase itself, but also by a verb applied to it. For example, ”it” referencing the object in the verb phrases ”builds a house” and ”sells a house” should be dereferenced to different meanings: ”a house which is built” and ”a house which is sold”, respectively. Therefore, our It reference can be set only upon processing the entire verb phrase, as captured in the following axiom:\nVPssett = Verbt ∗ (= /s/) ∗∗ONP ⇒ (SetIt, Apply) ∨ (8.4)\n((= /is/) ⇒ /be/) ⊲VerbBe) ∗∗ONP ⇒\n(λveetλxccλyc(eet)etIcc, Apply) ∨\n((= /does not/) ∗∗Verbt ∨ ((= /is not/) ⇒ /be/) ⊲VerbBe) ⇒\n(λveetλxccλyc(eet)etIcc,∼ Apply),\nwhere\nSetIt =def λveetλxccλyc(eet)etλzc(Setref It λueet(y (x z) (v ∧ u))),\nApply =def λveetλxccλyc(eet)etλzc(y (x z) v).\nWe shall see below how interaction of axioms 8.3 and 8.4 makes the correct semantics, but so far have to complete our language definition.\nThe context-dependent versions of the compound declarative verb phrase, clause and sentence can be defined straightforward by the axioms\nVPmsett = VPs ∗∗(= /and/) −→∗∗VPs ⇒ ρ (∧(et)(et)et)) ∨\nVPs ∗ (= /,/)−→∗∗VPm ⇒ ρ (∧(et)(et)et),\nVPs(et)tt = VPs ∨ VPm,\nClstt = SNP −→∗∗VP ⇒ ρ I((et)t)(et)t,\nDSstt = Cl ∗ (= /./) ∨ (Cl ∗ (= /,/) −→∗∗DS ∨ Cl ∗∗(= /and/)−→∗∗DS) ⇒ ρ (∧ttt),\nwhere (−→∗∗) =def λxsαtλysβt x ∗ (= / /) −→∗ y,\nand ρ(αβ)αβ =def λzαβλyccλycα (ycc, λxc (z (ycα x))).\nNow, to add the simplest (”yes/no”) interrogative sentence to our language, we need the axioms like\nIVPdosett = Verbt ∗∗ONP ⇒ (SetIt, Apply), IVPbesett = ONP ⇒ (λxccλyc(eet)etIcc, Apply (=eet)),\nIClstt = ((= /does/) ∗∗SNP −→∗∗ IVPdo ∨ (= /is/) ∗∗SNP−→∗∗ IVPbe) ⇒\nρ I((et)t)(et)t,\nISstt = ICl ∗ (= /?/).\nFinally, we wrap the declarative and interrogative sentences into the general sentence of the instructive type:\nSs(cc)t = DS ⇒ λyccλyct(Asserttcc ◦ yct ◦ ycc) ∨ (8.5)\nIS ⇒ λyccλyct(Testtcc ◦ yct ◦ ycc).\nIf now ∆S denotes the new set of axioms, then, due to the results of this section and in the assumption that TyAn has been extended by the axioms 8.1, 8.2, we will have, for example:\n∆S ⊢ S /Jack is a builder./\n(Assert ∃xe(Builder xe ∧ Jack = xe) ◦ Setref He Jack),\n∆S ⊢ S /is Jack a builder?/\n(Test ∃xe(Builder xe ∧ Jack = xe) ◦ Setref He Jack),\n∆S ⊢ S /Jack is a builder, he builds a house./\n(Assert (∃xe(Builder xe ∧ Jack = xe) ∧\n∃xe(Build xe Jack ∧ House xe)) ◦ Setref He Jack),\n∆S ⊢ S /Jack builds a house and sells it./\n(Assert (∃xe(Build xe Jack ∧ House xe) ∧\n∃xe((Build ∧ Sell) xe Jack ∧ House xe)) ◦\nSetref It λueetλye∃xe((Build ∧ ueet) xe ye ∧ House xe) ◦\nSetref He Jack).\nDue to the metatheorem\n⊢ (∃xeA ∧ ∃xe(A ∧ B)) = ∃xe(A ∧ B),\nwhere A and B are arbitrary formulas, the last derivation also implies a shorter form\n∆S ⊢ S /Jack builds a house and sells it./\n(Assert (∃xe((Build ∧ Sell) xe Jack ∧ House xe)) ◦\nSetref It λueetλye∃xe((Build ∧ ueet) xe ye ∧ House xe) ◦\nSetref He Jack).\nSimilarly, we would have also\n∆S ⊢ S /Every builder builds a house and sells it./\n(Assert (Builder → λye∃xe((Build ∧ Sell) xe ye ∧ House xe)) ◦\nSetref It λueetλye∃xe((Build ∧ ueet) xe ye ∧ House xe)).\nThe last examples give some hints on how this formalism could address donkey pronouns (Geach, 1962; Kamp, 1981; Heim, 1982; Elbourne, 2006), remaining entirely within the mainstream higher-order logic semantics. Of course, elaboration of this topic deserves a separate publication.\nNote that, due to the special semantic rules applied in the axiom 8.5, the sentence meaning captures not only an assertion or test instruction, but also all the ”side effects” of its reading. This is essential in order to pass the side effects between sentences, if we would like to further define a language like\nTexts(cc)t = S ∨ S −→∗∗Text ⇒ (◦(cc)(cc)cc),\nso that, if ∆S contains this last axiom too, then we would also have\n∆S ⊢ Text /Jack is a builder. he builds a house./\n(Assert ∃xe(Build xe Jack ∧ House xe) ◦\nSetref It λueetλye∃xe((Build ∧ ueet) xe ye ∧ House xe) ◦\nAssert ∃xe(Builder xe ∧ Jack = xe) ◦\nSetref He Jack)."
    }, {
      "heading" : "9 Translation/expression operators and",
      "text" : "partial translation\nLet an α-language L be represented by a term Lsαt and let w ∈ A ∗ be a non-ambiguous valid expression of this language, so that\n⊢ ∃1xα(Lsαt /w/ xα).\nThen, by the basic property of the description operator ι(αt)α,\n⊢ ι(αt)α(Lsαt /w/) = Aα,\nwhere {Aα} is any generator of the meaning of w in L (for a product type α =def β × γ here and below ι(αt)α denotes the pair\n(λzβγt(ι(βt)β λxβ∃xγ(zβγt xβ xγ)), λzβγt(ι(γt)γ λxγ∃xβ(zβγt xβ xγ))) (9.1)\nwhich definition may be applied recursively). Similarly, if {Aα} is a generator of a meaning which has a single expression w in L, then\n⊢ ι(st)sλxs(Lsαt xs Aα) = /w/.\nThus, given an α-language represented by a term Lsαt, the terms\nτ(sαt)sα =def λxsαtλxs(ι(αt)α (xsαt xs))\nand σ(sαt)αs =def λxsαtλxα(ι(st)s λxs(xsαt xs xα))\nenable Tyn representations of expression-to-meaning and meaning-to-expression mapping determined by the language, in forms like τ(sαt)sα Lsαt and σ(sαt)αs Lsαt respectively. They are referred to below as translation and expression operators.\nApplication of the translation operator to an invalid expression, of course, is not provable to be equal to any meaning. However, it still represents a meaning that the expression might acquire upon possible completion of the language definition. Here is a precise formulation of this statement:\nProposition 9.1. Let (∆, Lsαt) be a pseudo-canonic representation of a language L and\nL+sαt =def Lsαt ∨ λxs(= τ(sαt)sα Lsαt xs). (9.2)"
    }, {
      "heading" : "If w is either a valid and non-ambiguous or invalid expression of L, then",
      "text" : "∆ ⊢ τ(sαt)sα L + sαt /w/ = τ(sαt)sα Lsαt /w/.\nProof. If w is a non-ambiguous valid expression of L and Aα its meaning, then\n∆ ⊢ Lsαt /w/ = (= Aα)\nand ∆ ⊢ ι(αt)α (Lsαt /w/) = Aα,\nso that ∆ ⊢ L+sαt /w/ = Lsαt /w/.\nOtherwise, if w is an invalid expression, then by Lemma 6.1\n∆ ⊢ Lsαt /w/ = λxαF,\nso that ∆ ⊢ L+sαt /w/ = (= τ(sαt)sα Lsαt xs)\nand therefore ∆ ⊢ ι(αt)α (L + sαt /w/) = τ(sαt)sα Lsαt xs.\nThus, the language defined by (9.2) extends the language L with all and only those pairs (w, τ(sαt)sαLsαt/w/) in which w is not a valid non-ambiguous expression of L, while similar pairs in which w is such an expression are fully contracted. In this sense, such a self-extension of a language L does not add anything new to it. However, when a language is nested into another language of a recursive grammar, employment of its self-extension enables some new and useful features, as established by the following\nProposition 9.2. Let (∆, Lsαt) and (∆, Ksβt) be pseudo-canonic representations of languages L and K respectively and let uv be a single split of a word w such that v is a valid expression of K.\nIf, additionally, v is a non-ambiguous expression of K with the meaning Bβ and u an invalid expression of L, then\n∆ ⊢ τ(sαβt)s(α×β) (L + sαt ∗K + sβt) /w/ = (τ(sαt)sα Lsαt /u/, Bβ). (9.3)\nIf, alternatively, uv is a single split of a word w such that u is valid expression of L and, additionally, u is a non-ambiguous expression of L with the meaning Aα and v - an invalid expression of K, then\n∆ ⊢ τ(sαβt)s(α×β) (L + sαt ∗K + sβt) /w/ = (Aα, τ(sβt)sβ Ksβt /v/). (9.4)\nProof. In a similar way to the proof of Proposition 7.7, taking into account Proposition 9.1, for the first case we obtain\n∆ ⊢ (L+sαt ∗K + sβt) /w/ = (= τ(sαt)sα Lsαt /u/) &(= Bβ)\nand for the second case\n∆ ⊢ (L+sαt ∗K + sβt) /w/ = (= Aα) &(= τ(sβt)sβ Ksβt /v/).\n(9.3) and (9.4) follow from this according to (9.1).\nThe three features of the partial translations (9.3) and (9.4) worth noting are:\n1. they capture the correct overall structure of a precise meaning that the concatenation would acquire upon elaboration of an incomplete nested language;\n2. they allow accurate restoration of their expressions uv = w even while a nested language remains incomplete;\n3. translation of only a single constituent is sufficient to convert a partial translation to the full translation (Aα, Bβ) upon an elaboration of an incomplete nested language.\nFor example, consider the self-extension\nS+ =def S ∨ λxs(= τ(stt)st S xs)\nof the sample grammar we built in section 4. If ∆S denots the same set of axioms as in that section, then we will have, for example:\n∆S ⊢ S + /Jack paints a house/\n∃xe(τ(s(eet)t)eet Verbt /paint/ xe Jack ∧ House xe),\n∆S ⊢ S + /Jack builds a computer/\n∃xe(Build xe Jack ∧ τ(s(et)t)et Noun /computer/ xe),\nthat illustrates both features 1 and 2. Now assume lexicon Noun be extended with an entry (= /computer/) ⇒ Computeret and let ∆ ′ S denote the changed axiom set. Then the derivation\n∆′S ⊢ ∃xe(Build xe Jack ∧ τ(s(et)t)et Noun /computer/ xe) =\n∃xe(Build xe Jack ∧ Computer xe)\nfollows immediately from\n∆′S ⊢ Noun /computer/ = (= Computer),\nthat illustrates the feature 3."
    }, {
      "heading" : "10 Conclusion",
      "text" : "In this work we studied some classes of languages that can be defined entirely in terms of provability in an extension (TyAn ) of sorted type theory by interpreting one of its base types as symbolic, whose constants denote symbols of an alphabet A or their concatenations. The symbolic type (s) is quite similar to the phonological type of Higher Order Grammar (HOG) (Pollard & Hana, 2003; Pollard, 2004; Pollard, 2006). However, the theory TyAn differs from the logic of HOG in that it does not contain special types for syntactic entities.\nWe launched from the two simple observations. First, given an arbitrary consistent set ∆ of non-logical axioms and a term of type sαt, one can define an α-language, i.e. a relation between strings of symbols from alphabet A and terms of type α, by the condition\n∆ ⊢ Lsαt /w/ Aα,\nwhere /w/ stands for an s-term denoting a word (string) w ∈ A∗. Secondly, any Tyn-representable language, i.e. a language that can be defined this way, necessarily possesses the semantic property of being logically closed, meaning, loosely speaking, that the full semantic interpretation of every valid expression of the language is given by a whole class of logically equivalent terms.\nNext, we proved that the inverse statement is also true, that is, every logically closed language is Tyn-representable. This general result, however, is not constructive in the sense that it does not provide an effective procedure of actually building a Tyn representation for a language defined by a finite set of rules or rule schemata. Our further efforts therefore concentrated mainly on finding such procedures for some important special classes of logically closed languages.\nWe began this with definitions of α-lexicons and a special canonic representation and proved that a language has a canonic representation if and\nonly if it is a lexicon. The canonic representation of a lexicon is efficiently found from the description of the lexicon.\nThen we defined and investigated recursive grammars - a kind of transformational grammars equipped with Tyn semantics. We introduced Tyn operators representing the basic language-construction operations used in the recursive grammar rules and proved that a compact Tyn representation for every language component of a recursive grammar comes from its rules in a quite straightforward manner. We illustrated this technique by simple examples, from which it became clear that language components of a recursive grammar stand for syntactic categories. We also briefly discussed classification of recursively defined Tyn-representable languages in terms of Chomsky hierarchy and on this basis indicated some conditions of when such languages turn out to be decidable, in spite of the fact that Tyn is undecidable and hence so are generally Tyn-representable languages.\nThen we moved to a further specialization of TyAn by introducing the context type (c), which can be interpreted as a ”store” or ”state” and thus is similar to ”state of affairs” or ”World” types of (Gallin, 1975) and (Pollard, 2005), respectively. We showed that our interpretation allows to model not only languages with intensional semantics (as in the above referenced works), but also so called instructive and context dependent languages. The latter come in our formalism in result of transformation of an α-language to state-passing style (SPS) (Wadler, 1992; Sabry, 1995; Jones, 2003) c(c × α)-language, which enables passing ”side effects” of parsing some text constituents to others. An instructive, i.e. a cc-language can be considered as a context dependent transformation of a unit-type language and provides semantic features that principally could not be modeled by a regular t-language nor by its intensional (ct) transformation. We found Tyn representations of context-dependent language construction operations (anaphoric and cataphoric concatenations and context raising and instantiation) that allow generalization of the previous results for context-dependent languages. We demonstrated how this formalism can address pronoun anaphora resolution.\nFinally, we defined translation and expression TyAn operators and introduced a special language representation (self-extension), revealing a useful property of partial translation.\nThe proposed formalism efficiently addresses the known issues inherent in the two-component language models and also partially inherited by HOG. Indeed,\n1. as there are no restrictions on a type of meanings of a Tyn-representable language or a component of it, which type, in particular, can be constructed with use of the symbolic type too, such a language can generally express facts about itself or about another Tyn-representable language;\n2. the property of partial translation of a self-extensible Tyn language representation demonstrates its built-in lexical robustness;\n3. as syntactic categories are not captured in the Tyn logic, but introduced only in non-logical axioms defining a concrete language, the Tyn representation provides full structural robustness and flexibility.\nThese results have both theoretical and practical implications. First, they facilitate modeling of such fundamental abilities associated with the human language acquisition process like communication of new grammar rules and lexical entries directly in an (already acquired) sub-set of the object language and independently acquiring new lexical entries upon encountering them in a known context, with postponed acquisition of their exact meanings. Other possible applications of the proposed formalism may include:\n1. addressing donkey pronouns (Geach, 1962; Kamp, 1981; Heim, 1982; Elbourne, 2006) and other dynamic semantic phenomena entirely within the mainstream higher-order logic semantics, as it was preliminarily outlined in section 8;\n2. modeling advanced language self-learning mechanisms, for example, such like deriving or generalization of grammar rules from text samples (may be accompanied by their semantic interpretation, communicated by other means or just expressed differently in the same language), that might be reduced, in frame of this formalism, to a problem of higher-order unification (Gardent et al., 1997; Dougherty & Mart́ınez, 2004).\nFinally, an implementation of the proposed formalism, like that suggested in (Gluzberg & Brenner, 2006), should provide a platform for building NLP systems with the following powerful features:\n1. the ability to recursively define more complex or more comprehensive languages in terms of previously defined simpler or limited ones;\n2. automatically acquiring new lexical entries in the process of operation;\n3. storing partial text parses which can be automatically completed later, upon extending the used language definition;\n4. freely switching between different input and output languages to access the same semantic content."
    } ],
    "references" : [ {
      "title" : "An Introduction to Mathematical Logic and Type Theory: To Truth Through Proof",
      "author" : [ "P.B. Andrews" ],
      "venue" : "(San Diego, CA, USA: Academic Press Professional, Inc.).",
      "citeRegEx" : "Andrews,? 1986",
      "shortCiteRegEx" : "Andrews",
      "year" : 1986
    }, {
      "title" : "Logical Aspects of Computational Linguistics: an Introduction (In Retoré, C. (Ed.), LACL’96",
      "author" : [ "P. Blackburn", "M. Dymetman", "A. Lecomte", "A. Ranta", "C. Retoré", "E.V. de la Clergerie" ],
      "venue" : "First International Conference on Logical Aspects of Computational Linguistics (pp. 1–20). Berlin: Springer-Verlag)",
      "citeRegEx" : "Blackburn et al\\.,? \\Q1997\\E",
      "shortCiteRegEx" : "Blackburn et al\\.",
      "year" : 1997
    }, {
      "title" : "Unification and matching modulo type isomorphism",
      "author" : [ "D. Dougherty", "C. Mart́ınez" ],
      "venue" : "Proceedings of II international workshop of higher order rewriting",
      "citeRegEx" : "Dougherty and Mart́ınez,? \\Q2004\\E",
      "shortCiteRegEx" : "Dougherty and Mart́ınez",
      "year" : 2004
    }, {
      "title" : "Situations and individuals. Current Studies in Linguistics",
      "author" : [ "Elbourne", "Paul D" ],
      "venue" : null,
      "citeRegEx" : "Elbourne and D.,? \\Q2006\\E",
      "shortCiteRegEx" : "Elbourne and D.",
      "year" : 2006
    }, {
      "title" : "WordNet: An electronic lexical database",
      "author" : [ "Fellbaum", "Christiane" ],
      "venue" : null,
      "citeRegEx" : "Fellbaum and Christiane,? \\Q1998\\E",
      "shortCiteRegEx" : "Fellbaum and Christiane",
      "year" : 1998
    }, {
      "title" : "Intensional and Higher-Order Modal Logic with Applications to Montague Semantics",
      "author" : [ "D. Gallin" ],
      "venue" : "(Amsterdam: North-Holland Publishing Company).",
      "citeRegEx" : "Gallin,? 1975",
      "shortCiteRegEx" : "Gallin",
      "year" : 1975
    }, {
      "title" : "A multi-level, higher-order unification approach to ellipsis",
      "author" : [ "Gardent", "Claire", "Kohlhase", "Michael", "Konrad", "Karsten" ],
      "venue" : null,
      "citeRegEx" : "Gardent et al\\.,? \\Q1997\\E",
      "shortCiteRegEx" : "Gardent et al\\.",
      "year" : 1997
    }, {
      "title" : "Reference and generality: An examination of some medieval and modern theories",
      "author" : [ "P.T. Geach" ],
      "venue" : null,
      "citeRegEx" : "Geach,? \\Q1962\\E",
      "shortCiteRegEx" : "Geach",
      "year" : 1962
    }, {
      "title" : "A note on Higher Order Grammar. Corr, abs/0910.0537",
      "author" : [ "Gluzberg", "Victor" ],
      "venue" : null,
      "citeRegEx" : "Gluzberg and Victor.,? \\Q2009\\E",
      "shortCiteRegEx" : "Gluzberg and Victor.",
      "year" : 2009
    }, {
      "title" : "Method and system for processing, storing, retrieving and presenting information with an extendable interface for natural and artificial languages. US Patent 6,999,934",
      "author" : [ "V. Gluzberg", "A. Brenner" ],
      "venue" : null,
      "citeRegEx" : "Gluzberg and Brenner,? \\Q2006\\E",
      "shortCiteRegEx" : "Gluzberg and Brenner",
      "year" : 2006
    }, {
      "title" : "Dynamic montague grammar. Pages 3–48 of: Papers from the second symposium on logic and language. Akademiai Kiadoo",
      "author" : [ "Groenendijk", "Jeroen", "Stokhof", "Martin" ],
      "venue" : null,
      "citeRegEx" : "Groenendijk et al\\.,? \\Q1989\\E",
      "shortCiteRegEx" : "Groenendijk et al\\.",
      "year" : 1989
    }, {
      "title" : "Dynamic predicate logic",
      "author" : [ "Groenendijk", "Jeroen", "Stokhof", "Martin" ],
      "venue" : "Linguistics and philosophy,",
      "citeRegEx" : "Groenendijk et al\\.,? \\Q1990\\E",
      "shortCiteRegEx" : "Groenendijk et al\\.",
      "year" : 1990
    }, {
      "title" : "The semantics of definite and indefinite noun phrases",
      "author" : [ "Heim", "Irene" ],
      "venue" : "Ph.D. thesis,",
      "citeRegEx" : "Heim and Irene.,? \\Q1982\\E",
      "shortCiteRegEx" : "Heim and Irene.",
      "year" : 1982
    }, {
      "title" : "File change semantics and the familiarity theory of definiteness",
      "author" : [ "Heim", "Irene" ],
      "venue" : "Pages 114–126",
      "citeRegEx" : "Heim and Irene.,? \\Q1983\\E",
      "shortCiteRegEx" : "Heim and Irene.",
      "year" : 1983
    }, {
      "title" : "Haskell 98 language and libraries: The revised report",
      "author" : [ "Jones", "Simon Peyton" ],
      "venue" : null,
      "citeRegEx" : "Jones and Peyton.,? \\Q2003\\E",
      "shortCiteRegEx" : "Jones and Peyton.",
      "year" : 2003
    }, {
      "title" : "A theory of truth and semantic representation. Pages 277–321",
      "author" : [ "Kamp", "Hans" ],
      "venue" : null,
      "citeRegEx" : "Kamp and Hans.,? \\Q1981\\E",
      "shortCiteRegEx" : "Kamp and Hans.",
      "year" : 1981
    }, {
      "title" : "A logical semantics for feature structures. Pages 257–266 of: Acl proceedings, 24th annual meeting",
      "author" : [ "Kasper", "Robert", "Rounds", "William" ],
      "venue" : null,
      "citeRegEx" : "Kasper et al\\.,? \\Q1986\\E",
      "shortCiteRegEx" : "Kasper et al\\.",
      "year" : 1986
    }, {
      "title" : "A Logical Formalism for Head-Driven Phrase Structure Grammar",
      "author" : [ "King", "Paul John" ],
      "venue" : null,
      "citeRegEx" : "King and John.,? \\Q1989\\E",
      "shortCiteRegEx" : "King and John.",
      "year" : 1989
    }, {
      "title" : "The mathematics of sentence structure",
      "author" : [ "Lambek", "Joachim" ],
      "venue" : "American mathematical monthly,",
      "citeRegEx" : "Lambek and Joachim.,? \\Q1958\\E",
      "shortCiteRegEx" : "Lambek and Joachim.",
      "year" : 1958
    }, {
      "title" : "Higher-order categorical grammar",
      "author" : [ "Pollard", "Carl" ],
      "venue" : "Proceedings of the International Conference on Categorial Grammars (CG2004). http://www.ling.ohiostate.edu/",
      "citeRegEx" : "Pollard and Carl.,? \\Q2004\\E",
      "shortCiteRegEx" : "Pollard and Carl.",
      "year" : 2004
    }, {
      "title" : "Hyperintensional semantics in a higher order logic with definable subtypes. Pages 32–45 of: Proceedings of the second workshop on lambda calculus, type theory, and natural language, king’s college london",
      "author" : [ "Pollard", "Carl" ],
      "venue" : null,
      "citeRegEx" : "Pollard and Carl.,? \\Q2005\\E",
      "shortCiteRegEx" : "Pollard and Carl.",
      "year" : 2005
    }, {
      "title" : "Higher order grammar (introductory course, language and logic section). In: The 18th European Summer School in Logic, Language and Information",
      "author" : [ "Pollard", "Carl" ],
      "venue" : null,
      "citeRegEx" : "Pollard and Carl.,? \\Q2006\\E",
      "shortCiteRegEx" : "Pollard and Carl.",
      "year" : 2006
    }, {
      "title" : "Ambiguity, neutrality, and coordination in higher order grammar",
      "author" : [ "Pollard", "Carl", "Hana", "Jiri" ],
      "venue" : "Proceedings of formal grammar. http://www.ling.ohio-state.edu/",
      "citeRegEx" : "Pollard et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Pollard et al\\.",
      "year" : 2003
    }, {
      "title" : "A mathematical formalism for linguistic theories with an application in head-driven phrase structure grammar. Phil",
      "author" : [ "Richter", "Frank" ],
      "venue" : null,
      "citeRegEx" : "Richter and Frank.,? \\Q2004\\E",
      "shortCiteRegEx" : "Richter and Frank.",
      "year" : 2004
    }, {
      "title" : "The formal relationship between direct and continuation-passing style optimizing compilers: a synthesis of two paradigms",
      "author" : [ "Sabry", "Amr Afaf" ],
      "venue" : "Ph.D. thesis,",
      "citeRegEx" : "Sabry and Afaf.,? \\Q1995\\E",
      "shortCiteRegEx" : "Sabry and Afaf.",
      "year" : 1995
    }, {
      "title" : "Formal philosophy: Selected Papers of Richard Montague. New Haven (Conn.) (etc.): Yale",
      "author" : [ "Thomason", "Richmond H. (ed" ],
      "venue" : null,
      "citeRegEx" : "Thomason and .ed..,? \\Q1974\\E",
      "shortCiteRegEx" : "Thomason and .ed..",
      "year" : 1974
    }, {
      "title" : "The essence of functional programming. Pages 1–14 of: Popl ’92: Proceedings of the 19th acm sigplan-sigact symposium on principles of programming languages",
      "author" : [ "Wadler", "Philip" ],
      "venue" : "USA: ACM",
      "citeRegEx" : "Wadler and Philip.,? \\Q1992\\E",
      "shortCiteRegEx" : "Wadler and Philip.",
      "year" : 1992
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "This two-component architecture of a language model has not essentially changed with the invention and further rapid development of type-logical grammar (Lambek, 1958; Blackburn et al., 1997), i.",
      "startOffset" : 153,
      "endOffset" : 191
    }, {
      "referenceID" : 5,
      "context" : "In Section 8 we consider a further specialization of Ty n by interpreting another base type as a context, similar (though not identical) to ”state of affairs” or ”World” types of (Gallin, 1975) and (Pollard, 2005), respectively.",
      "startOffset" : 179,
      "endOffset" : 193
    }, {
      "referenceID" : 5,
      "context" : "Following (Gallin, 1975), we denote by Tyn a sorted type theory with a set of primitive types consisting of the truth type t and individual types e1, e2, .",
      "startOffset" : 10,
      "endOffset" : 24
    }, {
      "referenceID" : 5,
      "context" : "For sake of better visibility and compactness we combine the full syntax of Tyn from syntaxes of Ty2 of (Gallin, 1975) and Q0 of (Andrews, 1986) and extend it as follows.",
      "startOffset" : 104,
      "endOffset" : 118
    }, {
      "referenceID" : 0,
      "context" : "For sake of better visibility and compactness we combine the full syntax of Tyn from syntaxes of Ty2 of (Gallin, 1975) and Q0 of (Andrews, 1986) and extend it as follows.",
      "startOffset" : 129,
      "endOffset" : 144
    }, {
      "referenceID" : 0,
      "context" : "Note that, unlike (Andrews, 1986), we write “from” and “to” types from left to right.",
      "startOffset" : 18,
      "endOffset" : 33
    }, {
      "referenceID" : 5,
      "context" : "We assume an axiomatization of Tyn be a straightforward generalization to case of n > 2 individual types of either the theory denoted as Tyn + D in (Gallin, 1975) or the theory Q0 of (Andrews, 1986).",
      "startOffset" : 148,
      "endOffset" : 162
    }, {
      "referenceID" : 0,
      "context" : "We assume an axiomatization of Tyn be a straightforward generalization to case of n > 2 individual types of either the theory denoted as Tyn + D in (Gallin, 1975) or the theory Q0 of (Andrews, 1986).",
      "startOffset" : 183,
      "endOffset" : 198
    }, {
      "referenceID" : 5,
      "context" : "Introduction of an additional sort of individuals in Ty2 of (Gallin, 1975) allowed to accurately interpret in this theory the intensional logic (IL), that implied interpretation of the corresponding type (s in Gallin’s notations, not to be confused with the symbolic type of this work) as a set of possible “states of world” or “states of affairs”.",
      "startOffset" : 60,
      "endOffset" : 74
    }, {
      "referenceID" : 5,
      "context" : "Unlike that, in our model, vice-versa, the context type c is introduced as primitive and the propositional type can be defined as the functional type ct (see (Gallin, 1975)).",
      "startOffset" : 158,
      "endOffset" : 172
    }, {
      "referenceID" : 5,
      "context" : "To summarize this introductory informal discussion, we can state that, while type s of (Gallin, 1975) and type World of (Pollard, 2005) stand for “states of world”, the similar to them type c of our model stands rather for “states of an individual mind”, which mind is not necessarily complete nor consistent, but, on one hand, still determines interpretation of a text and, on the other hand, is changeable (in particular, extendable) in the process of interpretation.",
      "startOffset" : 87,
      "endOffset" : 101
    }, {
      "referenceID" : 7,
      "context" : "The last examples give some hints on how this formalism could address donkey pronouns (Geach, 1962; Kamp, 1981; Heim, 1982; Elbourne, 2006), remaining entirely within the mainstream higher-order logic semantics.",
      "startOffset" : 86,
      "endOffset" : 139
    }, {
      "referenceID" : 5,
      "context" : "Then we moved to a further specialization of Ty n by introducing the context type (c), which can be interpreted as a ”store” or ”state” and thus is similar to ”state of affairs” or ”World” types of (Gallin, 1975) and (Pollard, 2005), respectively.",
      "startOffset" : 198,
      "endOffset" : 212
    }, {
      "referenceID" : 7,
      "context" : "addressing donkey pronouns (Geach, 1962; Kamp, 1981; Heim, 1982; Elbourne, 2006) and other dynamic semantic phenomena entirely within the mainstream higher-order logic semantics, as it was preliminarily outlined in section 8;",
      "startOffset" : 27,
      "endOffset" : 80
    }, {
      "referenceID" : 6,
      "context" : "modeling advanced language self-learning mechanisms, for example, such like deriving or generalization of grammar rules from text samples (may be accompanied by their semantic interpretation, communicated by other means or just expressed differently in the same language), that might be reduced, in frame of this formalism, to a problem of higher-order unification (Gardent et al., 1997; Dougherty & Mart́ınez, 2004).",
      "startOffset" : 365,
      "endOffset" : 416
    } ],
    "year" : 2014,
    "abstractText" : "We examine the class of languages that can be defined entirely in terms of provability in an extension of the sorted type theory (Tyn) by embedding the logic of phonologies, without introduction of special types for syntactic entities. This class is proven to precisely coincide with the class of logically closed languages that may be thought of as functions from expressions to sets of logically equivalent Tyn terms. For a specific sub-class of logically closed languages that are described by finite sets of rules or rule schemata, we find effective procedures for building a compact Tyn representation, involving a finite number of axioms or axiom schemata. The proposed formalism is characterized by some useful features unavailable in a two-component architecture of a language model. A further specialization and extension of the formalism with a context type enable effective account of intensional and dynamic semantics.",
    "creator" : "dvips(k) 5.98 Copyright 2009 Radical Eye Software"
  }
}