{
  "name" : "0911.5395.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "An axiomatic approach to the roughness measure of rough sets",
    "authors" : [ "Ping Zhua" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :0\n91 1.\n53 95\nv2 [\ncs .A\nI] 2\n5 M\nay 2\n01 0\nIn Pawlak’s rough set theory, a set is approximated by a pair of lower and upper approximations. To measure numerically the roughness of an approximation, Pawlak introduced a quantitative measure of roughness by using the ratio of the cardinalities of the lower and upper approximations. Although the roughness measure is effective, it has the drawback of not being strictly monotonic with respect to the standard ordering on partitions. Recently, some improvements have been made by taking into account the granularity of partitions. In this paper, we approach the roughness measure in an axiomatic way. After axiomatically defining roughness measure and partition measure, we provide a unified construction of roughness measure, called strong Pawlak roughness measure, and then explore the properties of this measure. We show that the improved roughness measures in the literature are special instances of our strong Pawlak roughness measure and introduce three more strong Pawlak roughness measures as well. The advantage of our axiomatic approach is that some properties of a roughness measure follow immediately as soon as the measure satisfies the relevant axiomatic definition.\nKeywords: Accuracy measure, Approximation, Partition measure, Roughness measure, Rough set"
    }, {
      "heading" : "1. Introduction",
      "text" : "Rough set theory was proposed by Pawlak in the early 1980s [22, 23] as a new mathematical approach for dealing with inexact, uncertain or vague knowledge in information systems. Since then we have witnessed a systematic, world-wide growth of interest in rough set theory [4, 20, 25, 28, 37, 43, 44, 48, 49, 50, 52]. Nowadays, it is widely recognized that rough set applications have a great importance in several fields, such as granular computing, data mining, and approximate reasoning [19, 26, 27, 46, 51, 53].\nA basic hypothesis in rough set theory is that some elements of a universe may be indiscernible in view of the available information about the elements. Such an indiscernibility relation was first described by equivalence relation in the way that two elements are related by the relation if and only if they are indiscernible from each other [22, 23]. In this framework, a rough set is a formal approximation of a subset of the universe in terms of a pair of unions of equivalence classes which give the lower and upper approximations of the subset. In order to measure numerically the accuracy of an approximation, Pawlak introduced two quantitative measures of accuracy and roughness in [23]: The accuracy of a subset is defined as the ratio of the cardinalities of the lower and upper approximations of the subset, which is bounded by 0 and 1; the roughness of a subset is calculated by subtracting the accuracy of the subset from 1. Therefore, roughness is a complementary concept to the accuracy of approximation. The roughness is, in some sense, the amount of uncertainty of the underlying subset. A roughness of 1 shows that we have no certain knowledge on the underlying subset, and a roughness of 0 means we know everything for sure about the underlying subset. From this point of view, the roughness measure is an important indicator of the uncertainty and accuracy associated with a given subset.\nIt has been observed [2, 17, 35] that the roughness (and its dual, accuracy) due to Pawlak, however, has the drawback of not being strictly monotonic with respect to the standard ordering on partitions. In other words, Pawlak’s roughness and accuracy measures do not necessarily provide us with information on the uncertainty related to the\nEmail address: pzhubupt@gmail.com (Ping Zhu)\nPreprint submitted to Fundamenta Informaticae May 26, 2010\ngranularity of partitions. To modify such measures, Beaubouef, Petry, and Arora proposed the notion of rough entropy in [2]. This limitation has also been improved by Xu, Zhou, and Lu in [35] by using the so-called excess entropy approach. Most recently, Liang, Wang, and Qian made another improvement by exploiting the notion of knowledge granulation in [17]. All of these improvements share some good properties. Nevertheless, there exists no unified description for roughness measure.\nThe purpose of this paper is to investigate roughness measure in an axiomatic way. We first introduce an axiomatic definition of roughness measure by taking into account the common properties of the roughness measures from [35] and [17]. After giving an axiomatic definition of partition measure, we then provide a unified construction of roughness measure, called strong Pawlak roughness measure, by combining partition measure into Pawlak’s roughness measure. Some properties of the strong Pawlak roughness measure are examined in detail. Finally, we show that the existing roughness measures in [35] and [17] are two special instances of our strong Pawlak roughness measure and present three new strong Pawlak roughness measures as well. The advantage of our axiomatic approach is that some properties of a roughness measure follow immediately as soon as the measure satisfies the relevant axiomatic definition.\nThe remainder of the paper is structured as follows. In Section 2, we briefly review some basics of Pawlak’s rough set theory and the roughness measures in the literature. The axiomatic definitions of roughness measure and partition measure are given in Section 3. The strong Pawlak roughness measure and its properties are also provided in this section. Section 4 is devoted to the case study of strong Pawlak roughness measures. We conclude the paper in Section 5 with a brief discussion on the future research."
    }, {
      "heading" : "2. Preliminaries",
      "text" : "This section consists of four subsections. We recall the definition of Pawlak’s rough sets in Section 2.1. Sections 2.2, 2.3, and 2.4 are devoted to roughness measures proposed by Pawlak [23], Xu et al. [35], and Liang et al. [17], respectively. Some necessary properties of these measures are collected for later use.\n2.1. Rough sets\nWe start by recalling some basic notions in Pawlak’s rough set theory [22, 23]. Let U be a finite and nonempty universal set, and let R ⊆ U × U be an equivalence relation on U. Denote by U/R the set of all equivalence classes induced by R. Such equivalence classes are also called elementary sets; every union (not necessarily nonempty) of elementary sets is called a definable set. For any A ⊆ U, one can characterize A by a pair of lower and upper approximations. The lower approximation R∗(A) of A is defined as the greatest definable set contained in A, while the upper approximation R∗(A) of A is defined as the least definable set containing A. Formally,\nR∗(A) = ∪{C ∈ U/R |C ⊆ A} and R∗(A) = ∪{C ∈ U/R |C ∩ A , ∅}.\nIt follows immediately from definition that R∗(A) ⊆ A ⊆ R∗(A) for any A ⊆ U. In particular, when R∗(A) = A = R∗(A), the set A is also called R-exact. Clearly, every definable set is R-exact, and vice versa. The ordered pair 〈U,R〉 is said to be an approximation space. A rough set in 〈U,R〉 is the family of subsets of U with the same lower and upper approximations.\nRecall that a partition of U is a collection of nonempty subsets of U such that every element x in U is in exactly one of these subsets. We write Π(U) for the set of all partitions of U and P(U) for the power set of U. It is well-known that the notions of partition and equivalence relation are essentially equivalent, that is, for any equivalence relation R on U, the set U/R is a partition of U, and conversely, from any partition π of U, one can define an equivalence relation Rπ on U such that U/Rπ = π in the obvious way. Thus, we sometimes say that the ordered pair 〈U, π〉 is an approximation space and write π∗(A) and π∗(A) for Rπ∗(A) and Rπ\n∗(A), respectively. More generally, we will use equivalence relation and partition indiscriminately.\nWhatever be a nonempty universe U, it is always possible to introduce at least two canonical partitions: One is the trivial partition, denoted by π̌, consisting of a unique equivalence class, and the other is the discrete partition, denoted by π̂, consisting of all singletons from U. Formally,\nπ̌ = {U} and π̂ = {{x} | x ∈ U}.\nWe now define a partial order “ ” on Π(U): For any π, σ ∈ Π(U),\nπ σ ⇐⇒ for any C ∈ π, there exists D ∈ σ such that C ⊆ D.\nFor instance, π̂ π π̌ for any π ∈ Π(U). We say that π is finer than σ and that σ is coarser than π if π σ. When π ≺ σ, that is, π σ and π , σ, we say that π is strictly finer than σ and that σ is strictly coarser than π. Informally, this means that π is a further fragmentation of σ.\n2.2. Roughness measure by Pawlak\nLet 〈U, π〉 be an approximation space. To characterize the uncertainty of rough sets, Pawlak proposed two numerical measures: roughness and accuracy (see, for example, [23]). The accuracy reflects the degree of completeness of knowledge about a given subset A of U; it is defined by the ratio of the cardinalities of the lower and upper approximations. More formally, the accuracy of A (with respect to π) is defined by\nαP(π, A) = |π∗(A)| |π∗(A)| ,\nwhere A , ∅ and “|S |” denotes the cardinality of a set S . For convenience, we set αP(π, ∅) = 1, that is, |∅|/|∅| = 1. The roughness is opposed to the accuracy; it represents the degree of incompleteness of knowledge about a given subset A. The roughness βP(π, A) of A (with respect to π) is calculated by subtracting the accuracy αP(π, A) from 1, that is,\nβP(π, A) = 1 − αP(π, A).\nClearly, 0 ≤ βP(π, A) ≤ 1. It is easy to see that βP(π, A) = 1 if and only if π∗(A) = ∅ and π∗(A) , ∅, and βP(π, A) = 0 if and only if A is π-exact.\nTo state the next property, we need one more notation. By βP(π, ·) βP(σ, ·) we mean that βP(π, A) ≤ βP(σ, A) for every A ⊆ U and βP(π, B) , βP(σ, B) for some B ⊆ U. Similar usages of “ ” will appear in the subsequent sections. The following property follows from the fact that for any A ⊆ U, σ∗(A) ⊆ π∗(A) ⊆ A ⊆ π∗(A) ⊆ σ∗(A) if π σ.\nProperty 1. For any π, σ ∈ Π(U), if π ≺ σ, then βP(π, ·) βP(σ, ·).\nThe roughness and accuracy measures are of simple expressions and are suitable for evaluating the uncertainty arising from the boundary region. Nevertheless, neither the roughness nor the accuracy reflects the granularity of the underlying partition. This limitation has been pointed out by several researchers [2, 17, 35]. For the convenience of the reader, we record a simple example.\nExample 1. Let U = {a1, a2, a3, a4, a5}, π = { {a1}, {a2, a3}, {a4, a5} } , and σ = { {a1, a2, a3}, {a4, a5} }\n. Then it is easy to see that π and σ are partitions of U, and moreover, π ≺ σ. Assume that A = {a1, a2, a3, a4}. We thus have by definition that\nπ∗(A) = σ∗(A) = {a1, a2, a3} and π∗(A) = σ∗(A) = {a1, a2, a3, a4, a5} = U.\nTherefore, αP(π, A) = αP(ρ, A) = 0.6 and βP(π, A) = βP(ρ, A) = 0.4. It means that partitions with different granulations may give rise to the same accuracy (and thus roughness) for some subsets. This property is, of course, not desirable.\n2.3. Roughness measure by Xu et al.\nTo improve the accuracy and roughness measures suggested by Pawlak, Xu et al. [35] combined the granularity of the underlying partition into Pawlak’s accuracy by exploiting the so-called equivalence relation graphs. To introduce their definition, we need several notions.\nLet 〈U, π〉 be an approximation space. The equivalence relation graph with respect to π is defined as G(π) = (N(π), E(π)), where N(π) = U and E(π) = {(x, y) ∈ U×U |(x, y) ∈ Rπ}. For any vertex v on G(π) = (N(π), E(π)), let the subgraph corresponding to v be G(π)(v) = (N(π)(v), E(π)(v)), where N(π)(v) = N(π) and E(π)(v) = {(v, y) | (v, y) ∈ E(π)}. For any given G(π), let pG(π)L(G(π),v) be the proportion of the row vector L(G(π), v) out of |N(π)| row vectors in the incidence matrix of G(π), where L(G(π), v) is the row vector corresponding to v in the incidence matrix of G(π). More formally,\npG(π)L(G(π),v) = n/|N(π)|, where n is the number of row vectors in the incidence matrix of G(π) that are equal to L(G(π), v). For an equivalence relation graph G(π), the minimum description length of G(π) is defined by1\nI(G(π)) = − ∑\nv∈N(π)\nlog pG(π)L(G(π),v).\nFinally, we may state the key definition and results in [35] as follows. Let 〈U, π〉 be an approximation space. The roughness of A (with respect to π) due to Xu et al. is defined by\nβX(π, A) = βP(π, A) · con(G(π))\n|U |(|U | − 1) log |U | ,\nwhere βP(π, A) is the Pawlak’s roughness of A and\ncon(G(π)) = ∑\nv∈N(π)\nI(G(π)(v)) − I(G(π)).\nNote that I(G(π)(v)) is the minimum description length of the subgraph G(π)(v) corresponding to v. It follows from [35] that the new roughness measure βX(π, A) enjoys some useful properties, which are listed as follows.\nProperty 2. For any π ∈ Π(U) and A ⊆ U, 0 ≤ βX(π, A) ≤ 1.\nProperty 3. βX(π̂, A) = 0 for any A ⊆ U; βX(π̌,U) = 0, and βX(π̌, A) = 1 for any A ( U.\nProperty 4. For any π, σ ∈ Π(U), if π σ, then βX(π, A) ≤ βX(σ, A) for any A ⊆ U.\nProperty 5. Let π ∈ Π(U) and A, B ⊆ U.\n1) If π∗(A) = π∗(B), then βX(π, A ∩ B) ≤ min{βX(π, A), βX(π, B)}. 2) If π∗(A) = π∗(B), then βX(π, A ∪ B) ≤ min{βX(π, A), βX(π, B)}.\nIt should be pointed out that βX has not the same drawback as shown for βP in Example 1.\n2.4. Roughness measure by Liang et al.\nBased on the notion of knowledge granulation due to Miao and Fan [21], Liang et al. proposed a roughness measure [17] which is simpler than that in [35]. Let 〈U, π〉 be an approximation space and suppose that π = {C1,C2, . . . ,Cm}. The roughness of A (with respect to π) due to Liang et al. is defined by\nβL(π, A) = βP(π, A) ·\n∑m i=1 |Ci| 2\n|U |2 ,\nwhere βP(π, A) = 1 − |π∗(A)|/|π∗(A)| is the Pawlak’s roughness of A and the second term ∑m i=1 |Ci | 2\n|U|2 represents the knowledge granulation of π introduced in [21].\nThe following properties of the roughness measure βL(π, A) were given in [17].\nProperty 6. For any π ∈ Π(U) and A ⊆ U, 0 ≤ βL(π, A) ≤ 1.\nProperty 7. If βL(π, A) = 0 for all A ⊆ U, then π = π̂; if βL(π, A) = 1 for some A , U, then π = π̌.\nProperty 8. For any π, σ ∈ Π(U), if π σ, then βL(π, A) ≤ βL(σ, A) for any A ⊆ U.\nLike βX , the roughness measure βL has not the same drawback as shown for βP in Example 1.\n1All logarithms are to base 2 unless otherwise specified."
    }, {
      "heading" : "3. An axiomatic definition of roughness measure",
      "text" : "This section is composed of three subsections. Motivated by the roughness measures in [17, 35], we present an axiomatic definition of roughness measure and discuss its basic properties in Section 3.1. In order to construct more roughness measures, we introduce an axiomatic definition of partition measure in Section 3.2. By incorporating partition measure into Pawlak’s roughness measure, we introduce a strong Pawlak roughness measure and explore its properties in Section 3.3.\n3.1. Roughness measure\nFor later need, let us introduce the following notion which relates two approximation spaces.\nDefinition 1. Let 〈U, π〉 and 〈V, σ〉 be two approximation spaces, and suppose that f : U −→ V is a mapping.\n1) The mapping f is called a homomorphism from 〈U, π〉 to 〈V, σ〉 if for any C ∈ π, there exists D ∈ σ such that f (C) ⊆ D, where f (C) = { f (u) | u ∈ C}.\n2) A homomorphism f is called a monomorphism if f is an injective mapping. 3) A monomorphism f is called strictly monomorphic if there exist C ∈ π and D ∈ σ such that f (C) ( D, namely,\nf (C) ⊆ D and f (C) , D. 4) The mapping f is called an isomorphism if the mapping f : U −→ V is bijective, and moreover, both f and its\ninverse mapping f −1 are homomorphisms.\nLet us now present the axiomatic definition of roughness measure.\nDefinition 2. Let U be a finite and nonempty universal set and β a mapping from Π(U) × P(U) to the closed unit interval [0, 1]. We say that β is a roughness measure on U if the following conditions are satisfied:\n1) β(π, A) = 0 if and only if A is π-exact. 2) For any π, σ ∈ Π(U), if π ≺ σ, then β(π, ·) β(σ, ·). 3) For any π, σ ∈ Π(U), if there is an isomorphism f from 〈U, π〉 to 〈U, σ〉, then β(π, A) = β(σ, f (A)) for any\nA ⊆ U.\nIf β is a roughness measure on U, then the roughness of A (with respect to π) is defined by the value β(π, A).\nLet us give a brief, informal account of the above conditions. Condition 1) just says that a set is exact if and only if it has roughness 0. Condition 2) requires that roughness measure strictly maintains the partial order on Π(U). Notice that any isomorphism f from 〈U, π〉 to 〈U, σ〉 is actually a renaming of elements of U that keeps elementary sets. For example, there is an isomorphism between 〈{1, 2, 3, 4}, { {1, 2}, {3, 4} } 〉 and 〈{1, 2, 3, 4}, { {1, 3}, {2, 4} }\n〉. Therefore, the condition 3) requires that roughness measure is only dependent on the structure (i.e., blocks) of partitions; this seems quite reasonable.\nIt follows from the definition of Pawlak’s roughness measure βP and Property 1 that βP is a roughness measure in the sense of Definition 2. To illustrate the definition, let us examine a trivial example.\nExample 2. Consider β : Π(U) × P(U) −→ [0, 1] defined as follows:\nβ(π, A) =\n{\n0, if A is π-exact 1, otherwise.\nClearly, the condition 1) in Definition 2 is satisfied. For the condition 2), let π, σ ∈ Π(U) with π ≺ σ. For any A ⊆ U, it follows from definition that A is π-exact whenever it is σ-exact, but the converse does not hold, that is, a π-exact set may not be σ-exact. It means that if β(σ, A) = 0, then β(π, A) = 0, and there exists A′ ⊆ U such that β(π, A′) = 0 while β(σ, A′) = 1. This forces that β(π, ·) β(σ, ·), as desired. For the condition 3), note that the isomorphism f establishes a one-to-one correspondence between the set of π-exact sets and that of σ-exact ones. Therefore, the condition 3) holds, and β is indeed a roughness measure on U.\nBy definition, we have two properties of roughness measure. The first one is a characterization of the minimum of a roughness measure.\nProposition 1. Let β be a roughness measure on U. Then β(π, A) = 0 holds for all A ⊆ U if and only if π = π̂.\nProof. Note that if π = π̂, then every subset A of U is π-exact. Hence, the sufficiency follows immediately from Definition 2. Conversely, if β(π, A) = 0 holds for all A ⊆ U, then by definition every subset A of U is π-exact. This means that every nonempty subset of U is a definable set. As a result, we see that π = π̂, which proves the necessity.\nThe next property is a relaxation of the condition 2) in Definition 2.\nProposition 2. Let β be a roughness measure on U and π, σ ∈ Π(U). If π σ, then β(π, A) ≤ β(σ, A) for any A ⊆ U. In particular, β(π, A) ≤ β(π̌, A) for any π ∈ Π(U) and A ⊆ U.\nProof. It follows directly from the condition 2) in Definition 2.\nThe following property is equivalent to the condition 2) in Definition 2, under the condition 3) in this definition.\nProposition 3. Suppose that β is a roughness measure on U and f is a strict monomorphism from 〈U, π〉 to 〈U, σ〉. Then β(π, A) ≤ β(σ, f (A)) for any A ⊆ U, and moreover, there exists A′ ⊆ U such that β(π, A′) < β(σ, f (A′)).\nProof. Since f is a monomorphism from 〈U, π〉 to 〈U, σ〉, it gives an isomorphism between 〈U, π〉 and 〈U, f (π)〉, where f (π) = { f (A) |A ∈ π}. Note that U is finite and f is injective, so f is bijective and thus f (π) is indeed a partition of U. By definition, we see that β(π, A) ≤ β( f (π), f (A)) for any A ⊆ U. On the other hand, we have that f (π) ≺ σ since f is strictly monomorphic. This means by Proposition 2 that β( f (π), f (A)) ≤ β(σ, f (A)) for any A ⊆ U. As a result, β(π, A) ≤ β(σ, f (A)) for any A ⊆ U. The remainder of this proposition follows easily from the strictness of the monomorphism f .\nThe condition 2) in Definition 2 just says that β is strictly monotonic. Depending on applications, strict monotonicity may not be so required. For example, it is usually interesting to look at dependencies between partitions generated by decision attributes and condition attributes in a decision system. In such cases, one may be mostly interested in weak monotonicity but not in strict monotonicity. Actually, the cases when the measure does not change while changing the partition into a more or less detailed one are of special importance for feature selection, feature subset selection, feature extraction, and feature reduction in knowledge discovery (see, for example, [7, 11, 31]). In view of this, let us introduce a weak version of Definition 2 as follows.\nDefinition 3. Let U be a finite and nonempty universal set and β a mapping from Π(U) × P(U) to the closed unit interval [0, 1]. We say that β is a weak roughness measure on U if the following conditions are satisfied:\n1) β(π, A) = 0 if and only if A is π-exact. 2) For any π, σ ∈ Π(U), if π σ, then β(π, ·) ≤ β(σ, ·). 3) For any π, σ ∈ Π(U), if there is an isomorphism f from 〈U, π〉 to 〈U, σ〉, then β(π, A) = β(σ, f (A)) for any\nA ⊆ U. 4) β(π, ·) = 0 if and only if π = π̂.\nIf β is a weak roughness measure on U, then the weak roughness of A (with respect to π) is defined by the value β(π, A).\nClearly, Conditions 1) and 3) are the same as in Definition 2, and Condition 2) means that β is weakly monotonic. Note that in order to avoid β being constant, we add Condition 4) in the above definition. It is easy to check that any roughness measure in the sense of Definition 2 is a weak roughness measure, but the converse does not hold in general.\n3.2. Partition measure\nIn order to measure partitions, we provide an axiomatic definition of partition measure as follows.\nDefinition 4. Let U be a finite and nonempty universal set and h a mapping from Π(U) to [0,+∞), the set of nonnegative real numbers. We say that h is a partition measure on U if the following conditions are satisfied:\n1) For any π, σ ∈ Π(U), if π ≺ σ, then h(π) < h(σ).\n2) For any π, σ ∈ Π(U), if there is an isomorphism f from 〈U, π〉 to 〈U, σ〉, then h(π) = h(σ).\nIntuitively, we require that partition measures on U are only dependent upon the structure of partitions, not the names of elements in U. Roughly speaking, the greater the value of h, the coarser the corresponding partition. Let us see an example.\nExample 3. Let U = {1, 2, 3, 4}. Then U has 15 partitions because the total number of partitions of an n-element set is the Bell number Bn, recursively defined by Bn+1 = ∑n k=0 ( n k )\nBk and B0 = 1 (see, for example, [5]). For simplicity, we write 1/2/34 for the partition { {1}, {2}, {3, 4} } , alike to other partitions. With this notation, we have that\nΠ(U) = {1234, 1/234, 2/134, 3/124, 4/123, 14/23, 13/24, 12/34,\n1/2/34, 1/3/24, 1/4/23, 3/4/12, 2/4/13, 2/3/14, 1/2/3/4}.\nBy definition, any mapping h : Π(U) −→ [0,+∞) that satisfies the following conditions is a partition measure on U:\nh(1/2/3/4) = r1,\nh(1/2/34) = h(1/3/24) = h(1/4/23) = h(3/4/12)\n= h(2/4/13) = h(2/3/14) = r2,\nh(14/23) = h(13/24) = h(12/34) = r3,\nh(1/234) = h(2/134) = h(3/124) = h(4/123) = r4,\nh(1234) = r5,\nwhere ri ∈ [0,+∞), i = 1, 2, . . . , 5, with r1 < r2 < r3 < r5 and r1 < r2 < r4 < r5.\nWe remark that our axiomatic definition of partition measure is essentially based on the cardinalities of all equivalence classes in a partition. Recently, Yao and Zhao [41] have directly established a partition measure on the cardinality of a partition, and moreover, they constructed an interesting measure of the granularity of a partition which has several existing measures as instances. We see by Theorem 3 in [41] that this new measure satisfies Definition 4 as well. It should be stressed that constructing and evaluating partitions are the most basic issues in rough set theory, since the indiscernibility is the mathematical basis of rough set theory [25] and there are strong relationships between indiscernibility measures and partition measures [1, 21, 32, 39, 40, 45]. In addition to rough sets, the granularity of a partition is a very important concept in many other fields such as information theory, data mining, machine learning, and pattern recognition. In the literature, there are a large number of approaches to measuring partitions (see, for example, [2, 9, 10, 12, 13, 14, 15, 16, 17, 18, 24, 25, 29, 33, 34, 36, 38, 39, 42, 47]). In some sense, the roughness measure in Definition 2 as well as the weak roughness measure in Definition 3 can be viewed as a partition measure because for some given subsets, say A, of U, the function β(·, A) can reflect the granularity of a partition.\nThe following facts follow directly from Definition 4.\nCorollary 1. Suppose that h is a partition measure on U. 1) For any π, σ ∈ Π(U), if π σ, then h(π) ≤ h(σ). 2) For any π ∈ Π(U), h(π̂) ≤ h(π) ≤ h(π̌). In particular, h(π) > 0 whenever π , π̂.\nAs expected, partition measures have the following property.\nProposition 4. Let h be a partition measure on U and π, σ ∈ Π(U). If there is a strict monomorphism f from 〈U, π〉 to 〈U, σ〉, then h(π) < h(σ).\nProof. Assume that f is a strict monomorphism from 〈U, π〉 to 〈U, σ〉. Then it is clear that f gives rise to an isomorphism from 〈U, π〉 to 〈U, f (π)〉, where f (π) = { f (A) | A ∈ π}. We thus have that h(π) = h( f (π)) by Definition 4. Furthermore, we find that f (π) ≺ σ since f is strictly monomorphic. By definition, we obtain that h( f (π)) < h(σ). Consequently, h(π) < h(σ), finishing the proof.\nAs a corollary of Proposition 4, we get an equivalent definition of partition measure.\nCorollary 2. A mapping h : Π(U) −→ [0,+∞) is a partition measure on U if and only if the following conditions hold:\n1) For any π, σ ∈ Π(U), if there is a strict monomorphism f from 〈U, π〉 to 〈U, σ〉, then h(π) < h(σ). 2) For any π, σ ∈ Π(U), if there is an isomorphism f from 〈U, π〉 to 〈U, σ〉, then h(π) = h(σ).\n3.3. Strong Pawlak roughness measure\nGiven a partition measure, we can construct a roughness measure in the sense of Definition 2 as follows.\nTheorem 1. Let U be a finite and nonempty universal set. Suppose that h is a partition measure on U. Then the function βh : Π(U) × P(U) −→ [0, 1] defined by\nβh(π, A) = βP(π, A) · h(π) h(π̌) = ( 1 − |π∗(A)| |π∗(A)| ) · h(π) h(π̌)\nis a roughness measure on U.\nProof. We need to check all the three conditions in Definition 2. For the first condition, observe that βh(π, A) = 0 if and only if either |π∗(A)| |π∗(A)| = 1 or h(π) = 0. Clearly, |π∗(A)| |π∗(A)| = 1 is equivalent to that A is π-exact. Note that h(π) = 0 implies π = π̂ by Corollary 1. In this case, every subset A of U is π-exact. Hence, βh(π, A) = 0 if and only if A is π-exact, as desired.\nFor the second condition, assume that π ≺ σ. Then h(π) < h(σ) by definition. On the other hand, we have by Property 1 that βP(π, ·) βP(σ, ·). We thus obtain that βh(π, ·) βh(σ, ·), as desired.\nFor the third condition, suppose that f is an isomorphism from 〈U, π〉 to 〈U, σ〉, where π, σ ∈ Π(U). Then by definition we see that |π∗(A)| = |σ∗( f (A))| and |π∗(A)| = |σ∗( f (A))| for any A ⊆ U. Therefore, βP(π, A) = βP(σ, f (A)). Since f is an isomorphism, we also have that h(π) = h(σ) by definition. As a result, we get that βh(π, A) = βh(σ, f (A)) for any A ⊆ U. This completes the proof of the theorem.\nFor convenience, the roughness measure βh associated to a partition measure h is called a strong Pawlak roughness measure. Note that neither Pawlak’s roughness measure βP nor the roughness measure defined in Example 2 is a strong Pawlak roughness measure. We end this subsection with a discussion on the properties of strong Pawlak roughness measures. The first five properties follow immediately from Theorem 1, in which the assertion 3) justifies the modifier “strong”.\nCorollary 3.\n1) βh(π, A) = 0 if and only if A is π-exact. 2) For any π, σ ∈ Π(U), if π ≺ σ, then βh(π, ·) βh(σ, ·). Consequently, if π σ, then βh(π, A) ≤ βh(σ, A) for any\nA ⊆ U. 3) For any π, σ ∈ Π(U), if π ≺ σ and A ⊆ U is not σ-exact, then βh(π, A) < βh(σ, A). 4) For any π, σ ∈ Π(U), if there is an isomorphism f from 〈U, π〉 to 〈U, σ〉, then βh(π, A) = βh(σ, f (A)) for any\nA ⊆ U. 5) Assume that there is a strict monomorphism f from 〈U, π〉 to 〈U, σ〉. Then βh(π, A) ≤ βh(σ, f (A)) for any A ⊆ U,\nand moreover, there exists A′ ⊆ U such that βh(π, A′) < βh(σ, f (A′)).\nLike the previous roughness measures βP, βX , and βL, the strong Pawlak roughness measure βh is bounded as well.\nProposition 5. For any π ∈ Π(U) and A ⊆ U, 0 ≤ βh(π, A) ≤ 1.\nProof. It follows directly from 0 ≤ βP(π, A) ≤ 1 and Corollary 1.\nIn terms of the maximum and minimum of βh, we have further characterizations.\nProposition 6. βh(π, A) = 0 holds for all A ⊆ U if and only if π = π̂.\nProof. By the assertion 1) in Corollary 3, βh(π, A) = 0 holds for all A ⊆ U if and only if every subset A of U is π-exact, which is equivalent to that π = π̂. This proves the proposition.\nProposition 7. If there exists A ⊆ U such that βh(π, A) = 1, then π = π̌. Moreover,\nβh(π̌, A) =\n{\n0, if A = U 1, otherwise.\nProof. If there exists A ⊆ U such that βh(π, A) = 1, then it forces that βP(π, A) = 1 and h(π) = h(π̌). The latter yields that π = π̌ by Corollary 1. The remainder of this proposition follows readily from the definition of βh.\nLike the roughness measure βX , the strong Pawlak roughness measure βh has the following properties.\nProposition 8. Let π ∈ Π(U) and A, B ⊆ U.\n1) If π∗(A) = π∗(B), then βh(π, A ∩ B) ≤ min{βh(π, A), βh(π, B)}. 2) If π∗(A) = π∗(B), then βh(π, A ∪ B) ≤ min{βh(π, A), βh(π, B)}.\nProof. 1) Clearly, π∗(A ∩ B) ⊆ π∗(A). If π∗(A) = π∗(B), then we can verify that π∗(A ∩ B) = π∗(A). Hence,\n|π∗(A ∩ B)| |π∗(A ∩ B)| ≥ |π∗(A)| |π∗(A)| ,\nwhich means that βP(π, A ∩ B) ≤ βP(π, A). In the same way, we obtain that βP(π, A ∩ B) ≤ βP(π, B). It yields that βh(π, A ∩ B) ≤ min{βh(π, A), βh(π, B)}, as desired.\n2) The proof is similar to that of 1). It is easy to see that π∗(A) ⊆ π∗(A ∪ B). If π∗(A) = π∗(B), then we can check that π∗(A ∪ B) = π∗(A). As a result, we have that\n|π∗(A ∪ B)| |π∗(A ∪ B)| ≥ |π∗(A)| |π∗(A)| .\nTherefore, βP(π, A∪B) ≤ βP(π, A). Analogously, we can obtain that βP(π, A∪B) ≤ βP(π, B). It gives that βh(π, A∪B) ≤ min{βh(π, A), βh(π, B)}, finishing the proof of the proposition."
    }, {
      "heading" : "4. Case study of strong Pawlak roughness measures",
      "text" : "As we have seen in the previous section, if one can show that h is a partition measure on U, then βh is a strong Pawlak roughness measure and thus has the properties stated in Corollary 3 and Propositions 5, 6, 7, and 8. In this section, we first look at the roughness measures βX and βL due to Xu et al. [35] and Liang et al. [17], respectively, in the framework of strong Pawlak roughness measures, and then provide three new strong Pawlak roughness measures.\nProposition 9. The roughness measure βX due to Xu et al. is a strong Pawlak roughness measure.\nProof. By definition,\nβX(π, A) = βP(π, A) · con(G(π))\n|U |(|U | − 1) log |U | ,\nso it is sufficient to show that h defined by\nh(π) = con(G(π))\n|U |(|U | − 1) log |U |\nis a partition measure on U and h(π̌) = 1. It follows from Theorem 7 in [35] that h satisfies the condition 1) in Definition 4, that is, π ≺ σ implies h(π) < h(σ). In addition, if there is an isomorphism from 〈U, π〉 to 〈U, σ〉, then we see that con(G(π)) = con(G(σ)) by the definition of equivalence relation graph. Therefore, h(π) = h(σ). It follows from definition that con(G(π̌)) = |U |(|U | − 1) log |U |, namely, h(π̌) = 1. Hence, h is a partition measure, as desired. In fact, we may also define h′(π) = con(G(π)) and then verify that h′ is a partition measure and h′(π̌) = |U |(|U |−1) log |U |.\nProposition 10. The roughness measure βL due to Liang et al. is a strong Pawlak roughness measure.\nProof. By definition,\nβL(π, A) = βP(π, A) ·\n∑m i=1 |Ci| 2\n|U |2 ,\nwhere {C1,C2, . . . ,Cm} = π. In order to show that βL is a strong Pawlak roughness measure, it suffices to prove that h defined by h(π) =\n∑m i=1 |Ci| 2 is a partition measure on U and h(π̌) = |U |2. The former follows readily from the definition of h and the latter is obvious. Therefore, βL is a strong Pawlak roughness measure.\nRemark 1. Propositions 9 and 10 tell us that the roughness measures βX and βL have the properties stated in Corollary 3 and Propositions 5, 6, 7, and 8; some of these properties are missing in [35] or [17].\nTo introduce another strong Pawlak roughness measure, let us recall the notion of co-entropy [2, 15, 16, 18, 39]. Assume that π = {C1,C2, . . . ,Cm} ∈ Π(U). Then the co-entropy of partition π is defined as\nE(π) = 1 |U |\nm ∑\ni=1\n|Ci| log |Ci|.\nIt has been known that the following identity holds\nH(π) + E(π) = log |U | for any π ∈ Π(U),\nwhere H(π) is the entropy of partition π [15, 16, 30, 34, 39] defined as\nH(π) = − m ∑\ni=1\n|Ci| |U | log |Ci| |U | .\nNotice that a standard result of information theory assures the strict anti-monotonicity of entropy (see, for example, [30]):\nif π ≺ σ, then H(σ) < H(π).\nTherefore, we have the following strict monotonicity of co-entropy with respect to the partition ordering (a direct proof of this result can be found in [16]):\nif π ≺ σ, then E(π) < E(σ).\nThis result has been proven in a roughness monotonicity theorem of [34], which is based on a lemma of the same paper. We thus find that E is a partition measure on U. Noting that E(π̌) = log |U |, we get the following proposition.\nProposition 11. Define\nβE(π, A) = βP(π, A) · E(π)\nlog |U |\nfor any π ∈ Π(U) and A ⊆ U. Then βE is a strong Pawlak roughness measure.\nLet us remark that βP(π, A) · E(π) was defined as the rough entropy of A in [2]. Therefore, we may view βE(π, A) as a standardization of the rough entropy of A.\nIn [3], Bianucci et al. introduced a pseudo co-entropy related to a partition π = {C1,C2, . . . ,Cm} ∈ Π(U) as follows:\nE′(π) = 1 |U |\nm ∑\ni=1\n|Ci| 2 log |Ci|.\nIt has been proven in [3] that if π ≺ σ, then E′(π) < E′(σ).\nThis property, together with the definition of E′, implies that E′ is also a partition measure on U. By using E′(π̌) = |U | log |U |, we obtain the following proposition.\nProposition 12. Define\nβE′ (π, A) = βP(π, A) · E′(π)\n|U | log |U |\nfor any π ∈ Π(U) and A ⊆ U. Then βE′ is a strong Pawlak roughness measure.\nWe end this section with one more strong Pawlak roughness measure arising from the concept of combination granulation introduced by Qian and Liang in [29].\nLet π = {C1,C2, . . . ,Cm} ∈ Π(U). Then the combination granulation of π, denoted by CG(π), is defined as [29]\nCG(π) = m ∑\ni=1\n|Ci|2\n|U |2 · |Ci| − 1 |U | − 1 .\nIt has been shown by Proposition 9 in [29] that\nif π ≺ σ, then CG(π) < CG(σ).\nThis property, together with the definition of CG, implies that CG is a partition measure on U. As CG(π̌) = 1, we obtain the following proposition.\nProposition 13. Define βCG(π, A) = βP(π, A) · CG(π)\nfor any π ∈ Π(U) and A ⊆ U. Then βCG is a strong Pawlak roughness measure.\nRemark 2. Thanks to the axiomatic approach, Propositions 11, 12, and 13 show us that the roughness measures βE , βE′ , and βCG are of the properties stated in Corollary 3 and Propositions 5, 6, 7, and 8.\nLet us calculate the above five strong Pawlak roughness measures for the sets and partitions in Example 1.\nExample 4. Let us revisit Example 1, where U = {a1, a2, a3, a4, a5}, π = { {a1}, {a2, a3}, {a4, a5} } , and σ = {\n{a1, a2, a3}, {a4, a5} }\n. For A = {a1, a2, a3, a4}, we have already obtained that βP(π, A) = βP(ρ, A) = 0.4 in Example 1. By a direct computation, we can readily get the following results:\nβX(π, A) = 0.102 < βX(σ, A) = 0.219;\nβL(π, A) = 0.144 < βL(σ, A) = 0.208;\nβE(π, A) = 0.138 < βE(σ, A) = 0.233;\nβE′ (π, A) = 0.055 < βE′ (σ, A) = 0.126;\nβCG(π, A) = 0.032 < βCG(σ, A) = 0.088.\nAll of these are consistent with the fact that π ≺ σ."
    }, {
      "heading" : "5. Conclusion",
      "text" : "In this paper, we have investigated roughness measure in an axiomatic way. The axiomatic definitions of roughness measure and partition measure have been provided. Based on this, we have given a unified construction of roughness measure, called strong Pawlak roughness measure, by combining partition measure into Pawlak’s roughness measure. Some properties of the strong Pawlak roughness measure have been explored as well. In addition, we have shown that the existing roughness measures in [35] and [17] are two special instances of our strong Pawlak roughness measure, which supports our axiomatic definitions. The advantage of axiomatic approach is that it can bring together some seemingly different notions. As a result, we may study the properties of roughness measure in Definition 2 and weak roughness measure in Definition 3 instead of some specific measure.\nAs mentioned earlier, our axiomatic definition of roughness measure is largely dependent on partition measure, while the latter is based upon the cardinalities of all equivalence classes in a partition. Because partition measures can be defined from different perspectives, more axiomatic definitions and properties of roughness measure remain to be investigated. In addition, the present work focuses on the classical rough sets based on partitions. It would be interesting to examine our axiomatic approach in the framework of covering rough sets [6, 28, 43] or fuzzy rough sets [8]. Finally, in the face of so many roughness measures, the criterion for choice remains yet to be addressed."
    }, {
      "heading" : "Acknowledgements",
      "text" : "This work was supported by the National Natural Science Foundation of China under Grants 60821001, 60873191, and 60903152.\n[1] Bazan, J., Nguyen, H., Nguyen, S., Synak, P., Wróblewski, J., 2000. Rough set algorithms in classification problem. Rough Set Methods and Applications: New Developments in Knowledge Discovery in Information Systems, Studies in Fuzziness and Soft Computing 56. PhysicaVerlag, Heidelberg, Germany, pp. 49–88. [2] Beaubouef, T., Petry, F. E., Arora, G., 1998. Information-theoretic measures of uncertainty for rough sets and rough relational databases. Inform. Sci. 109, 185–195. [3] Bianucci, D., Cattaneo, G., Ciucci, D., 2007. Entropies and co-entropies of coverings with application to incomplete information systems. Fund. Inform. 75, 77–105. [4] Bonikowski, Z., Bryniarski, E., Wybraniec-Skardowska, U., 1998. Extensions and intentions in the rough set theory. Inform. Sci. 107, 149– 167. [5] Brualdi, R. A., 2004. Introductory Combinatorics, 4th Edition. Pearson Prentice Hall. [6] Bryniarski, E., 1989. A calculus of rough sets of the first order. Bull. Pol. Acad. Sci. 36 (16), 71–77. [7] Cornelis, C., Jensen, R., Hurtado, G., Ślȩzak, D., 2010. Attribute selection with fuzzy decision reducts. Inform. Sci. 180, 209–224. [8] Dubois, D., Prade, H., 1990. Rough fuzzy sets and fuzzy rough sets. Int. J. Gen. Syst. 17, 191–208. [9] Düntsch, I., Gediga, G., 1998. Uncertainty measures of rough set prediction. Artif. Intell. 106 (1), 109–137. [10] Düntsch, I., Gediga, G., 2001. Roughian: Rough information analysis. Int. J. Intell. Syst. 16 (1), 121–147. [11] Hepting, D. H., Maciag, T., Spring, R., Arbuthnott, K., Ślȩzak, D., 2009. A rough sets approach for personalized support of face recognition.\nVol. 5908 of Lect. Notes Artif. Intell., RSFDGrC 2009. pp. 201–208. [12] Klir, G. J., Folger, T. A., 1988. Fuzzy Sets, Uncertainty, and Information. Englewood Cliffs, NJ: Prentice Hall. [13] Kudo, Y., Murai, T., 2009. On a criterion of similarity between partitions based on rough set theory. Vol. 5908 of Lect. Notes Artif. Intell.,\nRSFDGrC 2009. pp. 101–108. [14] Lee, T. T., 1987. An information-theoretic analysis of relational databases–Part I: Data dependencies and information metric. IEEE Trans.\nSoftware Eng. 13 (10), 1049–1061. [15] Liang, J., Shi, Z., Li, D., Wierman, M. J., 2006. Information entropy, rough entropy and knowledge granulation in incomplete information\nsystems. Int. J. Gen. Syst. 35 (6), 641–654. [16] Liang, J. Y., Shi, Z. Z., 2004. The information entropy, rough entropy and knowledge granulation in rough set theory. Int. J. Uncert. Fuzz.\nKnowl. Syst. 12 (1), 37–46. [17] Liang, J. Y., Wang, J. H., Qian, Y. H., 2009. A new measure of uncertainty based on knowledge granulation for rough sets. Inform. Sci. 179,\n458–470. [18] Liang, J. Y., Xu, Z. B., 2000. Uncertainty measure of randomness of knowledge and rough sets in incomplete information systems. Intell.\nContr. Autom. 4, 2526–2529. [19] Lin, T. Y., Cercone, N. (Eds.), 1997. Rough Sets and Data Mining. Kluwer Academic Publishers, Boston. [20] Liu, G., 2006. The axiomatization of the rough set upper approximation operations. Fund. Inform. 69 (23), 331–342. [21] Miao, D. Q., Fan, S. D., 2002. The calculation of knowledge granulation and its application (in Chinese). Syst. Eng. Theory Pract. 22 (1),\n48–56. [22] Pawlak, Z., 1982. Rough sets. Int. J. Comput. Inform. Sci. 11 (5), 341–356. [23] Pawlak, Z., 1991. Rough Sets: Theoretical Aspects of Reasoning about Data. Kluwer Academic Publishers, Boston. [24] Pawlak, Z., Skowron, A., 2007. Rough sets and boolean reasoning. Infom. Sci. 177 (1), 41–73. [25] Pawlak, Z., Skowron, A., 2007. Rudiments of rough sets. Infom. Sci. 177 (1), 3–27. [26] Polkowski, L., Skowron, A. (Eds.), 1998. Rough Sets and Current Trends in Computing. Vol. 1424 of Lect. Notes Comput. Sci., RSCTC’98,\nSpringer, Berlin. [27] Polkowski, L., Skowron, A. (Eds.), 1998. Rough Sets in Knowledge Discovery. Vol. 1 and 2. Physica-Verlag, Heidelberg. [28] Pomykala, J. A., 1987. Approximation operations in approximation space. Bull. Pol. Acad. Sci. 35 (9-10), 653–662. [29] Qian, Y. H., Liang, J. Y., 2008. Combination entropy and combination granulation in rough set theory. Int. J. Uncert. Fuzz. Knowl. Syst.\n16 (2), 179–193. [30] Reza, F. M., 1994. An Introduction to Information Theory. Dover Publications, New York, originally published by Mc Graw-Hill, New York,\n1961. [31] Sakai, H., Hayashi, K., Nakata, M., Ślȩzak, D., 2009. The lower system, the upper system and rules with stability factor in non-deterministic\ninformation systems. Vol. 5908 of Lect. Notes Artif. Intell., RSFDGrC 2009. pp. 313–320. [32] Ślȩzak, D., 2000. Various approaches to reasoning with frequency based decision reducts: a survey. In: in: L. Polkowski, S. Tsumoto, T Y\nLin (eds.), Rough set methods and applications, New Developments in Knowledge Discovery in Information Systems, Studies in Fuzziness and Soft Computing 56. Physica-Verlag, Heidelberg, Germany, pp. 235–288. [33] Wang, J., Liang, J., Yian, Y., Dang, C., 2008. Uncertainty measure of rough sets based on a knowledge granulation for incomplete information systems. Int. J. Uncert. Fuzz. Knowl. Syst. 16 (2), 233–244. [34] Wierman, M., 1999. Measuring uncertainty in rough set theory. Int. J. Gen. Syst. 28, 283–297. [35] Xu, B. W., Zhou, Y. M., Lu, H. M., 2005. An improved accuracy measure for rough sets. J. Comput. Syst. Sci. 71, 163–173. [36] Yager, R. R., 2010. Partition measures for data mining. Advances in Machine Learning I: Dedicated to the Memory of Professor Ryszard S.\nMichalski, SCI 262, 299–319. [37] Yao, Y. Y., 1998. Constructive and algebraic methods of theory of rough sets. Infom. Sci. 109, 21–47. [38] Yao, Y. Y., 2003. Information-theoretic measures for knowledge discovery and data mining. in: Karmeshu (Ed.), Entropy Measures, Maximum\nEntropy and Emerging Applications, 115–136.\n[39] Yao, Y. Y., 2003. Probabilistic approaches to rough sets. Expert Syst. 20 (5), 287–297. [40] Yao, Y. Y., 2004. A partition model of granular computing. Vol. 3100 of Lect. Notes Comput. Sci. Springer, pp. 232–253. [41] Yao, Y. Y., Zhao, L. Q., 2009. Granularity of partitions, (private communication). [42] Yeung, R. W., 2002. A First Course in Information Theory. Information Technology: Transmission, Processing, and Storage. Springer-Verlag,\nNew York, Inc. Secaucus, NJ, USA. [43] Zakowski, W., 1983. Approximations in the space (u, π). Demonstr. Math. 16, 761–769. [44] Zhang, H., Liang, H., Liu, D., 2004. Two new operators in rough set theory with applications to fuzzy sets. Infom. Sci. 166, 147–165. [45] Zhao, Y., Yao, Y. Y., Luo, F., 2007. Data analysis based on discernibility and indiscernibility. Inform. Sci. 177, 4959–4976. [46] Zhong, N., Yao, Y., Ohshima, M., 2003. Peculiarity oriented multidatabase mining. IEEE Trans. Knowl. Data Eng. 15 (4), 952–960. [47] Zhu, P., 2009. An improved axiomatic definition of information granulation. Arxiv preprint arXiv:0908.3999. [48] Zhu, W., 2009. Relationship among basic concepts in covering-based rough sets. Infom. Sci. 179, 2478–2486. [49] Zhu, W., 2009. Relationship between generalized rough sets based on binary relation and covering. Infom. Sci. 179, 210–225. [50] Zhu, W., Wang, F. Y., 2003. Reduction and axiomization of covering generalized rough sets. Inform. Sci. 152, 217–230. [51] Zhu, W., Wang, F. Y., 2006. Covering based granular computing for conflict analysis. Vol. 3975 of Lect. Notes Comput. Sci. pp. 566–571,\nIEEE Int. Conf. Intell. Secur. Inform. (ISI 2006), San Diego, CA, May 23-24, 2006. [52] Zhu, W., Wang, F. Y., AUG 2007. On three types of covering rough sets. IEEE Trans. Knowl. Data Eng. 19 (8), 1131–1144. [53] Ziarko, W. (Ed.), 1994. Rough Sets, Fuzzy Sets, and Knowledge Discovery. Springer-Verlag, Berlin."
    } ],
    "references" : [ {
      "title" : "Rough set algorithms in classification problem. Rough Set Methods and Applications: New Developments in Knowledge Discovery in Information Systems, Studies in Fuzziness and Soft Computing 56",
      "author" : [ "J. Bazan", "H. Nguyen", "S. Nguyen", "P. Synak", "J. Wróblewski" ],
      "venue" : null,
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2000
    }, {
      "title" : "Information-theoretic measures of uncertainty for rough sets and rough relational databases",
      "author" : [ "T. Beaubouef", "F.E. Petry", "G. Arora" ],
      "venue" : "Inform. Sci",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 1998
    }, {
      "title" : "Entropies and co-entropies of coverings with application to incomplete information systems",
      "author" : [ "D. Bianucci", "G. Cattaneo", "D. Ciucci" ],
      "venue" : "Fund. Inform",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2007
    }, {
      "title" : "Extensions and intentions in the rough set theory",
      "author" : [ "Z. Bonikowski", "E. Bryniarski", "U. Wybraniec-Skardowska" ],
      "venue" : "Inform. Sci. 107,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 1998
    }, {
      "title" : "Introductory Combinatorics, 4th Edition",
      "author" : [ "R.A. Brualdi" ],
      "venue" : null,
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2004
    }, {
      "title" : "A calculus of rough sets of the first order",
      "author" : [ "E. Bryniarski" ],
      "venue" : "Bull. Pol. Acad. Sci",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 1989
    }, {
      "title" : "Attribute selection with fuzzy decision reducts",
      "author" : [ "C. Cornelis", "R. Jensen", "G. Hurtado", "D. Ślȩzak" ],
      "venue" : "Inform. Sci",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2010
    }, {
      "title" : "Rough fuzzy sets and fuzzy rough sets",
      "author" : [ "D. Dubois", "H. Prade" ],
      "venue" : "Int. J. Gen. Syst",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 1990
    }, {
      "title" : "Uncertainty measures of rough set prediction",
      "author" : [ "I. Düntsch", "G. Gediga" ],
      "venue" : "Artif. Intell",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 1998
    }, {
      "title" : "Roughian: Rough information analysis",
      "author" : [ "I. Düntsch", "G. Gediga" ],
      "venue" : "Int. J. Intell. Syst",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2001
    }, {
      "title" : "A rough sets approach for personalized support of face recognition",
      "author" : [ "D.H. Hepting", "T. Maciag", "R. Spring", "K. Arbuthnott", "D. Ślȩzak" ],
      "venue" : "Vol. 5908 of Lect. Notes Artif. Intell.,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 2009
    }, {
      "title" : "Fuzzy Sets, Uncertainty, and Information",
      "author" : [ "G.J. Klir", "T.A. Folger" ],
      "venue" : null,
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 1988
    }, {
      "title" : "On a criterion of similarity between partitions based on rough set theory",
      "author" : [ "Y. Kudo", "T. Murai" ],
      "venue" : "Vol. 5908 of Lect. Notes Artif. Intell.,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2009
    }, {
      "title" : "An information-theoretic analysis of relational databases–Part I: Data dependencies and information metric",
      "author" : [ "T.T. Lee" ],
      "venue" : "IEEE Trans. Software Eng",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 1987
    }, {
      "title" : "Information entropy, rough entropy and knowledge granulation in incomplete information systems",
      "author" : [ "J. Liang", "Z. Shi", "D. Li", "M.J. Wierman" ],
      "venue" : "Int. J. Gen. Syst",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2006
    }, {
      "title" : "The information entropy, rough entropy and knowledge granulation in rough set theory",
      "author" : [ "J.Y. Liang", "Z.Z. Shi" ],
      "venue" : "Int. J. Uncert. Fuzz. Knowl. Syst",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2004
    }, {
      "title" : "A new measure of uncertainty based on knowledge granulation for rough sets",
      "author" : [ "J.Y. Liang", "J.H. Wang", "Y.H. Qian" ],
      "venue" : "Inform. Sci",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2009
    }, {
      "title" : "Uncertainty measure of randomness of knowledge and rough sets in incomplete information systems",
      "author" : [ "J.Y. Liang", "Z.B. Xu" ],
      "venue" : "Intell. Contr. Autom",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2000
    }, {
      "title" : "The axiomatization of the rough set upper approximation operations",
      "author" : [ "G. Liu" ],
      "venue" : "Fund. Inform",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 2006
    }, {
      "title" : "The calculation of knowledge granulation and its application (in Chinese)",
      "author" : [ "D.Q. Miao", "S.D. Fan" ],
      "venue" : "Syst. Eng. Theory Pract",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2002
    }, {
      "title" : "Rough Sets: Theoretical Aspects of Reasoning about Data",
      "author" : [ "Z. Pawlak" ],
      "venue" : null,
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 1991
    }, {
      "title" : "Rough sets and boolean reasoning",
      "author" : [ "Z. Pawlak", "A. Skowron" ],
      "venue" : "Infom. Sci",
      "citeRegEx" : "24",
      "shortCiteRegEx" : "24",
      "year" : 2007
    }, {
      "title" : "Rough Sets and Current Trends in Computing",
      "author" : [ "L. Polkowski", "A. Skowron" ],
      "venue" : "Vol. 1424 of Lect. Notes Comput. Sci.,",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 1998
    }, {
      "title" : "Rough Sets in Knowledge Discovery. Vol. 1 and 2",
      "author" : [ "L. Polkowski", "A. Skowron" ],
      "venue" : null,
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 1998
    }, {
      "title" : "Approximation operations in approximation space",
      "author" : [ "J.A. Pomykala" ],
      "venue" : "Bull. Pol. Acad. Sci",
      "citeRegEx" : "28",
      "shortCiteRegEx" : "28",
      "year" : 1987
    }, {
      "title" : "Combination entropy and combination granulation in rough set theory",
      "author" : [ "Y.H. Qian", "J.Y. Liang" ],
      "venue" : "Int. J. Uncert. Fuzz. Knowl. Syst",
      "citeRegEx" : "29",
      "shortCiteRegEx" : "29",
      "year" : 2008
    }, {
      "title" : "An Introduction to Information Theory. Dover Publications, New York, originally published by Mc Graw-Hill",
      "author" : [ "F.M. Reza" ],
      "venue" : "New York,",
      "citeRegEx" : "30",
      "shortCiteRegEx" : "30",
      "year" : 1994
    }, {
      "title" : "The lower system, the upper system and rules with stability factor in non-deterministic information systems",
      "author" : [ "H. Sakai", "K. Hayashi", "M. Nakata", "D. Ślȩzak" ],
      "venue" : "Vol. 5908 of Lect. Notes Artif. Intell.,",
      "citeRegEx" : "31",
      "shortCiteRegEx" : "31",
      "year" : 2009
    }, {
      "title" : "Various approaches to reasoning with frequency based decision reducts: a survey",
      "author" : [ "D. Ślȩzak" ],
      "venue" : null,
      "citeRegEx" : "32",
      "shortCiteRegEx" : "32",
      "year" : 2000
    }, {
      "title" : "Uncertainty measure of rough sets based on a knowledge granulation for incomplete information systems",
      "author" : [ "J. Wang", "J. Liang", "Y. Yian", "C. Dang" ],
      "venue" : "Int. J. Uncert. Fuzz. Knowl. Syst",
      "citeRegEx" : "33",
      "shortCiteRegEx" : "33",
      "year" : 2008
    }, {
      "title" : "Measuring uncertainty in rough set theory",
      "author" : [ "M. Wierman" ],
      "venue" : "Int. J. Gen. Syst",
      "citeRegEx" : "34",
      "shortCiteRegEx" : "34",
      "year" : 1999
    }, {
      "title" : "An improved accuracy measure for rough sets",
      "author" : [ "B.W. Xu", "Y.M. Zhou", "H.M. Lu" ],
      "venue" : "J. Comput. Syst. Sci",
      "citeRegEx" : "35",
      "shortCiteRegEx" : "35",
      "year" : 2005
    }, {
      "title" : "Partition measures for data mining. Advances in Machine Learning I: Dedicated to the Memory of Professor",
      "author" : [ "R.R. Yager" ],
      "venue" : "Ryszard S. Michalski,",
      "citeRegEx" : "36",
      "shortCiteRegEx" : "36",
      "year" : 2010
    }, {
      "title" : "Constructive and algebraic methods of theory of rough sets",
      "author" : [ "Y.Y. Yao" ],
      "venue" : "Infom. Sci",
      "citeRegEx" : "37",
      "shortCiteRegEx" : "37",
      "year" : 1998
    }, {
      "title" : "Information-theoretic measures for knowledge discovery and data mining. in: Karmeshu (Ed.), Entropy Measures",
      "author" : [ "Y.Y. Yao" ],
      "venue" : "Maximum Entropy and Emerging Applications,",
      "citeRegEx" : "38",
      "shortCiteRegEx" : "38",
      "year" : 2003
    }, {
      "title" : "Probabilistic approaches to rough sets",
      "author" : [ "Y.Y. Yao" ],
      "venue" : "Expert Syst",
      "citeRegEx" : "39",
      "shortCiteRegEx" : "39",
      "year" : 2003
    }, {
      "title" : "A partition model of granular computing",
      "author" : [ "Y.Y. Yao" ],
      "venue" : "Vol. 3100 of Lect. Notes Comput. Sci. Springer,",
      "citeRegEx" : "40",
      "shortCiteRegEx" : "40",
      "year" : 2004
    }, {
      "title" : "A First Course in Information Theory. Information Technology: Transmission, Processing, and Storage",
      "author" : [ "R.W. Yeung" ],
      "venue" : null,
      "citeRegEx" : "42",
      "shortCiteRegEx" : "42",
      "year" : 2002
    }, {
      "title" : "Approximations in the space (u, π)",
      "author" : [ "W. Zakowski" ],
      "venue" : "Demonstr. Math",
      "citeRegEx" : "43",
      "shortCiteRegEx" : "43",
      "year" : 1983
    }, {
      "title" : "Two new operators in rough set theory with applications to fuzzy sets",
      "author" : [ "H. Zhang", "H. Liang", "D. Liu" ],
      "venue" : "Infom. Sci",
      "citeRegEx" : "44",
      "shortCiteRegEx" : "44",
      "year" : 2004
    }, {
      "title" : "Data analysis based on discernibility and indiscernibility",
      "author" : [ "Y. Zhao", "Y.Y. Yao", "F. Luo" ],
      "venue" : "Inform. Sci",
      "citeRegEx" : "45",
      "shortCiteRegEx" : "45",
      "year" : 2007
    }, {
      "title" : "Peculiarity oriented multidatabase mining",
      "author" : [ "N. Zhong", "Y. Yao", "M. Ohshima" ],
      "venue" : "IEEE Trans. Knowl. Data Eng",
      "citeRegEx" : "46",
      "shortCiteRegEx" : "46",
      "year" : 2003
    }, {
      "title" : "An improved axiomatic definition of information granulation",
      "author" : [ "P. Zhu" ],
      "venue" : "Arxiv preprint arXiv:0908.3999",
      "citeRegEx" : "47",
      "shortCiteRegEx" : "47",
      "year" : 2009
    }, {
      "title" : "Relationship among basic concepts in covering-based rough sets",
      "author" : [ "W. Zhu" ],
      "venue" : "Infom. Sci",
      "citeRegEx" : "48",
      "shortCiteRegEx" : "48",
      "year" : 2009
    }, {
      "title" : "Relationship between generalized rough sets based on binary relation and covering",
      "author" : [ "W. Zhu" ],
      "venue" : "Infom. Sci",
      "citeRegEx" : "49",
      "shortCiteRegEx" : "49",
      "year" : 2009
    }, {
      "title" : "Reduction and axiomization of covering generalized rough sets",
      "author" : [ "W. Zhu", "F.Y. Wang" ],
      "venue" : "Inform. Sci",
      "citeRegEx" : "50",
      "shortCiteRegEx" : "50",
      "year" : 2003
    }, {
      "title" : "Covering based granular computing for conflict analysis",
      "author" : [ "W. Zhu", "F.Y. Wang" ],
      "venue" : "Vol. 3975 of Lect. Notes Comput. Sci",
      "citeRegEx" : "51",
      "shortCiteRegEx" : "51",
      "year" : 2006
    }, {
      "title" : "On three types of covering rough sets",
      "author" : [ "W. Zhu", "F.Y. Wang" ],
      "venue" : "AUG",
      "citeRegEx" : "52",
      "shortCiteRegEx" : "52",
      "year" : 2007
    }, {
      "title" : "Rough Sets, Fuzzy Sets, and Knowledge Discovery",
      "author" : [ "W. Ziarko" ],
      "venue" : "Springer-Verlag, Berlin",
      "citeRegEx" : "53",
      "shortCiteRegEx" : "53",
      "year" : 1994
    } ],
    "referenceMentions" : [ {
      "referenceID" : 20,
      "context" : "Rough set theory was proposed by Pawlak in the early 1980s [22, 23] as a new mathematical approach for dealing with inexact, uncertain or vague knowledge in information systems.",
      "startOffset" : 59,
      "endOffset" : 67
    }, {
      "referenceID" : 3,
      "context" : "Since then we have witnessed a systematic, world-wide growth of interest in rough set theory [4, 20, 25, 28, 37, 43, 44, 48, 49, 50, 52].",
      "startOffset" : 93,
      "endOffset" : 136
    }, {
      "referenceID" : 18,
      "context" : "Since then we have witnessed a systematic, world-wide growth of interest in rough set theory [4, 20, 25, 28, 37, 43, 44, 48, 49, 50, 52].",
      "startOffset" : 93,
      "endOffset" : 136
    }, {
      "referenceID" : 24,
      "context" : "Since then we have witnessed a systematic, world-wide growth of interest in rough set theory [4, 20, 25, 28, 37, 43, 44, 48, 49, 50, 52].",
      "startOffset" : 93,
      "endOffset" : 136
    }, {
      "referenceID" : 33,
      "context" : "Since then we have witnessed a systematic, world-wide growth of interest in rough set theory [4, 20, 25, 28, 37, 43, 44, 48, 49, 50, 52].",
      "startOffset" : 93,
      "endOffset" : 136
    }, {
      "referenceID" : 38,
      "context" : "Since then we have witnessed a systematic, world-wide growth of interest in rough set theory [4, 20, 25, 28, 37, 43, 44, 48, 49, 50, 52].",
      "startOffset" : 93,
      "endOffset" : 136
    }, {
      "referenceID" : 39,
      "context" : "Since then we have witnessed a systematic, world-wide growth of interest in rough set theory [4, 20, 25, 28, 37, 43, 44, 48, 49, 50, 52].",
      "startOffset" : 93,
      "endOffset" : 136
    }, {
      "referenceID" : 43,
      "context" : "Since then we have witnessed a systematic, world-wide growth of interest in rough set theory [4, 20, 25, 28, 37, 43, 44, 48, 49, 50, 52].",
      "startOffset" : 93,
      "endOffset" : 136
    }, {
      "referenceID" : 44,
      "context" : "Since then we have witnessed a systematic, world-wide growth of interest in rough set theory [4, 20, 25, 28, 37, 43, 44, 48, 49, 50, 52].",
      "startOffset" : 93,
      "endOffset" : 136
    }, {
      "referenceID" : 45,
      "context" : "Since then we have witnessed a systematic, world-wide growth of interest in rough set theory [4, 20, 25, 28, 37, 43, 44, 48, 49, 50, 52].",
      "startOffset" : 93,
      "endOffset" : 136
    }, {
      "referenceID" : 47,
      "context" : "Since then we have witnessed a systematic, world-wide growth of interest in rough set theory [4, 20, 25, 28, 37, 43, 44, 48, 49, 50, 52].",
      "startOffset" : 93,
      "endOffset" : 136
    }, {
      "referenceID" : 22,
      "context" : "Nowadays, it is widely recognized that rough set applications have a great importance in several fields, such as granular computing, data mining, and approximate reasoning [19, 26, 27, 46, 51, 53].",
      "startOffset" : 172,
      "endOffset" : 196
    }, {
      "referenceID" : 23,
      "context" : "Nowadays, it is widely recognized that rough set applications have a great importance in several fields, such as granular computing, data mining, and approximate reasoning [19, 26, 27, 46, 51, 53].",
      "startOffset" : 172,
      "endOffset" : 196
    }, {
      "referenceID" : 41,
      "context" : "Nowadays, it is widely recognized that rough set applications have a great importance in several fields, such as granular computing, data mining, and approximate reasoning [19, 26, 27, 46, 51, 53].",
      "startOffset" : 172,
      "endOffset" : 196
    }, {
      "referenceID" : 46,
      "context" : "Nowadays, it is widely recognized that rough set applications have a great importance in several fields, such as granular computing, data mining, and approximate reasoning [19, 26, 27, 46, 51, 53].",
      "startOffset" : 172,
      "endOffset" : 196
    }, {
      "referenceID" : 48,
      "context" : "Nowadays, it is widely recognized that rough set applications have a great importance in several fields, such as granular computing, data mining, and approximate reasoning [19, 26, 27, 46, 51, 53].",
      "startOffset" : 172,
      "endOffset" : 196
    }, {
      "referenceID" : 20,
      "context" : "Such an indiscernibility relation was first described by equivalence relation in the way that two elements are related by the relation if and only if they are indiscernible from each other [22, 23].",
      "startOffset" : 189,
      "endOffset" : 197
    }, {
      "referenceID" : 20,
      "context" : "In order to measure numerically the accuracy of an approximation, Pawlak introduced two quantitative measures of accuracy and roughness in [23]: The accuracy of a subset is defined as the ratio of the cardinalities of the lower and upper approximations of the subset, which is bounded by 0 and 1; the roughness of a subset is calculated by subtracting the accuracy of the subset from 1.",
      "startOffset" : 139,
      "endOffset" : 143
    }, {
      "referenceID" : 1,
      "context" : "It has been observed [2, 17, 35] that the roughness (and its dual, accuracy) due to Pawlak, however, has the drawback of not being strictly monotonic with respect to the standard ordering on partitions.",
      "startOffset" : 21,
      "endOffset" : 32
    }, {
      "referenceID" : 16,
      "context" : "It has been observed [2, 17, 35] that the roughness (and its dual, accuracy) due to Pawlak, however, has the drawback of not being strictly monotonic with respect to the standard ordering on partitions.",
      "startOffset" : 21,
      "endOffset" : 32
    }, {
      "referenceID" : 31,
      "context" : "It has been observed [2, 17, 35] that the roughness (and its dual, accuracy) due to Pawlak, however, has the drawback of not being strictly monotonic with respect to the standard ordering on partitions.",
      "startOffset" : 21,
      "endOffset" : 32
    }, {
      "referenceID" : 1,
      "context" : "To modify such measures, Beaubouef, Petry, and Arora proposed the notion of rough entropy in [2].",
      "startOffset" : 93,
      "endOffset" : 96
    }, {
      "referenceID" : 31,
      "context" : "This limitation has also been improved by Xu, Zhou, and Lu in [35] by using the so-called excess entropy approach.",
      "startOffset" : 62,
      "endOffset" : 66
    }, {
      "referenceID" : 16,
      "context" : "Most recently, Liang, Wang, and Qian made another improvement by exploiting the notion of knowledge granulation in [17].",
      "startOffset" : 115,
      "endOffset" : 119
    }, {
      "referenceID" : 31,
      "context" : "We first introduce an axiomatic definition of roughness measure by taking into account the common properties of the roughness measures from [35] and [17].",
      "startOffset" : 140,
      "endOffset" : 144
    }, {
      "referenceID" : 16,
      "context" : "We first introduce an axiomatic definition of roughness measure by taking into account the common properties of the roughness measures from [35] and [17].",
      "startOffset" : 149,
      "endOffset" : 153
    }, {
      "referenceID" : 31,
      "context" : "Finally, we show that the existing roughness measures in [35] and [17] are two special instances of our strong Pawlak roughness measure and present three new strong Pawlak roughness measures as well.",
      "startOffset" : 57,
      "endOffset" : 61
    }, {
      "referenceID" : 16,
      "context" : "Finally, we show that the existing roughness measures in [35] and [17] are two special instances of our strong Pawlak roughness measure and present three new strong Pawlak roughness measures as well.",
      "startOffset" : 66,
      "endOffset" : 70
    }, {
      "referenceID" : 20,
      "context" : "4 are devoted to roughness measures proposed by Pawlak [23], Xu et al.",
      "startOffset" : 55,
      "endOffset" : 59
    }, {
      "referenceID" : 31,
      "context" : "[35], and Liang et al.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 16,
      "context" : "[17], respectively.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 20,
      "context" : "Rough sets We start by recalling some basic notions in Pawlak’s rough set theory [22, 23].",
      "startOffset" : 81,
      "endOffset" : 89
    }, {
      "referenceID" : 20,
      "context" : "To characterize the uncertainty of rough sets, Pawlak proposed two numerical measures: roughness and accuracy (see, for example, [23]).",
      "startOffset" : 129,
      "endOffset" : 133
    }, {
      "referenceID" : 1,
      "context" : "This limitation has been pointed out by several researchers [2, 17, 35].",
      "startOffset" : 60,
      "endOffset" : 71
    }, {
      "referenceID" : 16,
      "context" : "This limitation has been pointed out by several researchers [2, 17, 35].",
      "startOffset" : 60,
      "endOffset" : 71
    }, {
      "referenceID" : 31,
      "context" : "This limitation has been pointed out by several researchers [2, 17, 35].",
      "startOffset" : 60,
      "endOffset" : 71
    }, {
      "referenceID" : 31,
      "context" : "[35] combined the granularity of the underlying partition into Pawlak’s accuracy by exploiting the so-called equivalence relation graphs.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 31,
      "context" : "Finally, we may state the key definition and results in [35] as follows.",
      "startOffset" : 56,
      "endOffset" : 60
    }, {
      "referenceID" : 31,
      "context" : "It follows from [35] that the new roughness measure βX(π, A) enjoys some useful properties, which are listed as follows.",
      "startOffset" : 16,
      "endOffset" : 20
    }, {
      "referenceID" : 19,
      "context" : "Based on the notion of knowledge granulation due to Miao and Fan [21], Liang et al.",
      "startOffset" : 65,
      "endOffset" : 69
    }, {
      "referenceID" : 16,
      "context" : "proposed a roughness measure [17] which is simpler than that in [35].",
      "startOffset" : 29,
      "endOffset" : 33
    }, {
      "referenceID" : 31,
      "context" : "proposed a roughness measure [17] which is simpler than that in [35].",
      "startOffset" : 64,
      "endOffset" : 68
    }, {
      "referenceID" : 19,
      "context" : "where βP(π, A) = 1 − |π∗(A)|/|π(A)| is the Pawlak’s roughness of A and the second term ∑m i=1 |Ci | 2 |U|2 represents the knowledge granulation of π introduced in [21].",
      "startOffset" : 163,
      "endOffset" : 167
    }, {
      "referenceID" : 16,
      "context" : "The following properties of the roughness measure βL(π, A) were given in [17].",
      "startOffset" : 73,
      "endOffset" : 77
    }, {
      "referenceID" : 16,
      "context" : "Motivated by the roughness measures in [17, 35], we present an axiomatic definition of roughness measure and discuss its basic properties in Section 3.",
      "startOffset" : 39,
      "endOffset" : 47
    }, {
      "referenceID" : 31,
      "context" : "Motivated by the roughness measures in [17, 35], we present an axiomatic definition of roughness measure and discuss its basic properties in Section 3.",
      "startOffset" : 39,
      "endOffset" : 47
    }, {
      "referenceID" : 0,
      "context" : "Let U be a finite and nonempty universal set and β a mapping from Π(U) × P(U) to the closed unit interval [0, 1].",
      "startOffset" : 106,
      "endOffset" : 112
    }, {
      "referenceID" : 0,
      "context" : "Consider β : Π(U) × P(U) −→ [0, 1] defined as follows:",
      "startOffset" : 28,
      "endOffset" : 34
    }, {
      "referenceID" : 6,
      "context" : "Actually, the cases when the measure does not change while changing the partition into a more or less detailed one are of special importance for feature selection, feature subset selection, feature extraction, and feature reduction in knowledge discovery (see, for example, [7, 11, 31]).",
      "startOffset" : 274,
      "endOffset" : 285
    }, {
      "referenceID" : 10,
      "context" : "Actually, the cases when the measure does not change while changing the partition into a more or less detailed one are of special importance for feature selection, feature subset selection, feature extraction, and feature reduction in knowledge discovery (see, for example, [7, 11, 31]).",
      "startOffset" : 274,
      "endOffset" : 285
    }, {
      "referenceID" : 27,
      "context" : "Actually, the cases when the measure does not change while changing the partition into a more or less detailed one are of special importance for feature selection, feature subset selection, feature extraction, and feature reduction in knowledge discovery (see, for example, [7, 11, 31]).",
      "startOffset" : 274,
      "endOffset" : 285
    }, {
      "referenceID" : 0,
      "context" : "Let U be a finite and nonempty universal set and β a mapping from Π(U) × P(U) to the closed unit interval [0, 1].",
      "startOffset" : 106,
      "endOffset" : 112
    }, {
      "referenceID" : 4,
      "context" : "Bk and B0 = 1 (see, for example, [5]).",
      "startOffset" : 33,
      "endOffset" : 36
    }, {
      "referenceID" : 0,
      "context" : "It should be stressed that constructing and evaluating partitions are the most basic issues in rough set theory, since the indiscernibility is the mathematical basis of rough set theory [25] and there are strong relationships between indiscernibility measures and partition measures [1, 21, 32, 39, 40, 45].",
      "startOffset" : 283,
      "endOffset" : 306
    }, {
      "referenceID" : 19,
      "context" : "It should be stressed that constructing and evaluating partitions are the most basic issues in rough set theory, since the indiscernibility is the mathematical basis of rough set theory [25] and there are strong relationships between indiscernibility measures and partition measures [1, 21, 32, 39, 40, 45].",
      "startOffset" : 283,
      "endOffset" : 306
    }, {
      "referenceID" : 28,
      "context" : "It should be stressed that constructing and evaluating partitions are the most basic issues in rough set theory, since the indiscernibility is the mathematical basis of rough set theory [25] and there are strong relationships between indiscernibility measures and partition measures [1, 21, 32, 39, 40, 45].",
      "startOffset" : 283,
      "endOffset" : 306
    }, {
      "referenceID" : 35,
      "context" : "It should be stressed that constructing and evaluating partitions are the most basic issues in rough set theory, since the indiscernibility is the mathematical basis of rough set theory [25] and there are strong relationships between indiscernibility measures and partition measures [1, 21, 32, 39, 40, 45].",
      "startOffset" : 283,
      "endOffset" : 306
    }, {
      "referenceID" : 36,
      "context" : "It should be stressed that constructing and evaluating partitions are the most basic issues in rough set theory, since the indiscernibility is the mathematical basis of rough set theory [25] and there are strong relationships between indiscernibility measures and partition measures [1, 21, 32, 39, 40, 45].",
      "startOffset" : 283,
      "endOffset" : 306
    }, {
      "referenceID" : 40,
      "context" : "It should be stressed that constructing and evaluating partitions are the most basic issues in rough set theory, since the indiscernibility is the mathematical basis of rough set theory [25] and there are strong relationships between indiscernibility measures and partition measures [1, 21, 32, 39, 40, 45].",
      "startOffset" : 283,
      "endOffset" : 306
    }, {
      "referenceID" : 1,
      "context" : "In the literature, there are a large number of approaches to measuring partitions (see, for example, [2, 9, 10, 12, 13, 14, 15, 16, 17, 18, 24, 25, 29, 33, 34, 36, 38, 39, 42, 47]).",
      "startOffset" : 101,
      "endOffset" : 179
    }, {
      "referenceID" : 8,
      "context" : "In the literature, there are a large number of approaches to measuring partitions (see, for example, [2, 9, 10, 12, 13, 14, 15, 16, 17, 18, 24, 25, 29, 33, 34, 36, 38, 39, 42, 47]).",
      "startOffset" : 101,
      "endOffset" : 179
    }, {
      "referenceID" : 9,
      "context" : "In the literature, there are a large number of approaches to measuring partitions (see, for example, [2, 9, 10, 12, 13, 14, 15, 16, 17, 18, 24, 25, 29, 33, 34, 36, 38, 39, 42, 47]).",
      "startOffset" : 101,
      "endOffset" : 179
    }, {
      "referenceID" : 11,
      "context" : "In the literature, there are a large number of approaches to measuring partitions (see, for example, [2, 9, 10, 12, 13, 14, 15, 16, 17, 18, 24, 25, 29, 33, 34, 36, 38, 39, 42, 47]).",
      "startOffset" : 101,
      "endOffset" : 179
    }, {
      "referenceID" : 12,
      "context" : "In the literature, there are a large number of approaches to measuring partitions (see, for example, [2, 9, 10, 12, 13, 14, 15, 16, 17, 18, 24, 25, 29, 33, 34, 36, 38, 39, 42, 47]).",
      "startOffset" : 101,
      "endOffset" : 179
    }, {
      "referenceID" : 13,
      "context" : "In the literature, there are a large number of approaches to measuring partitions (see, for example, [2, 9, 10, 12, 13, 14, 15, 16, 17, 18, 24, 25, 29, 33, 34, 36, 38, 39, 42, 47]).",
      "startOffset" : 101,
      "endOffset" : 179
    }, {
      "referenceID" : 14,
      "context" : "In the literature, there are a large number of approaches to measuring partitions (see, for example, [2, 9, 10, 12, 13, 14, 15, 16, 17, 18, 24, 25, 29, 33, 34, 36, 38, 39, 42, 47]).",
      "startOffset" : 101,
      "endOffset" : 179
    }, {
      "referenceID" : 15,
      "context" : "In the literature, there are a large number of approaches to measuring partitions (see, for example, [2, 9, 10, 12, 13, 14, 15, 16, 17, 18, 24, 25, 29, 33, 34, 36, 38, 39, 42, 47]).",
      "startOffset" : 101,
      "endOffset" : 179
    }, {
      "referenceID" : 16,
      "context" : "In the literature, there are a large number of approaches to measuring partitions (see, for example, [2, 9, 10, 12, 13, 14, 15, 16, 17, 18, 24, 25, 29, 33, 34, 36, 38, 39, 42, 47]).",
      "startOffset" : 101,
      "endOffset" : 179
    }, {
      "referenceID" : 17,
      "context" : "In the literature, there are a large number of approaches to measuring partitions (see, for example, [2, 9, 10, 12, 13, 14, 15, 16, 17, 18, 24, 25, 29, 33, 34, 36, 38, 39, 42, 47]).",
      "startOffset" : 101,
      "endOffset" : 179
    }, {
      "referenceID" : 21,
      "context" : "In the literature, there are a large number of approaches to measuring partitions (see, for example, [2, 9, 10, 12, 13, 14, 15, 16, 17, 18, 24, 25, 29, 33, 34, 36, 38, 39, 42, 47]).",
      "startOffset" : 101,
      "endOffset" : 179
    }, {
      "referenceID" : 25,
      "context" : "In the literature, there are a large number of approaches to measuring partitions (see, for example, [2, 9, 10, 12, 13, 14, 15, 16, 17, 18, 24, 25, 29, 33, 34, 36, 38, 39, 42, 47]).",
      "startOffset" : 101,
      "endOffset" : 179
    }, {
      "referenceID" : 29,
      "context" : "In the literature, there are a large number of approaches to measuring partitions (see, for example, [2, 9, 10, 12, 13, 14, 15, 16, 17, 18, 24, 25, 29, 33, 34, 36, 38, 39, 42, 47]).",
      "startOffset" : 101,
      "endOffset" : 179
    }, {
      "referenceID" : 30,
      "context" : "In the literature, there are a large number of approaches to measuring partitions (see, for example, [2, 9, 10, 12, 13, 14, 15, 16, 17, 18, 24, 25, 29, 33, 34, 36, 38, 39, 42, 47]).",
      "startOffset" : 101,
      "endOffset" : 179
    }, {
      "referenceID" : 32,
      "context" : "In the literature, there are a large number of approaches to measuring partitions (see, for example, [2, 9, 10, 12, 13, 14, 15, 16, 17, 18, 24, 25, 29, 33, 34, 36, 38, 39, 42, 47]).",
      "startOffset" : 101,
      "endOffset" : 179
    }, {
      "referenceID" : 34,
      "context" : "In the literature, there are a large number of approaches to measuring partitions (see, for example, [2, 9, 10, 12, 13, 14, 15, 16, 17, 18, 24, 25, 29, 33, 34, 36, 38, 39, 42, 47]).",
      "startOffset" : 101,
      "endOffset" : 179
    }, {
      "referenceID" : 35,
      "context" : "In the literature, there are a large number of approaches to measuring partitions (see, for example, [2, 9, 10, 12, 13, 14, 15, 16, 17, 18, 24, 25, 29, 33, 34, 36, 38, 39, 42, 47]).",
      "startOffset" : 101,
      "endOffset" : 179
    }, {
      "referenceID" : 37,
      "context" : "In the literature, there are a large number of approaches to measuring partitions (see, for example, [2, 9, 10, 12, 13, 14, 15, 16, 17, 18, 24, 25, 29, 33, 34, 36, 38, 39, 42, 47]).",
      "startOffset" : 101,
      "endOffset" : 179
    }, {
      "referenceID" : 42,
      "context" : "In the literature, there are a large number of approaches to measuring partitions (see, for example, [2, 9, 10, 12, 13, 14, 15, 16, 17, 18, 24, 25, 29, 33, 34, 36, 38, 39, 42, 47]).",
      "startOffset" : 101,
      "endOffset" : 179
    }, {
      "referenceID" : 0,
      "context" : "Then the function βh : Π(U) × P(U) −→ [0, 1] defined by",
      "startOffset" : 38,
      "endOffset" : 44
    }, {
      "referenceID" : 31,
      "context" : "[35] and Liang et al.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 16,
      "context" : "[17], respectively, in the framework of strong Pawlak roughness measures, and then provide three new strong Pawlak roughness measures.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 31,
      "context" : "It follows from Theorem 7 in [35] that h satisfies the condition 1) in Definition 4, that is, π ≺ σ implies h(π) < h(σ).",
      "startOffset" : 29,
      "endOffset" : 33
    }, {
      "referenceID" : 31,
      "context" : "Propositions 9 and 10 tell us that the roughness measures βX and βL have the properties stated in Corollary 3 and Propositions 5, 6, 7, and 8; some of these properties are missing in [35] or [17].",
      "startOffset" : 183,
      "endOffset" : 187
    }, {
      "referenceID" : 16,
      "context" : "Propositions 9 and 10 tell us that the roughness measures βX and βL have the properties stated in Corollary 3 and Propositions 5, 6, 7, and 8; some of these properties are missing in [35] or [17].",
      "startOffset" : 191,
      "endOffset" : 195
    }, {
      "referenceID" : 1,
      "context" : "To introduce another strong Pawlak roughness measure, let us recall the notion of co-entropy [2, 15, 16, 18, 39].",
      "startOffset" : 93,
      "endOffset" : 112
    }, {
      "referenceID" : 14,
      "context" : "To introduce another strong Pawlak roughness measure, let us recall the notion of co-entropy [2, 15, 16, 18, 39].",
      "startOffset" : 93,
      "endOffset" : 112
    }, {
      "referenceID" : 15,
      "context" : "To introduce another strong Pawlak roughness measure, let us recall the notion of co-entropy [2, 15, 16, 18, 39].",
      "startOffset" : 93,
      "endOffset" : 112
    }, {
      "referenceID" : 17,
      "context" : "To introduce another strong Pawlak roughness measure, let us recall the notion of co-entropy [2, 15, 16, 18, 39].",
      "startOffset" : 93,
      "endOffset" : 112
    }, {
      "referenceID" : 35,
      "context" : "To introduce another strong Pawlak roughness measure, let us recall the notion of co-entropy [2, 15, 16, 18, 39].",
      "startOffset" : 93,
      "endOffset" : 112
    }, {
      "referenceID" : 14,
      "context" : "where H(π) is the entropy of partition π [15, 16, 30, 34, 39] defined as",
      "startOffset" : 41,
      "endOffset" : 61
    }, {
      "referenceID" : 15,
      "context" : "where H(π) is the entropy of partition π [15, 16, 30, 34, 39] defined as",
      "startOffset" : 41,
      "endOffset" : 61
    }, {
      "referenceID" : 26,
      "context" : "where H(π) is the entropy of partition π [15, 16, 30, 34, 39] defined as",
      "startOffset" : 41,
      "endOffset" : 61
    }, {
      "referenceID" : 30,
      "context" : "where H(π) is the entropy of partition π [15, 16, 30, 34, 39] defined as",
      "startOffset" : 41,
      "endOffset" : 61
    }, {
      "referenceID" : 35,
      "context" : "where H(π) is the entropy of partition π [15, 16, 30, 34, 39] defined as",
      "startOffset" : 41,
      "endOffset" : 61
    }, {
      "referenceID" : 26,
      "context" : "Notice that a standard result of information theory assures the strict anti-monotonicity of entropy (see, for example, [30]): if π ≺ σ, then H(σ) < H(π).",
      "startOffset" : 119,
      "endOffset" : 123
    }, {
      "referenceID" : 15,
      "context" : "Therefore, we have the following strict monotonicity of co-entropy with respect to the partition ordering (a direct proof of this result can be found in [16]):",
      "startOffset" : 153,
      "endOffset" : 157
    }, {
      "referenceID" : 30,
      "context" : "This result has been proven in a roughness monotonicity theorem of [34], which is based on a lemma of the same paper.",
      "startOffset" : 67,
      "endOffset" : 71
    }, {
      "referenceID" : 1,
      "context" : "Let us remark that βP(π, A) · E(π) was defined as the rough entropy of A in [2].",
      "startOffset" : 76,
      "endOffset" : 79
    }, {
      "referenceID" : 2,
      "context" : "In [3], Bianucci et al.",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 2,
      "context" : "It has been proven in [3] that if π ≺ σ, then E(π) < E(σ).",
      "startOffset" : 22,
      "endOffset" : 25
    }, {
      "referenceID" : 25,
      "context" : "We end this section with one more strong Pawlak roughness measure arising from the concept of combination granulation introduced by Qian and Liang in [29].",
      "startOffset" : 150,
      "endOffset" : 154
    }, {
      "referenceID" : 25,
      "context" : "Then the combination granulation of π, denoted by CG(π), is defined as [29]",
      "startOffset" : 71,
      "endOffset" : 75
    }, {
      "referenceID" : 25,
      "context" : "It has been shown by Proposition 9 in [29] that",
      "startOffset" : 38,
      "endOffset" : 42
    }, {
      "referenceID" : 31,
      "context" : "In addition, we have shown that the existing roughness measures in [35] and [17] are two special instances of our strong Pawlak roughness measure, which supports our axiomatic definitions.",
      "startOffset" : 67,
      "endOffset" : 71
    }, {
      "referenceID" : 16,
      "context" : "In addition, we have shown that the existing roughness measures in [35] and [17] are two special instances of our strong Pawlak roughness measure, which supports our axiomatic definitions.",
      "startOffset" : 76,
      "endOffset" : 80
    }, {
      "referenceID" : 5,
      "context" : "It would be interesting to examine our axiomatic approach in the framework of covering rough sets [6, 28, 43] or fuzzy rough sets [8].",
      "startOffset" : 98,
      "endOffset" : 109
    }, {
      "referenceID" : 24,
      "context" : "It would be interesting to examine our axiomatic approach in the framework of covering rough sets [6, 28, 43] or fuzzy rough sets [8].",
      "startOffset" : 98,
      "endOffset" : 109
    }, {
      "referenceID" : 38,
      "context" : "It would be interesting to examine our axiomatic approach in the framework of covering rough sets [6, 28, 43] or fuzzy rough sets [8].",
      "startOffset" : 98,
      "endOffset" : 109
    }, {
      "referenceID" : 7,
      "context" : "It would be interesting to examine our axiomatic approach in the framework of covering rough sets [6, 28, 43] or fuzzy rough sets [8].",
      "startOffset" : 130,
      "endOffset" : 133
    }, {
      "referenceID" : 0,
      "context" : "[1] Bazan, J.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 1,
      "context" : "[2] Beaubouef, T.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 2,
      "context" : "[3] Bianucci, D.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 3,
      "context" : "[4] Bonikowski, Z.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 4,
      "context" : "[5] Brualdi, R.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 5,
      "context" : "[6] Bryniarski, E.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 6,
      "context" : "[7] Cornelis, C.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 7,
      "context" : "[8] Dubois, D.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 8,
      "context" : "[9] Düntsch, I.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 9,
      "context" : "[10] Düntsch, I.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 10,
      "context" : "[11] Hepting, D.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 11,
      "context" : "[12] Klir, G.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 12,
      "context" : "[13] Kudo, Y.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 13,
      "context" : "[14] Lee, T.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 14,
      "context" : "[15] Liang, J.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 15,
      "context" : "[16] Liang, J.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 16,
      "context" : "[17] Liang, J.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 17,
      "context" : "[18] Liang, J.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 18,
      "context" : "[20] Liu, G.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 19,
      "context" : "[21] Miao, D.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 20,
      "context" : "[23] Pawlak, Z.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 21,
      "context" : "[24] Pawlak, Z.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 22,
      "context" : "[26] Polkowski, L.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 23,
      "context" : "[27] Polkowski, L.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 24,
      "context" : "[28] Pomykala, J.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 25,
      "context" : "[29] Qian, Y.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 26,
      "context" : "[30] Reza, F.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 27,
      "context" : "[31] Sakai, H.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 28,
      "context" : "[32] Ślȩzak, D.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 29,
      "context" : "[33] Wang, J.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 30,
      "context" : "[34] Wierman, M.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 31,
      "context" : "[35] Xu, B.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 32,
      "context" : "[36] Yager, R.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 33,
      "context" : "[37] Yao, Y.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 34,
      "context" : "[38] Yao, Y.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 35,
      "context" : "[39] Yao, Y.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 36,
      "context" : "[40] Yao, Y.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 37,
      "context" : "[42] Yeung, R.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 38,
      "context" : "[43] Zakowski, W.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 39,
      "context" : "[44] Zhang, H.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 40,
      "context" : "[45] Zhao, Y.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 41,
      "context" : "[46] Zhong, N.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 42,
      "context" : "[47] Zhu, P.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 43,
      "context" : "[48] Zhu, W.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 44,
      "context" : "[49] Zhu, W.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 45,
      "context" : "[50] Zhu, W.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 46,
      "context" : "[51] Zhu, W.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 47,
      "context" : "[52] Zhu, W.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 48,
      "context" : "[53] Ziarko, W.",
      "startOffset" : 0,
      "endOffset" : 4
    } ],
    "year" : 2010,
    "abstractText" : "In Pawlak’s rough set theory, a set is approximated by a pair of lower and upper approximations. To measure numerically the roughness of an approximation, Pawlak introduced a quantitative measure of roughness by using the ratio of the cardinalities of the lower and upper approximations. Although the roughness measure is effective, it has the drawback of not being strictly monotonic with respect to the standard ordering on partitions. Recently, some improvements have been made by taking into account the granularity of partitions. In this paper, we approach the roughness measure in an axiomatic way. After axiomatically defining roughness measure and partition measure, we provide a unified construction of roughness measure, called strong Pawlak roughness measure, and then explore the properties of this measure. We show that the improved roughness measures in the literature are special instances of our strong Pawlak roughness measure and introduce three more strong Pawlak roughness measures as well. The advantage of our axiomatic approach is that some properties of a roughness measure follow immediately as soon as the measure satisfies the relevant axiomatic definition.",
    "creator" : "LaTeX with hyperref package"
  }
}