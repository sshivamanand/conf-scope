{
  "name" : "1106.1853.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "פ Algorithm: its past present, futue present and comments",
    "authors" : [ "Ching-an Hsiao", "Xinchun Tian" ],
    "emails" : [ "xiao.qingan@nies.go.jp", "tianxc@fnal.gov" ],
    "sections" : [ {
      "heading" : null,
      "text" : "The human intelligence lies in the algorithm, the nature of algorithms lies in the classification, and the classification is equal to outlier detection. This paper is based on its past unpublished edition (2009), which discussed an application of פ (pe) algorithm in outlier detection for time series data. The פ algorithm, also named as RDD algorithm, is originated from the study on general AI. United with it, designed modules can be used to realize kinds of tasks. A primary framework concerned with the mind through פ algorithm has been constructed in prior works. In this concise paper, we neglect background and minor description of the early edition, and directly discuss the main contents include longest k–turn subsequence problem, curve type outliers, futural directions and related comments. In section “Past Present”, we keep all prior conclusions, though a little might be out of date."
    }, {
      "heading" : "I. Past Present",
      "text" : ""
    }, {
      "heading" : "1. Relative deviation degree",
      "text" : "A supplementary definition for outlier (Hsiao et al., 2008)\nDefinition 1: An outlier is an observation with a degree greater than a threshold in comparison\nwith other observations referred to or associated with one or more specified pattern.\nProblem 1: Given a time series data S1 as Fig. 1, suppose data match linear model, find out outliers. S1 = (3.1, 2.9, 2.85, 3, 3.05, 2.9, 3.2, 5.2, 8.5, 5.4, 5.3, 5.1, 3.1, 3.05, 3, 2.99, 3, 3.02, 3.2)\nFig.1. Regression lines for dataset S1\n0\n2\n4\n6\n8\n10\n0 2 4 6 8 10 12 14 16 18 20\ndata LS LTS\nBy classic LS regression, we get a line y=3.79-0.001x; and by robust LTS regression, line\ny=2.907+0.007x, as shown in Fig. 1. Based on the above definition, we present RDD (פ) algorithm.\nGiven a time series data S = d1d2……dN, denote point (i,di) by pi, and  pjpipk by  jik.\nRelative Deviant Degree: Algorithm 1 Input: time series data S Output: RDDs of S\n• Specify a similarity function sim(pk,(pi,pj))=exp(- jik^2/50), denoted by ij ks .\n• Specify an offset function off(pk,(pi,pj)): distance of k to line Lij, denoted by ij ko .\nfor ( i from 1 to N ) {\n   \n N\nip p\nN\nk\nip\nki sX 1 1\n   \n N\nip p\nN\nk\npi\nki sY 1 1\n}\nfor( i, j from 1 to N, j ≠ i )\nwij = Xi  Yj\n\n\n\n\n\n\n\n\n\n\n\n N\nji\nij\nN\nji\nij\nij k\nN\nji\nij\nN\nji\nij\nij k\nk\nw\nwo\nw\nws\nRDD\n1,\n1,\n1,\n1,\n)()(\nln\nNotes\n1. Similarity function is used to evaluate the similar degree of point k related to the system of i\nand j.\n2. Offset function calculates the real distance between k and system of i and j. 3. wij is the weight of system of ij, denotes relative effective degree. 4. Relative deviant degree combines two measurements: similarity and real distance.\nBy this algorithm, to problem 1 we get RDD values in Table 1. Points at position 8, 9, 10, 11 and 12 have high values.\nThough the פ algorithm, similar with robust regressions, tries to evaluate others by choosing reliable “good” data, it differs from robust ones at the point that we approach the problem from the inside structure of patterns and stress on a whole effect, thus with better balance. Note that the פ algorithm is with a highest breakdown point (50%) as same as the robust regressions. Now we modify our algorithm 1 to a general form. First, we introduce the definition of view.\nDefinition 2: Given a time series data S, a sub-series of S is also a time series where each element of it is an element of S. We denote e  S when e is a sub-series of S.\nDefinition 3: A view of S, Vα, is a set of sub-series of S of the same length  , that is Vα = { e | e S, |e| =  }.\nAlgorithm 1’: פ Algorithm\nInput: data set S Output: RDDs of S\n1. Let Vα be an evaluating view, e  Vα 2. Give a similarity function sim: S×S α  [0,1], describing similar degree of each\nelement k in S by the view of Vα, denoted by\n3. Give an offset function off: S×S α  , describing offset of each element k in S by\nthe view of Vα, denoted by\n4. Define different weight we and RDDk by and 5. For any element e in Vα\n\n0 R\ne\nkoff\ne ksim\ne ksim e koff\ncalculate we\n6. Calculate RDDk"
    }, {
      "heading" : "2. Longest k –turn subsequence",
      "text" : "In this section, we present an expression for pattern “curve” so that we can get a kind of view for פ\nalgorithm. Outlier problem of time series data can be described as follows.\nProblem 2: Given a sequence S of length N, {d1, d2, … dN }, which matches pattern “curve”, find outliers. An example is shown in Fig. 2.\nAs any curve can be expressed by several ordered sets hinged by several common points (turn points), we develop a dynamic programming algorithm to detect the order of curve type data, which can be traced to the longest increasing subsequence problem (Schensted, 1961). Firstly, we give a definition to “turn”.\nDefinition 4: Given a curve, except for boundary points, each extremum point is called a “turn point”; the number of extremum points is called turns. We denote maximum point by sign “＋”, and minimum point by sign “－ ”. If a sequence S has t turns and the 1st one is a maximum/minimum points, then it is denoted by [＋/－, t ]. [＋, 0 ] denotes strictly increasing sequence, [－, 0 ] denotes strictly decreasing sequence.\nWe then introduce longest k-turn subsequence problem followed by the corresponding algorithm.\nProblem 3: Given a time series data S of length N, {d0, d1, …, dN-1 }, with T turns, searching a longest subsequence having T turns by passing the first point p0 (0, d0).\nAlgorithm 2: The pseudo-code is shown below.\nDenote best + [i][t], the longest subsequence from point p0 to point pi with [＋, t ] best －\n[i][t], the longest subsequence from point p0 to point pi with [－, t ]\nP + [i][t], predecessor point of pi in best + [i][t] P － [i][t], predecessor point of pi in best － [i][t]\nInput: time series data S Output: the longest T-turn subsequence starting from point p0.\nFunc route(S )\nInitialize best to {} for (t from 0 to T )\nfor (i from t +1 to N-1 )\nfor( j from t to i -1) {\nif(t==0&&j==0) { if(d[i]> d[j]) best + [i][t]={j, i}\nif(d[i]< d[j]) best － [i][t]={j, i} }\nif (d[i], d[j], d[P + [j][t]] is a strictly monotonic sequence)\nbest + [i][t]=max(best + [i][t], best + [j][t] {i})\nif (d[i], d[j], d[P + [j][t-1]] is not a monotonic sequence)\nbest + [i][t]=max(best + [i][t], best + [j][t-1] {i})\nif (d[i], d[j], d[P － [j][t]] is a strictly monotonic sequence)\nbest － [i][t]=max(best － [i][t], best － [j][t] {i})\nif (d[i], d[j], d[P － [j][t-1]] is not a monotonic sequence)\nbest － [i][t]=max(best － [i][t], best － [j][t-1] {i})\n}\nbest + [][T] = max(best + [i][T]) i=0,1,…, N-1 best － [][T] = max(best － [i][T]) i=0,1,…, N-1 Return max (best + [][T] , best － [][T] )\nAlgorithm 3 returns the longest T-turn subsequence by passing any point pi (i,di).\nAlgorithm 3:\nInput: time series data S Output: the longest T-turn subsequence by passing point pi.\n1. Divide the whole series data into two parts, S1: di, di-1,… d0; and S2: di, di+1,di+2, …, dN-1. 2. Work out best1 + [][t] and best1 － [][t] in S1 on each t ≤ T 3. Work out best2 + [][t] and best2 － [][t ]in S2 on each t ≤ T 4. Combine them to identify the longest best + [][T] and best － [][T]\nReturn max(best + [][T], best － [][T] )"
    }, {
      "heading" : "3. Time series data outlier",
      "text" : "Following algorithm calculates the related RDD values for time series data.\nAlgorithm 4:\nDenote point(i, di) by pi, i=0, 1, …, N-1 Specify a curve pattern [sign, T] Specify view: a curve with [sign, T] passing pi, Denote similarity function by , offset function by k=0, 1, …, N-1\nInput: time series data S Output: RDDs of S\n1. To any pi , work out a subsequence P(S)i with T turns and maximum length by algorithm 3. 2. If P(S)i does not match pattern [sign, T]\n{\nLet = 0, = 0 (k ≠ i)\n=1, = 0\n}\nElse\n{ if pk  P(S)i\n{ = 1, = 0 }\nelse\n{\ncalculate interpolation value of pk according to P(S)i, get vk. let = ∣vk －dk ∣ , let max=max(di) , min=min(di) i=0, 1, 2, …, N-1 let coef=(max-min)/N normalize di, dk and vk by\n'\nid = (di -min) /coef\n'\nkd = (dk -min) /coef\n'\nkv = (vk -min) /coef\ndenote (i, ' id ) by pi’, (k, ' kd ) by pk’ and (k, ' kv ) by pj’\ni ksim i koff\ni ksim i\nkoff i\nisim i ioff\ni koff\ni koff i ksim\ncalculating angle  pk’ pi’ pj’ denoted by  j’i’k’\n= exp (- j’i’k’^2/50)\n}\n}\n3. Calculate RDDk by פ algorithm\nwith weight wi =\nand\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n 1\n0\n1\n0\n1\n0\n1\n0\n)()(\nln N\ni\ni\nN\ni\ni\ni\nk\nN\ni\ni\nN\ni\ni\ni k\nk\nw\nwoff\nw\nwsim\nRDD\n4. Output outliers by Expanding Algorithm [Hsiao, 2010]\nNote: To any series sets, since outliers deviate from others, they may disturb some order of the sets. So we can use order or orders to descript the pattern. Definition 2 and corresponding algorithms hold true to any orders."
    }, {
      "heading" : "4. Experiments and Discussion",
      "text" : "Following experiments are based on the Algorithm 4. Original sine data are got from function )472sin( xy  , x is an integer in [0,47]. Outlier patches are introduced, size -1 to the x index 7, 8, 9, 10, and size +2 to the x index 28, 29, 30, 31, 32. Result is shown in Fig. 2. Table 2 lists corresponding RDD values of the related points. The first point whose IIR value is greater than 1.81\nFig.2. Synthetic data\n-1.5\n-1\n-0.5\n0\n0.5\n1\n1.5\n2\n0 10 20 30 40 50 60\nsi n e - o u tl ie r\n0\n2\n4\n6\n8\n10\n12\nR D D\nsin-outlier RDD\ni ksim\n \n\n1\n0\nN\nk\ni ksim\nis the 10 th point (calculating from 1), so all points above 10 (whose RDD values are not less than that of the10th) are confirmed as outliers. We see all outliers are correctly detected. T is equal to 2 here."
    }, {
      "heading" : "1 29 11.6 -23.1 35 6715 -15.4",
      "text" : ""
    }, {
      "heading" : "2 33 11.6 -22.8 42 6425 -16.4",
      "text" : ""
    }, {
      "heading" : "3 30 11.5 -23.1 34 6275 4.0",
      "text" : ""
    }, {
      "heading" : "4 32 11.5 -23.1 44 3782 -10.1",
      "text" : ""
    }, {
      "heading" : "5 31 11.4 0.76 36 3304 -11.5",
      "text" : ""
    }, {
      "heading" : "6 8 5.7 -22.3 43 3025 -9.6",
      "text" : ""
    }, {
      "heading" : "7 11 5.6 -22.3 19 2480 11.7",
      "text" : ""
    }, {
      "heading" : "8 9 5.6 -22.5 30 557 0.7",
      "text" : ""
    }, {
      "heading" : "9 10 5.6 22.5 47 304 0.8",
      "text" : ""
    }, {
      "heading" : "10 48 0 0 4 149 -0.2",
      "text" : "are listed in Fig. 3, Fig. 4, and Fig. 5. One is CO2 flux data, one is sensible heat flux data, and the other is latent heat flux data. Both achieved from Yucheng station, China.\nIn Fig. 3 and Fig. 4, apparent outliers (19, 34, 35, 36, 42, 43, 44 in Fig. 3 and 9,12,24,25 in Fig.\n4) are detected rightly. But point 30 in Fig. 3 and point 11 in Fig. 4 seem to be missed, though their RDD values are the closest ones to detected outliers (19 in Table 2 and 12 in Table 3). Did the algorithm fail? Actually, it would rather be said the two points do not appear so outstanding of the whole associated with the “pattern” we used than they are falsely undetected. And from following examples, we will see even in some hard cases our algorithm can work. It is undoubtedly that pattern “curve” can not be completely expressed by order of data values. It includes other obvious or hidden patterns, like angle order etc. One aspect, we can only use data value order and so simply detect outliers; another aspect, if we exploit all patterns contained by curve, any tiny outliers must be detected correctly. It shows the power of פ algorithm. The פ algorithm treats outlier problem as pattern recognition problem, which is a view of wholism and makes both problems simplified. Following experiments furthermore indicate effectivity of פ algorithm.\nIn Fig. 5, points 17, 31, 25 are confirmed different from others. If not referred to a pattern, it is\nvery difficult to get such result. What we should note is that this time RDD values of 17, 31 and 25 are not so big, which indicates that the deviation to the whole is small.\nFig.3. Latent heat flux1 data\nFig.4. Sensible heat flux data\nFig.5. Co2 flux data\nThe last case is shown in Fig. 6, it is latent heat flux data of another day. The posterior half includes three outlier patches, respectively {35, 36}, {38, 39, 40, 41} and {43, 44, 45}, which makes the data\n-2500\n-2000\n-1500\n-1000\n-500\n0\n500\n1000\n1500\n2000\n0 10 20 30 40 50\nL E _7 5 0 0\n0\n1000\n2000\n3000\n4000\n5000\n6000\n7000\n8000\nR D D\nLE_7500 RDD\n-500\n-400\n-300\n-200\n-100\n0\n100\n0 10 20 30 40 50\nH _S at (W / m 2 )\n0\n500\n1000\n1500\n2000\n2500\nR D D\nH_Sat RDD\n-40\n-35\n-30\n-25\n-20\n-15\n-10\n-5\n0\n5\n10\n15\n0 10 20 30 40 50\nc o 2 - fl u x( μ m o l/ m 2 )\n0\n5\n10\n15\n20\n25\n30\nR D D\nco2-flux RDD\nin a very mess. RDD and IIR values are listed in Table 4. Only point 39 and point 43 are identified. Other points in outlier patches have big RDD values, but it seems that they are masked. However, this mask effect is not same as others, because RDD values still reflect deviation correctly. In order to find out outliers completely, we might have two methods. One is to use the relationship among RDD values, RDDs’ distribution and number N, which is our future work; another method is to do iterative calculation. After identifying outliers, remove them and calculate again until there is no outlier. In this way, we can get a serial of “pure” data. Such result to latent heat flux2 data is shown in Fig. 7. We can see a perfect 1-turn curve. Further study will work out a more effective method."
    }, {
      "heading" : "6 39 96 -0.5 29 1.9 -1.1",
      "text" : ""
    }, {
      "heading" : "5 11 114 -0.5 22 2.1 -0.5",
      "text" : ""
    }, {
      "heading" : "4 12 382 5.1 30 2.6 0.8",
      "text" : ""
    }, {
      "heading" : "3 9 1409 17.2 25 3.7 2.2",
      "text" : ""
    }, {
      "heading" : "2 25 2019 -9.5 31 7.5 9.9",
      "text" : ""
    }, {
      "heading" : "1 24 2074 -22.0 17 12.6 4.9",
      "text" : "Fig.7. Iterative result for Latent heat flux2 data"
    }, {
      "heading" : "II. Futural Present",
      "text" : ""
    }, {
      "heading" : "1. A new example",
      "text" : "The research was hanged up in 2009 for some special reasons. It is stimulated by a student in St. Louis. Here is a new example (Fig. 8), and the same algorithm is adpoted. We give a detailed analysis to complement past conclusions. Before giving the result, we can imagine our own answer. The disturbed points in our minds (natural principle) might be the fourth, 15 th , 16 th , 18 th , 22 nd , 24 th , 27 th , and the 36 th . If we remove these points, we can get a clean series like Fig. 9. One may have his own answer, based on his best principle.\nNow, let’s see what the פ algorithm tells us. Table 4 lists all outliers with corresponding RDD\nvalues. When outliers are removed, the clean data look like Fig.10.\nFig.8. St. Louis data\n-3000\n-2500\n-2000\n-1500\n-1000\n-500\n0\n500\n1000\n1500\n2000\n0 10 20 30 40 50\nnormal outlier\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n0 10 20 30 40\nFig.9. Supposed clean St. Louis data\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n0 10 20 30 40\nNow, let’s see the difference and the reasons. The main difference lies in data of the 15 th , 16 th ,\n17 th and the 25 th . The reason that removes the 15 th , 16 th and 18 th data is that the 17 th datum keeps more consistent angle with others, however, in פ algorithm, this is not considered. From the view of longest sequence, the 15 th and 16 th data should be kept. Then why was the 25 th datum labelled as bad one? In fact, the algorithm was simplied in processing multiple equal length sequence, where a random one was selected. In this way, the 24 th and 25 th data are all in a position that is selected by half chance. What we have to note again is that conclusion is view-driven. The פ algorithm is the basis of general AI, all intelligent outputs can be verified by it and kinds of views equip the brain of AI. The פ algorithm is the hidden algorithm."
    }, {
      "heading" : "2. Future work",
      "text" : "It is predicted that when parellel equal-length sequences are treated impartially, the 24 th and 25 th data could be kept at the same time. And if angle consistency is considered, only the 24 th datum would be an outlier. In order to get a consitent result with human minds, we could increase necessary views. Once we are placed into a complete set, we get a complete knowledge. Other instant applications of פ algorithm lie in the fields of image processing, pattern recognition etc."
    }, {
      "heading" : "III. Comments",
      "text" : "We have to understand that there is no “objective” outlier. If objectivity is expressed as main stream, we acknowledge that this kind of objectivity is a reasonable description. The Supreme Court has the power of final intepretation, the justice is nominted by the president, the president is selected by the all, and all are necessary to be honest. This is a kind of order. And this is what the פ algorithm tells us. What inner order we have, what external order we achieve. This is also what the Godel’s Theorems show us. For an example, we might have incompatible academies, but never let them become a tomb towards Wall Street."
    }, {
      "heading" : "Acknowledgements",
      "text" : "The authors are grateful to Kelly Moor, and they would also like to thank Prof. Hsi-Chia Hsiao\nfor very useful discussion.\nReferences\nC.A. Hsiao, H. Chen, K. Furuse and N. Ohbo, 2008, A relative deviation detection for time series\ndata based on Equality, Proceedings of International Multi-Conference on Engineer and Computer Scientist Vol. 1, pp. 511-516.\nC.A. Hsiao, K. Furuse and N. Ohbo, 2009, Figure and ground: a complete approach to outlier\ndetection. IAENG Transactions on Engineering Technologies Vol. 1, Ao, S.-L., Chan, A. H.-S., Katagiri, H., Castillo, O. & Xu, L. (Eds.), 70-81, American Institute of Physics, New York.\nC.A. Hsiao, 2010, On classification from the view of outlier. IAENG International Journal of\nComputer Science, Vol. 37, 4.\nC. Schensted, 1961, Longest increasing and decreasing subsequence, Canad. J. Math., 13, 179-191."
    } ],
    "references" : [ {
      "title" : "A relative deviation detection for time series",
      "author" : [ "C.A. Hsiao", "H. Chen", "K. Furuse", "N. Ohbo" ],
      "venue" : null,
      "citeRegEx" : "Hsiao et al\\.,? \\Q2008\\E",
      "shortCiteRegEx" : "Hsiao et al\\.",
      "year" : 2008
    }, {
      "title" : "On classification from the view of outlier",
      "author" : [ "H. Katagiri", "O. Castillo", "L. Xu" ],
      "venue" : "American Institute of Physics, New York. C.A. Hsiao,",
      "citeRegEx" : "Katagiri et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Katagiri et al\\.",
      "year" : 2010
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "A supplementary definition for outlier (Hsiao et al., 2008)",
      "startOffset" : 39,
      "endOffset" : 59
    } ],
    "year" : 2011,
    "abstractText" : "The human intelligence lies in the algorithm, the nature of algorithms lies in the classification, and the classification is equal to outlier detection. This paper is based on its past unpublished edition (2009), which discussed an application of פ (pe) algorithm in outlier detection for time series data. The פ algorithm, also named as RDD algorithm, is originated from the study on general AI. United with it, designed modules can be used to realize kinds of tasks. A primary framework concerned with the mind through פ algorithm has been constructed in prior works. In this concise paper, we neglect background and minor description of the early edition, and directly discuss the main contents include longest k–turn subsequence problem, curve type outliers, futural directions and related comments. In section “Past Present”, we keep all prior conclusions, though a little might be out of date.",
    "creator" : "Microsoft® Office Word 2007"
  }
}