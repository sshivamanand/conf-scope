{
  "name" : "1202.5284.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Elitism Levels Traverse Mechanism For The Derivation of Upper Bounds on Unimodal Functions",
    "authors" : [ "Aram Ter-Sarkisov" ],
    "emails" : [ "a.ter-sarkisov@massey.ac.nz" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n20 2.\n52 84\nv3 [\ncs .N\nE ]\n2 A\npr 2\n01 2\nIndex Terms—Evolutionary computation, Genetic algorithms, Computational complexity\nI. INTRODUCTION\nWe analyze an elitist population-based Evolutionary Algorithm with population size µ and recombination pool size λ, (µ + λ)EA using a genetic operator 1-Bit-Swap that recombines information between parents (see [1]).\nMost research in theoretical EA community is focused on mutation-based single species algorithms such as (1 + 1) 1\nµ EA\n(see e.g. [2]–[4]) with some sharp bounds on runtime obtained for OneMax function such as 0.982n log n in [4].\nResults on population-based algorithms are less abundant, and are restricted to mostly (µ + 1) 1\nµ EA (see [5]) with upper bound\nO(µn + n log n) and (1 + λ) 1 µ EA (see [6], [7]) with upper bound on OneMax O(n log n + nλ) in [6] and all linear functions O(⌊n log n\nλ + n log log λ log λ ⌋) in [7].\nAlthough so far (µ + λ) or (N + N) EAs have deserved less attention, they have been the subject of analysis in [8]–[10]. Specifically, in [10] it was derived that for a (N + N) EA with mutation and tournament selection solving OneMax the upper bound is O(nN logN + n log n) if measured in the number of function evaluations.\nUnfortunately many of these results are not directly comparable due to the difference in selection functions (fitness-proportional, truncation, elitist, tournament, etc) and elitism settings (save 1 best species or some variable proportion).\nEven more significantly, it was shown already in [8] that population effect is generally problem-specific, so it is quite hard to generalize findings to other functions. There is ample evidence though (e.g. [5], [6]) that for mutation-based algorithms (incl. Randomized Local Search, RLS) optimizing simple functions such as OneMax population is not beneficial and tends to degrade performance."
    }, {
      "heading" : "II. ALGORITHMS AND PROBLEMS",
      "text" : ""
    }, {
      "heading" : "A. Algorithm",
      "text" : "Although the mechanism described in this paper is quite universal, we test it on (µ + λ)EA1BS solving OneMax problem. This problem is well-known in EA community, recent achievements include [4], [11] with some sharp bounds. We selected this problem due to its simplicity and the ability to compare our findings to those available already."
    }, {
      "heading" : "B. Selection function",
      "text" : "Throughout the article we analyze an elitist recombination-driven (µ+λ) EA using a variant of tournament selection. It is both simple to implement and analyze. But since we recombine information between parents, we are interested in forming pairs of species in the recombination pool, and on the construction of these pairs the properties of the algorithm will be derived. This formation occurs in the following way:\nThus it is obvious that better-fit species have higher chances of entering the pool, so we can expect the proportion of α species to be higher in the pool rather than in the population.\nC. 1-Bit-Swap Genetic Operator\nWe apply the 1-Bit-Swap operator that was found to be useful solving a large number of test problems in [1] and was analyzed extensively in [12], [13] to have outperformed the mainstream RLS algorithm both theoretically and numerically.\nAnother advantage of 1BS is that we can compare it directly to RLS, since both are local search operators that cannot move too far from the current best search point. The operator works in the following way:"
    }, {
      "heading" : "III. DEFINITIONS",
      "text" : ""
    }, {
      "heading" : "A. Fitness levels partition",
      "text" : "Basic approach to analyzing elitist EA with a simple 1-bit mutation solving unimodal binary-encoded EAs was introduced by Wegener in [14] that is based on fitness partitioning: on a set of binary strings {0, 1}n size 2n a partition into a finite number of nonempty subsets A1, A2, · · · , Am is defined with ordering A1 - A2 - · · · - Am s.t. all a ∈ Am are the global optimum.\nThis approach allows definition and derivation of the lower bound of success probability of transition between states, si(a) = P (Ai+1|Ai) and the upper bound on expected convergence time of the algorithm, expected first hitting time of the best fitness level, E(Xf ) ≤ s−11 + s−12 . . . + s−1m−1. This idea can be extended to the situation when we apply non-negative weights w(f) (see [2], [14]) and to derive lower bounds (by considering the upper bound on si(a).\nAnother tool used extensively in the analysis of EAs are potential (auxiliary) functions that measure progress (see [14]). This is especially useful when working on functions that have fitness plateaus (see e.g. [15]), in which case we make the difference:\n1) fitness functions decide whether the new binary input (species) is better than the old one 2) potential function tracks the progress between states of the algorithm (fitness levels)\nOneMax (or some simple transformation of it) is used as a potential function for more complicated problems (Royal Roads, Binary Values, Short/Long Path etc)."
    }, {
      "heading" : "B. Elitism Levels Partition",
      "text" : "In this article we extend this approach to a population-based elitist algorithm, but rather than tracking the traverse of levels of fitness, we do the same to the levels of elitism, i.e., number of elite species in the population.\nWe focus on species that can either evolve to the currentlybest over 1 iteration or are already best. Therefore, the population\nis broken down into three disjoint subsets:\nα : currently best species\nβ1 : species with next-best fitness\nβ−1 : the rest of the population that cannot evolve over 1 generation\nSince 1BS swaps exactly 1 bit between two parents, this partition in combination with the assumptions made above enables construction of a very precise model, since the value of α cannot ’jump‘ more than 1 level of fitness and only α-species can breed better population, but only β1-species may evolve into α and change the probability of evolution."
    }, {
      "heading" : "C. α-levels subpartition",
      "text" : "This additional partition is necessary for functions with plateaus for which we use potential functions explained above. The need for it becomes evident in the next section, when probabilities of evolving elite species on two types of functions are compared. In addition to the elitism levels partition, for functions with plateaus we need to subpartition the α-level.\nIn slight abuse of notation in the rest of this article, we denote A the set of chromosomes in the population with the highest fitness. Also γ is the length of the plateau of fitness. Therefore the set A can be partitioned into\nA = A0 ∪A1 ∪ · · · ∪Aγ−1 where each subset Am has equal fitness. In order to differentiate between Am, we assign each elite species an additional auxiliary function, Vm that tracks progress to the next level by counting the number of 1-bits in the fitness level: A0 - A1 - . . . - Aγ−1 with corresponding auxiliary values V0 < V1 . . . < Vγ−1, i.e. OneMax is used as an auxiliary function. Species with both highest fitness and auxiliary values can be viewed as super-elite or α∗.\nIn the next section we use the notation α, α∗ to denote the set of elite or super-elite species, an element of that set and the size of it. This is done to reduce notational clutter."
    }, {
      "heading" : "IV. ELITISM LEVELS TRAVERSE MECHANISM FOR UPPER BOUNDS",
      "text" : "In this section we present the main result of the article on a general function that is later confirmed by further application to OneMax Test Function. We are interested in the upper bounds on optimization time (for explanation of Landau notation see e.g. Chapter 9 in [16]).\nThe working of the Elitism Levels Traverse Mechanism can be illustrated by an example from immunology.\nThere exists a population of species size N , which is susceptible to M types of infection, which are mutually exclusive, i.e. a species cannot be infected by more than one infection. The size of each set of infected species cannot be larger than mj . We denote E∗j an event that there are 1 ≤ r ≤ mj infected species of type j, of which exactly one spawns an infected offspring that destroys a healthy member of the population. Since the sets of infected species are mutually exclusive, by additivity we obtain the probability that any of the infected species adds exactly one infected offspring:\nP\n( M ⋃\nj=1\nE ∗ j\n)\n= P\n( M ⋃\nj=1\nmj ⋃\nr=1\nE ∗ jr\n)\n=\nM ∑\nj=1\nmj ∑\nr=1\nP (E∗jr) =\nM ∑\nj=1\nP (E∗j )\nThis expression is quite complicated for a number of reasons, e.g. the knowledge of mj . Although we can find bounds on the partial sum of rows of Pascal triangle, it is guaranteed to make the derivation quite messy. Therefore we need to lower-bound this probability. We do this by considering only one infected species of each type rather than r and the event of spawning exactly one infected species by Ej . This gives us the lower bound on the total probability of adding exactly one infected offspring, which is proven in Appendix A:\nP (E∗j ) ≥ P (Ej) ↔ M ∑\nj=1\nP (E∗j ) ≥ M ∑\nj=1\nP (Ej) (1)\nIn the notation of EA, N = λ 2 , the number of pairs of parents in the recombination pool with parents that are able to produce exactly one elite offspring. δµ (for 0 < δ < 1) is the number of elite individuals in the population that, once it is reached, the probability to generate an offspring with higher fitness is arbitrarily close to one, i.e. 1−o(1). We also have n− 1 levels of fitness. Combining this with the upper bound on the probability of adding elite offsprings to the population, we obtain the upper bound (worst-case) on the optimization time of the algorithm:\nEτ = O\n( n ∑\nk=1\nδµ ∑\nα=1\n1 ∑M\nj=1 P (Ej(α, k))\n)\n(2)\nDerivation of the upper bound from Equation 2 is rather versatile. We need to identify pairs of possible parents < p1, p2 > such that there exists some probability of swapping bits between parents ϕj(k) > 0 that as a results of applying a genetic operator to this pair either a new α species evolves from lower-ranked ones or an existing α is preserved after the recombination.\nIntuitively, for the functions with plateaus both the population size and the number of elite species are more important than for those without plateaus. In the remainder of this section we show that the probability to add a super-elite offspring when solving a function with plateaus is less than the probability to add an elite offspring when solving functions without plateaus.\nFor the rest of this section we denote f1 function without plateaus and f2 function with plateaus. What we show is that P (Ef1j (α, k)) ≥ P (Ef2j (α, k))."
    }, {
      "heading" : "A. Functions without plateaus",
      "text" : "For this type of unimodal functions (e.g. OneMax) intuitively it is easier to add an elite offspring and thus reduce the optimization time, but we need to show it rigorously.\nThe probability to select a pair with an α-parent can be bounded by\nP f1 sel ≥\nα µ ξ1\nwhere ξ1 is the probability to select a non-elite species to be paired with the elite one. Also bound the probability to flip the bits ϕj(k) ≥ η ∀ j, k. So the probability of an event Ej that includes pairs with elite species is\nP (Ef1j ) ≥ ( λ 2\n1\n)\nα µ ηξ1 = λαηξ1 2µ\nThe probability to select a pair without the the currently-elite species is lower-bounded by ρ1\nµ . By breaking down the set of parents Mf1\nin the recombination pool into those including α− parents, M∗f1\nand those that do not, M∗∗f1 , we can find the lower bound on the probability of adding another elite species:\nP (Sf1α,k) ≥ M∗f1λαξ1η\n2µ +\nM∗∗f1 ληρ1\n2µ"
    }, {
      "heading" : "B. Functions with plateaus",
      "text" : "As noted in [10], algorithms with well-chosen population size perform similar to, and best individuals evolve along the same path as (1 + 1)EA. The difference between (µ + λ)and (1 + 1) lies in the cost of traversing plateau. For this type of functions the length of plateau γ > 1. So we have K plateaus w.l.o.g. of the same length γ ∈ Z+, and n = γK.\nAlso we assume that at the start of the algorithm each ‘bin’ (plateau) starts with an equal number of 1’s and 0’s uniformly distributed, therefore fitness of the best species at the beginning of the run is 0. To track progress between jumps in fitness values we use OneMax as an auxiliary function (roughly along the lines of using potential or distance functions, see e.g. [7]) that sums bits in the plateau.\nThe tricky part in this analysis is that the selection is based on fitness of the string rather than auxiliary function, but the progress towards the next level of fitness plateau depends on the number of parents with highest auxiliary value, Vs rather than f(s). By denoting the subset of α with highest auxiliary function α∗, we notice that f(α) = f(α∗), and Vα < Vα∗ . Also trivially α∗ ≤ α (for the case of functions without plateaus these functions are identical and last two expressions are equalities).\nAs shown before, for a unimodal function without plateaus regardless of fitness function, the probability that one of the parents is elite is α\nµ , since if two elite species are selected for breeding,\nparent is chosen randomly. Obviously α ∗ µ ≤ α µ . Additionally,\nα∗ µ · (α− α ∗) µ · 1 2 ≤ α ∗ µ ≤ α µ\nObviously, unlike f1, for the evolution process on f2 only a small subset of parents are of use, these having the highest and next-highest auxiliary values. Therefore pairs that do not include at least 1 of these parents can’t add an α∗ offspring. Similar to f1, Mf2 = M ∗ f2 +M∗∗f2 and clearly M ∗ f2 ≤ M∗f1 and M ∗∗ f2 ≤ M∗∗f1 .\nAlong the lines of arguments in the previous subsection, ∃ξ2 s.t. probability to select a non super-elite parent in addition to the super-elite one is upper-bounded by it. We get:\nP f2 sel ≤ α∗(α− α∗)ξ2 2µ2\nso the probability of an event that an α∗ parent is added to a pool and a new α∗ offspring evolves is upper-bounded by\nP (Ef2j ) ≤ M∗f2λα ∗(α− α∗)ξ2η 4µ2\nwhere η is the lower bound on the probability of swapping bits. Therefore the probability to add one more α∗ species to the population is\nP (Sf2α,k) ≤ M∗f2λα ∗(α− α∗)ξ2η 4µ2 + M∗∗f2 ληρ2 2µ\nCombining the inequalities above, and taking M∗∗f1 ≥ M ∗∗ f2 + ǫ ρ1 , 0 < ǫ < 1, we compare the values in the first and second fractions\nin the expressions for P (Sf1α,k) and P (S f2 α,k). It is easy to see that ∃ two constants ψ2 < ψ1 s.t.\nP (Sf2α,k) ≤ ψ2 < ψ1 ≤ P (S f1 α,k) (3)\nV. UPPER BOUND ON RUNTIME OF (µ+ λ)EA1BS ON ONEMAX TEST FUNCTION USING ELITISM LEVELS TRAVERSE MECHANISM\nIn this section we present our findings on the upper bounds on runtime of (µ + λ)EA with 1-Bit-Swap operator optimizing OneMax function using the Elitism Levels Traverse Mechanism. We distinguish four pairs of parents that make possible evolution of currently-elite species:\nE1 :< α, β1 >\nE2 :< β1, β1 >\nE3 :< α, β−1 >\nE4 :< β1, β−1 >\nWe do not consider the obvious pair < α, α > as it either adds two elite offsprings, of generates an offspring with higher fitness, something we do not use in the Mechanism.\nFor the upper bound on optimization time we only consider increase of the number of elite species by at most one. Increase by two or more is ignored, or otherwise transformed into any of the lower-ranked species. Similar approach was used in [10] in bounding the takeover time."
    }, {
      "heading" : "A. Simple upper bound",
      "text" : "Of these four cases we start analysis with the first two. Main reason is that the other two cases involve cubic function, which becomes quite complicated to solve (see next subsection). For the cases E1, E2 we get the following probabilities of success:\nP (E1) = 2\n(\nλ 2 1\n)\nϕ1(k) · α µ · β1 µ\n(\n1− α µ\n)\n= αβ1λ(µ− α)ϕ1(k)\nµ3\nP (E2) =\n(\nλ 2 1\n)\nϕ2(k)\n(\nβ1\nµ\n(\n1− α µ\n))2\n= λϕ2(k)β 2 1(µ− α)2 2µ4\nThe probability of at least 1 of these events is\nP (Sα,k) ≥ P (E1) + P (E2) = 2ϕ1(k)αβ1λ(µ− α)\nµ3\n+ ϕ2(k)λβ 2 1ϕ1(k)(µ− α)2 2µ4\nand, since P (S) is minimal, the upper bound on expected time to traverse levels of elitism large enough to get a 1− o(1) probability of evolution is\nET̃α,k ≤ δµ ∑\nα=1\n1\nP (Sα) (4)\nThe expression for the expected first hitting time we obtain as a result of this setup is\nET̃α,k ≤ 2µ4 δµ ∑\nα=1\n1\nβ1λ(µ− α)(2αµϕ1(k)− αβ1ϕ2(k) + β1µϕ2(k))\n= 2µ4\nλ ·\nδµ ∑\nα=1\n1\n(ϕ2(k)− 2µϕ1(k))α2 + (2µ2ϕ1(k)− 2µϕ2(k))α+ µ2ϕ2(k)\n= 2µ4\nλ(ϕ2(k)− 2µϕ1(k))\nδµ ∑\nα=1\n1\nα2 + b1α+ b0 (5)\nwhere\nb0 = µ2ϕ2(k)\nϕ2(k)− 2µϕ1(k)\nb1 = 2µ(µϕ1(k)− ϕ2(k)) ϕ2(k)− 2µϕ1(k)\nAt this point we set β1 pessimistically to 1 to simplify the derivation. This a quadratic equation in α. The full solution to Equation 5 is in Appendix B.\nThe optimization time is\nEτ(µ+λ)EA1BS = O(µ 1+ε2n log n) (6)\nfor some constant ε2(µ). For the second option of δ = cµ the upper bound becomes\nEτ(µ+λ)EA1BS = O(µn log n) (7)\nor, in the number of function evaluations\nEτ(µ+λ)EA1BS = O(λµn log n) (8)"
    }, {
      "heading" : "B. Refined upper bound",
      "text" : "We add the other two cases to obtain a sharper upper bound on optimization time, we set β1 = 1:\nP (E3) = 2\n(\nλ 2 1\n)\nα µ · ( 1− α+ β1 µ )2 ϕ3(k)\n≈ λα µ\n(\n1− α µ\n)2\nϕ3(k)\nP (E4) = 2\n(\nλ 2 1\n)\nβ1\nµ\n(\n1− α µ\n)(\n1− α+ β1 µ\n)2\nϕ4(k)\n≈ λ µ\n(\n1− α µ\n)3\nϕ4(k)\nThe probability to evolve one more elite species is (P (E1), P (E2) are the same as in the previous derivation):\nP (Sα,k) = P (E1) + P (E2) + P (E3) + P (E4)\nand the expected time until there are δµ elite strings in the population:\nET̃µ,k ≤ δµ ∑\nα=1\n1\nSα,k\n= 2µ4 δµ ∑\nα=1\n1\nb3α3 + b2α2 + b1α+ b0\n= 2µ4\nb3\nδµ ∑\nα=1\n1\nα3 + b2 b3 α2 + b1 b3 α+ b0 b3\n(9)\nwhere\nb0 = λµ 2(2µϕ4(k) + ϕ2(k)) b1 = 2λµ(µϕ1(k) + µ 2 ϕ3(k)− 3µϕ4(k)− ϕ2(k)) b2 = λ(ϕ2(k)− 4µ2ϕ3(k)− 2µϕ1(k)− 6µϕ4(k)) b3 = 2λ(µϕ3(k)− ϕ4(k))\nFull solution of Equation 9 is in Appendix C.\nThe upper bound on expected optimization time is (for δ 6= c µ , c is a constant):\nEτ(µ+λ)EA1BS = cµ1+ǫn log n\nλ −O\n(\nµ1+ǫn\nλ\n)\n(10)\nfor 0 < ǫ(µ) < 1 and if δ = c µ , in the number of function evaluations:\nEτ(µ+λ)EA1BS = cµn log n−O(µn) (11)\nThis bound is sharper than the one obtained using simpler arguments earlier in this paper up to the order λ (since more possibilities of adding elite species are considered). It is also comparable to the results in [6], [7], [10] (see below). Such a result likely means that population has positive effect for some relatively small µ, but as it keeps increasing it either levels out (at best) or starts to degrade performance."
    }, {
      "heading" : "C. Generations vs Function evaluations",
      "text" : "Tournament selection has a property that you do not need to evaluate every species, but we need to make 2λ evaluations (since two species compete for 1 slot in the recombination pool, so the number of evaluations each generation is O(λ). Therefore, in terms of the number of functions evaluations the rough bound becomes O(µλn log n) and the refined one O(µn log n). If µ = λ = O(1) this reduces to the well-known result of O(n log n) for OneMax function. The λ term in the denominator means that for the algorithm run on parallel computers the increase in the recombination pool size improves the performance."
    }, {
      "heading" : "D. Comparison to earlier results",
      "text" : "The closest comparison we can draw is to (N+N )EA with mutation and tournament selection function in [10], O(nN logN + n log n) if measured in the number of function evaluations (Proposition 4). By setting N = O(1) = c ≥ 1 this bound becomes n log n + O(n), which is larger than just O(n log n). If instead we set µ = N = O( √ log n) or O( log n\nlog log n ) the result in [10] is sharper than in\nthis paper. For populations Ω( √ n\nlog n ) though the bound in this article\nbecomes sharper again, e.g., for µ = N = O( √ n) it is cn 3\n2 log n− n 3 2 , and in [10] it is n 3\n2 log n 2 +O(n log n)."
    }, {
      "heading" : "VI. DISCUSSION",
      "text" : "We presented a new tool to analyze population-based elitist EAs, Elitism Levels Traverse Mechanism, which we used to derive a new upper bound on (µ + λ) EAs with a recombination operator and a variant of tournament selection solving OneMax problem.\nWe derived and proved the lower bound on the probability of evolving exactly 1 new currently-elite species, which helped us obtain the upper bound on the expected optimization time.\nWe showed that for a function with fitness plateaus it is harder to add a super-elite offspring to the population than an elite offspring\nfor a function without plateaus. This means that the very number of super-elite species in the population is more important in the former case than the number of elite species in the latter.\nIt may seem from the derived equations that population generally degrades performance (since µ is in the numerator), but for small size of population, when the cost of functions evaluations is not much different from 1, population brings about some positive effect.\nAs it keeps increasing, the effect levels out, at the same time the costs of evaluating functions grows and population loses its benefit. For other algorithms, s.a. RLS the effect even of small-sized population is usually negative, which makes EA+1BS (and, possibly, other recombination-based algorithms) stand out.\nAt the same time the recombination pool improves performance (at least when measured in terms of the number of generations), since λ is in the denominator. This means there is a benefit from increasing recombination pool size when the algorithm is run on parallel computers.\nThe Mechanism we have designed in this article proved to be quite efficient in deriving upper bounds for OneMax function and we are confident it can also yield tight upper bounds on other population-driven algorithms and more complicated problems."
    }, {
      "heading" : "VII. CONCLUSIONS AND FUTURE WORK",
      "text" : "There are many reasons to use population in evolutionary computing rather than just (1+ 1) or (1, 1) algorithms, that includes higher diversity and shorter evolutionary path (see [10]). We intend to expand the results in this article by considering the following extensions to the upper bound tool:\n1) Analysis of functions with fitness plateaus. Apparently for functions with fitness plateaus (e.g. Royal roads) both large populations and large number of elite parents are crucial compared to functions without one, so we will extend our findings to these functions as well. 2) Typical runtime analysis. It is fairly obvious that the actual number of elite species grows every generation at some rate that realistically lies between the upper and lower bounds. We need to find an approximation on the expected number of α added to the population every generation and thus estimate the typical runtime. 3) Elitism rates analysis. In this article we never really considered the rate of elitism, i.e. the actual number of species saved in the population each generation, although numerical computation shows that it has a strong effect on the runtime. So far we only said that all the elite species are saved each generation, thus accumulating over time till δµ. It would be interesting to compare elitism level 1 to 50%, i.e. if there is any difference if only 1 species is saved compared to half of the population. 4) Derivation of δµ to find the proportion of elite species that yields a high enough probability of evolution. Quite obviously it is different for functions with plateaus and without. 5) Derivation of the optimal population size. We will do this by comparing the number of functions evaluations necessary of (1 + 1) and (µ+ λ) algorithms."
    }, {
      "heading" : "APPENDIX A PROOF OF EQUATIONS 1-2",
      "text" : "Main idea and logic of the lower bound on the probability of adding an elite offspring and the upper bound on runtime following from this is presented in Section IV. Here we present the derivation of this bound.\nWe prove this lower bound inequality for an arbitrary subset (it is not to be confused with at trivial one of the form\n∑ k≥r ( n k ) pk(1− p)k > ( n r ) pr(1− p)n−r):\nP (Ej) =\n(\nλ 2 1\n)\nPselPswap =\n(\nλ 2 1\n)\nPselϕj(k)\nP (E∗j ) = P\n( mj ⋃\nr=1\nE ∗ jr\n)\n=\nmj ∑\nr=1\n(\nλ 2 r\n)\nP r sel(1− Psel)\nλ 2 −r\n(\nr\n1\n)\nϕj(k)(1− ϕj(k))r−1\nIn this expression Pswap is not necessarily the probability to swap bits < 0, 1 >. It is the probability to swap bits such that an elite offspring evolves. Since all the terms in the sum are positive, we use the lower bound on this expression:\nP (E∗j ) ≥ mj ∑\nr=1\n(\nλ 2 r\n)\nP r sel(1− Psel)\nλ 2 −r ϕj(k)(1− ϕj(k))r−1\n≥ ϕj(k) (1− ϕj(k)\n( mj ∑\nr=0\n(\nλ 2 r\n)\nP r sel(1− ϕj(k))r(1− Psel)\nλ 2 −r\n− (1− Psel) λ 2\n)\n≥ ϕj(k) ( mj ∑\nr=0\n(\nλ 2 r\n)\nP r sel(1− ϕj(k))r(1− Psel) λ 2 −r−\n(1− Psel) λ 2\n)\nCanceling out ϕj(k) and moving the term e−1 ≤ (1 − Psel) λ 2 ≤ 1√ e < 1 on the other side, LHS of the inequality becomes\nP (E∗j ) ≥ mj ∑\nr=0\n(\nλ 2 r\n)\nP r sel(1− ϕj(k))r(1− Psel)\nλ 2 −r\n≥ (Psel(1− ϕj(k)) + 1− Psel) λ 2 = (1− Pselϕj(k)) λ 2\nand the RHS is upper-bounded by\n1√ e + λPsel 2 = 1√ e + o(λc−1)by the argument below\nLHS is lower-bounded by (using Bernoulli inequality for λ 2 ≥ 1):\nP (E∗j ) ≥ (1− Pselϕj(k)) λ 2 ≥ 1− λPselϕj(k)\n2\nSince we can select Psel = o(λc) and ϕj(k) = O( 1nc ), c ∈ Z, the expression is\nP (E∗j ) = 1− o(1) > 1√ e + o(1) = P (Ej) (12)\nthus proving the upper bound on the probability of evolving 1 more elite species for an arbitrary subset. This logic applies for each of the M subsets (types of pairs) of the recombination pool, and the inequality becomes\nP\n(\nM ⋃\nj=1\nE ∗ j\n)\n>\nM ∑\nj=1\nP (Ej) (13)\nThe upper bound in Equation 2 follows directly."
    }, {
      "heading" : "APPENDIX B SOLUTION OF EQUATION 5",
      "text" : "We have a quadratic equation\nS(µ, k) = ∑\nα\nP2(α) =\nδµ ∑\nα=1\n1\nα2 + b1α+ b0\nwith\nb0 = µ2ϕ2(k)\nϕ2(k)− 2µϕ1(k)\nb1 = 2µ(µϕ1(k)− ϕ2(k)) ϕ2(k)− 2µϕ1(k)\nIn order to simplify the already complicated derivation, we want the expression above in the form\nP2(α) = 1\n(α+ r)2 =\n1\n(α2 + 2rα+ r2)\nfor some r, not necessarily rational. From equating coefficients it becomes clear that\nr = √ b0 ∨ r = b1\n2\nand so, using the first root\nS(µ, k) =\nδµ ∑\nα=1\n1\n(α+ r)2 = ψ1(\n√ b0)− ψ1( √ b0 + δµ+ 1)\nFor large b0 these expressions involving digamma function can be expanded asymptotically in Taylor series (we use only the first two terms):\nS(µ, k) ≈ ( 1\nb0 − 1 2b0\n)\n− ( 1 b0 − δµ b0 − 1 2b0 ) = δµ b0\n= δµ(ϕ2(k)− 2µϕ1(k))\nµ2ϕ2(k) = δ(ϕ2(k)− 2µϕ1(k)) µϕ2(k)\nand therefore the expected time to traverse enough levels of elitism to improve 1 bit of the string is (plugging this expression into Equation 5)\nET̃µ,k = 2µ4 λ(ϕ2(k)− 2µϕ1(k)) · δ(ϕ2(k)− 2µϕ1(k)) µϕ2(k)\n= 2µ3δ\nλϕ2(k)\nTo improve the pair < β1, β1 > we need to either swap 1 from the first parent and 0 from the second, or the other way around (any other outcome just keeps the current number of bits in each parent):\nϕ2(k) = 2 · k − 1 n · n− k + 1 n = 2(k − 1)(n− k + 1) n2\nPlugging this into the expression for ET̃k, we obtain the expected optimization time of the algorithm, pessimistically assuming that at the beginning of the run the best species has only 2 1-bit and finishes at n − 2, since if the fitness of β1 = n − 1 implies the fitness of α = n.\nEτ(µ+λ)EA1BS ≤ µ3n2δ\nλ\nn−2 ∑\nk=2\n1\n(k − 1)(n− k + 1)\n= δµ3n2 λ · 1 n\n(\nn−2 ∑\nk=2\n1 k − 1 + n−2 ∑\nk=2\n1\nn− k + 1\n)\n= δµ3n\nλ\n( log(n− 1) +O(1) )\nThe second step is due to partial fraction expansion. Although this seems quite a loose bound given cubic in µ, we take µ = O(λ) so all we need to establish is δ to reduce the power.\nObviously 0 < δ < 1, but we need to select it s.t. summation over α makes sense. We set δ = µ−ε1 for an arbitrary ε1 > 0 s.t. δµ = µ1−ε1 > 1. Then δµ2 = µ2−ε1 = µ1+ε2 . For example, ε = 1\n2 yields δµ =\n√ µ and δµ2 = √\nµ3. Therefore, the upper bound on the expected convergence time is\nEτ(µ+λ)EA1BS = O(µ 1+ε2n log n) (14)\nIn fact if (similar to [10]) we set δ = c µ for c ∈ Z+, we get δµ = c and δµ2 = cµ = O(µ), so the expectation becomes linear in µ:\nEτ(µ+λ)EA1BS = O(µn log n) (15)"
    }, {
      "heading" : "APPENDIX C SOLUTION TO EQUATION 9",
      "text" : "We need a solution to the cubic equation of the form\nS(µ, k) = ∑\nα\nP3(α) =\nδµ ∑\nα=1\n1\nα3 + b′2α2 + b ′ 1α+ b0\nwhere\nb ′ 2 = ϕ2(k)− 4µ2ϕ3(k)− 2µϕ1(k)− 6µϕ4(k) 2(µϕ3(k)− ϕ4(k))\nb ′ 1 =\nµ(µϕ1(k) + µ 2ϕ3(k)− 3µϕ4(k)− ϕ2(k))\n2(µϕ3(k)− ϕ4(k))\nb ′ 0 =\nµ2(2µϕ4(k) + ϕ2(k))\n2(µϕ3(k)− ϕ4(k))\nSolution to S(µ, k) is of the form\nS(µ, k) = ∑\nα\n1\n(α+ ρ)3 = ∑\nα\n1\nα3 + 3α2ρ+ 3αρ2 + ρ3\nEquating the coefficients we obtain three roots ρ:\nρ = b′2 3 ρ = ± √\nb′1 3\nρ = 3 √ b′0\nTo simplify the increasingly hard notation, we select only the last root:\nS(µ, k) =\nδµ ∑\nα=1\n1\n(α+ 3 √ b′0) 3 =\nψ2( 3 √ b′0 + δµ+ 1)− ψ2( 3 √ b′0 + 1)\n2\n= 1\n2\n((\n− 1 3 √\nb′0 2 +\n2δµ+ 1\nb′0\n) − (\n− 1 3 √\nb′0 2 +\n1 b′0\n))\n= 1 2 · 2δµ b′0 = δµ b′0\nThe second line in the derivation was obtained by expanding both second-order polygamma functions in Taylor series as b′0 → ∞ and taking two first terms of each function. We now combine the front term in Equation 9 with this derivation to obtain the expression on\nthe upper bound on achieving the number of elite species in the population δµ:\nET̃µ,k ≤ 2µ5δ\nλb3b′0 =\n2δµ3\nλ(2µϕ3(k) + ϕ4(k))\nsince\nb3b ′ 0 = 2(µϕ3(k)− ϕ4(k)) ·\nµ2(2µϕ3(k) + ϕ4(k))\n2(µϕ3(k)− ϕ4(k)) = µ2(2µϕ3(k) + ϕ4(k))\nWe are now ready to find the upper bound on the expected optimization time of the algorithm:\nEτ(µ+λ)EA1BS ≤ n−3 ∑\nk=3\nET̃µ,k = 2δµ3\nλ\nn−1 ∑\nk=3\n1\n2µϕ3(k) + ϕ4(k)\n(16) Here again we pessimistically assume that the best species at the start of the run has fitness 3, since in such case fitness of β−1 has minimal fitness of 1, otherwise we obtain inconsistencies s.a. 1\n0 . We have two\nprobabilities to consider for the two new types of pairs:\n< α, β−1 >: ϕ3(k) = k n · k − 2 n + n− k n · n− k + 2 n\n= k(k − 2) + (n− k)(n− k + 2)\nn2\nWe need to preserve the better parent in order to get it added to the population, so need to either select 1-bits in each parent or 0-bits in each parent. for the last swap probability, ϕ4(k), we need only to select a 0 in the β1 parent and 1 in β−1 parent, other options either degrade the better parent or leave the current fitness.\n< β1, β−1 >: ϕ4(k) = (n− k + 1)(k − 2)\nn2\nWe continue with manipulating with the summand over k:\nS(n, k) = 1\n2µϕ3(k) + ϕ4(k)\n= n2\n(4µ− 1)k2 + (n− 8µ− 4µn+ 3)k + 4µn− 2n+ 2µn2 − 2\n≤ n 2 µ · 1 k2 − 4(n+ 2)k + 2n(n+ 1)\nWe leave out the first fraction, and factor the denominator in the form (k − s)(k − r), s.t. s, r are solutions to the set of equations:\n{\ns+ r = 4(n+ 2) sr = 2n(n+ 1)\nThe resulting solution (we only use one of the roots, which are symmetric) is:\n{ s = 2n+ √ 2 √ n2 + 7n+ 8 + 4\nr = 2n− √ 2 √ n2 + 7n+ 8 + 4\nThe value under the root can be bounded by\nn+ 2 ≤ √ n2 + 7n+ 8 ≤ n+ 4\nSo the expression becomes upper-bounded by\n1\n(k − (2n+ √ 2(n+ 2)))(k − (2n− √ 2(n+ 4)))\nExpanding this in partial fractions, we obtain\n1\n2 √ 2(n+ 3)\n· (\n1\nk − (2n+ √ 2(n+ 2))\n− 1 k − (2n− √ 2(n+ 2))\n)\nWe obtain two sums over k:\nS1(n, k) = n−3 ∑\nk=3\n1\nk − (2n+ √ 2(n+ 2))\n≈ ψ0(n− 2n− √ 2n)− ψ0(3− 2n− √ 2n) = ψ0(−(1− √ 2)n)− ψ0(3− (2 + √ 2)n) = O(1) −O(1) = −O(1)\nThe result of −O(1) is due to the fact that we can select any n, for which the values of digamma function are small negative constants (see Appendix D for details on Taylor series expansion of ψ0(n) for n < 0). For the second sum, we notice the upper bound on the value in the denominator, since 2− √ 2 ≈ 0.58 < 1:\nS2(n, k) =\nn−3 ∑\nk=3\n1\nk − (2n− √ 2(n+ 2))\n≤ n−3 ∑\nk=3\n1 k − n = − n−3 ∑\nk=3\n1\nn− k ≈ − log(n− 3) +O(1)\nthe minus sign in front of the expression cancels out and we obtain the upper bound for S(µ, n):\nS(µ, n) ≤ n 2(log(n− 3) −O(1)\nµn\nand the upper bound on the expected first hitting time:\nEτ(µ+λ)EA1BS ≤ 2δµ2n(log(n− 3)−O(1))\nλ (17)\nwith δ = c µ the expression becomes (measured in the number of generations, for c > 0)\nEτ(µ+λ)EA1BS = cµn log n\nλ −O\n(\nµn\nλ\n)\n(18)\nor, in the number of function evaluations,\nEτ(µ+λ)EA1BS = cµn log n−O(µn) (19)"
    }, {
      "heading" : "APPENDIX D MATHEMATICAL EXPRESSIONS",
      "text" : "There is a number of important mathematical expression used throughout the article, we present some of them here:\nH(n) =\nn−1 ∑\nk=0\n1 n− k = n−1 ∑\nk=0\n1 k ≈ ∫ n−1\n0\ndx\nn− x = log n < log n+ 1\nDigamma function:\nψ0(n) = log n+O\n(\n1\nn\n)\nFor ψ0(n) with n → −∞ we use the largest term of Taylor series for asymptotic expansion:\nψ0(n) ≈ π cot(πn) +O ( 1\nn\n)\nThe values for cot(πn) for integer n, such as in this article, are infinity. Therefore for expressions for S1(n, k) and S2(n, k) we have selected some constants, e.g. −(1 − √ 2), 2 − √ 2, s.t. the resulting values are constants. Since n is arbitrarily large, we can find such n that the difference between them is negative, hence we obtain term −O(1)."
    } ],
    "references" : [ ],
    "referenceMentions" : [ ],
    "year" : 2013,
    "abstractText" : "In this article we present an Elitism Levels Traverse Mech-<lb>anism that we designed to find bounds on population-based Evolutionary<lb>Algorithms solving unimodal functions. We prove its efficiency theoreti-<lb>cally and test it on OneMax function deriving bounds cμn logn−O(μn).<lb>This analysis can be generalized to any similar algorithm using variants<lb>of elitist selection and genetic operators that flip or swap only 1 bit in<lb>each string.<lb>",
    "creator" : "LaTeX with hyperref package"
  }
}