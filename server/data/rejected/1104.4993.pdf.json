{
  "name" : "1104.4993.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ "Hubie Chen", "Victor Dalmau", "Berit Grußien" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n10 4.\n49 93\nv1 [\ncs .A\nI] 2\n6 A\npr 2\n01 1"
    }, {
      "heading" : "1 Introduction",
      "text" : ""
    }, {
      "heading" : "1.1 Background",
      "text" : "The constraint satisfaction problem (CSP) involves deciding, given a set of variables and a set of constraints on the variables, whether or not there is an assignment to the variables satisfying all of the constraints. Cases of the constraint satisfaction problem appear in many fields of study, including artificial intelligence, spatial and temporal reasoning, logic, combinatorics, and algebra. Indeed, the constraint satisfaction problem is flexible in that it admits a number of equivalent formulations. In this paper, we work with the formulation as the relational homomorphism problem: given two similar relational structures A and B, does there exist a homomorphism from A to B? In this formulation, one can view each relation of A as containing variable tuples that are constrained together, and the corresponding relation of B as containing the permissible values for the variable tuples [18].\nThe constraint satisfaction problem is in general NP-hard; this general intractability has motivated the study of restricted versions of the CSP that have various desirable complexity and algorithmic properties. A natural and wellstudied way to restrict the CSP is to fix the value relations that can be used to pose constraints; in the homomorphism formulation, this corresponds to fixing the right-hand side structure B, which is also known as the constraint language. Each structure B then gives rise to a problem CSP(B), and one obtains a rich family of problems that include boolean satisfiability problems, graph homomorphism problems, and satisfiability problems on algebraic equations. One of the primary current research threads involving such problems is to understand for which finite-universe constraint languages B the problem CSP(B) is polynomial-time tractable [9]; there is also work on characterizing the languages B for which the problem CSP(B) is contained in lower complexity classes such as L (logarithmic space) and NL (non-deterministic logarithmic space) [13, 21]. With such aims providing motivation, there have been efforts to characterize the languages amenable to solution by certain algorithmic techniques, notably, representing solution spaces by generating sets [19] and consistency methods [22, 2, 6], which we now turn to discuss.\nChecking for consistency is a primary reasoning technique for the practical solution of the CSP, and has been studied theoretically from many viewpoints [22, 2, 4, 1, 3, 6, 5]. The most basic and simplest form of consistency is arc consistency, which algorithmically involves performing inferences concerning the set of feasible values for each variable. The question of how to efficiently implement an arc consistency check has been studied intensely, and highly\n∗Chen is supported by the Spanish program “Ramon y Cajal”. †Both Chen and Dalmau are supported by MICINN grant TIN2010-20967-C04-02. ‡Work by Grußien was supported by the Deutsche Forschungsgemeinschaft (DFG) within the research training group ”Methods for Discrete\nStructures” (GrK 1408).\noptimized implementations that are linear in both time and space have been presented. In general, a consistency check typically involves running an efficient method that performs inference on bounded-size sets of variables, and which can sometimes detect that a CSP instance is inconsistent and has no solution. While these methods exhibit one-sided error in that they do not catch all non-soluble CSP instances (as one expects from the conjunction of their efficiency and the intractability of the CSP), it has been shown that, for certain constraint languages, they can serve as complete decision procedures, by which is meant, they detect an inconsistency if (and only if) an instance has no solution. As an example, unit propagation, a consistency method that can be viewed as arc consistency specialized to SAT formulas, is well-known to decide the Horn-SAT problem in this sense."
    }, {
      "heading" : "1.2 Contributions",
      "text" : "In this paper, we study arc consistency and three natural extensions thereof from the perspective of constraint languages. The extensions of AC that we study are look-ahead arc consistency (LAAC) [12]; peek arc consistency (PAC) [8], and singleton arc consistency (SAC) [16, 7]. Each of these algorithms is natural, conceptually simple, readily understandable, and easily implementable using arc consistency as a black box. Tractability results for constraint languages have been presented for AC by Feder and Vardi [18] (for instance); and for LAAC and PAC in the previously cited work. In fact, for each of these three algorithms, characterizations of the class of tractable languages have been given, as we discuss in the paper.\nWe give a uniform presentation of these algorithms (Section 3), and conduct a comparison of these algorithms on the basis of which languages they solve (Section 4). Our comparison shows, roughly, that the algorithms can be placed into a hierarchy: solvability of a language by AC or LAAC implies solvability by PAC; solvability by PAC in turn implies solvability by SAC (see Section 4 for precise statements). We also study the strictness of the containments shown. We thus contribute to a basic, foundational understanding of the scope of these algorithms and of the situations in which these algorithms can be demonstrated to be effective.\nWe then present new tractability results for singleton arc consistency (Section 5). We prove that languages having certain types of 2-semilattice polymorphisms can be solved by singleton arc consistency; and, we prove that any language having a majority polymorphism is solvable by singleton arc consistency. The presence of a majority polymorphism is a robust and well-studied condition: majority polymorphisms were used to give some of the initial language tractability results, are known to exactly characterize the languages such that 3-consistency implies global consistency (we refer to [20] for definitions and more details), and gave one of the first large classes of languages whose constraint satisfaction problem could be placed in non-deterministic logarithmic space [14]. While the languages that we study are already known to be polynomial-time tractable [20, 10], from the standpoint of understanding the complexity and algorithmic properties of constraint languages, we believe our tractability results to be particularly attractive for a couple of reasons. First, relative to a fixed language, singleton arc consistency runs in quadratic time [7], constituting a highly non-trivial running time improvement over the cubic time bound that was previously known for the studied languages. Also, in showing that these languages are amenable to solution by singleton arc consistency, we demonstrate their polynomial-time tractability in an alternative fashion via an algorithm that is different from the previously used ones; the techniques that we employ expose a different type of structure in the studied constraint languages."
    }, {
      "heading" : "2 Preliminaries",
      "text" : "Our definitions and notation are fairly standard. For an integer k ≥ 1, we use the notation [k] to denote the set containing the first k positive integers, that is, the set {1, . . . , k}.\nStructures. A tuple over a set B is an element of Bk for a value k ≥ 1 called the arity of the tuple; when t is a tuple, we often use the notation t = (t1, . . . , tk) to denote its entries. A relation over a set B is a subset of Bk for a value k ≥ 1 called the arity of the relation. We use πi to denote the operator that projects onto the ith coordinate: πi(t) denotes the ith entry ti of a tuple t = (t1, . . . , tk), and for a relation R we define πi(R) = {πi(t) | t ∈ R}. Similarly, for a subset I ⊆ [k] whose elements are i1 < · · · < im, we use πI(t) to denote the tuple (ti1 , . . . , tim), and we define πI(R) = {πI(t) | t ∈ R}.\nA signature σ is a set of symbols, each of which has an associated arity. A structure B over signature σ consists of a universe B, which is a set, and a relation RB ⊆ Bk for each symbol R ∈ σ of arity k. (Note that in this paper, we are concerned only with relational structures, which we refer to simply as structures.) Throughout, we will use the bold capital letters A,B, . . . to denote structures, and the corresponding non-bold capital letters A,B, . . . to denote their universes. We say that a structure B is finite if its universe B has finite size. Unless stated otherwise, we assume all structures under discussion in this paper to be finite. We say that a structure B has all constants if for each b ∈ B, there is a relation symbol Rb with RBb = {(b)}.\nWhen two structures A and B are defined over the same signature σ, we say that they are similar. We define the following notions on similar structures. For similar structures A and B over a signature σ, we say that A is an induced substructure of B if A ⊆ B and for every R ∈ σ of arity k, it holds that RA = Ak ∩RB. Observe that for a structure B and a subset B′ ⊆ B, there is exactly one induced substructure of B with universe B′. For similar structures A and B over a signature σ, the product structure A × B is defined to be the structure with universe A × B and such that RA×B = {((a1, b1), . . . , (ak, bk)) | a ∈ RA, b ∈ RB} for all R ∈ σ. We use An to denote the n-fold product A× · · · ×A.\nWe say that a structure B over signature σ′ is an expansion of another structure A over signature σ if (1) σ′ ⊇ σ, (2) the universe of B is equal to the universe of A, and (3) for every symbol R ∈ σ, it holds that RB = RA. We will use the following non-standard notation. For any structure A (over signature σ) and any subset S ⊆ A, we define [A, S] to be the expansion of A with the signature σ∪{U} where U is a new symbol of arity 1, defined by U [A,S] = S and R[A,S] = RA for all R ∈ σ. More generally, for a structure A (over σ) and a sequence of subsets S1, . . . , Sn ⊆ A, we define [A, S1, . . . , Sn] to be the expansion of A with the signature σ ∪ {U1, . . . , Un} where U1, . . . , Un are new symbols of arity 1, defined by U [A,S1,...,Sn]i = Si for all i ∈ [n], and R [A,S1,...,Sn] = RA for all R ∈ σ.\nHomomorphisms and the constraint satisfaction problem. For similar structures A and B over the signature σ, a homomorphism from A to B is a mapping h : A → B such that for every symbol R of σ and every tuple (a1, . . . , ak) ∈ RA, it holds that (h(a1), . . . , h(ak)) ∈ RB. We use A → B to indicate that there is a homomorphism from A to B; when this holds, we also say that A is homomorphic to B. It is well-known and straightforward to verify that the homomorphism relation → is transitive, that is, if A → B and B → C, then A → C.\nThe constraint satisfaction problem (CSP) is the problem of deciding, given as input a pair (A,B) of similar structures, whether or not there exists a homomorphism from A to B. When (A,B) is an instance of the CSP, we will also call a homomorphism from A to B a satisfying assignment; say that the instance is satisfiable if there exists such a homomorphism; and, say that the instance is unsatisfiable if there does not exist such a homomorphism. We generally assume that in an instance of the CSP, the left-hand side structure A contains finitely many tuples. For any structure B (over σ), the constraint satisfaction problem for B, denoted by CSP(B), is the constraint satisfaction problem where the right-hand side structure is fixed to be B, that is, the problem of deciding, given as input a structure A over σ, whether or not there exists a homomorphism from A to B. In discussing a problem of the form CSP(B), the structure B is often referred to as the template or constraint language. There are several equivalent definitions of the constraint satisfaction problem. For instance, in logic, the constraint satisfaction problem can be formulated as the model checking problem for primitive positive sentences over relational structures, and in database theory, it can be formulated as the containment problem for conjunctive queries [11].\nPolymorphisms. When f : Bn → B is an operation on B and\nt1 = (t11, . . . , t1k), . . . , tn = (tn1, . . . , tnk) ∈ B k\nare tuples of the same arity k over B, we use f(t1, . . . , tn) to denote the arity k tuple obtained by applying f coordinatewise, that is,\nf(t1, . . . , tn) = (f(t11, . . . , tn1), . . . , f(t1k, . . . , tnk)).\nAn operation f : Bn → B is a polymorphism of a structure B over σ if for every symbol R ∈ σ and any tuples t1, . . . , tn ∈ RB, it holds that f(t1, . . . , tn) ∈ RB. That is, each relation RB is closed under the action of f . Equivalently, an operation f : Bn → B is a polymorphism of B if it is a homomorphism from Bn to B."
    }, {
      "heading" : "3 Algorithms",
      "text" : "In this section, we give a uniform presentation of the four algorithms under investigation in this paper: arc consistency, look-ahead arc consistency, peek arc consistency, and singleton arc consistency, presented in Sections 3.1, 3.2, 3.3, and 3.4, respectively. The results on the first three algorithms come from previous work, as we discuss in presenting each of these algorithms; for singleton arc consistency, we here develop results similar to those given for the other algorithms.\nOur treatment of arc consistency, peek arc consistency, and singleton arc consistency is uniform: for each of these algorithms, we present a homomorphism-based consistency condition, we show that the algorithm checks precisely this consistency condition, and we give an algebraic condition describing the structures B such that the algorithm solves CSP(B). These three algorithms give one-sided consistency checks: each either correctly rejects an instance as unsatisfiable or outputs “?”, which can be interpreted as a report that it is unknown whether or not the instance is satisfiable. The other algorithm, look-ahead arc consistency, has a somewhat different character. It attempts to build a satisfying assignment one variable at a time, using arc consistency as a filtering criterion; it either returns a satisfying assignment, or outputs “?”.\nThroughout this section and in later sections, we will make use of a structure℘(B) that is defined for every structure B, as follows [18, 15]. For a structure B (over σ), we define ℘(B) to be the structure with universe ℘(B) \\ {∅} and where, for every symbol R ∈ σ of arity k, R℘(B) = {(π1S, . . . , πkS) | S ⊆ RB, S 6= ∅}. Here, ℘(B) denotes the power set of the set B."
    }, {
      "heading" : "3.1 Arc Consistency",
      "text" : "We now present the arc consistency algorithm. The main idea of the algorithm is to associate to each element a ∈ A a set Sa of values which, throughout the execution of the algorithm, has the property that for any solution h, it must hold that h(a) ∈ Sa. The algorithm continually shrinks the sets Sa in a natural fashion until they stabilize; at this point, if some set Sa is the empty set, then no solution can exist, and the algorithm rejects the instance.\nArc Consistency Input: a pair (A,B) of similar structures\nforall a ∈ A do set Sa := B; repeat forall relations RA of A do\nforall tuples (a1, . . . , ak) ∈ RA do forall i ∈ [k] do\nset Sai := πi(R B ∩ (Sa1 × . . .× Sak));\nuntil no set Sa is changed ; if there exists a ∈ A such that Sa = ∅ then reject ; else return “?”;\nFeder and Vardi [18] have studied arc consistency, under an equivalent formulation in terms of Datalog Programs, for constraint languages. The results in this section are due to this reference. The connection of the results in Feder and Vardi with arc consistency was made explicit in Dalmau and Pearson [15].\nDefinition 1 An instance (A,B) has the arc consistency condition (ACC) if there exists a homomorphism from A to ℘(B).\nProposition 2 The arc consistency algorithm does not reject an instance (A,B) if and only if the instance has the ACC.\nDefinition 3 Let B be a structure. We say that arc consistency solves CSP(B) if for all structures A, the following holds: (A,B) has the ACC implies that there is a homomorphism A → B.\nNote that the converse of the condition given in this definition always holds: if h is a homomorphism from A to B, then the mapping sending each a ∈ A to the set {h(a)} is a homomorphism from A to ℘(B).\nTheorem 4 Let B be a structure. Arc consistency solves CSP(B) if and only if there is a homomorphism ℘(B) → B."
    }, {
      "heading" : "3.2 Look-Ahead Arc Consistency",
      "text" : "We now present the look-ahead arc consistency algorithm. It attempts to construct a satisfying assignment by setting one variable at a time, using arc consistency as a filter to find a suitable value for each variable.\nLook-Ahead Arc Consistency Input: a pair (A,B) of similar structures\nforall a ∈ A do set Sa := B; for i = 1 to |A| do pick arbitrary ai ∈ A with ai 6∈ {a1, . . . , ai−1}; forall b ∈ B do\nif Arc Consistency ([A, {a1}, . . . , {ai−1}, {ai}], [B, {b1}, . . . , {bi−1}, {b}]) rejects then remove b from Sai ;\nif Sai = ∅ then return “?”; else choose bi ∈ Sai arbitrarily;\naccept;\nLook-ahead arc consistency was introduced and studied by Chen and Dalmau [12], and the theorem that follows is due to them. This algorithm can be viewed as a generalization of an algorithm for SAT studied by Del Val [17].\nDefinition 5 Let B be a structure. We say that look-ahead arc consistency solves CSP(B) if for all structures A, the following holds: if there exists a homomorphism A → B, then the look-ahead arc consistency algorithm, given (A,B), outputs such a homomorphism.\nTheorem 6 Let B be a structure. Look-ahead arc consistency solves CSP(B) if and only if there is a homomorphism l : ℘(B)×B → B such that l({b}, b′) = b for all b, b′ ∈ B."
    }, {
      "heading" : "3.3 Peek Arc Consistency",
      "text" : "We now present the peek arc consistency algorithm. It attempts to find, for each variable a ∈ A, a value b ∈ B such that when a is set to b, the arc consistency check is passed.\nPeek Arc Consistency Input: a pair (A,B) of similar structures\nforall a ∈ A do set Sa := B; forall a ∈ A, b ∈ B do if Arc Consistency ([A, {a}], [B, {b}]) rejects then remove b from Sa; if there exists a ∈ A such that Sa = ∅ then reject ; else return “?”;\nPeek arc consistency was introduced and studied by Bodirsky and Chen [8]; the notions and results that follow come from them. In their work, the algorithm is shown to solve certain constraint languages, including some languages having infinite-size universes; such languages actually gave the motivation for introducing the algorithm. In this work, it is pointed out that peek arc consistency can be readily parallelized; by invoking the arc consistency checks independently in parallel, one can achieve a linear parallel running time.\nDefinition 7 An instance (A,B) has the peek arc consistency condition (PACC) if for every element a ∈ A, there exists a homomorphism h from A to ℘(B) such that h(a) is a singleton.\nProposition 8 The peek arc consistency algorithm does not reject an instance (A,B) if and only if the instance has the PACC.\nDefinition 9 Let B be a structure. We say that peek arc consistency solves CSP(B) if for all structures A, the following holds: (A,B) has the PACC implies that there is a homomorphism A → B.\nThe converse of the condition given in this definition always holds. Suppose that h is a homomorphism from A to B; then, the mapping taking each a ∈ A to the singleton {h(a)} is a homomorphism from A to ℘(B) and hence (A,B) has the PACC.\nWe use the notation Sing(℘(B)n) to denote the induced substructure of ℘(B)n whose universe contains an n-tuple of ℘(B)n if and only if at least one coordinate of the tuple is a singleton.\nTheorem 10 Let B be a structure. Peek arc consistency solves CSP(B) if and only if for all n ≥ 1 there is a homomorphism Sing(℘(B)n) → B."
    }, {
      "heading" : "3.4 Singleton Arc Consistency",
      "text" : "We now present the singleton arc consistency algorithm. As with arc consistency, this algorithm associates to each element a ∈ A a set Sa of feasible values. It then continually checks, for pairs (a, b) with a ∈ A and b ∈ Sa, whether or not arc consistency can be established with respect to the sets Sa and when a is assigned to b; if for some pair (a, b) it cannot, then b is removed from the set Sa. As with arc consistency, this algorithm’s outer loop runs until the sets Sa stabilize, and the algorithm rejects if one of the sets Sa is equal to the empty set.\nSingleton Arc Consistency Input: a pair (A,B) of similar structures\nforall a ∈ A do set Sa := B; denote A = {a1, . . . , an}; repeat\nforall a ∈ A, b ∈ Sa do if Arc Consistency ([A, {a1}, . . . , {an}, {a}], [B, Sa1, . . . , San , {b}]) rejects then\nremove b from Sa; until no set Sa is changed ; if there exists a ∈ A such that Sa = ∅ then reject ; else return “?”;\nSingleton arc consistency was introduced by Debruyne and Bessiere [16]. We now give a development of singleton arc consistency analogous to that of arc consistency and peek arc consistency.\nDefinition 11 An instance (A,B) has the singleton arc consistency condition (SACC) if there exists a mapping s : A → ℘(B) \\ {∅} such that for all a ∈ A, b ∈ s(a) there exists a homomorphism ha,b : A → ℘(B) where:\n• ha,b(a) = {b}, and\n• for all a′ ∈ A, it holds that ha,b(a′) ⊆ s(a′).\nProposition 12 The singleton arc consistency algorithm does not reject an instance (A,B) if and only if the instance has the SACC.\nProof. Suppose that the singleton arc consistency algorithm does not reject an instance (A,B). Let {Sa}a∈A denote the sets computed by the algorithm at the point of termination, and define s to be the mapping where s(a) = Sa\nfor all a ∈ A. Let a ∈ A and b ∈ s(a). By the definition of the algorithm, the pair ([A, {a1}, . . . , {an}, {a}], [B, Sa1 , . . . , San , {b}]) has the ACC, and thus the desired homomorphism ha,b exists.\nNow, suppose that the instance (A,B) has the SACC, and let s be a mapping with the described properties. We show that throughout the execution of the algorithm, it holds that s(a) ⊆ Sa for all a ∈ A. First, Sa is initialized with B for every a ∈ A. Next, we show that when a ∈ A and b ∈ s(a), then b is never removed from Sa by the algorithm. This is because by definition of SACC, there exists a homomorphism ha,b : A → ℘(B) with ha,b(a) = {b} such that for all a′ ∈ A, it holds that ha,b(a′) ⊆ s(a′). Since s(a′) ⊆ Sa′ by the inductive assumption, ([A, {a1}, . . . , {an}, {a}], [B, Sa1, . . . , San , {b}]) has the ACC and hence the algorithm does not remove b from Sa.\nDefinition 13 Let B be a structure. We say that singleton arc consistency solves CSP(B) if for all structures A, the following holds: (A,B) has the SACC implies that there is a homomorphism A → B.\nThe converse of the condition given in this definition always holds: suppose that h is a homomorphism from A to B. Then, the instance (A,B) has the SACC via the mapping s where s(a) = {h(a)} for all a ∈ A and the mappings ha,b defined by ha,b(a′) = {h(a′)} for all a′ ∈ A.\nWe use the notation UnionSing(℘(B)n) to denote the induced substructure of ℘(B)n whose universe contains an n-tuple (S1, . . . , Sn) of ℘(B)n if and only if it holds that ⋃ i∈[n] Si = ⋃ i∈[n],|Si|=1 Si.\nTheorem 14 Let B be a structure. Singleton arc consistency solves CSP(B) if and only if for all n ≥ 1 there is a homomorphism UnionSing(℘(B)n) → B.\nProof. First we show that if singleton arc consistency solves CSP(B), then there is a homomorphism from UnionSing(℘(B)n) to B for all n ≥ 1. Let n ≥ 1; we show that (UnionSing(℘(B)n),B) has the SACC. Then, there is a homomorphism from UnionSing(℘(B)n) to B, since the singleton arc consistency algorithm solves CSP(B).\nLet s be the mapping s(a) := ⋃ i∈[n] Si for all tuples a = (S1, . . . , Sn) of UnionSing(℘(B) n). Now let us\nconsider an arbitrary tuple a = (S1, . . . , Sn) of UnionSing(℘(B)n) and an arbitrary b ∈ s(a). Since ⋃\ni∈[n] Si = ⋃\ni∈[n],|Si|=1 Si, there is an i ∈ [n] such that {b} = Si. Thus, the homomorphism πi : UnionSing(℘(B)n) → ℘(B) that projects onto the ith coordinate satisfies πi(a) = {b}, and for all tuples a′ of UnionSing(℘(B)n), it holds that πi(a\n′) ⊆ s(a′). Hence, (UnionSing(℘(B)n),B) has the SACC. For the other direction, we show that if there is a homomorphism from UnionSing(℘(B)n) to B for all n ≥ 1, then singleton arc consistency solves CSP(B). Thus, we have to show that there exists a homomorphism from A to B if (A,B) has the SACC. Let s be the homomorphism from the definition of SACC, and let us use {h1, . . . , hn} to denote the set {ha,b | a ∈ A, b ∈ s(a)} of homomorphisms. Further, let g be the homomorphism (h1, . . . , hn) : A → ℘(B)n. Now, for every element a ∈ A the image g(a) = (h1(a), . . . , hn(a)) is a tuple of UnionSing(℘(B)n): for every b ∈ ⋃\nj∈[n] hj(a), it holds that b ∈ s(a) and thus there exists a homomorphism ha,b = hi that maps a to the singleton {b}; so, we have ⋃\nj∈[n] hj(a) = ⋃ i∈[n],|hi(a)|=1 hi(a). Since g is a homomorphism from A to UnionSing(℘(B)n),\nwe can compose g and a homomorphism from UnionSing(℘(B)n) to B, which we know to exist by assumption, to get a homomorphism from A to B. Consequently, singleton arc consistency solves CSP(B)."
    }, {
      "heading" : "4 Strength Comparison",
      "text" : "In this section, we investigate relationships among the sets of structures solvable by the various algorithms presented. We show that for the structures having all constants, AC solves a strictly smaller set of structures than LAAC does; on the other hand, we show that there is a structure (not having all constants) solvable by AC but not LAAC. We then show that the structures solvable by AC or LAAC are strictly contained in those solvable by PAC; and, in turn, that the structures solvable by PAC are strictly contained in those solvable by SAC. We also show that the structures solvable by SAC (and hence, those solvable by any of the studied algorithms) all fall into the class of structures having bounded width; bounded width is a well-studied condition admitting multiple characterizations [18, 22, 6].\nProposition 15 Suppose that B is a structure having all constants. If CSP(B) is solvable by AC, then it is solvable by LAAC.\nProof. By Theorem 4, there is a homomorphism f : ℘(B) → B. Since the structure B has all constants, for each b ∈ B there is a relation symbol Rb with RBb = {(b)}. Since ({b}) ∈ R ℘(B) b , it must hold that f({b}) ∈ R B\nb , from which it follows that f({b}) = b. The mapping l defined by l(S, b) = f(S) is then a homomorphism of the type described in Theorem 6.\nProposition 16 There exists a structure B having all constants such that CSP(B) is solvable by LAAC but not by AC.\nProof. Take B to be the relational structure with universe {0, 1} over signature {U0, U1, R(0,0), R(1,1)} where\nUB0 = {0}\nUB1 = {1}\nRB(0,0) = {0, 1} 2 \\ {(0, 0)}\nRB(1,1) = {0, 1} 2 \\ {(1, 1)}.\nIt is straightforward to verify that the mapping l defined by l({0, 1}, b′) = b′, l({0}, b′) = 0, and l({1}, b′) = 1 for all b′ ∈ {0, 1} is a homomorphism from ℘(B) × B to B satisfying the condition of Theorem 6. Hence, the problem CSP(B) is solvable by LAAC.\nTo show that the problem CSP(B) is not solvable by AC, let f be an arbitrary mapping from ℘(B) \\ {∅} to B. We show that f cannot be a homomorphism from ℘(B) to B, which suffices by Theorem 4. Let b = f({0, 1}). It holds that ({0, 1}, {0, 1}) ∈ R℘(B)(b,b) , but (f({0, 1}), f({0, 1})) = (b, b) /∈ R B (b,b), and we are done.\nProposition 17 There exists a structure B (not having all constants) such that CSP(B) is solvable by AC but not by LAAC.\nProof. Take B to be the relational structure with universe {0, 1} over signature {R,S} where RB = {0, 1}3 \\ {(0, 1, 1)} and SB = {0, 1}3 \\ {(1, 0, 0)}. The mapping p that sends each element of ℘(B) \\ {∅} to 0 is a homomorphism from ℘(B) to B, and hence AC solves CSP(B) by Theorem 4.\nTo show that the problem CSP(B) is not solvable by LAAC, let f be an arbitrary mapping from (℘(B)\\ {∅})×B to B that satisfies f({b}, b′) = b for all b, b′ ∈ B. We show that f cannot be a homomorphism from ℘(B) ×B to B, which suffices by Theorem 6. We consider two cases depending on the value of f({0, 1}, 0).\n• If f({0, 1}, 0) = 1, then we use the facts that ({0}, {0, 1}, {0, 1}) ∈ R℘(B) and that (0, 0, 0) ∈ RB; we have that (f({0}, 0), f({0, 1}, 0), f({0, 1}, 0)) = (0, 1, 1), which is not contained in RB, implying that f is not a homomorphism of the desired type.\n• If f({0, 1}, 0) = 0, then we use the facts that ({1}, {0, 1}, {0, 1}) ∈ S℘(B) and that (0, 0, 0) ∈ SB; we have that (f({1}, 0), f({0, 1}, 0), f({0, 1}, 0)) = (1, 0, 0), which is not contained in SB, implying that f is not a homomorphism of the desired type.\nWe now proceed to study PAC, and in particular, show that the structures solvable by AC or LAAC are solvable by PAC.\nProposition 18 Let B be a structure. If CSP(B) is solvable by AC, then it is also solvable by PAC.\nProposition 18 follows directly from the algebraic characterizations given in Theorems 4 and 10; it can also be seen to follow from the corresponding algorithm descriptions.\nTheorem 19 Let B be a structure. If CSP(B) is solvable by LAAC, then it is also solvable by PAC.\nProof. Suppose that look-ahead arc consistency solves CSP(B). By Theorem 6 there exists a homomorphism l : ℘(B)×B → B such that l({b}, b′) = b for all b, b′ ∈ B. We want to show that peek arc consistency solves CSP(B) by using Theorem 10. Thus, we have to show that for all n ≥ 1 there is a homomorphism gn : Sing(℘(B)n) → B.\nLet n ≥ 1. Let us consider the mapping gn with\ngn(S1, . . . , Sn) = l(S1, l(S2, . . . l(Sn−1, l(Sn, b)) . . .))\ndefined for all tuples T = (S1, . . . , Sn) ∈ Sing(℘(B)n) and all b ∈ B. First we want to show that gn is well defined. Let b1, b2 ∈ B with b1 6= b2, let (S1, . . . , Sn) ∈ Sing(℘(B)n) and let i ∈ [n] be an index such that Si is a singleton. Let Si = {b∗} for a b∗ ∈ B. We obtain that\nl(S1, . . . l(Si−1, l(Si, . . . l(Sn−1, l(Sn, b1)) . . .)) . . .)\n= l(S1, . . . l(Si−1, l(Si, b ′)) . . .)\n= l(S1, . . . l(Si−1, b∗) . . .)\nwith b′ = l(Si+1, . . . l(Sn−1, l(Sn, b1)) . . .) ∈ B, because l is applied to the singleton Si = {b∗} and b′. Similarly, we obtain that\nl(S1, . . . l(Si−1, l(Si, . . . l(Sn−1, l(Sn, b2)) . . .)) . . .)\n= l(S1, . . . l(Si−1, b∗) . . .)\nConsequently, gn is well defined. Next, we prove that gn is a homomorphism. Let RSing(℘(B) n) be a k-ary relation and let (T 1, . . . , T k) be a tuple in this relation. Denote T i = (Si1, S i 2, . . . , S i n) for all i ∈ [k]; then, S ′ j = (S 1 j , . . . , S k j ) has to be in R℘(B) for all j ∈ [n]. Further, we know that there exists a tuple b̄ = (b1, . . . , bk) ∈ RB, because R℘(B) is not empty. Since l is a homomorphism, the tuple\ngn(S ′ 1, S ′ 2, . . . , S ′ n) = l(S ′ 1, l(S ′ 2, . . . l(S ′ n−1, l(S ′ n, b̄)) . . .))\nis in RB. Thus, gn is a homomorphism from Sing(℘(B)n) to B.\nTheorem 20 There exists a structure B having all constants such that CSP(B) is solvable by PAC but not by LAAC nor AC.\nProof. Let us consider the structure with universe {0, 1, 2} over the signature {U0, U1, U2, R1, R2} where\nUB0 = {(0)}\nUB1 = {(1)}\nUB2 = {(2)}\nRB1 = ( {0, 1} × {0, 1, 2} ) \\ {(0, 0)}\nRB2 = {(0, 0), (1, 2), (2, 1)}.\nFirst we show that there is no homomorphism l : ℘(B) × B → B such that l({b}, b′) = b for all b, b′. Let us assume there is one. Since ({0}, {1, 2}) ∈ R℘(B)1 and (1, 0) ∈ R B 1 the tuple (l({0}, 1), l({1, 2}, 0)), which is equal to (0, l({1, 2}, 0)), has to be contained in RB1 . Thus, l({1, 2}, 0) cannot be equal to 0. On the other hand, ({1, 2}, {1, 2}) ∈ R\n℘(B) 2 and (0, 0) ∈ R B 2 implies that (l({1, 2}, 0), l({1, 2}, 0)) is in R B 2 . Therefore, l({1, 2}, 0) has\nto be 0, which is a contradiction. This establishes that the structure is not solvable by LAAC; by Proposition 15, it follows that the structure is not solvable by AC.\nNext we show that for all n, there exists a homomorphism f from Sing(℘(B)n) to B. Let n be arbitrary and let (S1, . . . , Sn) be an arbitrary n-tuple of Sing(℘(B)n). Further, let i be the minimal number such that Si is {1}, {2}, {0, 1} or {0, 2}; if such an Si does not exists, then i = 0. The homomorphism f can be defined as follows:\nf(S1, . . . , Sn) =\n\n \n \n1 if i > 0 and Si is {1} or {0, 1}\n2 if i > 0 and Si is {2} or {0, 2}\n0 otherwise.\nLet us verify that f is indeed a homomorphism: First of all, it is easy to see that f(S1, . . . , Sn) is in UBi whenever (S1, . . . , Sn) is in U Sing(℘(B)n) i . Next, let us consider R2. Let (S1, . . . , Sn) and (T1, . . . , Tn) be arbitrary n-tuples of Sing(℘(B)n) such that (Sl, Tl) is in R ℘(B) 2 for all l. Let i be the minimal number such that Si is {1}, {2}, {0, 1} or {0, 2}, and let j be the minimal number such that Tj is {1}, {2}, {0, 1} or {0, 2}, and if such an Si or Tj does not exists, then i = 0 or j = 0 respectively. If i > 0, then Ti has to be {1}, {2}, {0, 1} or {0, 2} and hence 0 < j ≤ i. Symmetrically, if j > 0, then 0 < i ≤ j. Therefore, i = j. Now, if i = j = 0, then (f(S1, . . . , Sn), f(T1, . . . , Tn)) = (0, 0), which is in RB2 ; if i = j > 0, then (f(S1, . . . , Sn), f(T1, . . . , Tn)) ∈ R B 2 follows directly from (Si, Ti) being in R℘(B)2 . Finally, let us consider two arbitrary n-tuples (S1, . . . , Sn) and (T1, . . . , Tn) of Sing(℘(B) n) such that (Sl, Tl) is in R ℘(B) 1 for all l. If f(S1, . . . , Sn) = 2, then Si = {2} or {0, 2} and (Si, Ti) cannot be in R ℘(B) 1 . If f(S1, . . . , Sn) = 1, then (f(S1, . . . , Sn), f(T1, . . . , Tn)) is in {1} × {0, 1, 2} and, thus, in RB1 . If j = 0, then let k be an index such that Tk = {0}. Such an index has to exist, because (T1, . . . , Tn) is a tuple of Sing(℘(B)n). Since (Sk, Tk) is in R ℘(B) 1 , Sk has to be {1}, and hence f(S1, . . . ., Sn) ∈ {1, 2}, and we appeal to one of the first two cases. The remaining case is i = 0 and j > 0. In this case, (f(S1, . . . , Sn), f(T1, . . . , Tn)) is in {0} × {1, 2} and therefore in RB1 .\nWe now move on to study SAC; we show that SAC is strictly more powerful than PAC.\nProposition 21 Let B be a structure. If CSP(B) is solvable by PAC, then it is also solvable by SAC.\nProposition 21 follows directly from the algebraic characterizations given in Theorems 10 and 14; it can also be seen to follow from the corresponding algorithm descriptions.\nTheorem 22 There exists a structure B having all constants such that CSP(B) is solvable by SAC but not by PAC.\nProof. We will consider a structure that has as a polymorphism the idempotent binary commutative operation ∗ defined on the set {0, 1, 2, 3} by 1 ∗ 2 = 2, 2 ∗ 3 = 3, 3 ∗ 1 = 1, and 0 ∗ a = a for all a ∈ {1, 2, 3}. We consider the structure B with universe {0, 1, 2, 3} over the signature {U0, U1, U2, U3, R1, R2} where we have\nUB0 = {(0)}\nUB1 = {(1)}\nUB2 = {(2)}\nUB3 = {(3)}.\nRB1 = {0, 1, 2, 3} 2 \\ {(0, 0)},\nRB2 = {(1, 2), (2, 3), (3, 1), (0, 0)}\nIt is straightforward to verify that this structure B has the operation ∗ as a polymorphism. The solvability of B follows from Theorem 32, which is proved in the next section; see also the discussion in Example 33.\nTo show that peek arc consistency does not solve CSP(B), we prove that there is no homomorphism from Sing(℘(B)2) to B, which is sufficient by Theorem 10. Define t1 = ({0}, {1, 2, 3}) and t2 = ({1, 2, 3}, {0}). It is straightforward to verify that (t1, t2) ∈ R ℘(B)2 1 ; since each of the tuples t1, t2 contains a singleton, it holds that (t1, t2) ∈ R Sing(℘(B)2) 1 . Assume, for a contradiction, that h is a homomorphism from Sing(℘(B)\n2) to B. It then holds that (h(t1), h(t2)) ∈ RB1 . Since (0, 0) /∈ R B 1 , we have that one of the values h(t1), h(t2) is not\nequal to 0. Let us assume that h(t1) is not equal to 0; the other case is symmetric. Denote h(t1) by b; we have b ∈ {1, 2, 3}. Since each of the two tuples ({0}, {0}), ({1, 2, 3}, {1, 2, 3}) is contained in R℘(B)2 , we have that (({0}, {1, 2, 3}), ({0}, {1, 2, 3})) ∈ R Sing(℘(B)2) 2 . It follows that (b, b) ∈ R B 2 , but since no tuple of the form (c, c) with c ∈ {1, 2, 3} is contained in RB2 , we have reached our contradiction.\nWe close this section by showing that the structures solvable by SAC, and hence those solvable by any of the algorithms studied here, fall into the class of structures having bounded width. We begin by defining bounded width. A partial homomorphism from A to B is a mapping f : A′ → B, where A′ ⊆ A, that defines a homomorphism to B from the substructure of A induced by A′. When f and g are partial homomorphisms we say that g extends f , denoted by f ⊆ g, if Dom(f) ⊆ Dom(g) and f(a) = g(a) for every a ∈ Dom(f).\nDefinition 23 Let k > 1. A k-strategy for an instance (A,B) is a nonempty collection H of partial homomorphisms from A to B satisfying the following conditions:\n1. (restriction condition) if f ∈ H and g ⊆ f , then g ∈ H;\n2. (extension condition) if f ∈ H , |Dom(f)| < k, and a ∈ A, there is g ∈ H such that f ⊆ g and a ∈ Dom(g).\nWhen H is a k-strategy for (A,B) and a1, . . . , aj ∈ A is a sequence, we define Ha1,...,aj ⊆ B j to be the relation\n{(f(a1), . . . , f(aj)) | f ∈ H,Dom(f) = {a1, . . . , aj}}.\nDefinition 24 Let B be a structure and k ≥ 1. We say that CSP(B) has width k if for all structures A the following holds: if there is a (k + 1)-strategy for (A,B) then there is a homomorphism A → B. We say that CSP(B) has bounded width if it has width k for some k ≥ 1.\nProposition 25 Let B be a structure. If CSP(B) is solvable by SAC, then CSP(B) has bounded width.\nProof. Let r be the maximum of all the arities of the signature of B, and set k = max(2, r+1). We shall show that for any instance A of CSP(B), if H is a k-strategy for (A,B), then the instance (A,B) has the SACC, which suffices.\nLet us define the mapping s : A → ℘(B) \\ {∅} as s(a) = Ha. Furthermore, for every a ∈ A, b ∈ s(a), define ha,b : A → ℘(B) \\ {∅} as the mapping ha,b(a′) = {b′ | (b, b′) ∈ Ha,a′}. Note that the extension property of H guarantees that, for every a′ ∈ A, ha,b(a′) is, indeed, nonempty. It follows from the definition of ha,b that ha,b(a) = {b}, and that for all a′ ∈ A, ha,b(a′) ⊆ s(a′).\nIt is only necessary to show that ha,b defines a homomorphism from A to ℘(B). Let RA be any relation in A, let (a1, . . . , ai) ∈ RA, and let Sj = ha,b(aj) for each j ∈ [i]. In order to prove that (S1, . . . , Si) ∈ R℘(B) it suffices to show that for every j ∈ [i] and every bj ∈ Sj , there exists some (c1, . . . , ci) ∈ RB ∩ (S1 × · · · × Si) with cj = bj . This is a direct consequence of the properties of the strategy. Indeed, by the definition of ha,b we know that (b, bj) ∈ Ha,aj and then, by an iterative application of the extension property, we can show that there exists an extension (b, c1, . . . , ci) ∈ Ha,a1,...,ai with cj = bj . The fact that H contains only partial homomomorphisms guarantees that (c1, . . . , ci) ∈ RB. Finally, it follows from the restriction condition that for every l ∈ [i], we have cl ∈ Sl."
    }, {
      "heading" : "5 Tractability via singleton arc consistency",
      "text" : ""
    }, {
      "heading" : "5.1 Majority operations",
      "text" : "An operation m : B3 → B is a majority operation if it satisfies the identity m(x, y, y) = m(y, x, y) = m(y, y, x) = y for all x, y ∈ B. Relative to a majority operation m : B3 → B, when I ⊆ J ⊆ B, we say that I is an ideal of J if for every x, y, z ∈ J such that x, z ∈ I we have m(x, y, z) ∈ I . We will establish the following result.\nTheorem 26 If B is a structure that has a majority polymorphism, then singleton arc consistency solves CSP(B).\nThe proof is obtained by using a strengthened version of the Prague strategy defined by Barto and Kozik [6]. In this section, for the sake of readability, we will typically use the notation t[i] to denote the ith entry of a tuple t. We introduce the following definitions relative to an instance (A,B) with signature σ. A pattern p of A is a sequence a1, e1, a2, . . . , em−1, am such that a1, . . . , am are elements of A and for every n ∈ [m− 1], we have that en is a triple (R, i, j) where R is a symbol in σ and i, j are indices such that there is a tuple t ∈ RA with t[i] = an and t[j] = an+1. The length of pattern p is defined to be m. A pattern is a cycle if a1 = am. By a set system, we mean any mapping H : A → ℘(B) \\ {∅}.\nA pattern q = b1, e′1, . . . , e ′ m−1, bm of B having the same length as a pattern p of A is a realization of p if en = e ′ n for all n ∈ [m− 1]. The pair (b1, bm) is said to be a support of p. For a set system H , if it holds that bn ∈ H(an) for all n ∈ [m] then (b1, bm) is said to be a support of p inside H .\nA set system H is a weak strategy if for every pattern p = a1, e1, . . . , em−1, am of A, and every b1 ∈ H(a1) there exists some bm ∈ H(am) such that (b1, bm) supports p inside H . A set system H is a strong strategy if for every cycle p = (a = a1, . . . , am = a) in A and every b ∈ H(a), the pair (b, b) supports p inside H . Note that every strong strategy is a weak strategy and that the class of weak strategies remains the same if, in the definition of weak strategy, one replaces “every pattern p = a1, e1, . . . , em−1, am” by “every pattern p = a1, e1, . . . , em−1, am of length m = 2”.\nObservation 1 Every strong strategy is a weak strategy, relative to an instance (A,B).\nProof. For a pattern p = a1, e1, . . . , em−1, am of A, one needs only to apply the definition of strong strategy to the the pattern a1, e1, . . . , em−1, am, e −1 m−1, am−1, . . . , e −1 1 , a1, where (R, i, j) −1 is defined to be (R, j, i).\nLemma 27 There exists a strong strategy for an instance (A,B) having the SACC.\nProof. Let s : A → ℘(B) \\ {∅}, {ha,b} be the mappings witnessing that (A,B) has the SACC. We claim that the set system H defined by H(a) = s(a) for all a ∈ A is a strong strategy. Indeed, let p = a1, e1, . . . , am be a pattern of A with a1 = am = a and let b ∈ H(a1). We claim that there exists a realization b1, e1, . . . , bm of p with b1 = bm = b such that for every 1 ≤ n ≤ m, bn ∈ ha,b(an). The realization is constructed in an inductive manner. First, set b1 to b. Assume now that bn−1 is already set and let en−1 be (R, i, j). There exists a tuple (x1, . . . , xr) ∈ RA such that xi = an−1 and xj = an. Since ha,b is a homomorphism, the subset S ⊆ Br defined by πlS = ha,b(xl) for every 1 ≤ l ≤ r is a subset of RB. From bn−1 ∈ ha,b(xi) it follows that there exists a tuple (y1, . . . , yr) ∈ S with yi = bn−1. Define bn to be yj . Since, by definition of SACC strategy ha,b(a) = {b}, it follows that bm = b.\nWe now prove the following lemma, which, as we explain after the proof, essentially establishes the desired theorem. In the course of proving this lemma, we establish a number of observations.\nBy a minimal strong strategy, we mean minimal with respect to the ordering where for two strategies H,H ′, we consider H ⊆ H ′ if H(a) ⊆ H ′(a) for all a ∈ A.\nLemma 28 If the relations of B are invariant under a majority operation φ and H is a minimal strong strategy then for every a ∈ A, the set H(a) is a singleton.\nProof. Towards a contradiction assume that H is a minimal strong strategy and a∗ ∈ A is such that H(a∗), is not a singleton. Consider the digraph G whose nodes are of the form (a, C) with a ∈ A and C ⊆ H(a), and there is an edge from (a, C) to (a′, C′) if there is a pattern p = a1, . . . , am with a = a1 and a′ = am in A such that the following holds: C′ is the set containing all b′ ∈ H(a′) such that (b, b′) is supported by p inside H for some b ∈ C.\nObservation 2 Let p = a1, e1, . . . , am be a pattern, let 1 < i < m, let q be the pattern a1, e1, . . . , ai and r be the pattern ai, ei . . . , em. If q defines an edge from (a1, C1) to (ai, Ci) and r defines an edge from (ai, Ci) to (am, Cm) then p defines an edge from (a1, C1) to (am, Cm). Hence, the graph G is transitive.\nThe following observation follows from the definition of strong strategy.\nObservation 3 If there is an edge from (a, C) to (a, C′) in G, then necessarily C ⊆ C′.\nObservation 4 If there is an edge from (a, C) to (a′, C′) in G, and C is an ideal of H(a), then C′ is an ideal of H(a′).\nProof (Observation 4). Let us prove the claim by induction on the length m of the pattern that defines the edge. Assume first that m = 2. Let a, (R, i, j), a′ be any such pattern. Let x1, x2, x3 ∈ H(a′) and assume that two of them, say x1, x3, belong toC′. It follows, by the definition of edge, that for everyn ∈ {1, 3} there exists tuple tn ∈ RB with tn[j] = xn and tn[i] ∈ C. Also, it follows by considering pattern a′, (R, j, i), a and from the fact that H is a weak strategy that there exists a tuple t2 ∈ RB with t2[i] ∈ H(a) and t2[j] = x2. Consider now tuple t = φ(t1, t2, t3). Since C is an ideal of H(a) we have that t[i] ∈ C. Hence, we conclude that φ(x1, x2, x3) = t[j] ∈ C′.\nThe case m > 2 follows from the inductive hypothesis and Observation 2.\nNow, let G′ be the subgraph of G induced by all nodes (a, C) such that C is an ideal of H(a) and C 6= H(a). Observe that as H(a∗) is not a singleton, the graph G′ is nonempty, because every singleton is an ideal.\nA subset M of vertices of a directed graph is a strongly connected component if for every pair (v, w) ∈ M2 there exists a path from v to w consisting only of vertices in M . It is a maximal strongly connected component if additionally, there is no edge (v, w) with v ∈ M and w 6∈ M .\nLet M be a maximal strongly connected component of G′. The following observation is a direct consequence of Observations 2 and 3.\nObservation 5 The maximal strongly connected component M cannot have two vertices (a, C), (a, C′) with C 6= C′.\nWe shall construct a new strong strategy H ′ as follows. If (a, C) belongs to M , then set H ′(a) = C otherwise set H ′(a) = H(a). Clearly H ′ is strictly smaller than H .\nWe shall start by showing that H ′ is a weak strategy. By the note following the definition of weak strategy it is only necessary to show that for every pattern p = a1, e1, a2 of length 2 of A and every b1 ∈ H ′(a1), there exists a support (b1, b2) of p inside H ′.\nWe do a case analysis. If (a2, H ′(a2)) does not belong to M the claim follows from the fact that H is a weak strategy. Assume now that (a2, H ′(a2)) belongs to M . Consider the pattern p = a2, e −1 1 , a1 where (R, i, j)\n−1 = (R, j, i). This pattern defines an edge (in G) from (a2, H ′(a2)) to a node (a1, C). Observe, that by the definition of the edges of G, we know that for every element b ∈ C there is some b′ ∈ H ′(a2) such that (b, b′) is supported by p inside H . Hence we only need to show that H ′(a1) ⊆ C.\nIf (a1, C) is in G′ then, since M is a maximal strongly connected component of G′, we have that (a1, C) belongs to M as well and hence C = H ′(a1). If (a1, C) is not in G′ this must be because C is not an ideal of H(a1) or because C = H(a1). We can rule out the first possibility in the following way: by the definitions of G′ and H ′, H ′(a2) is an ideal of H(a2). It follows by observation 4 that C is an ideal of H(a1). In consequence C = H(a1) and the proof that H ′ is a weak strategy is concluded.\nIt remains to show that H ′ is a strong strategy. Let p = a1, e1, . . . , em−1, am be any cycle in A with a1 = am = a and let b be any element in H ′(a). Since H ′ is a weak strategy we know that there is a realization b1, . . . , bm of p with b1 = b inside H ′. Notice that we do not necessarily have bm = b. Symmetrically, by considering pattern am, e −1 m−1, . . . , e −1 1 , a1 we know that there is a realization dm, e −1 m−1, . . . , e −1 1 , d1 of p with dm = b inside H\n′. Also, since H is a strong strategy we know that there exists a realization c1, e1, . . . , cm of p such that c1 = cm = b inside H (but not necessarily inside H ′). Finally consider the sequence x1, . . . , xm defined by xj = φ(bj , cj , dj), 1 ≤ j ≤ m. This sequence is a realization of p. Furthermore, we have that x1 = xm = b. It remains to show that it is inside H ′. Indeed, for every 1 ≤ j ≤ m, {bj, dj} ⊆ H ′(aj) and cj ∈ H(aj). Since H ′(aj) is an ideal of H(aj) the claim follows.\nProof. (Theorem 26) Suppose that the instance (A,B) has the SACC and that B has the majority polymorphism φ. By Lemmas 27 and 28 there exists a strong strategy H for (A,B) such that H(a) is a singleton for every a ∈ A. Consider now the mapping h : A → B that maps every a ∈ A to the only element in H(a). We claim that h is a homomorphism from A to B. Indeed, let R be any relation symbol, and (a1, . . . , ar) be any tuple in RA. Fix any 1 ≤ i, j ≤ r and consider pattern ai, (R, i, j), aj . It follows by the definition of strong strategy that there is a t ∈ RB such that t[i] = h(i) and t[j] = h(j). Since RB is necessarily 2-decomposable [20], h is a homomorphism."
    }, {
      "heading" : "5.2 2-semilattice operations",
      "text" : "A 2-semilattice G = (G, ⋆) consists of a set G, which in this paper we assume to be finite, and a binary operation ⋆ satisfying x⋆x = x (idempotency), x⋆y = y⋆x (commutativity), and x⋆(x⋆y) = (x⋆x)⋆y (restricted associativity).\nEach 2-semilattice naturally induces a directed graph (G,E) where (a, b) ∈ E if and only if a ⋆ b = b. When (a, b) ∈ E, we also write a ≤ b. The graph (G,E) is connected, since a⋆ (a⋆ b) = b ⋆ (a⋆ b) = a⋆ b for any a, b ∈ G, and therefore, a, b ≤ a ⋆ b. Each 2-semilattice has a unique maximal strongly connected component, that is a strongly connected component with no outgoing edges, denoted by G. The component G is also the unique strongly connected component of (G,E) such that for any a ∈ G, there exists b ∈ G such that a ≤ b. In this section, we will prove that a certain class of 2-semilattices is tractable via singleton arc consistency. Our treatment of 2-semilattices is inspired and influenced by the study conducted by Bulatov [10], who proved that they are polynomial-time tractable.\nA 2-semilattice G = (G, ⋆) is an algebra. By an algebra, we mean a pair (A,O) consisting of a set A, the universe of the algebra, and a set O of operations on A. A congruence of an algebra is an equivalence relation preserved by the operation(s) of the algebra, and an algebra is simple if its only congruences are trivial (that is, if its only congruences are the equality relation on A and A×A, where A is the universe of the algebra).\nWe will begin by proving some general results on singleton arc consistency. In the following discussion, a subalgebra is defined, with respect to a relational structure B, as a subset S ⊆ B that is preserved by all polymorphisms of B. For an arbitrary subset T ⊆ B, we use 〈T 〉 to denote the smallest subalgebra containing T .\nProposition 29 Suppose that g1, . . . , gk : A → ℘(B) are homomorphisms, and suppose that f : Bk → B is a polymorphism of B. Then the map g : A → ℘(B) \\ {∅} defined by g(a) = f(g1(a), . . . , gk(a)) for all a ∈ A is a homomorphism A → ℘(B).\nFor an operation f : Bk → B and a sequence of subsets B1, . . . , Bk ⊆ B, by the notation f(B1, . . . , Bk), we denote the set {f(b1, . . . , bk) | b1 ∈ B1, . . . , bk ∈ Bk}. Regarding this notation, it is easy to verify that f can be understood as a polymorphism of ℘(B) if f is a polymorphism of B. Proposition 29 follows straightforwardly from the definitions.\nProposition 30 Suppose that h : A → ℘(B) is a homomorphism. Then the map h′ defined by h′(a) = 〈h(a)〉 for all a ∈ A is also a homomorphism A → ℘(B).\nProof. Repeatedly apply Proposition 29 with a polymorphism f and g1 = · · · = gk = h, each time taking the resulting g and updating h to be h ∪ g. Note that at each step, the new h is a homomorphism A → ℘(B), since the union operation ∪ is a polymorphism of ℘(B). When no changes can be made, the resulting h is the desired h′.\nLet us say that a CSP instance (A,B) has the subalgebra SACC if (A,B) has the SACC relative to mappings s, {ha,b} such that for all a ∈ A, the set s(a) is a subalgebra, and for all a, a′ ∈ A, b ∈ s(a), the set ha,b(a′) is a subalgebra.\nProposition 31 If a pair (A,B) of similar structures has the SACC, and all polymorphisms of B are idempotent, then it has the subalgebra SACC.\nProof. Suppose that (A,B) has the SACC with respect to the mappings s, {ha,b}. Set s′(a) = 〈s(a)〉 for all a ∈ A, and h′a,b(a ′) = 〈ha,b(a ′)〉 for all a, a′ ∈ A, b ∈ s(a). Clearly, for all such a, a′, b we have h′a,b(a\n′) ⊆ s′(a′), and also, that h′a,b is a homomorphism A → ℘(B) (by Proposition 30). Let b be an element in s\n′(a) \\ s(a) for some a ∈ A. We need to show that there exists a homomorphism h′a,b that satisfies the two conditions of Definition 11 with respect to s′, and that also satisfies the subalgebra condition. As s′(a) is defined as 〈s(a)〉, it holds that s′(a) = {f(b1, . . . , bk) | f a polymorphism of B; b1, . . . , bk ∈ s(a)}; the containment ⊇ is clear by definition of subalgebra, and the containment ⊆ follows from the fact that the right hand side is a subalgebra, which in turn follows from the fact that the set of polymorphisms of B forms a clone and is closed under composition [23]. Thus, there exists a polymorphism f of B and elements b1, . . . , bk ∈ s(a) such that b = f(b1, . . . , bk). Let g′a,b be the homomorphism obtained from Proposition 29 with gi = ha,bi and f . Set h ′ a,b(a ′) = 〈g′a,b(a ′)〉 for all a′ ∈ A. The homomorphism h′a,b has the desired properties.\nWe now turn to prove our tractability result. We will now use the term subalgebra to refer to a subalgebra of a 2-semilattice (B, ⋆), that is, a subset of B preserved by ⋆. Note, however, that we will be working with a relational structure B assumed to have ⋆ as a polymorphism, so a subalgebra in the previous sense (that is, with respect to B) will also be a subalgebra in this sense. An algebra (B, ⋆) having a binary operation is conservative if for all b, b′ ∈ B, it holds that b ⋆ b′ ∈ {b, b′}. The following is the statement of our tractability result.\nTheorem 32 Let (B, ⋆) be a conservative 2-semilattice such that every strongly connected subalgebra is simple. If B is a structure having ⋆ as a polymorphism, then singleton arc consistency solves CSP(B).\nExample 33 We consider the binary operation ∗ on {0, 1, 2, 3} defined by the following table.\n* 0 1 2 3 0 0 1 2 3 1 1 1 2 1 2 2 2 2 3 3 3 1 3 3\nIt is straightforward to verify that this operation is commutative and conservative, and is a 2-semilattice. The graph induced by this operation has edges (0, 1), (0, 2), (0, 3), (1, 2), (2, 3), (3, 1), as well as self-edges on each of the vertices. There is thus just one strongly connected component of size strictly greater than one, namely, the component {1, 2, 3}. This is a subalgebra of the algebra ({0, 1, 2, 3}, ∗) and is readily verified to be simple. Hence, the tractability via singleton arc consistency of any structure preserved by the operation ∗ follows from Theorem 32.\nWe will make use of the following results. For our purposes here, a subdirect product of algebras A1, . . . ,Ak is a subalgebra S of A1 × · · · ×Ak such that for each i ∈ [k], it holds that πiS = Ai.\nLemma 34 Suppose that S is a subdirect product of 2-semilattices S1, . . . , Sn. Then S∩(S1×· · ·×Sn) is a subdirect product of S1, . . . , Sn.\nProof. Immediate from [10, Lemma 3.2].\nDefinition 35 A relation S ⊆ Bn is almost trivial if there exists a partition I1, . . . , Ik of [n] such that\n• t ∈ S if and only if for all i ∈ [k], it holds that πIi t ∈ πIiS; and,\n• for each j ∈ [k], it holds that πIjS has the form {(π1(p), π2(p), . . . , πm(p)) | p ∈ [q]} for some q ≥ 1 and where each mapping πi is a bijection from [q] to a subset of B.\nProposition 36 A subdirect product of simple strongly connected 2-semilattices is an almost trivial relation, and is hence itself strongly connected.\nProof. Immediate from [10, Proposition 3.1].\nProposition 37 Let (A,B) be an instance that has the SACC with respect to s : A → ℘(B) \\ {∅}. If for each tuple (a1, . . . , ak) ∈ RA, it holds that RB ∩ (s(a1)× · · · × s(ak)) is almost trivial, then there is a homomorphism from A to B.\nProof. Consider the following graph G = (A,E), where {a, b} ∈ E if and only if there is a relation RA in A, and, if I1, . . . , Ik is its partition regarding almost triviality of RB ∩ (s(a1) × · · · × s(ak)), there further is an l ∈ [k] and a tuple (a1, . . . , am) ∈ RAIl such that there are i, j with a = ai and b = aj . For each connected component C of the graph G arbitarily choose a ∈ C and b ∈ s(a). Since arc consistency can be established when a is set to b and using the structure of the projected relations RBIl , there exists a unique extension of a 7→ b to a homomorphism on C. Because of the first property of Definition 35 the homomorphisms on the single components can be combined to a homomorphism on A.\nThe following is the main result used to prove Theorem 32.\nTheorem 38 Suppose that B satisfies the hypotheses of Theorem 32, and suppose that (A,B) has the subalgebra SACC via s : A → ℘(B)\\{∅}. Then, (A,B) has the SACC via the map s′ : A → ℘(B)\\{∅} defined by s′(a) = s(a) for all a ∈ A.\nProof. Let a ∈ A and b ∈ s(a). By hypothesis, there exists a homomorphism h : A → ℘(B) where h(a) = {b} and for all a′ ∈ A, it holds that h(a′) ⊆ s(a′). We want to show that there exists a homomorphism h′ : A → ℘(B) where h′(a) = {b} and for all a′ ∈ A, it holds that h′(a′) ⊆ s′(a′). Define h′(a) as h(a) if h(a) ∩ s′(a) 6= ∅, and as s′(a) otherwise. Observe that in the first case, we have h′(a) = h(a) ⊆ s′(a), and that in both cases, the subset h′(a) is a subalgebra.\nWe claim that h′ is a homomorphism from A to ℘(B). Let a ∈ RA be a tuple in A. For the sake of notation, we assume that a = (a1, . . . , ak+l), I = {1, . . . , k}, J = {k + 1, . . . , k + l}, and that I contains exactly the coordinates i ∈ [k + l] such that h(ai) ∩ s′(ai) 6= ∅, so that h′(ai) = h(ai) for all i ∈ I and h′(aj) = s′(aj) for all j ∈ J . Let T = (πIRB ∩ (s(a1)× · · · × s(ak))) ∩ (s(a1)× · · · × s(ak)). By Lemma 34, we have that relation T is a subdirect product of s(a1), . . . , s(ak). Further, let W = (RB ∩ (s(a1)× · · · × s(ak+l))) ∩ (s(a1)× · · · × s(ak+l)). By Lemma 34, we have that W is a subdirect product of s(a1), . . . , s(ak+l). Clearly, πIW ⊆ T . We show that T ⊆ πIW (and hence that T = πIW ), as follows. Let t be a tuple in T . Let w be a tuple in W (such a tuple can be obtained, for instance, by ⋆-multiplying together all tuples of RB ∩ (s(a1) × · · · × s(ak+l)), in any order). By our assumption on B and by Proposition 36, there is a sequence of tuples u1, . . . , um in T such that πIw ≤ u1 ≤ · · · ≤ um = t. We hence have tuples v1, . . . , vm with vi ∈ RB ∩ (s(a1)× · · · × s(ak+l)) and πIvi = ui for each i ∈ [m]. The product (· · · ((w ⋆ v1) ⋆ v2) ⋆ · · · ⋆ vm) gives a tuple in W whose projection onto I is t.\nBy Proposition 36, it holds that W is almost trivial with respect to a partition {Ii}. Remove from the Ii any coordinates l such that s′(al) has just one element. We now show that the resulting partition {Ii} has the property that each Ii is a subset of either I or J . By the homomorphism h and its subalgebra property, there exists a tuple (t, x) ∈ RB such that t ∈ T and xj /∈ s(aj) for all j ∈ J (just multiply all tuples in RB ∩ (h(a1)× · · · × h(ak+l))). By the fact that T ⊆ πIW , we have a tuple (t, u) ∈ W . By the strong connectedness of W (Proposition 36), there is a tuple (t′, u′) ∈ W that is distinct from (t, u) at each coordinate in ∪Ii and such that (t′, u′) ⋆ (t, u) = (t, u). We also have (t′, u′) ⋆ (t, x) = (t, u′); note that u′ ⋆ x = u′ by conservativity of ⋆. As u and u′ differ at every coordinate in J ∩ (∪Ii), the claim follows.\nAs a consequence of this last result, for any tuple t ∈ πIW and any tuple u ∈ πJW , it holds that (t, u) ∈ W . Further it holds that (πIRB∩(h(a1)×· · ·×h(ak)))∩(h′(a1)×· · ·×h′(ak)) is a subdirect product of h′(a1), . . . , h′(ak) (Lemma 34), and we have that h′ is a homomorphism from A to ℘(B).\nProof. (Theorem 32) Suppose that (A,B) has the SACC. By Proposition 31, the instance (A,B) has the subalgebra SACC. By Theorem 38, (A,B) has the SACC via a mapping s′ where for all a ∈ A, it holds that s′(a) is a strongly connected subalgebra. By assumption, each such s′(a) is simple, and it follows from Propositions 36 and 37 that there is a homomorphism from A to B."
    }, {
      "heading" : "6 Discussion",
      "text" : "In this work, we performed a systematic study of arc consistency and three simple, natural extensions thereof. We performed a comparison of the studied consistency notions based on constraint languages, and proved positive tractability results for singleton arc consistency.\nAtserias and Weyer [5] gave a uniform treatment of AC, PAC, SAC, and general consistency. Among other results, they show that it can be decided, given a constraint language and any pair of the previous consistency methods, whether it is true that the set of instances that passes one of the consistency tests coincides with the set of instances that passes the other. Their results combined with the fact that general consistency/bounded width is decidable [6] implies that it can be decided whether or not a given constraint language is solvable by any of the other methods.\nWe conclude by posing one question for future work. Barto and Kozik [6] have recently characterized all languages solvable by bounded width. Can all such languages be solvable by singleton arc consistency, or are there bounded width languages not solvable by singleton arc consistency? Resolving this question in the positive would seem to yield an interesting alternative characterization of the bounded width languages.\nAcknowledgements. The authors thank Manuel Bodirsky for his comments and collaboration. The authors also thank Johan Thapper for his many useful comments."
    } ],
    "references" : [ {
      "title" : "On the power of k-consistency",
      "author" : [ "A. Atserias", "A. Bulatov", "V. Dalmau" ],
      "venue" : "In Proceedings of 34th International Colloquium on Automata, Languages and Programming (ICALP),",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 2007
    }, {
      "title" : "Affine systems of equations and counting infinitary logic",
      "author" : [ "A. Atserias", "A. Bulatov", "A. Dawar" ],
      "venue" : "Theoretical Computer Science,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2009
    }, {
      "title" : "Clause-learning algorithms with many restarts and bounded-width resolution",
      "author" : [ "A. Atserias", "J.K. Fichte", "M. Thurley" ],
      "venue" : "In Proceedings of 12th International Conference on Theory and Applications of Satisfiability Testing (SAT),",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2009
    }, {
      "title" : "Constraint propagation as a proof system",
      "author" : [ "A. Atserias", "P.G. Kolaitis", "M.Y. Vardi" ],
      "venue" : "In Proceedings of 10th International Conference on Principles and Practice of Constraint Programming (CP),",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2004
    }, {
      "title" : "Decidable relationships between consistency notions for constraint satisfaction problems",
      "author" : [ "A. Atserias", "M. Weyer" ],
      "venue" : "In Proceedings of 18th Annual Conference of the European Association for Computer Science Logic (CSL),",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2009
    }, {
      "title" : "Constraint satisfaction problems of bounded width",
      "author" : [ "L. Barto", "M. Kozik" ],
      "venue" : "In Proceedings of the 50th Annual IEEE Symposium on Foundations of Computer Science,",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2009
    }, {
      "title" : "Theoretical analysis of singleton arc consistency and its extensions",
      "author" : [ "C. Bessiere", "R. Debruyne" ],
      "venue" : "Artificial Intelligence,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2008
    }, {
      "title" : "Peek arc consistency",
      "author" : [ "M. Bodirsky", "H. Chen" ],
      "venue" : "Theoretical Computer Science,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2010
    }, {
      "title" : "Results on the algebraic approach to the csp",
      "author" : [ "A. Bulatov", "M. Valeriote" ],
      "venue" : "In Complexity of Constraints: An Overview of Current Research Themes,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2008
    }, {
      "title" : "Combinatorial problems raised from 2-semilattices",
      "author" : [ "A.A. Bulatov" ],
      "venue" : "Journal of Algebra,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2006
    }, {
      "title" : "Optimal implementation of conjunctive queries in relational data bases",
      "author" : [ "A.K. Chandra", "P.M. Merlin" ],
      "venue" : "In Proceddings of STOC’77,",
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 1977
    }, {
      "title" : "Smart) look-ahead arc consistency and the pursuit of CSP tractability",
      "author" : [ "H. Chen", "V. Dalmau" ],
      "venue" : "In Proceedings of CP’04,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2004
    }, {
      "title" : "Linear datalog and bounded path duality of relational structures",
      "author" : [ "V. Dalmau" ],
      "venue" : "Logical Methods in Computer Science,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2005
    }, {
      "title" : "Majority constraints have bounded pathwidth duality",
      "author" : [ "V. Dalmau", "A. Krokhin" ],
      "venue" : "European Journal on Combinatorics,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2008
    }, {
      "title" : "Closure functions and width 1 problems",
      "author" : [ "V. Dalmau", "J. Pearson" ],
      "venue" : "Proceedings of CP’99,",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 1999
    }, {
      "title" : "Some practicable filtering techniques for the constraint satisfaction problem",
      "author" : [ "R. Debruyne", "C. Bessiere" ],
      "venue" : "In Proceedings IJCAI’97,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 1997
    }, {
      "title" : "On 2-sat and renamable horn",
      "author" : [ "A. del Val" ],
      "venue" : "AAAI/IAAI",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2000
    }, {
      "title" : "The computational structure of monotone monadic SNP and constraint satisfaction: A study through Datalog and group theory",
      "author" : [ "T. Feder", "M. Vardi" ],
      "venue" : "SIAM Journal on Computing,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 1999
    }, {
      "title" : "Tractability and learnability arising from algebras with few subpowers",
      "author" : [ "P.M. Idziak", "P. Markovic", "R. McKenzie", "M. Valeriote", "R. Willard" ],
      "venue" : "In Proceedings of LICS’07,",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2007
    }, {
      "title" : "Constraints, consistency and closure",
      "author" : [ "P. Jeavons", "D. Cohen", "M. Cooper" ],
      "venue" : "AI, 101(1-2):251–265,",
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 1998
    }, {
      "title" : "Universal algebra and hardness results for constraint satisfaction problems",
      "author" : [ "B. Larose", "P. Tesson" ],
      "venue" : "Theoret. Comput. Sci.,",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2009
    }, {
      "title" : "Bounded width problems and algebras",
      "author" : [ "B. Larose", "L. Zádori" ],
      "venue" : "Algebra Universalis,",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2007
    }, {
      "title" : "Clones in Universal Algebra, volume 99 of Seminaires de Mathematiques Superieures",
      "author" : [ "A. Szendrei" ],
      "venue" : "University of Montreal,",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 1986
    } ],
    "referenceMentions" : [ {
      "referenceID" : 17,
      "context" : "In this paper, we work with the formulation as the relational homomorphism problem: given two similar relational structures A and B, does there exist a homomorphism from A to B? In this formulation, one can view each relation of A as containing variable tuples that are constrained together, and the corresponding relation of B as containing the permissible values for the variable tuples [18].",
      "startOffset" : 389,
      "endOffset" : 393
    }, {
      "referenceID" : 8,
      "context" : "One of the primary current research threads involving such problems is to understand for which finite-universe constraint languages B the problem CSP(B) is polynomial-time tractable [9]; there is also work on characterizing the languages B for which the problem CSP(B) is contained in lower complexity classes such as L (logarithmic space) and NL (non-deterministic logarithmic space) [13, 21].",
      "startOffset" : 182,
      "endOffset" : 185
    }, {
      "referenceID" : 12,
      "context" : "One of the primary current research threads involving such problems is to understand for which finite-universe constraint languages B the problem CSP(B) is polynomial-time tractable [9]; there is also work on characterizing the languages B for which the problem CSP(B) is contained in lower complexity classes such as L (logarithmic space) and NL (non-deterministic logarithmic space) [13, 21].",
      "startOffset" : 385,
      "endOffset" : 393
    }, {
      "referenceID" : 20,
      "context" : "One of the primary current research threads involving such problems is to understand for which finite-universe constraint languages B the problem CSP(B) is polynomial-time tractable [9]; there is also work on characterizing the languages B for which the problem CSP(B) is contained in lower complexity classes such as L (logarithmic space) and NL (non-deterministic logarithmic space) [13, 21].",
      "startOffset" : 385,
      "endOffset" : 393
    }, {
      "referenceID" : 18,
      "context" : "With such aims providing motivation, there have been efforts to characterize the languages amenable to solution by certain algorithmic techniques, notably, representing solution spaces by generating sets [19] and consistency methods [22, 2, 6], which we now turn to discuss.",
      "startOffset" : 204,
      "endOffset" : 208
    }, {
      "referenceID" : 21,
      "context" : "With such aims providing motivation, there have been efforts to characterize the languages amenable to solution by certain algorithmic techniques, notably, representing solution spaces by generating sets [19] and consistency methods [22, 2, 6], which we now turn to discuss.",
      "startOffset" : 233,
      "endOffset" : 243
    }, {
      "referenceID" : 1,
      "context" : "With such aims providing motivation, there have been efforts to characterize the languages amenable to solution by certain algorithmic techniques, notably, representing solution spaces by generating sets [19] and consistency methods [22, 2, 6], which we now turn to discuss.",
      "startOffset" : 233,
      "endOffset" : 243
    }, {
      "referenceID" : 5,
      "context" : "With such aims providing motivation, there have been efforts to characterize the languages amenable to solution by certain algorithmic techniques, notably, representing solution spaces by generating sets [19] and consistency methods [22, 2, 6], which we now turn to discuss.",
      "startOffset" : 233,
      "endOffset" : 243
    }, {
      "referenceID" : 21,
      "context" : "Checking for consistency is a primary reasoning technique for the practical solution of the CSP, and has been studied theoretically from many viewpoints [22, 2, 4, 1, 3, 6, 5].",
      "startOffset" : 153,
      "endOffset" : 175
    }, {
      "referenceID" : 1,
      "context" : "Checking for consistency is a primary reasoning technique for the practical solution of the CSP, and has been studied theoretically from many viewpoints [22, 2, 4, 1, 3, 6, 5].",
      "startOffset" : 153,
      "endOffset" : 175
    }, {
      "referenceID" : 3,
      "context" : "Checking for consistency is a primary reasoning technique for the practical solution of the CSP, and has been studied theoretically from many viewpoints [22, 2, 4, 1, 3, 6, 5].",
      "startOffset" : 153,
      "endOffset" : 175
    }, {
      "referenceID" : 0,
      "context" : "Checking for consistency is a primary reasoning technique for the practical solution of the CSP, and has been studied theoretically from many viewpoints [22, 2, 4, 1, 3, 6, 5].",
      "startOffset" : 153,
      "endOffset" : 175
    }, {
      "referenceID" : 2,
      "context" : "Checking for consistency is a primary reasoning technique for the practical solution of the CSP, and has been studied theoretically from many viewpoints [22, 2, 4, 1, 3, 6, 5].",
      "startOffset" : 153,
      "endOffset" : 175
    }, {
      "referenceID" : 5,
      "context" : "Checking for consistency is a primary reasoning technique for the practical solution of the CSP, and has been studied theoretically from many viewpoints [22, 2, 4, 1, 3, 6, 5].",
      "startOffset" : 153,
      "endOffset" : 175
    }, {
      "referenceID" : 4,
      "context" : "Checking for consistency is a primary reasoning technique for the practical solution of the CSP, and has been studied theoretically from many viewpoints [22, 2, 4, 1, 3, 6, 5].",
      "startOffset" : 153,
      "endOffset" : 175
    }, {
      "referenceID" : 11,
      "context" : "The extensions of AC that we study are look-ahead arc consistency (LAAC) [12]; peek arc consistency (PAC) [8], and singleton arc consistency (SAC) [16, 7].",
      "startOffset" : 73,
      "endOffset" : 77
    }, {
      "referenceID" : 7,
      "context" : "The extensions of AC that we study are look-ahead arc consistency (LAAC) [12]; peek arc consistency (PAC) [8], and singleton arc consistency (SAC) [16, 7].",
      "startOffset" : 106,
      "endOffset" : 109
    }, {
      "referenceID" : 15,
      "context" : "The extensions of AC that we study are look-ahead arc consistency (LAAC) [12]; peek arc consistency (PAC) [8], and singleton arc consistency (SAC) [16, 7].",
      "startOffset" : 147,
      "endOffset" : 154
    }, {
      "referenceID" : 6,
      "context" : "The extensions of AC that we study are look-ahead arc consistency (LAAC) [12]; peek arc consistency (PAC) [8], and singleton arc consistency (SAC) [16, 7].",
      "startOffset" : 147,
      "endOffset" : 154
    }, {
      "referenceID" : 17,
      "context" : "Tractability results for constraint languages have been presented for AC by Feder and Vardi [18] (for instance); and for LAAC and PAC in the previously cited work.",
      "startOffset" : 92,
      "endOffset" : 96
    }, {
      "referenceID" : 19,
      "context" : "The presence of a majority polymorphism is a robust and well-studied condition: majority polymorphisms were used to give some of the initial language tractability results, are known to exactly characterize the languages such that 3-consistency implies global consistency (we refer to [20] for definitions and more details), and gave one of the first large classes of languages whose constraint satisfaction problem could be placed in non-deterministic logarithmic space [14].",
      "startOffset" : 284,
      "endOffset" : 288
    }, {
      "referenceID" : 13,
      "context" : "The presence of a majority polymorphism is a robust and well-studied condition: majority polymorphisms were used to give some of the initial language tractability results, are known to exactly characterize the languages such that 3-consistency implies global consistency (we refer to [20] for definitions and more details), and gave one of the first large classes of languages whose constraint satisfaction problem could be placed in non-deterministic logarithmic space [14].",
      "startOffset" : 470,
      "endOffset" : 474
    }, {
      "referenceID" : 19,
      "context" : "While the languages that we study are already known to be polynomial-time tractable [20, 10], from the standpoint of understanding the complexity and algorithmic properties of constraint languages, we believe our tractability results to be particularly attractive for a couple of reasons.",
      "startOffset" : 84,
      "endOffset" : 92
    }, {
      "referenceID" : 9,
      "context" : "While the languages that we study are already known to be polynomial-time tractable [20, 10], from the standpoint of understanding the complexity and algorithmic properties of constraint languages, we believe our tractability results to be particularly attractive for a couple of reasons.",
      "startOffset" : 84,
      "endOffset" : 92
    }, {
      "referenceID" : 6,
      "context" : "First, relative to a fixed language, singleton arc consistency runs in quadratic time [7], constituting a highly non-trivial running time improvement over the cubic time bound that was previously known for the studied languages.",
      "startOffset" : 86,
      "endOffset" : 89
    }, {
      "referenceID" : 10,
      "context" : "For instance, in logic, the constraint satisfaction problem can be formulated as the model checking problem for primitive positive sentences over relational structures, and in database theory, it can be formulated as the containment problem for conjunctive queries [11].",
      "startOffset" : 265,
      "endOffset" : 269
    }, {
      "referenceID" : 17,
      "context" : "Throughout this section and in later sections, we will make use of a structure℘(B) that is defined for every structure B, as follows [18, 15].",
      "startOffset" : 133,
      "endOffset" : 141
    }, {
      "referenceID" : 14,
      "context" : "Throughout this section and in later sections, we will make use of a structure℘(B) that is defined for every structure B, as follows [18, 15].",
      "startOffset" : 133,
      "endOffset" : 141
    }, {
      "referenceID" : 17,
      "context" : "Feder and Vardi [18] have studied arc consistency, under an equivalent formulation in terms of Datalog Programs, for constraint languages.",
      "startOffset" : 16,
      "endOffset" : 20
    }, {
      "referenceID" : 14,
      "context" : "The connection of the results in Feder and Vardi with arc consistency was made explicit in Dalmau and Pearson [15].",
      "startOffset" : 110,
      "endOffset" : 114
    }, {
      "referenceID" : 11,
      "context" : "Look-ahead arc consistency was introduced and studied by Chen and Dalmau [12], and the theorem that follows is due to them.",
      "startOffset" : 73,
      "endOffset" : 77
    }, {
      "referenceID" : 16,
      "context" : "This algorithm can be viewed as a generalization of an algorithm for SAT studied by Del Val [17].",
      "startOffset" : 92,
      "endOffset" : 96
    }, {
      "referenceID" : 7,
      "context" : "Peek arc consistency was introduced and studied by Bodirsky and Chen [8]; the notions and results that follow come from them.",
      "startOffset" : 69,
      "endOffset" : 72
    }, {
      "referenceID" : 15,
      "context" : "Singleton arc consistency was introduced by Debruyne and Bessiere [16].",
      "startOffset" : 66,
      "endOffset" : 70
    }, {
      "referenceID" : 17,
      "context" : "We also show that the structures solvable by SAC (and hence, those solvable by any of the studied algorithms) all fall into the class of structures having bounded width; bounded width is a well-studied condition admitting multiple characterizations [18, 22, 6].",
      "startOffset" : 249,
      "endOffset" : 260
    }, {
      "referenceID" : 21,
      "context" : "We also show that the structures solvable by SAC (and hence, those solvable by any of the studied algorithms) all fall into the class of structures having bounded width; bounded width is a well-studied condition admitting multiple characterizations [18, 22, 6].",
      "startOffset" : 249,
      "endOffset" : 260
    }, {
      "referenceID" : 5,
      "context" : "We also show that the structures solvable by SAC (and hence, those solvable by any of the studied algorithms) all fall into the class of structures having bounded width; bounded width is a well-studied condition admitting multiple characterizations [18, 22, 6].",
      "startOffset" : 249,
      "endOffset" : 260
    }, {
      "referenceID" : 5,
      "context" : "The proof is obtained by using a strengthened version of the Prague strategy defined by Barto and Kozik [6].",
      "startOffset" : 104,
      "endOffset" : 107
    }, {
      "referenceID" : 19,
      "context" : "Since R is necessarily 2-decomposable [20], h is a homomorphism.",
      "startOffset" : 38,
      "endOffset" : 42
    }, {
      "referenceID" : 9,
      "context" : "Our treatment of 2-semilattices is inspired and influenced by the study conducted by Bulatov [10], who proved that they are polynomial-time tractable.",
      "startOffset" : 93,
      "endOffset" : 97
    }, {
      "referenceID" : 22,
      "context" : ", bk ∈ s(a)}; the containment ⊇ is clear by definition of subalgebra, and the containment ⊆ follows from the fact that the right hand side is a subalgebra, which in turn follows from the fact that the set of polymorphisms of B forms a clone and is closed under composition [23].",
      "startOffset" : 273,
      "endOffset" : 277
    }, {
      "referenceID" : 4,
      "context" : "Atserias and Weyer [5] gave a uniform treatment of AC, PAC, SAC, and general consistency.",
      "startOffset" : 19,
      "endOffset" : 22
    }, {
      "referenceID" : 5,
      "context" : "Their results combined with the fact that general consistency/bounded width is decidable [6] implies that it can be decided whether or not a given constraint language is solvable by any of the other methods.",
      "startOffset" : 89,
      "endOffset" : 92
    }, {
      "referenceID" : 5,
      "context" : "Barto and Kozik [6] have recently characterized all languages solvable by bounded width.",
      "startOffset" : 16,
      "endOffset" : 19
    } ],
    "year" : 2011,
    "abstractText" : "A natural and established way to restrict the constraint satisfaction problem is to fix the relations that can be used to pose constraints; such a family of relations is called a constraint language. In this article, we study arc consistency, a heavily investigated inference method, and three extensions thereof from the perspective of constraint languages. We conduct a comparison of the studied methods on the basis of which constraint languages they solve, and we present new polynomial-time tractability results for singleton arc consistency, the most powerful method studied.",
    "creator" : "LaTeX with hyperref package"
  }
}