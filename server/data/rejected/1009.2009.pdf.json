{
  "name" : "1009.2009.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Hierarchical Semi-Markov Conditional Random Fields for Recursive Sequential Data",
    "authors" : [ "Tran The Truyen", "Dinh Q. Phung", "Svetha Venkatesh" ],
    "emails" : [ "thetruyen.tran@postgrad.curtin.edu.au", "D.Phung@curtin.edu.au", "S.Venkatesh@curtin.edu.au", "bui@ai.sri.com" ],
    "sections" : [ {
      "heading" : null,
      "text" : "ar X\niv :1\n00 9.\n20 09\nv1 [\nInspired by the hierarchical hidden Markov models (HHMM), we present the hierarchical semi-Markov conditional random field (HSCRF), a generalisation of embedded undirected Markov chains to model complex hierarchical, nested Markov processes. It is parameterised in a discriminative framework and has polynomial time algorithms for learning and inference. Importantly, we consider partiallysupervised learning and propose algorithms for generalised partially-supervised learning and constrained inference. We demonstrate the HSCRF in two applications: (i) recognising human activities of daily living (ADLs) from indoor surveillance cameras, and (ii) noun-phrase chunking. We show that the HSCRF is capable of learning rich hierarchical models with reasonable accuracy in both fully and partially observed data cases.\nContents"
    }, {
      "heading" : "1 Introduction 3",
      "text" : "∗Hung Bui is supported by the Defense Advanced Research Projects Agency (DARPA) under Contract No. FA8750-07-D-0185/0004. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of DARPA, or the Air Force Research Laboratory (AFRL)."
    }, {
      "heading" : "2 Related Work 5",
      "text" : "2.1 Hierarchical Modelling of Stochastic Processes . . . . . . . . . . . . 5 2.2 Hierarchical Hidden Markov Models . . . . . . . . . . . . . . . . . . 6 2.3 Conditional Random Fields . . . . . . . . . . . . . . . . . . . . . . . 7"
    }, {
      "heading" : "3 Model Definition of HSCRF 9",
      "text" : ""
    }, {
      "heading" : "4 Asymmetric Inside-Outside Algorithm 13",
      "text" : "4.1 Building Blocks and Conditional Independence . . . . . . . . . . . . 13\n4.1.1 Contextual Markov blankets . . . . . . . . . . . . . . . . . . 13 4.1.2 Conditional independence . . . . . . . . . . . . . . . . . . . 14 4.1.3 Symmetric Inside/Outside Masses . . . . . . . . . . . . . . . 15 4.1.4 Asymmetric Inside/Outside Masses . . . . . . . . . . . . . . 17\n4.2 Computing Inside Masses . . . . . . . . . . . . . . . . . . . . . . . . 17 4.2.1 Computing asymmetric inside mass from inside mass . . . . . 17 4.2.2 Computing inside mass from asymmetric inside mass . . . . . 19 4.3 Computing Outside Masses . . . . . . . . . . . . . . . . . . . . . . . 20 4.3.1 Computing asymmetric outside mass from outside mass . . . 20 4.3.2 Computing outside mass from asymmetric outside mass . . . 21"
    }, {
      "heading" : "5 The Generalised Viterbi Algorithm 23",
      "text" : "5.1 Computing the Maximum Joint Potential, Maximal States and Time\nIndices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 5.2 Decoding the MAP Assignment . . . . . . . . . . . . . . . . . . . . 26"
    }, {
      "heading" : "6 Parameter Estimation 26",
      "text" : "6.1 Log-Linear Parameterisation . . . . . . . . . . . . . . . . . . . . . . 27 6.2 ESS for State-Persistence Features . . . . . . . . . . . . . . . . . . . 27 6.3 ESS for Transition Features . . . . . . . . . . . . . . . . . . . . . . . 28 6.4 ESS for Initialisation Features . . . . . . . . . . . . . . . . . . . . . 29 6.5 ESS for Ending Features . . . . . . . . . . . . . . . . . . . . . . . . 30"
    }, {
      "heading" : "7 Partially Observed Data in Learning and Inference 31",
      "text" : "7.1 The Constrained AIO algorithm . . . . . . . . . . . . . . . . . . . . 32 7.2 The Constrained Viterbi Algorithm . . . . . . . . . . . . . . . . . . . 33 7.3 Complexity Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . 34"
    }, {
      "heading" : "8 Numerical Scaling 34",
      "text" : "8.1 Scaling the Symmetric/Asymmetric Inside Masses . . . . . . . . . . 35 8.2 Scaling the Symmetric/Asymmetric Outside Masses . . . . . . . . . . 36"
    }, {
      "heading" : "9 Applications 36",
      "text" : "9.1 Recognising Indoor Activities . . . . . . . . . . . . . . . . . . . . . 36 9.2 POS Tagging and Noun-Phrase Chunking . . . . . . . . . . . . . . . 37\n10 Conclusions 39"
    }, {
      "heading" : "A Proofs 42",
      "text" : "A.1 Proof of Propositions 1 and 2 . . . . . . . . . . . . . . . . . . . . . . 42 A.2 Proof of Proposition 3 . . . . . . . . . . . . . . . . . . . . . . . . . . 43"
    }, {
      "heading" : "B Computing the State Marginals of HSCRF 44",
      "text" : ""
    }, {
      "heading" : "C Semi-Markov CRFs as Special Case of HSCRFs 45",
      "text" : "C.1 SemiCRF as an HSCRF . . . . . . . . . . . . . . . . . . . . . . . . . 45 C.2 Partially Supervised Learning and Constrained Inference . . . . . . . 47 C.3 Numerical Scaling . . . . . . . . . . . . . . . . . . . . . . . . . . . 48"
    }, {
      "heading" : "1 Introduction",
      "text" : "Modelling hierarchical aspects in complex stochastic processes is an important research issue in many application domains. In an hierarchy, each level is an abstraction of lower level details. Consider, for example, a frequent activity performed by human like ‘eat-breakfast’ may include a series of more specific activities like ‘enter-kitchen’, ‘goto-cupboard’, ‘take-cereal’, ‘wash-dishes’ and ‘leave-kitchen’. Each specific activity can be decomposed into finer details. Similarly, in natural language processing (NLP) syntax trees are inherently hierarchical. In a partial parsing task known as noun-phrase (NP) chunking (Sang and Buchholz, 2000), there are three semantic levels: the sentence, noun-phrases and part-of-speech (POS) tags. In this setting, the sentence is a sequence of NPs and non-NPs and each phrase is a sub-sequence of POS tags.\nA popular approach to deal with hierarchical data is to build a cascaded model where each level is modelled separately, and the output of the lower level is used as the input of the level right above it (e.g. see (Oliver et al., 2004)). For instance, in NP chunking this approach first builds a POS tagger and then constructs a chunker that incorporates the output of the tagger. This approach is clearly sub-optimal because the POS tagger takes no information of the NPs and the chunker is not aware of the reasoning of the tagger. In contrast, a noun-phrase is often very informative to infer the POS tags belonging to the phrase. As a result, this layered approach often suffers from the so-called cascading error problem as the error introduced from the lower layer will propagate to higher levels.\nA more holistic approach is to build a joint representation of all the levels. Formally, we are given a data observation z and we need to model and infer about the joint semantic x. The main problem is to choose an appropriate representation of x so that inference can be efficient. In this paper, we are interested in a specific class of hierarchical models that supports both joint modelling and efficient inference. More specifically, the models of interest are recursive and sequential, in that each level is a sequence and each node in a sequence can be decomposed further into a sub-sequence of finer grain at the lower level.\nThere has been substantial investigation of these types of model, especially in the area of probabilistic context-free grammars (e.g. see (Manning and Schütze, 1999, Chapter 11)). However, grammars are often unbounded in depth and thus difficult\nto represent by graphical models. A more restricted version known as hierarchical hidden Markov model (HHMM) (Fine et al., 1998) offers clearer representation in that the depth is fixed and the semantic levels are well defined. Essentially, the HHMM is a nested hidden Markov network (HMM) in the sense that each state is a sub HMM by itself.\nThese models share a common property in that they are generative, i.e. they assume that the data observation is generated by the hierarchical semantics. The generative models try to construct the the joint distribution Pr(x, z) = Pr(z|x) Pr(x). However, there are some drawbacks associated with this approach. First, the generative process modelled by Pr(z|x) is typically unknown and complicated. Second, given an observation z, we are more often interested in inferring Pr(x|z). Since Pr(x, z) = Pr(x|z) Pr(z), modelling Pr(z) may be unnecessary.\nAn attractive alternative is to model the distribution Pr(x|z) directly, avoiding the modelling of z. This line of research has recently attracted much interest, largely triggered by the introduction of the conditional random field (CRF) (Lafferty et al., 2001). The advantages of the CRF is largely attributed to its discriminative nature that allows arbitrary and long-range interdependent features.\nIn this paper we follow the HMM/HHMM path to generalise from chain-structured CRFs to nested CRFs. As a result, we construct a novel model called Hierarchical Semi-Markov Conditional Random Field (HSCRF), which is an undirected conditional graphical model of nested Markov chains. Thus HSCRF is the combination of the discriminative nature of CRFs and the nested modelling of the HHMM.\nTo be more concrete let us return to the NP chunking example. The problem can be modelled as a three-level HSCRF, where the root represents the sentence, the second level the NP process, and the bottom level the POS process. The root and the two processes are conditioned on the sequence of words in the sentence. Under the discriminative modelling of the HSCRF, rich contextual information such as starting and ending of the phrase, the phrase length, and the distribution of words falling inside the phrase can be effectively encoded. On the other hand, such encoding is much more difficult for HHMMs.\nWe then proceed to address important issues. First, we show how to represent HSCRFs using a dynamic graphical model (e.g. see (Lauritzen, 1996)) which effectively encodes hierarchical and temporal semantics. For parameter learning, an efficient algorithm based on the Asymmetric Inside-Outside of (Bui et al., 2004) is introduced. For inference, we generalise the Viterbi algorithm to decode the semantics from an observational sequence.\nThe common assumptions in discriminative learning and inference are that the training data in learning is fully labelled, and the test data during inference is not labelled. We propose to relax these assumptions in that training labels may only be partially available, and we term the learning as partial-supervision. Likewise, when some labels are given during inference, the algorithm should automatically adjust to meet the new constraints.\nWe demonstrate the effectiveness of HSCRFs in two applications: (i) segmenting and labelling activities of daily living (ADLs) in an indoor environment and (ii) jointly modeling noun-phrases and part-of-speeches in shallow parsing. Our experimental results in the first application show that the HSCRFs are capable of learning rich, hierar-\nchical activities with good accuracy and exhibit better performance when compared to DCRFs and flat-CRFs. Results for the partially observable case also demonstrate that significant reduction of training labels still results in models that perform reasonably well. We also show that observing a small amount of labels can significantly increase the accuracy during decoding. In shallow parsing, the HSCRFs can achieve higher accuracy than standard CRF-based techniques and the recent DCRFs.\nTo summarise, in this paper we claim the following contributions:\n• Introducing a novel Hierarchical Semi-Markov Conditional Random Field (HSCRF) to model complex hierarchical and nested Markovian processes in a discriminative framework,\n• Developing an efficient generalised Asymmetric Inside-Outside (AIO) algorithm for full-supervised learning.\n• Generalising the Viterbi algorithm for decoding the most probable semantic labels and structure given an observational sequence.\n• Addressing the problem of partially-supervised learning and constrained inference.\n• Demonstration of the applicability of the HSCRFs for modeling human activities in the domain of home video surveillance and shallow parsing of English.\nNotations and Organisation\nThis paper makes use of a number of mathematical notations which we include in Table 1 for reference.\nThe rest of the paper is organised as follows. Section 2 reviews Conditional Random Fields. Section 3 continues with the HSCRF model definition and parameterisation. Section 4 defines building blocks required for common inference tasks. These blocks are computed in Section 4.2 and 4.3. Section 5 presents the generalised Viterbi algorithm. Parameter estimation follows in Section 6. Learning and inference with partially available labels are addressed in Section 7. Section 8 presents a method for numerical scaling to prevent numerical overflow. Section 9 documents experimental results. Section 10 concludes the paper."
    }, {
      "heading" : "2 Related Work",
      "text" : ""
    }, {
      "heading" : "2.1 Hierarchical Modelling of Stochastic Processes",
      "text" : "Hierarchical modelling of stochastic processes can be largely categorised as either graphical models extending the flat hidden Markov models (HMM) (e.g., the layered HMM (Oliver et al., 2004), the abstract HMM (Bui et al., 2002), hierarchical HMM (HHMM) (Fine et al., 1998; Bui et al., 2004), DBN (Murphy, 2002)) or grammarbased models (e.g., PCFG (Pereira and Schabes, 1992)). These models are all generative.\nRecent development in discriminative, hierarchical structures include extension of the flat CRFs (e.g. dynamic CRFs (DCRF) (Sutton et al., 2007), hierarchical CRFs (Liao et al., 2007; Kumar and Hebert, 2005)) and conditional learning of the grammars (e.g. see (Miyao and Tsujii, 2002; Clark and Curran, 2003)). The main problem of the DCRFs is that they are not scalable due to inference intractability. The hierarchical CRFs, on the other hand, are tractable but assume fixed tree structures, and therefore are not flexible to adapt to complex data. For example, in the noun-phrase chunking problem no prior tree structures are known. Rather, if such a structure exists, it can only be discovered after the model has been successfully built and learned.\nThe conditional probabilistic context-free grammar (C-PCFG) appears to address both tractability and dynamic structure issues. More precisely, in C-PCFGs it takes cubic time in sequence length to parse a sentence. However, the context-free grammar does not limit the depth of semantic hierarchy, thus making it unnecessarily difficult to map many hierarchical problems into its form. Secondly, it lacks a graphical model representation and thus does not enjoy the rich set of approximate inference techniques available in graphical models."
    }, {
      "heading" : "2.2 Hierarchical Hidden Markov Models",
      "text" : "Hierarchical HMMs are generalisations of HMMs (Rabiner, 1989) in the way that a state in an HHMM may be a sub-HHMM. Thus, an HHMM is a nested Markov chain. In the model temporal evolution, when a child Markov chain terminates, it returns the control to its parent. Nothing from the terminated child chain is carried forward. Thus, the parent state abstracts out everything belonging to it. Upon receiving the return control the parent then either transits to a new parent, (given that the grand parent has not finished), or terminates.\nFigure 1 illustrates the state transition diagram of a two-level HHMM. At the top level there are two parent states {A,B}. The parentA has three children, i.e. ch(A) = {1, 2, 3} and B has four, i.e. ch(B) = {4, 5, 6, 7}. At the top level the transitions are between A and B, as in a normal directed Markov chain. Under each parent there are also transitions between child states, which only depend on the direct parent (either A or B). There are special ending states (represented as shaded nodes in Figure 1) to signify the termination of the Markov chains. At each time step of the child Markov chain, a child will emit an observational symbol (not shown here).\nThe temporal evolution of the HHMM can be represented as a dynamic Bayesian network, which was first done in (Murphy and Paskin, 2002). Figure 2 depicts a DBN structure of 3 levels. The bottom level is often referred to as production level. Associated with each state is an ending indicator to signify the termination of the state. Denote by xdt and e d t the state and ending indicator at level d and time t, respectively. When edt = 0, the state x d t continues, i.e. x d t = x d t+1. And when e d t = 1, the state x d t transits to a new state, or transits to itself. There are hierarchical consistency rules that must be ensured. Whenever a state persists (i.e. edt = 0), all of the states above it must also persist (i.e. ed ′\nt = 0 for all d ′ < d). Similarly, whenever a state ends (i.e edt = 1),\nall of the states below it must also end (i.e. ed ′ t = 1 for all d ′ > d).\nInference and learning in HHMMs follow the Inside-Outside algorithm of the probabilistic context-free grammars. Overall, the algorithm has O(|S|3DT 3) time com-\nplexity where |S| is the maximum size of the state space at each level, D is the depth of the model and T is the model length.\nWhen representing as a DBN, the whole stack of states x1:Dt can be collapsed into a ‘mega-state’ of a big HMM, and therefore inference can be carried out in O(|S|2DT ) time. This is efficient for a shallow model (i.e. D is small), but problematic for a deep model (i.e. D is large)."
    }, {
      "heading" : "2.3 Conditional Random Fields",
      "text" : "Denote by G = (V , E) the graph where V is the set of vertices, and E is the set of edges. Associated with each vertex i is a state variable xi Let x be joint state variable, i.e. x = (xi)i∈V . Conditional random fields (CRFs) (Lafferty et al., 2001) define a conditional distribution given the observation z as follows\nPr(x|z) = 1\nZ(z)\n∏\nc\nφc(xc, z) (1)\nwhere c is the index of cliques in the graph, φc(xc, z) is a non-negative potential function defined over the clique c, and Z(z) = ∑ x ∏ c φc(xc, z) is the partition function.\nLet {x̃} be the set of observed state variables with the empirical distribution Q(x̃), and w be the parameter vector. Learning in CRFs is typically by maximising the (log) likelihood\nw ∗ = argmax\nw L(w) = argmax w\n∑\nx̃\nQ(x̃) log Pr(x̃|z;w) (2)\nThe gradient of the log-likelihood can be computed as\n∇L(w) = ∑\nx̃\nQ(x̃) ∑\nc\n( ∇ logφc(x̃c, z)− ∑\nxc\nPr(xc|z)∇ logφc(xc, z)\n) (3)\nThus, the inference needed in CRF parameter estimation is the computation of clique marginals Pr(xc|z).\nTypically, CRFs are parameterised using log-linear models (also known as exponential family, Gibbs distribution or Maximum Entropy model), i.e. φc(xc, z) = exp(w⊤f(xc, z)), where f(.) is the feature vector andw is the vector of feature weights. The features are also known as sufficient statistics in the exponential family setting. Let F(x, z) = ∑ c f(xc, z) be the global feature. Equation 3 can be written as follows\n∇L = ∑\nx̃\nQ(x̃) ∑\nc\n( f(x̃c, z)− ∑\nxc\nPr(xc|z)f(xc, z)\n) (4)\n= EQ(x̃)[F]− EPr(x|z)[F] (5)\nThus gradient-based maximum likelihood learning in the log-linear setting boils down to estimating the feature expectations, also known as expected sufficient statistics (ESS).\nThe probabilistic nature of CRFs allows incorporating hidden variables in a disciplined manner. Let x̃ = (ϑ, h), where ϑ is the set of visible variables, and h is the set of hidden variables. The incomplete log-likelihood and its gradient are given as\nL = ∑\nx̃\nQ(x̃) log Pr(ϑ|z) = ∑\nx̃\nQ(x̃) log ∑\nh\nPr(ϑ, h|z)\n= ∑\nx̃\nQ(x̃)(logZ(ϑ, z)− logZ(z)) (6)\nwhere Z(ϑ, z) = ∑\nh ∏ c φc(ϑc, hc, z). The gradient reads\n∇L = Eh|ϑ,z[F(ϑ, h, z)]− Ex|z[F(x, z)]\n= ∑\nx̃\nQ(x̃) ∑\nc\n( ∑\nhc\nPr(hc|ϑ, z)f(ϑc, hc, z)− ∑\nxc\nPr(xc|z)f(xc, z)\n) (7)\nThere have been extensions to CRFs, which can be broadly grouped into two categories. The first category involves generalisation of model representation, for example by extending CRFs for complex temporal structures as in Dynamic CRFs\n(DCRFs) (Sutton et al., 2007), segmental sequences as in Semi-Markov CRFs (SemiCRFs) (Sarawagi and Cohen, 2004), and relational data (Taskar et al., 2002). The second category investigates learning schemes other than maximum likelihood, for example perceptron (Collins, 2002) and SVM (Taskar et al., 2004).\nDCRFs and SemiCRFs are the most closely related to our HSCRFs. DCRFs are basically the conditional, undirected version of the Dynamic Bayesian Networks (Murphy, 2002). The DCRFs introduce multi-level of semantics, which help to represent more complex sequential data. The main drawback of the DCRFs is the intractability of inference, except for shallow models with small state space.\nSimilarly, the SemiCRFs are the conditional, undirected version of the Semi-Markov HMMs. These allows non-Markovian processes to be embedded in the chain CRFs, and thus giving a possibility of modelling process duration. Appendix C analyses the SemiCRFs in more details.\nOur HSCRFs deal with the inference problem of DCRFs by limiting to recursive processes, and thus obtaining efficient inference via dynamic programming in the Inside-Outside family of algorithms. Furthermore, it generalises the SemiCRFs to model multilevel of semantics. It also addresses partial labels by introducing appropriate constraints to the Inside-Outside algorithms."
    }, {
      "heading" : "3 Model Definition of HSCRF",
      "text" : "Consider a hierarchically nested Markov process withD levels. Then as in the HHMMs (see Section 2.2), the parent state embeds a child Markov chain whose states may in turn contain child Markov chains. The family relation is defined in the model topology, which is a state hierarchy of depth D. The model has a set of states Sd at each level d ∈ [1, D], i.e. Sd = {1...|Sd|}, where |Sd| is the number of states at level d. For each state sd ∈ Sd where 1 ≤ d < D, the topological structure also defines a set of children ch(sd) ⊂ Sd+1. Conversely, each child sd+1 has a set of parents pa(sd+1) ⊂ Sd. Unlike the original HHMMs where the child states belong exclusively to the parent, the HSCRFs allow arbitrary sharing of children between parents. For example, in Figure 3, ch(s1 = 1) = {1, 2, 3}, and pa(s3 = 1) = {1, 2, 4}. This helps to avoid an explosive number of sub-states when D is large, leading to fewer parameters and possibly less training data and time. The shared topology has been investigated in the context of HHMMs in (Bui et al., 2004).\nThe temporal evolution in the nested Markov processes with sequence length of T operates as follows:\n• As soon as a state is created at level d < D, it initialises a child state at level d+ 1. The initialisation continues downward until reaching the bottom level.\n• As soon as a child process at level d + 1 ends, it returns control to its parent at level d, and in the case of d > 1, the parent either transits to a new parent state or returns to the grand-parent at level d− 1.\nThe main requirement for the hierarchical nesting is that the life-span of the child process belongs exclusively to the life-span of the parent. For example, consider a\nparent process at level d starts a new state sdi:j at time i and persists until time j. At time i the parent initialises a child state sd+1i which continues until it ends at time k < j, at which the child state transits to a new child state sd+1k+1. The child process exits at time j, at which the control from the child level is returned to the parent sdi:j . Upon receiving the control the parent state sdi:j may transit to a new parent state s d j+1:l, or end at j, returning the control to the grand-parent at level d− 1.\nWe are now in a position to specify the nested Markov processes in a more formal way. Let us introduce a multi-level temporal graphical model of length T withD levels, starting from the top as 1 and the bottom as D (Figure 4). At each level d ∈ [1, D] and time index i ∈ [1, T ], there is a node representing a state variable xdi ∈ S\nd = {1, 2, ..., |Sd|}. Associated with each xdi is an ending indicator e d i which can be either 1 or 0 to signify whether the state xdi ends or persists at i. The nesting nature of the HSCRFs is now realised by imposing the specific constraints on the value assignment of ending indicators (Figure 5).\nThus, specific value assignments of ending indicators provide contexts that realise the evolution of the model states in both hierarchical (vertical) and temporal (horizontal) directions. Each context at a level and associated state variables form a contextual clique, and we identify four contextual clique types:\n• State-persistence : This corresponds to the life time of a state at a given level (see Figure 6). Specifically, given a context c = (edi−1:j = (1, 0, .., 0, 1)), then\nσpersist,di:j = (x d i:j , c), is a contextual clique that specifies the life-span [i, j] of any state s = xdi:j .\nIn the HSCRF we are interested in the conditional setting in which the entire state variables and ending indicators (x1:D1:T , e 1:D 1:T ) are conditioned on observational sequences z. For example, in computational linguistics, the observation is often the sequence of words and the state variables might be the part-of-speech tags and the phrases.\nTo capture the correlation between variables and such conditioning, we define a non-negative potential function ψ(σ, z) over each contextual clique σ. Figure 8 shows the notations for potentials that correspond to the four contextual clique types we have identified above. Details of potential specification are described in the Section 6.1.\nLet ζ = (x1:D1:T , e 1:D 1:T ) denote the set of all variables that satisfies the set of hierarchical constraints in Figure 5. Let τd denote ordered set of all ending time indices at level d, i.e. if i ∈ τd then edi = 1. The joint potential defined for each configuration is the product of all contextual clique potentials over all ending time indices i ∈ [1, T ] and all semantic levels d ∈ [1, D]:\nΦ[ζ, z] =\n[\n∏\nd∈[1,D]\n∏\nik,ik+1∈τ d\nR d,s,z ik+1:ik+1\n]\n×\n×\n∏\nd∈[1,D−1]\n\n\n\n[\n∏\nik∈τ d+1,ik /∈τ d\nA d+1,s,z u,v,ik\n][\n∏\nik∈τ d+1\nπ d,s,z u,ik+1\n][\n∏\nik∈τ d+1\nE d,s,z u,ik\n]\n\n\n\n(8)\nThe conditional distribution is given as\nPr(ζ|z) = 1\nZ(z) Φ[ζ, z] (9)\nwhere Z(z) = ∑\nζ Φ[ζ, z] is the partition function for normalisation. In what follows we omit z for clarity, and implicitly use it as part of the partition function Z and the potential Φ[.]. It should be noted that in the unconditional formulation, there is only a single Z for all data instances. In conditional setting there is a Z(z) for each data instance z.\nRemarks: The temporal model of HSCRFs presented here is not a standard graphical model (Lauritzen, 1996) since the connectivity (and therefore the clique structures) is not fixed. The potentials are defined on-the-fly depending on the context of assignments of ending indicators. Although the model topology is identical to that of shared\nstructure HHMMs (Bui et al., 2004), the unrolled temporal representation is an undirected graph and the model distribution is formulated in a discriminative way. Furthermore, the state persistence potentials capture duration information that is not available in the dynamic DBN representation of the HHMMs in (Murphy and Paskin, 2002).\nIn the way the potentials are introduced it may first appear to resemble the clique templates in the discriminative relational Markov networks (RMNs) (Taskar et al., 2002). It is, however, different because cliques in the HSCRFs are dynamic and contextdependent."
    }, {
      "heading" : "4 Asymmetric Inside-Outside Algorithm",
      "text" : "This section describes a core inference engine called Asymmetric Inside-Outside (AIO) algorithm, which is partly adapted from the generative, directed counter part of HHMMs in (Bui et al., 2004). We now show how to compute the building blocks that are needed in most inference and learning tasks.\n4.1 Building Blocks and Conditional Independence"
    }, {
      "heading" : "4.1.1 Contextual Markov blankets",
      "text" : "In this subsection we define elements that are building blocks for inference and learning. These building blocks are identified given the corresponding boundaries. Let us introduce two types of boundaries: the contextual symmetric and asymmetric Markov blankets.\nDefinition 1. A symmetric Markov blanket at level d for a state s starting at i and ending at j is the following set\nΠd,si:j = (x d i:j = s, e d:D i−1 = 1, e d:D j = 1, e d i:j−1 = 0) (10)\nDefinition 2. Let Πd,si:j be a symmetric Markov blanket, we define ζ d,s i:j and ζ d,s i:j as follows\nζd,si:j = (x d+1:D i:j , e d+1:D i:j−1 ) (11)\nζd,s i:j = ζ\\(ζd,si:j ,Π d,s i:j ) (12)\nsubject to xdi:j = s. Further, we define\nζ̂d,si:j = (ζ d,s i:j ,Π d,s i:j ) (13) ζ̂ d,s\ni:j = (ζd,s i:j ,Πd,si:j ) (14)\nFigure 9a shows an example of a symmetric Markov blanket (represented by a double-arrowed line).\nDefinition 3. A asymmetric Markov blanket at level d for a parent state s starting at i and a child state u ending at j is the following set\nΓd,si:j (u) = (x d i:j = s, x d+1 j = u, e d:D i−1 = 1, e d+1:D j = 1, e d i:j−1 = 0) (15)\nDefinition 4. Let Γd,si:j (u) be an asymmetric Markov blanket, we define ζ d,s i:j (u) and ζd,s i:j (u) as follows\nζd,si:j (u) = (x d+1:D i:j−1 , x d+2:D j , e d+1:D i:j−1 ) (16)\nζd,s i:j (u) = ζ\\(ζd,si:j (u),Γ d,s i:j (u)) (17)\nsubject to xdi:j = s and x d+1 j = u. Further, we define\nζ̂d,si:j (u) = (ζ d,s i:j (u),Γ d,s i:j (u)) (18) ζ̂ d,s\ni:j (u) = (ζd,s i:j (u),Γd,si:j (u)) (19)\nFigure 9b shows an example of asymmetric Markov blanket (represented by an arrowed line).\nRemark: The concepts of contextual Markov blankets (or Markov blankets for short) are different from those in traditional Markov random fields and Bayesian networks because they are specific assignments of a subset of variables, rather than a collection of variables."
    }, {
      "heading" : "4.1.2 Conditional independence",
      "text" : "Given these two definitions we have the following propositions of conditional independence.\nProposition 1. ζd,si:j and ζ d,s i:j are conditionally independent given Πd,si:j\nPr(ζd,si:j , ζ d,s i:j |Πd,si:j ) = Pr(ζ d,s i:j |Π d,s i:j ) Pr(ζ d,s i:j |Πd,si:j ) (20)\nThis proposition gives rise to the following factorisation\nPr(ζ) = Pr(Πd,si:j ) Pr(ζ d,s i:j , ζ d,s i:j |Πd,si:j ) = Pr(Π d,s i:j ) Pr(ζ d,s i:j |Π d,s i:j ) Pr(ζ d,s i:j |Πd,si:j ) (21)\nProposition 2. ζd,si:j (u) and ζ d,s i:j (u) are conditionally independent given Γd,si:j (u)\nPr(ζd,si:j (u), ζ d,s i:j (u)|Γd,si:j (u)) = Pr(ζ d,s i:j (u)|Γ d,s i:j (u)) Pr(ζ d,s i:j (u)|Γd,si:j (u)) (22)\nThe following factorisation is a consequence of Proposition 2\nPr(ζ) = Pr(Γd,si:j (u)) Pr(ζ d,s i:j (u), ζ d,s i:j (u)|Γd,si:j (u))\n= Pr(Γd,si:j (u)) Pr(ζ d,s i:j (u)|Γ d,s i:j (u)) Pr(ζ d,s i:j (u)|Γd,si:j (u)) (23)\nThe proof of Propositions 1 and 2 is given in Appendix A.1."
    }, {
      "heading" : "4.1.3 Symmetric Inside/Outside Masses",
      "text" : "From Equation 12 we have ζ = (ζd,si:j ,Π d,s i:j , ζ d,s i:j ). Since Πd,si:j separates ζ d,s i:j from ζd,s i:j , we can group local potentials in Equation 8 into three parts: Φ[ζ̂d,si:j [, Φ[ζ̂ d,s i:j [, and Φ[Πd,si:j ]. By ‘grouping’ we mean to multiply all the local potentials belonging to a certain part, in the same way that we group all the local potentials belonging to the model in Equation 8. Note that although ζ̂d,si:j contains Π d,s i:j we do not group Φ[Π d,s i:j ] into Φ[ζ̂d,si:j ]. The same holds for Φ[ζ̂ d,s i:j ].\nBy definition of the state-persistence clique potential (Figure 8), we haveΦ[Πd,si:j ] =\nRd,si:j . Thus Equation 8 can be replaced by\nΦ[ζ] = Φ[ζ̂d,si:j ]R d,s i:j Φ[ζ̂\nd,s i:j ] (24)\nThere are two special cases: (1) when d = 1, Φ[ζ̂ 1,s\n1:T ] = 1 for s ∈ S1, and (2) when\nd = D, Φ[ζ̂D,si:i ] = 1 for s ∈ S D and i ∈ [1, T ]. This factorisation plays an important role in efficient inference. We know define a quantity called symmetric inside mass ∆d,si:j , and another called symmetric outside mass Λd,si:j .\nDefinition 5. Given a symmetric Markov blanket Πd,si:j , the symmetric inside mass ∆ d,s i:j and the symmetric outside mass Λd,si:j are defined as\n∆d,si:j = ∑\nζd,s i:j\nΦ[ζ̂d,si:j ] (25)\nΛd,si:j = ∑\nζd,s i:j\nΦ[ζ̂ d,s\ni:j ] (26)\nAs special cases we have Λ1,s1:T = 1 and s ∈ S 1, and ∆D,si:i = 1 for i ∈ [1, T ], s ∈ SD. For later use let us introduce the ‘full’ symmetric inside mass ∆̂d,si:j and the ‘full’ symmetric outside mass Λ̂d,si:j as\n∆̂d,si:j = R d,s i:j ∆ d,s i:j (27) Λ̂d,si:j = R d,s i:j Λ d,s i:j (28)\nIn the rest of the thesis, when it is clear in the context, we will use inside mass as a shorthand for symmetric inside mass, outside mass for symmetric outside mass, fullinside mass for full-symmetric inside mass, and full-outside mass for full-symmetric outside mass.\nThus, from Equation 24 the partition function can be computed from the full-inside mass at the top level (d = 1)\nZ = ∑\nζ\nΦ[ζ]\n= ∑\nζ1,s 1:T\n∑\ns∈S1\nΦ[ζ̂1,s1:T ]R 1,s 1:T\n= ∑\ns∈S1\n∆d,s1:TR d,s 1:T\n= ∑\ns∈S1\n∆̂1,s1:T (29)\nWith the similar derivation the partition function can also be computed from the fulloutside mass at the bottom level (d = D)\nZ = ∑\ns∈SD\nΛ̂D,si:i , for any i ∈ [1, T ] (30)\nIn fact, we will prove a more general way to compute Z in Appendix B\nZ = ∑\ns∈Sd\n∑\ni∈[1,t]\n∑\nj∈[t,T ]\n∆d,si:j Λ d,s i:j R d,s i:j (31)\nfor any t ∈ [1, T ] and d ∈ [2, D − 1]. These relations are summarised in Figure 10.\nGiven the fact that ζd,si:j is separated from the rest of variables by the symmetric\nMarkov blanket Πd,si:j , we have Proposition 3.\nProposition 3. The following relations hold\nPr(ζd,si:j |Π d,s i:j ) =\n1\n∆d,si:j Φ[ζ̂d,si:j ] (32)\nPr(ζd,s i:j |Πd,si:j ) = 1\nΛd,si:j Φ[ζ̂\nd,s i:j ] (33)\nPr(Πd,si:j ) = 1\nZ ∆d,si:j R d,s i:j Λ d,s i:j (34)\nThe proof of this proposition is given in Appendix A.2."
    }, {
      "heading" : "4.1.4 Asymmetric Inside/Outside Masses",
      "text" : "Recall that we have introduced the concept of asymmetric Markov blanket Γd,si:j (u) which separates ζd,si:j (u) and ζ d,s i:j (u). Let us group all the local contextual clique potentials associated with ζd,si:j (u) and Γ d,s i:j (u) into a joint potential Φ[ζ̂ d,s i:j (u)]. Similarly, we group all local potentials associated with ζd,s i:j (u) and Γd,si:j (u) into a joint potential Φ[ζ̂ d,s\ni:j (u)]. Note that Φ[ζ̂\nd,s i:j (u)]) includes the state-persistence potential Rd,si:j .\nDefinition 6. Given the asymmetric Markov blanket Γd,si:j (u), the asymmetric inside mass αd,si:j (u) and the asymmetric outside mass λ d,s i:j (u) are defined as follows\nαd,si:j (u) = ∑\nζd,s i:j (u)\nΦ[ζ̂d,si:j (u)] (35)\nλd,si:j (u) = ∑\nζd,s i:j (u)\nΦ[ζ̂ d,s\ni:j (u)] (36)\nThe relationship between the asymmetric outside mass and asymmetric inside mass is analogous to that between the outside and inside masses. However, there is a small difference, that is, the asymmetric outside mass ‘owns’ the segment xdi:j = s and the associated state-persistence potential Rd,si:j , whilst the outside mass Λ d i:j(s) does not."
    }, {
      "heading" : "4.2 Computing Inside Masses",
      "text" : "In this subsection we show how to recursively compute the pair: inside mass and asymmetric inside mass. The key idea here is to exploit the decomposition within the asymmetric Markov blanket. As shown in Figure 11, an outer asymmetric Markov blanket can be decomposed into a sub-asymmetric Markov blanket and a symmetric blanket."
    }, {
      "heading" : "4.2.1 Computing asymmetric inside mass from inside mass",
      "text" : "Assume that within the asymmetric Markov blanket Γd,si:j (u), the child u starts somewhere at t ∈ [i, j] and ends at j, i.e. xd+1t:j = u, e d+1 t:j−1 = 0 and e d+1:D−1 t−1 = 1. Let us consider two cases: t > i and t = i.\nCase 1. For t > i, denote by v = xd+1t−1 . We have two smaller blankets within Γd,si:j (u): the symmetric blanket Π d+1,u t:j associated with the child u = x d+1 t:j , and the asymmetric blanket Γd,si:t−1(v) associated with the child v ending at t − 1 under the parent s. Figure 11 illustrates the blanket decomposition. The assignment ζd,si:j (u) can be decomposed as\nζd,si:j (u) = (ζ d,s i:t−1(v), ζ d+1,u t:j , u = x d+1 t:j , e d t−1:j−1 = 0, e d+1:D t−1 = 1) (37)\nThus, the joint potential Φ[ζ̂d,si:j (u)] can be factorised as follows\nΦ[ζ̂d,si:j (u)] = Φ[ζ̂ d,s i:t−1(v)]Φ[ζ̂ d+1,u t:j ]A d+1,s v,u,t−1R d+1,u t:j (38)\nThe transition potential Ad+1,sv,u,t−1 is enabled in the context c = (e d t−1 = 0, e d+1 t−1 = 1, xdt = s, x d+1 t−1 = v, x d+1 t = u), and the state-persistence potential R d+1,u t:j in the context c = (ed+1t:j−1 = 0, e d+1:D t−1 = 1, e d+1:D j = 1, x d+1 t:j = u).\nCase 2. For t = i, the asymmetric blanket Γd,si:t−1(v) does not exist since i > t−1. We have the following decompositions of assignment ζ̂d,si:j (u) = (ζ̂ d+1,u i:j , e d i−1 = 1, edi:j−1 = 0). In the context c = (e d i−1 = 1), the state-initialisation potential π d,s u,i is activated. Thus we have\nΦ[ζ̂d,si:j (u)] = π d,s u,iΦ[ζ̂ d+1,u i:j ]R d+1,u i:j (39)\nSubstituting Equations 38 and 39 into Equation 35, and together with the fact that t can take any value in the interval [i, j], and v can take any value in Sd+1, we have the following relation αd,si:j (u) = ∑\nt∈[i+1,j]\n∑\nv∈Sd+1\n∑\nζd,s i:t−1 (v)\n∑\nζd+1,u t:j\nΦ[ζ̂d,si:t−1(v)]Φ[ζ̂ d+1,u t:j ]A d+1,s v,u,t−1R d+1,u t:j +\n+ ∑\nζd+1,u i:j\nπd,su,iΦ[ζ̂ d+1,u i:j ]R d+1,u i:j\n= ∑\nt∈[i+1,j]\n∑\nv∈Sd+1\nαd,si:t−1(v)∆̂ d+1,u t:j A d+1,s v,u,t−1 + ∆̂ d+1,u i:j π d,s u,i (40)\nAs we can see, the asymmetric inside mass α plays the role of a forward message starting from the starting time i to the ending time j. There is a recursion where the asymmetric inside mass ending at time j is computed from all the asymmetric inside masses ending at time t− 1, for t ∈ [i+ 1, j.\nThere are special cases for the asymmetric inside mass: (1) when i = j, we only have\nαd,si:i (u) = ∆̂ d+1,s i:i π d,s u,i (41)\nand (2) when d = D−1, the sum over the index t as in Equation 40 is not allowed since at level D the inside mass only spans a single index. We have the following instead\nαD−1,si:j (u) = ∑\nv∈Sd+1\nαD−1,si:j−1 (v)∆̂ D,u j:j A D,s v,u,j−1\n= ∑\nv∈Sd+1\nαD−1,si:j−1 (v)R D,u j:j A D,s v,u,j−1 (42)"
    }, {
      "heading" : "4.2.2 Computing inside mass from asymmetric inside mass",
      "text" : "Notice the relationship between the asymmetric Markov blanket Γd,si:j (u) and the symmetric blanket Πd,si:j , where d < D. When e d j = 1, i.e. the parent s ends at j, and Γd,si:j (u) will become Π d,s i:j with u = x d+1 j . Then we have decompositions ζ d,s i:j = (ζd,si:j (u), u = x d+1 j ) and ζ̂ d,s i:j = (ζ̂ d,s i:j (u), e d j = 1, u = x d+1 j ). These lead to the factorisation\nΦ[ζ̂d,si:j ] = Φ[ζ̂ d,s i:j (u)]E d,s u,j (43)\nwhere the state-ending potential Ed,su,j is activated in the context c = (e d j = 1). Thus, the inside mass in Equation 25 can be rewritten as\n∆d,si:j = ∑\nu∈Sd+1\n∑\nζd,s i:j (u)\nΦ[ζ̂d,si:j (u)]E d,s u,j\n= ∑\nu∈Sd+1\nEd,su,j ∑\nζd,s i:j (u)\nΦ[ζ̂d,si:j (u)]\n= ∑\nu∈Sd+1\nEd,su,jα d,s i:j (u) (44)\nThis equation holds for d < D. When d = D, we set ∆D,si:i = 1 for all s ∈ S D and i ∈ [1, T ], and when d = 1, we must ensure that i = 1 and j = T . Remark: Equations 40, 41, 42 and 44 specify a left-right and bottom-up algorithm to compute both the inside and asymmetric inside masses. Initially, at the bottom level ∆D,si:i = 1 for i ∈ [1, T ] and s ∈ S\nD. A pseudo-code of the dynamic programming algorithm to compute all the inside and asymmetric inside masses and the partition function is given in Figure 12."
    }, {
      "heading" : "4.3 Computing Outside Masses",
      "text" : "In this subsection we show how to recursively compute the symmetric outside mass and the asymmetric outside mass. We use the same blanket decomposition as in Section 4.2. However, this time the view is reversed as we are interested in quantities outside the blankets. For example, outside the inner symmetric Markov blanket in Figure 11, there exists an outer asymmetric blanket and another sub-asymmetric blanket on the left."
    }, {
      "heading" : "4.3.1 Computing asymmetric outside mass from outside mass",
      "text" : "Let us examine the variables ζd,s i:j (u) associated with the asymmetric Markov blanket Γd,si:j (u), for d ∈ [1, D − 1] and 1 ≤ i ≤ j ≤ T (see Definition 4). For j < T , assume that there exists an outer asymmetric Markov blanket Γd,si:t (v) for some v ∈ S d+1 and\nt ∈ [j + 1, T ], and a symmetric Markov blanket Πd+1,vj+1:t right next to Γ d,s i:j (u). Given these blankets we have the decomposition ζ̂ d,s\ni:j (u) = (ζ̂\nd,s i:t (v), ζ̂d+1,vj+1:t , x d+1 j = u),\nwhich leads to the following factorisation\nΦ[ζ̂ d,s\ni:j (u)] = Φ[ζ̂\nd,s i:t (v)]Φ[ζ̂d+1,vj+1:t ]R d+1,v j+1:t A d+1,s u,v,j (45)\nThe state transition potential Ad+1,su,v,j is enabled in the context c = (e d j = 0, e d+1 j = 1), and the state persistence potential Rd+1,vj+1:t in the context c = (e d+1 j = 1, e d+1 j+1:t−1 = 0, ed+1t = 1). In addition, there exists a special case where the state s ends at j. We have the decomposition ζ̂ d,s\ni:j (u) = (ζ̂\nd,s i:j , u = xd+1j ) and the following factorisation\nΦ[ζ̂ d,s\ni:j (u)] = Φ[ζ̂\nd,s i:j ]Rd,si:j E d,s u,j (46)\nThe ending potential Ed,su,j appears here because of the context c = (e d j = 1), i.e. s ends at j. Now we relax the assumption of t, v and allow them to receive all possible values, i.e. t ∈ [j, T ] and v ∈ Sd+1. Thus we can replace Equation 36 by\nλd,si:j (u) = ∑\nv∈Sd+1\n∑\nt∈[j+1,T ]\n∑\nζd,s i:t (v)\n∑\nζd+1,v j+1:t\nΦ[ζ̂ d,s\ni:t (v)]Φ[ζ̂d+1,vj+1:t ]R d+1,v j+1:t A d+1,s u,v,j\n+ ∑\nζd,s i:j (u)\nΦ[ζ̂ d,s\ni:j ]Rd,si:j E d,s u,j\n= ∑\nv∈Sd+1\n∑\nt∈[j+1,T ]\nλd,si:t (v)∆̂ d+1,v j+1:t A d+1,s u,v,j + Λ̂ d,s i:j E d,s u,j (47)\nfor d ∈ [2, D− 2], and 1 ≤ i ≤ j ≤ T . Thus, the λd,si:j (u) can be thought as a message passed backward from j = T to j = i. Here, the asymmetric outside mass ending at j is computed by using all the asymmetric outside masses ending at t for t ∈ [j + 1, T ].\nThere are two special cases. At the top level, i.e. d = 1, then λd,si:j (u) is only defined at i = 1, and the second term of the RHS of Equation 47 is included only if i = 1, j = T . At the second lowest level, i.e. d = D − 1, we cannot sum over t as in Equation 47 since ∆̂D,vj+1:t is only defined for t = j +1. We have the following relation instead\nλD−1,si:j (u) = ∑\nv∈SD\nλD−1,si:j+1 (v)∆̂ D,v j+1:j+1A D,s u,v,j + Λ̂ D−1,s i:j E D−1,s u,j (48)"
    }, {
      "heading" : "4.3.2 Computing outside mass from asymmetric outside mass",
      "text" : "Given a symmetric Markov blanket Πd+1,ui:j for d ∈ [1, D− 1], assume that there exists an asymmetric Markov blanket Γd,st:j (u) at the parent level d, where t ∈ [1, i]. Clearly,\nfor t ∈ [1, i − 1] there exists some sub-asymmetric Markov blanket Γd,st:i−1(v). See Figure 11 for an illustration.\nLet us consider two cases: t < i and t = i. Case 1. For t < i, this enables the decomposition ζ̂ d+1,u\ni:j = (ζ̂\nd,s t:j (u), ζ̂d,st:i−1(v), u =\nxd+1i:j ), which leads to the following factorisation\nΦ[ζ̂ d+1,u\ni:j ] = Φ[ζ̂\nd,s t:j (u)]Φ[ζ̂d,st:i−1(v)]A d,s v,u,i−1 (49)\nThe state transition potentialAd,sv,u,i−1 is activated in the context c = (e d i−1 = 0, e d+1 i−1 = 1).\nCase 2. For t = i, the decomposition reduces to ζ̂ d+1,u\ni:j = (ζ̂\nd,s i:j (u), u = xd+1i:j ),\nwhich leads to the following factorisation\nΦ[ζ̂ d+1,u\ni:j ] = Φ[ζ̂\nd,s i:j (u)]πd,su,i (50)\nThe state-initialisation potential πd,su,i plays the role in the context c = (e d i−1 = 1)\nHowever, these decompositions and factorisations only hold given the assumption of specific values of s ∈ Sd, v ∈ Sd+1, and t ∈ [1, i]. Without further information we have to take all possibilities into account. Substituting these relations into Equation 26, we have\nΛd+1,ui:j = ∑\ns∈Sd\n∑\nv∈Sd+1\n∑\nt∈[1,i−1]\n∑\nζd,s t:j (u)\n∑\nζd,s t:i−1 (v)\nΦ[ζ̂ d,s\nt:j (u)]Φ[ζ̂d,st:i−1(v)]A d+1,s v,u,i−1 +\n+ ∑\ns∈Sd\n∑\nζd,s i:j (u)\nΦ[ζ̂ d,s\ni:j (u)]πd,su,i\n= ∑\ns∈Sd\n∑\nt∈[1,i−1]\nλd,st:j (u) ∑\nv∈Sd+1\nαd,st:i−1(v)A d+1,s v,u,i−1 +\n∑\ns∈Sd\nλd,si:j (u)π d,s u,i (51)\nfor d ∈ [2, D − 2]. There are three special cases. The first is the base case where d = 0 and Λ1,s1:T = 1 for all s ∈ S1. In the second case, for d = 1, we must fix the index t = 1 since the asymmetric inside mass αd,st:i−1 is only defined at t = 1. Also the second term in the RHS is included only if i = 1 for the asymmetric outside mass λd,si:j (u) to make sense. In the second case, for d+ 1 = D, we only have i = j.\nRemark: Equations 47, 48 and 51 show a recursive top-down and outside-in approach to compute the symmetric/asymmetric outside masses. We start from the top with d = 1 and Λ1,s1:T = 1 for all s ∈ S\n1 and proceed downward until d = D. The pseudo-code is given in Figure 13. Figure 14 summarises the quantities computed in Section 4.2 and 4.3.\nFigure 15 summarises the AIO algorithm for computing all building blocks and the partition function."
    }, {
      "heading" : "5 The Generalised Viterbi Algorithm",
      "text" : "By definition the MAP assignment is the maximiser of the conditional distribution given an observation sequence z\nζMAP = argmax ζ Pr(ζ|z)\n= argmax ζ Φ[ζ, z] (52)\nFor clarity, let us drop the notation z and assume that it is implicitly there. The process of computing the MAP assignment is very similar to that of computing\nthe partition function. This similarity comes from the relation between the sum-product and max-product algorithm (a generalisation of the Viterbi algorithm) of Pearl (1988), and from the fact that inside/asymmetric inside procedures described in Section 4.2 are essentially a sum-product version. What we need to do is to just convert all the summations into corresponding maximisations. The algorithm is a two-step procedure:\n• In the first step the maximum joint potential is computed and local maximum states and ending indicators are saved along the way. These states and ending indicators are maintained in a bookkeeper.\n• In the second step we decode the best assignment by backtracking through saved local maximum states.\nWe make use of the contextual decompositions and factorisations from Section 4.2.\nNotations\nThis section, with some abuse, uses some slight modifications to the notations used in the rest of the paper. See Table 2 for reference.\nWe now describe the first step."
    }, {
      "heading" : "5.1 Computing the Maximum Joint Potential, Maximal States and",
      "text" : "Time Indices\nAs Φ[ζ] = Φ[ζ̂1,s1:T ]R 1,s 1:T for s ∈ S 1 we have\nmax ζ Φ[ζ] = max s∈S1 R1,s1:T max ζ1,s 1:T Φ[ζ̂1,s1:T ] (53)\nNow, for a sub-assignment ζd,si:j for 1 ∈ [1, D − 1], Equation 43 leads to\nmax ζd,s i:j\nΦ[ζ̂d,si:j ] = max u∈Sd+1 Ed,su,j max ζd,s i:j (u) Φ[ζ̂d,si:j (u)] (54)\nWith some slight abuse of notation we introduce ∆max,d,si:j as the optimal potential function of the subset of variables ζd,si:j , and α max,d,s i:j (u) as the optimal potential function of the subset of variables ζd,si:j (u).\nDefinition 7. We define ∆max,d,si:j and α max,d,s i:j (u) as follows\n∆max,d,si:j = max ζd,s i:j Φ[ζ̂d,si:j ] (55)\n∆̂max,d,si:j = ∆ max,d,s i:j R d,s i:j (56)\nαmax,d,si:j (u) = max ζd,s i:j (u) Φ[ζ̂d,si:j (u)] (57)\nThe Equations 53 and 54 can be rewritten more compactly as\nΦ[ζMAP ] = max s∈S1 ∆̂max,1,s1:T (58)\n∆max,d,si:j = max u∈Sd+1 Ed,su,jα max,d,s i:j (u) (59)\nfor d ∈ [1, D − 1]. When d = D, we simply set ∆max,D,si:i = 1 for all s ∈ S D and i ∈ [1, T ]. From the factorisation in Equation 38 and 39, we have\nmax ζd,s i:j (u) Φ[ζ̂d,si:j (u)] = max\n{( max\nv∈Sd+1 max t∈[i+1,j] Rd+1,ut:j A d+1,s v,u,t−1 max\nζd,s i:t−1\n(v) Φ[ζ̂d,si:t−1(v)]×\n× max ζd+1,u t:j\nΦ[ζ̂d+1,ut:j ]\n) ; ( Rd+1,ui:j max\nζd+1,u i:j\nπd,su,iΦ[ζ̂ d+1,u i:j ]\n)} (60)\nand\nαmax,d,si:j (u) = max\n{( max\nv∈Sd+1 max t∈[i+1,j] αmax,d,si:t−1 (v)∆̂ max,d+1,u t:j A d,s v,u,t−1\n) ;\n( ∆̂max,d+1,ui:j π d+1,s u,i )} (61)\nfor d ∈ [1, D− 2] and i < j. For d = D− 1, we cannot scan the index t in the interval [i+ 1, j] because the maximum inside ∆max,D,ut:j is only defined at t = j. We have the following instead\nαmax,D−1,si:j (u) = max v∈SD αmax,D−1,si:j−1 (v)∆̂ max,D,u j:j A D,s v,u,j−1 (62)\nThere is a base case for i = j, where the context c = (edi−1 = 1) is active, then\nαmax,d,si:i (u) = ∆̂ max,d+1,u i:i π d,s u,i (63)\nOf course, what we are really interested in is not the maximum joint potentials but the optimal states and time indices (or ending indicators). We need some bookkeepers to hold these quantities along the way. With some abuse of notation let us introduce the symmetric inside bookkeeper ∆arg,d,si:j associated with Equation 59, and the asymmetric inside bookkeeper αarg,d,si:j (u) associated with Equations 61, 62 and 63.\nDefinition 8. We define the symmetric inside bookkeeper ∆arg,d,si:j as follows\n∆arg,d,si:j = u ∗ = argmaxu∈Sd+1E d,s u,jα max,d,s i:j (u) (64)\nSimilarly, we define the asymmetric inside bookkeeper αarg,d,si:j (u) associated with Equation 61 for d ∈ [1, D − 2] as\nαarg,d,si:j (u) = (v, t) ∗ = argmaxt∈[i+1,j],v∈Sd+1α max,d,s i:t−1 (v)∆̂ max,d+1,u t:j A d,s v,u,t−1 (65)\nif maxv∈Sd+1,t∈[i+1,j] α max,d,s i:t−1 (v)∆̂ max,d+1,u t:j A d,s v,u,t−1 > ∆̂ max,d+1,u i:j π d+1,s u,i and i < j; and\nαarg,d,si:j (u) = undefined (66)\notherwise. For d = D − 1, the αarg,d,si:j (u) is associated with Equation 62\nαarg,D−1,si:j (u) = argmaxv∈SDα max,d,s i:j−1 (v)∆̂ max,D,u j:j A d,s v,u,j−1 (67)\nThe Equations 58,59,61,62 and 63 provide a recursive procedure to compute maximum joint potential in a bottom-up and left-right manner. Initially we just set ∆max,D,si:i = 1 for all s ∈ SD and i ∈ [1, T ]. The procedure is summarised in Figure 16."
    }, {
      "heading" : "5.2 Decoding the MAP Assignment",
      "text" : "The proceeding of the backtracking process is opposite to that of the max-product. Specifically, we start from the root and proceed in a top-down and right-left manner. The goal is to identify the right-most segment at each level. Formally, a segment is a triple (s, i, j) where s is the segment label, and i and j are start and end time indices, respectively. From the maximum inside ∆max,d,si:j at level d, we identify the best child u and its ending time j from Equation 59. This gives rise to the maximum asymmetric inside αmax,d,si:j (u). Then we seek for the best child v that transits to u under the same parent s using Equation 61. Since the starting time t for u has been identified the ending time for v is t − 1. We now have a right-most segment (u, t, j) at level d+ 1. The procedure is repeated until we reach the starting time i of the parent s. The backtracking algorithm is summarised in Figure 17.\nFinally, the generalised Viterbi algorithm is given in Figure 18.\nWorking in log-space to avoid numerical overflow\nWith long sequence and complex topology we may run into the problem of numerical overflow, i.e. when the numerical value of the maximum joint potential is beyond the number representation of the machine. To avoid this, we can work in the log-space instead, using the monotonic property of the log function. The equations in the logspace are summarised in Table 3."
    }, {
      "heading" : "6 Parameter Estimation",
      "text" : "In this section, we tackle the problem of parameter estimation by maximising the (conditional) data likelihood. Typically we need some parametric form to be defined for a particular problem and we need some numerical method to do the optimisation task.\nHere we employ the log-linear parameterisation, which is commonly used in the CRF setting. Recall from Section 2.3 that estimating parameters of the log-linear models using gradient-based methods requires the computation of feature expectation, or expected sufficient statistics (ESS). For our HSCRFs we need to compute four types of ESS corresponding to the state-persistence, state-transition, state-initialisation and state-ending."
    }, {
      "heading" : "6.1 Log-Linear Parameterisation",
      "text" : "In our HSCRF setting there is a feature vector fdσ(σ, z) associated with each type of contextual clique σ, in that φ(σd, z) = exp(w⊤σdf d σ(σ, z)). Thus, the features are active only in the context in which the corresponding contextual cliques appear. For the state-persistence contextual clique, the features incorporate state-duration, start time i and end time j of the state. Other feature types incorporate the time index in which the features are triggered. Specifically,\nRd,s,zi:j = exp(w ⊤ σpersist,d f d,s σpersist(i, j, z)) (68) Ad,s,zu,v,i = exp(w ⊤ σtransit,d f d,s σtransit,u,v(i, z) (69) πd,s,zu,i = exp(w ⊤ σinit,d f d,s σinit,u(i, z) (70) Ed,s,zu,i = exp(w ⊤ σend,df d,s σend,u (i, z) (71)\nDenote by Fdσ(ζ, z) the global feature, which is the sum of all active features f d σ(z) at level d in the duration [1, T ] for a given assignment of ζ and a clique type σ. Recall that τd = {ik}mk=1 is the set of ending time indices (i.e. e d ik\n= 1). The four feature types are given in Equations 72-75.\nF d,s σpersist(ζ, z) = f d,s σpersist(1, i1, z) +\n∑\nik∈τd,k>1\nf d,s σpersist(ik + 1, ik+1, z)(72)\nF d,s σtransit,u,v(ζ, z) =\n∑\nik /∈τd−1,ik∈τd\nf d,s σtransit,u,v(ik, z) (73)\nF d,s σinit,u(ζ, z) = f d,s σinit,u,v(1, z) +\n∑\nik∈τd\nf d,s σinit,u,v(ik + 1, z) (74)\nF d,s σend,u\n(ζ, z) = ∑\nik∈τd\nf d,s σend,u,v (i, z) (75)\nSubstituting the global features into potentials in Equation. 8 and 9 we obtain the following log-linear model:\nPr(ζ|z) = 1\nZ(z) exp(\n∑\nc∈C\nw ⊤ σcFσc(ζ, z)) (76)\nwhere C = {persist, transit, init, exit}. Again, for clarity of presentation we will drop the notion of z but implicitly assume that it is still in the each quantity."
    }, {
      "heading" : "6.2 ESS for State-Persistence Features",
      "text" : "Recall from Section 6.1 that the feature function for the state-persistence fd,sσpersist(i, j) is active only in the context where Πd,si:j ∈ ζ. Thus, Equation 72 can be rewritten as\nF d,s σpersist(ζ) =\n∑\ni∈[1,T ]\n∑\nj∈[i,T ]\nf d,s σpersist(i, j)δ[Π d,s i:j ∈ ζ] (77)\nThe indicator function in the RHS ensures that the feature fd,sσpersist(i, j) is only active if there exists a symmetric Markov blanket Πd,si:j in the assignment of ζ. Consider the following expectation\nE[fd,sσpersist(i, j)δ[Π d,s i:j ∈ ζ]] =\n∑\nζ\nPr(ζ)fd,sσpersist (i, j)δ[Π d,s i:j ∈ ζ] (78)\n= 1\nZ\n∑\nζ\nΦ[ζ]fd,sσpersist(i, j)δ[Π d,s i:j ∈ ζ] (79)\nUsing the factorisation in Equation 24 we can rewrite\nE[fd,sσpersist(i, j)δ[Π d,s i:j ∈ ζ]] =\n1\nZ\n∑\nζ\nΦ[ζ̂d,si:j ]Φ[ζ̂ d,s i:j ]Rd,si:j f d,s σpersist(i, j)δ[Π d,s i:j ∈ ζ] (80)\nNote that the elements inside the sum of the RHS are only non-zeros for those assignment of ζ that respect the persistent state sdi:j and the factorisation in Equation 24, i.e. ζ = (ζd,si:j , ζ d,s i:j ,Πd,si:j ). Thus, the equation can be simplified to\nE[fd,sσpersist(i, j)δ[Π d,s i:j ∈ ζ]] =\n1\nZ\n∑\nζd,s i:j\n∑\nζd,s i:j\nΦ[ζ̂d,si:j ]Φ[ζ̂ d,s i:j ]Rd,si:j f d,s σpersist(i, j)(81)\n= 1\nZ ∆d,si:j Λ d,s i:j R d,s i:j f d,s σpersist(i, j) (82)\nUsing Equation 77 we obtain the ESS for the state-persistence features\nE[F d,sk (ζ)] = ∑\ni∈[1,T ]\n∑\nj∈[i,T ]\nE[fd,sσpersist(i, j)δ[Π d,s i:j ∈ ζ]]\n= 1\nZ\n∑\ni∈[1,T ]\n∑\nj∈[i,T ]\n∆d,si:j Λ d,s i:j R d,s i:j f d,s σpersist(i, j) (83)\nThere are two special cases: (1) when d = 1, we do not sum over i, j but fix i = 1, j = T , and (2) when d = D then we keep j = i."
    }, {
      "heading" : "6.3 ESS for Transition Features",
      "text" : "Recall that in Section 6.1 we define fd,sσtransit,u,v(t) as a function that is active in the context ctransit = (ed−1t = 0, e d t = 1), in which the child state u\nd finishes its job at time t and transits to the child state vd under the same parent sd−1 (that is sd−1 is still running). Thus Equation 73 can be rewritten as\nF d,s σtransit,u,v(ζ) =\n∑\nt∈[1,T−1]\nf d,s σtransit,u,v(t)δ[c transit ∈ ζ] (84)\nWe now consider the following expectation\nE[fd,sσtransit,u,v(t)δ[c transit ∈ ζ]] =\n∑\nζ\nPr(ζ)fd,sσtransit ,u,v(t)δ[c transit ∈ ζ] (85)\n= 1\nZ\n∑\nζ\nΦ[ζ]fd,sσtransit,u,v(t)δ[c transit ∈ ζ](86)\nAssume that the parent s starts at i. Since edt = 1, the child v must starts at t + 1 and ends some time later at j ≥ t + 1. We have the following decomposition of the configuration ζ that respects this assumption\nζ = (ζ̂ d−1,s\ni:j (v), ζ̂d−1,si:t (u), ζ̂ d,v t+1:j) (87)\nand the following factorisation of the joint potential\nΦ[ζ] = Φ[ζ̂ d−1,s\ni:j (v)]Φ[ζ̂d−1,si:t (u)]Φ[ζ̂ d,v t+1:j ]R d,v t+1:jA d,s u,v,t (88)\nThe state persistent potential Rd,vt+1:j is enabled in the context c = (e d t = 1, e d t+1:j−1 = 0, edj = 1) and the state transition potential A d,s u,v,t in the context c\ntransit. Substituting this factorisation into the RHS of Equation 86 gives us\n1\nZ\n∑\ni∈[1,t]\n∑\nj∈[t+1,T ]\n∑\nζd−1,si:t (u)\n∑\nζd−1,s i:j (v)\n∑\nζd,vt+1:j\nΦ[ζ̂ d−1,s\ni:j (v)]Φ[ζ̂d−1,si:t (u)]Φ[ζ̂ d,v t+1:j ]R d,v t+1:jA d,s u,v,tf d,s σtransit,u,v(t)\nwhich can be simplified to\n1\nZ\n∑\ni∈[1,t]\n∑\nj∈[t+1,T ]\nλd−1,si:j (v)α d−1,s i:t (u)∆̂ d,v t+1:jA d,s u,v,tf d,s σtransit,u,v(t) (89)\nUsing Equations 84 and 89 we obtain the ESS for the state-transition features\nE[Fd,sσtransit,u,v(ζ)] = ∑\nt∈[1,T−1]\nE[fd,sσtransit,u,v(t)δ[c transit ∈ ζ]]\n= 1\nZ\n∑\nt∈[1,T−1]\nAd,su,v,tf d,s σtransit,u,v(t)\n∑\ni∈[1,t]\n∑\nj∈[t+1,T ]\nαd−1,si:t (u)λ d−1,s i:j (v)∆̂ d,v t+1:j(90)\nWhen d = 2 we must fix i = 1 since α1,si:t (u) and λ 1,s i:j (v) are only defined at i = 1."
    }, {
      "heading" : "6.4 ESS for Initialisation Features",
      "text" : "Recall that in Section 6.1 we define fd,sσinit,u(i) as a function at level d that is triggered at time i when a parent s at level d initialises a child u at level d + 1. In this event, the context cinit = (edi−1 = 1) must be activated for i > 1. Thus, Equation 74 can be rewritten as\nF d,s σinit,u(ζ) =\n∑\ni∈[1,T ]\nf d,s σinit,u(i)δ[c init ∈ ζ] (91)\nNow we consider the following feature expectation\nE[fd,sσinit,u(i)δ[c init ∈ ζ]] =\n∑\nζ\nPr(ζ)fd,sσinit ,u(i)δ[c init ∈ ζ]\n= 1\nZ\n∑\nζ\nΦ[ζ]fd,sσinit,u(i)δ[c init ∈ ζ] (92)\nFor each assignment of ζ that enables fd,sσinit,u(i), we have the following decomposition\nζ = (ζ̂ d,s\ni:j (u), ζ̂d+1,ui:j ) (93)\nwhere the context cinit activates the emission from s to u and the feature function f d,s σinit,u(i). Thus the joint potential Φ[ζ] can be factorised as\nΦ[ζ] = Φ[ζ̂ d,s\ni:j (u)]Φ[ζ̂d+1,ui:j ]R d+1,u i:j π d,s u,i (94)\nUsing this factorisation and noting that the elements within the summation in the RHS of Equation 92 are only non-zeros with such assignments, we can simplify the RHS of Equation 92 to\n1\nZ\n∑\nj∈[i,T ]\n∑\nζd,s i:j (u)\n∑\nζd+1,u i:j\nΦ[ζ̂ d,s\ni:j (u)]Φ[ζ̂d+1,ui:j ]R d+1,u i:j π d,s u,i f d,s σinit,u(i)\n= 1\nZ\n∑\nj∈[i,T ]\nλd,si:j (u)∆̂ d+1,u i:j π d,s u,i f d,s σinit,u(i) (95)\nThe summation over j ∈ [i, T ] is due to the fact that we do not know this index. Using Equation 91 and 95 we obtain the ESS for the initialisation features\nE[Fd,sσinit,u(ζ)] = ∑\ni∈[1,T ]\nE[fd,sσinit,u(i)δ[c init ∈ ζ]]\n= 1\nZ\n∑\ni∈[1,T ]\nπd,su,i f d,s σinit,u(i)\n∑\nj∈[i,T ]\nλd,si:j (u)∆̂ d+1,u i:j (96)\nThere are two special cases: (1) when d = 1, there must be no scanning of i but fix i = 1 since there is only a single initialisation at the beginning of sequence, (2) when d = D − 1, we fix j = i for ∆̂D,ui:j is only defined at i = j."
    }, {
      "heading" : "6.5 ESS for Ending Features",
      "text" : "Recall that in Section 6.1 we define fd,s σend,u\n(j) as a function that is activated when a child u at level d+1 returns the control to its parent s at level d and time j. This event also enables the context cend = (edj = 1). Thus Equation 75 can be rewritten as\nF d,s σend,u\n(ζ) = ∑\nj∈[1,T ]\nf d,s σend,u (j)δ[cend ∈ ζ] (97)\nNow we consider the following feature expectation\nE[fd,s σend,u\n(j)δ[cend ∈ ζ]] = ∑\nζ\nPr(ζ)fd,s σend ,u (j)δ[cend ∈ ζ]\n= 1\nZ\n∑\nζ\nΦ[ζ]fd,s σend,u (j)δ[cend ∈ ζ] (98)\nAssume that the state s starts at i and ends at j. For each assignment of ζ that enables f d,s σend,u (j) and respects this assumption, we have the following decomposition\nζ = (ζ̂ d,s\ni:j , ζ̂d,si:j (u)) (99)\nThis assignment has the context cend that activates the ending of u. Thus the joint potential Φ[ζ] can be factorised as\nΦ[ζ] = Φ[ζ̂ d,s\ni:j ]Φ[ζ̂d,si:j (u)]R d,s i:j E d,s u,j (100)\nSubstituting this factorisation into the summation of the RHS of Equation 98 yields ∑\ni∈[1,j]\n∑\nζ d,s i:j\n∑\nζ d,s i:j (u)\nΦ[ζ̂ d,s i:j ]Φ[ζ̂d,si:j (u)]R d,s i:j E d,s u,jf d,s σend,u (j) = ∑\ni∈[1,j]\nΛ̂d,si:j α d,s i:j (u)E d,s u,jf d,s σend,u (j)(101)\nUsing Equations 97 and 101 we obtain the ESS for the exiting features\nE[Fd,s σend,u\n(ζ)] = ∑\nj∈[1,T ]\nE[fd,s σend,u (j)δ[edi−1 ∈ ζ]]\n= 1\nZ\n∑\nj∈[1,T ]\nEd,su,jf d,s σend,u\n(j) ∑\ni∈[1,j]\nΛ̂d,si:j α d,s i:j (u) (102)\nThere is a special case: when d = 1 there must be no scanning of i, j but fix i = 1, j = T ."
    }, {
      "heading" : "7 Partially Observed Data in Learning and Inference",
      "text" : "So far we have assumed that training data is fully labeled, and that testing data does not have any labels. In this section we extend the AIO to handle the cases in which these assumptions do not hold. Specifically, it may happen that the training data is not completely labeled, possibly due to lack of labeling resources. In this case, the learning algorithm should be robust enough to handle missing labels. On the other hand, during inference, we may partially obtain high quality labels from external sources. This requires the inference algorithm to be responsive to that data."
    }, {
      "heading" : "7.1 The Constrained AIO algorithm",
      "text" : "In this section we consider the general case when ζ = (ϑ, h), where ϑ is the visible set labels, and h the hidden set. Since our HSCRF is also an exponential model it shares the same computation required for general CRFs (Equations 6 and 7). We have to compute four quantities: the partial log-partition function Z(ϑ, z), the partition function Z(z), the ‘constrained’ ESS Eh|ϑ,z[F(ϑ, h, z)], and the ‘free’ ESS Eζ|z[F(ζ, z)]. The partition function and the ‘free’ ESS has been computed in Sections 4 and 6, respectively. This section describes the other two quantities.\nLet the set of visible labels be ϑ = (x̃, ẽ) where x̃ is the visible set of state variables and ẽ is the visible set of ending indicators. The basic idea is that we have to modify procedures for computing the building blocks such as ∆d,si:j and α d,s i:j (u), to address constraints imposed by the labels. For example, ∆d,si:j implies that the state s at level d starts at i and persists till terminating at j. Then, if any labels (e.g. there is an x̃dk 6= s for k ∈ [i, j]) are seen, causing this assumption to be inconsistent, ∆ d,s i:j will be zero. Therefore, in general, the computation of each building block is multiplied by an identity function that enforces the consistency between these labels and the required constraints for computation of that block. As an example, we consider the computation of ∆d,si:j and α d,s i:j (u).\nThe symmetric inside mass ∆d,si:j is consistent only if all of the following conditions are satisfied:\n1. If there are state labels x̃dk at level d within the interval [i, j], then x̃ d k = s,\n2. If there is any label of ending indicator ẽdi−1, then ẽ d i−1 = 1,\n3. If there is any label of ending indicator ẽdk for some k ∈ [i, j − 1], then ẽ d k = 0,\nand\n4. If any ending indicator ẽdj is labeled, then ẽ d j = 1.\nThese conditions are captured by using the following identity function:\nI[∆d,si:j ] = δ[x̃ d k∈[i,j] = s]δ[ẽ d i−1 = 1]δ[ẽ d k∈[i:j−1] = 0]δ[ẽ d j = 1] (103)\nWhen labels are observed, Equation 44 is thus replaced by\n∆d,si:j = I[∆ d,s i:j ]\n( ∑\nu∈Sd+1\nαd,si:j (u)E d,s u,j\n) (104)\nNote that we do not need to explicitly enforce the state consistency in the summation over u since in the bottom-up and left-right computation, αd,si:j (u) is already computed and contributes to the sum only if it is consistent.\nAnalogously, the asymmetric inside mass αd,si:j (u) is consistent if all of the following conditions are satisfied:\n1. The first three conditions for the symmetric inside mass ∆d,si:j hold,\n2. If the state at level d at time j is labeled, it must be u, and\n3. If any ending indicator ẽd+1j is labeled, then ẽ d+1 j = 1.\nThese conditions are captured by the identity function\nI[αd,si:j (u)] = δ[x̃ d k∈[i,j] = s]δ[ẽ d i−1 = 1]δ[ẽ d k∈[i:j−1] = 0]δ[x̃ d+1 j = u]δ[ẽ d+1 j = 1](105)\nThus Equation 40 becomes\nαd,si:j (u) = I[α d,s i:j (u)]\n( j∑\nk=i+1\n∑\nv∈Sd+1\nαd,si:k−1(v)∆̂ d+1,u k:j A d,s v,u,k−1 + ∆̂ d+1,u i:j π d+1,s u,i\n) (106)\nNote that we do not need to explicitly enforce the state consistency in the summation over v and time consistency in the summation over k since in bottom-up computation, αd,si:j (u) and ∆ d+1,u k:j are already computed and contribute to the sum only if they are consistent. Finally, the constrained partition function Z(ϑ, z) is computed using Equation 29 given that the inside mass is consistent with the observations.\nOther building blocks, such as the symmetric outside mass Λd,si:j and the asymmetric\noutside mass λd,si:j (u), are computed in an analogous way. Since Λ d,s i:j and ∆ d,s i:j are complementary and they share (d, s, i, j), the same indicator function I[∆d,si:j ] can be applied. Similarly, the pair asymmetric inside mass αd,si:j (u) and asymmetric outside mass λd,si:j (u) are complementary and they share d, s, i, j, u, thus the same indicator function I[αd,si:j (u)] can be applied. Once all constrained building blocks have been computed they can be used to calculate constrained ESS as in Section 6 without any further modifications. The only difference is that we need to replace the partition function Z(z) by the constrained version Z(ϑ, z)."
    }, {
      "heading" : "7.2 The Constrained Viterbi Algorithm",
      "text" : "Recall that in the Generalised Viterbi Algorithm described in Section 5 we want to find the most probable configuration ζMAP = argmaxζ Pr(ζ|z). When some variables ϑ of ζ are labeled, it is not necessary to estimate them. The task is now to estimate the most probable configuration of the hidden variables h given the labels:\nhMAP = argmax h Pr(h|ϑ, z)\n= argmax h Pr(h, ϑ|z)\n= argmax h Φ[h, ϑ, z] (107)\nIt turns out that the constrained MAP estimation is identical to the standard MAP except that we have to respect the labeled variables ϑ.\nSince the Viterbi algorithm is just the max-product version of the AIO, the constrained Viterbi can be modified in the same manner as in the constrained AIO (Section 7.1). Specifically, for each auxiliary quantities such as ∆max,si:j and α max,s i:j (u), we\nneed to maintain a set of indicator functions that ensures the consistency with labels. Equations 103 and 104 become\nI[∆max,d,si:j ] = δ[x̃ d k∈[i,j] = s]δ[ẽ d i−1 = 1]δ[ẽ d k∈[i:j−1] = 0]δ[ẽ d j = 1]\n∆max,d,si:j = I[∆ max,d,s i:j ]\n( max\nu∈Sd+1 αmax,d,si:j (u)E d,s u,j\n) (108)\nLikewise, we have the modifications to Equation 105 and Equation 106, respectively.\nI[αmax,d,si:j (u)] = δ[x̃ d k∈[i,j] = s]δ[ẽ d i−1 = 1]δ[ẽ d k∈[i:j−1] = 0]δ[x̃ d+1 j = u]δ[ẽ d+1 j = 1]\nαmax,d,si:j (u) = I[α max,d,s i:j (u)]max\n{ max\nk∈[i+1,j] max v∈Sd+1 αmax,d,si:k−1 (v)∆̂ max,d+1,u k:j A d,s v,u,k−1;\n∆̂max,d+1,ui:j π d+1,s u,i\n} (109)\nOther tasks in the Viterbi algorithm including bookkeeping and backtracking are identical to those described in Section 5."
    }, {
      "heading" : "7.3 Complexity Analysis",
      "text" : "The complexity of the constrained AIO and constrained Viterbi has an upper bound of O(T 3), when no labels are given. It also has a lower bound of O(T ) when all ending indicators are known and the model reduces to the standard tree-structured graphical model. In general, the complexity decreases as more labels are available, and we can expect a sub-cubic time behaviour."
    }, {
      "heading" : "8 Numerical Scaling",
      "text" : "In previous sections, we have derived AIO-based inference and learning algorithms for both unconstrained and constrained models. The quantities computed by these algorithms like the inside/outside masses often involve summation over exponentially many positive potentials. The potentials, when estimated from data, are often not upperbound, leading to the fact that the magnitude of the masses increases exponentially fast in the sequence length T , thus goes beyond the numerical capacity of most machines for moderate T .\nIn this section we present a scaling method to reduce this numerical overflow problem. The idea can be traced back to the Pearl’s message-passing procedure (Pearl, 1988; Yedidia et al., 2005). Our AIO algorithms can be considered as generalisation of the message-passing, in which the inside masses play the role of the inside-out messages. In Pearl’s method, we reduce the messages’ magnitude by normalising them at each step. In the context of HHMMs with which the numerical underflow problem is associated, the similar idea has been proposed in (Bui et al., 2004), which we adapt to our overflow problem."
    }, {
      "heading" : "8.1 Scaling the Symmetric/Asymmetric Inside Masses",
      "text" : "Before proceeding to algorithmic details let us revisit Equation 44. If we scale down the asymmetric inside mass αd,si:j (u) by a factor κj > 1, i.e.\nα ′d,s i:j (u) ←\nαd,si:j (u)\nκj (110)\nthen the symmetric inside mass ∆d,si:j is also scaled down by the same factor. Similarly, as we can see from Equation 40 that\nαd,si:j (u) =\nj∑\nt=i+1\n∑\nv∈Sd+1\nαd,si:t−1(v)∆̂ d+1,u t:j A d,s v,u,t−1 + ∆̂ d+1,u i:j π d,s u,i\nwhere ∆̂d+1,ut:j = ∆ d+1,u t:j R d+1,u t:j , if ∆ d+1,u t:j for t ∈ [1, j] is reduced by κj , then α d,s i:j is also reduced by the same factor. In addition, using the set of recursive relations in Equations 40 and 44, any reduction at the bottom level of ∆D,sj:j will result in the reduction of the symmetric inside mass ∆d,si:j and of the asymmetric inside mass α d,s i:j (u), for d < D, by the same factor. Suppose ∆D,si:i for all i ∈ [1, j] is reduced by a factor of κi > 1, the quantities ∆ d,s 1:j and αd,s1:j (u) will be reduced by a factor of ∏j i=1 κi. That is\n∆̂ ′d,s 1:j ← ∆̂d,s1:j∏j i=1 κi\n(111)\nα ′d,s 1:j (u) ← αd,s1:j (u)∏j i=1 κi\n(112)\nIt follows immediately from Equation 29 that the partition function is scaled down by a factor of ∏T i=1 κi\nZ ′ = ∑\ns∈S1\n∆̂ ′1,s 1:T = Z ∏T\nj=1 κj (113)\nwhere ∆̂ ′1,s 1:T = ∆ ′1,s 1:T B 1,s 1:T . Clearly, we should deal with the log of this quantity to avoid numerical overflow. Thus, the log-partition function can be computed as\nlog(Z) = log ∑\ns∈S1\n∆̂ ′1,s 1:T +\nT∑\nj=1\nlog κj (114)\nwhere ∆ ′1,s 1:T has been scaled appropriately.\nOne question is how to choose the set of meaningful scaling factors {κj}T1 . The simplest way is to choose a relatively large number for all scaling factors but making the right choice is not straightforward. Here we describe a more natural way to do so. Assume that we have chosen all the scaling factors {κi} j−1 1 . Using the original\nEquations 40, 41, and 42, where all the sub-components have been scaled appropriately, we compute the partially-scaled inside mass ∆\n′′d,s i:j for d ∈ [2, D] and asymmetric\ninside mass α ′′d,s i:j (u), for d ∈ [1, D − 1] and i ∈ [1, j]. Then the scaling factor at time j is computed as\nκj = ∑\ns,u\nα ′′1,s 1:j (u) (115)\nThe next step is to rescale all the partially-scaled variables:\nα ′d,s i:j (u) ←\nα ′′d,s i:j (u)\nκj for s ∈ Sd, d ∈ [1, D − 1] (116)\n∆ ′d,s i:j ←\n∆ ′′d,s i:j\nκj for s ∈ Sd, d ∈ [2, D − 1] (117)\n∆ ′D,s j:j ←\n∆ ′′D,s j:j\nκj for s ∈ SD (118)\nwhere i ∈ [1, j]."
    }, {
      "heading" : "8.2 Scaling the Symmetric/Asymmetric Outside Masses",
      "text" : "In a similar fashion we can work out the set of factors from the derivation of symmetric/asymmetric outside masses since these masses solely depend on the inside masses as building blocks. In other words, after we finish scaling the inside masses we can compute the scaled outside masses directly, using the same set of equations described in Section 4.3.\nThe algorithm is summarised in Figure 19. Note that the order of performing the loops in this case is different from that in Figure 12."
    }, {
      "heading" : "9 Applications",
      "text" : ""
    }, {
      "heading" : "9.1 Recognising Indoor Activities",
      "text" : "In this experiment, we evaluate the HSCRFs with a relatively small dataset from the domain of indoor video surveillance. The task is to recognise indoor trajectories and activities of a person from his noisy positions extracted from video. The data, which was captured in (Nguyen et al., 2005), and subsequently used to evaluate DCRFs in (Truyen et al., 2006), has 90 sequences, each of which corresponds to one of 3 the persistent activities: (1) preparing short-meal, (2) having snack and (3) preparing normal-meal. The persistent activities share the some of 12 sub-trajectories. Each sub-trajectory is a sub-sequence of discrete positions. Thus naturally, the data has a state hierarchy of depth 3: the dummy root for each position sequence, the persistent activities, and the sub-trajectories. The input observations to the model are simply sequences of discrete positions.\nWe split the data into two sets of equal size for training and testing, respectively. For learning, labels for each sequence are provided fully for the case of fully observed state data, and partially for the case of missing state data. For testing, no labels are given to the decoder, and decoded labels obtained from the max-product algorithm are compared against the ground-truth.\nIn designing features, we assume that state features (i.e. between nodes) such as initialisation, transition and exiting are indicator functions. For the data-associations (i.e. embedded in state-persistence potentials) at the bottom level, we use the same features as in (Truyen et al., 2006). At the second level, we use average velocities and a vector of positions visited in the state duration. To encode the duration into the statepersistence potentials, we employ the sufficient statistics of the gamma distribution as features fk(s,∆t) = I(s) log(∆t) and fk+1(s,∆t) = I(s)(∆t).\nAt each level d and time t we count an error if the predicted state is not the same as the ground-truth. Firstly, we examine the fully observed case where the HSCRF is compared against the DCRF at both data levels, and against the flat-CRF at bottom level. Table 4 (the left half) shows that (a) both the multilevel models significantly outperform the flat model and (b) the HSCRF outperforms the DCRF.\nWe also test the ability of the model to learn the hierarchical topology and state transitions. We find the it is very informative to examine parameters which correspond to the state transition features. Typically, negative entries in the transition parameter matrix means that the transition is improbable. This is because state features are non-negative, so negative parameters mean the probabilities of these transitions are very small (due to the exponential), compared to the positive ones. For the transition at the second level (the complex activity level), we obtain all negative entries. This clearly match the training data, in which each sequence already belongs to one of three complex activities. With this method, we are able to construct the correct hierarchical topology as in Figure 20. The state transition model is presented in Figure 21. There is only one wrong transition, from state 12 to state 10, which is not presented in the training data. The rest is correct.\nNext we consider partially-supervised learning in that about 50% of start/end times of a segment and segment labels are observed at the second level. All ending indicators are known at the bottom level. The results are reported in Table 4 (the right half). As can be seen, although only 50% of the state labels and state start/end times are observed, the model learned is still performing well with accuracy of 80.2% and 90.4% at levels 2 and 3, respectively.\nWe now consider the issue of using partial observed labels during decoding to improve prediction accuracy of poorly estimated models. We extract the parameters from the 10th iteration of the fully observed data case. The labels are provided at random time indexes. Figure 22a shows the decoding accuracy as a function of available state labels. It is interesting to observe that a moderate amount of observed labels (e.g. 20− 40%) causes the accuracy rate to go up considerably."
    }, {
      "heading" : "9.2 POS Tagging and Noun-Phrase Chunking",
      "text" : "In this experiment we apply the HSCRF to the task of noun-phrase chunking. The data is from the CoNLL-2000 shared task (Sang and Buchholz, 2000), in which 8926\nEnglish sentences from the Wall Street Journal corpus are used for training and 2012 sentences are for testing. Each word in a pre-processed sentence is labeled by two labels: the part-of-speech (POS) and the noun-phrase (NP). There are 48 POS different labels and 3 NP labels (B-NP for beginning of a noun-phrase, I-NP for inside a noun-phrase or O for others). Each noun-phrase generally has more than one word. To reduce the computational burden, we reduce the POS tag-set to 5 groups: noun, verb, adjective, adverb and others. Since in our HSCRFs we do not have to explicitly indicate which node is at the beginning of a segment, the NP label set can be reduced further into NP for noun-phrase, and O for anything else.\nThe POS tags are actually the output of the Brill’s tagger (Brill, 1995), while the NPs are manually labeled. We extract raw features from the text in the way similar to that in (Sutton et al., 2007). However, we consider only a limited vocabulary extracted from the training data in that we only select words with more than 3 occurrences. This reduces the vocabulary and the feature size significantly. We also make use of bi-grams with similar selection criteria. Furthermore, we use the contextual window of 5 instead of 7 as in (Sutton et al., 2007). This setting gives rise to about 32K raw features. The model feature is factorised as f(xc, z) = I(xc)gc(z), where I(xc) is a binary function on the assignment of the clique variables xc, and gc(z) are the raw features.\nWe build an HSCRF topology of 3 levels where the root is just a dummy node, the second level has 2 NP states and the bottom level has 5 POS states. For comparison, we implement a DCRF, a simple sequential CRF (SCRF), and a semi-Markov CRF (SemiCRF) (Sarawagi and Cohen, 2004). The DCRF has grid structure of depth 2, one for modelling the NP process and another for the POS process. Since the state spaces are relatively small, we are able to run exact inference in the DCRF by collapsing both the NP and POS state spaces to a combined state space of size 3 × 5 = 15. The SCRF and SemiCRF model only the NP process, taking the POS tags as input.\nThe raw feature set used in the DCRF is identical to those in our HSCRF. However, the set shared by the SCRF and the SemiCRF is a little more elaborate since it takes the POS tags into account (Sutton et al., 2007).\nAlthough both the HSCRF and the SemiCRF are capable of modelling arbitrary segment durations, we use a simple exponential distribution as it can be processed sequentially and thus is very efficient. For learning, we use a simple online stochastic gradient ascent method since it has been shown to work relatively well and fast in CRFs (Vishwanathan et al., 2006). At test time, as the SCRF and the SemiCRF are able to use the Brill’s POS tags as input, it is not fair for the DCRF and HSCRF to predict those labels during inference. Instead, we also give the POS tags to the DCRF and HSCRF and perform constrained inference to predict only the NP labels. This boosts the performance of the two multi-level models significantly.\nThe performance of these models is depicted in Figure 23 and we are interested in only the prediction of the noun-phrases since this data has Brill’s POS tags. Without Brill’s POS tags given at test time, both the HSCRF and the DCRF perform worse than the SCRF. This is not surprising because the Brill’s POS tags are always given in the case of SCRF. However, with POS tags the HSCRF consistently works better than all other models. The DCRF does worse than the SCRF, even with POS tags given. This does not share the observation made in (Sutton et al., 2007). However, we use a much smaller POS tag set than (Sutton et al., 2007) does. Our explanation is that the SCRF is\nable to make use of wider context of the given POS tags (here, within the window of 5 tags) than the DCRF (limited to 1 POS tag per NP chunk). The SemiCRF, although in theory it is more expressive than the SCRF, does not show any advantage under current setting. Recall that the SemiCRF is a special case of HSCRF in that the POS level is not modelled, it is possible to conclude that joint modelling of NP and POS levels is important."
    }, {
      "heading" : "10 Conclusions",
      "text" : "In this paper, we have presented a novel model called Hierarchical Semi-Markov Conditional Random Field which extends the standard CRFs to incorporate hierarchical and multilevel semantics. We have developed a graphical model-like dynamic representation of the HSCRF. This appears similar to the DBN representation of the HHMMs in (Murphy and Paskin, 2002), and somewhat resembles a dynamic factor graph (Kschischang et al., 2001). However, it is not exactly the standard graphical model because the contextual cliques in HSCRFs are not fixed during inference.\nWe have derived efficient algorithms for learning and inference, especially the ability to learn and inference with partially given labels. We have demonstrated the capacity of the HSCRFs on home video surveillance data and the shallow parsing of English text, in which the hierarchical information inherent in the context helps to increase the recognition.\nIn future work we plan to attack the computational bottleneck in large-scale settings. Although the AIO family has cubic time complexity, it is still expensive in large-scale application, especially those with long sequences. It is therefore desirable to introduce approximation methods that can provide speed/quality trade-offs.\nWe also need to make a choice between pre-computing all the potentials prior to inference and learning, and computing them on-the-fly. The first choice requires O(D|S|3T 2) space, which is very significant with typical real-world problems, even with today’s computing power. The second choice, however, will slow the inference and learning very significantly due to repeated computation at every step of the AIO algorithm.\nPerhaps one of the most interesting point is that how good the HSCRFs can be an approximation to general multilevel processes, which are not necessarily recursive. For example, it is interesting to see if any data which is naturally represented as a DCRF can be approximately represented by an HSCRF. This is important because HSCRFs are tractable while DCRFs are generally not. Some data is intrinsically sequential in the sense that there is no really ‘exiting’ point. The HSCRFs force some transitions at the edge of segments to be broken, so the best HSCRFs can do is to model quite long segments."
    }, {
      "heading" : "A Proofs",
      "text" : "A.1 Proof of Propositions 1 and 2\nBefore proving Proposition 1 and 2 let us introduce a lemma.\nLemma 1. Given a distribution of the form\nPr(x) = 1\nZ Φ[x] (119)\nwhere x = (xa, xs, xb), if there exists a factorisation\nΦ[x] = Φ[xa, xs]Φ[xs]Φ[xs, xb] (120)\nthen xa and xb are conditionally independent given xs.\nProof: We want to prove that\nPr(xa, xb|xs) = Pr(xa|xs) Pr(xb|xs) (121)\nSince Pr(xa, xb|xs) = Pr(xa, xb, xs)/ ∑\nxa,xb Pr(xa, xb, xs), the LHS of Equa-\ntion 121 becomes\nPr(xa, xb|xs) = Φ[xa, xs]Φ[xs]Φ[xs, xb]∑\nxa,xb Φ[xa, xs]Φ[xs]Φ[xs, xb]\n= Φ[xa, xs]∑ xa Φ[xa, xs] Φ[xs, xb]∑ xb Φ[xs, xb] (122)\nwhere we have used the following fact\n∑\nxa,xb\nΦ[xa, xs]Φ[xs]Φ[xs, xb] = Φ[xs]\n(∑\nxa\nΦ[xa, xs]\n)(∑\nxb\nΦ[xs, xb]\n) (123)\nand canceled out the normalisation factor Z and Φ[xs]. To provePr(xa|xs) = Φ[xa, xs]/ ∑ xa\nΦ[xa, xs], we need only to showPr(xa|xs) ∝ Φ[xa, xs] since the normalisation over xa is due to ∑ xa\nPr(xa|xs) = 1. Using the Bayes rule, we have\nPr(xa|xs) ∝ Pr(xa, xs)\n= ∑\nxb\nPr(xa, xs, xb)\n= 1\nZ Φ[xa, xs]Φ[xs]\n∑\nxb\nΦ[xs, xb]\n∝ Φ[xa, xs] (124)\nwhere we have ignored all the factors that do not depend on xa. A similar proof gives Pr(xb|xs) = Φ[xs, xb]/ ∑ xb\nΦ[xs, xb]. Combining this result and Equation 124 with Equation 122 gives us Equation 121. This completes the proof\nIn fact, xs acts as a separator between xa and xb. In standard Markov networks there are no paths from xa to xb that do not go through xs. Now we proceed to proving Proposition 1 and 2.\nGiven the symmetric Markov blanket Πd,si:j , there are no potentials that are associ-\nated with variables belonging to both ζd,si:j and ζ d,s i:j . The blanket completely separates the ζd,si:j and ζ d,s i:j . Therefore, Lemma 1 ensures the conditional independence between ζd,si:j and ζ d,s i:j .\nSimilarly, the asymmetric Markov blanket Γd,si:j (u) separates ζ d,s i:j (u) and ζ d,s i:j (u)\nand thus these two variable sets are conditionally independent due to Lemma 1\nA.2 Proof of Proposition 3\nHere we want to derive Equations 32, 33 and 34. With the same conditions as in Lemma 1, in Equation 124 we have shown that Pr(xa|xs) ∝ Φ[xa, xs]. Similarly, this extends to\nPr(ζd,si:j |Π d,s i:j ) ∝ Φ[ζ d,s i:j ,Π d,s i:j ]\n= Φ[ζ̂d,si:j ] (125)\nwhich is equivalent to\nPr(ζd,si:j |Π d,s i:j ) = 1 ∑\nζd,s i:j\nΦ[ζ̂d,si:j ] Φ[ζ̂d,si:j ]\n= 1\n∆d,si:j Φ[ζ̂d,si:j ] (126)\nThe last equation follows from the definition of the symmetric inside mass in Equation 25. Similar procedure will yield Equation 33.\nTo prove Equation 34, notice the Equation 21 that says\nPr(ζ) = Pr(Πd,si:j ) Pr(ζ d,s i:j |Π d,s i:j ) Pr(ζ d,s i:j |Πd,si:j ) (127)\nor equivalently\nPr(Πd,si:j ) = Pr(ζ) 1\nPr(ζd,si:j |Π d,s i:j )\n1\nPr(ζd,s i:j |Πd,si:j ) (128)\n= 1\nZ Φ[ζ]\n∆d,si:j\nΦ[ζ̂d,si:j ]\nΛd,si:j\nΦ[ζ̂ d,s\ni:j ]\n(129)\n= 1\nZ Φ[ζ̂d,si:j ]R d,s i:j Φ[ζ̂\nd,s i:j ] ∆d,si:j\nΦ[ζ̂d,si:j ]\nΛd,si:j\nΦ[ζ̂ d,s\ni:j ]\n(130)\n= 1\nZ ∆d,si:j R d,s i:j Λ d,s i:j (131)\nIn the proof proceeding, we have made use of the relation in Equation 24. This completes the proof"
    }, {
      "heading" : "B Computing the State Marginals of HSCRF",
      "text" : "We are interested in computing the marginals of state variables Pr(xdt ). We have\nPr(xdt ) = ∑\nζ\\xdt\nPr(xdt , ζ\\x d t )\n= ∑\nζ\nPr(ζ)δ(xdt ∈ ζ)\n= 1\nZ\n∑\nζ\nΦ[ζ]δ(xdt ∈ ζ) (132)\nLet s = xdt and assume that the state s starts at i and end at j, and t ∈ [i, j]. For each configuration ζ that respects this assumption, we have the factorisation of Equation 24 that says\nΦ[ζ] = Φ[ζ̂d,si:j ]Φ[ζ̂ d,s i:j ]Rd,si:j (133)\nThen Equation 132 becomes\nPr(xdt = s) = 1\nZ\n∑\nζ\nΦ[ζ̂d,si:j ]Φ[ζ̂ d,s i:j ]Rd,si:j δ(t ∈ [i, j])\n= 1\nZ\n∑\ni∈[1,t]\n∑\nj∈[t,T ]\n∆d,si:j Λ d,s i:j R d,s i:j (134)\nThe summing over i and j is due to the fact that we do not know these indices. There are two special cases, (1) when d = 1 we cannot scan the left and right indices, the marginals are simply\nPr(x1t = s) = 1\nZ ∆̂1,s1:T (135)\nsince Λ1,s1:T = 1 for all s ∈ S 1; and (2) when d = D, the start and end times must be the same (i = j), thus\nPr(xDt = s) = 1\nZ Λ̂D,st:t (136)\nsince ∆D,st:t = 1 for all t ∈ [1, T ] and s ∈ S D.\nSince ∑\ns∈Sd Pr(x d t = s) = 1, it follows from Equation 134 that\nZ = ∑\ns∈Sd\n∑\ni∈[1,t]\n∑\nj∈[t,T ]\n∆d,si:j Λ d,s i:j R d,s i:j (137)\nThis turns out to be the most general way of computing the partition function. Some special cases have been shown earlier. For example, when d = 1, i = 1 and j = T , Equation 137 becomes Equation 29 since Λ1,s1:T = 1. Similarly, when d = D, i = j = t, Equation 137 recovers Equation 30 since ∆D,si:i = 1."
    }, {
      "heading" : "C Semi-Markov CRFs as Special Case of HSCRFs",
      "text" : "In this Appendix we first describe the semi-Markov CRF (SemiCRF) (Sarawagi and Cohen, 2004) in our HSCRF framework and show how to convert a SemiCRF into an HSCRF. Then under the light of HSCRF inference we show how to modify the original SemiCRF to handle (a) partial supervision and constrained inference, and (b) numerical scaling to avoid overflow. The modifications are of interest in their own right.\nC.1 SemiCRF as an HSCRF\nSemiCRF is an interesting flat segmental undirected model that generalises the chain CRF. In the SemiCRF framework the Markov process operates at the segment level, where a segment is a non-Markovian chain of nodes. A chain of segments is a Markov chain. However, since each segment can potentially have arbitrary length, inference in SemiCRFs is more involved than the chain CRFs.\nRepresented in our HSCRF framework (Figure 24), each node xt of the SemiCRF is associated with an ending indicator et, with the following contextual cliques\n• Segmental state, which corresponds to a single segment si:j and is essentially the state persistence contextual clique in the context c = (ei−1:j = (1, 0, .., 0, 1)) in the HSCRF’s terminology.\n• State transition, which is similar to the state transition contextual clique in the HSCRFs, corresponding to the context c = (et = 1).\nAssociated with the segmental state clique is the potential Rsi:j , and with the state transition is the potential As′,s,t, where s, s′ ∈ S, and S = {1, 2, ..., |S|}.\nA SemiCRF is a three-level HSCRF, where the root and bottom are dummy states. This gives a simplified way to compute the partition function, ESS, and the MAP assignment using the AIO algorithms. Thus, techniques developed in this paper for numerical scaling and partially observed data can be applied to the SemiCRF. To be more\nconsistent with the literature of flat models such as HMMs and CRFs, we call the asymmetric inside/outside masses by the forward/backward, respectively. Since the model is flat, we do not need the inside and outside variables.\nForward\nWith some abuse of notation, let ζs1:j = (x1:j−1, e1:j−1, xj = s, ej = 1). In other words, there is a segment of state s ending at j. We write the forward αt(s) as\nαj(s) = ∑\nζs 1:j\nΦ[ζs1:j , z] (138)\nAs a result the partition function can be written in term of the forward as\nZ(z) = ∑\nζ1:T\nΦ[ζ1:T , z] = ∑\ns\n∑\nζs 1:T\nΦ[ζs1:T , z]\n= ∑\ns\nαT (s) (139)\nWe now derive a recursive relation for the forward. Assume that the segment ending at j starts somewhere at i ∈ [1, j]. Then for i > 1, there exists the decomposition ζs1:j = (ζs ′\n1:i−1, xi:j = s, ei:j−1 = 0) for some s ′, which leads to the following factorisation\nΦ[ζs1:j , z] = Φ[ζ s′ 1:i−1]As′,s,i−1R s i:j (140)\nThe transition potential As′,s,i−1 occurs in the context c = (ei−1 = 1), and the segmental potential Rsi:j in the context c = (xi:j = s, ei−1 = 1, ei:j−1 = 0).\nFor i = 1, the factorisation reduces to Φ[ζs1:j , z] = R s 1:j . Since we do not know the starting i, we must consider all possible values in the interval [1, j. Thus, Equation 138 can be rewritten as\nαj(s) = ∑\ni∈[2,j]\n∑\ns′\n∑\nζs ′\n1:i−1\nΦ[ζs ′ 1:i−1]As′,s,i−1R s i:j +R s 1:j (141)\n= ∑\ni∈[2,j]\n∑\ns′\nαi−1(s ′)As′,s,i−1R s i:j +R s 1:j (142)\nBackward\nThe backward is the ‘mirrored’ version of the forward. In particular, let ζs j:T = (xj+1:T , ej:T , xj = s, ej−1 = 1). and we define the backward βt(s) as\nβj(s) = ∑\nζs j:T\nΦ[ζs j:T , z] (143)\nClearly, the partition function can be written in term of the backward as\nZ(z) = ∑\ns\nβ1(s) (144)\nThe recursive relation for the backward\nβi(s) = ∑\nj∈[i,T−1]\n∑\ns′\nRsi:jAs,s′,jβj+1(s ′) +Rsi:T (145)\nTypically, we want to limit the segment to the maximum length of L ∈ [1, T ]. This limitation introduces some special cases when performing recursive computation of the the forward and backward. Equation 141 and 145 are rewritten as follows\nαj(s) = ∑\ni∈[j−L+1,j],i>1\n∑\ns′\nαi−1(s ′)As′,s,i−1R s i:j +R s 1:j (146)\nβi(s) = ∑\nj∈[i,i+L−1],j<T\n∑\ns′\nRsi:jAs,s′,jβj+1(s ′) +Rsi:T (147)\nSince it is a bit clumsy to represent a SemiCRF as a three-level HSCRF, we can extend the HSCRF straightforwardly by allowing the bottom level states to persist. With this relaxation we have a nested SemiCRF model in the sense that each segment in a Markov chain is also a Markov chain of sub-segments.\nC.2 Partially Supervised Learning and Constrained Inference\nFollowing the intuition in Section 7.1, we require that all the forward and backward quantities and the potentials Rsi:j used in Equations 146 and 147 must be consistent with the labels in the case of partial supervision and constrained inference.\nSpecifically, any quantities that are not consistent are set to zero. Let the labels be ϑ = (x̃, ẽ). Then the potential Rsi:j is consistent if it satisfies the following requirements:\n• if there are any labeled states in the interval [i, j], they must be s,\n• if there is any labeled ending indicator ẽi−1, then ẽi−1 = 1,\n• if there is any labeled ending indicator ẽk for some k ∈ [i, j − 1], then ẽk = 0, and\n• if any ending indicator ẽj is labeled, then ẽj = 1.\nThese conditions are captured by using the following identity function:\nI[Rsi:j ] = δ[x̃k∈[i,j] = s]δ[ẽi−1 = 1]δ[ẽk∈[i:j−1] = 0]δ[ẽj = 1] (148)\nNotice how these conditions and equation resembles those in the Equation 103. This is because a SemiCRF is just a simplified version of an HSCRF where the potential Rsi:j plays the role of the inside ∆2,si:j .\nSimilarly, the forward αj(s) is consistent if the following conditions are satisfied:\n• if there is a labeled ending indicator at j, then ẽj = 1, and\n• if there is a labeled state at j, then x̃j = s.\nThe consistency is captured in the following identity function:\nI[αj(s)] = δ[ẽj = 1]δ[x̃j = s] (149)\nFurthermore, the backward βi(s) is consistent where:\n• if there is a labeled ending indicator at i− 1, then ẽi−1 = 1, and\n• if there is a labeled state at i then x̃i = s.\nAnd again, we have the following identity function\nI[βi(s)] = δ[ẽi−1 = 1]δ[x̃i = s] (150)\nBy installing the consistency identity functions in Equations 148, 149 and 150 into Equations 146 and 147, we now arrive at\nαj(s) = I[αj(s)]\n \n∑\ni∈[j−L+1,j],i>1\n∑\ns′\nαi−1(s ′)As′,s,i−1I[R s i:j ]R s i:j + I[R s 1:j ]R s 1:j\n (151)\nβi(s) = I[βi(s)]\n  ∑\nj∈[i,i+L−1],j<T\n∑\ns′\nI[Rsi:j ]R s i:jAs,s′,jβj+1(s ′) + I[Rsi:j ]R s i:T\n\n(152)\nC.3 Numerical Scaling\nWe have already shown that a SemiCRF is indeed a 3-level HSCRF where the top and the bottom levels are dummy states, that is, the state size is one and all the potentials associated with them have a value of one. To apply the scaling method described in Section 8, we notice that\n• αt(s) plays the role of the asymmetric inside mass α 1,1 1:j (s)\n• βt(s) plays the role of the asymmetric outside mass λ 1,1 1:j (s)\nWhat we do not have here is the explicit notion of inside mass ∆2,si:j , but it can be considered as having a value of one. So to apply the scaling algorithm in Figure 19 we may scale the state-persistence potential Rsi:j instead. The simplified version of Figure 19 is given in Figure 25. Of course, the partial scaling step can be the source of numerical overflow with∏j−1 k=i κk. The trick here is to realise that b/ ∏ k ak = exp(log b − ∑ k log ak) so that\nwe never compute b/ ∏ k ak directly but the equivalence exp(log b − ∑ k log ak).\n0 20 40 60 80\n60\n80\n100\nportions of available state labels\nlevel 2 level 3\n0 20 40 60 80 88\n90\n92\n94\n96\n98\n100\nportion of available labels\nav er\nag e\nF 1−\nsc or\ne (%\n)\ncomplex activities primitive activities"
    } ],
    "references" : [ {
      "title" : "Policy recognition in the abstract hidden Markov model",
      "author" : [ "H.H. Bui", "S. Venkatesh", "G. West" ],
      "venue" : "Journal of Artificial Intelligence Research, 17, 451–499.",
      "citeRegEx" : "Bui et al\\.,? 2002",
      "shortCiteRegEx" : "Bui et al\\.",
      "year" : 2002
    }, {
      "title" : "Hierarchical hidden Markov models with general state hierarchy",
      "author" : [ "H.H. Bui", "D.Q. Phung", "S. Venkatesh" ],
      "venue" : "D. L. McGuinness and G. Ferguson, editors, Proceedings of the 19th National Conference on Artificial Intelligence (AAAI), pages 324–329, San Jose, CA.",
      "citeRegEx" : "Bui et al\\.,? 2004",
      "shortCiteRegEx" : "Bui et al\\.",
      "year" : 2004
    }, {
      "title" : "Log-linear models for wide-coverage CCG parsing",
      "author" : [ "S. Clark", "J.R. Curran" ],
      "venue" : "Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 97–104.",
      "citeRegEx" : "Clark and Curran,? 2003",
      "shortCiteRegEx" : "Clark and Curran",
      "year" : 2003
    }, {
      "title" : "Discriminative training methods for hidden Markov models: Theory and experiments with the perceptron algorithm",
      "author" : [ "M. Collins" ],
      "venue" : "Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).",
      "citeRegEx" : "Collins,? 2002",
      "shortCiteRegEx" : "Collins",
      "year" : 2002
    }, {
      "title" : "The hierarchical hidden Markov model: Analysis and applications",
      "author" : [ "S. Fine", "Y. Singer", "N. Tishby" ],
      "venue" : "Machine Learning, 32(1), 41–62.",
      "citeRegEx" : "Fine et al\\.,? 1998",
      "shortCiteRegEx" : "Fine et al\\.",
      "year" : 1998
    }, {
      "title" : "Factor graphs and the sum-product algorithm",
      "author" : [ "F.R. Kschischang", "B.J. Frey", "H.A. Loeliger" ],
      "venue" : "IEEE Transactions on Information Theory, 47(2), 498–519.",
      "citeRegEx" : "Kschischang et al\\.,? 2001",
      "shortCiteRegEx" : "Kschischang et al\\.",
      "year" : 2001
    }, {
      "title" : "A hierarchical field framework for unified contextbased classification",
      "author" : [ "S. Kumar", "M. Hebert" ],
      "venue" : "Proceedings of the IEEE International Conference on Computer Vision (ICCV), volume 2, pages 1284–1291.",
      "citeRegEx" : "Kumar and Hebert,? 2005",
      "shortCiteRegEx" : "Kumar and Hebert",
      "year" : 2005
    }, {
      "title" : "Conditional random fields: Probabilistic models for segmenting and labeling sequence data",
      "author" : [ "J. Lafferty", "A. McCallum", "F. Pereira" ],
      "venue" : "Proceedings of the International Conference on Machine learning (ICML), pages 282–289.",
      "citeRegEx" : "Lafferty et al\\.,? 2001",
      "shortCiteRegEx" : "Lafferty et al\\.",
      "year" : 2001
    }, {
      "title" : "Graphical Models",
      "author" : [ "S. Lauritzen" ],
      "venue" : "Oxford Science Publications.",
      "citeRegEx" : "Lauritzen,? 1996",
      "shortCiteRegEx" : "Lauritzen",
      "year" : 1996
    }, {
      "title" : "Extracting places and activities from GPS traces using hierarchical conditional random fields",
      "author" : [ "L. Liao", "D. Fox", "H. Kautz" ],
      "venue" : "The International Journal of Robotics Research, 26(1), 119–134.",
      "citeRegEx" : "Liao et al\\.,? 2007",
      "shortCiteRegEx" : "Liao et al\\.",
      "year" : 2007
    }, {
      "title" : "Foundations of Statistical Natural Language Processing",
      "author" : [ "C.D. Manning", "H. Schütze" ],
      "venue" : "MIT Press.",
      "citeRegEx" : "Manning and Schütze,? 1999",
      "shortCiteRegEx" : "Manning and Schütze",
      "year" : 1999
    }, {
      "title" : "Maximum entropy estimation for feature forests",
      "author" : [ "Y. Miyao", "J. Tsujii" ],
      "venue" : "Proceedings of Human Language Technology Conference (HLT).",
      "citeRegEx" : "Miyao and Tsujii,? 2002",
      "shortCiteRegEx" : "Miyao and Tsujii",
      "year" : 2002
    }, {
      "title" : "Dynamic Bayesian Networks: Representation, Inference and Learning",
      "author" : [ "K. Murphy" ],
      "venue" : "Ph.D. thesis, Computer Science Division, University of California, Berkeley.",
      "citeRegEx" : "Murphy,? 2002",
      "shortCiteRegEx" : "Murphy",
      "year" : 2002
    }, {
      "title" : "Linear time inference in hierarchical HMMs",
      "author" : [ "K. Murphy", "M. Paskin" ],
      "venue" : "Advances in Neural Information Processing Systems (NIPS), volume 2, pages 833– 840. MIT Press.",
      "citeRegEx" : "Murphy and Paskin,? 2002",
      "shortCiteRegEx" : "Murphy and Paskin",
      "year" : 2002
    }, {
      "title" : "Learning and detecting activities from movement trajectories using the hierarchical hidden Markov models",
      "author" : [ "N. Nguyen", "D. Phung", "S. Venkatesh", "H.H. Bui" ],
      "venue" : "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), volume 2, pages 955–960, San Diego, CA.",
      "citeRegEx" : "Nguyen et al\\.,? 2005",
      "shortCiteRegEx" : "Nguyen et al\\.",
      "year" : 2005
    }, {
      "title" : "Layered representations for learning and inferring office activity from multiple sensory channels",
      "author" : [ "N. Oliver", "A. Garg", "E. Horvitz" ],
      "venue" : "Computer Vision and Image Understanding, 96(2), 163–180.",
      "citeRegEx" : "Oliver et al\\.,? 2004",
      "shortCiteRegEx" : "Oliver et al\\.",
      "year" : 2004
    }, {
      "title" : "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference",
      "author" : [ "J. Pearl" ],
      "venue" : "Morgan Kaufmann, San Francisco, CA.",
      "citeRegEx" : "Pearl,? 1988",
      "shortCiteRegEx" : "Pearl",
      "year" : 1988
    }, {
      "title" : "Inside-outside reestimation from partially bracketed corpora",
      "author" : [ "F. Pereira", "Y. Schabes" ],
      "venue" : "Proceedings of the Meeting of the Association for Computational Linguistics (ACL), pages 128–135.",
      "citeRegEx" : "Pereira and Schabes,? 1992",
      "shortCiteRegEx" : "Pereira and Schabes",
      "year" : 1992
    }, {
      "title" : "A tutorial on hidden Markov models and selected applications in speech recognition",
      "author" : [ "L.R. Rabiner" ],
      "venue" : "Proceedings of the IEEE, 77(2), 257–286.",
      "citeRegEx" : "Rabiner,? 1989",
      "shortCiteRegEx" : "Rabiner",
      "year" : 1989
    }, {
      "title" : "Introduction to the CoNLL-2000 shared task: Chunking",
      "author" : [ "Sang", "E.F.T.K.", "S. Buchholz" ],
      "venue" : "Proceedings of the 2nd Workshop on Learning Language in Logic and the 4th Conference on Computational Natural Language Learning, volume 7, pages 127–132, Lisbon, Portugal. http://www.cnts.ua.ac.be/conll2000/chunking/.",
      "citeRegEx" : "Sang et al\\.,? 2000",
      "shortCiteRegEx" : "Sang et al\\.",
      "year" : 2000
    }, {
      "title" : "Semi-Markov conditional random fields for information extraction",
      "author" : [ "S. Sarawagi", "W.W. Cohen" ],
      "venue" : "B. L. Saul LK, Weiss Y, editor, Advances in Neural Information Processing Systems 17, pages 1185–1192. MIT Press, Cambridge, Massachusetts.",
      "citeRegEx" : "Sarawagi and Cohen,? 2004",
      "shortCiteRegEx" : "Sarawagi and Cohen",
      "year" : 2004
    }, {
      "title" : "Dynamic conditional random fields: Factorized probabilistic models for labeling and segmenting sequence data",
      "author" : [ "C. Sutton", "A. McCallum", "K. Rohanimanesh" ],
      "venue" : "Journal of Machine Learning Research, 8, 693–723.",
      "citeRegEx" : "Sutton et al\\.,? 2007",
      "shortCiteRegEx" : "Sutton et al\\.",
      "year" : 2007
    }, {
      "title" : "Discriminative probabilistic models for relational data",
      "author" : [ "B. Taskar", "A. Pieter", "D. Koller" ],
      "venue" : "Proceedings of the 18th Conference on Uncertainty in Artificial Intelligence (UAI), pages 485–49. Morgan Kaufmann.",
      "citeRegEx" : "Taskar et al\\.,? 2002",
      "shortCiteRegEx" : "Taskar et al\\.",
      "year" : 2002
    }, {
      "title" : "Max-margin Markov networks",
      "author" : [ "B. Taskar", "C. Guestrin", "D. Koller" ],
      "venue" : "S. Thrun, L. Saul, and B. Schölkopf, editors, Advances in Neural Information Processing Systems 16. MIT Press, Cambridge, MA.",
      "citeRegEx" : "Taskar et al\\.,? 2004",
      "shortCiteRegEx" : "Taskar et al\\.",
      "year" : 2004
    }, {
      "title" : "AdaBoost.MRF: Boosted Markov random forests and application to multilevel activity recognition",
      "author" : [ "T.T. Truyen", "D.Q. Phung", "H.H. Bui", "S. Venkatesh" ],
      "venue" : "In Computer Vision and Pattern Recognition,",
      "citeRegEx" : "Truyen et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Truyen et al\\.",
      "year" : 2006
    }, {
      "title" : "Accelerated training of conditional random fields with stochastic gradient methods",
      "author" : [ "S.V.N. Vishwanathan", "N.N. Schraudolph", "M.W. Schmidt", "K.P. Murphy" ],
      "venue" : "Proceedings of the International Conference on Machine learning (ICML), pages 969–976.",
      "citeRegEx" : "Vishwanathan et al\\.,? 2006",
      "shortCiteRegEx" : "Vishwanathan et al\\.",
      "year" : 2006
    }, {
      "title" : "Constructing free-energy approxima",
      "author" : [ "J. Yedidia", "W. Freeman", "Y. Weiss" ],
      "venue" : null,
      "citeRegEx" : "Yedidia et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "Yedidia et al\\.",
      "year" : 2005
    }, {
      "title" : "Semi-Markov CRFs as Special Case of HSCRFs In this Appendix we first describe the semi-Markov CRF (SemiCRF) (Sarawagi and Cohen, 2004) in our HSCRF framework and show how to convert a SemiCRF into an HSCRF. Then under the light of HSCRF inference we show how to modify the original Semi",
      "author" : [ ],
      "venue" : null,
      "citeRegEx" : "1.,? \\Q2004\\E",
      "shortCiteRegEx" : "1.",
      "year" : 2004
    } ],
    "referenceMentions" : [ {
      "referenceID" : 15,
      "context" : "see (Oliver et al., 2004)).",
      "startOffset" : 4,
      "endOffset" : 25
    }, {
      "referenceID" : 4,
      "context" : "A more restricted version known as hierarchical hidden Markov model (HHMM) (Fine et al., 1998) offers clearer representation in that the depth is fixed and the semantic levels are well defined.",
      "startOffset" : 75,
      "endOffset" : 94
    }, {
      "referenceID" : 7,
      "context" : "This line of research has recently attracted much interest, largely triggered by the introduction of the conditional random field (CRF) (Lafferty et al., 2001).",
      "startOffset" : 136,
      "endOffset" : 159
    }, {
      "referenceID" : 8,
      "context" : "see (Lauritzen, 1996)) which effectively encodes hierarchical and temporal semantics.",
      "startOffset" : 4,
      "endOffset" : 21
    }, {
      "referenceID" : 1,
      "context" : "For parameter learning, an efficient algorithm based on the Asymmetric Inside-Outside of (Bui et al., 2004) is introduced.",
      "startOffset" : 89,
      "endOffset" : 107
    }, {
      "referenceID" : 15,
      "context" : ", the layered HMM (Oliver et al., 2004), the abstract HMM (Bui et al.",
      "startOffset" : 18,
      "endOffset" : 39
    }, {
      "referenceID" : 0,
      "context" : ", 2004), the abstract HMM (Bui et al., 2002), hierarchical HMM (HHMM) (Fine et al.",
      "startOffset" : 26,
      "endOffset" : 44
    }, {
      "referenceID" : 4,
      "context" : ", 2002), hierarchical HMM (HHMM) (Fine et al., 1998; Bui et al., 2004), DBN (Murphy, 2002)) or grammarbased models (e.",
      "startOffset" : 33,
      "endOffset" : 70
    }, {
      "referenceID" : 1,
      "context" : ", 2002), hierarchical HMM (HHMM) (Fine et al., 1998; Bui et al., 2004), DBN (Murphy, 2002)) or grammarbased models (e.",
      "startOffset" : 33,
      "endOffset" : 70
    }, {
      "referenceID" : 12,
      "context" : ", 2004), DBN (Murphy, 2002)) or grammarbased models (e.",
      "startOffset" : 13,
      "endOffset" : 27
    }, {
      "referenceID" : 17,
      "context" : ", PCFG (Pereira and Schabes, 1992)).",
      "startOffset" : 7,
      "endOffset" : 34
    }, {
      "referenceID" : 21,
      "context" : "dynamic CRFs (DCRF) (Sutton et al., 2007), hierarchical CRFs (Liao et al.",
      "startOffset" : 20,
      "endOffset" : 41
    }, {
      "referenceID" : 9,
      "context" : ", 2007), hierarchical CRFs (Liao et al., 2007; Kumar and Hebert, 2005)) and conditional learning of the grammars (e.",
      "startOffset" : 27,
      "endOffset" : 70
    }, {
      "referenceID" : 6,
      "context" : ", 2007), hierarchical CRFs (Liao et al., 2007; Kumar and Hebert, 2005)) and conditional learning of the grammars (e.",
      "startOffset" : 27,
      "endOffset" : 70
    }, {
      "referenceID" : 11,
      "context" : "see (Miyao and Tsujii, 2002; Clark and Curran, 2003)).",
      "startOffset" : 4,
      "endOffset" : 52
    }, {
      "referenceID" : 2,
      "context" : "see (Miyao and Tsujii, 2002; Clark and Curran, 2003)).",
      "startOffset" : 4,
      "endOffset" : 52
    }, {
      "referenceID" : 18,
      "context" : "2 Hierarchical Hidden Markov Models Hierarchical HMMs are generalisations of HMMs (Rabiner, 1989) in the way that a state in an HHMM may be a sub-HHMM.",
      "startOffset" : 82,
      "endOffset" : 97
    }, {
      "referenceID" : 13,
      "context" : "The temporal evolution of the HHMM can be represented as a dynamic Bayesian network, which was first done in (Murphy and Paskin, 2002).",
      "startOffset" : 109,
      "endOffset" : 134
    }, {
      "referenceID" : 7,
      "context" : "Conditional random fields (CRFs) (Lafferty et al., 2001) define a conditional distribution given the observation z as follows",
      "startOffset" : 33,
      "endOffset" : 56
    }, {
      "referenceID" : 21,
      "context" : "(DCRFs) (Sutton et al., 2007), segmental sequences as in Semi-Markov CRFs (SemiCRFs) (Sarawagi and Cohen, 2004), and relational data (Taskar et al.",
      "startOffset" : 8,
      "endOffset" : 29
    }, {
      "referenceID" : 20,
      "context" : ", 2007), segmental sequences as in Semi-Markov CRFs (SemiCRFs) (Sarawagi and Cohen, 2004), and relational data (Taskar et al.",
      "startOffset" : 63,
      "endOffset" : 89
    }, {
      "referenceID" : 22,
      "context" : ", 2007), segmental sequences as in Semi-Markov CRFs (SemiCRFs) (Sarawagi and Cohen, 2004), and relational data (Taskar et al., 2002).",
      "startOffset" : 111,
      "endOffset" : 132
    }, {
      "referenceID" : 3,
      "context" : "The second category investigates learning schemes other than maximum likelihood, for example perceptron (Collins, 2002) and SVM (Taskar et al.",
      "startOffset" : 104,
      "endOffset" : 119
    }, {
      "referenceID" : 23,
      "context" : "The second category investigates learning schemes other than maximum likelihood, for example perceptron (Collins, 2002) and SVM (Taskar et al., 2004).",
      "startOffset" : 128,
      "endOffset" : 149
    }, {
      "referenceID" : 12,
      "context" : "DCRFs are basically the conditional, undirected version of the Dynamic Bayesian Networks (Murphy, 2002).",
      "startOffset" : 89,
      "endOffset" : 103
    }, {
      "referenceID" : 1,
      "context" : "The shared topology has been investigated in the context of HHMMs in (Bui et al., 2004).",
      "startOffset" : 69,
      "endOffset" : 87
    }, {
      "referenceID" : 8,
      "context" : "Remarks: The temporal model of HSCRFs presented here is not a standard graphical model (Lauritzen, 1996) since the connectivity (and therefore the clique structures) is not fixed.",
      "startOffset" : 87,
      "endOffset" : 104
    }, {
      "referenceID" : 1,
      "context" : "structure HHMMs (Bui et al., 2004), the unrolled temporal representation is an undirected graph and the model distribution is formulated in a discriminative way.",
      "startOffset" : 16,
      "endOffset" : 34
    }, {
      "referenceID" : 13,
      "context" : "Furthermore, the state persistence potentials capture duration information that is not available in the dynamic DBN representation of the HHMMs in (Murphy and Paskin, 2002).",
      "startOffset" : 147,
      "endOffset" : 172
    }, {
      "referenceID" : 22,
      "context" : "In the way the potentials are introduced it may first appear to resemble the clique templates in the discriminative relational Markov networks (RMNs) (Taskar et al., 2002).",
      "startOffset" : 150,
      "endOffset" : 171
    }, {
      "referenceID" : 1,
      "context" : "4 Asymmetric Inside-Outside Algorithm This section describes a core inference engine called Asymmetric Inside-Outside (AIO) algorithm, which is partly adapted from the generative, directed counter part of HHMMs in (Bui et al., 2004).",
      "startOffset" : 214,
      "endOffset" : 232
    }, {
      "referenceID" : 16,
      "context" : "This similarity comes from the relation between the sum-product and max-product algorithm (a generalisation of the Viterbi algorithm) of Pearl (1988), and from the fact that inside/asymmetric inside procedures described in Section 4.",
      "startOffset" : 137,
      "endOffset" : 150
    }, {
      "referenceID" : 16,
      "context" : "The idea can be traced back to the Pearl’s message-passing procedure (Pearl, 1988; Yedidia et al., 2005).",
      "startOffset" : 69,
      "endOffset" : 104
    }, {
      "referenceID" : 26,
      "context" : "The idea can be traced back to the Pearl’s message-passing procedure (Pearl, 1988; Yedidia et al., 2005).",
      "startOffset" : 69,
      "endOffset" : 104
    }, {
      "referenceID" : 1,
      "context" : "In the context of HHMMs with which the numerical underflow problem is associated, the similar idea has been proposed in (Bui et al., 2004), which we adapt to our overflow problem.",
      "startOffset" : 120,
      "endOffset" : 138
    }, {
      "referenceID" : 14,
      "context" : "The data, which was captured in (Nguyen et al., 2005), and subsequently used to evaluate DCRFs in (Truyen et al.",
      "startOffset" : 32,
      "endOffset" : 53
    }, {
      "referenceID" : 24,
      "context" : ", 2005), and subsequently used to evaluate DCRFs in (Truyen et al., 2006), has 90 sequences, each of which corresponds to one of 3 the persistent activities: (1) preparing short-meal, (2) having snack and (3) preparing normal-meal.",
      "startOffset" : 52,
      "endOffset" : 73
    }, {
      "referenceID" : 24,
      "context" : "embedded in state-persistence potentials) at the bottom level, we use the same features as in (Truyen et al., 2006).",
      "startOffset" : 94,
      "endOffset" : 115
    }, {
      "referenceID" : 21,
      "context" : "We extract raw features from the text in the way similar to that in (Sutton et al., 2007).",
      "startOffset" : 68,
      "endOffset" : 89
    }, {
      "referenceID" : 21,
      "context" : "Furthermore, we use the contextual window of 5 instead of 7 as in (Sutton et al., 2007).",
      "startOffset" : 66,
      "endOffset" : 87
    }, {
      "referenceID" : 20,
      "context" : "For comparison, we implement a DCRF, a simple sequential CRF (SCRF), and a semi-Markov CRF (SemiCRF) (Sarawagi and Cohen, 2004).",
      "startOffset" : 101,
      "endOffset" : 127
    }, {
      "referenceID" : 21,
      "context" : "However, the set shared by the SCRF and the SemiCRF is a little more elaborate since it takes the POS tags into account (Sutton et al., 2007).",
      "startOffset" : 120,
      "endOffset" : 141
    }, {
      "referenceID" : 25,
      "context" : "For learning, we use a simple online stochastic gradient ascent method since it has been shown to work relatively well and fast in CRFs (Vishwanathan et al., 2006).",
      "startOffset" : 136,
      "endOffset" : 163
    }, {
      "referenceID" : 21,
      "context" : "This does not share the observation made in (Sutton et al., 2007).",
      "startOffset" : 44,
      "endOffset" : 65
    }, {
      "referenceID" : 21,
      "context" : "However, we use a much smaller POS tag set than (Sutton et al., 2007) does.",
      "startOffset" : 48,
      "endOffset" : 69
    } ],
    "year" : 2010,
    "abstractText" : "Inspired by the hierarchical hidden Markov models (HHMM), we present the hierarchical semi-Markov conditional random field (HSCRF), a generalisation of embedded undirected Markov chains to model complex hierarchical, nested Markov processes. It is parameterised in a discriminative framework and has polynomial time algorithms for learning and inference. Importantly, we consider partiallysupervised learning and propose algorithms for generalised partially-supervised learning and constrained inference. We demonstrate the HSCRF in two applications: (i) recognising human activities of daily living (ADLs) from indoor surveillance cameras, and (ii) noun-phrase chunking. We show that the HSCRF is capable of learning rich hierarchical models with reasonable accuracy in both fully and partially observed data cases.",
    "creator" : "LaTeX with hyperref package"
  }
}