{
  "name" : "1103.4778.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "A Formal and Computational Properties of the Confidence Boost of Association Rules",
    "authors" : [ "JOSÉ L. BALCÁZAR" ],
    "emails" : [ "(joseluis.balcazar@unican.es)." ],
    "sections" : [ {
      "heading" : null,
      "text" : "A Formal and Computational Properties of the Confidence Boost of Association Rules\nJOSÉ L. BALCÁZAR, Universidad de Cantabria\nSome existing notions of redundancy among association rules allow for a logical-style characterization and lead to irredundant bases of absolutely minimum size. One can push the intuition of redundancy further and find an intuitive notion of interest of an association rule, in terms of its “novelty” with respect to other rules. Namely: an irredundant rule is so because its confidence is higher than what the rest of the rules would suggest; then, one can ask: how much higher?\nWe propose to measure such a sort of “novelty” through the confidence boost of a rule, which encompasses two previous similar notions (confidence width and rule blocking, of which the latter is closely related to the earlier measure “improvement”). Acting as a complement to confidence and support, the confidence boost helps to obtain small and crisp sets of mined association rules, and solves the well-known problem that, in certain cases, rules of negative correlation may pass the confidence bound. We analyze the properties of two versions of the notion of confidence boost, one of them a natural generalization of the other. We develop efficient algorithmics to filter rules according to their confidence boost, compare the concept to some similar notions in the bibliography, and describe the results of some experimentation employing the new notions on standard benchmark datasets. We describe an open-source association mining tool that embodies one of our variants of confidence boost in such a way that the data mining process does not require the user to select any value for any parameter.\nGeneral Terms: Algorithms, Theory, Human factors\nAdditional Key Words and Phrases: Association rule mining, association rule quality, confidence\nACM Reference Format: ACM V, N, Article A (January YYYY), 36 pages. DOI = 10.1145/0000000.0000000 http://doi.acm.org/10.1145/0000000.0000000"
    }, {
      "heading" : "1. INTRODUCTION",
      "text" : "As the now well-known task of association rule mining was defined, the problems faced were twofold. First, the quantity of candidate itemsets for antecedent X and consequent Y of association rules X → Y grows exponentially with the often already large universe of items. The introduction of a support threshold parameter was a key advance that allowed for the design of efficient frequent set miners and for the computation of association rules in large datasets: there, exploration is limited to those itemsets that appear “often enough” as subsets of the transactions, that is, their relative frequency exceeds a certain ratio of the transactions; see [Agrawal et al. 1996] and the references there. Then, the second problem is that, often, the set of rules provided as output is too large, specially if we consider that its purpose is to be read, and understood, by a human. We consider that this problem warrants further research, and we attempt at providing here yet one more approach to it.\nAddress at the time of submission: Departmento de Matemáticas, Estad́ıstica y Computación, Av Los Castros s/n, Santander 39005, Spain (joseluis.balcazar@unican.es). This work has been partially supported by project TIN2007-66523 (FORMALISM) of Programa Nacional de Investigación, Ministerio de Ciencia e Innovación (MICINN), Spain, and by the Pascal-2 Network of the European Union. Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior specific permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701 USA, fax +1 (212) 869-0481, or permissions@acm.org. c© YYYY ACM 0000-0000/YYYY/01-ARTA $10.00 DOI 10.1145/0000000.0000000 http://doi.acm.org/10.1145/0000000.0000000\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nar X\niv :1\n10 3.\n47 78\nv1 [\ncs .D\nB ]\n2 4\nM ar\n2 01\n1\nThese two difficulties are of very different sorts. The exponential growth of candidates is essentially a combinatorial, almost technological problem, and all the existing solutions are based on the acceptance that, as not all the billions of candidates can be considered within reasonable running times, we make do with those that obey the support constraint. However, this solution puts unto the shoulders of the user the heavy responsibility of choosing the support threshold, with little or no guidance about how to do it.\nOn the other hand, it is no problem for our current computing equipments to extract association rules from frequent sets. The proposal in [Agrawal et al. 1996] (and already in the early [Luxenburger 1991] where, however, the support bound proposal does not appear) is to impose upon association rules X → Y a confidence constraint, that is, a threshold on the conditional probability of Y conditioned to X.\nIndeed, association rule mining, in essence, amounts to enumerating all the rules that are not disproved by the data. As there are exponentially growing quantities of potential associations, even relatively large datasets are unable to disprove most of them. Therefore, in the standard “support and confidence” framework, it is well-known, and easy to check using any of the public datasets and free association miners available on the web, that whereas high, demanding thresholds for these parameters generally yield few somewhat obvious rules, softening them, as much as the algorithmics (and the user patience) would allow, leads to large amounts of rules, with many of them looking very much like each other; often, they are not a user-friendly enough result of a data mining process, due to the presence of these intuitive redundancies.\nAs a preliminary filter, there are several essentially logical definitions of redundancy, patterned after similar intuitions in Propositional or First-Order Logic. This leads to minimum-size bases, such as the Representative (or Essential) Rules [Aggarwal and Yu 2001; Kryszkiewicz 1998b] for plain redundancy or the basis B?γ [Balcázar 2010c] for closure-based redundancy, at confidence threshold γ, that spares the computation of minimal generators needed by the Representative Rules, but needs to be complemented with a basis for full implications. All these questions are thoroughly surveyed in [Balcázar 2010c]. But even taking redundancies into account, the results are, in many cases, unsatisfactory; therefore, many alternative quality measures exist for association rules, essentially due to the facts that, first, the confidence of a rule X → Y can be high even in cases where the actual correlation between X and Y is negative, and, second, it is often extremely difficult to settle for thresholds where interesting rules are kept but the total amount of rules can be handled; see [Geng and Hamilton 2006; Lenca et al. 2008; Tan et al. 2004] and their references for information about the rich research area opened up by these difficulties. We note that, from the point of view of the user, the usage of alternative implicational measures leads to an even worse situation, as (s)he has to choose again both the measures to apply and their corresponding thresholds. The literature on this topic is huge and cannot be reviewed here; a discussion of the relationships of our contributions with the most relevant ones among the published proposals is deferred to Subsections 7.1 and 7.2.\nOur development is based on the simple consideration that rules can be evaluated for “novelty”, by comparison with the rest of the rules mined. Actually, the outcome of every Data Mining project is expected to offer some degree of novelty. If one ends up identifying only facts whose validity is obvious, these would not be really useful. However, to formally study the novelty of Data Mining results is far from being a trivial task. Indeed, novelty is, in an intuitive sense, a relative notion: it refers to facts that are, somehow, unexpected; hence, some “low expectation” reason must exist, and must be due to alternative facts or prediction mechanisms. That is: a piece of information is novel or is not, always with respect to a given context of previously known facts; definitions of novelty must take into account, then, some form of previously available knowledge, a notion hard to formalize (Subsection 7.1 describes some approaches, but see e.g. [Padmanabhan and Tuzhilin 2000] and the references therein).\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nHowever, as one very partial and probably insufficient, but necessary action, we claim that, as a minimum, each rule should be evaluated for novelty by comparison with the rest of the rules mined, treated as “alternative” mechanism [Balcázar 2009]. One can attempt at measuring to what extent the confidence of the rule is substantially higher than that of related rules that would, intuitively, explain the same facts. In the same reference, the confidence width is proposed as a measure of a relative form of objective novelty or surprisingness of each individual rule with respect to other rules that hold in the same dataset. As some intuitive redundancies are not covered by that measure, the same paper proposes also to allow some rules to block other rules in case the blocked rule does not bring in enough novelty with respect to the blocker. (We give below the precise definitions of these notions.) Essentially, these proposals measure novelty through the extent to which the confidence value is “robust”, taken relative to the confidences of related rules, as opposed to the absolute consideration of the single rule at hand.\nTo give a hint of the sort of process we are discussing, assume a rule, of confidence say 75%, is found in a census-like dataset, stating that young people earn lesser salaries; in the presence of such a rule, a more complex one stating that young, unmarried people earn lesser salaries could be novel, but only if its confidence turns out to be substantially higher than 75%, maybe 90%. Otherwise, it would not be novel, the simpler rule should be preferred, and even the complex rule discarded (or blocked), all depending on thresholds on confidence and on some other parameter such as improvement [Bayardo et al. 1999], blocking factor, or confidence boost (to be introduced here). Further discussion will be provided along the body of the paper.\nIt was empirically demonstrated in [Balcázar 2009] that better results were obtained using both a confidence width threshold and a blocking threshold, than using a single one of these filters (or none). However, no really fast way of testing a rule for blockings was provided. Thus, our contribution here is a new attempt at formalizing the notion of novelty, the confidence boost, similar in its syntactic definition to confidence width, but different in its semantics, which is more restrictive; its main feature is that it encompasses at once both the bound on the confidence width and the ability to detect that a rule would be blocked, so that the confidence boost bound embodies both of the bounds proposed in [Balcázar 2009], yet it is computable with reasonable efficiency. Confidence boost comes in two flavors: a “plain” one, that we develop in Section 3, and a more general variant that takes into account the closure space implicit in the data, developed in Section 4.\nThree short extended abstracts of three, six, and seven pages respectively have announced results from this paper in scientific meetings; reference [Balcázar 2010b] contains the definition of confidence boost, fragments of Section 2 (where we also review a small number of necessary facts from [Balcázar 2010c]), part of Section 3 (the definition of confidence boost), and the algorithm in Subsection 3.2 (but not its correctness proof). Reference [Balcázar 2010a] contains the definition of closure-based confidence boost and part of the materials in Section 4, again including the main algorithm but not its correctness proof, as well as materials from Subsection 5.2. The tool yacaree which embodies closure-based confidence boost into a parameter-free association miner (Section 6) was advertised at [Balcázar 2011] (demo track). The rest of Sections 3, 4, and 5, as well as the discussions in Section 7, are unpublished."
    }, {
      "heading" : "2. PRELIMINARIES",
      "text" : "A given set of available items U is assumed; its subsets are called itemsets. We will denote itemsets by capital letters from the end of the alphabet, and use juxtaposition to denote union, as in XY . The inclusion sign as in X ⊂ Y denotes proper subset, whereas improper inclusion is denoted X ⊆ Y . For a given dataset D, consisting of n transactions, each of which is an itemset labeled with a unique transaction identifier, we can count the support sD(X) of an itemset X, which is the cardinality of the set of transactions that contain X. An\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nalternative rendering of support is its normalized version, the relative frequency or empirical probability sD(X)/n; we will work with the unnormalized quantity.\nAssociation miners explore datasets in search of valid expressions of the form X → Y , where X and Y stand for itemsets. Intuitively, an association rule X → Y means that, in the given dataset, the transactions that contain X “tend to contain” Y as well. The confidence of a rule X → Y is cD(X → Y ) = sD(XY )/sD(X), akin to an empirical approximation to a conditional probability. It is important to observe that the precise definition of association rules depends on the formalization chosen for the informal expression “tend to”, as only then these syntactical expressions become endowed with a concrete semantics and associated specific properties. For instance, if we define the meaning of X → Y through confidence, then rules X → Y and X → XY are equivalent, whereas, if we use lift (defined below), then they may not be equivalent.\nConfidence is a very natural notion to prune and rank the output of an association rule mining algorithm, but we must point out that, due to some objections that we review in Subsection 2.2, there exist other proposals of notions to replace confidence. When confidence is 1, the maximum value, we say that X → Y is an implication: every transaction containing X contains as well Y . Sometimes we use the term partial rule for an association rule of confidence less than 1. The support of a rule X → Y is sD(X → Y ) = sD(XY ). When the dataset is clear from the context, we will omit the subscript D from both support and confidence. We do allow X = ∅ as antecedent of association rules: then the confidence coincides with the normalized support, c(∅ → Y ) = s(Y )/s(∅) = s(Y )/n. Allowing Y = ∅ as consequent as well is possible but not very useful, as this case leads only to trivial rules equivalent to reflexivity statements; therefore we assume that such rules are omitted from all our sets of rules. In the proposal of [Agrawal et al. 1996], association rules are restricted to |Y | = 1. This allows for faster algorithmics, as rules are directly obtained from each frequent set. In fact, whereas confidence 1 implications, say, A → B and A → C jointly are indeed equivalent to A → BC, for confidence less than 1 they are not. A → BC says that B and C appear jointly often with A, whereas associations A→ B and A→ C, even together, provide less information, as B and C could appear often with A but not so much together (we offer an example below). Thus, we do not force |Y | = 1.\nIn many cases we assume that the context provides for a threshold on the confidence, imposing a constraint c(X → Y ) ≥ γ on rules, and likewise a support threshold constraint s(X → Y ) > τ . It is formally convenient to use strict inequality in the latter case, to easily cater for the case where no support bound is imposed, by simply taking τ = 0; whereas, for confidence, we prefer to be able to select full-confidence implications via the nonstrict inequality with γ = 1.\nRemark 2.1. As we consider mainly confidence and support, rules X → Y and X → XY are equivalent in almost all our statements, as are all rules where some part of the left-hand side X is repeated in the right-hand side. Our novelty notions will respect as well this equivalence. The only exceptions will be in our brief considerations of lift. Two natural canonical choices to simplify the discussion are to restrict the discussion either to the rules of the form X → Y or to those of the form X → XY , where, in both cases, X ∩ Y = ∅. We will see in Subsection 7.2 that failing to clarify this option risks overlooking subtle differences among sets of rules enjoying, however, quite different properties. Based on the similar developments in implications and functional dependencies, we choose the latter: we will make explicit always what part of the consequent is already in the antecedent and write all our association rules as X → XY where X ∩ Y = ∅. However, this choice is somewhat arbitrary, and whomever prefers association rules with disjoint sides only needs to remove the copy of the antecedent from the consequent. In fact, in our implementations, at the time of showing a rule to the user, of course only the Y part of the consequent is shown.\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nGiven a dataset D, an itemset X ⊆ U is closed if the support of any strictly larger itemset is strictly smaller; and is free, or a minimal generator, if the support of any strictly smaller itemset is strictly larger. We denote as X the closure of itemset X with respect to a given dataset: X is the smallest closed itemset that includes X or, equivalently, the largest itemset that includes X and has the same support as X in the dataset. It is easy to check that it is unique. The intersection of closed itemsets is closed and, ordered by inclusion, the closed itemsets form a lattice which we call “closure space”. We will make liberal use of the three characteristic properties of closure operators, namely, extensivity: X ⊆ X; monotonicity: X ⊆ Y implies X ⊆ Y ; and idempotency: X = X. We will mention below further details about the connections of closure operators and free sets with association mining; see e. g. [Boulicaut et al. 2003; Zaki 2004] for further information.\nExample 2.2. We will employ as running example through most of this paper the closure space obtained from a specific dataset. For this example, the universe U includes the five items A, B, C, D, and E. The dataset consists of 12 transactions, six of which include all of U ; two more consist of ABC, again two transactions consist of AB, and then one transaction consists of CDE and another one consists of BC. It is easy to see that the associated closure-space lattice is as depicted in Figure 1, where transitive arcs have been omitted and, besides the closed sets, three minimal generators (connected to their closures) have been indicated in broken lines. The supports of all closed sets are reported in the figure for convenience. The support of each minimal generator coincides with that of its closure. Note that sometimes the minimal generator coincides with its closure, as in set BC, for one. This example illustrates that, at confidence 9/11, both the association rules B → A and B → C hold, whereas the stronger rule B → AC does not, as its confidence is only 8/11. That is, if and when B → AC holds, it would give more information than B → A and B → C holding jointly.\nWe will propose to measure the novelty of each rule with respect to the rest of the outcome of the same data mining process, through a variant of the intuitive idea of redundancy. Several notions of redundancy for association rules exist. In the early proposal [Luxenburger 1991], a rule is redundant if its confidence can be computed from that of other rules. Later, this idea has been refined, making precise what information is maintained and which operations are allowed to infer confidence or support of redundant rules: see the survey of\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nseveral concise representations and redundancy notions in [Kryszkiewicz 2002]. In [Pasquier et al. 2005] (and in earlier conference versions of their work) the following set of rules is shown to be sufficient to compute the confidence and support of any given partial rule:\nDefinition 2.3. Given a dataset and a support threshold τ acting on all sets and rules:\n(1) The min-max rules are those of the form X → XY where XY is a closed set and X is a minimal generator; they are split into the following two cases. (2) The min-max approximate rules are those of the form X → XY where XY is a closed set, X is a minimal generator, and X ⊂ XY . They have confidence less than 1. (3) The min-max exact rules are those of the form X → XY where XY is a closed set, X is a minimal generator, and X = XY . They have confidence 1.\nSimilar notions of redundancy are studied in [Zaki 2004], where, however, the approximate bases are constructed as rules having minimal generators both at the left- and at the righthand sides. These bases are quite more succinct than the sets of all association rules that hold in a specific dataset, yet they still conform far too large quantities in many cases of interest. Therefore, less demanding notions of redundancy for association rules have been studied. If we assume that the set of frequent closures is kept, so that confidences are easily computed from them, and focus on the “user-centric” view, there is a very precise and natural notion that allows us to identify irredundant bases of absolutely minimum size. For the whole paper, we concentrate basically on this redundancy notion, and on a somewhat more sophisticate variant that we will describe in Section 4.\nLemma 2.4. Consider two association rules, X0 → X0Y0 and X1 → X1Y1. The following are equivalent:\n(1 ) The confidence and support of X0 → X0Y0 are always larger than or equal to those of X1 → X1Y1, in all datasets; that is, for every dataset D, we will have cD(X0 → X0Y0) ≥ cD(X1 → X1Y1) and sD(X0Y0) ≥ sD(X1Y1) in it. (2 ) X1 ⊆ X0 ⊆ X0Y0 ⊆ X1Y1. When these cases hold, we say that X1 → X1Y1 makes X0 → X0Y0 redundant, or also that X1 → X1Y1 is logically stronger than X0 → X0Y0. The notions come, essentially, from [Aggarwal and Yu 2001; Kryszkiewicz 1998b]. For a fixed confidence threshold, those rules that reach it, and are not made redundant by other rules also above the threshold, form the representative (or essential) rule basis for that confidence threshold [Aggarwal and Yu 2001; Kryszkiewicz 1998b; Phan-Luong 2001]; that is, every rule that reaches the confidence threshold is either in the corresponding representative basis, or made redundant by a rule in the basis. Hence, a redundant rule is so because we can know beforehand, from the information in a basis, that its confidence will be above the threshold. These references also explain how to compute the representative basis out of the closed itemsets for the dataset.\nThe fact that statement (2) implies statement (1) in Lemma 2.4 is easy to see and was already pointed out in [Aggarwal and Yu 2001; Kryszkiewicz 1998b; Phan-Luong 2001] (in somewhat different terms). The converse implication is nontrivial and much more recently shown [Balcázar 2010c]; see this reference as well for the proof that the representative basis has the minimum possible size among all bases for this notion of redundancy, and for discussions of other related redundancy notions. In particular, several other natural proposals are shown there to be equivalent to this redundancy. Also, from this same source, we will consider later on a variant which makes a deeper use of the closure operator.,\nA known property that relates representative rules to closure-based miners is:\nProposition 2.5. On a given dataset and in the presence of a fixed support threshold τ , consider the association rule X → XY , and set γ = c(X → XY ). The following are equivalent:\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\n(1 ) X → XY is a representative rule for some confidence threshold. (2 ) X → XY is a min-max rule: XY is a closed set and X is a minimal generator. (3 ) X → XY is a representative rule for confidence threshold γ.\nHence, whenever we refer to X → XY as a representative rule, without mention of the specific confidence threshold γ for which it is so, we implicitly understand that we mean γ = c(X → XY ). The implication from (1) to (2) is from [Kryszkiewicz 1998a] (see also [Kryszkiewicz 2001] for a clearer notation): if X → XY is a representative rule then s(X) < s(X ′) for all X ′ ⊂ X, and s(Z) < s(XY ) for all Z with XY ⊂ Z; that is, X is a minimal generator and XY is closed.\nWe have not found the other implications explicitly stated, but they appear implicitly, in a sense, in the references that discuss these notions. We sketch here the rather simple proofs for completeness. Set γ = c(X → XY ). We assume that X → XY is a min-max rule, and consider a different rule, X ′ → X ′Y ′, logically stronger than X → XY ; we must argue that it fails the confidence threshold. By Lemma 2.4, we have X ′ ⊆ X and XY ⊆ X ′Y ′. If the left-hand sides differ, X ′ ⊂ X and, X being a minimal generator, s(X ′) > s(X); then c(X ′ → X ′Y ′) ≤ c(X ′ → XY ) < c(X → XY ) = γ. If, instead, X ′ = X, then XY ⊂ X ′Y ′ and, XY being closed, s(X ′Y ′) < s(XY ); we obtain that c(X ′ → X ′Y ′) = c(X → X ′Y ′) < c(X → XY ) = γ again. The remaining implication, (3) to (1), is obvious.\nExample 2.6. One can check that the dataset and the closure space of Example 2.2 lead to seven representative rules at confidence threshold 0.8, namely, A→ BC, C → AB, B → C, ∅ → C, ∅ → AB, and D → ABCE, and E → ABCD. The first two have confidence exactly 0.8, the others have confidences slightly higher.\nFor fixed confidence thresholds, the representative rules at that confidence form often a properly smaller basis than the min-max rules; this can be achieved because of two reasons. One is that, obviously, min-max rules of confidence below the threshold are omitted. But a more sophisticate reason is that a representative rule at a given confidence γ may cease to be so at lower confidences: at a lower threshold γ′ it is possible that a stronger rule appears that makes it redundant. This observation is key in the notion of confidence width that we review next."
    }, {
      "heading" : "2.1. Confidence Width",
      "text" : "Along most of our discussions in this paper, we assume that a dataset D and a support threshold τ have been fixed: all our rules are assumed to reach strictly above that support threshold on D.\nAccording to the definition of redundancy in Lemma 2.4, all rules in the representative basis provide some irredundant information. However, it is often the case that still the representative basis contains more rules than reasonable for human inspection. In [Balcázar 2009], the intuition of redundancy is pushed further in order to gain a perspective of novelty of association rules. An irredundant rule of a given confidence c belongs to the basis for that confidence threshold γ = c: no rule of that confidence or higher makes it redundant; equivalently, all rules that make it redundant have lower confidence. Then, one can ask: “how much lower?”. This can be evaluated by means of the following definition from the same reference:\nDefinition 2.7. For an association rule X → XY , consider all rules that are not equivalent to X → XY (as per Remark 2.1), but such that X → XY is redundant with respect to them, and pick one with maximum confidence in D among them, say X ′ → X ′Y ′. The\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nconfidence width of X → XY in D is:\nw(X → XY ) = c(X → XY ) c(X ′ → X ′Y ′)\nThe condition that X → XY is redundant with respect to X ′ → X ′Y ′ implies that c(X ′ → X ′Y ′) ≤ c(X → XY ), hence the confidence width is always 1 or larger. In fact, w(X → XY ) is strictly higher than 1 if and only if X → XY is a representative rule.\nTo explain better the intuition behind the notion of confidence width, consider a rule X → XY of a given confidence, say c(X → XY ) = c0 ∈ [0, 1], and let us see what happens as we mine the representative basis at a varying confidence threshold γ. If c0 < γ, the rule at hand will not play any role at all, being of confidence too low for the threshold. At γ = c0, the rule becomes part of the output of any standard association mining process, but it could be that some other “logically stronger” rule appears at the same confidence c0. For instance, it could be that both rules A→ AB and A→ ABC have confidence c0: then A→ AB is redundant and will not belong to the basis for that confidence. In this case, the confidence width is 1, its smallest possible value.\nIf no stronger rule appears at threshold γ = c0, then X → XY will belong to the representative basis for that threshold. Let us keep decreasing the threshold. At some lower confidence, a logically stronger rule may appear. If a logically stronger rule shows up early, at a confidence threshold γ very close to c0, then the rule X → XY is not very novel: it is too similar to the logically stronger one, and this shows in the fact that the interval of confidence thresholds where it is a representative rule is narrow. Its confidence width will be barely above 1. To the contrary, a stronger rule may take long to appear: in that case, only rules of much lower confidence entail X → XY , so that the fact that it does reach confidence c0 is novel in this sense. The interval of confidence thresholds where X → XY is a representative rule is wide, as will be the value of the confidence width. For instance, if the confidence of A → AB is 0.9, and all rules that make it redundant have confidences below 0.75, the rule is a much better candidate to novelty than it would be if some rule like A → ABC would have a confidence of 0.88: in this last case, A → AB indeed brings in additional information, but its novelty, with respect to the other rules, is not high; it only belongs to the basis when the confidence threshold is in the interval (0.88, 0.9]. In the other case where all rules that could make it redundant have confidences, say, 0.75 or less, then A → AB would belong to the basis for a considerably wider interval of confidences, (0.75, 0.9]. It states something really different from the rest of the information mined. As an objective novelty measure, thus, confidence width measures the width of the interval of confidences in which the rule at hand belongs to the representative basis.\nIt is proved in [Balcázar 2009] that, in Definition 2.7, it suffices to consider representative rules for the role of X ′ → X ′Y ′.\nExample 2.8. For association rule A → BC, of confidence 0.8, in Example 2.2, the confidence width is 1.2. The confidence of that rule is at least 20% higher than that of any rule that entails it. Indeed, there are two representative rules logically stronger, namely A → BCDE (of confidence 0.6) and ∅ → ABC (of higher confidence, 2/3); hence, w(A→ BC) = (8/10)/(2/3) = 1.2.\nBelow we will need Definition 2.7 in a single formula; for this, we can replace the redundancy condition with its characterization according to Lemma 2.4: w(X → XY ) =\n= c(X → XY ) max{c(X ′ → X ′Y ′) ∣∣ (X → XY ) 6= (X ′ → X ′Y ′), X ′ ⊆ X, XY ⊆ X ′Y ′}\nwhere again we are assuming that X ∩ Y = ∅ and X ′ ∩ Y ′ = ∅.\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nFor each fixed support, there are rules that are not redundant with respect to any other, different rule; then, this quotient is undefined due to the emptiness of the set in the denominator, for instance, if all candidate rules to it are of too low support. By convention, we use ∞ as value of the confidence width in that case (equivalently, likening the max to a zero). We can identify easily which rules have infinite width (this proposition is reported here for the first time):\nProposition 2.9. The value of w(X → XY ) is finite and well-defined if and only if either X 6= ∅, or Y has some proper superset Z with s(Z) > τ . Proof. Indeed, if X = ∅ and no proper superset of Y reaches support above τ in the dataset, then no rule can make ∅ → Y redundant; conversely, for s(Z) > τ , ∅ → Z is different from X → XY and makes it redundant if either X 6= ∅ and Z = XY , or XY ⊂ Z; since this second case only needs to be applied to rules with X = ∅, Y ⊂ Z suffices.\nThus, the only rules of infinite width are of the form ∅ → Z with Z maximal under the condition that s(Z) > τ , and their confidence would coincide with the normalized support of Z. We observe in passing that, in practice, such maximal Z’s usually have a support barely above τ , because all supersets must have a support falling below τ ; whenever the confidence threshold is substantially higher than the normalized support threshold (which does not happen always but extremely often), all rules of infinite width will be filtered out by the confidence constraint.\nIt is easy to prove a simple observation, that will be useful to compare below with confidence boost: consider the condition XY ⊆ X ′Y ′ in the rules entering the maximization of the denominator; it can be written equivalently as follows, using the other condition that X ′ ⊆ X and the empty-intersection assumptions:\nProposition 2.10. Assume X ′ ⊆ X, X ∩ Y = ∅, and X ′ ∩ Y ′ = ∅. Then XY ⊆ X ′Y ′ ⇐⇒ (X −X ′) ⊆ Y ′ and Y ⊆ Y ′.\nIn [Balcázar 2009], some intuitions are described that suggest that, for a confidence threshold γ, a natural choice could be to set the confidence width threshold at 2− γ; however, so far no formal support for this proposal (or any other proposal, for that matter) is known."
    }, {
      "heading" : "2.2. Blocking Rules",
      "text" : "On the basis of a clear, simple intuition described in many papers (e.g. [Bayardo et al. 1999; Liu et al. 1999; Padmanabhan and Tuzhilin 2000; Shah et al. 1999; Toivonen et al. 1995] just to name a few), [Balcázar 2009] proposes also a notion of “rule blocking”, whereby a subset of the antecedent may “block” an association rule, that is, forbid its being provided in the output, if the confidence of the rule with the smaller antecedent and the same consequent is higher enough.\nThe main question behind this option is the following. Consider an association rule X → XY , and reduce the antecedent to a smaller Z ⊂ X. Whereas, intuitively, the rule with larger antecedent should be subsumed by the other, this is due to the human intuitive habit of working with full implications, where indeed this is the case. But this is not so anymore with association rules. For instance, at confidence 1, if A → C holds, then AB → C also holds, and does not bring new information. But association rules are not implications; instead, they relate relative frequencies: compared to X → XY , a smaller antecedent Z ⊂ X does not lead to a new rule Z → ZY that entails it. Actually, for Z ⊂ X, either of X → XY or Z → ZY may have arbitrarily higher confidence than the other. Indeed: rule X → XY speaks about the abundancy of Y among the population of transactions that contain X; reducing the antecedent into Z changes the population into, in principle, a larger one, and Y can be distributed at very different rates along each of these two sets of transactions. The distribution of Y in the larger population supporting Z can be very imbalanced, so that Y can appear more frequently in either.\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nExample 2.11. Consider two association rules like A → C and AB → C. It is easy to construct examples where almost all transactions with A and B have C, but they are a small fraction of those having A, and thus the confidence of A→ C is very small, whereas that of AB → C is high, even 1; conversely, C might hold for nearly all of the transactions having A, but it could be that the only transactions having both A and B are those without C and, then, the confidence of AB → C can be zero yet the confidence of A → C can be very high.\nExample 2.12. Returning briefly to the dataset of Example 2.2, it is easy to check that c(∅ → BC) < c(A→ BC) whereas c(∅ → C) > c(B → C).\nAs a consequence, we also find the fundaments of the criticism that confidence does not detect negative correlations.\nExample 2.13. Fix a confidence threshold at 0.75, and consider a simple dataset with 10 transactions: 3 transactions BC, 6 transactions just C, and 1 transaction B. Then c(B → BC) = 0.75, reaching the confidence threshold. Most association miners would report B → C as interesting at that threshold. However, the correlation between B and C is actually negative. Indeed, C is less frequent among the transactions having B than in the total population, as c(∅ → C) = s(C)/n = 0.9.\nThe natural reaction, consisting of a normalization by dividing the confidence by the (normalized) support of the consequent of the rule, gives a parameter that we find in the references going by several different names: it has been called interest [Silverstein et al. 1998] or, in a slightly different but fully equivalent form, strength [Shah et al. 1999]; “lift” seems to be catching up as a short name, possibly aided by the fact that the Intelligent Miner system from IBM employed that name. The quantity is well-known in basic probability, as it measures the deviation from independence, as a multiplicative distance from the case of fully independent X and Y , which would give value 1 for it:\nDefinition 2.14. The lift of rule X → Y is c(X→Y )s(Y )/n = s(XY )×n s(X)×s(Y ) .\n(If supports are already normalized, then the factor n for the dataset size in the numerator has to be omitted.) The related parameter leverage [Piatetsky-Shapiro 1991] measures essentially the same thing, just that it does so as an additive distance. It must be noted that, contrary to confidence, the lift of X → Y does not coincide with the lift of X → XY : if we are to use lift, then we must be careful to keep the right-hand side Y disjoint from the left-hand side: X ∩Y = ∅. Otherwise, misleadingly higher lift values are obtained. Note also that, in case X = ∅, the lift trivializes to 1.\nHowever, this natural measure lacks the ability to orient the rules, because, in it, the roles of X and Y are symmetric. Additionally, lift is limited in its ability to control cases where c(Z → Y ) > c(X → Y ) for ∅ 6= Z ⊂ X. We describe a case found in data from real census information, pointed out also in [Balcázar 2009]. Mining for association rules at 5% support and 100% confidence the Adult dataset from Irvine [Asuncion and Newman 2007], 67 (out of 71) rules in the basis are of the form “Husband” + something else → “Male”, and the other four rules are also of this form except for the addition of one more item in the consequent. The reason is that the rule “Husband” → “Male”, that we would expect to hold, does not reach 100% confidence: indeed, tuple 7110 includes the items “Husband” and “Female” (instead of “Male”). This opens the door to many rules, intuitively uninformative, that enlarge a bit the left-hand side, just enough to avoid tuple 7110 so as to reach confidence 100%. The whole issue would not be solved by dividing all confidences by the support of “Male”. Further examples are given in the same paper, and in many others such as those cited above.\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nIt is desirable to react to the negative correlation problem for confidence and still maintain orientability. As an alternative approach to this problem, in [Balcázar 2009] the confidence parameter is used in an intuitive way to find a threshold at which a smaller antecedent would suggest to omit a given rule. The proposal there is fully equivalent to the following one:\nDefinition 2.15. Given rule X → XY , with X ∩ Y = ∅, a proper subset Z ⊂ X blocks X → XY at blocking threshold b if\ns(XY )− c(Z → ZY )s(X) c(Z → ZY )s(X) ≤ b.\nThe threshold b is intended to take positive but small values, say around 0.2 or lower. The intuition behind this definition is as follows: we will want to discard rule X → XY in case we find a rule Z → ZY , with Z ⊂ X (and therefore ZY ⊂ XY , also properly), having “almost” the same confidence, or larger. (In the presence of a support threshold τ , we would be requiring as well, naturally, that s(Z → ZY ) > τ .) To do this, we compare the number of tuples having XY with the quantity that would be predicted from the confidence of the rule Z → ZY .\nMore precisely, let c(Z → ZY ) = c. If Y is distributed along the support of X at the same ratio as along the larger support of Z, we would expect s(XY ) ≈ c × s(X): we are, thus, considering the relative error committed by c × s(X) used as an approximation to s(XY ). In case the difference in the numerator is negative, it would mean that s(XY ) is even lower than what Z → ZY would suggest. If it is positive but the quotient is low, c(Z → ZY )× s(X) still suggests a good approximation to c(X → XY ), and the larger rule does not bring high enough confidence with respect to the simpler one to be considered: it remains blocked. But, if the quotient is larger, and this happens for all Z, then X → XY becomes interesting since its confidence is higher enough than suggested by other rules of the form Z → ZY .\nThe higher the block threshold, the more demanding the constraint is. It can be checked that the particular problems of the Adult dataset indicated above are actually solved already by imposing just a generously tiny blocking threshold (around 0.000075). Again the specific choice of value for the blocking threshold is justified in [Balcázar 2009] just in merely intuitive terms; however, note for later use that the confidence width bound and the blocking threshold are related in that paper as follows: if the confidence width bound is b, then the blocking threshold proposed is b− 1.\nExample 2.16. Due to the inequalities in Example 2.12, we can see that, at any nonnegative blocking threshold, ∅ blocks B → C:\ns(XY )− c(Z → ZY )s(X) c(Z → ZY )s(X) = s(BC)− c(∅ → C)s(B) c(∅ → C)s(B) ≈ 9− 9.16 9.16 < 0.\nLikewise, considering A→ BC, we have s(ABC)− c(∅ → BC)s(A)\nc(∅ → BC)s(A) = 8− (9/12) ∗ 10 (9/12) ∗ 10 ≈ 0.066\nso that this rule would be blocked by ∅ as soon as a blocking threshold higher than this quantity is imposed."
    }, {
      "heading" : "2.3. Support Ratio",
      "text" : "We will relate our values of confidence width and of confidence boost to an expression essentially employed first, to our knowledge, in [Kryszkiewicz 2001], where no particular name was assigned to it. Together with other similar quotients, it was introduced with the\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\naim of providing a faster algorithm for computing representative rules; it turns out that, as demonstrated in [Balcázar and T̂ırnăucă 2011], this approach is efficient and useful in practice but runs into the risk of providing incomplete output, as actual representative rules may be missed. The same reference provides further analysis, including almost equally efficient alternatives whose output is complete.\nHere we introduce this notion because it is related to all of our three parameters of confidence width, blocking, and confidence boost; it will allow us to explain more carefully their mutual relationships, and it allows for confidence boost constraints to be “pushed” into a closure mining process, as we will do in Section 6.\nDefinition 2.17. In the presence of a support threshold τ , the support ratio of an association rule X → XY is\nσ(X → XY ) = s(XY ) max{s(Z) ∣∣ XY ⊂ Z, s(Z) > τ} We see that this measure does not depend on the antecedent X but just on XY . Again, we set its value to ∞ if no Z exists as required for the maximization in the denominator. We have the following relationship:\nProposition 2.18. If the value of σ(X → XY ) is finite and well-defined then the confidence width w(X → XY ) is also finite, and then\nw(X → XY ) ≤ σ(X → XY ).\nProof. This is easy to see from Proposition 2.9, and by observing that X → Z, for the Z 6= XY that maximizes the support in the denominator of support ratio, leads to w(X → XY ) ≤ c(X → XY )/c(X → Z) = s(XY )/s(Z) = σ(X → XY ) by simplifying the value of s(X) 6= 0.\nIt is clear that σ(X → XY ) ≥ 1 for all rules; σ(X → XY ) = 1 exactly when XY is not closed, since these sets are those that have some proper superset Z with the same support. The following easy consequence is worth mentioning: many of the quantities we study for an association rule X → XY are bounded from above by the support ratio and, therefore, will trivialize to values less than or equal to 1 unless we consider only closed sets XY as right hand sides. Together with Proposition 2.5, this is the reason of the importance of the closure notion in our context, and of the introduction of a closure-aware version of confidence boost in Section 4.\nExample 2.19. Looking again at association rule A → BC in Example 2.2, we see that σ(A→ BC) = s(ABC)/s(ABCDE) = 4/3."
    }, {
      "heading" : "3. CONFIDENCE BOOST",
      "text" : "This section introduces the first, simpler version of our main notion; it is very similar to the one given for confidence width, but with a twist that, even though formally tiny, semantically changes it far enough so as to encompass the notion of blocking.\nDefinition 3.1. The confidence boost of an association rule X → XY (always with X ∩ Y = ∅) is β(X → XY ) =\n= c(X → XY ) max{c(X ′ → X ′Y ′) ∣∣ (X → XY ) 6= (X ′ → X ′Y ′), X ′ ⊆ X, Y ⊆ Y ′}\nAs in previous cases, the rules in the denominator are implicitly required to clear the support threshold: s(X ′ → X ′Y ′) > τ . Again, in case the set in the denominator is empty, the confidence boost is infinite by convention. As in Proposition 2.9, we can point out exactly which rules fall in that case: the same ones, in fact.\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nProposition 3.2. The value of β(X → XY ) is finite and well-defined if and only if either X 6= ∅, or Y has some proper superset Z with s(Z) > τ . That is: the set of rules of infinite confidence boost coincides with the set of rules of infinite width.\nProof. Like in Proposition 2.9, if X = ∅ and no proper superset of Y reaches support above τ in the dataset, then no different rule (of sufficient support) is available for the set in the denominator. Conversely, ∅ → Z belongs to that set if either X 6= ∅, or Y ⊂ Z.\nAs indicated above, these cases of infinite confidence boost hardly ever appear in practice, due to their confidence being below the threshold.\nExample 3.3. Considering again association rule A → BC in Example 2.2, we find a value of the confidence boost of 16/15 for this rule. This is obtained as follows: we consider all rules X ′ → X ′Y ′ with X ′ ⊆ A and BC ⊆ Y ′ (and different from it); one can see that the maximum confidence among them is 0.75, attained by ∅ → BC. Then β(A → BC) = 0.8/0.75 = 16/15 ≈ 1.066.\nThe fact that a low confidence boost corresponds to a low novelty is similar to the analogous explanation for width, and can be argued intuitively as follows. Suppose that β(X → XY ) is low, say β(X → XY ) ≤ b, where b is just slightly larger than 1. Then, according to the definition, there must exist some different rule X ′ → X ′Y ′, with X ′ ⊆ X and Y ⊆ X ′Y ′, such that c(X→XY )c(X′→X′Y ′) ≤ b, or c(X\n′ → X ′Y ′) ≥ c(X → XY )/b. This inequality says that the rule X ′ → X ′Y ′, stating that transactions with X ′ tend to have X ′Y ′, has a confidence relatively high, not much lower than that of X → XY ; equivalently, the confidence of X → XY is not much higher (it could be lower) than that of X ′ → X ′Y ′. But all transactions having X do have X ′, and all transactions having Y ′ have Y , so that the confidence found for X → XY is not really that novel, given that it does not give so much additional confidence over a rule that states such a similarly confident, and intuitively stronger, fact, namely X ′ → X ′Y ′.\nAt a bare minimum, we should not consider association rules with confidence boost 1 or less. Notice that this solves the objection against confidence that negative correlations go undetected: for instance, if the support of B is, say, 80%, a rule A → B of confidence less than that would yield a confidence boost below 1, due to the rule ∅ → B."
    }, {
      "heading" : "3.1. Boost, Lift, Support Ratio, Width, and Blocking",
      "text" : "We present now some analyses clarifying the properties of the confidence boost. First, we see that it allows one to filter out rules that would be discarded on the basis of lift, since rules of low lift have low confidence boost.\nProposition 3.4. Let X 6= ∅; then, the confidence boost β(X → XY ) is bounded from above by the lift of X → Y . Proof. We simply consider the rule ∅ → Y , which differs from X → Y since X 6= ∅. Its support is above that of X → Y and thus above the support threshold. Clearly, it appears among the rules considered to maximize the confidence in the denominator of the definition of β(X → XY ), hence β(X → XY ) ≤ c(X→XY )c(∅→Y ) ; but c(∅ → Y ) = s(Y )/n and then c(X→XY ) c(∅→Y ) is exactly the lift of X → Y . In the case where X = ∅, the lift is 1, as already indicated; this value turns out to be uninformative in this case, since any right-hand side is independent from ∅. Confidence boost does apply to this case, being able to detect low novelty through larger consequents.\nThe only formal difference between confidence boost and confidence width of a rule X → XY is that, upon exploring alternative rules X ′ → X ′Y ′, in the confidence boost the antecedent X is not required anymore to be a subset of the consequent X ′Y ′, whereas it must be for X ′ → Y ′ to qualify in the computation of the width. More precisely, given that\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nX ∩ Y = ∅ and X ′ ⊆ X, it follows X ′ ∩ Y = ∅, so that the condition Y ⊆ Y ′ is equivalent to the condition Y ⊆ X ′Y ′. Proposition 2.10 tells us that XY ⊆ X ′Y ′ ⇐⇒ (X −X ′) ⊆ Y ′ and Y ⊆ Y ′, and we see that confidence boost simply keeps the inclusion among the right-hand sides Y ⊆ Y ′ and does not require additionally that (X − X ′) ⊆ Y ′ anymore. This also tells us that all rules X ′ → X ′Y ′ that are considered for the maximization in the denominator in the definition of confidence width are also considered for the corresponding maximization in confidence boost. Thus, the value of the maximum itself is at least the same, or possibly larger, and the difference is that the boost case may consider further candidates to X ′ → X ′Y ′. That is:\nProposition 3.5. The confidence boost of a rule is bounded above by its confidence width: β(X → XY ) ≤ w(X → XY ). Hence, β(X → XY ) ≤ σ(X → XY ).\nThe last sentence comes from Proposition 2.18, and was proved directly first in [Balcázar et al. 2010b]. For the next theorem, we state separately a simple technical equivalence.\nLemma 3.6. Z ⊂ X blocks X → XY at block threshold b−1 if and only if c(X→XY )c(Z→ZY ) ≤ b.\nProof. By definition, Z ⊂ X blocks X → XY at blocking threshold b− 1 if and only if s(XY )− c(Z → ZY )s(X)\nc(Z → ZY )s(X) ≤ b− 1.\nMultiplying both sides of the inequality by c(Z → ZY ), separating the two terms of the lefthand side, and replacing s(XY )/s(X) by its meaning, c(X → XY ), we find the equivalent expression\nc(X → XY )− c(Z → ZY ) ≤ (b− 1)(c(Z → ZY ) where solving for b leads to\nc(X → XY ) c(Z → ZY ) ≤ b.\nAll the algebraic manipulations are reversible (in particular, confidences and supports appearing all along are never zero so we can multiply or divide by them without trouble.)\nWe show next that confidence boost embodies exactly both blocking and confidence width, precisely with the same relation between the thresholds as used in [Balcázar 2009], under the already stated proviso that all the association rules involved must clear the support threshold.\nTheorem 3.7. For an association rule X → XY , β(X → XY ) ≤ b if and only if either w(X → XY ) ≤ b or X → XY is blocked at a blocking threshold b− 1. Proof. First we prove that either of low width or blocking imply low boost. We have already argued in Proposition 3.5 that β(X → XY ) ≤ w(X → XY ). Likewise, assume that Z ⊂ X (proper subset) blocks X → XY at a blocking threshold b − 1. Clearly the rule Z → ZY differs from X → XY since Z is a proper subset of X and fulfills the conditions to enter the maximum confidence denominator in the definition of confidence boost. This means that this maximum is at least as large as c(Z → ZY ), and therefore, by Lemma 3.6,\nβ(X → XY ) ≤ c(X → XY ) c(Z → ZY ) ≤ b.\nConversely, we assume now that β(X → XY ) ≤ b and prove that either w(X → XY ) ≤ b or X → XY is blocked at a blocking threshold b−1. The definition of confidence boost tells us that there is a different rule X ′ → X ′Y ′ (X ′ ∩ Y ′ = ∅) for which s(X ′Y ′) > τ , X ′ ⊆ X, Y ⊆ Y ′, and c(X→XY )c(X′→X′Y ′) ≤ b. We consider two cases, according to whether X = X ′. If\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nX = X ′, necessarily Y ⊂ Y ′ properly, thus XY ⊂ X ′Y ′ properly, and s(X) = s(X ′) plus s(X ′Y ′) > τ tells us that\nw(X → XY ) ≤ σ(X → XY ) ≤ s(XY ) s(X ′Y ′) = c(X → XY ) c(X ′ → X ′Y ′) ≤ b.\nOtherwise, X ′ ⊂ X properly, and Y ⊆ Y ′ (and a fortiori X ′ ∩ Y = ∅) gives us c(X ′ → X ′Y ) ≥ c(X ′ → X ′Y ′) whence c(X→XY )c(X′→X′Y ) ≤ c(X→XY ) c(X′→X′Y ′) ≤ b. Applying again Lemma 3.6, we obtain that X ′ blocks X → Y at blocking threshold b− 1. Hence, bounding the confidence boost at b ensures us that the rules that would be filtered by that confidence boost bound are exactly the same as those that would be filtered by either (or both) of the checks w(X → XY ) ≤ b or blocking at threshold b− 1. In this sense, confidence boost embodies both low-novelty tests from [Balcázar 2009], and with the same thresholds employed there.\nWe briefly consider the case of rules with a single item in the antecedent.\nProposition 3.8. Assume that |X| = 1 in rule X → XY , that is, the left hand side is a single item. Then β(X → XY ) coincides with the minimum among the lift of X → Y and σ(X → XY ). Proof. Let X ′ → X ′Y ′ be the rule that leads to β(X → XY ) = c(X → XY )/c(X ′ → X ′Y ′). It must be different from X → XY , and must clear the support threshold.\nIf X ′ ⊂ X, as X is a singleton, we have X ′ = ∅, s(X ′) = n (the number of transactions in the dataset), Y ⊆ Y ′, s(Y ′) ≤ s(Y ), and\nβ(X → XY ) = c(X → XY ) c(X ′ → X ′Y ′) = c(X → Y ) s(Y ′)/n ≥ c(X → Y ) s(Y )/n = s(XY )× n s(X)× s(Y )\nwhich is the value of the lift; but the boost is also less than or equal to the lift by Proposition 3.4, and they must coincide. The support ratio must be higher by Proposition 3.5, so the confidence boost equals the stated minimum.\nThe other case is where X ′ = X; then, as the two association rules are different, necessarily XY 6= X ′Y ′ = XY ′, so that σ(X → XY ) ≤ s(XY )/s(XY ′) = c(X → XY )/c(X → XY ′) because we can divide by s(X) 6= 0; that is, σ(X → XY ) ≤ β(X → XY ). The converse inequality is furnished by Proposition 3.5 and, once we have the equality σ(X → XY ) = β(X → XY ), the fact that this value is the indicated minimum comes from Proposition 3.4.\nCorollary 3.9. Assume a threshold b in place such that σ(X → XY ) ≥ b is known, for |X| = 1, that is, for a rule with a single antecedent item. If the lift of X → Y is less than b, then it equals β(X → XY ).\nExample 3.10. We revisit again association rule A→ BC in Example 2.2. For this rule, the lift is 16/15, less than the support ratio 4/3, so that the former coincides with the confidence boost as per Proposition 3.8. The quantities evaluated in previous examples lead now to the inequalities\nβ(A→ BC) = 16/15 < w(A→ BC) = 6/5 < σ(A→ BC) = 4/3 which obey, of course, all inequalities we have proved so far and, at the same time, witness that each inequality may well be proper."
    }, {
      "heading" : "3.2. Double-Threshold Confidence",
      "text" : "In order to be of practical use, we need a deeper study of the confidence boost. As it currently stands, it makes no sense to traverse all the alternative rules to be taken into account for computing the maximum confidence in the denominator. The same sort of\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\ndifficulty appears for confidence width and for blocking. A mild precomputation allows one to compute quite efficiently the width [Balcázar 2009], but the same method does not seem to work for blocking or boost. In fact, the experiments reported in that reference resort, as indicated there, to an approximation to blocking.\nBy the reasons already discussed, we will not be interested in confidence boost bounds of 1 or less; above 1, by Proposition 3.5, we only find representative rules. Given confidence threshold γ, we will show that, in order to test the confidence boost threshold, it suffices to do so against the set of representative rules computed at a lower confidence threshold, namely γ/b. Indeed, consider Algorithm 1. The comparisons are written there in such a way so as to avoid division by zero in the cases of infinite boost, such as s(XAY ) = 0, which may potentially be the case.\nAlgorithm 1: A double confidence threshold algorithm\nData: dataset D; thresholds for support τ , for confidence γ, and for confidence boost b > 1; rule X → XY with X ∩ Y = ∅, c(X → XY ) ≥ γ, and s(XY ) ≥ τ Result: boolean value indicating whether β(X → XY ) > b mine D for the representative rules R at threshold γ/b for each rule X ′ → X ′Y ′ ∈ R such that X ′ ∩ Y ′ = ∅, X ′ ⊆ X and Y ⊆ Y ′ do\nif ∃Z ⊂ X −X ′ such that c(X → XY ) ≤ b× c(X ′Z → X ′ZY ) then return False if ∃A ∈ Y ′ −XY such that c(X → XY ) ≤ b× c(X → XAY ) then return False\nreturn True\nTheorem 3.11. Let X → XY be a rule of confidence at least γ. Then, Algorithm 1 accepts it if and only if β(X → XY ) > b.\nProof. First we see that the rejections are correct. In each case, we just found a rule X ′′ → X ′′Y ′′ with X ′′ ⊆ X and Y ⊆ Y ′′, be it X ′Z → X ′ZY or X → XAY ; also X ′′ → X ′′Y ′′ 6= X → XY : in the first case, Z is a proper subset of X −X ′, so X ′Z 6= X, and in the second case the item A did not appear in X → XY . In each case, the rule X ′′ → X ′′Y ′′ enters the maximization in the denominator of the confidence boost and shows that its value is less than or equal to b.\nTo see that acceptance is correct, assume β(X → XY ) ≤ b: we prove that, at some point, rule X → XY must fail one of the two tests in the algorithm. By the definition of confidence boost, there must exist some rule X ′′ → X ′′Y ′′, different from X → XY , with X ′′ ⊆ X and Y ⊆ Y ′′, such that c(X → XY ) ≤ b× c(X ′′ → X ′′Y ′′).\nThen, from c(X → XY ) ≥ γ we infer c(X ′′ → X ′′Y ′′) ≥ γ/b, so that there must exist a representative rule at confidence γ/b, let it be X ′ → X ′Y ′ ∈ R, that makes X ′′ → X ′′Y ′′ redundant (possibly itself): by Lemma 2.4, X ′ ⊆ X ′′ and X ′′Y ′′ ⊆ X ′Y ′. At some point (unless a correct negative answer is found earlier), the algorithm will consider this rule X ′ → X ′Y ′ ∈ R. As in the proof of Theorem 3.7, we distinguish two cases.\nFirst assume that X ′′ is a proper subset of X, X ′′ ⊂ X. Since X ′ ⊆ X ′′, we can consider Z = X ′′ − X ′ ⊂ X − X ′: at some point, the algorithm will compare c(X → XY ) to b × c(X ′Z → X ′ZY ). But it holds that X ′Z = X ′′ and that Y ⊆ Y ′′, resulting in c(X → XY ) ≤ b× c(X ′′ → X ′′Y ′′) ≤ b× c(X ′Z → X ′ZY ) and failing the test.\nAlternatively, assume X ′′ ⊆ X holds with equality: X ′′ = X. From X ′′ → X ′′Y ′′ 6= X → XY (and using X ∩ Y = ∅ and X ′′ ∩ Y ′′ = ∅) we know that Y ⊂ Y ′′ is a proper inclusion: there is some A ∈ Y ′′ ⊆ X ′Y ′ that is not in Y . Such A is not in X either, because X ′′ ∩ Y ′′ = X ∩ Y ′′ = ∅, and then, in fact, A /∈ X ′, so that A ∈ Y ′ −XY . In due time, the\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nalgorithm will compare c(X → XY ) to b × c(X → XAY ). But X = X ′′, and A ∈ Y ′′ so that AY ⊆ Y ′′, hence c(X → XY ) ≤ b× c(X ′′ → X ′′Y ′′) ≤ b× c(X → XAY ) and the test will fail as well. This completes the proof."
    }, {
      "heading" : "4. CLOSURE-BASED CONFIDENCE BOOST",
      "text" : "Representative rules are a minimum size basis for redundancy, defined as per Lemma 2.4; still, they constitute often a large set. Prior to accepting the option of losing information in a quantifiable manner, as we are doing via confidence boost, one could consider the option of using stronger notions of redundancy. Several earlier papers, e. g. [Luxenburger 1991; Pasquier et al. 2005; Zaki 2004], suggest to treat separately the implications, which allow for more compact bases, from the partial rules. In [Balcázar 2010c], besides another more complicated alternative, we follow up this suggestion as well, and employ a notion of closure-based redundancy which also turns out to provide a complete basis of provably minimum size, denoted B?. This option has definite advantages: whereas it provides bases comparable in size with, and often clearly smaller than, the set of representative rules, it has the desirable property that the portion of it that refers to partial associations (of confidence below 1) can be computed faster. The best approaches to the representative rules need to work on the basis of both the closures lattice plus all the minimal generators of each closure ([Kryszkiewicz 2001], but see the related discussion in [Balcázar and T̂ırnăucă 2011]); instead, the B? basis can be computed just from the closures. In this section, we port confidence boost into closure-based redundancy and the corresponding minimum-size basis B?.\nClosure-based redundancy corresponds to restricting consideration of datasets as a function of the closure operator they induce. It is well-known that the closure operator is equivalently specified by a set of implications, that is, association rules of confidence 1 (see e. g. [Zaki 2004]). Closure-based redundancy [Balcázar 2010c] takes into account the closure operator indirectly as follows:\nDefinition 4.1. Let B be a set of implications. Partial rule X0 → X0Y0 has closure-based redundancy relative to B with respect to rule X1 → X1Y1 if the inequalities\nc(X0 → X0Y0) ≥ c(X1 → X1Y1) and s(X0 → X0Y0) ≥ s(X1 → X1Y1)\nhold in any dataset D in which all the rules in B hold with confidence 1.\nThis redundancy has a characterization parallel to that of Lemma 2.4, proved in the same reference:\nLemma 4.2. Let B be a set of implications. Consider two association rules, X0 → X0Y0 and X1 → X1Y1. The following are equivalent:\n(1 ) Rule X0 → X0Y0 has closure-based redundancy relative to B with respect to rule X1 → X1Y1. (2 ) X1 ⊆ X0 and X0Y0 ⊆ X1Y1.\nThe closure operator in the second statement is the one corresponding to the set of implications B.\nIn all applications, B is the set of full-confidence implications holding in the dataset, so that the closure operator is actually the one induced by the dataset. For closure-based redundancy, a minimum-size basis can be constructed as well. Essentially, this basis, denoted B?γ for confidence threshold γ, is defined in a manner analogous to that of the representative rules, except that it is restricted to rules of the form X → XY where both X and XY are closed sets, instead of X being a minimal generator as in representative rules. All these definitions are studied in depth in [Balcázar 2010c].\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nIf we are to employ this notion of redundancy and the B? basis, then the definition of confidence boost requires some fine tuning. This basis is often smallish because many different representative rules could correspond to many left-hand sides that are minimal generators of the same closure. Such sets of rules become a single rule in B?. But, if we use the given definition of confidence boost, these rules are syntactically different from the one in B? and “kill it” by forcing its boost down to 1. Thus, to avoid trivializing B?, we need to take into account the closure operator in the definition of boost. The main notion of this section is as follows:\nDefinition 4.3. The closure-based confidence boost of a rule X → XY is β(X → XY ) =\n= c(X → XY ) max{c(X ′ → X ′Y ′) ∣∣ (X 6= X ′ ∨XY 6= X ′Y ′), X ′ ⊆ X, Y ⊆ X ′Y ′}\nThis is the natural definition paralleling the confidence boost when the notion of reduncancy is closure-based: on one hand, the rules in the denominator may resort to the use of closures to make the rule at hand redundant, widening the options of redundancy; on the other hand, rules that are syntactically different from the rule at hand, but equivalent to it in closure-based redundancy, must be discarded, as they trivially entail the rule at hand. Failing to discard them unduly trivializes the confidence boost in many cases. Observe that the notion of confidence boost in the previous section corresponds to the particular case where the closure operator is the identity function.\nExample 4.4. Out of the seven representative rules at confidence threshold 0.8 that we enumerated in Example 2.6, some are unchanged in B?0.8, such as C → AB, B → C, ∅ → C, and ∅ → AB. Instead of A → BC, we find AB → C, which is equivalent to it due to the implication A → B; and, due to the implications D → CE and E → CD, it suffices to keep CDE → AB instead of the other two. If we were to employ plain confidence boost, β(CDE → AB) ≤ 1, due to rules D → ABCE and E → ABCD. Closure-based confidence boost is able to perform a finer distinction. As these two rules have the same closure of the antecedent as D = E = CDE, and the same associated closed set ABCDE, they do not enter the computation of closure-based confidence boost of CDE → AB, which is actually β(CDE → AB) = c(CDE → AB)/c(C → ABDE) = 10/7 > 1."
    }, {
      "heading" : "4.1. Double-Threshold Confidence Revisited",
      "text" : "We develop next an algorithm to compute closure-based confidence boost. We just need to make a number of adjustments to the one given for plain confidence boost: first, one must explore the rules of the B? basis for confidence γ/b, instead of the representative rules for it, since that is the appropriate basis for closure-based redundancy; and, second, one must take into account the closure operator at the time of checking whether a specific B? rule may lead to guaranteeing low boost of the input rule.\nTheorem 4.5. Let X → XY be a rule of confidence at least γ. Algorithm 2 accepts it if and only if β(X → XY ) > b.\nProof. We follow essentially the same steps as in Theorem 3.11, although we must argue more carefully about the places where the closure operator plays a role. Again, we see first that the rejections are correct. In each case, we just found a rule X ′′ → X ′′Y ′′ with X ′′ ⊆ X and Y ⊆ Y ′′, be it X ′Z → X ′ZY or X → XAY . In both cases, (X 6= X ′′ ∨XY 6= X ′′Y ′′) holds: in the first case, X ′Z 6= X is explicitly checked, whereas, for the second case, A ∈ XAY ⊆ XAY but A /∈ XY . In each case, the rule X ′′ → X ′′Y ′′ contributes to the maximization in the denominator of the confidence boost and shows that its value is less than or equal to b.\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nAlgorithm 2: A variant of Algorithm 1 for closure-based confidence boost\nData: dataset D; thresholds for support τ , for confidence γ, and for closure-based confidence boost b > 1; rule X → XY with X ∩ Y = ∅, c(X → XY ) ≥ γ, and s(XY ) ≥ τ Result: boolean value indicating whether β(X → XY ) > b mine D for the basis B? at threshold γ/b for each rule X ′ → X ′Y ′ ∈ B?γ/b where X\n′ ∩ Y ′ = ∅, with X ′ ⊆ X and Y ⊆ X ′Y ′ do if ∃Z ⊂ X −X ′ such that X ′Z ⊂ X (with inequality) and c(X → XY ) ≤ b× c(X ′Z → X ′ZY ) then\nreturn False\nif ∃A ∈ X ′Y ′ −XY such that c(X → XY ) ≤ b× c(X → XAY ) then return False\nreturn True\nTo see that acceptance is correct, assume β(X → XY ) ≤ b: we prove that, at some point, rule X → XY must fail one of the two tests in the algorithm. By the definition of closurebased confidence boost, there must exist some rule X ′′ → X ′′Y ′′ with X ′′ ⊆ X, Y ⊆ X ′′Y ′′, and (X 6= X ′′ ∨XY 6= X ′′Y ′′), and such that c(X → XY ) ≤ b × c(X ′′ → X ′′Y ′′). Then, from c(X → XY ) ≥ γ we infer c(X ′′ → X ′′Y ′′) ≥ γ/b, so that there must exist a rule in the basis B?γ/b, let it be X\n′ → X ′Y ′, that makes X ′′ → X ′′Y ′′ redundant (possibly itself) under closure-based redundancy. By Lemma 4.2, X ′ ⊆ X ′′ and X ′′Y ′′ ⊆ X ′Y ′ = X ′Y ′, where the last equality is due to the fact that X ′ → X ′Y ′ ∈ B?γ/b so that X ′Y ′ is closed. At some point (unless a correct negative answer is found earlier), the algorithm will consider this rule X ′ → X ′Y ′ ∈ B?γ/b. As in the proof of Theorem 3.7, we distinguish two cases.\nFirst assume that X ′′ ⊂ X. Since X ′ ⊆ X ′′, we can consider Z = X ′′ −X ′ ⊂ X −X ′: at some point, the algorithm will compare c(X → XY ) to b× c(X ′Z → X ′ZY ). But it holds that X ′Z = X ′′ and that Y ⊆ X ′′Y ′′, resulting in c(X → XY ) ≤ b × c(X ′′ → X ′′Y ′′) = b× c(X ′′ → X ′′Y ′′) ≤ b× c(X ′Z → X ′ZY ) and failing the test.\nAlternatively, let’s consider the case where X ′′ ⊆ X holds with equality: X ′′ = X, so that XY 6= X ′′Y ′′; on the other hand, we know now X ⊆ X = X ′′ ⊆ X ′′Y ′′, and also Y ⊆ X ′′Y ′′, so that XY ⊆ X ′′Y ′′.\nAssume briefly that Y ′′ ⊆ XY : as X ′′ ⊆ X ′′ = X ⊆ XY , we would obtain X ′′Y ′′ ⊆ XY and, therefore, the equality XY = X ′′Y ′′; however, we know that this equality does not hold.\nHence, Y ′′ is not included in XY , and there is some A ∈ Y ′′ ⊆ X ′Y ′ that is not in XY , that is, A ∈ X ′Y ′ − XY . (If we know that X = X, for instance when the rule X → XY comes from a B? basis, X ′ ⊆ X ′′ = X = X tells us that the search for A can be circumscribed further to just A ∈ Y ′ − XY .) In due time, the algorithm will compare c(X → XY ) to b× c(X → XAY ). But X = X ′′, and A ∈ Y ′′ so that XAY ⊆ X ′′Y ′′, hence c(X → XY ) ≤ b× c(X ′′ → X ′′Y ′′) = b× c(X ′′ → X ′′Y ′′) ≤ b× c(X → XAY ) and the test will fail as well. This completes the proof.\nWe report on a second algorithm below."
    }, {
      "heading" : "4.2. Inequalities",
      "text" : "Compared to confidence boost, closure-based confidence boost relaxes the alternative rules to which a given rule is compared, e.g. by allowing left hand sides included in X that are not included in X; but, on the other hand, restricts them by the proviso that the rules are “inequivalent” in a closure-based sense, and not just different. Therefore, either can end\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nup being higher than the other, and the relationship with other quantities like width or support ratio become less clear. We must review which inequalities still hold; we start with the (partial) analogs of Propositions 3.5 and 3.4.\nProposition 4.6. Assume XY closed. Then, the closure-based confidence boost is bounded by the support ratio: β(X → XY ) ≤ σ(X → XY ).\nProof. Let Z be the proper superset ofXY of largest support above τ , so that σ(X → XY ) = s(XY )/s(Z). As XY is closed, Z 6= XY . Rule X → Z enters, therefore, the maximization in the denominator of the closure-based confidence boost and leads to β(X → XY ) ≤ c(X → XY )/c(X → Z) = s(XY )/s(Z) = σ(X → XY ).\nProposition 4.7. Assume s(X) < n, the dataset size; then, the closure-based confidence boost β(X → XY ) is bounded above by the lift of X → Y .\nProof. We consider the rule ∅ → Y . For it to play a role in closure-based confidence boost, we need ∅ 6= X, which is equivalent to s(X) < n. The rest of the argumentation is as in Proposition 3.4: its support is above the threshold, and β(X → XY ) ≤ c(X→XY )c(∅→Y ) which is the lift of X → Y .\nIt is interesting to note that the condition about the left-hand side being nonempty in Proposition 3.4 corresponds now to having support less than the dataset size: the intuition is that any items that appear in all transactions become part of the closure of the empty set, which is now the limit case.\nWe discuss now some relationships between the plain and the closure-based versions of the confidence boost.\nProposition 4.8. Let X → XY be an association rule where XY is a closed set and X is a minimal generator. Then, β(X → XY ) ≤ β(X → XY ).\nProof. Let β(X → XY ) = b: there must be a different rule X ′ → X ′Y ′ such that X ′ ⊆ X, Y ⊆ Y ′, and c(X→XY )c(X′→X′Y ′) = b. Assume first that X\n′ ⊂ X. As X is a minimum generator, any subset of X has strictly larger support. Hence, s(X) = s(X) 6= s(X ′) = s(X ′), which implies that X 6= X ′; then, the same rule X ′ → X ′Y ′ is accounted for in β as well, and leads to a value of at most b.\nThe remaining case is X = X ′, which requires that XY 6= X ′Y ′. Moreover, both X = X ′ ⊆ X ′Y ′ and Y ⊆ X ′Y ′ by the definition of confidence boost, and XY is closed, so that XY = XY ⊂ X ′Y ′ ⊆ X ′Y ′. Again in this case X ′ → X ′Y ′ is accounted for in β, and the stated inequality holds.\nCorollary 4.9. Let X → XY be a representative rule at any confidence threshold; then β(X → XY ) ≤ β(X → XY ).\nOne interesting particular case is that of rules of confidence 1 formed when X is a minimum generator of the closed set XY itself; these rules form the min-max exact basis from Definition 2.3 [Pasquier et al. 2005] (a nonminimal basis for the implications of confidence 1, as the GD basis is sometimes smaller [Guigues and Duquenne 1986]). Proposition 4.8 applies to these rules as well, of course. On the other hand, we have:\nProposition 4.10. Let X → XY be an association rule where both X and XY are closed sets. Then, β(X → XY ) ≤ β(X → XY ).\nProof. Let β(X → XY ) = b: there must be a rule X ′ → X ′Y ′ such that c(X→XY )c(X′→X′Y ′) = b, fulfilling the conditions X ′ ⊆ X, Y ⊆ X ′Y ′, and either X 6= X ′ or XY 6= X ′Y ′. We observe\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nfirst that, as X is closed, X ′ ⊆ X = X. Together with X ∩ Y = ∅, we get for later use that X ′ ∩ Y = ∅ as well.\nWe modify the rule X ′ → X ′Y ′ by extending its right-hand side into a closed set, as X ′ → X ′Y ′, which has the same confidence, and then rewrite it into X ′ → X ′Y ′′ by setting Y ′′ = X ′Y ′ −X ′. Note that Y ⊆ X ′Y ′, together with X ′ ∩ Y = ∅, leads to Y ⊆ Y ′′.\nHence, with that rule written in this form, the properties become c(X→XY )c(X′→X′Y ′′) = b, X ′ ⊆ X = X, Y ⊆ Y ′′, and either X 6= X ′ or XY 6= X ′Y ′′. It suffices to show that X ′ → X ′Y ′′ and X → XY are different rules to ensure that X ′ → X ′Y ′′ participates in the computation of β(X → XY ) and, hence, to obtain the desired inequality. But: if X 6= X ′, then necessarily X 6= X ′; and, in the other case, XY = XY 6= X ′Y ′′ = X ′Y ′′ as both XY and X ′Y ′′ = X ′Y ′ are closed sets. This completes the proof.\nAs the B? basis consists of rules where both antecedent X and consequent XY are closed sets, we obtain:\nCorollary 4.11. Let X → XY be a rule in the B? basis (at confidence c(X → XY )); then, β(X → XY ) ≤ β(X → XY ).\nFor the not unusual cases where a representative rule participates as well in the B? basis, Section 3 suggests measuring its confidence boost, whereas Section 4 would propose to measure its closure-based confidence boost. Now we see that there is no conflict:\nCorollary 4.12. If X → XY is both a representative rule and a member of the B? basis (both at confidence c(X → XY )), then β(X → XY ) = β(X → XY ).\nThis follows at once from Corollaries 4.9 and 4.11.\nExample 4.13. In general, either of β and β can be strictly larger, when permitted by the statements we have proved so far. In Example 4.4, we saw a B? rule for which β(CDE → AB) > β(CDE → AB). This also shows that Corollary 4.9 cannot be extended to the B? basis. Conversely, as A = AB in our running example, rule B → C is taken into account for the closure-based confidence boost of the representative rule A→ BC, leading to β(A→ BC) < 1, whereas β(A→ BC) = 16/15 as we saw in Example 3.10.\nWe develop some further inequalities and yet another algorithm that we will employ in Section 6.\nTheorem 4.14. Assume that a threshold b has been fixed for the closure-based confidence boost. Consider rule X → XY where both X and XY are closed sets. Then β(X → XY ) ≤ b if and only if either σ(X → XY ) ≤ b, or there is some closed proper subset X ′ ⊂ X, c(X → XY ) ≤ b× c(X ′ → X ′Y ).\nProof. Assume first β(X → XY ) ≤ b. Let X ′ → X ′Y ′ be the rule in the denominator of the definition of β that leads to its actual value. Due to Y ⊆ X ′Y ′, we have c(X ′ → X ′Y ) ≥ c(X ′ → X ′Y ′). If X ′ 6= X, as X is assumed closed, we can state X ′ ⊆ X = X so that, by monotonicity, X ′ ⊆ X ′ ⊂ X = X. Thus, c(X→XY )c(X′→X′Y ) ≤ c(X→XY ) c(X′→X′Y ′) = β(X → XY ) ≤ b, and the second case holds. If, on the other hand, X ′ = X, then s(X) = s(X) = s(X ′) = s(X ′) and, necessarily, XY 6= X ′Y ′; yet XY = XY ⊆ X ′Y ′ ⊆ X ′Y ′ as XY is closed, hence XY = XY ⊂ X ′Y ′, leading to σ(X → XY ) ≤ s(XY )s(X′Y ′) = c(X→XY ) c(X′→X′Y ′) = β(X → XY ) ≤ b.\nConversely, if σ(X → XY ) ≤ b then β(X → XY ) ≤ b by Proposition 4.6. Also, assuming X ′ ⊂ X gives us c(X → XY ) ≤ b × c(X ′ → X ′Y ), where both X and X ′ are closed, X ′ = X ′ ⊂ X = X so that X ′ 6= X, and rule X ′ → X ′Y participates in the computation of β(X → XY ), leading to β(X → XY ) ≤ c(X→XY )c(X′→X′Y ) ≤ b.\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nFor convenience in a later application, we restate this theorem in its contrapositive form:\nCorollary 4.15. Assume that a threshold b has been fixed for the closure-based confidence boost. Consider rule X → XY where both X and XY are closed sets. Then β(X → XY ) > b if and only if both σ(X → XY ) > b and for every closed proper subset X ′ ⊂ X, c(X → XY ) > b× c(X ′ → X ′Y ).\nYet another application of this theorem is to identify the analog of Proposition 3.8 for the closure-based case. To get there, it is convenient to factor off the proof the following technical but easy fact:\nLemma 4.16. Let X be a closed singleton, that is, X = X and |X| = 1. If s(X) < n, then there is exactly one closed proper subset of X, namely ∅ = ∅; and, besides, X is free, that is, it is a minimum generator of itself.\nProof. By definition, ∅ contains exactly those items that appear in all the transactions. By monotonicity, as ∅ ⊆ Z for all Z, ∅ is a subset of all closures. If X is a closed singleton, either ∅ = ∅ or ∅ = X; this second case is ruled out by the condition s(X) < n, as s(∅) = s(∅) = n. Our statements follow.\nProposition 4.17. Assume that |X| = 1 in rule X → XY , that is, the left hand side is a single item. Further, assume that s(X) < n, and that X and XY are closed. Then β(X → XY ) coincides with the minimum among the lift of X → Y and σ(X → XY ).\nProof. By Propositions 4.6 and 4.7, we already know that β(X → XY ) is less than or equal to both quantities, under the given conditions. To complete the proof, we only need to show the converse inequality, that is, β(X → XY ) is larger than or equal to the minimum among the lift of X → Y and σ(X → XY ). For this, we will apply Theorem 4.14: β(X → XY ) ≤ b if and only if either σ(X → XY ) ≤ b or there is some closed proper subset X ′ ⊂ X, c(X → XY ) ≤ b×c(X ′ → X ′Y ). We observe that, by Lemma 4.16, in our current conditions there is exactly one such X ′, namely ∅, and the last inequality becomes, then, the statement that the lift of X → Y is at most b; indeed, the lift coincides with c(X→XY )c(∅→Y ) .\nAs we can chose any value of b, we pick simply b = β(X → XY ) itself, so that we can infer that either σ(X → XY ) ≤ b = β(X → XY ) or the lift of X → Y is also at most b = β(X → XY ). Thus, either σ(X → XY ) or the lift of X → Y are less than or equal to β(X → XY ) and, certainly, the lesser of both quantities obeys the same bound, which completes the proof.\nWe obtain the corresponding variant of Corollary 3.9:\nCorollary 4.18. Assume a threshold b in place such that σ(X → XY ) ≥ b is known, for |X| = 1, that is, for a rule with a single antecedent item. If s(X) < n, X and XY are closed, and the lift of X → Y is less than b, then it equals β(X → XY ).\nAs a consequence, β(X → XY ) = β(X → XY ) for these cases. This is also consistent with Corollary 4.12: as we have stated in Lemma 4.16, in this case X is both closed and a minimal generator; if c(X → XY ) < 1, then this implies that it is equivalent to state that X → XY is a representative rule and to state that it is in the B? basis. This corollary will be very relevant in the implementation described in Section 6."
    }, {
      "heading" : "4.3. Alternative Algorithm",
      "text" : "Theorem 4.14 leads to an alternative algorithm to filter rules from the B? basis according to their closure-based confidence boost; we present it as Algorithm 3. Its correctness is immediate from Theorem 4.14. This algorithm is part of the tool described in Section 6;\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nit tends to be better than the previous one when left-hand sides tend to be small. It pays the price of traversing all closed subsets of a given closed set but spares traversing the alternative basis at lower confidence. In our implementation, as described below, the test of the support ratio is actually pushed into the closure mining, so that it becomes unnecessary to repeat it at the time of evaluating rules.\nAlgorithm 3: An alternative algorithm for closure-based confidence boost\nData: dataset D; thresholds for support τ , for confidence γ, and for closure-based confidence boost b > 1; rule X → XY with X ∩ Y = ∅, X and XY both closed, c(X → XY ) ≥ γ, and s(XY ) ≥ τ Result: boolean value indicating whether β(X → XY ) > b if σ(X → XY ) ≤ b then\nreturn False if ∃Z ⊂ X closed such that c(X → XY ) ≤ b× c(Z → ZY ) then\nreturn False return True"
    }, {
      "heading" : "5. EMPIRICAL VALIDATION",
      "text" : "This section describes the outcomes of several empiric applications of the notions of confidence boost; the next section describes a complete tool that employs closure-based confidence boost, and the properties we have developed, to offer parameter-less association mining. With respect to specific datasets, we report first on objective figures: numbers of rules passing rather mild confidence boost thresholds on three datasets, all consisting of real world data, but of very different characteristics. Subsequently, we briefly discuss the much more difficult and subjective question of whether the rules that we find are actually the rules one may want."
    }, {
      "heading" : "5.1. Quantitative Evaluation",
      "text" : "Dataset Adult is the training set part of the Adult US census dataset from UCI [Asuncion and Newman 2007]. Dataset Retail was downloaded from the FIMI repository, and contains typical market basket data (http://fimi.cs.helsinki.fi/); and dataset Now (based on the Neogene of the Old World dataset, public release 030710 [Fortelius 2003]) is a transactional version of a paleontological dataset from Europe: we downloaded and preprocessed slightly file NOW public 030710.xls, so that each paleontological site has been casted into a transaction, where the items in the transactions are the species of which fossile remains have been found at that site. Additional information such as name or geographical position of the site have been omitted, in order to keep the transactional format.\nTable I gives some information about the datasets: their size (in number of transactions), the number of items involved, and the total of item occurrences. Each dataset has been mined at two different levels of support and three different levels of confidence. Support thresholds were chosen so as to produce noticeable numbers of rules, and also to make sure that the closure spaces were nontrivial in size (several thousand closures). Table II reports, for each pair of support and confidence values, the basis size (RR/B?, standing for representative rules and B? basis respectively) and then the number of these basis rules, for\neach basis, passing the corresponding confidence boost thresholds as given. Of course, for the B? case we bound the closure-based confidence boost.\nOur implementation was not particularly aimed at speed. Still, for instance, computing all the figures regarding the representative rule basis took less than 35 minutes on a lowrange laptop. For the higher support threshold in each dataset, each computation time was between 20 and 45 seconds. For the larger, more demanding closure lattice at the lower support threshold of each dataset, these figures required between 2 minutes and up to a maximum of 6 minutes. It will not be difficult to improve the running times in future work, as a number of known accelerations can be applied; we are already undertaking this task. Computationally, the slowest part was always the construction of the closure lattice.\nWith respect to the outcome, we see that the reduction of the number of rules is clear, and in some cases it is very considerable. Recall that the bound at 1 of the confidence boost discards those basis rules for which a rule with higher confidence can be obtained by either reducing the antecedent, enlarging the consequent, or both; in the first case, it would mean that the rule is actually a case of negative correlation that is better left off from the output."
    }, {
      "heading" : "5.2. Subjective Evaluation",
      "text" : "Quantitatively, the figures just given imply that large fractions of representative rules are somewhat uninteresting in that they fully lack any novelty, measured according to confidence boost. However, one may question whether the actual rules passing the thresholds are “the right ones”. To our subjective perception, after seeing the outcome of our experiments, the whole process makes a lot of sense, but, in order to argue that indeed bounding the confidence boost leads to a worthy data mining scheme, we should find a more convincing argumentation. We hasten to add here that using the mined rules for classification will\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nnot provide a reasonable evaluation, since for such applications we must focus on single pairs of attribute and value as right-hand side, thus making useless to consider larger righthand sides; and, also, the classification will only be sensible to minimal left-hand sides independently of their confidences (as in Subsection 7.2 below). Because of these properties, a classification task is not fine enough to provide information about the usefulness of the subtler confidence quotients involved in the confidence boost bounds.\nClearly, the difficulty of this evaluation lies in the fact that the issue is largely subjective. At the present moment, our way through is to involve “end-users” in the evaluation of the obtained association rules: persons that are extremely well-versed on the dataset at hand. Both for our version of confidence boost, and for a sensible extension of it to handle absence of items besides presence of items in the transactions, we are developing an analysis of educational datasets, containing information about online courses on multimedia systems and on the Linux operating system, in close cooperation with the teachers of said courses [Balcázar et al. 2010a]. Here, however, instead of looking for experts on a given dataset, we use a dataset for which some readers of this paper might be expected to be reasonably knowledgeable: in the same vein as the evaluations in [Gallo et al. 2007], we employ the titles, topics, and abstracts of all the reports submitted to the e-prints repository of the Pascal Network of Excellence along its early years of existence. This dataset, extracted from the repository by Professor Steve Gunn, was the object of a visualization challenge of the Pascal Network in 2006. (Professor Gunn has also kindly furnished to this author a similar but much larger dataset, to which we plan to apply the same scheme in the near future.)\nThe collection of papers was processed starting from a plain text file containing one line for each of the 721 papers, including the title, the subjects chosen from among the specific choices allowed by the repository (marked by a ’ !’ sign that we changed into the word “subject”), and the whole text of the abstract of the report. The (mild) preprocessing consisted in removing punctuation and nonprintable characters, mapping all letters into lowercase, stripping off stop words as per the list from www.textfixer.com, and removing duplicate words from each of the transactions so obtained. This left 45185 total word occurrences chosen from a vocabulary of 8233 items. We checked the size of the closure space at supports of 10% (135 closures) and 5% (830 closures, still somewhat small), and then at 1% (too large, as after a few minutes the program was still computing the closure lattice’s edges—in fact, a later run showed that it consists of 59713 closures). We settled for a far from trivial but manageable closure space consisting of 9621 closed itemsets obtained at 2% support. Then, we computed the B? basis at confidences 70% (1070 rules), 75% (729) rules, and 80% (412 rules), and cut them down by filtering them at closure-based confidence boosts of 1, 1.05, 1.1, 1.15, 1.2, 1.25, 1.3, 1.35, 1.4, 1.45 and 1.5. All the runs were almost instantaneous. The figures obtained, given in Table III, make it indeed possible to proceed to manual inspection of many of these options.\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nNext, as a particular case, we chose to perform an examination of the 26 rules found at 2% support, 80% confidence, and 1.5 (closure-based) confidence boost, which revealed rules with little or no redundancy among themselves, all of them semantically sensible, and with a handful of them actually quite interesting (for this author). The whole process leading to these “nuggets” lasted less than two hours, including all the preprocessing, for a single person (the author) and quite limited computing power (an old Centrino Solo laptop). These rules are given in Table V. The predefined subjects of the e-prints Pascal server appearing in the table have been shortened to fit the page; Table IV reports the abbreviations used for them in Tables V and VI.\nBy way of comparison, at the same level of support, at the most demanding possible level of confidence (100%), with the less redundant basis computation currently known (the Guigues-Duquenne basis, [Guigues and Duquenne 1986]), the result is 44 rules, with considerably more “intuitive redundancy” and less interest overall, and requires somewhat longer time to be computed. Note that, by their own definition, the rules in the B? basis do not attempt at capturing rules with 100% confidence, but just at complementing them with partial rules; hence, the Guigues-Duquenne basis has some additional information. For the sake of comparison, this basis is given in Table VI. The considerable redundancy is clear: many variants of “support” implies “vector” become reduced to a single one under the confidence boost bound. One may ask why the similar case of “vector” implies “support” is missing from the list of 26 rules: the answer is that its confidence is slightly under 75% and, thus, it is not reported under the 80% threshold. Once more we see that setting the thresholds with no formal guidance runs into very risky processes. It would be necessary to try and help the user by some sort of self-adjustment of the thresholds. We have attempted at one first approach along this line, which is reported next.\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY."
    }, {
      "heading" : "6. TOWARDS PARAMETER-FREE ASSOCIATION MINING",
      "text" : "In this section we describe an open-source software tool that profits from closure-based confidence boost and its properties to offer a sensible association mining process, while refraining from asking the user to select any value of any parameter: our system yacaree (Yet Another Closure-based Association Rule Experimentation Environment), a proof-ofconcept currently implemented fully in pure Python. It combines several processes using lazy evaluation by means of the functional programming facilities available in current versions of Python to mine high-boost B? association rules. Its key property is the self-tuning of the support and the confidence boost thresholds.\nAs in most current proposals, yacaree mines only frequent closed itemsets; initially, it enforces a support bound that starts ridiculously low (namely, at 5 transactions). In most applications, one cannot rely on mining all frequent closures at this threshold: this might or\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nmight not be possible, depending on the dataset; therefore, along the process, the threshold will be automatically increased. Frequent closures are mined via a simplified variant of ChARM [Zaki and Hsiao 2005], rather close to a depth-first search but with the proviso that closed itemsets are produced in order of decreasing support, so that increasing the support threshold does not invalidate the closures found so far.\nThis idea is reminiscent of the decreasing support in the version of “apriori” implemented in the Weka tool [Witten and Frank 2005], but in that well-known system the user still has to provide a maximum and a minimum values to try the support threshold, and a “delta” by which the support keeps decreasing; then, the “apriori” algorithm is run repeatedly for the corresponding sequence of support thresholds. Further, the process stops when a given number of rules, also chosen by the user, has been found. This makes it unlikely to find rules of low support. The “predictive apriori” alternative, present in that tool as well [Scheffer 2005; Witten and Frank 2005], also attempts at adjusting the support, by balancing it with respect to confidence. Our system works very differently, as it is able to mine closures in order of decreasing support by its own algorithmics, and self-adjusts the internal effective support bound on the basis of technological limitations, in a manner that is autonomous and independent of the confidence or of any other parameter of the mining process.\nThe closed set miner takes the form of an iterator, and searches for the next closed set to be reported only when asked to do so. Each closure found is analyzed, upon yielding it to the next phase, to see whether it can be further extended without failing the current support threshold, and all those extensions, with their explicit supporting transaction lists, are added to a heap which provides instantaneously the largest-support closed set that has not been extended so far.\nThe closures are passed on to a lattice constructor, a “border” algorithm which computes the lattice structure, so that immediate predecessors of each closed set are readily available, as it is convenient for computing the basis B?. The lattice constructor itself is based on [Baixeries et al. 2009] and works also as an iterator, constructing Hasse edges only when they are needed. Rules are, then, constructed from the lattice. Closures and candidate rules are either discarded, if we can guarantee that future threshold adjustments will never recover them; or processed, if they obey the thresholds; or maintained separately on hold, if they fail the current thresholds but might turn to obey them after future adjustments.\nThe support threshold changes along the process. It starts, as indicated, at an almost trivial level, and grows, if necessary, as the monitorization of the mining process reveals that the memory consumption surpasses internal thresholds. More precisely, the heap where unexpanded closures are stored is considered in overflow when either its length, or the total memory it uses, or the sum of the lengths of the associated support lists, exceeds a corresponding predefined threshold. At that point, the minimal support constraint is recomputed and raised as necessary so that the exploration can continue. In this way, both the risk of entering a huge closure space, and the risk of memory overflow upon computing the supports of the closed sets (as sometimes happens for dense datasets) are avoided.\nWe impose a very mild confidence threshold that remains fixed, letting large quantities of rules pass; but we control the number of rules to be provided to the user via a threshold on the closure-based confidence boost, which is adjusted also along the run. We use the approximation to the confidence boost provided by the support ratio (Proposition 4.6) to push the confidence boost constraint into the mining process, and we use the lift, applied to the particular cases to which Corollary 4.18 applies, to self-adjust the boost threshold.\nIn fact, as the Hasse edges of the closures lattice are identified, the support ratio can be computed easily. If it is lower than the current confidence boost threshold, the closure is not adequate to yield high boost rules, but it could become so if, in the future, the confidence boost threshold decreases. Therefore, the confidence boost constraint is partially “pushed into” the mining process by temporarily omitting the expansion of such closed sets. Instead, they are maintained separately into a dedicated data structure, from where they are “fished\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\noff” again in case a decrease of the boost bound promotes them to candidate closures for creating high-boost rules. We take advantage of the support ratio constraint also to compute the confidence boost of rules, as per Algorithm 3: we know that, if the closed set reaches that stage, then its support ratio is high enough, so we do not need to test it again.\nThe mining process starts with a somewhat demanding confidence boost bound, that requires a rule to have at least 15% more confidence than any of the rules participating in its confidence boost in order to qualify as interesting. In some datasets, this figure is not that restrictive, and dozens of rules still make it. By default, the system writes off as result the up to 50 rules of highest boost.\nIn many datasets, though, that confidence boost bound is too demanding. The program monitors the lift of rules having one single item as antecedent and obtained from a closed set that has support ratio above the confidence boost bound (cf. Corollary 4.18). If these lift values keep decreasing, they enter a weighted average with the current confidence boost bound and may decrease it. In this way, we track the degree of correlation empirically found in the dataset to reduce conveniently the confidence boost bound. There is a static limit to this boost bound: it is never allowed to drop below 1.05. (All the hardwired limits can be modified easily in the same module statics.py of the source code.)\nThe result is a functional preliminary system, where ample room still remains for efficiency and algorithmic improvements, which shows that it is possible to find interesting association rules in a fully autonomous manner: the user simply selects a dataset and launches the process, which takes just one to five minutes in many easy datasets, and up to ten to twenty minutes on a modern laptop for a few difficult, highly dense datasets. The output is a set of rules which, in most cases, is reasonably small and shows independent and sensible associations.\nThe open source, plus some example datasets, can be downloaded from http://sourceforge.net/projects/yacaree/; these example datasets are already preprocessed into transactional form, and come from [Asuncion and Newman 2007] or [Fortelius 2003], or from the e-prints repository of the Pascal Network of Excellence. The screenshot provided in Figure 2 shows the simple interface (button “Run” is disabled as the system has been just run) and the two text files generated: the log, where we can see that the process took a bit over five minutes, and the start of the file containing the rules found. Both the console and the log indicate the self-adjustments of the support; along this particular run, no adjustment was performed on the boost threshold, as enough high-boost rules were found for its initial value."
    }, {
      "heading" : "7. DISCUSSION",
      "text" : "The main contribution of this paper is the closure-based confidence boost: a new concept that measures a form of objective novelty for association rules, which we have studied from the formal and algorithmic perspective and which we have used to construct open source association mining tools.\nOur starting point was the study of notions of redundancy in a “logical” spirit. When a rule is irredundant, we still can use relative confidences to assess the degree of irredundancy, which we see as a potentially useful formalization of objective novelty.\nA redundancy due to larger consequents can be measured by the support ratio; as such, both earlier notions like confidence width and our new proposals are related to it. A redundancy due to smaller antecedents only in some cases is handled appopriately by the preexisting confidence width, due to the stringent condition of “logical” redundancy; with the also preexisting notion of blocking, the case of smaller antecedents is handled in a less strict, more intuitively useful way. A bound on the simplest of the two versions of confidence boost is exactly equivalent to bounding both preexisting notions, width and blocking; therefore, our first new proposal allows for much smoother handling of the combination of the previously studied concepts.\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nAs the notion of plain confidence boost turns out to be debatable for one specific “closureaware” basis, the B? rules, we have proposed also a more sophisticate “closure-aware” version of the confidence boost, for which we have developed the corresponding formal and algorithmic study.\nAn obvious drawback of using a confidence boost bound is the need to choose yet another parameter for the mining process, besides confidence and support. However, in our experiments, this problem did not seem to be that serious: a noticeable aspect of the confidence boost bound is that the outcome of the mining shows relatively quite low sensitivity both with respect to its precise value and with respect to the values of other parameters such as confidence: quite similar sets of rules are obtained. We quickly learned to use two standard values, at 1.05 to prune off just really low novelty rules and at 1.2 to prune more aggressively; whereas, in case the dataset still gives many rules above this threshold, occassionally we would employ the very drastic value of 1.5. This scheme tends to work well, and not only that: it also make less critical the choice of the confidence threshold, that can be safely left at a somewhat low value (say, around 0.6 to 0.7), leaving to the boost parameter the task of reducing the output size. These empirical facts were widespread to such an extent that we attempted at using (closure-based) confidence boost to try and construct a parameterfree association miner: the yacaree system, able to self-tune the closure-based confidence boost and the support thresholds. We believe that the embodiment of the computation of the B? basis together with closure-based confidence boost bounds in an open source tool will promote its use in data mining practice, as yacaree exhibits a unique quality of “turnkey” system that works with just the few clicks needed to choose the input dataset. Of course, it can be used as well in the standard manner, as the default initial values of confidence, support, and other internal parameters can be manually tuned effortlessly, if necessary, by data mining experts. However, this action is not anymore necessary, as yacaree is ready to do its best with no need of user choices. The system is platform independent, although in a system with small memory, the control of the heap size may require some initial tuning (to be made just once) to avoid runtime errors for lack of memory; whereas, in very powerful systems, obtaining the most of them may also require some tuning.\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nThe shortcomings of confidence thresholds discussed at the beginning of Subsection 2.2 have been often interpreted as an inadequacy of the very notion of confidence. Yet, we prefer to develop our proposal in the context of support and confidence bounds, for several reasons.\nFirst, conditional probability is a concept known to many educated users from a number of scientific and engineering disciplines, so that communication between the data mining expert and the domain expert is often simplified if our measure is confidence. Second, as a very elementary concept, it is the best playground to study other proposals, such as our contribution here, which could be then lifted to other similar parameters.\nThird, and more importantly, we believe that, in fact, our approach of complementing it with relative measures will make up for many of the objections raised against confidence. In fact, our interpretation of this sort of objections is not the widespread consequence that “confidence is inapproprate” to filter and rank association rules, but that “an absolute threshold on confidence is inappropriate” to filter and rank association rules. This does not mean that it has to be replaced as a measure of intensity of implication, and, in fact, it has been observed and argued that (at least in somewhat sparse transactional datasets) the combination of support and confidence is already very good at discarding rules that are present only as statistical artifacts and do not really correspond to correlations in the phenomenon at the origin of the dataset [Megiddo and Srikant 1998]; instead, we consider that our message is that it should be complemented with relative confidence thresholds that assess the novelty of each rule by comparison with the confidence of logically (or intuitively) stronger rules. The identification of the precise notion for this task is a clear research issue, to which we have contributed via our two variants of the notion of confidence boost.\nA number of connected approaches to association rule quality exist in the literature. We discuss here those that we have found most closely related; Subsection 7.2 is devoted to the deeper analysis of a particularly close contribution. We finish the paper with a description of forthcoming work."
    }, {
      "heading" : "7.1. Comparisons to Related Work",
      "text" : "We refer to [Geng and Hamilton 2006] for an excellent survey of many options to relate supports of left and right hand sides of association rules to construct indicators of interestingness. Many of these only work on a single rule, with no reference to alternative rules with, say, smaller but otherwise arbitrary left-hand sides. A notable case is lift, which implicitly refers to a rule with the same right-hand side and an empty left-hand side, as discussed in the proof of Proposition 3.4. Compared to this family of measures, confidence boost is finer as it can distinguish among many alternative antecedents to compare, at the price of being potentially more expensive to evaluate due to the search for smaller but arbitrary left-hand sides, and larger but arbitrary right-hand sides. We have shown several algorithms that attempt at circumscribing this search to smaller spaces.\nMore sophisticated interestingness measures are possible, for instance those based on the KL-divergence between probability distributions induced with and without the given rule [Jaroszewicz and Simovici 2002]: the induced distributions satisfy the supports of the rule and of its antecedent but otherwise maximize the entropy. In preliminary tests, our approach, with quite robust settings of confidence (between 0.6 and 0.7) and boost (stardard threshold of 1.2) gives results very close to those in [Jaroszewicz and Simovici 2002].\nSeveral published works attempt at a similar detection of the “exceptionality” or “surprisingness” of rules; many of these work in the relational setting, instead of the transactional setting where our work fits. Relational data can be analysed in the transactional setting by converting a pair given by an attribute name and a value for the attribute into a single item, as we do in the Adult dataset in Table II. Assuming the relational structure of the data, however, brings in the extra power of “implicit negation” of attributes, due to the incompatibility among simultaneous values of the same attribute. This implicit negation is\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nuseful to explain novelty by comparing more specific rules stating a consequent of the form A = V to more general rules stating a consequent of the form A = V ′ for V ′ 6= V , and quite interesting results along this line can be found in [Padmanabhan and Tuzhilin 2000; Suzuki 1997; Suzuki and Kodratoff 1998], among others. Our purely transactional setting (like for the Retail or Now datasets) does not allow us to employ this method of implicit negation and, therefore, such contributions are not directly comparable to ours.\nA few additional contributions that still lie in the transactional setting and are similar to ours are discussed next. The notions of confidence width and rule blocking from [Balcázar 2009] are similar to the “pruning” proposal from [Liu et al. 1999], in that the intuition is the same; also our proposal here follows an analogous intuitive path. Major differences are that, in the proposals we discuss, a large portion of the pruning becomes unnecessary because we work on minimum-size bases, namely representative rules, and, more importantly, that the pruning in [Liu et al. 1999] is based on the χ2 statistic, whereas we will look instead into the confidence thresholds that would make the rule “redundant”, either in a “formal logic” sense or in a more intuitive, but still logical-style relaxation. Our notions are also similar to the notion of improvement, proposed in [Bayardo et al. 1999] and also discussed in [Liu et al. 1999; Webb 2007]; but improvement is a measure of an absolute, additive confidence increase, with no reference to representative rules or redundancy, and it only allows for varying the antecedent into a smaller one, keeping the same consequent."
    }, {
      "heading" : "7.2. Minimum Antecedent and Maximum Consequent",
      "text" : "Many works suggest further notions of redundancy, in most cases based upon mere intuition. The fact that a rule X → XY is redundant with respect to X → XY ′ whenever Y ⊂ Y ′ (in the sense of having at least the same confidence) is pointed out in many places (e.g. [Aggarwal and Yu 2001; Kryszkiewicz 1998b; Phan-Luong 2001; Shah et al. 1999]). Our starting point being the representative basis, we only would keep X → XY if its confidence is higher than that of X → XY ′, by a factor indicated by the confidence boost; this quantification is an effective refinement of that known proposal.\nOn the other hand, redundancy of X → XY with respect to X ′ → X ′Y , where X ′ ⊂ X, is debatable. As we have already discussed in Subsection 2.2, rules X → XY and X ′ → X ′Y , where X ′ ⊂ X, provide different, orthogonal information. Still, one may wish to forget about AB → C if A → C is already present; this seems a natural attitude, and, in fact, explicit proposals of removing the seemingly redundant rule appear in many references, often jointly with the (correct) observation of redundancy due to larger consequents. This happens in the structural cover of [Toivonen et al. 1995], and in some of the pruning rules of [Shah et al. 1999] (which focuses on a slightly different approach since their main measure is actually lift, but, in fact, most of their developments work for confidence as well); and also in [Scheffer 2005]. All these proposals may make sense as heuristics, and their connection to confidence boost is developed below; however, if taken as redundancy statements then they are incorrect and, in some cases, where a precise mathematical statement and its proof are provided (like [Scheffer 2005]), the proof can be seen to switch into a “full implication” meaning of the “arrow” connective, and is actually wrong, therefore, since it does not apply to partial rules. Discarding the apparently weaker rule requires more care and a finer discussion and, actually, the confidence boost provides for this.\nIn fact, without pretending to argue redundancy, one could consider rules with minimal antecedent and maximal consequent simply as an heuristic for handling a large set of mined rules, acting as a sort of summaries of rules with larger antecedents or shorter consequents, or both. As a representative of these proposals, we chose to discuss the approach of [Kryszkiewicz 1998c] which can be casted as follows:\nDefinition 7.1. For a fixed confidence threshold γ and a fixed support threshold τ , the minimal-antecedent, maximal-consequent rules MMRτ,γ are those rules X → XY (with\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nX ∩ Y = ∅) such that c(X → XY ) ≥ γ, s(X → XY ) ≥ τ , and for which the following holds: the only rule X ′ → X ′Y ′ with X ′ ∩ Y ′ = ∅, c(X ′ → X ′Y ′) ≥ γ, s(X → XY ) ≥ τ which satisfies that X ′ ⊆ X and Y ⊆ Y ′, is itself: X = X ′ and Y = Y ′.\nThe following holds [Kryszkiewicz 1998c]:\nProposition 7.2. For a confidence threshold γ and a support threshold τ , all MMRτ,γ rules are representative rules for these thresholds.\nLet us point out that these rules are subtly different from the min-max approximate basis of [Pasquier et al. 2005], given in Definition 2.3, their apparent similarity notwithstanding. There, the closed set forming the whole right-hand side is to be maximal, including the antecedent; here, only the part of the closed set that does not belong to the antecedent is to be maximal. As the antecedent is itself minimal, the notions differ. In a sense, MMR are to min-max rules as confidence boost is to confidence width.\nExample 7.3. In our running example, we find that rule BC → A has confidence γ = 8/9. It is a representative rule at its confidence threshold γ = 8/9, hence it is a min-max rule by Proposition 2.5; but it is not in MMRτ,γ since c(B → A) = 10/11 > γ. This example also proves that the converse of Proposition 7.2 does not hold.\nAs discussed in depth in Subsection 2.2, we must be aware that MMR’s may lose information, since rules that have nonminimal antecedents may be actually irredundant and potentially interesting. Our main proposal in this paper, confidence boost, can be interpreted as a quantitative variant of MMR’s, whereby nonminimal antecedents or nonmaximal consequents are likely to be considered not novel (and conversely), yet this connection depends on how well the rule clears the confidence and support thresholds. More precisely:\nProposition 7.4. Fix support and confidence thresholds τ and γ. (1 ) If X → Y is a MMRτ,γ rule, then β(X → Y ) ≥ min ( s(X→Y ) τ , c(X→Y ) γ ) . (2 ) If X → Y is not a MMRτ,γ rule, then β(X → Y ) ≤ c(X→Y )γ .\nProof.\n(1) Consider an MMRτ,γ rule X → Y . Any different rule X ′ → Y ′ with X ′ ⊆ X and Y ⊆ Y ′ must fail either the support threshold τ or the confidence threshold γ. First we show that, for such a rule, c(X ′ → Y ′) ≤ max( τs(X) , γ), considering two cases. Assume X ′ 6= X, and consider rule X ′ → Y , which is also different from X → Y . We have s(X ′Y ) ≥ s(XY ) > τ so that it must fail the confidence threshold; hence, c(X ′ → Y ′) ≤ c(X ′ → Y ) < γ ≤ max( τs(X) , γ). Assume now X\n′ = X: either c(X ′ → Y ′) < γ, or X ′ → Y ′ fails the support threshold, s(X ′Y ′) = s(XY ′) ≤ τ , whence c(X ′ → Y ′) = s(X\n′Y ′) s(X′) ≤ τ s(X′) = τ s(X) ; thus c(X ′ → Y ′) ≤ max( τs(X) , γ) again. Now we can bound the confidence boost easily: any rule considered for the maximization in the denominator of the definition of confidence boost has confidence at most max( τs(X) , γ), and there are finitely many of them, so that the denominator itself\nobeys the same bound, which implies that β(X → Y ) ≥ min ( c(X→Y )\nτ s(X)\n, c(X→Y )γ\n) =\nmin ( s(X→Y )\nτ , c(X→Y ) γ\n) .\n(2) This part is quite simple. If X → Y is not an MMRτ,γ rule, then there must exist some different rule X ′ → Y ′ with X ′ ⊆ X and Y ⊆ Y ′ passing the support and confidence thresholds; this rule enters the maximization in the denominator of the\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\ndefinition of confidence boost, which is, then, at least γ, resulting in a confidence boost β(X → Y ) ≤ c(X→Y )γ .\nThat is: a rule that is not an MMRτ,γ rule, and barely clears the confidence threshold γ, can be appropriately pruned as not novel due to low boost; but, if its confidence is much higher than the threshold, even if it is not MMR, it may exhibit enough novelty to make it debatable whether it must be pruned off the output. Conversely, an MMRτ,γ rule that clears barely the support and confidence thresholds may turn out to be of low confidence boost, and it could be better to omit it from the output. Essentially, the same purpose is attempted by both approaches but confidence boost bounds offers a quantitative evaluation of the extent to which representative rules are appropriate as rules to choose for the output of the mining process: they will often coincide with the MMRτ,γ but these will be occassionally inadequate."
    }, {
      "heading" : "7.3. Further Work",
      "text" : "Of course, the use of confidence boost does not preclude a combination with lift or any other measure of intensity of implication; to what extent these separate measures interact with confidence boost, and which ones perform best, is one among many open lines of future research.\nIndeed, whatever method is proposed to reduce the output of an association miner leaves a major doubt: are these the rules one really wants? We plan to continue working on this rather subjective issue, and intend to employ further actual end-user evaluations from dataset providers, as we have started to do with respect to partial aspects. We are working on datasets coming from an e-learning platform, for which we have a manually recorded labeling of the interest of each rule, provided by the dataset suppliers, namely, the teachers of the courses where the datasets originated, who are also available for consultation. The particular characteristics of this dataset require us first to extend our approach into handling both presence and absence of each item [Balcázar et al. 2010a; 2010b]. Also, sometimes, some of the full-confidence implications would be desirable indeed for inclusion in the output, given that working on the basis B? leaves them fully out; however, it is unclear whether confidence boost would still be the right notion, and, even so, full-confidence implications require to compute the minimal generators of each closure, therefore losing the desirable advantage offered by closure-based confidence boost operating on top of B? rules, which can be computed much faster since they only use the closures lattice. We continue to investigate this problem, and some partial progress, on which we still hope to improve, is reported in [Balcázar et al. 2010b].\nThe yacaree tool has many developments open to further work. First, since we mine frequent closures in descending support, instead of ascending, some of the optimizations in ChARM require further work before being readily applicable; also, the best algorithm in [Baixeries et al. 2009] (namely iPred) to compute Hasse edges is not applied, as it assumes a cardinality-ordered traversal of the closed sets instead of a support-oriented one; the theorems that guarantee its applicability have been obtained only recently, and a forthcoming version of yacaree will sport this faster algorithm, iPred. Also, it seems possible that a smarter coupling of the miner with the lattice computation might provide further accelerations. On the other hand, from the point of view of the user, and beyond efficiency improvement considerations, a few alternative internal configurations of the parameters might reveal themselves useful, provided one can hit with intuitive descriptions that make them clearly understandable by nonexperts: indeed, whereas the user is grateful for being able to run the program with no parameter selection, yacaree is not snake oil, and it is likely that, for certain datesets, and after seeing the result, the user may be tempted to “try again” in some alternative way.\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nHence, we will work next on improving the speed of the system, on finding sensible ways of reporting interesting full-confidence implications without paying too much as a time overhead, and on developing interactions with end users to study their evaluations of the generated sets of rules, possibly leading thus to further refinements of the confidence boost notion and of any other aspect that might be considered. In the meantime, researchers interested in conducting their own evaluation can download the system freely and analyze the output of confidence-boost-bounded mining on their datasets; this author would be grateful to be informed of the results."
    } ],
    "references" : [ {
      "title" : "A new approach to online generation of association rules",
      "author" : [ "C.C. Aggarwal", "P.S. Yu" ],
      "venue" : "IEEE Transactions on Knowledge and Data Engineering 13, 4, 527–540.",
      "citeRegEx" : "Aggarwal and Yu,? 2001",
      "shortCiteRegEx" : "Aggarwal and Yu",
      "year" : 2001
    }, {
      "title" : "Fast discovery of association rules",
      "author" : [ "R. Agrawal", "H. Mannila", "R. Srikant", "H. Toivonen", "A.I. Verkamo" ],
      "venue" : "Advances in Knowledge Discovery and Data Mining. AAAI/MIT Press, 307–328.",
      "citeRegEx" : "Agrawal et al\\.,? 1996",
      "shortCiteRegEx" : "Agrawal et al\\.",
      "year" : 1996
    }, {
      "title" : "Yet a faster algorithm for building the Hasse diagram of a concept lattice",
      "author" : [ "J. Baixeries", "L. Szathmary", "P. Valtchev", "R. Godin" ],
      "venue" : "Proc. of the 7th International Conference on Formal Concept Analysis (ICFCA), S. Ferré and S. Rudolph, Eds. Lecture Notes in Artificial Intelligence Series, vol. 5548. Springer-Verlag, 162–177.",
      "citeRegEx" : "Baixeries et al\\.,? 2009",
      "shortCiteRegEx" : "Baixeries et al\\.",
      "year" : 2009
    }, {
      "title" : "Two measures of objective novelty in association rule mining",
      "author" : [ "J.L. Balcázar" ],
      "venue" : "PAKDD Workshops (Springer-Verlag LNCS 5669). 76–98.",
      "citeRegEx" : "Balcázar,? 2009",
      "shortCiteRegEx" : "Balcázar",
      "year" : 2009
    }, {
      "title" : "Closure-based confidence boost in association rules",
      "author" : [ "J.L. Balcázar" ],
      "venue" : "JMLR Workshop and Conference Proceedings – Workshop on Applications of Pattern Analysis 11, 1–7.",
      "citeRegEx" : "Balcázar,? 2010a",
      "shortCiteRegEx" : "Balcázar",
      "year" : 2010
    }, {
      "title" : "Objective novelty of association rules: Measuring the confidence boost",
      "author" : [ "J.L. Balcázar" ],
      "venue" : "EGC, S. B. Yahia and J.-M. Petit, Eds. Revue des Nouvelles Technologies de l’Information Series, vol. RNTIE-19. Cépaduès-Éditions, 297–302.",
      "citeRegEx" : "Balcázar,? 2010b",
      "shortCiteRegEx" : "Balcázar",
      "year" : 2010
    }, {
      "title" : "Redundancy, deduction schemes, and minimum-size bases for association rules",
      "author" : [ "J.L. Balcázar" ],
      "venue" : "Logical Methods in Computer Science 6, 2:3, 1–33.",
      "citeRegEx" : "Balcázar,? 2010c",
      "shortCiteRegEx" : "Balcázar",
      "year" : 2010
    }, {
      "title" : "Parameter-free association rule mining with yacaree",
      "author" : [ "J.L. Balcázar" ],
      "venue" : "See Khenchaf and Poncelet",
      "citeRegEx" : "Balcázar,? 2011",
      "shortCiteRegEx" : "Balcázar",
      "year" : 2011
    }, {
      "title" : "Closed-set-based discovery of representative association rules revisited",
      "author" : [ "J.L. Balcázar", "C. T̂ırnăucă" ],
      "venue" : "See Khenchaf and Poncelet",
      "citeRegEx" : "Balcázar and T̂ırnăucă,? \\Q2011\\E",
      "shortCiteRegEx" : "Balcázar and T̂ırnăucă",
      "year" : 2011
    }, {
      "title" : "Mining educational data for patterns with negations and high confidence boost",
      "author" : [ "J.L. Balcázar", "C. T̂ırnăucă", "M. Zorrilla" ],
      "venue" : "Taller de Mineŕıa de Datos TAMIDA",
      "citeRegEx" : "Balcázar et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Balcázar et al\\.",
      "year" : 2010
    }, {
      "title" : "Filtering association rules with negations on the basis of their confidence boost",
      "author" : [ "J.L. Balcázar", "C. T̂ırnăucă", "M.E. Zorrilla" ],
      "venue" : "KDIR",
      "citeRegEx" : "Balcázar et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Balcázar et al\\.",
      "year" : 2010
    }, {
      "title" : "Constraint-based rule mining in large, dense databases",
      "author" : [ "R. Bayardo", "R. Agrawal", "D. Gunopulos" ],
      "venue" : "ICDE. 188–197.",
      "citeRegEx" : "Bayardo et al\\.,? 1999",
      "shortCiteRegEx" : "Bayardo et al\\.",
      "year" : 1999
    }, {
      "title" : "Free-sets: A condensed representation of boolean data for the approximation of frequency queries",
      "author" : [ "Boulicaut", "J.-F.", "A. Bykowski", "C. Rigotti" ],
      "venue" : "Data Min. Knowl. Discov. 7, 1, 5–22.",
      "citeRegEx" : "Boulicaut et al\\.,? 2003",
      "shortCiteRegEx" : "Boulicaut et al\\.",
      "year" : 2003
    }, {
      "title" : "Neogene of the old world database of fossil mammals (NOW)",
      "author" : [ "M. Fortelius" ],
      "venue" : "University of Helsinki, 2003, [http://www.helsinki.fi/science/now].",
      "citeRegEx" : "Fortelius,? 2003",
      "shortCiteRegEx" : "Fortelius",
      "year" : 2003
    }, {
      "title" : "Mini: Mining informative non-redundant itemsets",
      "author" : [ "A. Gallo", "T. De Bie", "N. Cristianini" ],
      "venue" : "PKDD, J. N. Kok, J. Koronacki, R. L. de Mántaras, S. Matwin, D. Mladenic, and A. Skowron, Eds. Lecture Notes in Computer Science Series, vol. 4702. Springer, 438–445.",
      "citeRegEx" : "Gallo et al\\.,? 2007",
      "shortCiteRegEx" : "Gallo et al\\.",
      "year" : 2007
    }, {
      "title" : "Interestingness measures for data mining: A survey",
      "author" : [ "L. Geng", "H.J. Hamilton" ],
      "venue" : "ACM Comput. Surv. 38, 3.",
      "citeRegEx" : "Geng and Hamilton,? 2006",
      "shortCiteRegEx" : "Geng and Hamilton",
      "year" : 2006
    }, {
      "title" : "Familles minimales d’implications informatives résultant d’un tableau de données binaires",
      "author" : [ "J. Guigues", "V. Duquenne" ],
      "venue" : "Mathématiques et Sciences Humaines 95, 5–18.",
      "citeRegEx" : "Guigues and Duquenne,? 1986",
      "shortCiteRegEx" : "Guigues and Duquenne",
      "year" : 1986
    }, {
      "title" : "Pruning redundant association rules using maximum entropy principle",
      "author" : [ "S. Jaroszewicz", "D. Simovici" ],
      "venue" : "Proc. of the 6th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD). Lecture Notes in Artificial Intelligence. Springer-Verlag, 135–147.",
      "citeRegEx" : "Jaroszewicz and Simovici,? 2002",
      "shortCiteRegEx" : "Jaroszewicz and Simovici",
      "year" : 2002
    }, {
      "title" : "Actes de Extraction et gestion des connaissances (EGC)",
      "author" : [ "A. Khenchaf", "P. Poncelet", "Eds." ],
      "venue" : "Revue des Nouvelles Technologies de l’Information Series, vol. E.20. Hermann.",
      "citeRegEx" : "Khenchaf et al\\.,? 2011",
      "shortCiteRegEx" : "Khenchaf et al\\.",
      "year" : 2011
    }, {
      "title" : "Fast discovery of representative association rules",
      "author" : [ "M. Kryszkiewicz" ],
      "venue" : "Proc. of the 1st International Conference on Rough Sets and Current Trends in Computing (RSCTC), L. Polkowski and A. Skowron, Eds. Lecture Notes in Artificial Intelligence Series, vol. 1424. Springer-Verlag, 214–221.",
      "citeRegEx" : "Kryszkiewicz,? 1998a",
      "shortCiteRegEx" : "Kryszkiewicz",
      "year" : 1998
    }, {
      "title" : "Representative association rules",
      "author" : [ "M. Kryszkiewicz" ],
      "venue" : "Proc. of the 2nd Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD), X. Wu, K. Ramamohanarao, and K. B. Korb, Eds. Lecture Notes in Artificial Intelligence Series, vol. 1394. Springer-Verlag, 198–209.",
      "citeRegEx" : "Kryszkiewicz,? 1998b",
      "shortCiteRegEx" : "Kryszkiewicz",
      "year" : 1998
    }, {
      "title" : "Representative association rules and minimum condition maximum consequence association rules",
      "author" : [ "M. Kryszkiewicz" ],
      "venue" : "See Zytkow and Quafafou [1998], 361–369.",
      "citeRegEx" : "Kryszkiewicz,? 1998c",
      "shortCiteRegEx" : "Kryszkiewicz",
      "year" : 1998
    }, {
      "title" : "Closed set based discovery of representative association rules",
      "author" : [ "M. Kryszkiewicz" ],
      "venue" : "Proc. of the 4th International Symposium on Intelligent Data Analysis (IDA), F. Hoffmann, D. J. Hand, N. M. Adams, D. H. Fisher, and G. Guimarães, Eds. Lecture Notes in Computer Science Series, vol. 2189. Springer-Verlag, 350–359.",
      "citeRegEx" : "Kryszkiewicz,? 2001",
      "shortCiteRegEx" : "Kryszkiewicz",
      "year" : 2001
    }, {
      "title" : "Concise representations of association rules",
      "author" : [ "M. Kryszkiewicz" ],
      "venue" : "Proc. of the ESF Exploratory Workshop on Pattern Detection and Discovery, D. J. Hand, N. M. Adams, and R. J. Bolton, Eds. Lecture Notes in Computer Science Series, vol. 2447. Springer-Verlag, 92–109.",
      "citeRegEx" : "Kryszkiewicz,? 2002",
      "shortCiteRegEx" : "Kryszkiewicz",
      "year" : 2002
    }, {
      "title" : "On selecting interestingness measures for association rules: User oriented description and multiple criteria decision aid",
      "author" : [ "P. Lenca", "P. Meyer", "B. Vaillant", "S. Lallich" ],
      "venue" : "European Journal of Operational Research 184, 2, 610–626.",
      "citeRegEx" : "Lenca et al\\.,? 2008",
      "shortCiteRegEx" : "Lenca et al\\.",
      "year" : 2008
    }, {
      "title" : "Pruning and summarizing the discovered associations",
      "author" : [ "B. Liu", "W. Hsu", "Y. Ma" ],
      "venue" : "Proc. Knowledge Discovery in Databases. 125–134.",
      "citeRegEx" : "Liu et al\\.,? 1999",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 1999
    }, {
      "title" : "Implications partielles dans un contexte",
      "author" : [ "M. Luxenburger" ],
      "venue" : "Mathématiques et Sciences Humaines 29, 35–55.",
      "citeRegEx" : "Luxenburger,? 1991",
      "shortCiteRegEx" : "Luxenburger",
      "year" : 1991
    }, {
      "title" : "Discovering predictive association rules",
      "author" : [ "N. Megiddo", "R. Srikant" ],
      "venue" : "Proc. Knowledge Discovery in Databases. 274–278.",
      "citeRegEx" : "Megiddo and Srikant,? 1998",
      "shortCiteRegEx" : "Megiddo and Srikant",
      "year" : 1998
    }, {
      "title" : "Small is beautiful: discovering the minimal set of unexpected patterns",
      "author" : [ "B. Padmanabhan", "A. Tuzhilin" ],
      "venue" : "Proc. Knowledge Discovery in Databases. 54–63.",
      "citeRegEx" : "Padmanabhan and Tuzhilin,? 2000",
      "shortCiteRegEx" : "Padmanabhan and Tuzhilin",
      "year" : 2000
    }, {
      "title" : "Generating a condensed representation for association rules",
      "author" : [ "N. Pasquier", "R. Taouil", "Y. Bastide", "G. Stumme", "L. Lakhal" ],
      "venue" : "J. Intell. Inf. Syst. 24, 1, 29–60.",
      "citeRegEx" : "Pasquier et al\\.,? 2005",
      "shortCiteRegEx" : "Pasquier et al\\.",
      "year" : 2005
    }, {
      "title" : "The representative basis for association rules",
      "author" : [ "V. Phan-Luong" ],
      "venue" : "Proc. of the 2001 IEEE International Conference on Data Mining (ICDM), N. Cercone, T. Y. Lin, and X. Wu, Eds. IEEE Computer Society, 639–640.",
      "citeRegEx" : "Phan.Luong,? 2001",
      "shortCiteRegEx" : "Phan.Luong",
      "year" : 2001
    }, {
      "title" : "Discovery, analysis, and presentation of strong rules",
      "author" : [ "G. Piatetsky-Shapiro" ],
      "venue" : "Proc. Knowledge Discovery in Databases. 229–248.",
      "citeRegEx" : "Piatetsky.Shapiro,? 1991",
      "shortCiteRegEx" : "Piatetsky.Shapiro",
      "year" : 1991
    }, {
      "title" : "Finding association rules that trade support optimally against confidence",
      "author" : [ "T. Scheffer" ],
      "venue" : "Intelligent Data Analysis 9, 293–313.",
      "citeRegEx" : "Scheffer,? 2005",
      "shortCiteRegEx" : "Scheffer",
      "year" : 2005
    }, {
      "title" : "Interestingness and pruning of mined patterns",
      "author" : [ "D. Shah", "L. Lakshmanan", "K. Ramamritham", "S. Sudarshan" ],
      "venue" : "ACM SIGMOD Workshop on Research Issues in Data Mining and Knowledge Discovery.",
      "citeRegEx" : "Shah et al\\.,? 1999",
      "shortCiteRegEx" : "Shah et al\\.",
      "year" : 1999
    }, {
      "title" : "Beyond market baskets: Generalizing association rules to dependence rules",
      "author" : [ "C. Silverstein", "S. Brin", "R. Motwani" ],
      "venue" : "Data Min. Knowl. Discov. 2, 1, 39–68.",
      "citeRegEx" : "Silverstein et al\\.,? 1998",
      "shortCiteRegEx" : "Silverstein et al\\.",
      "year" : 1998
    }, {
      "title" : "Autonomous discovery of reliable exception rules",
      "author" : [ "E. Suzuki" ],
      "venue" : "Proc. Knowledge Discovery in Databases.",
      "citeRegEx" : "Suzuki,? 1997",
      "shortCiteRegEx" : "Suzuki",
      "year" : 1997
    }, {
      "title" : "Discovery of surprising exception rules based on intensity of implication",
      "author" : [ "E. Suzuki", "Y. Kodratoff" ],
      "venue" : "See Zytkow and Quafafou [1998].",
      "citeRegEx" : "Suzuki and Kodratoff,? 1998",
      "shortCiteRegEx" : "Suzuki and Kodratoff",
      "year" : 1998
    }, {
      "title" : "Selecting the right objective measure for association analysis",
      "author" : [ "Tan", "P.-N.", "V. Kumar", "J. Srivastava" ],
      "venue" : "Information Systems 29, 4, 293–313.",
      "citeRegEx" : "Tan et al\\.,? 2004",
      "shortCiteRegEx" : "Tan et al\\.",
      "year" : 2004
    }, {
      "title" : "Pruning and grouping discovered association rules",
      "author" : [ "H. Toivonen", "M. Klemettinen", "P. Ronkainen", "K. Hätönen", "H. Mannila" ],
      "venue" : "ECML-95 Workshop on Statistics, Machine Learning, and Knowledge Discovery in Databases. 47–52.",
      "citeRegEx" : "Toivonen et al\\.,? 1995",
      "shortCiteRegEx" : "Toivonen et al\\.",
      "year" : 1995
    }, {
      "title" : "Discovering significant patterns",
      "author" : [ "G.I. Webb" ],
      "venue" : "Machine Learning 68, 1, 1–33.",
      "citeRegEx" : "Webb,? 2007",
      "shortCiteRegEx" : "Webb",
      "year" : 2007
    }, {
      "title" : "Data Mining: Practical Machine Learning Tools and Techniques (2ed)",
      "author" : [ "I.H. Witten", "E. Frank" ],
      "venue" : "Morgan Kaufmann.",
      "citeRegEx" : "Witten and Frank,? 2005",
      "shortCiteRegEx" : "Witten and Frank",
      "year" : 2005
    }, {
      "title" : "Mining non-redundant association rules",
      "author" : [ "M.J. Zaki" ],
      "venue" : "Data Min. Knowl. Discov. 9, 3, 223–248.",
      "citeRegEx" : "Zaki,? 2004",
      "shortCiteRegEx" : "Zaki",
      "year" : 2004
    }, {
      "title" : "Efficient algorithms for mining closed itemsets and their lattice structure",
      "author" : [ "M.J. Zaki", "Hsiao", "C.-J." ],
      "venue" : "IEEE Transactions on Knowledge and Data Engineering 17, 4, 462–478.",
      "citeRegEx" : "Zaki et al\\.,? 2005",
      "shortCiteRegEx" : "Zaki et al\\.",
      "year" : 2005
    }, {
      "title" : "Principles of Data Mining and Knowledge Discovery, Second European Symposium, PKDD ’98, Nantes, France, September 23-26, 1998, Proceedings",
      "author" : [ "J.M. Zytkow", "M. Quafafou", "Eds." ],
      "venue" : "Lecture Notes in Computer Science Series, vol. 1510. Springer.",
      "citeRegEx" : "Zytkow et al\\.,? 1998",
      "shortCiteRegEx" : "Zytkow et al\\.",
      "year" : 1998
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "The introduction of a support threshold parameter was a key advance that allowed for the design of efficient frequent set miners and for the computation of association rules in large datasets: there, exploration is limited to those itemsets that appear “often enough” as subsets of the transactions, that is, their relative frequency exceeds a certain ratio of the transactions; see [Agrawal et al. 1996] and the references there.",
      "startOffset" : 383,
      "endOffset" : 404
    }, {
      "referenceID" : 1,
      "context" : "The proposal in [Agrawal et al. 1996] (and already in the early [Luxenburger 1991] where, however, the support bound proposal does not appear) is to impose upon association rules X → Y a confidence constraint, that is, a threshold on the conditional probability of Y conditioned to X.",
      "startOffset" : 16,
      "endOffset" : 37
    }, {
      "referenceID" : 26,
      "context" : "1996] (and already in the early [Luxenburger 1991] where, however, the support bound proposal does not appear) is to impose upon association rules X → Y a confidence constraint, that is, a threshold on the conditional probability of Y conditioned to X.",
      "startOffset" : 32,
      "endOffset" : 50
    }, {
      "referenceID" : 0,
      "context" : "This leads to minimum-size bases, such as the Representative (or Essential) Rules [Aggarwal and Yu 2001; Kryszkiewicz 1998b] for plain redundancy or the basis B γ [Balcázar 2010c] for closure-based redundancy, at confidence threshold γ, that spares the computation of minimal generators needed by the Representative Rules, but needs to be complemented with a basis for full implications.",
      "startOffset" : 82,
      "endOffset" : 124
    }, {
      "referenceID" : 20,
      "context" : "This leads to minimum-size bases, such as the Representative (or Essential) Rules [Aggarwal and Yu 2001; Kryszkiewicz 1998b] for plain redundancy or the basis B γ [Balcázar 2010c] for closure-based redundancy, at confidence threshold γ, that spares the computation of minimal generators needed by the Representative Rules, but needs to be complemented with a basis for full implications.",
      "startOffset" : 82,
      "endOffset" : 124
    }, {
      "referenceID" : 6,
      "context" : "This leads to minimum-size bases, such as the Representative (or Essential) Rules [Aggarwal and Yu 2001; Kryszkiewicz 1998b] for plain redundancy or the basis B γ [Balcázar 2010c] for closure-based redundancy, at confidence threshold γ, that spares the computation of minimal generators needed by the Representative Rules, but needs to be complemented with a basis for full implications.",
      "startOffset" : 163,
      "endOffset" : 179
    }, {
      "referenceID" : 6,
      "context" : "All these questions are thoroughly surveyed in [Balcázar 2010c].",
      "startOffset" : 47,
      "endOffset" : 63
    }, {
      "referenceID" : 15,
      "context" : "But even taking redundancies into account, the results are, in many cases, unsatisfactory; therefore, many alternative quality measures exist for association rules, essentially due to the facts that, first, the confidence of a rule X → Y can be high even in cases where the actual correlation between X and Y is negative, and, second, it is often extremely difficult to settle for thresholds where interesting rules are kept but the total amount of rules can be handled; see [Geng and Hamilton 2006; Lenca et al. 2008; Tan et al. 2004] and their references for information about the rich research area opened up by these difficulties.",
      "startOffset" : 475,
      "endOffset" : 535
    }, {
      "referenceID" : 24,
      "context" : "But even taking redundancies into account, the results are, in many cases, unsatisfactory; therefore, many alternative quality measures exist for association rules, essentially due to the facts that, first, the confidence of a rule X → Y can be high even in cases where the actual correlation between X and Y is negative, and, second, it is often extremely difficult to settle for thresholds where interesting rules are kept but the total amount of rules can be handled; see [Geng and Hamilton 2006; Lenca et al. 2008; Tan et al. 2004] and their references for information about the rich research area opened up by these difficulties.",
      "startOffset" : 475,
      "endOffset" : 535
    }, {
      "referenceID" : 37,
      "context" : "But even taking redundancies into account, the results are, in many cases, unsatisfactory; therefore, many alternative quality measures exist for association rules, essentially due to the facts that, first, the confidence of a rule X → Y can be high even in cases where the actual correlation between X and Y is negative, and, second, it is often extremely difficult to settle for thresholds where interesting rules are kept but the total amount of rules can be handled; see [Geng and Hamilton 2006; Lenca et al. 2008; Tan et al. 2004] and their references for information about the rich research area opened up by these difficulties.",
      "startOffset" : 475,
      "endOffset" : 535
    }, {
      "referenceID" : 28,
      "context" : "[Padmanabhan and Tuzhilin 2000] and the references therein).",
      "startOffset" : 0,
      "endOffset" : 31
    }, {
      "referenceID" : 3,
      "context" : "However, as one very partial and probably insufficient, but necessary action, we claim that, as a minimum, each rule should be evaluated for novelty by comparison with the rest of the rules mined, treated as “alternative” mechanism [Balcázar 2009].",
      "startOffset" : 232,
      "endOffset" : 247
    }, {
      "referenceID" : 11,
      "context" : "Otherwise, it would not be novel, the simpler rule should be preferred, and even the complex rule discarded (or blocked), all depending on thresholds on confidence and on some other parameter such as improvement [Bayardo et al. 1999], blocking factor, or confidence boost (to be introduced here).",
      "startOffset" : 212,
      "endOffset" : 233
    }, {
      "referenceID" : 3,
      "context" : "It was empirically demonstrated in [Balcázar 2009] that better results were obtained using both a confidence width threshold and a blocking threshold, than using a single one of these filters (or none).",
      "startOffset" : 35,
      "endOffset" : 50
    }, {
      "referenceID" : 3,
      "context" : "Thus, our contribution here is a new attempt at formalizing the notion of novelty, the confidence boost, similar in its syntactic definition to confidence width, but different in its semantics, which is more restrictive; its main feature is that it encompasses at once both the bound on the confidence width and the ability to detect that a rule would be blocked, so that the confidence boost bound embodies both of the bounds proposed in [Balcázar 2009], yet it is computable with reasonable efficiency.",
      "startOffset" : 439,
      "endOffset" : 454
    }, {
      "referenceID" : 5,
      "context" : "Three short extended abstracts of three, six, and seven pages respectively have announced results from this paper in scientific meetings; reference [Balcázar 2010b] contains the definition of confidence boost, fragments of Section 2 (where we also review a small number of necessary facts from [Balcázar 2010c]), part of Section 3 (the definition of confidence boost), and the algorithm in Subsection 3.",
      "startOffset" : 148,
      "endOffset" : 164
    }, {
      "referenceID" : 6,
      "context" : "Three short extended abstracts of three, six, and seven pages respectively have announced results from this paper in scientific meetings; reference [Balcázar 2010b] contains the definition of confidence boost, fragments of Section 2 (where we also review a small number of necessary facts from [Balcázar 2010c]), part of Section 3 (the definition of confidence boost), and the algorithm in Subsection 3.",
      "startOffset" : 294,
      "endOffset" : 310
    }, {
      "referenceID" : 4,
      "context" : "Reference [Balcázar 2010a] contains the definition of closure-based confidence boost and part of the materials in Section 4, again including the main algorithm but not its correctness proof, as well as materials from Subsection 5.",
      "startOffset" : 10,
      "endOffset" : 26
    }, {
      "referenceID" : 7,
      "context" : "The tool yacaree which embodies closure-based confidence boost into a parameter-free association miner (Section 6) was advertised at [Balcázar 2011] (demo track).",
      "startOffset" : 133,
      "endOffset" : 148
    }, {
      "referenceID" : 1,
      "context" : "In the proposal of [Agrawal et al. 1996], association rules are restricted to |Y | = 1.",
      "startOffset" : 19,
      "endOffset" : 40
    }, {
      "referenceID" : 12,
      "context" : "[Boulicaut et al. 2003; Zaki 2004] for further information.",
      "startOffset" : 0,
      "endOffset" : 34
    }, {
      "referenceID" : 41,
      "context" : "[Boulicaut et al. 2003; Zaki 2004] for further information.",
      "startOffset" : 0,
      "endOffset" : 34
    }, {
      "referenceID" : 26,
      "context" : "In the early proposal [Luxenburger 1991], a rule is redundant if its confidence can be computed from that of other rules.",
      "startOffset" : 22,
      "endOffset" : 40
    }, {
      "referenceID" : 23,
      "context" : "several concise representations and redundancy notions in [Kryszkiewicz 2002].",
      "startOffset" : 58,
      "endOffset" : 77
    }, {
      "referenceID" : 29,
      "context" : "In [Pasquier et al. 2005] (and in earlier conference versions of their work) the following set of rules is shown to be sufficient to compute the confidence and support of any given partial rule:",
      "startOffset" : 3,
      "endOffset" : 25
    }, {
      "referenceID" : 41,
      "context" : "Similar notions of redundancy are studied in [Zaki 2004], where, however, the approximate bases are constructed as rules having minimal generators both at the left- and at the righthand sides.",
      "startOffset" : 45,
      "endOffset" : 56
    }, {
      "referenceID" : 0,
      "context" : "The notions come, essentially, from [Aggarwal and Yu 2001; Kryszkiewicz 1998b].",
      "startOffset" : 36,
      "endOffset" : 78
    }, {
      "referenceID" : 20,
      "context" : "The notions come, essentially, from [Aggarwal and Yu 2001; Kryszkiewicz 1998b].",
      "startOffset" : 36,
      "endOffset" : 78
    }, {
      "referenceID" : 0,
      "context" : "For a fixed confidence threshold, those rules that reach it, and are not made redundant by other rules also above the threshold, form the representative (or essential) rule basis for that confidence threshold [Aggarwal and Yu 2001; Kryszkiewicz 1998b; Phan-Luong 2001]; that is, every rule that reaches the confidence threshold is either in the corresponding representative basis, or made redundant by a rule in the basis.",
      "startOffset" : 209,
      "endOffset" : 268
    }, {
      "referenceID" : 20,
      "context" : "For a fixed confidence threshold, those rules that reach it, and are not made redundant by other rules also above the threshold, form the representative (or essential) rule basis for that confidence threshold [Aggarwal and Yu 2001; Kryszkiewicz 1998b; Phan-Luong 2001]; that is, every rule that reaches the confidence threshold is either in the corresponding representative basis, or made redundant by a rule in the basis.",
      "startOffset" : 209,
      "endOffset" : 268
    }, {
      "referenceID" : 30,
      "context" : "For a fixed confidence threshold, those rules that reach it, and are not made redundant by other rules also above the threshold, form the representative (or essential) rule basis for that confidence threshold [Aggarwal and Yu 2001; Kryszkiewicz 1998b; Phan-Luong 2001]; that is, every rule that reaches the confidence threshold is either in the corresponding representative basis, or made redundant by a rule in the basis.",
      "startOffset" : 209,
      "endOffset" : 268
    }, {
      "referenceID" : 0,
      "context" : "4 is easy to see and was already pointed out in [Aggarwal and Yu 2001; Kryszkiewicz 1998b; Phan-Luong 2001] (in somewhat different terms).",
      "startOffset" : 48,
      "endOffset" : 107
    }, {
      "referenceID" : 20,
      "context" : "4 is easy to see and was already pointed out in [Aggarwal and Yu 2001; Kryszkiewicz 1998b; Phan-Luong 2001] (in somewhat different terms).",
      "startOffset" : 48,
      "endOffset" : 107
    }, {
      "referenceID" : 30,
      "context" : "4 is easy to see and was already pointed out in [Aggarwal and Yu 2001; Kryszkiewicz 1998b; Phan-Luong 2001] (in somewhat different terms).",
      "startOffset" : 48,
      "endOffset" : 107
    }, {
      "referenceID" : 6,
      "context" : "The converse implication is nontrivial and much more recently shown [Balcázar 2010c]; see this reference as well for the proof that the representative basis has the minimum possible size among all bases for this notion of redundancy, and for discussions of other related redundancy notions.",
      "startOffset" : 68,
      "endOffset" : 84
    }, {
      "referenceID" : 19,
      "context" : "The implication from (1) to (2) is from [Kryszkiewicz 1998a] (see also [Kryszkiewicz 2001] for a clearer notation): if X → XY is a representative rule then s(X) < s(X ′) for all X ′ ⊂ X, and s(Z) < s(XY ) for all Z with XY ⊂ Z; that is, X is a minimal generator and XY is closed.",
      "startOffset" : 40,
      "endOffset" : 60
    }, {
      "referenceID" : 22,
      "context" : "The implication from (1) to (2) is from [Kryszkiewicz 1998a] (see also [Kryszkiewicz 2001] for a clearer notation): if X → XY is a representative rule then s(X) < s(X ′) for all X ′ ⊂ X, and s(Z) < s(XY ) for all Z with XY ⊂ Z; that is, X is a minimal generator and XY is closed.",
      "startOffset" : 71,
      "endOffset" : 90
    }, {
      "referenceID" : 3,
      "context" : "In [Balcázar 2009], the intuition of redundancy is pushed further in order to gain a perspective of novelty of association rules.",
      "startOffset" : 3,
      "endOffset" : 18
    }, {
      "referenceID" : 3,
      "context" : "It is proved in [Balcázar 2009] that, in Definition 2.",
      "startOffset" : 16,
      "endOffset" : 31
    }, {
      "referenceID" : 3,
      "context" : "In [Balcázar 2009], some intuitions are described that suggest that, for a confidence threshold γ, a natural choice could be to set the confidence width threshold at 2− γ; however, so far no formal support for this proposal (or any other proposal, for that matter) is known.",
      "startOffset" : 3,
      "endOffset" : 18
    }, {
      "referenceID" : 11,
      "context" : "[Bayardo et al. 1999; Liu et al. 1999; Padmanabhan and Tuzhilin 2000; Shah et al. 1999; Toivonen et al. 1995] just to name a few), [Balcázar 2009] proposes also a notion of “rule blocking”, whereby a subset of the antecedent may “block” an association rule, that is, forbid its being provided in the output, if the confidence of the rule with the smaller antecedent and the same consequent is higher enough.",
      "startOffset" : 0,
      "endOffset" : 109
    }, {
      "referenceID" : 25,
      "context" : "[Bayardo et al. 1999; Liu et al. 1999; Padmanabhan and Tuzhilin 2000; Shah et al. 1999; Toivonen et al. 1995] just to name a few), [Balcázar 2009] proposes also a notion of “rule blocking”, whereby a subset of the antecedent may “block” an association rule, that is, forbid its being provided in the output, if the confidence of the rule with the smaller antecedent and the same consequent is higher enough.",
      "startOffset" : 0,
      "endOffset" : 109
    }, {
      "referenceID" : 28,
      "context" : "[Bayardo et al. 1999; Liu et al. 1999; Padmanabhan and Tuzhilin 2000; Shah et al. 1999; Toivonen et al. 1995] just to name a few), [Balcázar 2009] proposes also a notion of “rule blocking”, whereby a subset of the antecedent may “block” an association rule, that is, forbid its being provided in the output, if the confidence of the rule with the smaller antecedent and the same consequent is higher enough.",
      "startOffset" : 0,
      "endOffset" : 109
    }, {
      "referenceID" : 33,
      "context" : "[Bayardo et al. 1999; Liu et al. 1999; Padmanabhan and Tuzhilin 2000; Shah et al. 1999; Toivonen et al. 1995] just to name a few), [Balcázar 2009] proposes also a notion of “rule blocking”, whereby a subset of the antecedent may “block” an association rule, that is, forbid its being provided in the output, if the confidence of the rule with the smaller antecedent and the same consequent is higher enough.",
      "startOffset" : 0,
      "endOffset" : 109
    }, {
      "referenceID" : 38,
      "context" : "[Bayardo et al. 1999; Liu et al. 1999; Padmanabhan and Tuzhilin 2000; Shah et al. 1999; Toivonen et al. 1995] just to name a few), [Balcázar 2009] proposes also a notion of “rule blocking”, whereby a subset of the antecedent may “block” an association rule, that is, forbid its being provided in the output, if the confidence of the rule with the smaller antecedent and the same consequent is higher enough.",
      "startOffset" : 0,
      "endOffset" : 109
    }, {
      "referenceID" : 3,
      "context" : "1995] just to name a few), [Balcázar 2009] proposes also a notion of “rule blocking”, whereby a subset of the antecedent may “block” an association rule, that is, forbid its being provided in the output, if the confidence of the rule with the smaller antecedent and the same consequent is higher enough.",
      "startOffset" : 27,
      "endOffset" : 42
    }, {
      "referenceID" : 34,
      "context" : "The natural reaction, consisting of a normalization by dividing the confidence by the (normalized) support of the consequent of the rule, gives a parameter that we find in the references going by several different names: it has been called interest [Silverstein et al. 1998] or, in a slightly different but fully equivalent form, strength [Shah et al.",
      "startOffset" : 249,
      "endOffset" : 274
    }, {
      "referenceID" : 33,
      "context" : "1998] or, in a slightly different but fully equivalent form, strength [Shah et al. 1999]; “lift” seems to be catching up as a short name, possibly aided by the fact that the Intelligent Miner system from IBM employed that name.",
      "startOffset" : 70,
      "endOffset" : 88
    }, {
      "referenceID" : 31,
      "context" : ") The related parameter leverage [Piatetsky-Shapiro 1991] measures essentially the same thing, just that it does so as an additive distance.",
      "startOffset" : 33,
      "endOffset" : 57
    }, {
      "referenceID" : 3,
      "context" : "We describe a case found in data from real census information, pointed out also in [Balcázar 2009].",
      "startOffset" : 83,
      "endOffset" : 98
    }, {
      "referenceID" : 3,
      "context" : "As an alternative approach to this problem, in [Balcázar 2009] the confidence parameter is used in an intuitive way to find a threshold at which a smaller antecedent would suggest to omit a given rule.",
      "startOffset" : 47,
      "endOffset" : 62
    }, {
      "referenceID" : 3,
      "context" : "Again the specific choice of value for the blocking threshold is justified in [Balcázar 2009] just in merely intuitive terms; however, note for later use that the confidence width bound and the blocking threshold are related in that paper as follows: if the confidence width bound is b, then the blocking threshold proposed is b− 1.",
      "startOffset" : 78,
      "endOffset" : 93
    }, {
      "referenceID" : 22,
      "context" : "We will relate our values of confidence width and of confidence boost to an expression essentially employed first, to our knowledge, in [Kryszkiewicz 2001], where no particular name was assigned to it.",
      "startOffset" : 136,
      "endOffset" : 155
    }, {
      "referenceID" : 8,
      "context" : "aim of providing a faster algorithm for computing representative rules; it turns out that, as demonstrated in [Balcázar and T̂ırnăucă 2011], this approach is efficient and useful in practice but runs into the risk of providing incomplete output, as actual representative rules may be missed.",
      "startOffset" : 110,
      "endOffset" : 139
    }, {
      "referenceID" : 3,
      "context" : ") We show next that confidence boost embodies exactly both blocking and confidence width, precisely with the same relation between the thresholds as used in [Balcázar 2009], under the already stated proviso that all the association rules involved must clear the support threshold.",
      "startOffset" : 157,
      "endOffset" : 172
    }, {
      "referenceID" : 3,
      "context" : "In this sense, confidence boost embodies both low-novelty tests from [Balcázar 2009], and with the same thresholds employed there.",
      "startOffset" : 69,
      "endOffset" : 84
    }, {
      "referenceID" : 3,
      "context" : "A mild precomputation allows one to compute quite efficiently the width [Balcázar 2009], but the same method does not seem to work for blocking or boost.",
      "startOffset" : 72,
      "endOffset" : 87
    }, {
      "referenceID" : 26,
      "context" : "[Luxenburger 1991; Pasquier et al. 2005; Zaki 2004], suggest to treat separately the implications, which allow for more compact bases, from the partial rules.",
      "startOffset" : 0,
      "endOffset" : 51
    }, {
      "referenceID" : 29,
      "context" : "[Luxenburger 1991; Pasquier et al. 2005; Zaki 2004], suggest to treat separately the implications, which allow for more compact bases, from the partial rules.",
      "startOffset" : 0,
      "endOffset" : 51
    }, {
      "referenceID" : 41,
      "context" : "[Luxenburger 1991; Pasquier et al. 2005; Zaki 2004], suggest to treat separately the implications, which allow for more compact bases, from the partial rules.",
      "startOffset" : 0,
      "endOffset" : 51
    }, {
      "referenceID" : 6,
      "context" : "In [Balcázar 2010c], besides another more complicated alternative, we follow up this suggestion as well, and employ a notion of closure-based redundancy which also turns out to provide a complete basis of provably minimum size, denoted B.",
      "startOffset" : 3,
      "endOffset" : 19
    }, {
      "referenceID" : 22,
      "context" : "The best approaches to the representative rules need to work on the basis of both the closures lattice plus all the minimal generators of each closure ([Kryszkiewicz 2001], but see the related discussion in [Balcázar and T̂ırnăucă 2011]); instead, the B basis can be computed just from the closures.",
      "startOffset" : 152,
      "endOffset" : 171
    }, {
      "referenceID" : 8,
      "context" : "The best approaches to the representative rules need to work on the basis of both the closures lattice plus all the minimal generators of each closure ([Kryszkiewicz 2001], but see the related discussion in [Balcázar and T̂ırnăucă 2011]); instead, the B basis can be computed just from the closures.",
      "startOffset" : 207,
      "endOffset" : 236
    }, {
      "referenceID" : 41,
      "context" : "[Zaki 2004]).",
      "startOffset" : 0,
      "endOffset" : 11
    }, {
      "referenceID" : 6,
      "context" : "Closure-based redundancy [Balcázar 2010c] takes into account the closure operator indirectly as follows:",
      "startOffset" : 25,
      "endOffset" : 41
    }, {
      "referenceID" : 6,
      "context" : "All these definitions are studied in depth in [Balcázar 2010c].",
      "startOffset" : 46,
      "endOffset" : 62
    }, {
      "referenceID" : 29,
      "context" : "3 [Pasquier et al. 2005] (a nonminimal basis for the implications of confidence 1, as the GD basis is sometimes smaller [Guigues and Duquenne 1986]).",
      "startOffset" : 2,
      "endOffset" : 24
    }, {
      "referenceID" : 16,
      "context" : "2005] (a nonminimal basis for the implications of confidence 1, as the GD basis is sometimes smaller [Guigues and Duquenne 1986]).",
      "startOffset" : 101,
      "endOffset" : 128
    }, {
      "referenceID" : 13,
      "context" : "fi/); and dataset Now (based on the Neogene of the Old World dataset, public release 030710 [Fortelius 2003]) is a transactional version of a paleontological dataset from Europe: we downloaded and preprocessed slightly file NOW public 030710.",
      "startOffset" : 92,
      "endOffset" : 108
    }, {
      "referenceID" : 14,
      "context" : "Here, however, instead of looking for experts on a given dataset, we use a dataset for which some readers of this paper might be expected to be reasonably knowledgeable: in the same vein as the evaluations in [Gallo et al. 2007], we employ the titles, topics, and abstracts of all the reports submitted to the e-prints repository of the Pascal Network of Excellence along its early years of existence.",
      "startOffset" : 209,
      "endOffset" : 228
    }, {
      "referenceID" : 16,
      "context" : "By way of comparison, at the same level of support, at the most demanding possible level of confidence (100%), with the less redundant basis computation currently known (the Guigues-Duquenne basis, [Guigues and Duquenne 1986]), the result is 44 rules, with considerably more “intuitive redundancy” and less interest overall, and requires somewhat longer time to be computed.",
      "startOffset" : 198,
      "endOffset" : 225
    }, {
      "referenceID" : 40,
      "context" : "This idea is reminiscent of the decreasing support in the version of “apriori” implemented in the Weka tool [Witten and Frank 2005], but in that well-known system the user still has to provide a maximum and a minimum values to try the support threshold, and a “delta” by which the support keeps decreasing; then, the “apriori” algorithm is run repeatedly for the corresponding sequence of support thresholds.",
      "startOffset" : 108,
      "endOffset" : 131
    }, {
      "referenceID" : 32,
      "context" : "The “predictive apriori” alternative, present in that tool as well [Scheffer 2005; Witten and Frank 2005], also attempts at adjusting the support, by balancing it with respect to confidence.",
      "startOffset" : 67,
      "endOffset" : 105
    }, {
      "referenceID" : 40,
      "context" : "The “predictive apriori” alternative, present in that tool as well [Scheffer 2005; Witten and Frank 2005], also attempts at adjusting the support, by balancing it with respect to confidence.",
      "startOffset" : 67,
      "endOffset" : 105
    }, {
      "referenceID" : 2,
      "context" : "The lattice constructor itself is based on [Baixeries et al. 2009] and works also as an iterator, constructing Hasse edges only when they are needed.",
      "startOffset" : 43,
      "endOffset" : 66
    }, {
      "referenceID" : 13,
      "context" : "net/projects/yacaree/; these example datasets are already preprocessed into transactional form, and come from [Asuncion and Newman 2007] or [Fortelius 2003], or from the e-prints repository of the Pascal Network of Excellence.",
      "startOffset" : 140,
      "endOffset" : 156
    }, {
      "referenceID" : 27,
      "context" : "This does not mean that it has to be replaced as a measure of intensity of implication, and, in fact, it has been observed and argued that (at least in somewhat sparse transactional datasets) the combination of support and confidence is already very good at discarding rules that are present only as statistical artifacts and do not really correspond to correlations in the phenomenon at the origin of the dataset [Megiddo and Srikant 1998]; instead, we consider that our message is that it should be complemented with relative confidence thresholds that assess the novelty of each rule by comparison with the confidence of logically (or intuitively) stronger rules.",
      "startOffset" : 414,
      "endOffset" : 440
    }, {
      "referenceID" : 15,
      "context" : "We refer to [Geng and Hamilton 2006] for an excellent survey of many options to relate supports of left and right hand sides of association rules to construct indicators of interestingness.",
      "startOffset" : 12,
      "endOffset" : 36
    }, {
      "referenceID" : 17,
      "context" : "More sophisticated interestingness measures are possible, for instance those based on the KL-divergence between probability distributions induced with and without the given rule [Jaroszewicz and Simovici 2002]: the induced distributions satisfy the supports of the rule and of its antecedent but otherwise maximize the entropy.",
      "startOffset" : 178,
      "endOffset" : 209
    }, {
      "referenceID" : 17,
      "context" : "2) gives results very close to those in [Jaroszewicz and Simovici 2002].",
      "startOffset" : 40,
      "endOffset" : 71
    }, {
      "referenceID" : 28,
      "context" : "useful to explain novelty by comparing more specific rules stating a consequent of the form A = V to more general rules stating a consequent of the form A = V ′ for V ′ 6= V , and quite interesting results along this line can be found in [Padmanabhan and Tuzhilin 2000; Suzuki 1997; Suzuki and Kodratoff 1998], among others.",
      "startOffset" : 238,
      "endOffset" : 309
    }, {
      "referenceID" : 35,
      "context" : "useful to explain novelty by comparing more specific rules stating a consequent of the form A = V to more general rules stating a consequent of the form A = V ′ for V ′ 6= V , and quite interesting results along this line can be found in [Padmanabhan and Tuzhilin 2000; Suzuki 1997; Suzuki and Kodratoff 1998], among others.",
      "startOffset" : 238,
      "endOffset" : 309
    }, {
      "referenceID" : 36,
      "context" : "useful to explain novelty by comparing more specific rules stating a consequent of the form A = V to more general rules stating a consequent of the form A = V ′ for V ′ 6= V , and quite interesting results along this line can be found in [Padmanabhan and Tuzhilin 2000; Suzuki 1997; Suzuki and Kodratoff 1998], among others.",
      "startOffset" : 238,
      "endOffset" : 309
    }, {
      "referenceID" : 3,
      "context" : "The notions of confidence width and rule blocking from [Balcázar 2009] are similar to the “pruning” proposal from [Liu et al.",
      "startOffset" : 55,
      "endOffset" : 70
    }, {
      "referenceID" : 25,
      "context" : "The notions of confidence width and rule blocking from [Balcázar 2009] are similar to the “pruning” proposal from [Liu et al. 1999], in that the intuition is the same; also our proposal here follows an analogous intuitive path.",
      "startOffset" : 114,
      "endOffset" : 131
    }, {
      "referenceID" : 25,
      "context" : "Major differences are that, in the proposals we discuss, a large portion of the pruning becomes unnecessary because we work on minimum-size bases, namely representative rules, and, more importantly, that the pruning in [Liu et al. 1999] is based on the χ statistic, whereas we will look instead into the confidence thresholds that would make the rule “redundant”, either in a “formal logic” sense or in a more intuitive, but still logical-style relaxation.",
      "startOffset" : 219,
      "endOffset" : 236
    }, {
      "referenceID" : 11,
      "context" : "Our notions are also similar to the notion of improvement, proposed in [Bayardo et al. 1999] and also discussed in [Liu et al.",
      "startOffset" : 71,
      "endOffset" : 92
    }, {
      "referenceID" : 25,
      "context" : "1999] and also discussed in [Liu et al. 1999; Webb 2007]; but improvement is a measure of an absolute, additive confidence increase, with no reference to representative rules or redundancy, and it only allows for varying the antecedent into a smaller one, keeping the same consequent.",
      "startOffset" : 28,
      "endOffset" : 56
    }, {
      "referenceID" : 39,
      "context" : "1999] and also discussed in [Liu et al. 1999; Webb 2007]; but improvement is a measure of an absolute, additive confidence increase, with no reference to representative rules or redundancy, and it only allows for varying the antecedent into a smaller one, keeping the same consequent.",
      "startOffset" : 28,
      "endOffset" : 56
    }, {
      "referenceID" : 0,
      "context" : "[Aggarwal and Yu 2001; Kryszkiewicz 1998b; Phan-Luong 2001; Shah et al. 1999]).",
      "startOffset" : 0,
      "endOffset" : 77
    }, {
      "referenceID" : 20,
      "context" : "[Aggarwal and Yu 2001; Kryszkiewicz 1998b; Phan-Luong 2001; Shah et al. 1999]).",
      "startOffset" : 0,
      "endOffset" : 77
    }, {
      "referenceID" : 30,
      "context" : "[Aggarwal and Yu 2001; Kryszkiewicz 1998b; Phan-Luong 2001; Shah et al. 1999]).",
      "startOffset" : 0,
      "endOffset" : 77
    }, {
      "referenceID" : 33,
      "context" : "[Aggarwal and Yu 2001; Kryszkiewicz 1998b; Phan-Luong 2001; Shah et al. 1999]).",
      "startOffset" : 0,
      "endOffset" : 77
    }, {
      "referenceID" : 38,
      "context" : "This happens in the structural cover of [Toivonen et al. 1995], and in some of the pruning rules of [Shah et al.",
      "startOffset" : 40,
      "endOffset" : 62
    }, {
      "referenceID" : 33,
      "context" : "1995], and in some of the pruning rules of [Shah et al. 1999] (which focuses on a slightly different approach since their main measure is actually lift, but, in fact, most of their developments work for confidence as well); and also in [Scheffer 2005].",
      "startOffset" : 43,
      "endOffset" : 61
    }, {
      "referenceID" : 32,
      "context" : "1999] (which focuses on a slightly different approach since their main measure is actually lift, but, in fact, most of their developments work for confidence as well); and also in [Scheffer 2005].",
      "startOffset" : 180,
      "endOffset" : 195
    }, {
      "referenceID" : 32,
      "context" : "All these proposals may make sense as heuristics, and their connection to confidence boost is developed below; however, if taken as redundancy statements then they are incorrect and, in some cases, where a precise mathematical statement and its proof are provided (like [Scheffer 2005]), the proof can be seen to switch into a “full implication” meaning of the “arrow” connective, and is actually wrong, therefore, since it does not apply to partial rules.",
      "startOffset" : 270,
      "endOffset" : 285
    }, {
      "referenceID" : 21,
      "context" : "As a representative of these proposals, we chose to discuss the approach of [Kryszkiewicz 1998c] which can be casted as follows:",
      "startOffset" : 76,
      "endOffset" : 96
    }, {
      "referenceID" : 21,
      "context" : "The following holds [Kryszkiewicz 1998c]:",
      "startOffset" : 20,
      "endOffset" : 40
    }, {
      "referenceID" : 29,
      "context" : "Let us point out that these rules are subtly different from the min-max approximate basis of [Pasquier et al. 2005], given in Definition 2.",
      "startOffset" : 93,
      "endOffset" : 115
    }, {
      "referenceID" : 2,
      "context" : "First, since we mine frequent closures in descending support, instead of ascending, some of the optimizations in ChARM require further work before being readily applicable; also, the best algorithm in [Baixeries et al. 2009] (namely iPred) to compute Hasse edges is not applied, as it assumes a cardinality-ordered traversal of the closed sets instead of a support-oriented one; the theorems that guarantee its applicability have been obtained only recently, and a forthcoming version of yacaree will sport this faster algorithm, iPred.",
      "startOffset" : 201,
      "endOffset" : 224
    } ],
    "year" : 2013,
    "abstractText" : "Some existing notions of redundancy among association rules allow for a logical-style characterization and lead to irredundant bases of absolutely minimum size. One can push the intuition of redundancy further and find an intuitive notion of interest of an association rule, in terms of its “novelty” with respect to other rules. Namely: an irredundant rule is so because its confidence is higher than what the rest of the rules would suggest; then, one can ask: how much higher? We propose to measure such a sort of “novelty” through the confidence boost of a rule, which encompasses two previous similar notions (confidence width and rule blocking, of which the latter is closely related to the earlier measure “improvement”). Acting as a complement to confidence and support, the confidence boost helps to obtain small and crisp sets of mined association rules, and solves the well-known problem that, in certain cases, rules of negative correlation may pass the confidence bound. We analyze the properties of two versions of the notion of confidence boost, one of them a natural generalization of the other. We develop efficient algorithmics to filter rules according to their confidence boost, compare the concept to some similar notions in the bibliography, and describe the results of some experimentation employing the new notions on standard benchmark datasets. We describe an open-source association mining tool that embodies one of our variants of confidence boost in such a way that the data mining process does not require the user to select any value for any parameter.",
    "creator" : "TeX"
  }
}