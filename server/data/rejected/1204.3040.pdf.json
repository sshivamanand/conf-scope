{
  "name" : "1204.3040.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Tractable Answer-Set Programming with Weight Constraints: Bounded Treewidth is not Enough",
    "authors" : [ "Reinhard Pichler", "Stefan Rümmele", "Stefan Szeider", "Stefan Woltran" ],
    "emails" : [ "woltran}@dbai.tuwien.ac.at,", "stefan@szeider.net" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Answer-set programming (ASP) has evolved as a paradigm that allows for very elegant solutions to many combinatorial problems [14]. The basic idea is to describe a problem by a logic program in such a way that the stable models correspond to the solutions of the considered problem. By extending logic programs with cardinality or, more generally, weight constraints, an even larger class of problems is accessible to this method [16]. For instance, in the product configuration domain, we need to express cardinality, cost, and resource constraints, which are very difficult to capture using logic programs without weights.\nIn this paper, we restrict ourselves to normal logic programs with cardinality constraints (PCCs, for short) or weight constraints (PWCs, for short). Clearly, all common algorithmic tasks related to PCCs and PWCs – like checking the consistency of a program – are intractable, since intractability even holds without such constraints. An interesting approach to dealing with intractable problems comes from parameterized complexity theory and is based on the following observation: Many hard problems become tractable if some parameter that represents a structural aspect of the problem instance is small. One important parameter is treewidth, which measures the “tree-likeness” of a graph or, more generally, of a structure. In the area of knowledge representation and reasoning (KR & R), many tractability results for instances of bounded treewidth have been recently proven [8]. The goal of this work is to obtain tractability results via bounded treewidth also for PCCs and PWCs. Hereby, the treewidth of a PCC or PWC is\n∗To appear in Theory and Practice of Logic Programming (TPLP). A preliminary version appeared in the Proceedings of the Twelfth International Conference on Principles of Knowledge Representation and Reasoning (KR 2010). †Supported by the Austrian Science Fund (FWF): P20704-N18. ‡Supported by the European Research Council (ERC), project 239962. §Supported by Vienna University of Technology special fund “Innovative Projekte 9006.09/008”.\nar X\niv :1\n20 4.\n30 40\nv2 [\ncs .L\nO ]\n2 9\nM ay\n2 01\ndefined in terms of its incidence graph (see Section 2). It will turn out that the straightforward application of treewidth to PWCs does not suffice to obtain tractability. However, by imposing further restrictions, tractability can be achieved.\nMain results of the paper.\n• We show that the consistency problem of PWCs remains NP-complete even if the treewidth of the considered programs is bounded by a constant (actually, even if this constant is 1). Hence, we have to search for further restrictions on the PWCs to ensure tractability.\n• We thus consider the largest integer occurring in (lower or upper) bounds of the constraints in the PWC, and call this parameter constraint-width. If also the constraint-width is bounded by an arbitrary but fixed constant, then the consistency problem of PWCs becomes linear time tractable (the bound on the running time entails a constant factor that is exponential in constraint-width and treewidth).\n• For PCCs (i.e., PWCs where all weights are equal to 1) we obtain non-uniform polynomial time tractability by designing a new dynamic programming algorithm. Let w denote the treewidth of a PCC Π and let n denote the size of Π. Then our algorithm works in time O(f(w) · n2w) for some function f that only depends on the treewidth, but not on the size n of the program. The term “non-uniform” refers to the factor n2w in the time bound, where the size n of the program is raised to the power of an expression that depends on the treewidth w. We shall also discuss further extensions of this dynamic programming algorithm for PCCs. For example, it can be used to solve in non-uniform polynomial time the consistency problem of PWCs if the weights are given in unary representation.\n• Of course, an algorithm for the PCC consistency problem that operates in time O(f(w) · nO(1)) would be preferable, i.e., the parameter w does not occur in the exponent of the program size n. A problem with such an algorithm is called fixed-parameter tractable. Alas, we show that under common complexity theoretical assumptions no such algorithm exists. Technically, we prove that the consistency problem of PCCs parameterized by treewidth is hard for the parameterized complexity class W [1]. In other words, a non-uniform polynomial-time running time of our dynamic programming algorithm is the best that one can expect.\nStructure of the paper. After recalling the necessary background in Section 2, we prove in Section 3 the NP-completeness of the consistency problem of PWCs in case of binary representation of the weights. In Section 4, we show the linear fixed-parameter tractability of the problem if we consider the treewidth plus the size of the bounds as parameter. In Section 5, the non-uniform polynomial-time upper bound for the consistency problem of PCCs is established by presenting a dynamic programming algorithm. Section 6 contains the extensions of the dynamic programming algorithm. By giving a W [1]-hardness proof in case of unary representation in Section 7, we show that it is unlikely that this result can be significantly improved. Section 8 contains a discussion and a conclusion is given in Section 9."
    }, {
      "heading" : "2 Background",
      "text" : "Weight constraint programs. A program with weight constraints (PWC) is a triple Π = (A, C,R), where A is a set of atoms, C is a set of weight constraints (or constraints for short), and R is a set of rules. Each constraint c ∈ C is a triple (S, l, u) where S is a set of weight literals over A representing a clause and l ≤ u are nonnegative integers, the lower and upper bound. A weight literal over A is a pair (a, j) or (¬a, j) for a ∈ A and 1 ≤ j ≤ u + 1, the weight of the literal. Unless stated otherwise, we assume that the bounds and weights are given in binary representation. For a constraint c = (S, l, u) ∈ C, we write Cl(c) := S, l(c) := l, and u(c) := u. Moreover, we use a ∈ Cl(c) and ¬a ∈ Cl(c) as an abbreviation for (a, j) ∈ Cl(c)\nrespectively (¬a, j) ∈ Cl(c) for an arbitrary j. A rule r ∈ R is a pair (h, b) where h ∈ C is the head and b ⊆ C is the body. We write H(r) := h and B(r) := b. We denote by ‖Π‖ the size of a reasonable encoding of program Π and call it the size of Π. Unless otherwise stated, weights are assumed to be encoded in binary notation. For instance taking ‖Π‖ = |A| + ∑ (S,l,u)∈C(1 + log l + log u + ∑ (lit,j)∈S(1 + log j)) + ∑ (h,b)∈R(1 + |b|) would do. Given a constraint c ∈ C and an interpretation I ⊆ A over atoms A, we denote the weight of c in I by\nW (c, I) = ∑\n(a,j)∈Cl(c) a∈I\nj + ∑\n(¬a,j)∈Cl(c) a 6∈I\nj .\nI is a model of c, denoted by I |= c, if l(c) ≤W (c, I) ≤ u(c). For a set C ⊆ C, I |= C if I |= c for all c ∈ C. Moreover, C is a model of a rule r ∈ R, denoted by C |= r, if H(r) ∈ C or B(r) 6⊆ C. I is a model of program Π (denoted by I |= Π) if {c ∈ C : I |= c} |= r for all r ∈ R. If the lower bound of a constraint c ∈ C is missing, we assume l(c) = 0. If the upper bound is missing, I |= c if l(c) ≤ W (c, I). A program with cardinality constraints (PCC) can be seen as a special case of a PWC, where each literal has weight 1.\nStable model semantics. Given a PWC Π = (A, C,R) and an interpretation I ⊆ A. Following [16], the reduct cI of a constraint c ∈ C w.r.t. I is obtained by removing all negative literals and the upper bound from c, and replacing the lower bound by\nl′ = max(0, l(c)− ∑\n(¬a,j)∈Cl(c) a 6∈I\nj).\nThe reduct ΠI of program Π w.r.t. I can be obtained by first removing each rule r ∈ R which contains a constraint c ∈ B(r) with W (c, I) > u(c). Afterwards, each remaining rule r is replaced by the set of rules1 (h, b), where h ∈ I ∩ Cl(H(r)) and b = {cI : c ∈ B(r)}, i.e., the head of the new rules is an atom instead of a constraint. Interpretation I is called a stable model (or answer set) of Π if I is a model of Π and there exists no J ⊂ I such that J is a model of ΠI . The set of all answer sets of Π is denoted by AS(Π). The consistency problem for PWCs is to decide whether AS(Π) 6= ∅.\nTree decompositions and treewidth. A tree decomposition of a graph G = (V,E) is a pair T = (T, χ), where T is a tree and χ maps each node n of T (we use n ∈ T as a shorthand below) to a bag χ(n) ⊆ V such that\n(1) for each v ∈ V , there is an n ∈ T with v ∈ χ(n);\n(2) for each (v, w) ∈ E, there is an n ∈ T with v, w ∈ χ(n);\n(3) for each n1, n2, n3 ∈ T such that n2 lies on the path from n1 to n3, χ(n1) ∩ χ(n3) ⊆ χ(n2) holds.\nA tree decomposition (T, χ) is called normalized (or nice) [11], if T is a rooted tree and the following conditions hold: (1) each n ∈ T has ≤ 2 children; (2) for each n ∈ T with two children n1, n2, χ(n) = χ(n1) = χ(n2); and (3) for each n ∈ T with one child n′, χ(n) and χ(n′) differ in exactly one element.\nThe width of a tree decomposition is defined as the cardinality of its largest bag χ(n) minus one. It is known that every tree decomposition can be normalized in linear time without increasing the width [11]. The treewidth of a graph G, denoted as tw(G), is the minimum width over all tree decompositions of G. For arbitrary but fixed w ≥ 1, it is feasible in linear time to decide whether a graph has treewidth ≤ w and, if so, to compute a tree decomposition of width w, see [1].\n1With some abuse of notation, we sometimes write for an atom h, (h, b) as a shorthand for the rule (({(h, 1)}, 1, 1), b).\nTreewidth and constraint-width of PWCs. To build tree decompositions for programs, we use incidence graphs. For a PWC Π = (A, C,R), such a graph has vertex set A∪C ∪R. There is an edge between a ∈ A and c ∈ C if a ∈ Cl(c) or ¬a ∈ Cl(c), and there is an edge between c ∈ C and r ∈ R if c ∈ {H(r)} ∪ B(r). The treewidth of Π, denoted by tw(Π), is the treewidth of its incidence graph. The constraint-width of Π, denoted by cw(Π), is the largest (lower or upper) bound occurring in the constraints of C (or 0 if there are no bounds).\nExample 1. Consider the following system configuration problem, where one has to choose among the given parts: p1 : 4000$, p2 : 2000$, and p3 : 1000$ such that the total cost is ≤ 5000$. Thereby one of {p1, p2} has to be selected and p3 requires p2.\nThis scenario can be represented by the PWC\nΠEx = ({p1, p2, p3}, {c1, c2, c3, c4}, {r1, r2, r3})\nwith\nc1 = ({(p1, 4), (p2, 2), (p3, 1)}, 0, 5) r1 = (c1, ∅) c2 = ({(p1, 1), (p2, 1)}, 1, 2) r2 = (c2, ∅) c3 = ({(p2, 1)}, 1, 1) r3 = (c3, {c4}) c4 = ({(p3, 1)}, 1, 1)\nThe incidence graph GEx of ΠEx as well as a normalized tree decomposition TEx for ΠEx of width 2 are depicted in Figure 1."
    }, {
      "heading" : "3 NP-Completeness",
      "text" : "Theorem 2. The consistency problem for PWCs is NP-complete already for programs having treewidth 1.\nProof. Clearly the problem is in NP. To show NP-hardness we reduce from the well-known NP-complete problem Partition. An instance of Partition is a collection of positive integers X = {x1, . . . , xn} (encoded in binary); the question is whether there exists a set I ⊆ {1, . . . , n} such that ∑ i∈I xi = ∑ i/∈I xi. Given an instance X = {x1, . . . , xn}, we construct a PWC Π =\n(A, C,R) as follows. Let S = ∑n i=1 xi; we may assume that S is even since otherwise X is\na no-instance and can immediately be rejected. We put A = {a1, . . . , an}, C = {c} where c = ({(a1, x1), . . . , (an, xn)}, S/2, S/2), and R = {(c, ∅)}.\nClaim 1: Π has treewidth 1. By construction the incidence graph of Π is a tree, hence of treewidth 1.\nClaim 2: X is a yes-instance of Partition if and only if Π has a model. This claim follows easily from the definitions.\nClaim 3: All models of Π are stable. Let M be a model of Π. Since each atom appears positively in a constraint at the head of a rule, and since all the rules have an empty body, it follows that the reduct ΠM is the conjunction of all the elements of M . Hence M is stable since no proper subset of M can satisfy ΠM . We conclude that X is a yes-instance of Partition if and only if Π is consistent.\nIt is evident that Π can be constructed from X in polynomial time. Hence, by Claims 1–3 we have a polynomial-time reduction from Partition to the consistency problem of PWCs of treewidth 1, and the theorem follows.\nNote that Partition is “weakly NP-hard” since its NP-hardness depends on the binary encoding of the given integers. Accordingly, our reduction provides only weak NP-hardness for the consistency of PWCs of bounded treewidth. In fact, we shall prove in Section 6 that if we assume the weights to be given in unary the consistency problem is feasible in (non-uniform) polynomial time for PWCs of bounded treewidth."
    }, {
      "heading" : "4 Linear-Time Tractability",
      "text" : "Theorem 3. The consistency problem for PWCs can be solved in linear time for instances whose treewidth and constraint-width are bounded by constants.\nTo prove this result we shall take a logic approach and use Courcelle’s Theorem [4], see also [6, 7]. To this aim we consider Monadic Second Order (MSO) logic on labeled graphs in terms of their incidence structure whose universe contains vertices and edges. We assume an infinite supply of individual variables x, x1, x2, . . . and set variables X,X1, X2, . . . The atomic formulas are E(x) (“x is an edge”), V (x) (“x is a vertex”), I(x, y) (“vertex x is incident with edge y”), x = y (equality), and X(y) (“element y belongs to set X”). Further we assume that a vertex or edge x can be labeled with an element a of some fixed finite set, denoted by the atomic formula Pa(x). MSO formulas are built up from atomic formulas using the usual Boolean connectives (¬,∧,∨), quantification over individual variables (∀x, ∃x), and quantification over set variables (∀X, ∃X).\nWe writeG |= ϕ to indicate that an MSO formula ϕ is true for the labeled graphG. Courcelle’s Theorem states thatG |= ϕ can be checked in linear time for labeled graphs if a tree decomposition of constant width is provided as an input. The latter is no restriction for proving Theorem 3, since by Bodlaender’s Theorem [1], we can compute in linear time a tree decomposition of smallest width for graphs whose treewidth is bounded by a constant.\nLet k be a constant and consider a PWC Π = (A, C,R) of constraint-width k. We encode all the information of Π by adding edge and vertex labels to the incidence graph of Π. We use the edge labels +,− to indicate polarity of literals and the labels h, b to distinguish between head and body of rules. That is, an edge {a, c} for a ∈ A and c ∈ C has label + if a ∈ Cl(c), and label − if ¬a ∈ Cl(c); an edge {c, r} for c ∈ C and r ∈ R has label h if c = H(r) and label b if c ∈ B(r). We use edge labels 1, . . . , k + 1 to encode weights of literals (literals of weight 0 can be omitted, weights exceeding k + 1 can be replaced by k + 1). That is, an edge {a, c} for a ∈ A and c ∈ C has label j if the constraint c contains the weight literal (a, j) or (¬a, j). We use vertex labels low[i] for i ∈ {0 . . . , k} and up[j] for j ∈ {0 . . . , k,∞} to encode the bounds of constraints (we use low[0] and up[∞] in case the lower or upper bound is missing, respectively).\nFinally we use vertex labels A, C,R to indicate whether a vertex represents an atom, a clause or a rule, respectively.\nLet G denote the incidence graph of the PWC Π with added labels as described above. In the following we will explain how to construct an MSO formula ϕ such that G |= ϕ if and only if Π has a stable model. For convenience we will slightly abuse notation and use meta-language terms as shorthands for their obvious definitions in the MSO language; for example we will write X ⊆ Y instead of ∀x(X(x)→ Y (x)), and a ∈ A instead of V (a) ∧ PA(a).\nLet X and Y be set variables and c an individual variable. For each integer s ∈ {0, . . . , k+ 1} we define an MSO formula Sums(X,Y, c) that is true for G if and only if X and Y are interpreted as sets of atoms, c is interpreted as a constraint, and we have\ns = ∑\n(a,j)∈Cl(c) a∈X\nj + ∑\n(¬a,j)∈Cl(c) a/∈Y\nj.\nWe use the fact that it is always sufficient to choose at most k + 1 literals from c (say r positive and r′ negative literals) to witness that the above equality holds.\nSums(X,Y, c) ≡ X,Y ⊆ A ∧ c ∈ C (1) ∧ ∨\n1≤r+r′≤k, 1≤n1,...,nr+r′≤k+1, s=n1+···+nr+r′ ∃e1, . . . , er+r′ (2)[∧r+r′\ni=1 (Pni(ei) ∧ I(c, ei) ∧ ∃a ∈ A, I(a, ei)) (3) ∧ ∧\n1≤i<i′≤r+r′ ei 6= ei′ (4) ∧∀e ∈ E (¬I(c, e) ∨ ∀a ∈ A,¬I(a, e) ∨ ∨r+r′ i=1 e = ei) (5)\n∧ ∧r i=1(P+(ei) ∧ ∃a ∈ X, I(a, ei)) (6)\n∧ ∧r′ i=r+1(P−(ei) ∧ ¬∃a ∈ Y, I(a, ei)) ] (7)\nSome further explanation: Each of the r + r′ literals is represented by an edge ei of weight ni. The disjunction in line (2) runs over all possible combinations of weights n1, . . . , nr+r′ that give the sum s. Line (3) makes sure that each edge ei has weight ni and runs between constraint c and some atom. Lines (4) and (5) make sure that the edges are mutually different and that no other edge runs between constraint c and an atom. Lines (6) and (7) make sure that e1, . . . , er represent positive literals over atoms that belong to X, and er+1, . . . , er+r′ represent negative literals over atoms that do not belong to Y .\nThe following formula is true if and only if X satisfies c.\nSat(X, c) ≡ SatL(X,X, c) ∧ SatU(X,X, c), where SatL(X,Y, c) ≡ Plow[0] ∨ ∨\ni∈{1,...,k}\n(Plow[i](c) ∧ ∨\ni≤s≤k+1\nSums(X,Y, c)), and\nSatU(X,Y, c) ≡ Pup[∞] ∨ ∨\nj∈{0,...,k}\n(Pup[j](c) ∧ ∨\n0≤s≤j\nSums(X,Y, c)).\nThe next formula is true if and only if Y is a model of Π. Mod(Y ) ≡ ∀r ∈ R ∃c ∈ C [ (H(c, r) ∧ Sat(Y, c)) ∨ (B(c, r) ∧ ¬Sat(Y, c)) ] , where\nH(c, r) ≡ ∃e ∈ E (I(c, e) ∧ I(r, e) ∧ Ph(e)), and B(c, r) ≡ ∃e ∈ E (I(c, e) ∧ I(r, e) ∧ Pb(e)).\nFinally, the formula SMod(Y ) is true if and only if Y is a stable model of Π. We make use of the\nformula Red(X,Y ) that states that X satisfies the reduct ΠY .\nSMod(Y ) ≡ Mod(Y ) ∧ ∀X ⊆ Y (X = Y ∨ ¬Red(X,Y )), where Red(X,Y ) ≡ ∀r ∈ R ∀a ∈ A [a ∈ X ∨ a /∈ Y ∨ ¬InH(a, r)\n∨ ∃c (B(c, r) ∧ (¬SatU(Y, Y, c) ∨ ¬SatL(X,Y, c)))], and InH(a, r) ≡ ∃c ∈ C ∃e, e′ ∈ E [I(a, e) ∧ I(c, e) ∧ P+(e)\n∧ I(r, e′) ∧ I(c, e′) ∧ Ph(e′)],\nthat is, a is an atom that occurs as a positive literal in the constraint at the head of rule r. We summarize the correctness of the construction in the following lemma.\nLemma 4. Let ϕ = ∃Y SMod(Y ). Then Π has a stable model if and only if G |= ϕ.\nSince the labeled graph G can be constructed in linear time, Theorem 3 now follows directly by Courcelle’s Theorem."
    }, {
      "heading" : "5 Dynamic Programming Approach",
      "text" : "Recently, [9] presented a dynamic programming algorithm for answer-set programming that works for programs without cardinality or weight constraints, but possibly with disjunction in the head of the rules. One way to obtain a dynamic programming algorithm for PCCs is to try to extend that algorithm of Jakl et al. by methods to handle the cardinality constraints. In principle, this should be feasible. However, computationally, this approach has a serious drawback, namely: the aforementioned algorithm is tractable for bounded treewidth, but it is double exponential w.r.t. the treewidth (basically this is due to the handling of disjunctions). Our goal here is to present an algorithm that is only single exponential w.r.t. the treewidth. In order to achieve this goal, we have to manipulate a slightly more complicated data structure along the bottom-up traversal of the tree decomposition. In particular, we have to deal with orderings on the atoms in a model.\nTo this end, we need an alternative characterization of stable models. Slightly rephrasing a result by [13] we can characterize answer sets of PCCs as follows:\nProposition 5. Given a PCC Π = (A, C,R), M ⊆ A is an answer set (stable model) of Π if and only if the following conditions are jointly satisfied:\n• M is a model of Π, i.e., M |= Π,\n• there exists a strict linear order < over M , such that for each atom a ∈ M , there exists a rule r ∈ R with (R1) a ∈ Cl(H(r)), (R2) M |= B(r), (R3) for each c ∈ B(r), l(c) ≤ |{b ∈ Cl(c) : b < a} ∪ {¬b ∈ Cl(c) : b ∈ A \\M}|.\nSince the handling of linear orders is crucial for utilizing the above characterization, we will fix some notation first. We denote by [x1, x2, . . . , xn] a (strict) linear order x1 < x2 < . . . < xn on a set X = {x1, . . . , xn}. Moreover, [[X]] denotes the set of all possible linear orders over X. Two linear orders [x1, . . . , xn] and [y1, . . . , ym] are called inconsistent, if there are xi, xj , yk, yl such that xi < xj , yk < yl, xi = yl and xj = yk. Otherwise, we call them consistent. Given two consistent linear orders [x1, . . . , xn] ∈ [[X]] and [y1, . . . , ym] ∈ [[Y ]], we denote by [x1, . . . , xn]+ [y1, . . . , ym] = S the set of their possible combinations. S contains those linear orders [z1, . . . , zp] ∈ [[X ∪ Y ]] such that for every pair xi < xj (respectively yi < yj), there exists zk < zl with zk = xi and zl = xj (respectively zk = yi and zl = yj). Note that in general, there exists more than one possible combination. Furthermore, we denote by [x1, . . . , xi−1, xi, xi+1, . . . , xn]− [xi] the linear order [x1, . . . , xi−1, xi+1, . . . , xn].\nThroughout the whole section, let T = (T, χ) be a normalized tree decomposition of a PCC Π = (A, C,R). We present a dynamic programming algorithm, traversing T in bottom-up direction in order to compute whether Π admits an answer set. Ultimately, we will state properties about subtrees of T and inductively add more and more nodes, until we get a statement about the whole tree. To this end, the following notions become handy. Given a node n ∈ T , we denote by Tn the subtree of T rooted at n. For a set S ⊆ A ∪ C ∪ R, n|S is a shorthand for χ(n) ∩ S. Moreover, n↓S := ⋃ m∈Tn m|S and n⇓S := n↓S \\ n|S . Since the scope of a solution will always be limited to a subtree of the whole tree decomposition, the notion of a model has to be refined with respect to a universe U = n↓A. To this end, the cardinality of a constraint c ∈ C with respect to an interpretation I ⊆ U is given by\nΓ(c, I, U) = |{b ∈ Cl(c) : b ∈ I}|+ |{¬b ∈ Cl(c) : b ∈ U \\ I}| .\nThen I is a model of c under universe U (denoted by I |=U c) if l(c) ≤ Γ(c, I, U) ≤ u(c). Note that |=U and |= coincide for U = A. Similarly, for a subset of constraints C′ ⊆ C, set C ⊆ C′ is a model of a rule r ∈ R under restriction C′, denoted by C |=C′ r, if H(r) ∈ C or B(r) ∩ C′ 6⊆ C.\nIn order to facilitate the discussion below, we define the following sum for constraint c ∈ C, interpretation I ⊆ U over a set of atoms U ⊆ A and linear order L< containing at least I ∪ {c}:\nΓ<(c, I, U, L<) = |{b ∈ Cl(c) : b ∈ I ∧ b < c}|+ |{¬b ∈ Cl(c) : b ∈ U \\ I}| .\nThe following definition helps us to find partial answer sets, limited to the scope of a subtree of T .\nDefinition 6. A partial solution (for node n ∈ T ) is a tuple ϑ̂ = (n, M̂, Ĉ, R̂, L̂<, γ̂, γ̂<, ∆̂), with interpretation M̂ ⊆ n↓A, satisfied constraints Ĉ ⊆ n↓C, satisfied rules R̂ ⊆ n↓R, linear order L̂< ∈ [[M̂ ∪ Ĉ ∪ n↓R]], cardinality functions γ̂ : n↓C → N and γ̂< : Ĉ → N, and derivation witness ∆̂ = (δ̂R, δ̂M , δ̂h, δ̂b, σ̂) with derivation rules δ̂R ⊆ n↓R, derived atoms δ̂M ⊆ M̂ , derivation head constraints δ̂h ⊆ Ĉ, derivation body constraints δ̂b ⊆ Ĉ, and check function σ̂ : δ̂h → {0, 1} such that the following conditions are jointly satisfied:\n1. Ĉ ∩ n⇓C = {c ∈ n⇓C : M̂ |=n↓A c}\n2. R̂ = {r ∈ n↓R : Ĉ |=n↓C r} and n⇓R ⊆ R̂\n3. γ̂(c) = Γ(c, M̂ , n↓A) for all c ∈ n↓C\n4. γ̂<(c) = Γ<(c, M̂ , n↓A, L̂<) for all c ∈ Ĉ\n5. δ̂M = {a ∈ M̂ : c ∈ δ̂h, a ∈ Cl(c), a > c} and M̂ ∩ n⇓A ⊆ δ̂M 6. δ̂b = ⋃ r∈δ̂R B(r) and δ̂b ⊆ Ĉ\n7. c ∈ B(r)⇒ r > c for all c ∈ δ̂b and r ∈ δ̂R\n8. l(c) ≤ γ̂<(c) for all c ∈ δ̂b ∩ n⇓C\n9. σ̂(c) = 1⇔ ∃r ∈ δ̂R with H(r) = c and c > r\n10. σ̂(c) = 1 for all c ∈ δ̂h ∩ n⇓C\nThe idea of this data structure is that, for some atom, clause, or rule that is no longer “visible” in the current bag but was included in the subtree, the containment in one of the sets of ϑ̂ is strictly what one would expect from an answer set, while for elements that are still visible this containment does not have to fulfill that many conditions and can be seen as some sort of “guess”.\nFor example, Ĉ ∩ n⇓C , the set of constraints in Ĉ that are no longer visible, indeed contains exactly the constraints that are satisfied under interpretation M̂ , i.e., {c ∈ n⇓C : M̂ |=n↓A c}, while Ĉ ∩ n|C represents the guess of those constraints, we still want to become true when we further traverse the tree towards the root node. M̂, Ĉ, R̂, and γ̂ are used to ensure that the answer set is a model of our program. L̂< is the strict linear order, whose existence is demanded in the definition of answer sets. γ̂< will be used to check condition (R3) of stable models, i.e., it will contain the cardinality on the left side of the equation in (R3). The derivation of atoms a ∈ M̂ is represented by ∆̂. The definition of answer sets requires for each a ∈ M̂ the existence of some rule r ∈ R satisfying (R1)-(R3). The set of those rules will be represented by δ̂R. Sets δ̂h and δ̂b contain the head, and respectively, body constraints of the rules in δ̂R. The set δ̂M contains those atoms, for which we already found a head constraint to derive it. σ̂ is a utility function, which ensures that each (guessed) constraint in δ̂h is indeed the head of some rule in δ̂R. Thereby σ̂(c) = 1 marks that such a rule was found. Note that, w.l.o.g., we may assume that the root node of a normalized tree decomposition has an empty bag. Indeed, this can always be achieved by introducing at most tw(Π) + 1 additional nodes above the root of a given tree decomposition. Then the following proposition shows the correspondence between answer sets and partial solutions for the root node of a given normalized tree decomposition.\nProposition 7. Let nroot be the root node of T and let χ(nroot) = ∅. Then AS(Π) 6= ∅ if and only if there exists a partial solution ϑ̂ = (nroot, M̂ , Ĉ, R̂, L̂<, γ̂, γ̂<, ∆̂) for nroot.\nProof. (⇒) Given an answer set M ∈ AS(Π), we construct a partial solution ϑ̂ for nroot with derivation witness ∆̂ = (δ̂R, δ̂M , δ̂h, δ̂b, σ̂) as follows. Let M̂ := M , let Ĉ := {c ∈ C : M |= c} and let R̂ := R. Let L< := [a1, . . . , a|M |] ∈ [[M ]] be the linear order from Proposition 5 and let f : M → R be the function that assigns each atom a ∈M the rule r ∈ R that satisfies conditions (R1)–(R3) of Proposition 5 for a. Furthermore, let δ̂R := {f(a) : a ∈M}. In order to create L̂<, we modify L< as follows. For every r ∈ δ̂R let ar be the smallest atom in L< such that f(ar) = r. Atom ar is then replaced in L< by the sequence c1, . . . , cj , r, cj+1, ar, where {c1, . . . , cj} = B(r) and cj+1 = H(r). Note that by construction {c1, . . . , cj+1} ⊆ Ĉ. The remaining clauses from Ĉ as well as the rulesR\\R are arbitrarily appended at the end of L̂<. For every constraint c ∈ C we set γ̂(c) := Γ(c,M,A). For every constraint c ∈ Ĉ we set γ̂<(c) := Γ<(c,M,A, L̂<). Let δ̂M := M , let δ̂h := {H(r) : r ∈ δ̂R}, and let δ̂b := ⋃ r∈δ̂R B(r). Finally, let σ̂(c) := 1 for all c ∈ δ̂h. We show now that ϑ̂ is indeed a partial solution by checking conditions 1–10 of Definition 6. Conditions 1–4, 6–7, and 9–10 are satisfied by construction. For each a ∈ M let ca := H(f(a)). Then ca ∈ δ̂h, a ∈ Cl(ca), and ca < a. Therefore, δ̂M = {a ∈ M̂ : c ∈ δ̂h, a ∈ Cl(c), a > c} which satisfies condition 5. Condition 8 is satisfied because of (R3) of Proposition 5. Hence ϑ̂ is a partial solution for nroot.\n(⇐) For the other direction, the requirement that χ(nroot) = ∅ ensures, that the guessing part of a given partial solution ϑ̂ is nonexistent. Therefore, Ĉ = {c ∈ C : M̂ |= c} and R̂ = {r ∈ R : Ĉ |= r} = R. This ensures that M̂ |= Π and is therefore a model of Π. Let the linear order L< be the restriction of L̂< to the set M̂ . Let a ∈ M̂ be an arbitrary atom. By condition 5 of Proposition 5 there exists a constraint c ∈ δ̂h with a ∈ Cl(c) and a > c. Therefore, by condition 9 and 10 there exists a rule r ∈ δ̂R with H(r) = c and c > r. We now show that rule r is the one fulfilling (R1)–(R3) of Proposition 5 for atom a. (R1) is satisfied by construction. By condition 6, B(r) ⊆ Ĉ. Therefore, M̂ |= B(r), satisfying (R2). Finally, (R3) is satisfied through condition 8. This shows that M̂ is indeed an answer set of Π.\nAn algorithm that computes all partial solutions at each node of the tree decomposition is highly inefficient, since the size and the number of such solutions can grow exponentially in the input size. Therefore we introduce bag assignments, which is a data structure similar to partial\nsolutions, but instead of ranging over the whole subtree, their scope is restricted to a single bag of the tree decomposition. But we are not interested in arbitrary bag assignments. Instead we consider only those, which can be seen as the projection of a partial solution for node n to the bag of node n. Formally this is stated as follows:\nDefinition 8. A bag assignment (for node n ∈ T ) is a tuple ϑ = (n,M,C,R,L<, γ, γ<,∆), with partial model M ⊆ n|A, satisfied constraints C ⊆ n|C, satisfied rules R ⊆ n|R, linear order L< ∈ [[M ∪ C ∪ n|R]], cardinality functions γ : n|C → N and γ< : C → N, and derivation witness ∆ = (δR, δM , δh, δb, σ) with derivation rules δR ⊆ n|R, derived atoms δM ⊆ M , derivation head constraints δh ⊆ C, derivation body constraints δb ⊆ C, and check function σ : δh → {0, 1}.\nDefinition 9. A bag assignment ϑ for node n with ϑ = (n,M,C,R,L<, γ, γ<,∆) and ∆ = (δR, δM , δh, δb, σ) is called a bag model (for node n) if there exists a partial solution ϑ̂ = (n, M̂, Ĉ, R̂, L̂<, γ̂, γ̂<, ∆̂), with ∆̂ = (δ̂R, δ̂M , δ̂h, δ̂b, σ̂) such that\n• M̂ ∩ χ(n) = M , Ĉ ∩ χ(n) = C, R̂ ∩ χ(n) = R,\n• L̂< and L< are consistent,\n• γ̂(c) = γ(c), γ̂<(c) = γ<(c) for all c ∈ n|C,\n• δ̂R ∩ χ(n) = δR, δ̂M ∩ χ(n) = δM ,\n• δ̂h ∩ χ(n) = δh, δ̂b ∩ χ(n) = δb,\n• σ̂(c) = σ(c) for all c ∈ δh.\nIndeed, it turns out that it is sufficient to maintain only bag models during the tree traversal.\nProposition 10. Let nroot be the root node of T , and let χ(nroot) = ∅. Then AS(Π) 6= ∅ if and only if ϑ = (nroot, ∅, ∅, ∅, [], ∅, ∅,∆) with ∆ = (∅, ∅, ∅, ∅, ∅) is a bag model for nroot.\nProof. Since χ(nroot) = ∅, every partial solution for nroot is an extension of ϑ according to the conditions of Definition 9. Therefore, this statement follows from Proposition 7.\nBy the same argument as for the root node, we may assume that χ(n) = ∅ for leaf nodes n. Now a dynamic programming algorithm can be achieved, by creating the only possible bag model ϑ = (n, ∅, ∅, ∅, [], ∅, ∅,∆) with ∆ = (∅, ∅, ∅, ∅, ∅) for each leaf n, and then propagating these bag models along the paths to the root node. Thereby the bag models are altered according to rules, which depend only on the bag of the current node. In order to sketch the cornerstones of the dynamic programming algorithm more clearly, we distinguish between eight types of nodes in the tree decomposition: leaf (L), branch (B), atom introduction (AI), atom removal (AR), rule introduction (RI), rule removal (RR), constraint introduction (CI), and constraint removal (CR) node. The last six types will be often augmented with the element e (either an atom, a rule, or a constraint) which is removed or added compared to the bag of the child node.\nNext we define a relation ≺T between bag assignments, which will be used to propagate bag models in a bottom-up direction along the tree decomposition T . Afterwards we demonstrate the intuition of these rules with the help of a small example.\nDefinition 11. Let ϑ = (n,M,C,R,L<, γ, γ<,∆) and ϑ ′ = (n′,M ′, C ′, R′, L′<, γ ′, γ′<,∆ ′) with ∆ = (δR, δM , δh, δb, σ) and ∆ ′ = (δ′R, δ ′ M , δ ′ h, δ ′ b, σ ′) be bag assignments for nodes n, n′ ∈ T . We relate ϑ′ ≺T ϑ if n has a single child n′ and the following properties are satisfied, depending on the node type of n:\n(r-RR): r ∈ R′ and\nϑ = (n,M ′, C ′, R′ \\ {r}, L′< − [r], γ′, γ′<,∆), with ∆ = (δ′R \\ {r}, δ′M , δ′h, δ′b, σ′).\n(r-RI): ϑ ∈ {(n,M ′, C ′, R∗, L∗<, γ′, γ′<,∆) : L∗< ∈ (L′< + [r])}, with\nR∗ = { R′ ∪ {r} if C ′ |=n|C r R′ otherwise\nand one of the following two groups of properties has to be satisfied:\n• “r is used”: H(r) ∈ n|C ⇒ (H(r) ∈ δ′h∧H(r) > r), for all b ∈ B(r)∩n|C : b ∈ C ′∧b < r, and\n∆ = (δ′R ∪ {r}, δ′M , δ′h, δ′b ∪ (B(r) ∩ n|C), σ∗), with\nσ∗(c) =\n{ 1 if c = H(r)\nσ′(c) otherwise.\n• “r is not used”: ∆ = ∆′.\n(a-AR): a ∈M ′ ⇒ a ∈ δ′M and\nϑ = (n,M ′ \\ {a}, C ′, R′, L′< − [a], γ′, γ′<,∆), with ∆ = (δ′R, δ ′ M \\ {a}, δ′h, δ′b, σ′).\n(a-AI): One of the following two groups of properties has to be satisfied:\n• “set a to false”: ϑ = (n,M ′, C ′, R′, L′<, γ ∗, γ∗<,∆ ′), with\nγ∗(c) = γ′(c) + Γ(c,M ′, n|A)− Γ(c,M ′, n′|A), and γ∗<(c) = γ ′ <(c) + Γ<(c,M\n′, n|A, L′<)− Γ<(c,M ′, n′|A, L′<). • “set a to true”:\nϑ ∈ {(n,M∗ = M ′ ∪ {a}, C ′, R′, L∗<, γ∗, γ∗<,∆) : L∗< ∈ (L′< + [a])}, with\n∆ = (δ′R, δ ′ M ∪ δ∗M , δ′h, δ′b, σ′), where\nδ∗M = { {a} if ∃c ∈ δ′h, a ∈ Cl(c), a > c ∅ otherwise,\nγ∗(c) = γ′(c) + Γ(c,M∗, n|A)− Γ(c,M ′, n′|A), and γ∗<(c) = γ ′ <(c) + Γ<(c,M ∗, n|A, L∗<)− Γ<(c,M ′, n′|A, L′<).\n(c-CR): c ∈ C ′ ⇔ l(c) ≤ γ′(c) ≤ u(c), c ∈ δ′h ⇒ σ′(c) = 1, c ∈ δ′b ⇒ γ′<(c) ≥ l(c), and\nϑ = (n,M ′, C ′ \\ {c}, R′, L′< − [c], γ′, γ′<,∆), with ∆ = (δ′R, δ ′ M , δ ′ h \\ {c}, δ′b \\ {c}, σ′).\n(c-CI): One of the following two groups of properties has to be satisfied:\n• “set c to false”: c 6∈ B(r) ∧ c 6= H(r) for all r ∈ δ′R, and\nϑ = (n,M ′, C ′, R′ ∪R∗, L′<, γ′ ∪ γ∗, γ′<,∆′), with\nR∗ = {r ∈ n|R : C ′ |=n|C r}, and γ∗ = {(c,Γ(c,M ′, n|A)}.\n• “set c to true”: (c ∈ B(r)⇒ r > c) ∧ (c = H(r)⇒ r < c) for all r ∈ δ′R, and\nϑ ∈ {(n,M ′, C∗ = C ′ ∪ {c}, R′ ∪R∗, L∗<, γ∗, γ∗<,∆) : L∗< ∈ (L′< + [c])}, with\n∆ = (δ′R, δ ′ M ∪ δ∗M , δ′h ∪ δ∗h, δ′b ∪ δ∗b , σ∗), where\nR∗ = {r ∈ n|R : C∗ |=n|C r}, γ∗ = γ′ ∪ {(c,Γ(c,M ′, n|A)}, γ∗< = γ ′ < ∪ {(c,Γ<(c,M ′, n|A, L∗<)},\nδ∗b = { {c} if ∃r ∈ δ′R : c ∈ B(r) ∅ otherwise,\nδ∗h ∈ { {{c}} if ∃r ∈ δ′R : c = H(r) {∅, {c}} otherwise,\nδ∗M = {a ∈M ′ : a ∈ Cl(c), c ∈ δ∗h, a > c}, and σ∗(c) = 1⇔ c ∈ δ∗h ∧ ∃r ∈ δR : H(r) = c.\nFor branch nodes, we extend (with slight abuse of notation) ≺T to a ternary relation.\nDefinition 12. Let ϑ = (n,M,C,R,L<, γ, γ<,∆), ϑ ′ = (n′,M ′, C ′, R′, L′<, γ ′, γ′<,∆ ′), and ϑ′′ = (n′′,M ′′, C ′′, R′′, L′′<, γ ′′, γ′′<,∆\n′′) be bag assignments for nodes n, n′, n′′ ∈ T with ∆ = (δR, δM , δh, δb, σ), ∆ ′ = (δ′R, δ ′ M , δ ′ h, δ ′ b, σ ′), and ∆′′ = (δ′′R, δ ′′ M , δ ′′ h, δ ′′ b , σ\n′′). We relate (ϑ′, ϑ′′) ≺T ϑ if n has two children n′ and n′′ and the following conditions are fulfilled.\n• M = M ′ = M ′′ C = C ′ = C ′′\n• R = R′ ∪R′′ L< = L′< = L′′<\n• γ(c) = γ′(c) + γ′′(c)− Γ(c,M, n|A) for all c ∈ n|C\n• γ<(c) = γ′<(c) + γ′′<(c)− Γ<(c,M, n|A, L<) for all c ∈ C\n• δR = δ′R = δ′′R δM = δ′M ∪ δ′′M\n• δh = δ′h = δ′′h δb = δ′b ∪ δ′′b\n• σ(c) = max{σ′(c), σ′′(c)} for all c ∈ δh\nWhat follows is a small example which demonstrates how this ≺T relation is used to solve the consistency problem for PCCs. Thereby we start with the only possible bag model ϑ = (n, ∅, ∅, ∅, [], ∅, ∅,∆) and ∆ = (∅, ∅, ∅, ∅, ∅) for each leaf node. Now we traverse through the tree decomposition and calculate for each node all the bag assignments according to the relation ≺T . Finally, we check whether for the root node any such bag assignment could be generated.\nExample 13. We are given a PCC Π = ({p1, p2}, {c1, c2}, {r1}) with c1 = ({(p1, 1)}, 1, 1), c2 = ({(¬p2, 1)}, 1, 1), and r1 = (c1, {c2}).\nIts incidence graph as well as a normalized tree decomposition of width 1 are depicted in Figure 2. What follows is a list of all the bag assignments that can be computed according to the relation ≺T , starting from the trivial bag assignments of the empty leaf nodes. Node n1: (L)\nϑ1 = (n1, ∅, ∅, ∅, [], ∅, ∅, (∅, ∅, ∅, ∅, ∅))\nNode n2: (p1-AI)\nϑ2,1 = (n2, ∅, ∅, ∅, [], ∅, ∅, (∅, ∅, ∅, ∅, ∅)) ϑ2,2 = (n2, {p1}, ∅, ∅, [p1], ∅, ∅, (∅, ∅, ∅, ∅, ∅))\nNode n3: (c1-CI)\nϑ3,1 = (n3, ∅, ∅, ∅, [], {(c1, 0)}, ∅, (∅, ∅, ∅, ∅, ∅)) ϑ3,2 = (n3, ∅, {c1}, ∅, [c1], {(c1, 0)}, {(c1, 0)}, (∅, ∅, ∅, ∅, ∅)) ϑ3,3 = (n3, ∅, {c1}, ∅, [c1], {(c1, 0)}, {(c1, 0)}, (∅, ∅, {c1}, ∅, {(c1, 0)})) ϑ3,4 = (n3, {p1}, ∅, ∅, [p1], {(c1, 1)}, ∅, (∅, ∅, ∅, ∅, ∅)) ϑ3,5 = (n3, {p1}, {c1}, ∅, [c1, p1], {(c1, 1)}, {(c1, 0)}, (∅, ∅, ∅, ∅, ∅)) ϑ3,6 = (n3, {p1}, {c1}, ∅, [c1, p1], {(c1, 1)}, {(c1, 0)}, (∅, {p1}, {c1}, ∅, {(c1, 0)})) ϑ3,7 = (n3, {p1}, {c1}, ∅, [p1, c1], {(c1, 1)}, {(c1, 1)}, (∅, ∅, ∅, ∅, ∅)) ϑ3,8 = (n3, {p1}, {c1}, ∅, [p1, c1], {(c1, 1)}, {(c1, 1)}, (∅, ∅, {c1}, ∅, {(c1, 0)}))\nNode n4: (p1-AR)\nϑ4,1 = (n4, ∅, ∅, ∅, [], {(c1, 0)}, ∅, (∅, ∅, ∅, ∅, ∅)) ϑ4,2 = (n4, ∅, {c1}, ∅, [c1], {(c1, 0)}, {(c1, 0)}, (∅, ∅, ∅, ∅, ∅)) ϑ4,3 = (n4, ∅, {c1}, ∅, [c1], {(c1, 0)}, {(c1, 0)}, (∅, ∅, {c1}, ∅, {(c1, 0)})) ϑ4,4 = (n4, ∅, {c1}, ∅, [c1], {(c1, 1)}, {(c1, 0)}, (∅, ∅, {c1}, ∅, {(c1, 0)}))\nNode n5: (r1-RI)\nϑ5,1 = (n5, ∅, ∅, ∅, [r1], {(c1, 0)}, ∅, (∅, ∅, ∅, ∅, ∅)) ϑ5,2 = (n5, ∅, {c1}, {r1}, [r1, c1], {(c1, 0)}, {(c1, 0)}, (∅, ∅, ∅, ∅, ∅)) ϑ5,3 = (n5, ∅, {c1}, {r1}, [c1, r1], {(c1, 0)}, {(c1, 0)}, (∅, ∅, ∅, ∅, ∅)) ϑ5,4 = (n5, ∅, {c1}, {r1}, [r1, c1], {(c1, 0)}, {(c1, 0)}, ({r1}, ∅, {c1}, ∅, {(c1, 1)})) ϑ5,5 = (n5, ∅, {c1}, {r1}, [r1, c1], {(c1, 0)}, {(c1, 0)}, (∅, ∅, {c1}, ∅, {(c1, 0)})) ϑ5,6 = (n5, ∅, {c1}, {r1}, [c1, r1], {(c1, 0)}, {(c1, 0)}, (∅, ∅, {c1}, ∅, {(c1, 0)})) ϑ5,7 = (n5, ∅, {c1}, {r1}, [r1, c1], {(c1, 1)}, {(c1, 0)}, ({r1}, ∅, {c1}, ∅, {(c1, 1)})) ϑ5,8 = (n5, ∅, {c1}, {r1}, [r1, c1], {(c1, 1)}, {(c1, 0)}, (∅, ∅, {c1}, ∅, {(c1, 0)})) ϑ5,9 = (n5, ∅, {c1}, {r1}, [c1, r1], {(c1, 1)}, {(c1, 0)}, (∅, ∅, {c1}, ∅, {(c1, 0)}))\nNode n6: (c1-CR)\nϑ6,1 = (n6, ∅, ∅, ∅, [r1], ∅, ∅, (∅, ∅, ∅, ∅, ∅)) ϑ6,2 = (n6, ∅, ∅, {r1}, [r1], ∅, ∅, ({r1}, ∅, ∅, ∅, ∅))\nThe branch of nodes n7 till n12 is very similar to nodes n1 till n6. Therefore we just present the bag assignments for n12.\nNode n12: (c2-CR)\nϑ12,1 = (n12, ∅, ∅, ∅, [r1], ∅, ∅, (∅, ∅, ∅, ∅, ∅)) ϑ12,2 = (n12, ∅, ∅, ∅, [r1], ∅, ∅, ({r1}, ∅, ∅, ∅, ∅))\nNode n13: (B)\nϑ13,1 = (n13, ∅, ∅, ∅, [r1], ∅, ∅, (∅, ∅, ∅, ∅, ∅)) ϑ13,2 = (n13, ∅, ∅, {r1}, [r1], ∅, ∅, ({r1}, ∅, ∅, ∅, ∅))\nNode n14: (r1-RR)\nϑ14 = (n14, ∅, ∅, ∅, [], ∅, ∅, (∅, ∅, ∅, ∅, ∅))\nSince ϑ14 could be derived, the example is a yes-instance of the consistency problem. Indeed it has exactly one answer set {p1}. a\nLet us look exemplarily at (CR) nodes in more detail. Consider nodes n which remove a constraint c, i.e., χ(n) = χ(n′) \\ {c}, where n′ is the child of n (see, for instance, the node with bag {p3, c3} in the left branch of TEx in Figure 1, which is a c4-removal node). Let ϑ′ = (n′,M ′, C ′, R′, L′<, γ ′, γ′<,∆ ′) with ∆′ = (δ′R, δ ′ M , δ ′ h, δ ′ b, σ ′) be a bag model for n′. We then create a bag model for n as follows: First we have to check whether the conditions c ∈ C ′ ⇔ l(c) ≤ γ′(c) ≤ u(c), c ∈ δ′h ⇒ σ′(c) = 1, and c ∈ δ′b ⇒ γ′<(c) ≥ l(c) are satisfied. Note that those checks correspond to the conditions 1, 10, and 8 of Definition 6. They ensure that all guesses with respect to c are correct. In the case of an affirmative answer, we remove c from all sets of ϑ′ in order to create the new bag model ϑ = (n,M ′, C ′ \\ {c}, R′, L′< − [c], γ′, γ′<,∆) with ∆ = (δ′R, δ ′ M , δ ′ h \\ {c}, δ′b \\ {c}, σ′).\nThe following two theorems state that the rules defined above indeed help in finding bag models.\nTheorem 14 (Soundness). Given a bag model ϑ′ (respectively bag models ϑ′ and ϑ′′). Then each bag assignment ϑ with ϑ′ ≺T ϑ (respectively (ϑ′, ϑ′′) ≺T ϑ) is a bag model.\nProof. Let ϑ′ be a bag model for n′ ∈ T and let ϑ be a bag assignment for node n ∈ T with ϑ′ ≺T ϑ. Then n′ is the single child of n, with n being of type (RR), (RI), (AR), (AI), (CR), or (CI). Assume n is a (r-RR) node. According to Definition 11, we have r ∈ R′ with ϑ and ϑ′ differing only in R = R′ \\ {r}, L< = L′< − [r], and δR = δ′R \\ {r}. Since ϑ′ is a bag model, there exists a partial solution ϑ̂ of n′, satisfying all the conditions of Definition 9.\nClaim: ϑ̂ is also a partial solution of n. To verify this claim, we have to check the conditions of Definition 6. Since n′⇓C = n⇓C , n′↓C = n↓C , n′⇓A = n⇓A, n′↓A = n↓A, and n′↓R = n↓R, the only non-trivial condition is number 2 where we have to check n⇓R ⊆ R̂. Since r ∈ R′ and R′ = R̂ ∩ n′|R, we have r ∈ R̂. Hence, from n′⇓R ⊆ R̂ follows that n⇓R = n′⇓R ∪ {r} ⊆ R̂.\nFurthermore, the projection of ϑ̂ to the bag χ(n) is exactly ϑ, since ϑ′ and ϑ differ only by the fact, that r is removed from every set in ϑ. Therefore ϑ is a bag model. Analogously the theorem can be checked for the other five node types above.\nNow let ϑ′ and ϑ′′ be bag models for n′, n′′ ∈ T and let ϑ be a bag assignment for node n ∈ T with (ϑ′, ϑ′′) ≺T ϑ. Then n has two children n′ and n′′ and all the properties of Definition 12 are satisfied. Since ϑ′ and ϑ′′ are bag models, there exist partial solutions ϑ̂′ of n′ and ϑ̂′′ of n′′. Using these two partial solutions we construct ϑ̂ = (n, M̂ ′ ∪ M̂ ′′, Ĉ ′ ∪ Ĉ ′′, R̂′ ∪ R̂′′, L̂<, γ̂, γ̂<, ∆̂) with ∆̂ = (δ̂′R ∪ δ̂′′R, δ̂′M ∪ δ̂′′M , δ̂′h ∪ δ̂′′h, δ̂′b ∪ δ̂′′b , σ̂). Thereby L̂< ∈ (L̂′< + L̂′′<),\nγ̂(c) =  γ̂′(c) c ∈ n′⇓C , γ̂′′(c) c ∈ n′′⇓C , γ̂′(c) + γ̂′′(c)− Γ(c, n|M̂ , n|A) otherwise,\nγ̂<(c) =  γ̂′<(c) c ∈ n′⇓C , γ̂′′<(c) c ∈ n′′⇓C , γ̂′<(c) + γ̂ ′′ <(c)− Γ<(c, n|M̂ , n|A, L̂<) otherwise,\nσ̂(c) =  σ̂′(c) c ∈ δ̂′h \\ δ̂′′h, σ̂′′(c) c ∈ δ̂′′h \\ δ̂′h, max{σ̂′(c), σ̂′′(c)} otherwise.\nOne can now check the conditions of Definition 6 in order to verify that ϑ̂ is a partial solution for n. Furthermore, our construction ensures that the projection of ϑ̂ to the bag χ(n) is exactly ϑ, which is therefore a bag model.\nTheorem 15 (Completeness). Given a bag model ϑ for node n ∈ T . Then either n is a leaf node, or there exists a bag model ϑ′ (respectively two bag models ϑ′ and ϑ′′) with ϑ′ ≺T ϑ (respectively (ϑ′, ϑ′′) ≺T ϑ).\nProof. Again, we have to distinguish between the node type of n. For instance, let n ∈ T be an (r-RR) node with child n′, let ϑ be a bag model for n. We have to show that there exists a bag model ϑ′ for n′ with ϑ′ ≺T ϑ. Since ϑ is a bag model, there exists a partial solution ϑ̂ of n, satisfying all the conditions of Definition 9. From r ∈ n⇓R follows, that r ∈ R̂. Now consider the projection of ϑ̂ onto the bag of n′. Then the result is a bag model ϑ′ of n′ satisfying the conditions of Definition 9 and having r ∈ R′. But then it is easy to check, that ϑ′ ≺T ϑ, which closes the proof for (RR) nodes. Analogously the theorem can be checked for the other six node types.\nTheorem 14 and Theorem 15 show, that starting from the trivial bag models for empty leafs, the dynamic programming algorithm creates all bag models for the root node. According to Proposition 10, those bag models are all we need to know. Thus, this dynamic programming algorithm solves the consistency problem.\nTheorem 16. The consistency problem for PCCs Π can be solved in time O(26ww!k4w · ‖Π‖) with w = tw(Π) and k = cw(Π).\nProof. We first show that the number of different bag models at each node n ∈ T is bounded. The number of possible sets M,C,R is bounded by 2w, there are at most w! different orderings L<, the number of cardinality functions γ, γ< is bounded by k\n2w, the number of possible sets δR, δh as well as δM , δb is bounded by 2\nw each, and finally the number of check functions σ is bounded by 2w. This leads to at most 24ww!k2w many different bag models at node n. At each node the effort to compute a single bag model is constant with the exception of branch nodes, where one has to compare possible pairs of bag models of each child node. Thereby only pairs are combined which have identical M,C,R,L<, δR, δh. This means for each bag model of the first child node there are at most 22wk2w (the number of possible functions/sets γ, γ<, δM , δb, σ) bag\nmodels at the second child to consider. The time per node is therefore bounded by 26ww!k4w and since the number of nodes in our tree decomposition is bounded by O(‖Π‖), the total time of O(26ww!k4w · ‖Π‖) follows."
    }, {
      "heading" : "6 Extensions",
      "text" : "In this section, we discuss some extensions of our dynamic programming approach and of Theorem 16.\nPWCs with unary weights. Our dynamic programming algorithm for the consistency problem of PCCs can be easily extended to PWCs with unary representation both, of the weights and of the constraint bounds (PWCs with unary weights, for short).\nTheorem 17. Given an arbitrary PWC Π. The consistency problem for PWCs with unary weights can be solved in time O(26ww!k4w · ‖Π‖) with w = max(3, tw(Π)) and k = cw(Π).\nProof. It suffices to show that every PWC Π with unary weights can be efficiently transformed into a PCC Π′ such that Π is only linearly bigger than Π, the constraint-width remains the same, and the treewidth is max(3, tw(Π)). The transformation from Π to Π′ processes each literal ` with weight j > 1 in each constraint c of Π as follows: reduce the weight of ` to 1 and add j − 1 fresh atoms `2, . . . , `j (each of weight 1) to c. Moreover, we add, for α ∈ {2, . . . , j}, new constraints cα := ({(`, 1), (¬`α, 1)}, 1, 1) and new rules rα := (cα, ∅) to ensure that the fresh variables `2, . . . , `j have the same truth value as ` in every model of Π. It is easy to check that Π′ is only linearly bigger than Π (since j is given in unary representation) and that the constraint-width and treewidth are not increased (resp. changed from treewidth ≤ 2 to treewidth 3).\nReasoning with PCCs and PWCs with unary weights. In non-monotonic reasoning, two kinds of reasoning are usually considered, namely skeptical and credulous reasoning. Recall that an atom a is skeptically implied by a program Π if a is true (i.e., contained) in every stable model of Π. Likewise, an atom a is credulously implied by Π if a is true in some stable model of Π. Our algorithm for the consistency problem can be easily extended to an algorithm for skeptical or credulous reasoning with PCCs and PWCs with unary weights. The above upper bounds on the complexity thus carry over from the consistency problem to the reasoning problems. We only work out the PCC-case below:\nTheorem 18. Both the skeptical and the credulous reasoning problem for PCCs Π can be solved in time O(26ww!k4w · ‖Π‖) with w = tw(Π) and k = cw(Π).\nProof. Suppose that we are given a PCC Π and an atom a. The dynamic programming algorithm for the consistency problem has to be extended in such a way that we additionally maintain two flags cr(ϑ) and sk(ϑ) for every bag assignment ϑ. These flags may take one of the values {⊥,>} with the intended meaning that cr(ϑ) = > (resp. sk(ϑ) = >) if and only if there exists a partial solution ϑ̂ = (n, M̂, . . . ), (resp. if and only if for all partial solutions ϑ̂ = (n, M̂, . . . )) the atom a is true in M̂ . Otherwise this flag is set to ⊥. Then a is credulously (resp. skeptically) implied by Π if and only if there exists a bag model (resp. if and only if for all bag models) ϑ of the root node nroot of T , we have cr(ϑ) = > (resp. sk(ϑ) = >). Clearly, maintaining the two flags fits within the desired complexity bound.\nBounded treewidth and bounded constraint-width. Recall that we have proved the fixedparameter linearity of the consistency problem of PWCs when treewidth and constraint-width are taken as parameter (see Theorem 3). This fixed-parameter linearity result (as well as the\nanalogous result for the skeptical and credulous reasoning problem which can be easily seen to be expressible in MSO logic) could also be obtained as a corollary of Theorem 17. Indeed, consider a PWC Π whose treewidth w and constraint-width k are bounded by some fixed constant. By previous considerations, we may thus assume that all weights occurring in Π are bounded by a constant. Therefore, we can transform all weights and bounds into unary representation such that the size of the resulting PWC with unary weights differs from ‖Π‖ only by a constant factor (namely 2k). The upper bound on the complexity in Theorem 17 immediately yields the desired fixed-parameter linearity result since f(w) ·O(k2w) is bounded by a constant that is independent of the size of Π."
    }, {
      "heading" : "7 W[1]-Hardness",
      "text" : "In this section we will show that it is unlikely that one can improve the non-uniform polynomialtime result of Theorem 16 to a fixed-parameter tractability result (without bounding the constraint-width as in Theorem 3). We will develop our hardness result within the framework of parameterized complexity. Therefore we first outline some of the main concepts of the subject, for an in-depth treatment we refer to other sources [6, 7, 15].\nAn instance of a parameterized problem is a pair (x, k), where x is the main part and k (usually a non-negative integer) is the parameter. A parameterized problem is fixed-parameter tractable if an instance (x, k) of size n can be solved in time O(f(k)nc) where f is a computable function and c is a constant independent of k. If c = 1 then we speak of linear-time fixed-parameter tractability. FPT denotes the class of all fixed-parameter tractable decision problems. Parameterized complexity theory offers a completeness theory similar to the theory of NP-completeness. An fpt-reduction from a parameterized decision problem P to a parameterized decision problem Q is a transformation that maps an instance (x, k) of P of size n to an instance (x′, k′) of Q with k′ ≤ g(k) in time O(f(k)nc) (f, g are arbitrary computable functions, c is a constant) such that (x, k) is a yes-instance of P if and only if (x′, k′) is a yes-instance of Q. A parameterized complexity class C is the class of parameterized decision problems fpt-reducible to a certain parameterized decision problem Q. A parameterized problem P is C-hard, if every problem in C is fpt-reducible to P . Problem P is called C-complete, if it is additionally contained in C. Of particular interest is the class W [1] which is considered as the parameterized analog to NP. For example, the Clique problem (given a graph G and an integer k, decide whether G contains a complete subgraph on k vertices), parameterized by k, is a well-known W [1]-complete problem. It is believed that FPT 6= W [1], and there is strong theoretical evidence that supports this belief, for example, FPT = W [1] would imply that the Exponential Time Hypothesis fails, see [7].\nIn the proof of Theorem 19 below we will devise an fpt-reduction from the Minimum Maximum Outdegree problem (or MMO, for short). To state this problem we need to introduce some concepts. A (positive integral) edge weighting of a graph H = (V,E) is a mapping w that assigns to each edge of H a positive integer. An orientation of H is a mapping Λ : E → V × V with Λ({u, v}) ∈ {(u, v), (v, u)}. The weighted outdegree of a vertex v ∈ V with respect to an edge weighting w and an orientation Λ is defined as\nd+H,w,Λ(v) = ∑\n{v,u}∈E with Λ({v,u})=(v,u)\nw({v, u}).\nAn instance of MMO consists of a graph H, an edge weighting w of H, and a positive integer r; the question is whether there exists an orientation Λ of H such that d+H,w,Λ(v) ≤ r for each v ∈ V . The MMO problem with edge weights (and therefore also r) given in unary is W [1]-hard when parameterized by the treewidth of H [17].\nTheorem 19. The consistency problem for PCCs is W [1]-hard when parameterized by treewidth.\nProof. Let (H,w, r) be an instance of MMO of treewidth t, H = (V,E). We may assume that no edge is of weight larger than r since otherwise we can reject the instance. Let ≺ be an arbitrary linear ordering of V . We form a PWC Π = (A, C,R) with unary weights as follows: The set A contains an atom auv = avu for each edge {u, v} ∈ E; C contains a constraint cv = (Sv, 0, r) for each vertex v ∈ V where Sv = { (auv, w({v, u})) : {u, v} ∈ E, v ≺ u } ∪ { (¬auv, w({v, u})) : {u, v} ∈ E, u ≺ v }; R contains a rule rv = (cv, ∅) for each vertex v ∈ V .\nClaim 1. tw(Π) ≤ max(2, t). Let (T, χ) be a tree decomposition of H of width t. We extend (T, χ) to a tree decomposition of Π as follows. For each edge {u, v} ∈ E we pick a node nuv of T with u, v ∈ χ(nuv) and for each vertex v ∈ V we pick a node nv of T with v ∈ χ(nv) (such nodes exist by the definition of a tree decomposition). We attach to nuv a new neighbor n ′ uv (of degree 1) and put χ(n′uv) = {u, v, auv}, and we attach to nv a new neighbor n′v (of degree 1) and put χ(n′v) = {v, rv}. It is easy to verify that we obtain this way a tree decomposition of Π of width max(t, 2), hence the claim follows. Note that in fact we have tw(Π) ≥ tw(H) since H is a graph minor of the incidence graph of Π.\nClaim 2. H has an orientation Λ with maxv∈V d + H,w,Λ(v) ≤ r if and only if Π has a model. We associate with an orientation Λ the subset AΛ = { auv ∈ AΛ : u ≺ v and Λ({u, v}) = (u, v) }. This gives a natural one-to-one correspondence between orientations of H and subsets of A. We observe that for each v ∈ V , the sum of weights of the literals in constraint cv satisfied by AΛ is exactly the weighted outdegree of v with respect to Λ. Hence AΛ is a model of Π if and only if d+H,w,Λ(v) ≤ r for all v ∈ V .\nClaim 3. All models of Π are stable. This claim follows by exactly the same argument as in the proof of Theorem 2.\nΠ can certainly be obtained from (H,w, r) in polynomial time. We can even encode the weights of literals in unary since we assumed that that the edge weighting w is given in unary. Hence, by Claims 1–3 we have an fpt-reduction from MMO to the consistency problem for PWCs with unary weights. Using the construction as described in the proof of Theorem 17, we can transform Π in polynomial time into a decision-equivalent PCC Π′ by increasing the treewidth at most by a small constant. In total we have an fpt-reduction from MMO to the consistency problem for PCCs (both problems parameterized by treewidth). The theorem now follows by the W [1]-hardness of MMO for parameter treewidth."
    }, {
      "heading" : "8 Discussion",
      "text" : "In this work, we have proved several results for PWCs and PCCs of bounded treewidth without addressing the problem of actually computing a tree decomposition of appropriate width. As has been mentioned earlier, [1] showed that deciding if a graph has treewidth ≤ w and, if this is the case, computing a tree decomposition of width w is fixed-parameter linear for parameter w. Unfortunately, this linear time algorithm is only of theoretical interest and the practical usefulness is limited [12]. However, considerable progress has been recently made in developing heuristic-based tree decomposition algorithms which can handle graphs with moderate size of several hundreds of vertices [12, 2, 19, 3, 10].\nRecently a meta-theorem for MSO problems on graphs with cardinality and weight constraints was shown [18]. This meta-theorem allows one to handle cardinality constraints with respect to sets that occur as free variables in the corresponding MSO formula. It provides a polynomial time algorithm for checking whether a PCC (or a PWC with weights in unary) of bounded treewidth has a model. However, in order to check whether a PCC has a stable model, one needs to handle cardinality constraints with respect to sets that occur as quantified variables in the MSO formula, which is not possible with the above mentioned meta-theorem.\nWe have already mentioned a dynamic programming algorithm for ASP [9]. This algorithm works for programs without cardinality or weight constraints, but possibly with disjunction in the head of the rules. The data structure manipulated at each node for this ASP algorithm is\nconceptually much simpler than the one used here: Potential models of the given program are represented by so-called tree-models. A tree-model consists of a subset of the atoms in a bag (the ones which are true in the models thus represented) and a subset of the rules in a bag (the ones which are validated by the models thus represented). However, to handle the minimality condition on stable models, it is not sufficient to propagate potential models along the bottomup traversal of the tree decomposition. In addition, it is required, for each potential model M , to keep track of all those models of the reduct w.r.t. M which would prevent M from being minimal. Those models are represented by a set of tree-models accompanying each tree-model. Hence, despite the simplicity of the data structure, the time complexity of the algorithm from [9] is double exponential in the treewidth, since it has to handle sets of subsets of the bag at each node. Therefore, rather than extending that algorithm by mechanisms to handle weight or cardinality constraints, we have presented here an algorithm based on a completely different data structure – in particular, keeping track of orderings of the atoms. We have thus managed to obtain an algorithm whose time complexity is single exponential in the treewidth."
    }, {
      "heading" : "9 Conclusion",
      "text" : "In this paper we have shown how the notion of bounded treewidth can be used to identify tractable fragments of answer-set programming with weight constraints. However, by proving hardness results, we have also shown that a straightforward application of treewidth is not sufficient to achieve the desired tractability.\nThe upper bounds on the time complexity of our dynamic programming algorithms were obtained by very coarse estimates (see Theorems 16, 17, 18). In particular, we assumed straightforward methods for storing and manipulating bag assignments. For an actual implementation of our algorithm, we plan to use the SHARP framework2, a C++ interface that enables rapid development of algorithms which are based on tree or hypertree decompositions by providing (hyper-)tree decomposition routines and algorithm interfaces. It thus allows the designer to focus on the problem-specific part of the algorithm. SHARP itself uses the htdecomp library3 which implements several heuristics for (hyper)tree decompositions, see also [5]. Using sophisticated methods and data structures in implementing the functionality of the different node types of our algorithm should eventually result in a further improvement of the (theoretical) upper bounds on the time complexity provided in this paper.\nFor future work, we plan to extend the parameterized complexity analysis and the development of efficient algorithms to further problems where weights or cardinalities play a role. Note that weights are a common feature in the area of knowledge representation and reasoning, for instance, to express costs or probabilities."
    } ],
    "references" : [ {
      "title" : "A linear-time algorithm for finding tree-decompositions of small treewidth",
      "author" : [ "H.L. Bodlaender" ],
      "venue" : "SIAM J. Comput.,",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1996
    }, {
      "title" : "Safe separators for treewidth",
      "author" : [ "H.L. Bodlaender", "A.M.C.A. Koster" ],
      "venue" : "Discrete Mathematics,",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2006
    }, {
      "title" : "Combinatorial optimization on graphs of bounded treewidth",
      "author" : [ "H.L. Bodlaender", "A.M.C.A. Koster" ],
      "venue" : "Comput. J.,",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2008
    }, {
      "title" : "Recognizability and second-order definability for sets of finite graphs",
      "author" : [ "B. Courcelle" ],
      "venue" : "Technical Report I-8634, Université de Bordeaux,",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 1987
    }, {
      "title" : "Heuristic methods for hypertree decomposition",
      "author" : [ "A. Dermaku", "T. Ganzow", "G. Gottlob", "B.J. McMahan", "N. Musliu", "M. Samer" ],
      "venue" : "In Proc. MICAI,",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2008
    }, {
      "title" : "Parameterized Complexity",
      "author" : [ "R.G. Downey", "M.R. Fellows" ],
      "venue" : null,
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 1999
    }, {
      "title" : "Parameterized Complexity Theory",
      "author" : [ "J. Flum", "M. Grohe" ],
      "venue" : null,
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 2006
    }, {
      "title" : "Bounded treewidth as a key to tractability of knowledge representation and reasoning",
      "author" : [ "G. Gottlob", "R. Pichler", "F. Wei" ],
      "venue" : "Artif. Intell.,",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2010
    }, {
      "title" : "Answer-set programming with bounded treewidth",
      "author" : [ "M. Jakl", "R. Pichler", "S. Woltran" ],
      "venue" : "In C. Boutilier, editor, Proc. IJCAI’09,",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 2009
    }, {
      "title" : "Pushing the power of stochastic greedy ordering schemes for inference in graphical models",
      "author" : [ "K. Kask", "A. Gelfand", "L. Otten", "R. Dechter" ],
      "venue" : "Proc. AAAI’11,",
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2011
    }, {
      "title" : "Treewidth, Computations and Approximations",
      "author" : [ "T. Kloks" ],
      "venue" : null,
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 1994
    }, {
      "title" : "Treewidth: Computational experiments",
      "author" : [ "A.M.C.A. Koster", "H.L. Bodlaender", "S.P.M. van Hoesel" ],
      "venue" : "Electronic Notes in Discrete Mathematics,",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 2001
    }, {
      "title" : "Level mapping induced loop formulas for weight constraint and aggregate programs",
      "author" : [ "G. Liu" ],
      "venue" : "Proc. LPNMR’09,",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 2009
    }, {
      "title" : "Stable models and an alternative logic programming paradigm",
      "author" : [ "V.W. Marek", "M. Truszczyński" ],
      "venue" : "The Logic Programming Paradigm: A 25-Year Perspective,",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 1999
    }, {
      "title" : "Invitation to Fixed-Parameter Algorithms",
      "author" : [ "R. Niedermeier" ],
      "venue" : null,
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2006
    }, {
      "title" : "Stable model semantics of weight constraint rules",
      "author" : [ "I. Niemelä", "P. Simons", "T. Soininen" ],
      "venue" : "Proc. LPNMR’99,",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 1999
    }, {
      "title" : "Not so easy problems for tree decomposable graphs. In Advances in discrete mathematics and applications: Mysore, 2008, volume",
      "author" : [ "S. Szeider" ],
      "venue" : "Ramanujan Math. Soc. Lect. Notes Ser.,",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2010
    }, {
      "title" : "Monadic second order logic on graphs with local cardinality constraints",
      "author" : [ "S. Szeider" ],
      "venue" : "ACM Trans. Comput. Log.,",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2011
    }, {
      "title" : "Safe reduction rules for weighted treewidth",
      "author" : [ "F. van den Eijkhof", "H.L. Bodlaender", "A.M.C.A. Koster" ],
      "venue" : null,
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2007
    } ],
    "referenceMentions" : [ {
      "referenceID" : 13,
      "context" : "Answer-set programming (ASP) has evolved as a paradigm that allows for very elegant solutions to many combinatorial problems [14].",
      "startOffset" : 125,
      "endOffset" : 129
    }, {
      "referenceID" : 15,
      "context" : "By extending logic programs with cardinality or, more generally, weight constraints, an even larger class of problems is accessible to this method [16].",
      "startOffset" : 147,
      "endOffset" : 151
    }, {
      "referenceID" : 7,
      "context" : "In the area of knowledge representation and reasoning (KR & R), many tractability results for instances of bounded treewidth have been recently proven [8].",
      "startOffset" : 151,
      "endOffset" : 154
    }, {
      "referenceID" : 0,
      "context" : "Technically, we prove that the consistency problem of PCCs parameterized by treewidth is hard for the parameterized complexity class W [1].",
      "startOffset" : 135,
      "endOffset" : 138
    }, {
      "referenceID" : 0,
      "context" : "By giving a W [1]-hardness proof in case of unary representation in Section 7, we show that it is unlikely that this result can be significantly improved.",
      "startOffset" : 14,
      "endOffset" : 17
    }, {
      "referenceID" : 15,
      "context" : "Following [16], the reduct c of a constraint c ∈ C w.",
      "startOffset" : 10,
      "endOffset" : 14
    }, {
      "referenceID" : 10,
      "context" : "A tree decomposition (T, χ) is called normalized (or nice) [11], if T is a rooted tree and the following conditions hold: (1) each n ∈ T has ≤ 2 children; (2) for each n ∈ T with two children n1, n2, χ(n) = χ(n1) = χ(n2); and (3) for each n ∈ T with one child n′, χ(n) and χ(n′) differ in exactly one element.",
      "startOffset" : 59,
      "endOffset" : 63
    }, {
      "referenceID" : 10,
      "context" : "It is known that every tree decomposition can be normalized in linear time without increasing the width [11].",
      "startOffset" : 104,
      "endOffset" : 108
    }, {
      "referenceID" : 0,
      "context" : "For arbitrary but fixed w ≥ 1, it is feasible in linear time to decide whether a graph has treewidth ≤ w and, if so, to compute a tree decomposition of width w, see [1].",
      "startOffset" : 165,
      "endOffset" : 168
    }, {
      "referenceID" : 3,
      "context" : "To prove this result we shall take a logic approach and use Courcelle’s Theorem [4], see also [6, 7].",
      "startOffset" : 80,
      "endOffset" : 83
    }, {
      "referenceID" : 5,
      "context" : "To prove this result we shall take a logic approach and use Courcelle’s Theorem [4], see also [6, 7].",
      "startOffset" : 94,
      "endOffset" : 100
    }, {
      "referenceID" : 6,
      "context" : "To prove this result we shall take a logic approach and use Courcelle’s Theorem [4], see also [6, 7].",
      "startOffset" : 94,
      "endOffset" : 100
    }, {
      "referenceID" : 0,
      "context" : "The latter is no restriction for proving Theorem 3, since by Bodlaender’s Theorem [1], we can compute in linear time a tree decomposition of smallest width for graphs whose treewidth is bounded by a constant.",
      "startOffset" : 82,
      "endOffset" : 85
    }, {
      "referenceID" : 8,
      "context" : "Recently, [9] presented a dynamic programming algorithm for answer-set programming that works for programs without cardinality or weight constraints, but possibly with disjunction in the head of the rules.",
      "startOffset" : 10,
      "endOffset" : 13
    }, {
      "referenceID" : 12,
      "context" : "Slightly rephrasing a result by [13] we can characterize answer sets of PCCs as follows:",
      "startOffset" : 32,
      "endOffset" : 36
    }, {
      "referenceID" : 0,
      "context" : "7 W[1]-Hardness",
      "startOffset" : 3,
      "endOffset" : 6
    }, {
      "referenceID" : 5,
      "context" : "Therefore we first outline some of the main concepts of the subject, for an in-depth treatment we refer to other sources [6, 7, 15].",
      "startOffset" : 121,
      "endOffset" : 131
    }, {
      "referenceID" : 6,
      "context" : "Therefore we first outline some of the main concepts of the subject, for an in-depth treatment we refer to other sources [6, 7, 15].",
      "startOffset" : 121,
      "endOffset" : 131
    }, {
      "referenceID" : 14,
      "context" : "Therefore we first outline some of the main concepts of the subject, for an in-depth treatment we refer to other sources [6, 7, 15].",
      "startOffset" : 121,
      "endOffset" : 131
    }, {
      "referenceID" : 0,
      "context" : "Of particular interest is the class W [1] which is considered as the parameterized analog to NP.",
      "startOffset" : 38,
      "endOffset" : 41
    }, {
      "referenceID" : 0,
      "context" : "For example, the Clique problem (given a graph G and an integer k, decide whether G contains a complete subgraph on k vertices), parameterized by k, is a well-known W [1]-complete problem.",
      "startOffset" : 167,
      "endOffset" : 170
    }, {
      "referenceID" : 0,
      "context" : "It is believed that FPT 6= W [1], and there is strong theoretical evidence that supports this belief, for example, FPT = W [1] would imply that the Exponential Time Hypothesis fails, see [7].",
      "startOffset" : 29,
      "endOffset" : 32
    }, {
      "referenceID" : 0,
      "context" : "It is believed that FPT 6= W [1], and there is strong theoretical evidence that supports this belief, for example, FPT = W [1] would imply that the Exponential Time Hypothesis fails, see [7].",
      "startOffset" : 123,
      "endOffset" : 126
    }, {
      "referenceID" : 6,
      "context" : "It is believed that FPT 6= W [1], and there is strong theoretical evidence that supports this belief, for example, FPT = W [1] would imply that the Exponential Time Hypothesis fails, see [7].",
      "startOffset" : 187,
      "endOffset" : 190
    }, {
      "referenceID" : 0,
      "context" : "The MMO problem with edge weights (and therefore also r) given in unary is W [1]-hard when parameterized by the treewidth of H [17].",
      "startOffset" : 77,
      "endOffset" : 80
    }, {
      "referenceID" : 16,
      "context" : "The MMO problem with edge weights (and therefore also r) given in unary is W [1]-hard when parameterized by the treewidth of H [17].",
      "startOffset" : 127,
      "endOffset" : 131
    }, {
      "referenceID" : 0,
      "context" : "The consistency problem for PCCs is W [1]-hard when parameterized by treewidth.",
      "startOffset" : 38,
      "endOffset" : 41
    }, {
      "referenceID" : 0,
      "context" : "The theorem now follows by the W [1]-hardness of MMO for parameter treewidth.",
      "startOffset" : 33,
      "endOffset" : 36
    }, {
      "referenceID" : 0,
      "context" : "As has been mentioned earlier, [1] showed that deciding if a graph has treewidth ≤ w and, if this is the case, computing a tree decomposition of width w is fixed-parameter linear for parameter w.",
      "startOffset" : 31,
      "endOffset" : 34
    }, {
      "referenceID" : 11,
      "context" : "Unfortunately, this linear time algorithm is only of theoretical interest and the practical usefulness is limited [12].",
      "startOffset" : 114,
      "endOffset" : 118
    }, {
      "referenceID" : 11,
      "context" : "However, considerable progress has been recently made in developing heuristic-based tree decomposition algorithms which can handle graphs with moderate size of several hundreds of vertices [12, 2, 19, 3, 10].",
      "startOffset" : 189,
      "endOffset" : 207
    }, {
      "referenceID" : 1,
      "context" : "However, considerable progress has been recently made in developing heuristic-based tree decomposition algorithms which can handle graphs with moderate size of several hundreds of vertices [12, 2, 19, 3, 10].",
      "startOffset" : 189,
      "endOffset" : 207
    }, {
      "referenceID" : 18,
      "context" : "However, considerable progress has been recently made in developing heuristic-based tree decomposition algorithms which can handle graphs with moderate size of several hundreds of vertices [12, 2, 19, 3, 10].",
      "startOffset" : 189,
      "endOffset" : 207
    }, {
      "referenceID" : 2,
      "context" : "However, considerable progress has been recently made in developing heuristic-based tree decomposition algorithms which can handle graphs with moderate size of several hundreds of vertices [12, 2, 19, 3, 10].",
      "startOffset" : 189,
      "endOffset" : 207
    }, {
      "referenceID" : 9,
      "context" : "However, considerable progress has been recently made in developing heuristic-based tree decomposition algorithms which can handle graphs with moderate size of several hundreds of vertices [12, 2, 19, 3, 10].",
      "startOffset" : 189,
      "endOffset" : 207
    }, {
      "referenceID" : 17,
      "context" : "Recently a meta-theorem for MSO problems on graphs with cardinality and weight constraints was shown [18].",
      "startOffset" : 101,
      "endOffset" : 105
    }, {
      "referenceID" : 8,
      "context" : "We have already mentioned a dynamic programming algorithm for ASP [9].",
      "startOffset" : 66,
      "endOffset" : 69
    }, {
      "referenceID" : 8,
      "context" : "Hence, despite the simplicity of the data structure, the time complexity of the algorithm from [9] is double exponential in the treewidth, since it has to handle sets of subsets of the bag at each node.",
      "startOffset" : 95,
      "endOffset" : 98
    }, {
      "referenceID" : 4,
      "context" : "SHARP itself uses the htdecomp library which implements several heuristics for (hyper)tree decompositions, see also [5].",
      "startOffset" : 116,
      "endOffset" : 119
    } ],
    "year" : 2012,
    "abstractText" : "Cardinality constraints or, more generally, weight constraints are well recognized as an important extension of answer-set programming. Clearly, all common algorithmic tasks related to programs with cardinality or weight constraints – like checking the consistency of a program – are intractable. Many intractable problems in the area of knowledge representation and reasoning have been shown to become linear time tractable if the treewidth of the programs or formulas under consideration is bounded by some constant. The goal of this paper is to apply the notion of treewidth to programs with cardinality or weight constraints and to identify tractable fragments. It will turn out that the straightforward application of treewidth to such class of programs does not suffice to obtain tractability. However, by imposing further restrictions, tractability can be achieved.",
    "creator" : "TeX"
  }
}