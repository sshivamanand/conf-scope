{
  "name" : "288.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "The Effect of Different Writing Tasks on Linguistic Style: A Case Study of the ROC Story Cloze Task",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "1 000\n011\n012\n013\n014\n015\n016\n017\n018\n019\n020\n021\n022\n023\n024\n025\n026\n027\n028\n029\n030\n031\n032\n033\n034\n035\n036\n037\n038\n039\n040\n041\n042\n043\n044\n045\n046\n047\n048\n049\n080\n081\n082\n083\n084\n085\n086\n087\n088\n089\n090\n091\n092\n093\n094\n095\n096\n097\n098\n099"
    }, {
      "heading" : "1 Introduction",
      "text" : "Writing style is expressed through a range of linguistic elements such as words, sentence structure, and rhetorical devices. It is influenced by personal factors such as age and gender (Schler et al., 2006), by personality traits such as agreeableness and openness (Ireland and Mehl, 2014), as well as by mental states such as sentiment (Davidov et al., 2010), sarcasm (Tsur et al., 2010), and deception (Feng et al., 2012). In this paper, we study the extent to which writing style is affected by the nature of the writing task the writer was asked to perform, since different tasks likely engage different cognitive processes (Campbell and Pennebaker, 2003;\nBanerjee et al., 2014).\nWe show that similar writing tasks with different constraints on the author can lead to measurable differences in her writing style. As a case study, we present experiments based on the recently introduced ROC story cloze task (Mostafazadeh et al., 2016a). In this task, authors were asked to write five-sentence self-contained stories, henceforth original stories. Then, each original story was given to a different author, who was shown only the first four sentences as a story context, and asked to write two contrasting story endings: a right (coherent) ending, and a wrong\n2\n101\n102\n103\n104\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n123\n124\n125\n126\n127\n128\n129\n130\n131\n132\n133\n134\n135\n136\n137\n138\n139\n140\n141\n142\n143\n144\n145\n146\n147\n148\n149\n150\n151\n152\n153\n154\n155\n156\n157\n158\n159\n160\n161\n162\n163\n164\n165\n166\n167\n168\n169\n170\n171\n172\n173\n174\n175\n176\n177\n178\n179\n180\n181\n182\n183\n184\n185\n186\n187\n188\n189\n190\n191\n192\n193\n194\n195\n196\n197\n198\n199\n(incoherent) ending. Framed as a story cloze task, the goal of this dataset is to serve as a commonsense challenge for NLP and AI research. Table 1 shows an example of an original story, a coherent story, and an incoherent story.\nWhile the story cloze task was originally designed to be a story understanding challenge, its annotation process introduced three variants of the same writing task: writing an original, right, or wrong ending to a short story. In this paper, we show that a linear classifier informed by stylistic features can distinguish among the different endings to a large degree, even without looking at the story context (64.5–75.6% binary classification results).\nOur results allow us to make a few key observations. First, people adopt a different writing style when asked to write coherent vs. incoherent story endings. Second, people change their writing style when writing the entire story on their own compared to writing only the final sentence for a given story context written by someone else.\nIn order to further validate our method, we also directly tackle the story cloze task. Adapting our classifier to the task, we obtain 72.4% accuracy, a 12.5% increase over the previously reported stateof-the-art (Salle et al., 2016). We also show that the style differences captured by our model can be combined with neural language models to make a better use of the story context. Our final model that combines context with stylistic features achieves 75.2%—an additional 2.8% gain, 15.3% better than the best published result.\nThe contributions of our study are threefold. First, findings from our study can potentially shed light on how different kinds of cognitive load influence the style of written language. Second, our results indicate that when designing new NLP tasks, special attention needs to be payed to the instructions given to authors. Third, we establish a new state-of-the-art result on the commonsense story cloze challenge."
    }, {
      "heading" : "2 Background: The Story Cloze Task",
      "text" : "To understand how different writing tasks affect writing style, we focus on the story cloze task (Mostafazadeh et al., 2016a). While this task was developed to facilitate representation and learning of commonsense story understanding, its design included a few key choices which make it ideal for our study. We describe the task below.\nROC stories. The ROC story corpus consists of 49,255 five-sentence commonsense stories, collected on Amazon Mechanical Turk (AMT).1 Workers were instructed to write a coherent selfcontained story, which has a clear beginning and end. To collect a broad spectrum of commonsense knowledge, there was no imposed subject for the stories, which resulted in a wide range of different topics.\nStory cloze task. After compiling the story corpus, the story cloze task—a task based on the corpus—was introduced. A subset of the stories was selected, and only the first four sentences of each story were presented to AMT workers. Workers were asked to write a pair of new story endings for each story context: one right and one wrong. Both endings are required to complete the story using one of the characters in the story context. Additionally, the ending is required to be “realistic and sensible” (Mostafazadeh et al., 2016a) when read out of context.\nThe resulting stories, both right and wrong, were then individually rated for coherence and meaningfulness by additional AMT workers. Only stories rated as simultaneously coherent with a right ending and neutral with a wrong ending were selected for the task. It is worth noting that workers rated the stories as a whole, not only the endings.\nBased on the new stories, Mostafazadeh et al. (2016a) proposed the story cloze task. The task is simple: given a pair of stories that differ only in their endings, the system decides which ending is right and which is wrong. The official training data contains only the original stories (without alternative endings), while development and test data consist of the revised stories with alternative endings (for a different set of original stories that are not included in the training set). The task was suggested as an extensive evaluation framework: as a commonsense story understanding task, as the shared task for the Linking Models of Lexical, Sentential and Discourse-level Semantics workshop (LSDSem 2017), and as a testbed for vectorspace evaluation (Mostafazadeh et al., 2016b).\nInterestingly, at the time of this submission, 10 months after the task was first introduced, the published benchmark on this task is still below\n1Recently, an additional 53K stories were released, which results in roughly 100K stories.\n3\n201\n202\n203\n204\n205\n206\n207\n208\n209\n210\n211\n212\n213\n214\n215\n216\n217\n218\n219\n220\n221\n222\n223\n224\n225\n226\n227\n228\n229\n230\n231\n232\n233\n234\n235\n236\n237\n238\n239\n240\n241\n242\n243\n244\n245\n246\n247\n248\n249\n250\n251\n252\n253\n254\n255\n256\n257\n258\n259\n260\n261\n262\n263\n264\n265\n266\n267\n268\n269\n270\n271\n272\n273\n274\n275\n276\n277\n278\n279\n280\n281\n282\n283\n284\n285\n286\n287\n288\n289\n290\n291\n292\n293\n294\n295\n296\n297\n298\n299\n60% (Salle et al., 2016).2 This comes in contrast to other recent similar machine reading tasks such as CNN/DailyMail (Hermann et al., 2015), SNLI (Bowman et al., 2015), LAMBADA (Paperno et al., 2016) and SQuAD (Rajpurkar et al., 2016), for which results improved dramatically over a similar or shorter period of time. This suggests that this task is challenging and that high performance is hard to achieve.\nIn addition, Mostafazadeh et al. (2016a) made substantial efforts to ensure the quality of this dataset. First, each pair of endings was written by the same author, which ensured that style differences between authors could not be used to solve the task. Furthermore, Mostafazadeh et al. implemented nine baselines for the task, using surface level features as well as narrative-informed ones, and showed that each of them reached roughly chance-level. These results suggest that real understanding of text is required in order to solve the task.\nDifferent writing tasks in the story cloze task. Several key design decisions make the task an interesting testbed for the purpose of this study. First, the training set for the task (ROC Stories corpus) is not a training sample in the usual sense,3 as it contains only positive (right) samples, and not negative (wrong) ones.\nOn top of that, the original endings, which serve as positive training samples, were generated differently from the right samples, which serve as the positive samples in the development and test sets. While the former are part of a single coherent story written by the same author, the latter were generated by letting an author read four sentences, and then asking her to generate a fifth right ending.\nFinally, although the right and wrong sentences were generated by the same author, the tasks for generating them were quite different: in one case, the author was asked to write a right ending, which would create a coherent five-sentence story along with the other four sentences. In the other case, the author was asked to write a wrong ending, which would result in an incoherent five-sentence story.\n2The LSDSem 2017 shared task website (https: //competitions.codalab.org/competitions/ 15333) does report higher results, which are still unpublished along with the underlying methodology.\n3I.e., the training instances are not drawn from a population similar to the one that future testing instances will be drawn from."
    }, {
      "heading" : "3 Surface Analysis of the Story Cloze Task",
      "text" : "We begin by computing several characteristics of the three types of endings: original endings (from the ROC story corpus training set), right endings and wrong endings (both from the story cloze task development set). Our analysis reveals several style differences between different groups. First, original endings are on average longer (11 words per sentence) than right endings (8.75 words), which are in turn slightly longer than wrong ones (8.47 words). Previous work has shown that sentence length is also indicative of whether a text was deceptive (Yancheva and Rudzicz, 2013; Qin et al., 2004). Although writing wrong sentences is not the same as lying, it is not entirely surprising to observe similar trends in both tasks.\nSecond, Figure 1a shows the distribution of five frequent POS tags in all three groups. The figure shows that both original and right endings use pronouns more frequently than wrong endings. Once again, deceptive text is also characterized by fewer pronouns compared to truthful text (Newman et al., 2003).\nFinally, Figure 1b presents the distribution of five frequent words across the different groups. The figure shows that original endings use coordinations (“and”) more than right endings, and substantially more than wrong ones. Furthermore, original and right endings seem to prefer enthusiastic language (e.g., “!”), while wrong endings tend to use more negative language (“hates”), similarly as deceptive text (Newman et al., 2003). Next we show that these style differences are not anecdotal, but can be used to distinguish among the different types of story endings."
    }, {
      "heading" : "4 Model",
      "text" : "The goal of this paper is to determine the extent to which different writing constraints lead the authors to adopt different writing styles. In order to answer these questions, we use simple methods that have been shown to be very effective for recognizing style (see Section 9). We describe our model below.\nWe train a logistic regression classifier to categorize an ending, either as right vs. wrong or as original vs. new (right). Each feature vector is computed using the words in one ending, without considering earlier parts of the story. We use the following style features.\n4\n301\n302\n303\n304\n305\n306\n307\n308\n309\n310\n311\n312\n313\n314\n315\n316\n317\n318\n319\n320\n321\n322\n323\n324\n325\n326\n327\n328\n329\n330\n331\n332\n333\n334\n335\n336\n337\n338\n339\n340\n341\n342\n343\n344\n345\n346\n347\n348\n349\n350\n351\n352\n353\n354\n355\n356\n357\n358\n359\n360\n361\n362\n363\n364\n365\n366\n367\n368\n369\n370\n371\n372\n373\n374\n375\n376\n377\n378\n379\n380\n381\n382\n383\n384\n385\n386\n387\n388\n389\n390\n391\n392\n393\n394\n395\n396\n397\n398\n399\noriginal right wrong\n5\n10 15 Fr eq ue nc y in C\nor pu\ns (%\n) NN VBD PRP DT NNP\n(a) POS tags\noriginal right wrong 0\n1\n2\n3\nto and I hates !\n(b) Words\nFigure 1: The distribution of five frequent POS tags (1a) and words (1b) across original endings (story cloze training set), and right and wrong endings (from the story cloze task).\n• Length. The number of words in the sentence.\n• Word n-grams. We use sequences of 1-5 words. Following Tsur et al. (2010) and Schwartz et al. (2013b), we distinguish between high frequency and low frequency words. Specifically, we replace content words (nouns, verbs, adjectives, and adverbs), which are often low frequency, with their part-of-speech tags.\n• Character n-grams. Character n-grams are one of the most useful features in identifying author style (Stamatatos, 2009). We use character 4-grams."
    }, {
      "heading" : "5 Experiments",
      "text" : "We design two experiments to answer our research questions. The first is an attempt to distinguish between right and wrong endings, the second between original endings and new (right) endings. We describe both experiments below.\nExperiment 1: right/wrong endings. The goal of this experiment is to measure the extent to which style features capture differences between the right and wrong endings. As the story cloze task doesn’t have a training corpus for the right and wrong endings (see Section 2), we use the development set as our training set, holding out 10% for development (3,366 training endings, 374 for development). We keep the story cloze test set as is (3,742 endings).\nIt is worth noting that our classification task is slightly different from the story cloze task. Instead of classifying pairs of endings, one which is right and another which is wrong, our classifier decides about each ending individually, whether it\nis right (positive instance) or wrong (negative instance). By ignoring the coupling between right and wrong pairs, we are able to decrease the impact of author-specific style differences, and focus on the difference between the styles accompanied with right and wrong writings.\nExperiment 2: original/new endings. Here the goal is to measure whether writing the ending as part of a story imposes different style compared to writing a new (right) ending to an existing story. We use the endings of the ROC stories as our original samples and right endings from the story cloze task as new samples. As there are far more original instances than new instances, we randomly select the same number of original instances as we have new instances (3,366 training endings, 374 development endings, and 3,742 test endings). We randomly sample 5 original sets and repeat the classification experiments. We report the average classification result.\nExperimental setup. In both experiments, we add a START symbol at the beginning of each sentence.4 For computing our features, we keep ngram (character or word) features that occur at least five times in the training set. All feature values are normalized to [0, 1]. For the POS features, we tag all endings with the Spacy POS tagger.5 We use Python’s sklearn logistic regression implementation (Pedregosa et al., 2011) with L2 regularization, performing grid search on the development set to tune a single hyperparameter—the regularization parameter.\n4Virtually all sentences end with a period or an exclamation mark, so we do not add a STOP symbol.\n5http://spacy.io/\n5\n401\n402\n403\n404\n405\n406\n407\n408\n409\n410\n411\n412\n413\n414\n415\n416\n417\n418\n419\n420\n421\n422\n423\n424\n425\n426\n427\n428\n429\n430\n431\n432\n433\n434\n435\n436\n437\n438\n439\n440\n441\n442\n443\n444\n445\n446\n447\n448\n449\n450\n451\n452\n453\n454\n455\n456\n457\n458\n459\n460\n461\n462\n463\n464\n465\n466\n467\n468\n469\n470\n471\n472\n473\n474\n475\n476\n477\n478\n479\n480\n481\n482\n483\n484\n485\n486\n487\n488\n489\n490\n491\n492\n493\n494\n495\n496\n497\n498\n499\nExperiment Accuracy right vs. wrong 0.645 original vs. right 0.685 original vs. wrong 0.756\nTable 2: Results of experiments 1 (right vs. wrong) and 2 (original vs. right (new)). The bottom row shows an additional experiment which classifies original vs. wrong (new) endings. In all cases, our setup implies a 50% random baseline."
    }, {
      "heading" : "6 Results",
      "text" : "Table 2 shows our results. In both experiments, our model achieves performance well above what would be expected under chance (50% by design). Noting again that our model ignores the story context (the preceding four sentences), our model is unable to capture any notion of coherence. This finding provides strong evidence that the authors’ style was affected by the writing task they were given to perform. We further applied the model to a third task, original vs. wrong (new) endings, and even stronger differences were apparent to the model, allowing over 75% accuracy.\nStory cloze task. The results of Experiment 1 indicate that right and wrong endings are characterized by different styles. In order to further estimate the quality of our classification results, we tackle the story cloze task using our classifier. This classification task is more constrained than Experiment 1, as two endings are given and the question is which is right and which is wrong. We apply the classifier from Experiment 1 as follows: if it assigns different labels to the two given endings, we keep them. Otherwise, the label whose posterior probability is lower is reversed.\nTable 3 shows our results on the story cloze test set. Our classifier obtains 72.4% accuracy, 12.5% (absolute) higher than the published state-of-theart result on the task (Salle et al., 2016). Importantly, unlike previous approaches, our classifier does not require the story corpus training data, and in fact doesn’t even consider the first four sentences of the story in question. These numbers further support the claim that the styles of right and wrong endings are indeed very different.\nCombination with a neural language model. We investigate whether our model can benefit from state-of-the-art text comprehension models,\nModel Acc. †DSSM (Mostafazadeh et al., 2016a) 0.585 †LexVec (Salle et al., 2016) 0.599 †RNN 0.677 Ours 0.724 †Combined (ours + RNN) 0.752 †Human judgment 1.000\nTable 3: Results on the test set of the story cloze task. The upper block shows published results, the middle block are our results. LexVec results are taken from (Speer et al., 2016). Human judgement scores are taken from (Mostafazadeh et al., 2016a). Methods marked with (†) use the story context in order to make a prediction.\nfor which this task was designed. Specifically, we experiment with an LSTM-based (Hochreiter and Schmidhuber, 1997) recurrent neural network language model (RNNLM; Mikolov et al., 2010). Unlike the model in this paper, which only considers the story endings, this language model follows the protocol suggested by the story cloze task designers, and harnesses their ROC Stories training set, which consists of single-ending stories, as well as the story context for each pair of endings. We show that adding our features to this powerful language model gives improvements over our classifier as well as the language model.\nWe train the RNNLM using a single-layer LSTM of hidden dimension 512. We use the ROC stories for training,6 setting aside 10% for validation of the language model. We replace all words occurring less than 3 times with a special out-ofvocabulary character, yielding a vocabulary size of 21,582. Only during training, we apply a dropout rate of 60% while running the LSTM over all 5 sentences of the stories. Using the Adam optimizer (Kingma and Ba, 2015) and a learning rate of η = .001, we train to minimize cross-entropy.\nTo apply the language model to the classification problem, we select as right the ending with the higher value of\npθ(ending | story) pθ(ending)\n(1)\nThe intuition is that a right ending should be unsurprising (to the model) given the four preceding\n6We use the extended, 100K stories corpus (see Section 2).\n6\n501\n502\n503\n504\n505\n506\n507\n508\n509\n510\n511\n512\n513\n514\n515\n516\n517\n518\n519\n520\n521\n522\n523\n524\n525\n526\n527\n528\n529\n530\n531\n532\n533\n534\n535\n536\n537\n538\n539\n540\n541\n542\n543\n544\n545\n546\n547\n548\n549\n557\n558\n559\n560\n561\n562\n563\n564\n565\n566\n567\n568\n569\n570\n571\n572\n573\n574\n575\n576\n577\n578\n579\n580\n581\n582\n583\n584\n585\n586\n587\n588\n589\n590\n591\n592\n593\n594\n595\n596\n597\n598\n599\nFeature Type Accuracy Word n-grams 0.612\nCharacter n-grams 0.639 Full model 0.645\nTable 4: Results on Experiment 1 with different subsets of features.\nsentences of the story (the numerator), controlling for the inherent surprisingness of the words in that ending (the denominator).\nOn its own, our neural language model performs moderately well on the story cloze test. Selecting endings based on pθ(ending | story) (i.e., the numerator of Equation 1), we obtained only 55% accuracy. The ratio in Equation 1 achieves 67.7% (see Table 3).7\nWe combine our linear model with the RNNLM by adding three features to our classifier: the numerator, denominator, and ratio in Equation 1, all in log space. We retrain our linear model with the new feature set, and gain 2.8% absolute, reaching 75.2% (15.3% better than the published state-ofthe-art result). These results indicate that contextignorant style features can be used to obtain high accuracy on the task, adding value even when context and a large training dataset are used."
    }, {
      "heading" : "7 Further Analysis",
      "text" : ""
    }, {
      "heading" : "7.1 Most Discriminative Feature Types",
      "text" : "A natural question that follows this study is which style features are most helpful in detecting the underlying task an author was asked to perform. To answer this question, we re-ran Experiment 1 with different sub-groups of features. Table 4 shows our results. Results show that character n-grams are the most effective style predictors, reaching within 0.6% of the full model, but that word ngrams also capture much of the signal, yielding 61.2%, which is only 3.3% worse than the full model. These findings are in line with previous work that used character n-grams along with other types of features to predict writing style (Schwartz et al., 2013b)."
    }, {
      "heading" : "7.2 Most Salient Features",
      "text" : "A follow-up question is which individual features contribute most to the classification process, as\n7Note that taking the logarithm of the expression in Equation 1 gives the pointwise mutual information between the story and the ending, under the language model.\nthese could shed light on the stylistic differences imposed by each of the writing tasks.\nIn order to answer this question, we consider the highest absolute positive and negative coefficients in the logistic regression classifier in both Experiments 1 and 2, an approach widely used as a method of extracting the most salient features (Nguyen et al., 2013; Burke et al., 2013; Brooks et al., 2013). It is worth noting that its reliability is not entirely clear, since linear models like logistic regression can assign large coefficients to rare features (Yano et al., 2012). To mitigate this concern, we consider only features appearing in at least 5% of the endings in our training set.\nExperiment 1. Table 5 shows the most salient features for right (coherent) and wrong (incoherent) endings in Experiment 1, along with their corpus frequency. The table shows a few interesting trends. First, authors tend to structure their sentences differently when writing coherent vs. incoherent endings. For instance, incoherent endings are more likely to start with a proper noun and end with a common noun, while coherent endings have a greater tendency to end with a past tense verb.\nSecond, right endings will make wider use of coordination structures, as well as adjectives. The latter might indicate that writing coherent stories inspires the authors to write more descriptive text compared to incoherent ones, as is the case in truthful vs. deceptive text (Ott et al., 2011). Finally, we notice a few syntactic differences: right endings will more often use infinite verb structure, while wrong endings prefer gerunds (VBG).\nExperiment 2. Table 6 shows the same analysis for Experiment 2. As noted in Section 2, original endings tend to be much longer, which is indeed the most salient feature for them. An interesting observation is that exclamation marks are a strong indication for an original ending. This suggests\n7\n601\n602\n603\n604\n605\n606\n607\n608\n609\n610\n611\n612\n613\n614\n615\n616\n617\n618\n619\n620\n621\n622\n623\n624\n625\n626\n627\n628\n629\n630\n631\n632\n633\n634\n635\n636\n637\n638\n639\n640\n641\n642\n643\n644\n645\n646\n647\n648\n649\n650\n651\n652\n653\n654\n655\n656\n657\n658\n659\n660\n661\n662\n663\n664\n665\n666\n667\n668\n669\n670\n671\n672\n673\n674\n675\n676\n677\n678\n679\n680\n681\n682\n683\n684\n685\n686\n687\n688\n689\n690\n691\n692\n693\n694\n695\n696\n697\n698\n699\nOriginal Freq. New Freq. length .100.0% ‘.’ 93.0% ‘!’ 006.1% START NNP 39.2% NN 0078.9% START NNP VBD 29.0% RB 044.7% NN . 42.3% ‘,’ 012.7% the NN . 10.6%\nTable 6: The top 5 most heavily weighted features for predicting original vs. new (right) endings. length is the sentence length feature (see Section 4).\nthat authors are more likely to show or evoke enthusiasm when writing their own text compared to ending an existing task.\nFinally, when comparing the two groups of salient features from both experiments, we find an interesting trend. Several features, such as “START NNP” and “NN .”, which indicate wrong sentences in Experiment 1, are used to predict new (i.e., right) endings in Experiment 2. This indicates that, for instance, incoherent endings have a stronger tendency to begin with a proper noun compared to coherent endings, which in turn are more likely to do so than original endings. This partially explains why distinguishing between original and wrong endings is an easier task compared to the other pairs (Section 6)."
    }, {
      "heading" : "8 Discussion",
      "text" : "The effect of writing tasks on mental states. In this paper we have shown that giving a writer different writing tasks affects her writing style in easily detected ways. Our results indicate that when authors are asked to write the last sentence of a five-sentence story, they will use different style to write a right ending compared to a wrong ending. We have also shown that writing the ending as part of one’s own five-sentence story is very different than reading four sentences and then writing the fifth. Our findings hint that the nature of the writing task imposes a different mental state on the author, which is expressed in ways that can be observed using extremely simple automatic tools.\nPrevious work has shown that a writing task can affect mental state. For instance, writing deceptive text leads to a significant cognitive burden accompanied by a writing style that is different from truthful text (Newman et al., 2003; Banerjee et al., 2014). Writing tasks can even have a long-term\neffect, as writing emotional texts was observed to benefit both physical and mental health (Lepore and Smyth, 2002; Frattaroli, 2006). Campbell and Pennebaker (2003) also showed that the health benefits of writing emotional text are accompanied by changes in writing style, mostly in the use of pronouns.\nAnother line of work has shown that writing style is affected by mental state. First, an author’s personality traits (e.g., depression, neuroticism, narcissism) affect her writing style (Schwartz et al., 2013a; Ireland and Mehl, 2014). Second, temporary changes, such as a romantic relationship (Ireland et al., 2011; Bowen et al., 2016), work collaboration (Tausczik, 2009; Gonzales et al., 2009), or negotiation (Ireland and Henderson, 2014) may also affect writing style. Finally, writing style can also change from one sentence to another, for instance between positive and negative text (Davidov et al., 2010) or when writing sarcastic text (Tsur et al., 2010).\nThis large body of work indicates a tight connection between writing tasks, mental states, and variation in writing style. This connection hints that the link discovered in this paper, between different writing tasks and resulting variation in writing style, involves differences in mental state. Further investigation is required in order to further validate this hypothesis.\nDesign of NLP tasks. Our study also provides important insights for the future design of NLP tasks. The story cloze task was very carefully designed. Many factors, such as topic diversity and temporal and causal relation diversity, were controlled for (Mostafazadeh et al., 2016a). The authors also made sure each pair of endings was written by the same author, partly in order to avoid author-specific style effects. Nonetheless, despite these efforts, several significant style differences can be found between the training and the test set, as well as between the positive and negative labels.\nOur findings suggest that careful attention must be paid to instructions given to authors, especially in unnatural tasks such as writing a wrong ending. One way to avoid such problems is by using shorter text spans, such as the ones used in the Winograd schema (Levesque, 2011). A different approach is to use naturally occurring text, as used in recent machine reading tasks (see Section 9). One way to avoid the inherent biases people have when writing is to have them rate sentences from\n8\n701\n702\n703\n704\n705\n706\n707\n708\n709\n710\n711\n712\n713\n714\n715\n716\n717\n718\n719\n720\n721\n722\n723\n724\n725\n726\n727\n728\n729\n730\n731\n732\n733\n734\n735\n736\n737\n738\n739\n740\n741\n742\n743\n744\n745\n746\n747\n748\n749\n750\n751\n752\n753\n754\n755\n756\n757\n758\n759\n760\n761\n762\n763\n764\n765\n766\n767\n768\n769\n770\n771\n772\n773\n774\n775\n776\n777\n778\n779\n780\n781\n782\n783\n784\n785\n786\n787\n788\n789\n790\n791\n792\n793\n794\n795\n796\n797\n798\n799\nnaturally occurring text by parameters such as coherence (or, very differently, the level of surprise), rather than asking them to generate new text."
    }, {
      "heading" : "9 Related Work",
      "text" : "Writing style. Writing style has been an active topic of research for decades. The models used to characterize style are often linear classifiers with style features such as character and word n-grams (Stamatatos, 2009; Koppel et al., 2009). Previous work has shown that different authors can be grouped by their writing style, according to factors such as age (Pennebaker and Stone, 2003; Argamon et al., 2003; Schler et al., 2006; Rosenthal and McKeown, 2011; Nguyen et al., 2011), gender (Argamon et al., 2003; Schler et al., 2006; Bamman et al., 2014), and native language (Koppel et al., 2005; Tsur and Rappoport, 2007; Bergsma et al., 2012). At the extreme case, each individual author adopts a unique writing style (Mosteller and Wallace, 1963; Pennebaker and King, 1999; Schwartz et al., 2013b).\nThe line of work that most resembles our work is the detection of deceptive text. Several researchers have used stylometric features to predict deception (Newman et al., 2003; Hancock et al., 2007; Ott et al., 2011; Feng et al., 2012). Some works even showed that gender affects a person’s writing style when lying (Pérez-Rosas and Mihalcea, 2014a,b). In this work, we have shown that an even more subtle writing task—writing coherent and incoherent story endings—imposes different styles on the author.\nMachine reading. The story cloze task, which is the focus of this paper, is part of a wide set of machine reading/comprehension challenges published in the last few years. These include datasets like bAbI (Weston et al., 2016), SNLI (Bowman et al., 2015), CNN/DailyMail (Hermann et al., 2015), LAMBADA (Paperno et al., 2016) and SQuAD (Rajpurkar et al., 2016). While these works have presented resources for researchers, it is often the case that these datasets suffer from methodological problems caused by applying noisy automatic tools to generate them (Chen et al., 2016). In this paper, we have pointed to another methodological challenge in designing machine reading tasks: different writing tasks used to generated the data affect writing style, confounding classification problems."
    }, {
      "heading" : "10 Conclusion",
      "text" : "Different writing tasks assigned to an author result in different writing styles for that author. We experimented with the story cloze task, which introduces two interesting comparison points: the difference between writing a story on one’s own and continuing someone else’s story, and the difference between writing a coherent and an incoherent story ending. In both cases, a simple linear model reveals measurable differences in writing styles, which in turn allows our final model to achieve state-of-the-art results on the story cloze task.\nThe findings presented in this paper have cognitive implications, as they motivate further research on the effects that a writing prompt has on an author’s mental state, and also her concrete response. They also provide valuable lessons for designing new NLP datasets."
    } ],
    "references" : [ {
      "title" : "Gender, genre, and writing style in formal written texts",
      "author" : [ "Shlomo Argamon", "Moshe Koppel", "Jonathan Fine", "Anat Rachel Shimoni." ],
      "venue" : "Text 23(3):321– 346.",
      "citeRegEx" : "Argamon et al\\.,? 2003",
      "shortCiteRegEx" : "Argamon et al\\.",
      "year" : 2003
    }, {
      "title" : "Gender identity and lexical variation in social media",
      "author" : [ "David Bamman", "Jacob Eisenstein", "Tyler Schnoebelen." ],
      "venue" : "Journal of Sociolinguistics 18(2):135– 160.",
      "citeRegEx" : "Bamman et al\\.,? 2014",
      "shortCiteRegEx" : "Bamman et al\\.",
      "year" : 2014
    }, {
      "title" : "Keystroke patterns as prosody in digital writings: A case study with deceptive reviews and essays",
      "author" : [ "Ritwik Banerjee", "Song Feng", "Jun S. Kang", "Yejin Choi." ],
      "venue" : "Proc. of EMNLP. http://www.aclweb.org/anthology/D14-1155.",
      "citeRegEx" : "Banerjee et al\\.,? 2014",
      "shortCiteRegEx" : "Banerjee et al\\.",
      "year" : 2014
    }, {
      "title" : "Stylometric analysis of scientific articles",
      "author" : [ "Shane Bergsma", "Matt Post", "David Yarowsky." ],
      "venue" : "Proc. of NAACL. http://www.aclweb.org/anthology/N121033.",
      "citeRegEx" : "Bergsma et al\\.,? 2012",
      "shortCiteRegEx" : "Bergsma et al\\.",
      "year" : 2012
    }, {
      "title" : "Language style matching in romantic partners? conflict and support interactions",
      "author" : [ "Jeffrey D. Bowen", "Lauren A. Winczewski", "Nancy L. Collins." ],
      "venue" : "Journal of Language and Social Psychology 0(0):1–24.",
      "citeRegEx" : "Bowen et al\\.,? 2016",
      "shortCiteRegEx" : "Bowen et al\\.",
      "year" : 2016
    }, {
      "title" : "A large annotated corpus for learning natural language inference",
      "author" : [ "Samuel R. Bowman", "Gabor Angeli", "Christopher Potts", "Christopher D. Manning." ],
      "venue" : "Proc. of EMNLP.",
      "citeRegEx" : "Bowman et al\\.,? 2015",
      "shortCiteRegEx" : "Bowman et al\\.",
      "year" : 2015
    }, {
      "title" : "Statistical affect detection in collaborative chat",
      "author" : [ "Michael Brooks", "Katie Kuksenok", "Megan K. Torkildson", "Daniel Perry", "John J. Robinson", "Taylor J. Scott", "Ona Anicello", "Ariana Zukowski", "Paul Harris", "Cecilia R. Aragon." ],
      "venue" : "Proc. of CSCW.",
      "citeRegEx" : "Brooks et al\\.,? 2013",
      "shortCiteRegEx" : "Brooks et al\\.",
      "year" : 2013
    }, {
      "title" : "Families on facebook",
      "author" : [ "Moira Burke", "Lada A. Adamic", "Karyn Marciniak." ],
      "venue" : "Proc. of ICWSM.",
      "citeRegEx" : "Burke et al\\.,? 2013",
      "shortCiteRegEx" : "Burke et al\\.",
      "year" : 2013
    }, {
      "title" : "The secret life of pronouns flexibility in writing style and physical health",
      "author" : [ "R. Sherlock Campbell", "James W. Pennebaker." ],
      "venue" : "Psychological Science 14(1):60–65.",
      "citeRegEx" : "Campbell and Pennebaker.,? 2003",
      "shortCiteRegEx" : "Campbell and Pennebaker.",
      "year" : 2003
    }, {
      "title" : "A thorough examination of the CNN/Daily Mail reading comprehension task",
      "author" : [ "Danqi Chen", "Jason Bolton", "Christopher D. Manning." ],
      "venue" : "Proc. of ACL. http://www.aclweb.org/anthology/P16-1223.",
      "citeRegEx" : "Chen et al\\.,? 2016",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2016
    }, {
      "title" : "Enhanced sentiment learning using twitter hashtags and smileys",
      "author" : [ "Dmitry Davidov", "Oren Tsur", "Ari Rappoport." ],
      "venue" : "Proc. of COLING.",
      "citeRegEx" : "Davidov et al\\.,? 2010",
      "shortCiteRegEx" : "Davidov et al\\.",
      "year" : 2010
    }, {
      "title" : "Syntactic stylometry for deception detection",
      "author" : [ "Song Feng", "Ritwik Banerjee", "Yejin Choi." ],
      "venue" : "Proc. of ACL.",
      "citeRegEx" : "Feng et al\\.,? 2012",
      "shortCiteRegEx" : "Feng et al\\.",
      "year" : 2012
    }, {
      "title" : "Experimental disclosure and its moderators: a meta-analysis",
      "author" : [ "Joanne Frattaroli." ],
      "venue" : "Psychological bulletin 132(6):823.",
      "citeRegEx" : "Frattaroli.,? 2006",
      "shortCiteRegEx" : "Frattaroli.",
      "year" : 2006
    }, {
      "title" : "Language style matching as a predictor of social dynamics in small groups",
      "author" : [ "Amy L. Gonzales", "Jeffrey T. Hancock", "James W. Pennebaker." ],
      "venue" : "Communication Research 37(1):3–19.",
      "citeRegEx" : "Gonzales et al\\.,? 2009",
      "shortCiteRegEx" : "Gonzales et al\\.",
      "year" : 2009
    }, {
      "title" : "On lying and being lied to: A linguistic analysis of deception in computer-mediated communication",
      "author" : [ "Jeffrey T. Hancock", "Lauren E. Curry", "Saurabh Goorha", "Michael Woodworth." ],
      "venue" : "Discourse Processes 45(1):1–23.",
      "citeRegEx" : "Hancock et al\\.,? 2007",
      "shortCiteRegEx" : "Hancock et al\\.",
      "year" : 2007
    }, {
      "title" : "Teaching machines to read and comprehend",
      "author" : [ "Karl Moritz Hermann", "Tomáš Kočiský", "Edward Grefenstette", "Lasse Espeholt", "Will Kay", "Mustafa Suleyman", "Phil Blunsom." ],
      "venue" : "Proc. of NIPS.",
      "citeRegEx" : "Hermann et al\\.,? 2015",
      "shortCiteRegEx" : "Hermann et al\\.",
      "year" : 2015
    }, {
      "title" : "Long short-term memory",
      "author" : [ "Sepp Hochreiter", "Jürgen Schmidhuber." ],
      "venue" : "Neural Computation 9(8):1735–1780.",
      "citeRegEx" : "Hochreiter and Schmidhuber.,? 1997",
      "shortCiteRegEx" : "Hochreiter and Schmidhuber.",
      "year" : 1997
    }, {
      "title" : "Language style matching, engagement, and impasse in negotiations",
      "author" : [ "Molly E. Ireland", "Marlone D. Henderson." ],
      "venue" : "Negotiation and Conflict Management Research 7(1):1–16.",
      "citeRegEx" : "Ireland and Henderson.,? 2014",
      "shortCiteRegEx" : "Ireland and Henderson.",
      "year" : 2014
    }, {
      "title" : "Natural language use as a marker of personality, Oxford University Press, USA, pages 201–237",
      "author" : [ "Molly E. Ireland", "Matthias R. Mehl." ],
      "venue" : "The Oxford Handbook of Language and Social Psychology.",
      "citeRegEx" : "Ireland and Mehl.,? 2014",
      "shortCiteRegEx" : "Ireland and Mehl.",
      "year" : 2014
    }, {
      "title" : "Language style matching predicts relationship initiation and stability",
      "author" : [ "Molly E. Ireland", "Richard B. Slatcher", "Paul W. Eastwick", "Lauren E. Scissors", "Eli J. Finkel", "James W. Pennebaker." ],
      "venue" : "Psychological Science 22(1):39–44.",
      "citeRegEx" : "Ireland et al\\.,? 2011",
      "shortCiteRegEx" : "Ireland et al\\.",
      "year" : 2011
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "Diederik Kingma", "Jimmy Ba." ],
      "venue" : "Proc. of ICLR.",
      "citeRegEx" : "Kingma and Ba.,? 2015",
      "shortCiteRegEx" : "Kingma and Ba.",
      "year" : 2015
    }, {
      "title" : "Computational methods in authorship attribution",
      "author" : [ "Moshe Koppel", "Jonathan Schler", "Shlomo Argamon." ],
      "venue" : "Journal of the American Society for information Science and Technology 60(1):9–26.",
      "citeRegEx" : "Koppel et al\\.,? 2009",
      "shortCiteRegEx" : "Koppel et al\\.",
      "year" : 2009
    }, {
      "title" : "Determining an author’s native language by mining a text for errors",
      "author" : [ "Moshe Koppel", "Jonathan Schler", "Kfir Zigdon." ],
      "venue" : "Proc. of KDD.",
      "citeRegEx" : "Koppel et al\\.,? 2005",
      "shortCiteRegEx" : "Koppel et al\\.",
      "year" : 2005
    }, {
      "title" : "The writing cure: How expressive writing promotes health and emotional well-being",
      "author" : [ "Stephen J. Lepore", "Joshua M. Smyth." ],
      "venue" : "American Psychological Association.",
      "citeRegEx" : "Lepore and Smyth.,? 2002",
      "shortCiteRegEx" : "Lepore and Smyth.",
      "year" : 2002
    }, {
      "title" : "The winograd schema challenge",
      "author" : [ "Hector J. Levesque." ],
      "venue" : "Proc. of Commonsense.",
      "citeRegEx" : "Levesque.,? 2011",
      "shortCiteRegEx" : "Levesque.",
      "year" : 2011
    }, {
      "title" : "Recurrent neural network based language model",
      "author" : [ "Tomáš Mikolov", "Martin Karafiát", "Lukáš Burget", "Jan Černocký", "Sanjeev Khudanpur." ],
      "venue" : "Proc. of Interspeech.",
      "citeRegEx" : "Mikolov et al\\.,? 2010",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2010
    }, {
      "title" : "A corpus and cloze evaluation for deeper understanding of commonsense stories",
      "author" : [ "Nasrin Mostafazadeh", "Nathanael Chambers", "Xiaodong He", "Devi Parikh", "Dhruv Batra", "Lucy Vanderwende", "Pushmeet Kohli", "James Allen." ],
      "venue" : "Proc. of NAACL.",
      "citeRegEx" : "Mostafazadeh et al\\.,? 2016a",
      "shortCiteRegEx" : "Mostafazadeh et al\\.",
      "year" : 2016
    }, {
      "title" : "2016b. Story cloze evaluator: Vector space representation evaluation by predicting what happens next",
      "author" : [ "Nasrin Mostafazadeh", "Lucy Vanderwende", "Wen-tau Yih", "Pushmeet Kohli", "James Allen" ],
      "venue" : null,
      "citeRegEx" : "Mostafazadeh et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Mostafazadeh et al\\.",
      "year" : 2016
    }, {
      "title" : "Inference in an authorship problem",
      "author" : [ "Frederick Mosteller", "David L. Wallace." ],
      "venue" : "Journal of the American Statistical Association 58(302):275–309.",
      "citeRegEx" : "Mosteller and Wallace.,? 1963",
      "shortCiteRegEx" : "Mosteller and Wallace.",
      "year" : 1963
    }, {
      "title" : "Lying words: Predicting deception from linguistic styles",
      "author" : [ "Matthew L. Newman", "James W. Pennebaker", "Diane S. Berry", "Jane M. Richards." ],
      "venue" : "Personality and Social Psychology Bulletin 29(5):665–675.",
      "citeRegEx" : "Newman et al\\.,? 2003",
      "shortCiteRegEx" : "Newman et al\\.",
      "year" : 2003
    }, {
      "title" : "how old do you think i am?” a study of language and age in twitter",
      "author" : [ "Dong Nguyen", "Rilana Gravel", "Dolf Trieschnigg", "Theo Meder." ],
      "venue" : "Proc. of ICWSM.",
      "citeRegEx" : "Nguyen et al\\.,? 2013",
      "shortCiteRegEx" : "Nguyen et al\\.",
      "year" : 2013
    }, {
      "title" : "Author age prediction from text using linear regression",
      "author" : [ "Dong Nguyen", "Noah A. Smith", "Carolyn P. Rosé." ],
      "venue" : "Proc. of LaTeCH.",
      "citeRegEx" : "Nguyen et al\\.,? 2011",
      "shortCiteRegEx" : "Nguyen et al\\.",
      "year" : 2011
    }, {
      "title" : "Finding deceptive opinion spam by any stretch of the imagination",
      "author" : [ "Myle Ott", "Yejin Choi", "Claire Cardie", "Jeffrey T. Hancock." ],
      "venue" : "Proc. of ACL.",
      "citeRegEx" : "Ott et al\\.,? 2011",
      "shortCiteRegEx" : "Ott et al\\.",
      "year" : 2011
    }, {
      "title" : "The lambada dataset: Word prediction",
      "author" : [ "Denis Paperno", "Germán Kruszewski", "Angeliki Lazaridou", "Ngoc Quan Pham", "Raffaella Bernardi", "Sandro Pezzelle", "Marco Baroni", "Gemma Boleda", "Raquel Fernández" ],
      "venue" : null,
      "citeRegEx" : "Paperno et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Paperno et al\\.",
      "year" : 2016
    }, {
      "title" : "Scikit-learn: Machine learning in Python",
      "author" : [ "Matthieu Perrot", "Édouard Duchesnay." ],
      "venue" : "JMLR 12:2825–2830.",
      "citeRegEx" : "Perrot and Duchesnay.,? 2011",
      "shortCiteRegEx" : "Perrot and Duchesnay.",
      "year" : 2011
    }, {
      "title" : "Linguistic styles: language use as an individual difference",
      "author" : [ "James W. Pennebaker", "Laura A. King." ],
      "venue" : "Journal of Personality and Social Psychology 77(6):1296–1312.",
      "citeRegEx" : "Pennebaker and King.,? 1999",
      "shortCiteRegEx" : "Pennebaker and King.",
      "year" : 1999
    }, {
      "title" : "Words of wisdom: language use over the life span",
      "author" : [ "James W. Pennebaker", "Lori D. Stone." ],
      "venue" : "Journal of Personality and Social Psychology 85(2):291– 301.",
      "citeRegEx" : "Pennebaker and Stone.,? 2003",
      "shortCiteRegEx" : "Pennebaker and Stone.",
      "year" : 2003
    }, {
      "title" : "Cross-cultural deception detection",
      "author" : [ "Verónica Pérez-Rosas", "Rada Mihalcea." ],
      "venue" : "Proc. of ACL. http://www.aclweb.org/anthology/P14-2072.",
      "citeRegEx" : "Pérez.Rosas and Mihalcea.,? 2014a",
      "shortCiteRegEx" : "Pérez.Rosas and Mihalcea.",
      "year" : 2014
    }, {
      "title" : "Gender differences in deceivers writing style",
      "author" : [ "Verónica Pérez-Rosas", "Rada Mihalcea." ],
      "venue" : "Lecture Notes in Computer Science 8856:163–174.",
      "citeRegEx" : "Pérez.Rosas and Mihalcea.,? 2014b",
      "shortCiteRegEx" : "Pérez.Rosas and Mihalcea.",
      "year" : 2014
    }, {
      "title" : "An exploratory study on promising cues in deception detection and application of decision tree",
      "author" : [ "Tiantian Qin", "Judee Burgoon", "Jay F. Nunamaker Jr." ],
      "venue" : "Proc. of HICSS.",
      "citeRegEx" : "Qin et al\\.,? 2004",
      "shortCiteRegEx" : "Qin et al\\.",
      "year" : 2004
    }, {
      "title" : "Squad: 100,000+ questions for machine comprehension of text",
      "author" : [ "Pranav Rajpurkar", "Jian Zhang", "Konstantin Lopyrev", "Percy Liang." ],
      "venue" : "Proc. of EMNLP.",
      "citeRegEx" : "Rajpurkar et al\\.,? 2016",
      "shortCiteRegEx" : "Rajpurkar et al\\.",
      "year" : 2016
    }, {
      "title" : "Age prediction in blogs: A study of style, content, and online behavior in pre- and postsocial media generations",
      "author" : [ "Sara Rosenthal", "Kathleen McKeown." ],
      "venue" : "Proc. of ACL. Association for Computational Linguistics.",
      "citeRegEx" : "Rosenthal and McKeown.,? 2011",
      "shortCiteRegEx" : "Rosenthal and McKeown.",
      "year" : 2011
    }, {
      "title" : "Enhancing the lexvec distributed word representation model using positional contexts and external memory",
      "author" : [ "Alexandre Salle", "Marco Idiart", "Aline Villavicencio." ],
      "venue" : "arXiv:1606.01283.",
      "citeRegEx" : "Salle et al\\.,? 2016",
      "shortCiteRegEx" : "Salle et al\\.",
      "year" : 2016
    }, {
      "title" : "Effects of age and gender on blogging",
      "author" : [ "Jonathan Schler", "Moshe Koppel", "Shlomo Argamon", "James Pennebaker." ],
      "venue" : "AAAI spring symposium: Computational approaches to analyzing weblogs.",
      "citeRegEx" : "Schler et al\\.,? 2006",
      "shortCiteRegEx" : "Schler et al\\.",
      "year" : 2006
    }, {
      "title" : "Authorship attribution of micro-messages",
      "author" : [ "Roy Schwartz", "Oren Tsur", "Ari Rappoport", "Moshe Koppel." ],
      "venue" : "Proc. of EMNLP. http://www.aclweb.org/anthology/D13-1193.",
      "citeRegEx" : "Schwartz et al\\.,? 2013b",
      "shortCiteRegEx" : "Schwartz et al\\.",
      "year" : 2013
    }, {
      "title" : "Conceptnet 5.5: An open multilingual graph of general knowledge",
      "author" : [ "Robert Speer", "Joshua Chin", "Catherine Havasi" ],
      "venue" : null,
      "citeRegEx" : "Speer et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Speer et al\\.",
      "year" : 2016
    }, {
      "title" : "A survey of modern authorship attribution methods",
      "author" : [ "Efstathios Stamatatos." ],
      "venue" : "Journal of the American Society for information Science and Technology 60(3):538–556.",
      "citeRegEx" : "Stamatatos.,? 2009",
      "shortCiteRegEx" : "Stamatatos.",
      "year" : 2009
    }, {
      "title" : "Linguistic analysis of workplace computer-mediated communication",
      "author" : [ "Yla Rebecca Tausczik" ],
      "venue" : null,
      "citeRegEx" : "Tausczik.,? \\Q2009\\E",
      "shortCiteRegEx" : "Tausczik.",
      "year" : 2009
    }, {
      "title" : "Icwsm-a great catchy name: Semi-supervised recognition of sarcastic sentences in online product reviews",
      "author" : [ "Oren Tsur", "Dmitry Davidov", "Ari Rappoport." ],
      "venue" : "Proc. of ICWSM.",
      "citeRegEx" : "Tsur et al\\.,? 2010",
      "shortCiteRegEx" : "Tsur et al\\.",
      "year" : 2010
    }, {
      "title" : "Using classifier features for studying the effect of native language on the choice of written second language words",
      "author" : [ "Oren Tsur", "Ari Rappoport." ],
      "venue" : "Proc. of CACLA. http://www.aclweb.org/anthology/W/W07/W07-",
      "citeRegEx" : "Tsur and Rappoport.,? 2007",
      "shortCiteRegEx" : "Tsur and Rappoport.",
      "year" : 2007
    }, {
      "title" : "Towards ai-complete question answering: A set of prerequisite toy tasks",
      "author" : [ "Jason Weston", "Antoine Bordes", "Sumit Chopra", "Alexander M Rush", "Bart van Merriënboer", "Armand Joulin", "Tomas Mikolov." ],
      "venue" : "Proc. of ICLR.",
      "citeRegEx" : "Weston et al\\.,? 2016",
      "shortCiteRegEx" : "Weston et al\\.",
      "year" : 2016
    }, {
      "title" : "Automatic detection of deception in child-produced speech using syntactic complexity features",
      "author" : [ "Maria Yancheva", "Frank Rudzicz." ],
      "venue" : "Proc. of ACL.",
      "citeRegEx" : "Yancheva and Rudzicz.,? 2013",
      "shortCiteRegEx" : "Yancheva and Rudzicz.",
      "year" : 2013
    }, {
      "title" : "Textual predictors of bill survival in congressional committees",
      "author" : [ "Tae Yano", "Noah A. Smith", "John D. Wilkerson." ],
      "venue" : "Proc. of NAACL.",
      "citeRegEx" : "Yano et al\\.,? 2012",
      "shortCiteRegEx" : "Yano et al\\.",
      "year" : 2012
    } ],
    "referenceMentions" : [ {
      "referenceID" : 26,
      "context" : "We present a case study based on the story cloze task (Mostafazadeh et al., 2016a), where annotators were assigned similar writing tasks with different constraints: (1) writing an entire story, (2) adding a story ending for a given story context, and (3) adding an incoherent ending to a story.",
      "startOffset" : 54,
      "endOffset" : 82
    }, {
      "referenceID" : 43,
      "context" : "It is influenced by personal factors such as age and gender (Schler et al., 2006), by personality traits such as agreeableness and openness (Ireland and Mehl, 2014), as well as by mental states such as sentiment (Davidov et al.",
      "startOffset" : 60,
      "endOffset" : 81
    }, {
      "referenceID" : 18,
      "context" : ", 2006), by personality traits such as agreeableness and openness (Ireland and Mehl, 2014), as well as by mental states such as sentiment (Davidov et al.",
      "startOffset" : 66,
      "endOffset" : 90
    }, {
      "referenceID" : 10,
      "context" : ", 2006), by personality traits such as agreeableness and openness (Ireland and Mehl, 2014), as well as by mental states such as sentiment (Davidov et al., 2010), sarcasm (Tsur et al.",
      "startOffset" : 138,
      "endOffset" : 160
    }, {
      "referenceID" : 48,
      "context" : ", 2010), sarcasm (Tsur et al., 2010), and deception (Feng et al.",
      "startOffset" : 17,
      "endOffset" : 36
    }, {
      "referenceID" : 11,
      "context" : ", 2010), and deception (Feng et al., 2012).",
      "startOffset" : 23,
      "endOffset" : 42
    }, {
      "referenceID" : 26,
      "context" : "Table 1: Examples of stories from the story cloze task (Mostafazadeh et al., 2016a).",
      "startOffset" : 55,
      "endOffset" : 83
    }, {
      "referenceID" : 26,
      "context" : "As a case study, we present experiments based on the recently introduced ROC story cloze task (Mostafazadeh et al., 2016a).",
      "startOffset" : 94,
      "endOffset" : 122
    }, {
      "referenceID" : 42,
      "context" : "5% increase over the previously reported stateof-the-art (Salle et al., 2016).",
      "startOffset" : 57,
      "endOffset" : 77
    }, {
      "referenceID" : 26,
      "context" : "To understand how different writing tasks affect writing style, we focus on the story cloze task (Mostafazadeh et al., 2016a).",
      "startOffset" : 97,
      "endOffset" : 125
    }, {
      "referenceID" : 26,
      "context" : "Additionally, the ending is required to be “realistic and sensible” (Mostafazadeh et al., 2016a) when read out of context.",
      "startOffset" : 68,
      "endOffset" : 96
    }, {
      "referenceID" : 26,
      "context" : "Additionally, the ending is required to be “realistic and sensible” (Mostafazadeh et al., 2016a) when read out of context. The resulting stories, both right and wrong, were then individually rated for coherence and meaningfulness by additional AMT workers. Only stories rated as simultaneously coherent with a right ending and neutral with a wrong ending were selected for the task. It is worth noting that workers rated the stories as a whole, not only the endings. Based on the new stories, Mostafazadeh et al. (2016a) proposed the story cloze task.",
      "startOffset" : 69,
      "endOffset" : 521
    }, {
      "referenceID" : 42,
      "context" : "60% (Salle et al., 2016).",
      "startOffset" : 4,
      "endOffset" : 24
    }, {
      "referenceID" : 15,
      "context" : "2 This comes in contrast to other recent similar machine reading tasks such as CNN/DailyMail (Hermann et al., 2015), SNLI (Bowman et al.",
      "startOffset" : 93,
      "endOffset" : 115
    }, {
      "referenceID" : 5,
      "context" : ", 2015), SNLI (Bowman et al., 2015), LAMBADA (Paperno et al.",
      "startOffset" : 14,
      "endOffset" : 35
    }, {
      "referenceID" : 33,
      "context" : ", 2015), LAMBADA (Paperno et al., 2016) and SQuAD (Rajpurkar et al.",
      "startOffset" : 17,
      "endOffset" : 39
    }, {
      "referenceID" : 40,
      "context" : ", 2016) and SQuAD (Rajpurkar et al., 2016), for which results improved dramatically over a similar or shorter period of time.",
      "startOffset" : 18,
      "endOffset" : 42
    }, {
      "referenceID" : 5,
      "context" : ", 2015), SNLI (Bowman et al., 2015), LAMBADA (Paperno et al., 2016) and SQuAD (Rajpurkar et al., 2016), for which results improved dramatically over a similar or shorter period of time. This suggests that this task is challenging and that high performance is hard to achieve. In addition, Mostafazadeh et al. (2016a) made substantial efforts to ensure the quality of this dataset.",
      "startOffset" : 15,
      "endOffset" : 317
    }, {
      "referenceID" : 51,
      "context" : "Previous work has shown that sentence length is also indicative of whether a text was deceptive (Yancheva and Rudzicz, 2013; Qin et al., 2004).",
      "startOffset" : 96,
      "endOffset" : 142
    }, {
      "referenceID" : 39,
      "context" : "Previous work has shown that sentence length is also indicative of whether a text was deceptive (Yancheva and Rudzicz, 2013; Qin et al., 2004).",
      "startOffset" : 96,
      "endOffset" : 142
    }, {
      "referenceID" : 29,
      "context" : "Once again, deceptive text is also characterized by fewer pronouns compared to truthful text (Newman et al., 2003).",
      "startOffset" : 93,
      "endOffset" : 114
    }, {
      "referenceID" : 29,
      "context" : ", “!”), while wrong endings tend to use more negative language (“hates”), similarly as deceptive text (Newman et al., 2003).",
      "startOffset" : 102,
      "endOffset" : 123
    }, {
      "referenceID" : 47,
      "context" : "Following Tsur et al. (2010) and Schwartz et al.",
      "startOffset" : 10,
      "endOffset" : 29
    }, {
      "referenceID" : 44,
      "context" : "(2010) and Schwartz et al. (2013b), we distinguish between high frequency and low frequency words.",
      "startOffset" : 11,
      "endOffset" : 35
    }, {
      "referenceID" : 46,
      "context" : "Character n-grams are one of the most useful features in identifying author style (Stamatatos, 2009).",
      "startOffset" : 82,
      "endOffset" : 100
    }, {
      "referenceID" : 42,
      "context" : "5% (absolute) higher than the published state-of-theart result on the task (Salle et al., 2016).",
      "startOffset" : 75,
      "endOffset" : 95
    }, {
      "referenceID" : 26,
      "context" : "†DSSM (Mostafazadeh et al., 2016a) 0.",
      "startOffset" : 6,
      "endOffset" : 34
    }, {
      "referenceID" : 42,
      "context" : "585 †LexVec (Salle et al., 2016) 0.",
      "startOffset" : 12,
      "endOffset" : 32
    }, {
      "referenceID" : 45,
      "context" : "LexVec results are taken from (Speer et al., 2016).",
      "startOffset" : 30,
      "endOffset" : 50
    }, {
      "referenceID" : 26,
      "context" : "Human judgement scores are taken from (Mostafazadeh et al., 2016a).",
      "startOffset" : 38,
      "endOffset" : 66
    }, {
      "referenceID" : 16,
      "context" : "Specifically, we experiment with an LSTM-based (Hochreiter and Schmidhuber, 1997) recurrent neural network language model (RNNLM; Mikolov et al.",
      "startOffset" : 47,
      "endOffset" : 81
    }, {
      "referenceID" : 25,
      "context" : "Specifically, we experiment with an LSTM-based (Hochreiter and Schmidhuber, 1997) recurrent neural network language model (RNNLM; Mikolov et al., 2010).",
      "startOffset" : 122,
      "endOffset" : 151
    }, {
      "referenceID" : 20,
      "context" : "Using the Adam optimizer (Kingma and Ba, 2015) and a learning rate of η = .",
      "startOffset" : 25,
      "endOffset" : 46
    }, {
      "referenceID" : 44,
      "context" : "These findings are in line with previous work that used character n-grams along with other types of features to predict writing style (Schwartz et al., 2013b).",
      "startOffset" : 134,
      "endOffset" : 158
    }, {
      "referenceID" : 30,
      "context" : "In order to answer this question, we consider the highest absolute positive and negative coefficients in the logistic regression classifier in both Experiments 1 and 2, an approach widely used as a method of extracting the most salient features (Nguyen et al., 2013; Burke et al., 2013; Brooks et al., 2013).",
      "startOffset" : 245,
      "endOffset" : 307
    }, {
      "referenceID" : 7,
      "context" : "In order to answer this question, we consider the highest absolute positive and negative coefficients in the logistic regression classifier in both Experiments 1 and 2, an approach widely used as a method of extracting the most salient features (Nguyen et al., 2013; Burke et al., 2013; Brooks et al., 2013).",
      "startOffset" : 245,
      "endOffset" : 307
    }, {
      "referenceID" : 6,
      "context" : "In order to answer this question, we consider the highest absolute positive and negative coefficients in the logistic regression classifier in both Experiments 1 and 2, an approach widely used as a method of extracting the most salient features (Nguyen et al., 2013; Burke et al., 2013; Brooks et al., 2013).",
      "startOffset" : 245,
      "endOffset" : 307
    }, {
      "referenceID" : 52,
      "context" : "It is worth noting that its reliability is not entirely clear, since linear models like logistic regression can assign large coefficients to rare features (Yano et al., 2012).",
      "startOffset" : 155,
      "endOffset" : 174
    }, {
      "referenceID" : 32,
      "context" : "deceptive text (Ott et al., 2011).",
      "startOffset" : 15,
      "endOffset" : 33
    }, {
      "referenceID" : 29,
      "context" : "For instance, writing deceptive text leads to a significant cognitive burden accompanied by a writing style that is different from truthful text (Newman et al., 2003; Banerjee et al., 2014).",
      "startOffset" : 145,
      "endOffset" : 189
    }, {
      "referenceID" : 2,
      "context" : "For instance, writing deceptive text leads to a significant cognitive burden accompanied by a writing style that is different from truthful text (Newman et al., 2003; Banerjee et al., 2014).",
      "startOffset" : 145,
      "endOffset" : 189
    }, {
      "referenceID" : 23,
      "context" : "Writing tasks can even have a long-term effect, as writing emotional texts was observed to benefit both physical and mental health (Lepore and Smyth, 2002; Frattaroli, 2006).",
      "startOffset" : 131,
      "endOffset" : 173
    }, {
      "referenceID" : 12,
      "context" : "Writing tasks can even have a long-term effect, as writing emotional texts was observed to benefit both physical and mental health (Lepore and Smyth, 2002; Frattaroli, 2006).",
      "startOffset" : 131,
      "endOffset" : 173
    }, {
      "referenceID" : 18,
      "context" : ", depression, neuroticism, narcissism) affect her writing style (Schwartz et al., 2013a; Ireland and Mehl, 2014).",
      "startOffset" : 64,
      "endOffset" : 112
    }, {
      "referenceID" : 19,
      "context" : "Second, temporary changes, such as a romantic relationship (Ireland et al., 2011; Bowen et al., 2016), work collaboration (Tausczik, 2009; Gonzales et al.",
      "startOffset" : 59,
      "endOffset" : 101
    }, {
      "referenceID" : 4,
      "context" : "Second, temporary changes, such as a romantic relationship (Ireland et al., 2011; Bowen et al., 2016), work collaboration (Tausczik, 2009; Gonzales et al.",
      "startOffset" : 59,
      "endOffset" : 101
    }, {
      "referenceID" : 47,
      "context" : ", 2016), work collaboration (Tausczik, 2009; Gonzales et al., 2009), or negotiation (Ireland and Henderson, 2014) may also affect writing style.",
      "startOffset" : 28,
      "endOffset" : 67
    }, {
      "referenceID" : 13,
      "context" : ", 2016), work collaboration (Tausczik, 2009; Gonzales et al., 2009), or negotiation (Ireland and Henderson, 2014) may also affect writing style.",
      "startOffset" : 28,
      "endOffset" : 67
    }, {
      "referenceID" : 17,
      "context" : ", 2009), or negotiation (Ireland and Henderson, 2014) may also affect writing style.",
      "startOffset" : 24,
      "endOffset" : 53
    }, {
      "referenceID" : 10,
      "context" : "Finally, writing style can also change from one sentence to another, for instance between positive and negative text (Davidov et al., 2010) or when writing sarcastic text (Tsur et al.",
      "startOffset" : 117,
      "endOffset" : 139
    }, {
      "referenceID" : 48,
      "context" : ", 2010) or when writing sarcastic text (Tsur et al., 2010).",
      "startOffset" : 39,
      "endOffset" : 58
    }, {
      "referenceID" : 2,
      "context" : ", 2003; Banerjee et al., 2014). Writing tasks can even have a long-term effect, as writing emotional texts was observed to benefit both physical and mental health (Lepore and Smyth, 2002; Frattaroli, 2006). Campbell and Pennebaker (2003) also showed that the health benefits of writing emotional text are accompanied by changes in writing style, mostly in the use of pronouns.",
      "startOffset" : 8,
      "endOffset" : 238
    }, {
      "referenceID" : 26,
      "context" : "Many factors, such as topic diversity and temporal and causal relation diversity, were controlled for (Mostafazadeh et al., 2016a).",
      "startOffset" : 102,
      "endOffset" : 130
    }, {
      "referenceID" : 24,
      "context" : "One way to avoid such problems is by using shorter text spans, such as the ones used in the Winograd schema (Levesque, 2011).",
      "startOffset" : 108,
      "endOffset" : 124
    }, {
      "referenceID" : 46,
      "context" : "The models used to characterize style are often linear classifiers with style features such as character and word n-grams (Stamatatos, 2009; Koppel et al., 2009).",
      "startOffset" : 122,
      "endOffset" : 161
    }, {
      "referenceID" : 21,
      "context" : "The models used to characterize style are often linear classifiers with style features such as character and word n-grams (Stamatatos, 2009; Koppel et al., 2009).",
      "startOffset" : 122,
      "endOffset" : 161
    }, {
      "referenceID" : 36,
      "context" : "Previous work has shown that different authors can be grouped by their writing style, according to factors such as age (Pennebaker and Stone, 2003; Argamon et al., 2003; Schler et al., 2006; Rosenthal and McKeown, 2011; Nguyen et al., 2011), gender (Argamon et al.",
      "startOffset" : 119,
      "endOffset" : 240
    }, {
      "referenceID" : 0,
      "context" : "Previous work has shown that different authors can be grouped by their writing style, according to factors such as age (Pennebaker and Stone, 2003; Argamon et al., 2003; Schler et al., 2006; Rosenthal and McKeown, 2011; Nguyen et al., 2011), gender (Argamon et al.",
      "startOffset" : 119,
      "endOffset" : 240
    }, {
      "referenceID" : 43,
      "context" : "Previous work has shown that different authors can be grouped by their writing style, according to factors such as age (Pennebaker and Stone, 2003; Argamon et al., 2003; Schler et al., 2006; Rosenthal and McKeown, 2011; Nguyen et al., 2011), gender (Argamon et al.",
      "startOffset" : 119,
      "endOffset" : 240
    }, {
      "referenceID" : 41,
      "context" : "Previous work has shown that different authors can be grouped by their writing style, according to factors such as age (Pennebaker and Stone, 2003; Argamon et al., 2003; Schler et al., 2006; Rosenthal and McKeown, 2011; Nguyen et al., 2011), gender (Argamon et al.",
      "startOffset" : 119,
      "endOffset" : 240
    }, {
      "referenceID" : 31,
      "context" : "Previous work has shown that different authors can be grouped by their writing style, according to factors such as age (Pennebaker and Stone, 2003; Argamon et al., 2003; Schler et al., 2006; Rosenthal and McKeown, 2011; Nguyen et al., 2011), gender (Argamon et al.",
      "startOffset" : 119,
      "endOffset" : 240
    }, {
      "referenceID" : 0,
      "context" : ", 2011), gender (Argamon et al., 2003; Schler et al., 2006; Bamman et al., 2014), and native language (Koppel et al.",
      "startOffset" : 16,
      "endOffset" : 80
    }, {
      "referenceID" : 43,
      "context" : ", 2011), gender (Argamon et al., 2003; Schler et al., 2006; Bamman et al., 2014), and native language (Koppel et al.",
      "startOffset" : 16,
      "endOffset" : 80
    }, {
      "referenceID" : 1,
      "context" : ", 2011), gender (Argamon et al., 2003; Schler et al., 2006; Bamman et al., 2014), and native language (Koppel et al.",
      "startOffset" : 16,
      "endOffset" : 80
    }, {
      "referenceID" : 22,
      "context" : ", 2014), and native language (Koppel et al., 2005; Tsur and Rappoport, 2007; Bergsma et al., 2012).",
      "startOffset" : 29,
      "endOffset" : 98
    }, {
      "referenceID" : 49,
      "context" : ", 2014), and native language (Koppel et al., 2005; Tsur and Rappoport, 2007; Bergsma et al., 2012).",
      "startOffset" : 29,
      "endOffset" : 98
    }, {
      "referenceID" : 3,
      "context" : ", 2014), and native language (Koppel et al., 2005; Tsur and Rappoport, 2007; Bergsma et al., 2012).",
      "startOffset" : 29,
      "endOffset" : 98
    }, {
      "referenceID" : 28,
      "context" : "At the extreme case, each individual author adopts a unique writing style (Mosteller and Wallace, 1963; Pennebaker and King, 1999; Schwartz et al., 2013b).",
      "startOffset" : 74,
      "endOffset" : 154
    }, {
      "referenceID" : 35,
      "context" : "At the extreme case, each individual author adopts a unique writing style (Mosteller and Wallace, 1963; Pennebaker and King, 1999; Schwartz et al., 2013b).",
      "startOffset" : 74,
      "endOffset" : 154
    }, {
      "referenceID" : 44,
      "context" : "At the extreme case, each individual author adopts a unique writing style (Mosteller and Wallace, 1963; Pennebaker and King, 1999; Schwartz et al., 2013b).",
      "startOffset" : 74,
      "endOffset" : 154
    }, {
      "referenceID" : 29,
      "context" : "Several researchers have used stylometric features to predict deception (Newman et al., 2003; Hancock et al., 2007; Ott et al., 2011; Feng et al., 2012).",
      "startOffset" : 72,
      "endOffset" : 152
    }, {
      "referenceID" : 14,
      "context" : "Several researchers have used stylometric features to predict deception (Newman et al., 2003; Hancock et al., 2007; Ott et al., 2011; Feng et al., 2012).",
      "startOffset" : 72,
      "endOffset" : 152
    }, {
      "referenceID" : 32,
      "context" : "Several researchers have used stylometric features to predict deception (Newman et al., 2003; Hancock et al., 2007; Ott et al., 2011; Feng et al., 2012).",
      "startOffset" : 72,
      "endOffset" : 152
    }, {
      "referenceID" : 11,
      "context" : "Several researchers have used stylometric features to predict deception (Newman et al., 2003; Hancock et al., 2007; Ott et al., 2011; Feng et al., 2012).",
      "startOffset" : 72,
      "endOffset" : 152
    }, {
      "referenceID" : 50,
      "context" : "These include datasets like bAbI (Weston et al., 2016), SNLI (Bowman et al.",
      "startOffset" : 33,
      "endOffset" : 54
    }, {
      "referenceID" : 5,
      "context" : ", 2016), SNLI (Bowman et al., 2015), CNN/DailyMail (Hermann et al.",
      "startOffset" : 14,
      "endOffset" : 35
    }, {
      "referenceID" : 15,
      "context" : ", 2015), CNN/DailyMail (Hermann et al., 2015), LAMBADA (Paperno et al.",
      "startOffset" : 23,
      "endOffset" : 45
    }, {
      "referenceID" : 33,
      "context" : ", 2015), LAMBADA (Paperno et al., 2016) and SQuAD (Rajpurkar et al.",
      "startOffset" : 17,
      "endOffset" : 39
    }, {
      "referenceID" : 40,
      "context" : ", 2016) and SQuAD (Rajpurkar et al., 2016).",
      "startOffset" : 18,
      "endOffset" : 42
    }, {
      "referenceID" : 9,
      "context" : "While these works have presented resources for researchers, it is often the case that these datasets suffer from methodological problems caused by applying noisy automatic tools to generate them (Chen et al., 2016).",
      "startOffset" : 195,
      "endOffset" : 214
    } ],
    "year" : 2017,
    "abstractText" : "A writer’s style depends not just on personal traits but also on her intent and mental state. In this paper, we show how variants of the same writing task can lead to measurable differences in writing style. We present a case study based on the story cloze task (Mostafazadeh et al., 2016a), where annotators were assigned similar writing tasks with different constraints: (1) writing an entire story, (2) adding a story ending for a given story context, and (3) adding an incoherent ending to a story. We show that a simple linear classifier informed with stylistic features is able to successfully distinguish among the three cases, without even looking at the story context. In addition, our style-based classifier establishes a new state-of-the-art result on the story cloze challenge, substantially higher than previous results based on deep learning models. Our results demonstrate that different task framings can dramatically affect the way people write.",
    "creator" : "LaTeX with hyperref package"
  }
}