{
  "name" : "769.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Learning Symmetric Collaborative Dialogue Agents with Dynamic Knowledge Graph Embeddings",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "1 000\n011\n012\n013\n014\n015\n016\n017\n018\n019\n020\n021\n022\n023\n024\n025\n026\n027\n028\n029\n030\n031\n032\n033\n034\n035\n036\n037\n038\n039\n040\n041\n042\n043\n044\n045\n046\n047\n048\n049\n073\n074\n075\n076\n077\n078\n079\n080\n081\n082\n083\n084\n085\n086\n087\n088\n089\n090\n091\n092\n093\n094\n095\n096\n097\n098\n099"
    }, {
      "heading" : "1 Introduction",
      "text" : "Current task-oriented dialogue systems (Young et al., 2013; Wen et al., 2017; Dhingra et al., 2016) require a pre-defined dialogue state (e.g., slots such as food type and price range for a restaurant searching task) and a fixed set of dialogue acts (e.g., request, inform). However, human conversation often requires richer dialogue states and more nuanced, pragmatic dialogue acts. In contrast, recent open-domain chat systems (Shang et al., 2015; Serban et al., 2015b; Sordoni et al., 2015; Li et al., 2016a) learn a mapping directly from previous utterances to the next utterance. While these models capture open-ended aspects of dialogue, the lack of structured dialogue state prevents them from being directly applied to settings that require interfacing with structured knowledge.\nIn order to bridge the gap between the two types of systems, we focus on a symmetric collabora-\ntive dialogue setting, which is task-oriented but encourages open-ended dialogue acts. In our setting, two agents, each with a private list of items with attributes, must communicate to identify the unique shared item. Consider the dialogue in Figure 1, in which two people are trying to find their mutual friend. When B asks “do you have anyone who went to columbia?”, it suggests that she has some Columbia friends and they probably work at Google. Such conversational implicature is lost when interpreting it as simply requesting information about Columbia. In addition, it is hard to define a state that captures the diverse semantics in these utterances (e.g., defining “most of”, “might be”; see details in Table 1).\nTo model both structured and open-ended context, we propose the Dynamic Knowledge Graph Network (DynoNet), in which the dialogue state is modeled as a knowledge graph with an embedding for each node (Section 3). Our model is similar\n2\n101\n102\n103\n104\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n123\n124\n125\n126\n127\n128\n129\n130\n131\n132\n133\n134\n135\n136\n137\n138\n139\n140\n141\n142\n143\n144\n145\n146\n147\n148\n149\n150\n151\n152\n153\n154\n155\n156\n157\n158\n159\n160\n161\n162\n163\n164\n165\n166\n167\n168\n169\n170\n171\n172\n173\n174\n175\n176\n177\n178\n179\n180\n181\n182\n183\n184\n185\n186\n187\n188\n189\n190\n191\n192\n193\n194\n195\n196\n197\n198\n199\nto EntNet (Henaff et al., 2017) in that node/entity embeddings are updated recurrently given new utterances. The difference is that we structure entities as a knowledge graph; as the dialogue proceeds, new nodes are added and new context is propagated on the graph. An attention-based mechanism (Bahdanau et al., 2015) over the node embeddings drives generation of new utterances. Our model’s use of knowledge graphs captures the grounding capability of classic task-oriented systems and the graph embedding provides the representational flexibility of neural models.\nThe naturalness of communication in the symmetric collaborative setting enables large-scale data collection: We were able to crowd-source around 11K human-human dialogues on Amazon Mechanical Turk (AMT) in less than 15 hours.1 We show that the new dataset calls for more powerful representation beyond fully-structured states (Section 2.2).\nAside from the third-party human evaluation adopted by most work (Liu et al., 2016; Li et al., 2016b,c), we also conduct partner evaluation (Wen et al., 2017) where AMT workers rate their conversational partners (our models) based on fluency, correctness, cooperation, and human-likeness. We compare DynoNet with baseline neural models and a strong rule-based system. The results show that DynoNet can perform the task with humans efficiently and naturally; it also captures some strategic aspects of human-human dialogues.\nThe contributions of this work are: (i) a new symmetric collaborative dialogue setting and a large dialogue corpus that push the boundaries of existing dialogue systems; (ii) DynoNet that integrates semantically rich utterances with structured knowledge to represent open-ended dialogue states; (iii) multiple automatic metrics based on bot-bot chat and a comparison of third-party and partner evaluation."
    }, {
      "heading" : "2 Symmetric Collaborative Dialogue",
      "text" : "We introduce a collaborative task between two agents and describe the human-human dialogue collection process. We show that our data exhibits diverse, interesting language phenomena.\n1The dataset is available publicly at http: //anonymous."
    }, {
      "heading" : "2.1 Task Definition",
      "text" : "In the symmetric collaborative dialogue setting, there are two agents, A and B, each with a private knowledge base—KBA and KBB, respectively. Each knowledge base includes a list of items, where each item has a value for each attribute. For example, in the MutualFriends setting, Figure 1, items are friends and attributes are name, school, etc. There is a shared item that A and B both have; their goal is to converse with each other to determine the shared item and select it. Formally, an agent is a mapping from its private KB and the dialogue thus far (sequence of utterances) to the next utterance to generate. A dialogue is considered successful when both agents correctly select the shared item. This setting has parallels in human-computer collaboration where each agent has different expertise."
    }, {
      "heading" : "2.2 Data collection",
      "text" : "We created a schema containing 7 attributes and more than 3K entities (attribute values) in total. To elicit linguistic and strategic variants, we generate a random scenario for each task by varying the number of items, the number attributes, and the distribution of values for each attribute. See Appendix B for details of scenario generation.\nWe crowd-sourced dialogues on AMT by randomly pairing up users to perform the task within 5 minutes.2 To discourage random guessing, we prevent users from selecting more than once every 10 seconds. The chat interface is shown in Appendix C. Our task was very popular and we collected 11K dialogues over a period of 13.5 hours.3"
    }, {
      "heading" : "2.3 Dataset statistics",
      "text" : "We show the basic statistics of our dataset in Table 3. An utterance is defined as a message sent by the user. The average utterance length is shorter due to the informality of the chat, however, a user usually sends multiple utterances in one turn. Some example dialogues are shown in Table 6 and Appendix H.\nWe coarsely categorize utterances into inform, ask, answer, greeting, apology by pattern matching (Appendix E). There are 7.4% multi-type utterances and 30.9% multi-entity utterances. In Ta-\n2If users exceed the time limit, the dialogue is marked as unsuccessful (but still logged).\n3Tasks are put up in batches; the total time excludes intervals between batches.\n4Entity names are replaced by entity types.\n3\n206\n207\n208\n216\n217\n218\n219\n220\n221\n222\n223\n224\n225\n226\n227\n228\n229\n230\n231\n232\n233\n234\n235\n236\n237\n238\n239\n240\n241\n242\n243\n244\n245\n246\n247\n248\n249\n256\n257\n258\n266\n267\n268\n269\n270\n271\n272\n273\n274\n275\n276\n277\n278\n279\n280\n281\n282\n283\n284\n285\n286\n287\n288\n289\n290\n291\n292\n293\n294\n295\n296\n297\n298\n299\n# dialogues 11439 # completed dialogues 9041 Vocabulary size 4548 Average # of utterances 11.41 Average time taken per task (sec.) 91.18 Average utterance length (tokens) 4.84 Number of linguistic templates4 30370\nTable 3: Statistics of the MutualFriends dataset.\nble 1, we show example utterances where the rich semantics cannot be sufficiently represented by traditional slot-value pairs. Even the more standard ones can be challenging due to coreference and conjunctions.\nOur dataset also exhibits interesting communication phenomena that add to its complexity. Coreference occurs frequently when people check attributes jointly. Sometimes the mentions are dropped: it simply continues from the previous partner utterance. People occasionally use external knowledge to group items with out-of-schema attributes (e.g., gender based on names, location based on schools). We summarize these phenomena in Table 2. In addition, we find 30% utterances involve cross-talk where the conversation does not progress linearly (e.g., italic utterances in Figure 1). Cross-talk is a common characteristic of online chat that creates ambiguity (Ivanovic, 2005).\nOne strategic aspect of this task is the order in which attributes are mentioned. We find that peo-\nple tend to start from attributes with fewer unique values, e.g., “all my friends like morning” given the KBB in Table 6, as intuitively it would help exclude items quickly given fewer values to check.5 We provide a more detailed analysis of strategy in Section 4.2 and Appendix F."
    }, {
      "heading" : "3 Dynamic Knowledge Graph Network",
      "text" : "The diverse semantics in our data motivates us to combine rich but unstructured representation of the dialogue history with structured knowledge. Our model consists of three components shown in Figure 2: (i) a dynamic knowledge graph, which represents the private KB and dialogue history in a graph (Section 3.1), (ii) a graph embedding over the nodes (Section 3.2), and (iii) an utterance generator (Section 3.3).\nThe knowledge graph represents entities and relations in the agent’s private KB, e.g., google belongs to company. As the conversation unrolls, utterances are embedded and incorporated to node embeddings of mentioned entities. In Figure 2, “Most of my friends work for Google” updates the embedding of google. Further, mentioned nodes pass on this new information to their neighbors so that related entities (e.g., those in the same row or column) also receive the information. In our example, jessica and josh both receive new context when google and columbia are mentioned.\n5Our goal is to model human behavior thus we do not discuss the optimal strategy here.\n4\n309\n310\n311\n312\n313\n314\n315\n316\n317\n318\n319\n320\n321\n322\n323\n324\n325\n326\n327\n328\n329\n330\n331\n332\n333\n334\n335\n336\n337\n338\n339\n340\n341\n342\n343\n344\n345\n346\n347\n348\n349\n359\n360\n361\n362\n363\n364\n365\n366\n367\n368\n369\n370\n371\n372\n373\n374\n375\n376\n377\n378\n379\n380\n381\n382\n383\n384\n385\n386\n387\n388\n389\n390\n391\n392\n393\n394\n395\n396\n397\n398\n399\nThe utterance generator, an LSTM, then produces the next utterance by attending to the node embeddings that represent the dialogue state."
    }, {
      "heading" : "3.1 Knowledge Graph",
      "text" : "Given a dialogue of T utterances, we construct an evolving graph Gt over the KB and dialogue history for agent A.6 We consider three types of nodes: item nodes, attribute nodes, and entity nodes. Edges between nodes represent their relations. For example, (item-1, hasSchool, columbia) means that the first item has attribute school whose value is columbia. An example graph is shown in Figure 2. The graph is updated at the end of an utterance if new entities (not in KBA) are mentioned; they are added as dangling nodes.7"
    }, {
      "heading" : "3.2 Graph Embedding",
      "text" : "Given a knowledge graph, we are interested in computing a vector representation for each node v that captures both its unstructured context from the dialogue history and its structured context in the KB. The node embedding V is built from three parts: structural properties of an entity defined by the KB, embeddings of utterances in the dialogue history, and message passing between neighboring nodes.\nNode Features. Simple structural properties of the KB often govern what is talked about; e.g., a high-frequency entity is often interesting (consider\n6 It is important to differentiate perspectives of the two agents as they have different KBs. Thereafter we assume the perspective of agent A, i.e., accessing KBA and generating utterances for A only, and refer to B as the partner.\n7 We use a rule-based lexicon to link text spans to entities. See details in Appendix D.\n“All my friends like dancing.”). We represent this type of information as an indicator vector F (v), including the frequency and type (item, attribute, or entity type) of entity v.\nMention Vectors. A mention vector Mt(v) contains unstructured context from utterances relevant to node v up to turn t. Given embedding ut of the last utterance (Section 3.3), we define\nMt(v) = Mt 1(v) + (1 )ut,\n=\n( W [Mt 1(v), ut] if ut mentions v\n1 otherwise\nwhere is the sigmoid function and W is a projection matrix. If no entity is mentioned in ut, we update v in ut 1. This is useful when ut answers a question, e.g., “do you have any google friends?” “No.” To differentiate between the agent’s and the partner’s utterances, Mt(v) consists of two separate components for utterances from each source.\nRecursive Node Embeddings. We propagate information between nodes according to the structure of the knowledge graph. In Figure 2, given “anyone went to columbia?”, the agent should focus on her Google friends who went to Columbia. Therefore, we want this information to be sent to item nodes connected to columbia, and one step further to other attributes of these items because they might be implicitly referred to (google which was mentioned previously) or mentioned next (jessica and josh which will be generated).\nWe compute the embeddings recursively, analogous to belief propagation:\nV kt (v) = max v02N(v) tanh\n⇣ Wm h V k 1t (v 0 ), R(ev!v0) i⌘ ,\n5\n401\n402\n403\n404\n405\n406\n407\n408\n409\n410\n411\n412\n413\n414\n415\n416\n417\n418\n419\n420\n421\n422\n423\n424\n425\n426\n427\n428\n429\n430\n431\n432\n433\n434\n435\n436\n437\n438\n439\n440\n441\n442\n443\n444\n445\n446\n447\n448\n449\n450\n451\n452\n453\n454\n455\n456\n457\n458\n459\n460\n461\n462\n463\n464\n465\n466\n467\n468\n469\n470\n471\n472\n473\n474\n475\n476\n477\n478\n479\n480\n481\n482\n483\n484\n485\n486\n487\n488\n489\n490\n491\n492\n493\n494\n495\n496\n497\n498\n499\nwhere V kt (v) is the depth-k node embedding at turn t, Wm is a projection matrix, R is an relation embedding function, ev!v0 denotes the relation from v to v0, and max is an element-wise max operation.8 Example message passing paths are shown in Figure 2.\nThe final node embedding is the concatenation of embeddings at each depth:\nVt(v) = ⇥ V 0t (v), . . . , V K t (v) ⇤ ,\nwhere K is a hyperparameter (we experiment with K 2 {0, 1, 2}) and V 0t (v) = [F (v),Mt(v)]. The node embedding is updated periodically whenever Mt(v) is updated by a new utterance."
    }, {
      "heading" : "3.3 Utterance Generation",
      "text" : "In this section, we describe how an utterance is embedded and generated. Our model is based on a recurrent neural network (RNN). On turn t (we elide the subscript t for notational convenience), upon receiving an utterance of n tokens, {xn}Nn=1, the RNN maps it to a vector: hn = LSTMenc(hn 1, xn). We use the last hidden state hn as the utterance embedding u which updates the mention vectors.\nGiven (updated) embeddings of each node, we use another RNN to generate the next utterance, where each token is either copied from a node or generated from the vocabulary. Formally,\nhn = LSTMdec(hn 1, [xn, ct]),\nwhere ct is a weighted sum of node embeddings in the current turn: ct = P i ↵n,iVt(vi). As shown in Figure 2, entities relevant to generating the next utterance should have high weights. We compute the weights through standard attention mechanism: ↵n = softmax(an) and an,i = wa tanh (W a [hn 1, Vt(vi)]), where wa is a scoring vector and W a is a projection matrix.\nThe RNN outputs a distribution over words in the vocabulary and the nodes in Gt as in the copying mechanism of Jia and Liang (2016) :\np(xn+1 = w |xn, Gt) / exp (Uwhcn + b) , p(xn+1 = r(vi) |xn, Gt) / exp (an,i) ,\nwhere w is a word in the vocabulary, Uw and b are the model parameters, and r(vi) is the realization of the entity represented by node i, e.g., generating “Google” given the node google.9\n8Using sum slightly hurts performance. 9 We realize an entity by sampling from the empirical dis-\ntribution of its surface forms in the training set."
    }, {
      "heading" : "3.4 Entity Abstraction",
      "text" : "In our setting, the role of an entity is governed by its relation to other entities and relevant utterances. For example, replacing google with alphabet in Figure 1 should make very little difference to the conversation. Note that we do not use an embedding matrix for any entity when computing V (v). Furthermore, in the input embedding layer of the LSTM, we represent an entity by its type embedding concatenated with its node embedding. Accordingly, a regular word is represented as its word embedding concatenated with a zero vector of the same dimension as V . This way, the models’ representation of an entity only depends on its structural property in the KB and the dialogue context."
    }, {
      "heading" : "4 Experiments",
      "text" : ""
    }, {
      "heading" : "4.1 Setup",
      "text" : "We use a one-layer LSTM with 100 hidden units and 100-dimensional word vectors for both the encoder and the decoder. We maximize the likelihood of each utterance from perspectives of both agents. The parameters are optimized by AdaGrad (Duchi et al., 2010) with a learning rate of 0.5. We ran at least 10 epochs; after that, training stops if there is no improvement for 5 epochs. By default, we perform K = 2 iterations of message passing to compute node embeddings. We randomly split the data into train, dev, and test sets and only train on successful dialogues. For decoding, we sequentially sample from the output distribution with a softmax temperature of 0.5.10 Hyperparameters are tuned on the dev set. We compare DynoNet with its static cousion (StanoNet) and a rule-based system (Rule). StanoNet uses G0 throughout the dialogue, thus the dialogue context is completely contained in the RNN hidden states instead of being structured around the knowledge graph. Rule maintains weights for each entity and each item in the KB to decide what to talk about and which item to select. It has a pattern-matching semantic parser, a rule-based policy, and a templated generator. See Appendix G for details.\n10 Since selection is a common ‘utterance’ in our dataset and neural generation models are susceptible to overgenerating common sentences, we halve its probability during sampling.\n6\n501\n502\n503\n504\n505\n506\n507\n508\n509\n510\n511\n512\n513\n514\n515\n516\n517\n518\n519\n520\n521\n522\n523\n524\n525\n526\n527\n528\n529\n530\n531\n532\n533\n534\n535\n536\n537\n538\n539\n540\n541\n542\n543\n544\n545\n546\n547\n548\n549\n550\n551\n552\n553\n554\n555\n556\n557\n558\n559\n560\n561\n562\n563\n564\n565\n566\n567\n568\n569\n570\n571\n572\n573\n574\n575\n576\n577\n578\n579\n580\n581\n582\n583\n584\n585\n586\n587\n588\n589\n590\n591\n592\n593\n594\n595\n596\n597\n598\n599"
    }, {
      "heading" : "4.2 Evaluation",
      "text" : "We test our systems in two interactive settings: bot-bot chat and bot-human chat. We perform both automatic evaluation and human evaluation to test syntactic, semantic, and pragmatic competence of each system.\nAutomatic Evaluation. First, we compute the cross-entropy (`) of a model on test data. As shown in Table 4, DynoNet has the lowest test loss. Next, we have a model chat with itself on the scenarios from the test set.11 We evaluate the chats with respect to language variation, effectiveness and strategy.\nFor language variation, we report the average utterance length Lu and the unigram entropy H in Table 4. Compared to Rule, the neural models tend to generate shorter utterances (Li et al., 2016b; Serban et al., 2017). However, they are more diverse; for example, questions are asked in multiple ways such as “Do you have ...”, “Any friends like ...”, “What about ...”.\nAt the discourse level, we expect the distribution of a bot’s utterance types to match the distribution of human’s. We show percentages of each utterance type in Table 4. For Rule, the decision about which action to take is written in the rules, while StanoNet and DynoNet learned to behave in a more human-like way, frequently informing and asking questions.\nTo measure effectiveness, we compute the success rate per turn (CT ) and per selection (CS). In Table 4, humans are the best at this game, followed by Rule which is comparable to DynoNet. Next, we investigate the strategies leading to these results.\nAn agent needs to decide which entity/attribute to check first to quickly reduce the search space. We hypothesize that humans tend to first focus on a majority entity and an attribute with fewer unique values (Section 2.3). We show the average frequency of first-mentioned entities (#Ent1) and the average number of unique values for first-mentioned attributes (|Attr1|) in Table 4.12 Clearly, both DynoNet and StanoNet successfully matched human’s starting strategy by favoring more frequent entities and attributes of smaller do-\n11 We limit the number of turns in bot-bot chat to be the maximum number of turns humans took in the test set (46 turns).\n12 Both numbers are normalized to [0, 1] with respect to all entities/attributes in the corresponding KB.\nmain size. To examine the overall strategy, we show the average number of attributes and entities mentioned during the conversation in Table 4. Humans and DynoNet strategically focus on a few attributes and entities, whereas Rule needs almost twice entities to achieve similar success rates. This suggests that the effectiveness of Rule mainly comes from large amounts of unselective information, which is consistent with feedback from their human partners.\nPartner Evaluation. We generated 200 new scenarios and put up the bots on AMT using the same chat interface that used for data collection. Each AMT worker is randomly paired with Rule, StanoNet, DynoNet, or another human (but they don’t know which), and we make sure that all four types of agents are tested in each scenario (800 dialogues in total). At the end of each task, humans are asked to rate their partner in terms of fluency, correctness, cooperation, and humanlikeness from 1 (very bad) to 5 (very good), along with optional comments.\nAs shown in the example dialogues in Table 6, DynoNet cooperates smoothly with the human partner, e.g., replying with relevant information about morning/indoor friends when the partner mentioned that all her friends prefer morning and most like indoor. However, it “lied” when saying that it had a morning friend who likes outdoor. StanoNet starts well but doesn’t continue with the morning friend, because the morning node is not updated dynamically when mentioned by the partner. Rule always informs true facts but poorly follows the partner. In the comments, most complaint about Rule is that it was not ‘listening’ or ‘understanding’. We show the average ratings in Table 5 and the histograms in Appendix H. Overall, DynoNet achieves better partner satisfaction, especially in cooperation.\nThird-party Evaluation. Since the evaluator cannot see the partner’s KB, judgment on correctness is a mere guess. Therefore, we also created a third-party evaluation task, where an independent AMT worker is shown a conversation and the KB of one of the agents; she is asked to rate the same aspects of the agent as in the partner eval-\n13We only show the most frequent speech acts therefore the numbers do not sum to 1.\n14For third-party evaluation, we first take mean of each question then average the ratings.\n7\n606\n607\n608\n609\n618\n619\n620\n621\n622\n623\n624\n625\n626\n627\n628\n629\n630\n631\n632\n633\n634\n635\n636\n637\n638\n639\n640\n641\n642\n643\n644\n645\n646\n647\n648\n649\n656\n657\n658\n659\n668\n669\n670\n671\n672\n673\n674\n675\n676\n677\n678\n679\n680\n681\n682\n683\n684\n685\n686\n687\n688\n689\n690\n691\n692\n693\n694\n695\n696\n697\n698\n699\nuation and provide justifications.15 The average ratings and histograms are shown in Table 5 and Appendix H respectively.\nSurprisingly, there is a discrepancy between the two evaluation modes. Manual analysis of the comments indicates that while a participant in the dialogue considers the partner fluent as long as there is no communication overhead, a third person may have higher standards, e.g., thinking short sentences do not fully reveal an agent’s fluency. For human-likeness, partner evaluation is largely correlated with coherence (e.g., not repeating or ignoring past information) and task success, whereas third-party evaluators often rely on informality (e.g., usage of colloquia like “hiya”, capitalization, and abbreviation) or intuition.16 Interestingly, third-party evaluators noted most phenomena listed in Table 2 as indicators of humanbeings, e.g., correcting oneself, making chit-chat other than simply finishing the task."
    }, {
      "heading" : "4.3 Ablation Studies",
      "text" : "Our model has two novel designs: entity abstraction and message passing for node embeddings.\n15Each agent in a dialogue is rated by at least 5 people. 16 Nevertheless, informality can be easily handcrafted or\nlearned.\nTable 7 shows what happens if we ablate these. When the number of message passing iterations, K, is reduced from 2 to 0, the loss consistently increases. Removing entity abstraction—meaning adding entity embeddings to node embeddings and the LSTM input embeddings—also degrades performance. This shows that DynoNet benefits from contextually-defined, structural node embeddings rather than ones based on a classic lookup table.\nModel `\nDynoNet (K = 2) 2.16 DynoNet (K = 1) 2.20 DynoNet (K = 0) 2.26 DynoNet - entity abstraction 2.21\nTable 7: Ablations of our model on the dev set."
    }, {
      "heading" : "5 Discussion",
      "text" : "There has been a recent surge of interest in endto-end task-oriented dialogue systems. Unfortunately, the progress has been limited by the size of available datasets (Serban et al., 2015a). Most work uses a small corpus (< 5K dialogues) through Wizard-of-Oz data collection (Williams et al., 2016; Asri et al., 2016) or simulators (Bordes and Weston, 2017; Li et al., 2016d), which\n8\n725\n726\n727\n728\n729\n730\n731\n732\n733\n734\n735\n736\n737\n738\n739\n740\n741\n742\n743\n744\n745\n746\n747\n748\n749\n775\n776\n777\n778\n779\n780\n781\n782\n783\n784\n785\n786\n787\n788\n789\n790\n791\n792\n793\n794\n795\n796\n797\n798\n799\nmainly focuses on information-query tasks. Current strategic dialogue datasets include Settlers of Catan (Afantenos et al., 2012) (2K turns) and the cards corpus (Potts, 2012) (1.3K dialogues), though neither has offered an end-to-end dialogue system.\nMost task-oriented dialogue systems follow the POMDP-based approach (Young et al., 2013). Despite their success (Wen et al., 2017; Dhingra et al., 2016), the requirement for handcrafted slots limits their scalability to new domains and burdens data collection with extra state labeling. To break this limit, Bordes and Weston (2017) propose a Memory-Networks-based approach without domain-specific features. However, the memory is unstructured and interfacing with KBs relies on API calls, whereas our model embeds both the dialogue history and the KB structurally. Williams and Zweig (2016) use an LSTM to automatically infer the dialogue state, but as they focus on dialogue control rather than the full prob-\nlem, the LSTM input contains only recognized entities, which restricts the representational power for richer utterances. Our network architecture is most similar to EntNet (Henaff et al., 2017), where memories are also updated by input sentences recurrently. The main difference is that our model allows information to be propagated between structured entities, which is shown to be crucial in our setting (Section 4.3).\nIn conclusion, we believe the symmetric collaborative dialogue setting and our dataset provide unique opportunities at the interface of traditional task-oriented dialogue and open-domain chat. We also offered DynoNet as a promising means for open-ended dialogue state representation. Looking forward, our dataset facilitates the study of pragmatics and human strategies in dialogue—a good stepping stone towards learning more complex dialogues such as negotiation. It would be interesting to integrate supervised learning with game-theoretic approaches in future.\n9\n801\n802\n803\n804\n805\n806\n807\n808\n809\n810\n811\n812\n813\n814\n815\n816\n817\n818\n819\n820\n821\n822\n823\n824\n825\n826\n827\n828\n829\n830\n831\n832\n833\n834\n835\n836\n837\n838\n839\n840\n841\n842\n843\n844\n845\n846\n847\n848\n849\n850\n851\n852\n853\n854\n855\n856\n857\n858\n859\n860\n861\n862\n863\n864\n865\n866\n867\n868\n869\n870\n871\n872\n873\n874\n875\n876\n877\n878\n879\n880\n881\n882\n883\n884\n885\n886\n887\n888\n889\n890\n891\n892\n893\n894\n895\n896\n897\n898\n899"
    } ],
    "references" : [ {
      "title" : "Developing a corpus of strategic conversation in the settlers of catan",
      "author" : [ "S. Afantenos", "N. Asher", "F. Benamara", "A. Cadilhac", "C. Dégremont", "P. Denis", "M. Guhe", "S. Keizer", "A. Lascarides", "O. Lemon", "P. Muller", "S. Paul", "V. Rieser", "L. Vieu." ],
      "venue" : "SeineDial 2012 -",
      "citeRegEx" : "Afantenos et al\\.,? 2012",
      "shortCiteRegEx" : "Afantenos et al\\.",
      "year" : 2012
    }, {
      "title" : "Frames: A corpus for adding memory to goaloriented dialogue systems",
      "author" : [ "L.E. Asri", "H. Schulz", "S. Sharma", "J. Zumer", "J. Harris", "E. Fine", "R. Mehrotra", "K. Suleman." ],
      "venue" : "Maluuba Technical Report .",
      "citeRegEx" : "Asri et al\\.,? 2016",
      "shortCiteRegEx" : "Asri et al\\.",
      "year" : 2016
    }, {
      "title" : "Neural machine translation by jointly learning to align and translate",
      "author" : [ "D. Bahdanau", "K. Cho", "Y. Bengio." ],
      "venue" : "International Conference on Learning Representations (ICLR).",
      "citeRegEx" : "Bahdanau et al\\.,? 2015",
      "shortCiteRegEx" : "Bahdanau et al\\.",
      "year" : 2015
    }, {
      "title" : "Learning end-to-end goal-oriented dialog",
      "author" : [ "A. Bordes", "J. Weston." ],
      "venue" : "International Conference on Learning Representations (ICLR).",
      "citeRegEx" : "Bordes and Weston.,? 2017",
      "shortCiteRegEx" : "Bordes and Weston.",
      "year" : 2017
    }, {
      "title" : "End-to-end reinforcement learning of dialogue agents for information access",
      "author" : [ "B. Dhingra", "L. Li", "X. Li", "J. Gao", "Y. Chen", "F. Ahmed", "L. Deng." ],
      "venue" : "arXiv preprint arXiv:1609.00777 .",
      "citeRegEx" : "Dhingra et al\\.,? 2016",
      "shortCiteRegEx" : "Dhingra et al\\.",
      "year" : 2016
    }, {
      "title" : "Adaptive subgradient methods for online learning and stochastic optimization",
      "author" : [ "J. Duchi", "E. Hazan", "Y. Singer." ],
      "venue" : "Conference on Learning Theory (COLT).",
      "citeRegEx" : "Duchi et al\\.,? 2010",
      "shortCiteRegEx" : "Duchi et al\\.",
      "year" : 2010
    }, {
      "title" : "Tracking the world state with recurrent entity networks",
      "author" : [ "M. Henaff", "J. Weston", "A. Szlam", "A. Bordes", "Y. LeCun." ],
      "venue" : "International Conference on Learning Representations (ICLR).",
      "citeRegEx" : "Henaff et al\\.,? 2017",
      "shortCiteRegEx" : "Henaff et al\\.",
      "year" : 2017
    }, {
      "title" : "Dialogue act tagging for instant messaging chat sessions",
      "author" : [ "E. Ivanovic." ],
      "venue" : "Association for Computational Linguistics (ACL).",
      "citeRegEx" : "Ivanovic.,? 2005",
      "shortCiteRegEx" : "Ivanovic.",
      "year" : 2005
    }, {
      "title" : "Data recombination for neural semantic parsing",
      "author" : [ "R. Jia", "P. Liang." ],
      "venue" : "Association for Computational Linguistics (ACL).",
      "citeRegEx" : "Jia and Liang.,? 2016",
      "shortCiteRegEx" : "Jia and Liang.",
      "year" : 2016
    }, {
      "title" : "A persona-based neural conversation model",
      "author" : [ "J. Li", "M. Galley", "C. Brockett", "J. Gao", "B. Dolan." ],
      "venue" : "Association for Computational Linguistics (ACL).",
      "citeRegEx" : "Li et al\\.,? 2016a",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2016
    }, {
      "title" : "A diversity-promoting objective function for neural conversation models",
      "author" : [ "J. Li", "M. Galley", "C. Brockett", "J. Gao", "W.B. Dolan." ],
      "venue" : "Human Language Technology and North American Association for Computational Linguistics (HLT/NAACL).",
      "citeRegEx" : "Li et al\\.,? 2016b",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2016
    }, {
      "title" : "Deep reinforcement learning for dialogue generation",
      "author" : [ "J. Li", "W. Monroe", "A. Ritter", "D. Jurafsky", "M. Galley", "J. Gao." ],
      "venue" : "Empirical Methods in Natural Language Processing (EMNLP).",
      "citeRegEx" : "Li et al\\.,? 2016c",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2016
    }, {
      "title" : "A user simulator for taskcompletion dialogues",
      "author" : [ "X. Li", "Z.C. Lipton", "B. Dhingra", "L. Li", "J. Gao", "Y. Chen." ],
      "venue" : "arXiv .",
      "citeRegEx" : "Li et al\\.,? 2016d",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2016
    }, {
      "title" : "How NOT to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation",
      "author" : [ "C. Liu", "R. Lowe", "I.V. Serban", "M. Noseworthy", "L. Charlin", "J. Pineau." ],
      "venue" : "Empirical Methods in Natural Language",
      "citeRegEx" : "Liu et al\\.,? 2016",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2016
    }, {
      "title" : "Goal-driven answers in the Cards dialogue corpus",
      "author" : [ "C. Potts." ],
      "venue" : "Proceedings of the 30th West Coast Conference on Formal Linguistics.",
      "citeRegEx" : "Potts.,? 2012",
      "shortCiteRegEx" : "Potts.",
      "year" : 2012
    }, {
      "title" : "A hierarchical latent variable encoder-decoder model for generating dialogues",
      "author" : [ "I. Serban", "A. Sordoni", "R. Lowe", "L. Charlin", "J. Pineau", "A.C. Courville", "Y. Bengio." ],
      "venue" : "Association for the Advancement of Artificial Intelligence (AAAI).",
      "citeRegEx" : "Serban et al\\.,? 2017",
      "shortCiteRegEx" : "Serban et al\\.",
      "year" : 2017
    }, {
      "title" : "A survey of available corpora for building data-driven dialogue systems",
      "author" : [ "I.V. Serban", "R. Lowe", "L. Charlin", "J. Pineau." ],
      "venue" : "arXiv preprint arXiv:1512.05742 .",
      "citeRegEx" : "Serban et al\\.,? 2015a",
      "shortCiteRegEx" : "Serban et al\\.",
      "year" : 2015
    }, {
      "title" : "Building end-to-end dialogue systems using generative hierarchical neural network models",
      "author" : [ "I.V. Serban", "A. Sordoni", "Y. Bengio", "A. Courville", "J. Pineau." ],
      "venue" : "arXiv preprint arXiv:1507.04808 .",
      "citeRegEx" : "Serban et al\\.,? 2015b",
      "shortCiteRegEx" : "Serban et al\\.",
      "year" : 2015
    }, {
      "title" : "Neural responding machine for short-text conversation",
      "author" : [ "L. Shang", "Z. Lu", "H. Li." ],
      "venue" : "Association for Computational Linguistics (ACL).",
      "citeRegEx" : "Shang et al\\.,? 2015",
      "shortCiteRegEx" : "Shang et al\\.",
      "year" : 2015
    }, {
      "title" : "A neural network approach to context-sensitive generation of conversational responses",
      "author" : [ "A. Sordoni", "M. Galley", "M. Auli", "C. Brockett", "Y. Ji", "M. Mitchell", "J. Nie", "J. Gao", "B. Dolan." ],
      "venue" : "North American Association for Computational Linguis-",
      "citeRegEx" : "Sordoni et al\\.,? 2015",
      "shortCiteRegEx" : "Sordoni et al\\.",
      "year" : 2015
    }, {
      "title" : "A network-based end-to-end trainable task-oriented dialogue system",
      "author" : [ "T. Wen", "M. Gasic", "N. Mrksic", "L.M. Rojas-Barahona", "P. Su", "S. Ultes", "D. Vandyke", "S. Young." ],
      "venue" : "European Association for Computational Linguistics (EACL).",
      "citeRegEx" : "Wen et al\\.,? 2017",
      "shortCiteRegEx" : "Wen et al\\.",
      "year" : 2017
    }, {
      "title" : "The dialog state tracking challenge series: A review",
      "author" : [ "J.D. Williams", "A. Raux", "M. Henderson." ],
      "venue" : "Dialogue and Discourse 7.",
      "citeRegEx" : "Williams et al\\.,? 2016",
      "shortCiteRegEx" : "Williams et al\\.",
      "year" : 2016
    }, {
      "title" : "End-to-end LSTM-based dialog control optimized with supervised and reinforcement learning",
      "author" : [ "J.D. Williams", "G. Zweig." ],
      "venue" : "arXiv preprint arXiv:1606.01269 .",
      "citeRegEx" : "Williams and Zweig.,? 2016",
      "shortCiteRegEx" : "Williams and Zweig.",
      "year" : 2016
    }, {
      "title" : "POMDP-based statistical spoken dialog systems: A review",
      "author" : [ "S. Young", "M. Gasic", "B. Thomson", "J.D. Williams." ],
      "venue" : "Proceedings of the IEEE 101(5):1160–1179.",
      "citeRegEx" : "Young et al\\.,? 2013",
      "shortCiteRegEx" : "Young et al\\.",
      "year" : 2013
    } ],
    "referenceMentions" : [ {
      "referenceID" : 23,
      "context" : "Current task-oriented dialogue systems (Young et al., 2013; Wen et al., 2017; Dhingra et al., 2016) require a pre-defined dialogue state (e.",
      "startOffset" : 39,
      "endOffset" : 99
    }, {
      "referenceID" : 20,
      "context" : "Current task-oriented dialogue systems (Young et al., 2013; Wen et al., 2017; Dhingra et al., 2016) require a pre-defined dialogue state (e.",
      "startOffset" : 39,
      "endOffset" : 99
    }, {
      "referenceID" : 4,
      "context" : "Current task-oriented dialogue systems (Young et al., 2013; Wen et al., 2017; Dhingra et al., 2016) require a pre-defined dialogue state (e.",
      "startOffset" : 39,
      "endOffset" : 99
    }, {
      "referenceID" : 18,
      "context" : "In contrast, recent open-domain chat systems (Shang et al., 2015; Serban et al., 2015b; Sordoni et al., 2015; Li et al., 2016a) learn a mapping directly from previous utterances to the next utterance.",
      "startOffset" : 45,
      "endOffset" : 127
    }, {
      "referenceID" : 17,
      "context" : "In contrast, recent open-domain chat systems (Shang et al., 2015; Serban et al., 2015b; Sordoni et al., 2015; Li et al., 2016a) learn a mapping directly from previous utterances to the next utterance.",
      "startOffset" : 45,
      "endOffset" : 127
    }, {
      "referenceID" : 19,
      "context" : "In contrast, recent open-domain chat systems (Shang et al., 2015; Serban et al., 2015b; Sordoni et al., 2015; Li et al., 2016a) learn a mapping directly from previous utterances to the next utterance.",
      "startOffset" : 45,
      "endOffset" : 127
    }, {
      "referenceID" : 9,
      "context" : "In contrast, recent open-domain chat systems (Shang et al., 2015; Serban et al., 2015b; Sordoni et al., 2015; Li et al., 2016a) learn a mapping directly from previous utterances to the next utterance.",
      "startOffset" : 45,
      "endOffset" : 127
    }, {
      "referenceID" : 6,
      "context" : "to EntNet (Henaff et al., 2017) in that node/entity embeddings are updated recurrently given new utterances.",
      "startOffset" : 10,
      "endOffset" : 31
    }, {
      "referenceID" : 2,
      "context" : "An attention-based mechanism (Bahdanau et al., 2015) over the node embeddings drives generation of new utterances.",
      "startOffset" : 29,
      "endOffset" : 52
    }, {
      "referenceID" : 20,
      "context" : ", 2016b,c), we also conduct partner evaluation (Wen et al., 2017) where AMT workers rate their conversational partners (our models) based on fluency, correctness, cooperation, and human-likeness.",
      "startOffset" : 47,
      "endOffset" : 65
    }, {
      "referenceID" : 7,
      "context" : "Cross-talk is a common characteristic of online chat that creates ambiguity (Ivanovic, 2005).",
      "startOffset" : 76,
      "endOffset" : 92
    }, {
      "referenceID" : 8,
      "context" : "The RNN outputs a distribution over words in the vocabulary and the nodes in Gt as in the copying mechanism of Jia and Liang (2016) :",
      "startOffset" : 111,
      "endOffset" : 132
    }, {
      "referenceID" : 5,
      "context" : "The parameters are optimized by AdaGrad (Duchi et al., 2010) with a learning rate of 0.",
      "startOffset" : 40,
      "endOffset" : 60
    }, {
      "referenceID" : 10,
      "context" : "Compared to Rule, the neural models tend to generate shorter utterances (Li et al., 2016b; Serban et al., 2017).",
      "startOffset" : 72,
      "endOffset" : 111
    }, {
      "referenceID" : 15,
      "context" : "Compared to Rule, the neural models tend to generate shorter utterances (Li et al., 2016b; Serban et al., 2017).",
      "startOffset" : 72,
      "endOffset" : 111
    }, {
      "referenceID" : 16,
      "context" : "Unfortunately, the progress has been limited by the size of available datasets (Serban et al., 2015a).",
      "startOffset" : 79,
      "endOffset" : 101
    }, {
      "referenceID" : 21,
      "context" : "Most work uses a small corpus (< 5K dialogues) through Wizard-of-Oz data collection (Williams et al., 2016; Asri et al., 2016) or simulators (Bordes and Weston, 2017; Li et al.",
      "startOffset" : 84,
      "endOffset" : 126
    }, {
      "referenceID" : 1,
      "context" : "Most work uses a small corpus (< 5K dialogues) through Wizard-of-Oz data collection (Williams et al., 2016; Asri et al., 2016) or simulators (Bordes and Weston, 2017; Li et al.",
      "startOffset" : 84,
      "endOffset" : 126
    }, {
      "referenceID" : 3,
      "context" : ", 2016) or simulators (Bordes and Weston, 2017; Li et al., 2016d), which",
      "startOffset" : 22,
      "endOffset" : 65
    }, {
      "referenceID" : 12,
      "context" : ", 2016) or simulators (Bordes and Weston, 2017; Li et al., 2016d), which",
      "startOffset" : 22,
      "endOffset" : 65
    }, {
      "referenceID" : 0,
      "context" : "Current strategic dialogue datasets include Settlers of Catan (Afantenos et al., 2012) (2K turns) and the cards corpus (Potts, 2012) (1.",
      "startOffset" : 62,
      "endOffset" : 86
    }, {
      "referenceID" : 14,
      "context" : ", 2012) (2K turns) and the cards corpus (Potts, 2012) (1.",
      "startOffset" : 40,
      "endOffset" : 53
    }, {
      "referenceID" : 23,
      "context" : "Most task-oriented dialogue systems follow the POMDP-based approach (Young et al., 2013).",
      "startOffset" : 68,
      "endOffset" : 88
    }, {
      "referenceID" : 20,
      "context" : "Despite their success (Wen et al., 2017; Dhingra et al., 2016), the requirement for handcrafted slots limits their scalability to new domains and burdens data collection with extra state labeling.",
      "startOffset" : 22,
      "endOffset" : 62
    }, {
      "referenceID" : 4,
      "context" : "Despite their success (Wen et al., 2017; Dhingra et al., 2016), the requirement for handcrafted slots limits their scalability to new domains and burdens data collection with extra state labeling.",
      "startOffset" : 22,
      "endOffset" : 62
    }, {
      "referenceID" : 6,
      "context" : "Our network architecture is most similar to EntNet (Henaff et al., 2017), where memories are also updated by input sentences recurrently.",
      "startOffset" : 51,
      "endOffset" : 72
    }, {
      "referenceID" : 3,
      "context" : "To break this limit, Bordes and Weston (2017) propose a Memory-Networks-based approach without domain-specific features.",
      "startOffset" : 21,
      "endOffset" : 46
    }, {
      "referenceID" : 3,
      "context" : "To break this limit, Bordes and Weston (2017) propose a Memory-Networks-based approach without domain-specific features. However, the memory is unstructured and interfacing with KBs relies on API calls, whereas our model embeds both the dialogue history and the KB structurally. Williams and Zweig (2016) use an LSTM to automatically infer the dialogue state, but as they focus on dialogue control rather than the full problem, the LSTM input contains only recognized entities, which restricts the representational power for richer utterances.",
      "startOffset" : 21,
      "endOffset" : 305
    } ],
    "year" : 2017,
    "abstractText" : "We study a symmetric collaborative dialogue setting in which two agents, each with private knowledge, must strategically communicate to achieve a common goal. The open-ended dialogue state in this setting poses new challenges for existing dialogue systems. We collected a dataset of 11K human-human dialogues, which exhibits interesting lexical, semantic, and strategic elements. To model both structured knowledge and unstructured language, we propose a neural model with dynamic knowledge graph embeddings that evolve as the dialogue progresses. Automatic and human evaluations show that our model is both more effective at achieving the goal and more human-like than baseline neural and rule-based models.",
    "creator" : "Preview"
  }
}