{
  "name" : "103.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Measuring Topic Quality using Word Buckets",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "1 000\n011\n012\n013\n014\n015\n016\n017\n018\n019\n020\n021\n022\n023\n024\n025\n026\n027\n028\n029\n030\n031\n032\n033\n034\n035\n036\n037\n038\n039\n040\n041\n042\n043\n044\n045\n046\n047\n048\n049\n061\n062\n063\n064\n065\n066\n067\n068\n069\n070\n071\n072\n073\n074\n075\n076\n077\n078\n079\n080\n081\n082\n083\n084\n085\n086\n087\n088\n089\n090\n091\n092\n093\n094\n095\n096\n097\n098\n099"
    }, {
      "heading" : "1 Introduction",
      "text" : "Starting with the formalization of the notion of a topic as a probability distribution over words, probabilistic graphical models have been widely investigated for inferring the set of topics present in a document collection in an unsupervised manner (Blei et al., 2003). These models also infer the probability distribution over topics for documents in the collection. Since topics give a particular perspective on the structure of the document collection, topic modelling techniques have been applied on a variety of real-life document collections, such as scientific papers (Griffiths and Steyvers, 2004), (Blei, 2012) and newspapers archives (Yang et al., 2011). Topic models have also been used for im-\nproving many traditional text-mining tasks, such as document classification (Hingmire et al., 2013), document summarization (Wang et al., 2009), sentiment analysis (Lin and He, 2009), word sense disambiguation (Boyd-Graber et al., 2007), corpus visualization (Newman et al., 2010a) etc. Several variations on topic models are also being researched; e.g., correlated topic models (e.g., a document having a topic environment is likely to include topics such as UN and politics but not sports) (David M. Blei, 2007), dynamic topic models evolving over time (Blei and Lafferty, 2006), (Wang et al., 2008) and supervised topic models (Mcauliffe and Blei, 2008), (Ramage et al., 2009).\nGiven this growing importance of topic modelling in text mining techniques and in practical applications, it is crucial to ensure that the inferred topics are of as high quality as possible. An attractive feature of the probabilistic topic models is that the inferred topics can be easily interpreted by humans, each topic being just a bag of probabilistically selected “prominent” words in that topic’s distribution. This has opened up a research area which explores using human expertise or designing automated techniques to measure the quality of topics and improve the topic modelling techniques by incorporating these measures. As an example, consider the following two topics inferred from a document collection: {loan, foreclosure, mortgage, home, property, lender, housing, bank, homeowner, claim} {horse, sullivan, business, secretariat, owner, get, truck, back, old, merchant}\nThe first topic is easily interpretable by humans whereas the second topic is much less coherent and hence less understandable.\nOne could evaluate a single topic or an entire set of topics (“topic model”) for quality. Several different approaches have been proposed in the\n2\n101\n102\n103\n104\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n123\n124\n125\n126\n127\n128\n129\n130\n131\n132\n133\n134\n135\n136\n137\n138\n139\n140\n141\n142\n143\n144\n145\n146\n147\n148\n149\n150\n151\n152\n153\n154\n155\n156\n157\n158\n159\n160\n161\n162\n163\n164\n165\n166\n167\n168\n169\n170\n171\n172\n173\n174\n175\n176\n177\n178\n179\n180\n181\n182\n183\n184\n185\n186\n187\n188\n189\n190\n191\n192\n193\n194\n195\n196\n197\n198\n199\nliterature for measuring the quality of a particular topic or that of an entire topic model: word and topic intrusions (Chang et al., 2009), analysis of the topic word probability distributions (AlSumait et al., 2009), average pointwise mutual information (PMI) between topic words (Newman et al., 2010b), co-document frequencies of the topic words (Mimno et al., 2011), coverage and specificities of WordNet hierarchies for words in a topic (Musat et al., 2011), distributional semantics (distances between vectors for words in a topic) (Aletras and Stevenson, 2013), among many others.\nIn this paper, we propose a novel approach TBuckets which groups topic words into thematic groups (which we call buckets). The intuition is that if a single large bucket is obtained from a topic, then the topic carries a single coherent theme. Under TBuckets, we explore three techniques for creating buckets of words - i) clustering based, ii) using singular value decomposition (SVD) and iii) SVD with reorganization. We evaluate our techniques by correlating their estimated coherence scores with human annotated scores and compare with state-of-the-art results reported in Roder et al. (2015). The TBuckets approach not only outperforms the state-of-the-art, but its SVD-based techniques carry merit for being completely parameter free.\nThis rest of the paper is organized as follows. Section 2 briefly discusses the necessary background. Sections 3 describes the TBuckets approach in detail. Section 4 gives experimental evaluation of our techniques. Section 5 discusses the relevant related work and section 6 concludes with a discussion on future work."
    }, {
      "heading" : "2 Background",
      "text" : ""
    }, {
      "heading" : "2.1 Word Embeddings",
      "text" : "Word embeddings are vector representations of words which have become popular recently. Some efficient approaches to learn these vector representations from large unlabeled corpora are by Mikolov et al. (2013) and Pennington et al. (2014). Each word is mapped to a real-valued vector in d dimensions, such that vectors of semantically similar words lie close to each other. The cosine similarity of word vectors in this space is hence, a good estimation of semantic similarity between the corresponding words."
    }, {
      "heading" : "2.2 Singular Value Decomposition (SVD)",
      "text" : "Through SVD, a rectangular matrix A can be factorized to three components U , S and V where the matrix U contains eigenvectors of AAT , the matrix V contains the eigenvectors of ATA and the matrix S is a diagonal matrix containing the singular values of A, which are effectively square roots of eigenvalues of AAT and ATA. Intuitively, the SVD of a rectangular matrix, allows to express the matrix as a combination of three geometrical operations - rotation through U , scaling through S and another rotation through V . More clearly, for an m × n matrix A, where m entities are represented by their n features, the U matrix helps to identify important dimensions among the entities and the V matrix does so for important dimensions among the entities in terms of their features. In the paper, we focus particularly on the V matrix allowing us to obtain eigenvectors of the matrix ATA, which captures feature-feature interactions of the m entities."
    }, {
      "heading" : "3 TBuckets: Creating buckets of topic words",
      "text" : "The TBuckets idea is based on how we humans generally observe a topic and conclude on its coherence. Assuming a topic with words ordered (descending) by their probability of getting generated from the topic, the general procedure involves observing the topic words one by one and putting them in some form of logical groups (or buckets, as we call them). Starting with a fresh bucket for the first word, every new word is put in an already created bucket if the word is semantically similar or semantically associated with the words in the bucket; otherwise the word is put in a new bucket. On completion of this exercise, all topic words would be distributed in various buckets. A distribution with a single large bucket and few small buckets would signify better coherence. On the other hand, a distribution with multiple medium sized buckets would indicate lower coherence.\nTo see an example dry run of the above procedure, lets consider a coherent and a non-coherent topic. The topic {storm, weather, wind, temperature, rain, snow, air, high, cold, northern} is quite coherent and deals with weather and its factors. The bucket procedure for this topic executes as follows:\n1. Word Seen: storm. Bucket-1: {storm}\n3\n201\n202\n203\n204\n205\n206\n207\n208\n209\n210\n211\n212\n213\n214\n215\n216\n217\n218\n219\n220\n221\n222\n223\n224\n225\n226\n227\n228\n229\n230\n231\n232\n233\n234\n235\n236\n237\n238\n239\n240\n241\n242\n243\n244\n245\n246\n247\n248\n249\n250\n251\n252\n253\n254\n255\n256\n257\n258\n259\n260\n261\n262\n263\n264\n265\n266\n267\n268\n269\n270\n271\n272\n273\n274\n275\n276\n277\n278\n279\n280\n281\n282\n283\n284\n285\n286\n287\n288\n289\n290\n291\n292\n293\n294\n295\n296\n297\n298\n299\n2. Word Seen: weather. Bucket-1: {storm, weather}\n3. Word Seen: wind. Bucket-1: {storm, weather, wind}\n4. Word Seen: temperature. Bucket-1: {storm, weather, wind, temperature}\n5. Word Seen: rain. Bucket-1: {storm, weather, wind, temperature, rain}.\n6. Word Seen: snow. Bucket-1: {storm, weather, wind, temperature, rain, snow}.\n7. Word Seen: air. Bucket-1: {storm, weather, wind, temperature, rain, snow, air}.\n8. Word Seen: high. Bucket-1: {storm, weather, wind, temperature, rain, snow, air}; Bucket-2: {high}\n9. Word Seen: cold. Bucket-1: {storm, weather, wind, temperature, rain, snow, air, cold}; Bucket-2: {high}\n10. Word Seen: northern. Bucket-1: {storm, weather, wind, temperature, rain, snow, air, cold}; Bucket-2: {high}; Bucket-3: {northern}\nAnother topic {karzai, afghan, miner, official, mine, assange, government, kabul, afghanistan, wikileaks} is not coherent and deals with multiple areas like afghanistan, wikileaks and mining. The bucket procedure for this topic executes as follows:\n1. Word Seen: karzai. Bucket-1: {karzai}\n2. Word Seen: afghan. Bucket-1: {karzai, afghan}\n3. Word Seen: miner. Bucket-1: {karzai, afghan}; Bucket-2: {miner}\n4. Word Seen: official. Bucket-1: {storm, weather}; Bucket-2: {miner}; Bucket-3: {official}\n5. Word Seen: mine. Bucket-1: {karzai, afghan}; Bucket-2: {miner, mine}; Bucket-3: {official}\n6. Word Seen: assange. Bucket-1: {karzai, afghan}; Bucket-2: {miner, mine}; Bucket-3: {official}; Bucket-4: {assange}\n7. Word Seen: government. Bucket-1: {karzai, afghan}; Bucket-2: {miner, mine}; Bucket-3: {official, government}; Bucket-4: {assange}\n8. Word Seen: kabul. Bucket-1: {karzai, afghan, kabul}; Bucket-2: {miner, mine}; Bucket-3: {official, government}; Bucket-4: {assange}\n9. Word Seen: afghanistan. Bucket-1: {karzai, afghan, kabul, afghanistan}; Bucket-2: {miner, mine}; Bucket-3: {official, government}; Bucket-4: {assange}\n10. Word Seen: wikileaks. Bucket-1: {karzai, afghan, kabul, afghanistan}; Bucket-2: {miner, mine}; Bucket-3: {official, government}; Bucket-4: {assange, wikileaks}\nIt is evident from the above iterations that final distributions of topic words into buckets, reflects the coherence of a topic quite closely. Based on this idea, we devise approaches to carry out topic word distribution into buckets, automatically. We consider properties of the finally formed buckets to compute a coherence score for a topic.\nThe TBuckets approach powers us to do this bucketing automatically and generates a coherence score for a topic. It mainly requires two resources namely the word embeddings of topic words and the topic model (i.e. complete set of topics with words ordered according to their generation probability). These resources are not difficult to obtain as the topic model is available de facto and word embeddings of a large set of words, trained on various corpora, are now available publicly. The approach can be characterized through three techniques.\nThe first technique (TBuckets-Clustering) is based on a the idea of clustering which arises intuitively when we think of forming related groups among a set of items (words here). The TBucketsClustering technique involves representing words by their word embeddings and clustering them using agglomerative clustering. We use a maximum distance threshold as an input to the clustering for facilitating the agglomeration. Further we try with all single, average and complete linkage configurations. The technique proves to be competent involving only a single parameter.\nThe notion for the SVD-based technique (TBuckets-SVD) is to find the various orthogonal\n4\n301\n302\n303\n304\n305\n306\n307\n308\n309\n310\n311\n312\n313\n314\n315\n316\n317\n318\n319\n320\n321\n322\n323\n324\n325\n326\n327\n328\n329\n330\n331\n332\n333\n334\n335\n336\n337\n338\n339\n340\n341\n342\n343\n344\n345\n346\n347\n348\n349\n350\n351\n352\n353\n354\n355\n356\n357\n358\n359\n360\n361\n362\n363\n364\n365\n366\n367\n368\n369\n370\n371\n372\n373\n374\n375\n376\n377\n378\n379\n380\n381\n382\n383\n384\n385\n386\n387\n388\n389\n390\n391\n392\n393\n394\n395\n396\n397\n398\n399\ndimensions or sub-themes inside a topic and attach words to those sub-themes. The technique starts by constructing a matrix of d dimensional word embeddings of n words of a topic leading to a n × d rectangular matrix A. An SVD operation on A provides the orthonormal bases in U and V and singular values in S. We focus particularly on the V matrix, as that records the eigenvectors of ATA, which are in turn the orthogonal d dimensional directions we are interested in. This is intuitive as a d dimensional vector would represent some definite concept in the space of word embeddings and can become a distinct bucket identifier. Further, the V matrix, provides eigenvectors ordered according to most significant singular values first. We use the first n eigenvectors as bucket identifiers to attach words to. The attachment is simple - the word goes to the bucket represented by the word’s most similar eigenvector."
    }, {
      "heading" : "3.1 Reorganization over TBuckets-SVD",
      "text" : "Observation of buckets getting formed by TBuckets-SVD revealed that some words in spite of being similar/associated with words in the largest bucket, were being put to another bucket due to high similarity with that eigenvector. An example of such a topic is - {show, television, tv, news, network, medium, fox, cable, channel, series}. The output of TBuckets-SVD reveals the distribution - Bucket 1: {show, television, tv, network, cable, channel}; Bucket 2: {medium}; Bucket 3: {series}; Bucket 4: {news}; Bucket 5: {fox}. We can clearly observe that words news, fox and series belonging to other buckets should be a part of the largest bucket (Bucket 1). Many such similar examples were observed and hence the need for a reorganization step over TBuckets-SVD was desirable. Moreover, there were examples of topics where some words in the largest bucket were a better fit to other buckets than the current one and hence needed to be evicted for better coherence of the largest bucket. An example is a topic where TBuckets-SVD generates the largest bucket as {cocktail, glass, drink, girl}, where it is important to shift the word girl out from the bucket.\nWe collectively denote both the reorganization steps i.e. into and from the largest bucket, as the TBuckets-SVD-Reorg technique. The methodol-\nogy for automatic reorganization is based on four important parameters for each word:\n• Native Bucket Pull - Words (NBPW): Maximum semantic similarity of the word with all other words in the word’s native bucket.\n• Native Bucket Pull - EigenVector (NBPE): Similarity of the word with the eigenvector representing the word’s native bucket.\n• Largest Bucket Pull - Words (LBPW): Maximum semantic similarity of the word with all words in the largest bucket.\n• Other Bucket Pull - Words (OBPW): Maximum semantic similarity of the word with all words in a bucket other than the native bucket.\nNow, it is intuitive that for a word in the nonlargest bucket, a condition where LBPW > NBPE, is a indication for carrying out the into step and for a word in the largest bucket, a condition where OBPW > max(NBPW, NBPE) is an indication for carrying out the from step. However, considering the into case, even a marginal difference (say of the order 0.01 or less) between LBPW and NBPE would lead to the shift. A similar argument holds for the from case. Hence, an additive threshold to the Right Hand Side (RHS) in both conditions would be necessary. We do not decide the threshold empirically, instead devise it based on the topic under consideration and hence removing possibility of any parameter tuning. The dynamic threshold depends on two values namely average word pair similarity (AWPS) among the topic words and average word eigenvector similarity (AWES). The former value is computed as an average of semantic similarity among all pairs of words in the topic. The latter value is obtained after the buckets are formed using TBuckets-SVD and the value is computed as an average of similarities between each word and its corresponding bucket’s eigenvector. The threshold is computed as AWES − AWPSAWES . The ratio in the threshold denotes flexibility among words for reorganization. A higher value of the ratio indicates better word-word similarities and lenient word-eigenvector similarities making reorganization meaningful. The subtraction from AWES manages the gap in the ranges of word pair similarities and word eigenvector similarities.\n5\n401\n402\n403\n404\n405\n406\n407\n408\n409\n410\n411\n412\n413\n414\n415\n416\n417\n418\n419\n420\n421\n422\n423\n424\n425\n426\n427\n428\n429\n430\n431\n432\n433\n434\n435\n436\n437\n438\n439\n440\n441\n442\n443\n444\n445\n446\n447\n448\n449\n450\n451\n452\n453\n454\n455\n456\n457\n458\n459\n460\n461\n462\n463\n464\n465\n466\n467\n468\n469\n470\n471\n472\n473\n474\n475\n476\n477\n478\n479\n480\n481\n482\n483\n484\n485\n486\n487\n488\n489\n490\n491\n492\n493\n494\n495\n496\n497\n498\n499"
    }, {
      "heading" : "3.2 Computation of coherence score",
      "text" : "For all techniques we consider the properties of words in the largest bucket to compute the coherence score. This scoring is in line with the important idea - more topic words belonging to a common theme signifies higher coherence. The coherence is computed based on various word and bucket properties like length of the largest bucket, function of word order in the topic, similarity to the eigenvector and most significant singular value.\nConsider the largest bucket obtained from a topic, Bucket 1: {w0, · · ·wk−1}. A basic coherence score is the size of Bucket 1 which is k in this case. We also consider the order of words in a topic which is based on their generation probability. A weight is computed for each ith word in a topic as follows:\nLDA Order Weight(wi) = 1\nlog(i+ 1) if i > 0\n= 1 otherwise\nTopic coherence score based on LDA word order, denoted by WL, is then computed as the sum of LDA Order Weight of each word in the largest bucket. For TBuckets-SVD and TBucketsSVD-Reorg, another topic coherence score, denoted as EVS, can be computed using each word’s similarity with its corresponding eigenvector. For reporting results for TBuckets-SVD and TBuckets-SVD-Reorg techniques, we weight the scores (size, WL and EVS) with the square of the highest singular value."
    }, {
      "heading" : "4 Experimental Analysis",
      "text" : ""
    }, {
      "heading" : "4.1 Datasets",
      "text" : "We evaluate TBuckets on 3 datasets - 20 NewsGroups (20NG), New York Times (NYT) and Genomics. Each dataset consists of a set of 100 topics where each topic is represented by its 10 most probable words. Moreover, each topic is associated with a real number between 1 and 3 indicating human judgement of its coherence. Detailed description of these datasets is provided in Roder et. al (2015).\nFor all our experiments, we use the 300 dimensional pre-trained word embeddings provided by the GloVe framework 1. These embeddings have\n1http://nlp.stanford.edu/projects/ glove/\nbeen trained on Wikipedia and Gigaword corpora."
    }, {
      "heading" : "4.2 Evaluation",
      "text" : "We use the same evaluation scheme used in (Röder et al., 2015). Each technique generates coherence scores for all the topics in a dataset. Pearson’s r correlation co-efficient is computed between the coherence scores based on human judgement and the coherence scores automatically generated by the technique. Higher the correlation with human scores, better is the performance of the technique at measuring coherence.\nTable 1 shows the Pearson’s r values for our techniques - TBuckets-Clustering, TBuckets-SVD and TBuckets-SVD-Reorg. We compare their performance with the best performing correlation values as reported by Roder et al. (2015).\nAs observed in Table 1, our technique TBuckets-SVD-Reorg outperforms the state-ofthe-art on 2 out of 3 datasets, namely NYT and 20NG. This is significant considering the fact that both SVD based techniques are completely parameter less whereas the state-of-the-art requires considerable tuning of multiple parameters. This also is a sound validation of the TBuckets idea for measuring topic coherence. TBuckets-Clustering also performs at par with the state-of-the-art on the Genomics dataset. It requires only one parameter, namely Max Dist which is maximum allowable distance for merging in Agglomerative clustering. Figure 1 shows the variation in the performance of TBuckets-Clustering for various values of Max Dist. Table 2 shows some examples of topics and the buckets which were created for them using the TBuckets-SVD-Reorg technique."
    }, {
      "heading" : "4.3 Application to Text Classification",
      "text" : "Topic models have been used for text classification with weak supervision in several previous approaches like Hingmire et al. (2013), Hingmire and Chakraborti (2014) and Pawar et al. (2016). The core idea used in these approaches is that instead of obtaining gold labels for documents, the human annotators can provide labels for the learned topics. This reduces the labelling effort drastically as it was reported that a small number of topics (usually twice the number of class labels) was sufficient to achieve good classification performance.\nAs learning topics from a text corpus is based on approximate inference, different topics are generated when the process of learning topics is run\n6\n501\n502\n503\n504\n505\n506\n507\n508\n509\n510\n511\n512\n513\n514\n515\n516\n517\n518\n519\n520\n521\n522\n523\n524\n525\n526\n527\n528\n529\n530\n531\n532\n533\n534\n535\n536\n537\n538\n539\n540\n541\n542\n543\n544\n545\n546\n547\n548\n549\n550\n551\n552\n553\n554\n555\n556\n557\n558\n559\n560\n561\n562\n563\n564\n565\n566\n567\n568\n569\n570\n571\n572\n573\n574\n575\n576\n577\n578\n579\n580\n581\n582\n583\n584\n585\n586\n587\n588\n589\n590\n591\n592\n593\n594\n595\n596\n597\n598\n599\nSetting/Scoring Metric NYT 20NG Genomics Roder et al. (2015) Best performing settings 0.806 0.859 0.773\nTBuckets-Clustering\nSingle-linkage, size 0.779 (0.63) 0.832 (0.7) 0.774 (0.67) Single-linkage, WL 0.766 (0.63) 0.848 (0.72) 0.751 (0.69) Average-linkage, size 0.745 (0.81) 0.856 (0.79) 0.709 (0.77) Average-linkage, WL 0.73 (0.81) 0.863 (0.79) 0.721 (0.86) Complete-linkage, size 0.709 (0.91) 0.806 (0.86) 0.581 (0.81) Complete-linkage, WL 0.702 (0.91) 0.835 (0.86) 0.567 (0.81)\nTBuckets-SVD\nsize 0.758 0.867 0.698 WL 0.772 0.868 0.694 EVS 0.762 0.854 0.693 WL*EVS 0.772 0.858 0.69\nTBuckets-SVD-Reorg size 0.837 0.863 0.68 WL 0.837 0.866 0.685 EVS 0.828 0.868 0.687 WL*EVS 0.833 0.869 0.691\nsize: Size of the largest bucket WL: Word order based on generation probability from LDA\nEVS: Eigenvector similarity\nTable 1: Comparative performance of various techniques in terms of Pearson’s r correlation co-efficient\nFigure 1: Effect of varying Max Dist for TBuckets-Clustering (size)\nDataset Buckets TBuckets-SVD-Reorg Human\n20NG\nBucket 1: { gun, crime, firearm, weapon, handgun, law, criminal, control} Bucket 2: { rate} Bucket 3: { 000}\n0.542 2.3125\n20NG\nBucket 1: { convex} Bucket 2: { oracle, opinion, expressed} Bucket 3: { user} Bucket 4: { princeton, tamu} Bucket 5: { corporation} Bucket 6: { phil} Bucket 7: { phoenix}\n0.028 1.23\nNYT Bucket 1: { show, television, tv, network, cable, channel, series, news, fox} Bucket 2: { medium}\n0.796 2.82\nNYT\nBucket 1: { portugal, portuguese} Bucket 2: { dinosaur, fossil} Bucket 3: { apple} Bucket 4: { ant} Bucket 5: { rent, peru} Bucket 6: { sherman} Bucket 7: { evans}\n0.071 1.25\nTBuckets-SVD-Reorg coherence scores are normalized to lie between 0 and 1 Human assigned coherence scores lie between 1 and 3\nTable 2: Examples of buckets created using TBuckets-SVD-Reorg\n7\n601\n602\n603\n604\n605\n606\n607\n608\n609\n610\n611\n612\n613\n614\n615\n616\n617\n618\n619\n620\n621\n622\n623\n624\n625\n626\n627\n628\n629\n630\n631\n632\n633\n634\n635\n636\n637\n638\n639\n640\n641\n642\n643\n644\n645\n646\n647\n648\n649\n650\n651\n652\n653\n654\n655\n656\n657\n658\n659\n660\n661\n662\n663\n664\n665\n666\n667\n668\n669\n670\n671\n672\n673\n674\n675\n676\n677\n678\n679\n680\n681\n682\n683\n684\n685\n686\n687\n688\n689\n690\n691\n692\n693\n694\n695\n696\n697\n698\n699\nmultiple times. Hence, the process of learning topics is repeated several times and the average of classification accuracies obtained over these runs is considered as the final accuracy. Labels by human annotators have to be obtained for the set of topics generated in each of these runs. As reported in (Pawar et al., 2016) the quality of topics can be different for various runs. Low quality topics are difficult for human annotators to annotate and incorrect labels by them results in poor classification performance. To overcome this problem, we propose to evaluate quality of topics using TBuckets and present only high quality topics for human annotation. For computing quality of set of topics, we simply add the coherence scores of individual topics in the set. As all the set of topics have same number of topics, these scores are comparable.\nHere, we consider 4 subsets (PC vs MAC, MEDICAL vs SPACE, POLITICS vs SCIENCE and POLITICS vs RELIGION) of 20NG dataset for the experiments involving text classification using topic labelling. We compare the performance of LPA-TD classifier used in (Pawar et al., 2016) using two different strategies for generating and labelling topics (Table 3):\nS1 (Without considering quality of topics) : Topic learning process is repeated for 5 times and human annotations were obtained. Reported classification accuracies are average of accuracies for all 5 runs.\nS2 (Considering quality of topics) : Topic learning process is repeated for 10 times and quality of each set of topics was measured using TBuckets-SVDReorg. But human annotations were obtained only for the best 5 sets of topics. Reported classification accuracies are average of accuracies for the corresponding 5 runs with best coherence scores. To emphasize usefulness of our coherence scores, we also obtain human annotations for remaining 5 sets of topics with lowest coherence scores and report average classification performance for them also.\nIt can be observed from Table 3 that strategy S2 produces better accuracies than S1 in 3 out of 4 datasets. Also, except for the MED-SPACE dataset, there is wide difference in the accuracies in S2 when the highest 5 sets of topics as per coherence are considered as against the lowest 5 sets. This can be attributed to the fact that MED-SPACE is considered to be one of the easiest for classification amongst the 20NG datasets and hence coherent topics are generated more often than not.\nDataset S1 S2\n5 Highest 5 Lowest Coh. sets Coh. sets\nPC vs MAC 66.98 68.47 67.96 MEDICAL vs SPACE 94.67 94.83 95.37 POLITICS vs SCIENCE 95.95 96.19 91.09 POLITICS vs RELIGION 85.61 85.23 82.85\nTable 3: Text Classification performance (macroF1) with and without considering quality of topics\nFor other datasets, especially PC-MAC which is considered one of the most difficult amongst the 20NG datasets, the large difference in accuracies (Highest 5 coherence sets vs Lowest 5 coherence sets) underlines the importance of measuring topic coherence before obtaining human annotations."
    }, {
      "heading" : "5 Related Work",
      "text" : "LDA uses statistical relations between words like word co-occurrence while inferring topics and not semantic relations. Hence, topics inferred by LDA may not correlate well with human judgements even though they better optimize perplexity on held-out documents (Chang et al., 2009). (Chang et al., 2009) emphasize that quality of topics should depend on their human interpretability rather than purely statistical measures like perplexity.\nSeveral authors (e.g. (Newman et al., 2010b; Mimno et al., 2011)) hypothesize that coherence of the most N probable words of a topic capture its semantic interpretability and proposed measures to estimate coherence of topics. (Newman et al., 2010b) used the set of N most probable words of a topic and computed its coherence (CUCI ) based on pointwise mutual information (PMI) between all possible word pairs of N words. CUCI of a topic t is computed as:\nCUCI(t) = 2\nN(N − 1) N−1∑ i=1 N∑ j=i+1 PMI(wi, wj)\nwhere,\nPMI(wi, wj) = log P (wi, wj)\nP (wi)P (wj)\nWhere, P (wi, wj) is estimated based on the number of times words wi and wj co-occur in a sliding window of size 10 that moves over all the articles in Wikipedia. (Lau et al., 2014) propose a variant\n8\n701\n702\n703\n704\n705\n706\n707\n708\n709\n710\n711\n712\n713\n714\n715\n716\n717\n718\n719\n720\n721\n722\n723\n724\n725\n726\n727\n728\n729\n730\n731\n732\n733\n734\n735\n736\n737\n738\n739\n740\n741\n742\n743\n744\n745\n746\n747\n748\n749\n750\n751\n752\n753\n754\n755\n756\n757\n758\n759\n760\n761\n762\n763\n764\n765\n766\n767\n768\n769\n770\n771\n772\n773\n774\n775\n776\n777\n778\n779\n780\n781\n782\n783\n784\n785\n786\n787\n788\n789\n790\n791\n792\n793\n794\n795\n796\n797\n798\n799\nof CUCI by using normalized PMI (NPMI) instead of PMI.\n(Mimno et al., 2011) propose similar topic coherence measure (CUMASS) that uses log conditional probability (LCP) instead of PMI and uses the same corpus on which topics are inferred, to estimate LCP rather than Wikipedia. CUMASS for a topic t is computed as:\nCUMASS(t) = 2\nN(N − 1) N∑ i=2 i−1∑ j=1 log P (wi, wj) + 1 P (wj)\n(Aletras and Stevenson, 2013) propose a topic coherence measure based on distributional similarity between the most N probable words of the topic. In this approach, a topic word (wi) is represented as a context vector (~vi) over the words that co-occur with wi in Wikipedia in a window of ±5 words, such that vi,j represents PMI (or NPMI) between words wi and wj . The word vectors of topic words are then used to find coherence (CUSheffield) of a topic (t) as follows:\nCUSheffield(t) =\n∑N i=1 sim(TC , ~vi)\nN\nwhere, TC represents the centroid of the word vectors of the topic and sim(~u,~v) is cosine similarity between vectors ~u and ~v.\n(Aletras and Stevenson, 2013) observed that CUCI with NPMI correlates well with human judgements than CUMASS and CUCI with PMI.\n(Aletras and Stevenson, 2013) also propose an alternative to CUSheffield where they represent a topic word wi as a context vector over the space of topic words only. They observed that CUSheffield with topic words only outperforms CUCI with NPMI.\nRoder et al. (2015) propose a unifying framework that represents a coherence measure as a composition of parts, that can be freely combined to form a configuration space of coherence definitions. These parts can be grouped into four dimensions: 1) first dimension defines number of ways a word set can be divided into smaller pieces, 2) second dimension defines confirmation measures like PMI or NPMI to measure the agreement of a given word pair, 3) third dimension defines different ways to estimate word probabilities (P (wi) and P (wi, wj)), 4) fourth dimension defines methods to aggregate scalar values computed by the\nconfirmation measure. This framework spans over a large number of configuration space of coherence measures, hence it becomes computationally expensive to find appropriate coherence measure for a set of topics."
    }, {
      "heading" : "6 Conclusion and Future Work",
      "text" : "We proposed a novel approach TBuckets to measure quality of Latent Dirichlet Allocation (LDA) based topics, based on grouping of topic words into buckets. TBuckets uses 3 different techniques for creating buckets of words - TBucketsClustering which performs agglomerative clustering of words, TBuckets-SVD which uses singular value decomposition (SVD) to discover important sub-themes in topic words and lastly TBucketsSVD-Reorg which reorganized buckets obtained from TBuckets-SVD. We evaluated our techniques on three publicly available datasets by correlating the estimated coherence scores with human annotated scores and demonstrated better performance than the state-of-the-art results. Moreover, as compared to the state-of-the-art technique which needs to tune multiple parameters, our techniques TBuckets-SVD and TBuckets-SVD-Reorg require absolutely no parameter tuning. We also highlighted the utility of TBuckets for the task of weakly supervised text classification.\nIn future, we plan to devise better ways to compute word similarities which would be more suitable for specific domains like Genomics. Furthermore, we plan to devise a unified framework to evaluate and employ various scoring metrics. Also, we wish to explore usefulness of our techniques for applications other than text classification."
    } ],
    "references" : [ {
      "title" : "Evaluating topic coherence using distributional semantics",
      "author" : [ "N. Aletras", "M. Stevenson." ],
      "venue" : "Proceedings of the Tenth International Workshop on Computational Semantics, pages 13–22.",
      "citeRegEx" : "Aletras and Stevenson.,? 2013",
      "shortCiteRegEx" : "Aletras and Stevenson.",
      "year" : 2013
    }, {
      "title" : "Topic significance ranking of lda generative models",
      "author" : [ "Loulwah AlSumait", "Daniel Barbara", "James Gentle", "Carlotta Domeniconi." ],
      "venue" : "Machine Learning and Knowledge Discovery in Databases, pages 67–82.",
      "citeRegEx" : "AlSumait et al\\.,? 2009",
      "shortCiteRegEx" : "AlSumait et al\\.",
      "year" : 2009
    }, {
      "title" : "Dynamic topic models",
      "author" : [ "David M. Blei", "John D. Lafferty." ],
      "venue" : "Proceedings of the 23rd International Conference on Machine Learning, ICML ’06, pages 113–120.",
      "citeRegEx" : "Blei and Lafferty.,? 2006",
      "shortCiteRegEx" : "Blei and Lafferty.",
      "year" : 2006
    }, {
      "title" : "Latent dirichlet allocation",
      "author" : [ "David M. Blei", "Andrew Y. Ng", "Michael I. Jordan." ],
      "venue" : "Journal of Machine Learning Research, 3:993–1022, March.",
      "citeRegEx" : "Blei et al\\.,? 2003",
      "shortCiteRegEx" : "Blei et al\\.",
      "year" : 2003
    }, {
      "title" : "Probabilistic topic models",
      "author" : [ "David M. Blei." ],
      "venue" : "Communications of ACM, 55(4):77–84, April.",
      "citeRegEx" : "Blei.,? 2012",
      "shortCiteRegEx" : "Blei.",
      "year" : 2012
    }, {
      "title" : "A topic model for word sense disambiguation",
      "author" : [ "Jordan L. Boyd-Graber", "David M. Blei", "Xiaojin Zhu." ],
      "venue" : "EMNLP-CoNLL, pages 1024–1033.",
      "citeRegEx" : "Boyd.Graber et al\\.,? 2007",
      "shortCiteRegEx" : "Boyd.Graber et al\\.",
      "year" : 2007
    }, {
      "title" : "Reading tea leaves: How humans interpret topic models",
      "author" : [ "Jonathan Chang", "Jordan Boyd-Graber", "Chong Wang", "Sean Gerrish", "David M. Blei." ],
      "venue" : "Neural Information Processing Systems.",
      "citeRegEx" : "Chang et al\\.,? 2009",
      "shortCiteRegEx" : "Chang et al\\.",
      "year" : 2009
    }, {
      "title" : "A correlated topic model of science",
      "author" : [ "John D. Lafferty David M. Blei." ],
      "venue" : "The Annals of Applied Statistics, 1(1):17–35.",
      "citeRegEx" : "Blei.,? 2007",
      "shortCiteRegEx" : "Blei.",
      "year" : 2007
    }, {
      "title" : "Finding scienti?c topics",
      "author" : [ "Thomas L. Griffiths", "Mark Steyvers." ],
      "venue" : "Proceedings of the National Academy of Sciences 101 (Suppl 1), pages 5228– 5235.",
      "citeRegEx" : "Griffiths and Steyvers.,? 2004",
      "shortCiteRegEx" : "Griffiths and Steyvers.",
      "year" : 2004
    }, {
      "title" : "Topic labeled text classification: a weakly supervised approach",
      "author" : [ "Swapnil Hingmire", "Sutanu Chakraborti." ],
      "venue" : "Proceedings of the 37th international ACM SIGIR conference on Research & development in information retrieval, pages 385–394.",
      "citeRegEx" : "Hingmire and Chakraborti.,? 2014",
      "shortCiteRegEx" : "Hingmire and Chakraborti.",
      "year" : 2014
    }, {
      "title" : "Document classification by topic labeling",
      "author" : [ "Swapnil Hingmire", "Sandeep Chougule", "Girish K. Palshikar", "Sutanu Chakraborti." ],
      "venue" : "Proceedings of the 36th International ACM SIGIR Conference on Research and Development in Information Re-",
      "citeRegEx" : "Hingmire et al\\.,? 2013",
      "shortCiteRegEx" : "Hingmire et al\\.",
      "year" : 2013
    }, {
      "title" : "Machine Reading Tea Leaves: Automatically Evaluating Topic Coherence And Topic Model Quality",
      "author" : [ "Jey Han Lau", "David Newman", "Timothy Baldwin." ],
      "venue" : "EACL, pages 530–539.",
      "citeRegEx" : "Lau et al\\.,? 2014",
      "shortCiteRegEx" : "Lau et al\\.",
      "year" : 2014
    }, {
      "title" : "Joint sentiment/topic model for sentiment analysis",
      "author" : [ "Chenghua Lin", "Yulan He." ],
      "venue" : "Proceedings of the 18th ACM Conference on Information and Knowledge Management, CIKM ’09, pages 375–384.",
      "citeRegEx" : "Lin and He.,? 2009",
      "shortCiteRegEx" : "Lin and He.",
      "year" : 2009
    }, {
      "title" : "Supervised topic models",
      "author" : [ "Jon D. Mcauliffe", "David M. Blei." ],
      "venue" : "Proc. Advances in Neural Information Processing Systems 20, pages 121–128.",
      "citeRegEx" : "Mcauliffe and Blei.,? 2008",
      "shortCiteRegEx" : "Mcauliffe and Blei.",
      "year" : 2008
    }, {
      "title" : "Efficient estimation of word representations in vector space",
      "author" : [ "Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean." ],
      "venue" : "arXiv preprint arXiv:1301.3781.",
      "citeRegEx" : "Mikolov et al\\.,? 2013",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2013
    }, {
      "title" : "Optimizing semantic coherence in topic models",
      "author" : [ "David Mimno", "Hanna Wallach", "Edmund Talley", "Miriam Leenders", "Andrew McCallum." ],
      "venue" : "Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages",
      "citeRegEx" : "Mimno et al\\.,? 2011",
      "shortCiteRegEx" : "Mimno et al\\.",
      "year" : 2011
    }, {
      "title" : "Improving topic evaluation using conceptual knowledge",
      "author" : [ "Claudiu C. Musat", "Julien Velcin", "Stefan Trausan-Matu", "Marian A. Rizoiu." ],
      "venue" : "Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence, pages 1866–1871.",
      "citeRegEx" : "Musat et al\\.,? 2011",
      "shortCiteRegEx" : "Musat et al\\.",
      "year" : 2011
    }, {
      "title" : "Visualizing search results and document collections using topic maps",
      "author" : [ "David Newman", "Timothy Baldwin", "Lawrence Cavedon", "Eric Huang", "Sarvnaz Karimi", "David Martinez", "Falk Scholer", "Justin Zobel." ],
      "venue" : "Web Semantics: Science, Services and Agents",
      "citeRegEx" : "Newman et al\\.,? 2010a",
      "shortCiteRegEx" : "Newman et al\\.",
      "year" : 2010
    }, {
      "title" : "Automatic evaluation of topic coherence",
      "author" : [ "David Newman", "Jey Han Lau", "Karl Grieser", "Timothy Baldwin." ],
      "venue" : "Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Lin-",
      "citeRegEx" : "Newman et al\\.,? 2010b",
      "shortCiteRegEx" : "Newman et al\\.",
      "year" : 2010
    }, {
      "title" : "Topics and label propagation: Best of both worlds for weakly supervised text classification",
      "author" : [ "Sachin Pawar", "Nitin Ramrakhiyani", "Swapnil Hingmire", "Girish Palshikar." ],
      "venue" : "CICLing.",
      "citeRegEx" : "Pawar et al\\.,? 2016",
      "shortCiteRegEx" : "Pawar et al\\.",
      "year" : 2016
    }, {
      "title" : "Glove: Global vectors for word representation",
      "author" : [ "Jeffrey Pennington", "Richard Socher", "Christopher D Manning." ],
      "venue" : "EMNLP, volume 14, pages 1532– 1543.",
      "citeRegEx" : "Pennington et al\\.,? 2014",
      "shortCiteRegEx" : "Pennington et al\\.",
      "year" : 2014
    }, {
      "title" : "Labeled lda: A supervised topic model for credit attribution in multilabeled corpora",
      "author" : [ "Daniel Ramage", "David Hall", "Ramesh Nallapati", "Christopher D. Manning." ],
      "venue" : "Proceedings of the 2009 Conference on Empirical Methods in Natural Language",
      "citeRegEx" : "Ramage et al\\.,? 2009",
      "shortCiteRegEx" : "Ramage et al\\.",
      "year" : 2009
    }, {
      "title" : "Exploring the space of topic coherence measures",
      "author" : [ "Michael Röder", "Andreas Both", "Alexander Hinneburg." ],
      "venue" : "Proceedings of the eighth ACM international conference on Web search and data mining, pages 399–408. ACM.",
      "citeRegEx" : "Röder et al\\.,? 2015",
      "shortCiteRegEx" : "Röder et al\\.",
      "year" : 2015
    }, {
      "title" : "Continuous time dynamic topic models",
      "author" : [ "C. Wang", "D. Blei", "D. Heckerman." ],
      "venue" : "The 23rd Conference on Uncertainty in Artificial Intelligence.",
      "citeRegEx" : "Wang et al\\.,? 2008",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2008
    }, {
      "title" : "Multi-document summarization using sentence-based topic models",
      "author" : [ "Dingding Wang", "Shenghuo Zhu", "Tao Li", "Yihong Gong." ],
      "venue" : "Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, ACLShort ’09, pages 297–300.",
      "citeRegEx" : "Wang et al\\.,? 2009",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2009
    }, {
      "title" : "Topic modeling on historical newspapers",
      "author" : [ "Tze-I Yang", "Andrew J. Torget", "Rada Mihalcea." ],
      "venue" : "Proceedings of the 5th ACL-HLT Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities, pages 96–104.",
      "citeRegEx" : "Yang et al\\.,? 2011",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2011
    } ],
    "referenceMentions" : [ {
      "referenceID" : 3,
      "context" : "Starting with the formalization of the notion of a topic as a probability distribution over words, probabilistic graphical models have been widely investigated for inferring the set of topics present in a document collection in an unsupervised manner (Blei et al., 2003).",
      "startOffset" : 251,
      "endOffset" : 270
    }, {
      "referenceID" : 8,
      "context" : "Since topics give a particular perspective on the structure of the document collection, topic modelling techniques have been applied on a variety of real-life document collections, such as scientific papers (Griffiths and Steyvers, 2004), (Blei, 2012) and newspapers archives (Yang et al.",
      "startOffset" : 207,
      "endOffset" : 237
    }, {
      "referenceID" : 4,
      "context" : "Since topics give a particular perspective on the structure of the document collection, topic modelling techniques have been applied on a variety of real-life document collections, such as scientific papers (Griffiths and Steyvers, 2004), (Blei, 2012) and newspapers archives (Yang et al.",
      "startOffset" : 239,
      "endOffset" : 251
    }, {
      "referenceID" : 25,
      "context" : "Since topics give a particular perspective on the structure of the document collection, topic modelling techniques have been applied on a variety of real-life document collections, such as scientific papers (Griffiths and Steyvers, 2004), (Blei, 2012) and newspapers archives (Yang et al., 2011).",
      "startOffset" : 276,
      "endOffset" : 295
    }, {
      "referenceID" : 10,
      "context" : "Topic models have also been used for improving many traditional text-mining tasks, such as document classification (Hingmire et al., 2013), document summarization (Wang et al.",
      "startOffset" : 115,
      "endOffset" : 138
    }, {
      "referenceID" : 24,
      "context" : ", 2013), document summarization (Wang et al., 2009), sentiment analysis (Lin and He, 2009), word sense disambiguation (Boyd-Graber et al.",
      "startOffset" : 32,
      "endOffset" : 51
    }, {
      "referenceID" : 12,
      "context" : ", 2009), sentiment analysis (Lin and He, 2009), word sense disambiguation (Boyd-Graber et al.",
      "startOffset" : 28,
      "endOffset" : 46
    }, {
      "referenceID" : 5,
      "context" : ", 2009), sentiment analysis (Lin and He, 2009), word sense disambiguation (Boyd-Graber et al., 2007), corpus visualization (Newman et al.",
      "startOffset" : 74,
      "endOffset" : 100
    }, {
      "referenceID" : 17,
      "context" : ", 2007), corpus visualization (Newman et al., 2010a) etc.",
      "startOffset" : 30,
      "endOffset" : 52
    }, {
      "referenceID" : 2,
      "context" : "Blei, 2007), dynamic topic models evolving over time (Blei and Lafferty, 2006), (Wang et al.",
      "startOffset" : 53,
      "endOffset" : 78
    }, {
      "referenceID" : 23,
      "context" : "Blei, 2007), dynamic topic models evolving over time (Blei and Lafferty, 2006), (Wang et al., 2008) and supervised topic models (Mcauliffe and Blei, 2008), (Ramage et al.",
      "startOffset" : 80,
      "endOffset" : 99
    }, {
      "referenceID" : 13,
      "context" : ", 2008) and supervised topic models (Mcauliffe and Blei, 2008), (Ramage et al.",
      "startOffset" : 36,
      "endOffset" : 62
    }, {
      "referenceID" : 21,
      "context" : ", 2008) and supervised topic models (Mcauliffe and Blei, 2008), (Ramage et al., 2009).",
      "startOffset" : 64,
      "endOffset" : 85
    }, {
      "referenceID" : 6,
      "context" : "literature for measuring the quality of a particular topic or that of an entire topic model: word and topic intrusions (Chang et al., 2009), analysis of the topic word probability distributions (AlSumait et al.",
      "startOffset" : 119,
      "endOffset" : 139
    }, {
      "referenceID" : 1,
      "context" : ", 2009), analysis of the topic word probability distributions (AlSumait et al., 2009), average pointwise mutual information (PMI) between topic words (Newman et al.",
      "startOffset" : 62,
      "endOffset" : 85
    }, {
      "referenceID" : 18,
      "context" : ", 2009), average pointwise mutual information (PMI) between topic words (Newman et al., 2010b), co-document frequencies of the topic words (Mimno et al.",
      "startOffset" : 72,
      "endOffset" : 94
    }, {
      "referenceID" : 15,
      "context" : ", 2010b), co-document frequencies of the topic words (Mimno et al., 2011), coverage and specificities of WordNet hierarchies for words in a topic (Musat et al.",
      "startOffset" : 53,
      "endOffset" : 73
    }, {
      "referenceID" : 16,
      "context" : ", 2011), coverage and specificities of WordNet hierarchies for words in a topic (Musat et al., 2011), distributional semantics (distances between vectors for words in a topic) (Aletras and Stevenson, 2013), among many others.",
      "startOffset" : 80,
      "endOffset" : 100
    }, {
      "referenceID" : 0,
      "context" : ", 2011), distributional semantics (distances between vectors for words in a topic) (Aletras and Stevenson, 2013), among many others.",
      "startOffset" : 83,
      "endOffset" : 112
    }, {
      "referenceID" : 0,
      "context" : ", 2011), distributional semantics (distances between vectors for words in a topic) (Aletras and Stevenson, 2013), among many others. In this paper, we propose a novel approach TBuckets which groups topic words into thematic groups (which we call buckets). The intuition is that if a single large bucket is obtained from a topic, then the topic carries a single coherent theme. Under TBuckets, we explore three techniques for creating buckets of words - i) clustering based, ii) using singular value decomposition (SVD) and iii) SVD with reorganization. We evaluate our techniques by correlating their estimated coherence scores with human annotated scores and compare with state-of-the-art results reported in Roder et al. (2015). The TBuckets approach not only outperforms the state-of-the-art, but its SVD-based techniques carry merit for being completely parameter free.",
      "startOffset" : 84,
      "endOffset" : 730
    }, {
      "referenceID" : 14,
      "context" : "Some efficient approaches to learn these vector representations from large unlabeled corpora are by Mikolov et al. (2013) and Pennington et al.",
      "startOffset" : 100,
      "endOffset" : 122
    }, {
      "referenceID" : 14,
      "context" : "Some efficient approaches to learn these vector representations from large unlabeled corpora are by Mikolov et al. (2013) and Pennington et al. (2014). Each word is mapped to a real-valued vector in d dimensions, such that vectors of semantically similar words lie close to each other.",
      "startOffset" : 100,
      "endOffset" : 151
    }, {
      "referenceID" : 22,
      "context" : "2 Evaluation We use the same evaluation scheme used in (Röder et al., 2015).",
      "startOffset" : 55,
      "endOffset" : 75
    }, {
      "referenceID" : 22,
      "context" : "2 Evaluation We use the same evaluation scheme used in (Röder et al., 2015). Each technique generates coherence scores for all the topics in a dataset. Pearson’s r correlation co-efficient is computed between the coherence scores based on human judgement and the coherence scores automatically generated by the technique. Higher the correlation with human scores, better is the performance of the technique at measuring coherence. Table 1 shows the Pearson’s r values for our techniques - TBuckets-Clustering, TBuckets-SVD and TBuckets-SVD-Reorg. We compare their performance with the best performing correlation values as reported by Roder et al. (2015). As observed in Table 1, our technique TBuckets-SVD-Reorg outperforms the state-ofthe-art on 2 out of 3 datasets, namely NYT and 20NG.",
      "startOffset" : 56,
      "endOffset" : 655
    }, {
      "referenceID" : 9,
      "context" : "3 Application to Text Classification Topic models have been used for text classification with weak supervision in several previous approaches like Hingmire et al. (2013), Hingmire and Chakraborti (2014) and Pawar et al.",
      "startOffset" : 147,
      "endOffset" : 170
    }, {
      "referenceID" : 9,
      "context" : "(2013), Hingmire and Chakraborti (2014) and Pawar et al.",
      "startOffset" : 8,
      "endOffset" : 40
    }, {
      "referenceID" : 9,
      "context" : "(2013), Hingmire and Chakraborti (2014) and Pawar et al. (2016). The core idea used in these approaches is that instead of obtaining gold labels for documents, the human annotators can provide labels for the learned topics.",
      "startOffset" : 8,
      "endOffset" : 64
    }, {
      "referenceID" : 19,
      "context" : "As reported in (Pawar et al., 2016) the quality of topics can be different for various runs.",
      "startOffset" : 15,
      "endOffset" : 35
    }, {
      "referenceID" : 19,
      "context" : "We compare the performance of LPA-TD classifier used in (Pawar et al., 2016) using two different strategies for generating and labelling topics (Table 3): S1 (Without considering quality of topics) : Topic learning process is repeated for 5 times and human annotations were obtained.",
      "startOffset" : 56,
      "endOffset" : 76
    }, {
      "referenceID" : 6,
      "context" : "Hence, topics inferred by LDA may not correlate well with human judgements even though they better optimize perplexity on held-out documents (Chang et al., 2009).",
      "startOffset" : 141,
      "endOffset" : 161
    }, {
      "referenceID" : 6,
      "context" : "(Chang et al., 2009) emphasize that quality of topics should depend on their human interpretability rather than purely statistical measures like perplexity.",
      "startOffset" : 0,
      "endOffset" : 20
    }, {
      "referenceID" : 18,
      "context" : "(Newman et al., 2010b; Mimno et al., 2011)) hypothesize that coherence of the most N probable words of a topic capture its semantic interpretability and proposed measures to estimate coherence of topics.",
      "startOffset" : 0,
      "endOffset" : 42
    }, {
      "referenceID" : 15,
      "context" : "(Newman et al., 2010b; Mimno et al., 2011)) hypothesize that coherence of the most N probable words of a topic capture its semantic interpretability and proposed measures to estimate coherence of topics.",
      "startOffset" : 0,
      "endOffset" : 42
    }, {
      "referenceID" : 18,
      "context" : "(Newman et al., 2010b) used the set of N most probable words of a topic and computed its coherence (CUCI ) based on pointwise mutual information (PMI) between all possible word pairs of N words.",
      "startOffset" : 0,
      "endOffset" : 22
    }, {
      "referenceID" : 11,
      "context" : "(Lau et al., 2014) propose a variant",
      "startOffset" : 0,
      "endOffset" : 18
    }, {
      "referenceID" : 15,
      "context" : "(Mimno et al., 2011) propose similar topic coherence measure (CUMASS) that uses log conditional probability (LCP) instead of PMI and uses the same corpus on which topics are inferred, to estimate LCP rather than Wikipedia.",
      "startOffset" : 0,
      "endOffset" : 20
    }, {
      "referenceID" : 0,
      "context" : "(Aletras and Stevenson, 2013) propose a topic coherence measure based on distributional similarity between the most N probable words of the topic.",
      "startOffset" : 0,
      "endOffset" : 29
    }, {
      "referenceID" : 0,
      "context" : "(Aletras and Stevenson, 2013) observed that CUCI with NPMI correlates well with human judgements than CUMASS and CUCI with PMI.",
      "startOffset" : 0,
      "endOffset" : 29
    }, {
      "referenceID" : 0,
      "context" : "(Aletras and Stevenson, 2013) also propose an alternative to CUSheffield where they represent a topic word wi as a context vector over the space of topic words only.",
      "startOffset" : 0,
      "endOffset" : 29
    }, {
      "referenceID" : 0,
      "context" : "(Aletras and Stevenson, 2013) observed that CUCI with NPMI correlates well with human judgements than CUMASS and CUCI with PMI. (Aletras and Stevenson, 2013) also propose an alternative to CUSheffield where they represent a topic word wi as a context vector over the space of topic words only. They observed that CUSheffield with topic words only outperforms CUCI with NPMI. Roder et al. (2015) propose a unifying framework that represents a coherence measure as a composition of parts, that can be freely combined to form a configuration space of coherence definitions.",
      "startOffset" : 1,
      "endOffset" : 395
    } ],
    "year" : 2016,
    "abstractText" : "Measuring topic quality is essential for scoring the learned topics and their subsequent use in Information Retrieval and Text classification. To measure quality of Latent Dirichlet Allocation (LDA) based topics learned from text, we propose a novel approach based on grouping of topic words into buckets (TBuckets). A single large bucket signifies a single coherent theme, in turn indicating high topic coherence. TBuckets represents topic words using their word embeddings and employs 3 different techniques for creating buckets of words i) clustering based, ii) using singular value decomposition (SVD) and iii) SVD with reorganization. The TBuckets approach outperforms the state-of-theart techniques when evaluated using three publicly available datasets. Further, we demonstrate the usefulness of TBuckets for the task of weakly supervised text classification.",
    "creator" : "TeX"
  }
}