{
  "name" : "12.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Learning when to trust distant supervision: An application to low-resource POS tagging using cross-lingual projection",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "1 000\n011\n012\n013\n014\n015\n016\n017\n018\n019\n020\n021\n022\n023\n024\n025\n026\n027\n028\n029\n030\n031\n032\n033\n034\n035\n036\n037\n038\n039\n040\n041\n042\n043\n044\n045\n046\n047\n048\n049\n061\n062\n063\n064\n065\n066\n067\n068\n069\n070\n071\n072\n073\n074\n075\n076\n077\n078\n079\n080\n081\n082\n083\n084\n085\n086\n087\n088\n089\n090\n091\n092\n093\n094\n095\n096\n097\n098\n099"
    }, {
      "heading" : "1 Introduction",
      "text" : "Part-of-speech tagging is a critical task for natural language processing (NLP) applications, providing lexical syntactic information. Automatic POS tagging has been wildly successful on many rich resource languages using supervised learning over large training corpora (McCallum et al., 2000; Lafferty et al., 2001; Ammar et al., 2016). However, learning POS taggers for low-resource languages from small amounts of annotated data is very challenging (Garrette and Baldridge, 2013; Duong et al., 2014a). For such problems, distant supervision via heuristic methods can provide cheap but inaccurately labelled data (Mintz et al., 2009; Takamatsu et al., 2012; Ritter et al., 2013; Plank et al., 2014). A compromise, considered here, is to use a mixture of both resources: a small collection of clean annotated data and noisy “distant” data.\nA popular method for distant supervision is to use parallel data between a low-resource language and a rich-resource language. Although annotated data in low-resource languages are difficult to obtain, bilingual resources are more plentiful. For example parallel translations into English are often available, in the form of news reports, novels or the Bible. Parallel data allows annotation from the high-resource language to be projected across alignments to the low-resource language, which has been shown to be effective for several language processing tasks including POS tagging (Yarowsky et al., 2001; Das and Petrov, 2011; Duong et al., 2013), named entity recognition (Wang and Manning, 2013) and dependency parsing (McDonald et al., 2013).\nAlthough cross-lingual POS projection is popular it has several problems, including noise from poor word alignments (Täckström et al., 2013; Das and Petrov, 2011) and cross-lingual syntactic divergence (Duong et al., 2013). Previous work has proposed heuristics or constraints to clean the projected tag before or during learning. In contrast, we consider compensating for these problems explicitly, by learning a noise transformation to encode the mapping between ‘clean’ tags and the kinds of noisy tags produced from projection.\nWe propose a new neural network model for sequence tagging in a low-resource language, suitable for training with both a tiny gold standard annotated corpus, as well as distant supervision using cross lingual tag projection. Our model uses a bidirectional Long Short-Term Memory (BiLSTM), which produces two types of output: gold tags generated directly from the hidden state of neural network, and uncertain projected tags generated after applying a further linear transformation. This transformation, which we refer to as output noising encodes the mapping between the projected high-resource tags and low-resource\n2\n101\n102\n103\n104\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n123\n124\n125\n126\n127\n128\n129\n130\n131\n132\n133\n134\n135\n136\n137\n138\n139\n140\n141\n142\n143\n144\n145\n146\n147\n148\n149\n151\n152\n153\n154\n155\n156\n157\n158\n159\n160\n161\n162\n163\n164\n165\n166\n167\n168\n169\n170\n171\n172\n173\n174\n175\n176\n177\n178\n179\n180\n181\n182\n183\n184\n185\n186\n187\n188\n189\n190\n191\n192\n193\n194\n195\n196\n197\n198\n199\ntags, and learning when and how much to trust the projected data. For example, for languages without determiners, the model can learn to map projected determiner tags to nouns, or if verbs are often poorly aligned, the model can learn to effectively ignore the projected verb tag, through associating all tags with verbs. Our model is trained jointly on gold and distant projected annotations, and can be trained end-to-end with backpropagation.\nOur approach captures the relations among tokens, noisy projected POS tags and ground truth POS tags. Our work differs in the use of projection, in that we explicitly model the transformation between tagsets as part of a more expressive deep learning neural network. Our contributions fall in three aspects. First, we study the noise of projected data in word alignments and describe it with an additional layer model. Second, we integrate the model into a deep neural network and jointly train the model on both annotated and projected data to make the model learn from better supervisions. Finally, evaluating on eight simulated and two real-world low-resource languages, experimental results demonstrate that our approach uniformly equals or exceeds existing methods on simulated languages, and achieves 86.3% accuracy for Malagasy and 82.5% on Kinyarwanda, exceeding the state-of-the-art results (Duong et al., 2014a)."
    }, {
      "heading" : "2 Related Work",
      "text" : "For most natural language processing tasks, the conventional approach to developing a system is to use supervised learning algorithms trained on a set of annotated data. However, this approach is inappropriate to low-resource languages due to the lack of annotated data. An alternative approach is to harness different source of information aside from simple annotated text. Knowledgebases such as dictionaries are one possible source of information, which can be used to to inform or constrain models, such as limiting the search space for POS tagging (Banko and Moore, 2004; Goldberg et al., 2008; Li et al., 2012).\nParallel bilingual corpora provide another important source of information, and are often plentiful even for many low-resource languages in the form of multilingual government documents, book translations, multilingual websites, etc. Word alignments can provide a bridge to project in-\nformation from a resource-rich source language to a resource-poor target language. For example, parallel data has been used for named entity recognition (Wang and Manning, 2013) based on the observation that named entities are most often preserved in translation; and also in syntactic tasks such as POS tagging (Yarowsky et al., 2001; Das and Petrov, 2011; Duong et al., 2013) and dependency parsing (McDonald et al., 2013). Clues from related languages can also compensate for the lack of annotated data, as we expect there to be information shared between closely related languages in terms of the lexical items, morphology and syntactic structure. Some successful applications using language relatedness information are dependency parsing (McDonald et al., 2011), where a parser is estimated from a source, resource-rich language, but then applied to a target, low-resource language, and POS tagging (Hana et al., 2004) where parts of the tagger are estimated from the source language. However, these approaches are limited to closely related languages such as Czech and Russian, or Telugu and Kannada, and it is unclear whether these techniques will work well in situations where parallel data only exists for less-related languages, as is often the case in practice.\nTo summarize, for all these mentioned tasks, lexical resources are valuable sources of knowledge, but are also costly to build. Language relatedness information is applicable for closely related languages, but it is often the case that a given low-resource language does not have a closely-related, resource-rich language. Parallel data therefore appears to be the most realistic additional source of information for developing NLP systems for low-resource languages (Yarowsky et al., 2001; Duong et al., 2014b; Guo et al., 2016; Guo et al., 2015), and here we primarily investigate methods to exploit parallel texts.\nYarowsky et al. (2001) pioneered the use of parallel data for projecting POS tag information from a resource-rich language to a resource-poor language. Duong et al. (2014b) proposed an approach using a maximum entropy classifier trained on 1000 tagged tokens, and used projected tags as auxiliary outputs. Das and Petrov (2011) used parallel data and exploited graph-based label propagation to expand the coverage of labelled tokens. Our work is closest to Duong et al. (2014a), and we share the same evaluation setting, which we\n3\n201\n202\n203\n204\n205\n206\n207\n208\n209\n210\n211\n212\n213\n214\n215\n216\n217\n218\n219\n220\n221\n222\n223\n224\n225\n226\n227\n228\n229\n230\n231\n232\n233\n234\n235\n236\n237\n238\n239\n240\n241\n242\n243\n244\n245\n246\n247\n248\n249\n263\n264\n265\n266\n267\n268\n269\n270\n271\n272\n273\n274\n275\n276\n277\n278\n279\n280\n281\n282\n283\n284\n285\n286\n287\n288\n289\n290\n291\n292\n293\n294\n295\n296\n297\n298\n299\nbelieve is well suited to the low-resource applications. Our approach differs from theirs in two ways: first we propose a deep learning model based on a long short term memory recurrent structure versus their maximum entropy classifier, and secondly we model the projection tag explicitly as a form of noise applied after classification, while they attempt to capture the correlations between tagsets only implicitly through a joint feature set over both tags. We believe that our work is the first to explicitly model the noise affecting cross-lingual projected annotations, and thereby allowing this rich data resource to be better exploited in learning NLP models in low-resource languages."
    }, {
      "heading" : "3 Framework",
      "text" : "In this work, we consider the POS tagging problem for a low-resource language using both the gold annotated data and distant projected data. For a low-resource language, we assume two sets of data. First, there is a small conventional corpus for the low-resource language, annotated with gold tags. Second, there is also a parallel corpus between the language and English, where we can reliably tag the English side and project these annotations across the word alignments. Then based on the annotated and the projected data, we learn a deep neural model for the POS tagging. The goal of learning here is to improve the POS tagging accuracy on the low resource language."
    }, {
      "heading" : "3.1 POS projection via word alignments",
      "text" : "Parallel data is often available for low-resource languages. For example, for Malagasy we can obtain bilingual documents with English directly from the web. This provides ample opportunity for projecting annotations from English into the lowresource language. Although the POS tags can be projected, given sentence and word-alignments, direct projection has several issues and results in very noisy and unreliable annotations (Yarowsky et al., 2001; Duong et al., 2014b). One source of error are the word alignments. These errors arise from words in the source language that are not aligned any words in the other language, which might be due to their not being translated closely, errors in alignments, or translation phenomena that do not fit the assumptions underlying the word based alignment models (e.g., many to many translations cannot be captured).\nAn example of POS projection via word alignments between Malagasy and English is shown in Figure 1. A word in Malagasy is connected to a word in English or NULL word. Thus there exist words in the target language which are not aligned a word from source, for example ny in Figure 1. Previous works either used the majority projected POS tag for a token or used a default value to represent the token (Duong et al., 2014a; Täckström et al., 2013). Another problem is about noisy projected tags. For example, in this sentence, fanomezan-kevitra is labelled as VERB incorrectly, but should be NOUN, a consequence of a non-literal translation.\nWe now turn to the manner of labelling the projected data. For the parallel data, we consider each token in the low-resource language. Where this token is aligned to a single token in English, we assign the tag for that English token. For tokens that are aligned to many English words or none at all (NULL), we assign a distribution over tags according to the tag frequency distribution over the whole English sentence.\nA natural question is whether this projected labelling might be suitable for use directly in supervised learning of a POS tagger. To test this, we compare training a bidirectional Long ShortTerm Memory (BiLSTM) tagger on this data, a small 1000 token dataset with gold-standard tags, and the union of the two.1 Evaluating the tag-\n1See §3.2 for the model details, and §4.1 for a description\n4\n301\n302\n303\n304\n305\n306\n307\n308\n309\n310\n311\n312\n313\n314\n315\n316\n317\n318\n319\n320\n321\n322\n323\n324\n325\n326\n327\n328\n329\n330\n331\n332\n333\n334\n335\n336\n337\n338\n339\n340\n341\n342\n343\n344\n345\n346\n347\n348\n349\n351\n352\n353\n354\n355\n356\n357\n358\n359\n360\n361\n362\n363\n364\n365\n366\n367\n368\n369\n370\n371\n372\n373\n374\n375\n376\n377\n378\n379\n380\n381\n382\n383\n384\n385\n386\n387\n388\n389\n390\n391\n392\n393\n394\n395\n396\n397\n398\n399\nging accuracy against gold standard tags, we observe in Tables 1 and 2 (top section, rows labelled BiLSTM) that the use of the gold-standard (Annotated) data is considerably superior to training on the directly Projected data, despite the smaller amount of Annotated data, while using the union of the two datasets does result in mild improvements in a few languages, but worsens performance for others.\nThese sobering results raise the question of how we might use the bilingual resources in a more effectively manner than direct projection. Clearly projections contain useful information, as the tagging accuracy is well above chance, however they are riddled with noise and biases, which needs to be accounted for for adequate performance."
    }, {
      "heading" : "3.2 BiLSTM with noise layer",
      "text" : "To address this problem, we propose a model based on jointly modelling the clean annotated data and the noisy projected data. For this we use a bidirectional LSTM tagger, as illustrated on the left in Figure 2, although other classifiers could be easily used in its place. The BiLSTM offers access to both the left and right lexical contexts around a given word (Graves et al., 2013), which are likely be of considerable use in POS tagging where context of central importance.\nLet xt indicate a word in a sentence and yt indicate its corresponding POS tag, where K is the size of the tagset.2 The recurrent layer is designed to store contextual information, while the values in the hidden and output layers are computed as follows:\n−→ h t = lstm( −→ h t−1, xt) ←− h t = lstm( ←− h t+1, xt)\not = softmax(W→ −→ h t +W← ←− h t + b) (1) yt ∼ Multinomial(ot) .\nThis supervised model is trained on annotated gold data in the standard manner using a cross-entropy objective with stochastic gradient descent through the use of gradient backpropagation.\nThe projected data, however, needs to be treated differently to the annotated data: the tagging is often uncertain, as tokens may have been aligned to words with different parts of speech, be multiply\nof the datasets and evaluation. 2We use the universal tagset from (Petrov et al., 2011), enabling comparison across languages.\naligned or left unaligned. These tags are not to be trusted in the same way as the gold annotated data. Our work allows for noise explicitly in the training objective, by attempting to model the noise generating process. The projected data consists of pairs, (xt, ỹ), where ỹ denotes the projected POS tag. In this setting, we assume that the true label, yt, is latent variable and both ỹ and y are K-dimensional binary random variables: ỹt is a vector representation of a projected tag, and yt is a one-hot representation of a gold tag.\nWe augment the deep neural network model to include a noise transformation such that its prediction matches the POS tag distribution of the noisy data, as follows:\np(Ỹt = j|xt, θ, A) = softmax (∑ i ai,jot,i ) ,\n(2) where ot,i = p(Yt = i|xt, θ) is the probability of tag i in position t according to (1). This equation is parameterized by a K ×K matrix A.3 Each cell ai,j denotes the confusion score between classes i and j, with negative values quashing the correspondance, and positive values rewarding a pairing; in the situations where the projected tags closely match the supervised tagging, we expect that A ∝ I .\nJoint modelling of the gold supervision and projected data gives rise to a training objective combining two cross-entropy terms,\nL(θ,A) =− 1 |T p| ∑ t∈T p 〈ỹt, log softmax (Aot)〉\n− 1 |T t| ∑ t∈T t 〈yt, log ot〉 ,\nwhere T p indexes all the token positions in the projected dataset, and similarly for T t over the annotated training set.\nWe illustrate the combined model in Figure 2, showing on the left the gold supervised model and on the right the distant supervised components. The distant model builds on the base part, through feeding the output through a noising layer, which is finally used in a softmax to produce the noised output layer. The matrix A parameterizes the final layer, to adjust the tag probabilities from\n3Our approach also supports mismatching tagsets, in which case A would be rectangular with dimensions based on the sizes of the two tag sets.\n5\n401\n402\n403\n404\n405\n406\n407\n408\n409\n410\n411\n412\n413\n414\n415\n416\n417\n418\n419\n420\n421\n422\n423\n424\n425\n426\n427\n428\n429\n430\n431\n432\n433\n434\n435\n436\n437\n438\n439\n440\n441\n442\n443\n444\n445\n446\n447\n448\n449\n451\n452\n453\n454\n455\n456\n457\n458\n459\n460\n461\n462\n463\n464\n465\n466\n467\n468\n469\n470\n471\n472\n473\n474\n475\n476\n477\n478\n479\n480\n481\n482\n483\n484\n485\n486\n487\n488\n489\n490\n491\n492\n493\n494\n495\n496\n497\n498\n499\nraha ny marina\nembedding, e\ntext, x\nBiLSTM, h\nh\noutput, o\nlabel, y Conj Det Noun\ntsara fa\n...\nnoised output, õ\nprojected labels, ỹ\nAnnotated data\nProjected data\nShared layers\nmisaotra\nAdj\nFigure 2: Illustration of the model architecture, using a bidirectional LSTM recurrent network, with a tag classification output. The left part illustrates the supervised training scenario and test setting, where each word x is assigned a tag y; the right part shows the projection training setting, with a noise layer, where the supervision is either a projected label or label distribution (used for NULL aligned words).\nthe supervised model into a distribution that better matches the noisy projected POS tags. However, the ultimate goal is to predict the POS tag yt. Consider the training effect of the projected POS tags: when performing error backpropagation, the cross-entropy error signal must pass through the tag transformation linking õ with o, which can be seen as a de-noising step, after which the cleaned error signal can be further backpropagated to the rest of the model. Provided there are consistent patterns of noise in the projection output, this technique can readily model these sources of variation, with a tiny handful of parameters, and thus greatly improve the utility of this form of distant supervision.\nDirectly training the whole deep neural network with random initialization is impractical, because without a good estimate for theAmatrix, the noise from the projected tags may misdirect training result in a poor local optima. For this reason the training process contains two stages. On the first stage, we use the clean annotated data to pretrain the network. On the second stage, we jointly use both projected and annotated data to continue training the model."
    }, {
      "heading" : "4 Experiments",
      "text" : "We evaluate our algorithm on two kinds of experiment settings, simulation experiments and realworld experiments. For the simulation exper-\niments, we use the following 8 European languages: Danish (da), Dutch (nl), German (de), Greek (el), Italian (it), Portuguese (pt), Spanish (es), Swedish (sv). These eight languages are obviously not low-resource languages, however we can use this data to simulate the low-resource setting by only using a small fraction of the gold annotations for training. This evaluation technique is widely used in previous work, and allows us to compare our results with prior stateof-the-art algorithms. For the real-world experiments, we use the following two low-resource languages: Malagasy, an Austronesian language spoken in Madagascar, and Kinyarwanda, a NigerCongo language spoken in Rwanda."
    }, {
      "heading" : "4.1 Evaluation Corpora",
      "text" : ""
    }, {
      "heading" : "4.1.1 Parallel data",
      "text" : "For the simulation experiments, we use the Europarl v7 corpus, with English as the source language and each of eight languages as the target language. There are an average 1.85 million parallel sentences for each of the language pairs. For the real-world experiments, parallel data is smaller and generally of a lower quality. For Malagasy, we use a web-sourced collection of parallel texts.4 The parallel data of Malagasy has 100k sentences and 1,231k tokens. For Kinyarwanda, we obtained\n4http://www.cs.cmu.edu/ ark/global-voices/\n6\n501\n502\n503\n504\n505\n506\n507\n508\n509\n510\n511\n512\n513\n514\n515\n516\n517\n518\n519\n520\n521\n522\n523\n524\n525\n526\n527\n528\n529\n530\n531\n532\n533\n534\n535\n536\n537\n538\n539\n540\n541\n542\n543\n544\n545\n546\n547\n548\n549\n550\n551\n552\n553\n554\n555\n556\n557\n558\n559\n560\n561\n562\n563\n564\n565\n566\n567\n568\n569\n570\n571\n572\n573\n574\n575\n576\n577\n578\n579\n580\n581\n582\n583\n584\n585\n586\n587\n588\n589\n590\n591\n592\n593\n594\n595\n596\n597\n598\n599\nda nl de el it pt es sv Average BiLSTM Annotated 89.3 87.4 89.5 88.1 85.9 89.5 90.6 84.7 88.1 BiLSTM Projected 64.4 81.9 81.3 78.9 80.1 81.9 81.2 74.9 78.0 BiLSTM Ann+Proj 85.4 88.9 90.2 84.2 86.1 88.2 91.3 83.6 87.2 MaxEnt Supervised 90.1 84.6 89.6 88.2 81.4 87.6 88.9 85.4 86.9 Duong et al. 92.1 91.1 92.5 92.1 89.9 92.5 91.6 88.7 91.3 BiLSTM+noise layer 92.3 91.7 92.5 92.8 90.2 92.9 92.4 89.1 91.7\nTable 1: The POS tagging accuracy for various models in 8 languages: Danish (da), Dutch (nl), German (de), Greek (el), Italian (it), Portuguese (pt), Spanish (es) Swedish (sv). The top results of the second part are taken from (Duong et al., 2014a), evaluated on the same data split.\nparallel texts from ARL MURI project.5 The parallel data of Kinyarwanda has 11k sentences and 52k tokens."
    }, {
      "heading" : "4.1.2 POS projection",
      "text" : "We use Giza++ to induce word alignments on the parallel data (Och and Ney, 2003), using IBM model 3. Following prior work (Duong et al., 2014b), we retain only one-to-one alignments. Using all alignments, i.e., many-to-one and one-tomany, would result in many more POS-tagged tokens, but also bring considerable additional noise. For example, the English laws (NNS) aligned to French les (DT) lois (NNS) would end up incorrectly tagging the French determiner les as a noun (NNS). We use the Stanford POS tagger (Toutanova et al., 2003) to tag the English side of the parallel data and then project the label to the target side. As we show in the following section, and as confirmed in many studies (Täckström et al., 2013; Das and Petrov, 2011) the directly projected labels are very noisy and it is unwise to use the tags directly. We further filter the noise using the approach of Yarowsky et al. (2001) which selects sentences with the highest sentence alignment scores from IBM model 3. For 8 languages in Europarl corpus, we collect 200k sentences for each language. For the low-resource languages, we use the whole parallel data because of limited bilingual text."
    }, {
      "heading" : "4.1.3 Annotated data",
      "text" : "Gold annotated data is expensive and difficult to obtain, and thus we assume that only a small annotated dataset is available. For the simulation experiments, we use the CoNLL data (Buchholz and Marsi, 2006) as annotated data for eight languages. To simulate the low-resource setting, we\n5The dataset was provided directly by Noah Smith.\ntake the first 1,000 tagged tokens for training and the remaining data is split equally between development and testing sets, following Duong et al. (2014a). For the real-world experiments, we use the Malagasy and Kinyarwanda data from Garrette and Baldridge (2013), who showed that a small annotated dataset could be collected very cheaply, requiring less than 2 hours of non-expert time to tag 1000 tokens. This constitutes a reasonable demand for cheap portability to other low-resource languages. We use the datasets from Garrette and Baldridge (2013), constituting training sets of 383 sentences and 5,294 tokens in Malagasy and 196 sentences and 4,882 tokens for Kinyarwanda. There are similar sized datasets used for testing."
    }, {
      "heading" : "4.2 Setup and baselines",
      "text" : "We compare our algorithm with several baselines, including the state-of-the-art algorithm from Duong et al. (2014a), a two-output maxent model, their reported baseline method of a supervised maximum entropy model trained on the annotated data, and our BiLSTM POS tagger trained directly from the annotated and/or projected data (denoted BiLSTM Annotated, Projected and Ann+Proj for the model trained on union of the two datasets). For the real low-resource languages, we also compare our algorithm with Garrette et al. (Garrette and Baldridge, 2013), which showed good results on the two low-resource languages. Our implementation is based on clab/cnn. 6 In all cases, the BiLSTM models use 128 dimensional word embeddings and 128 dimensional hidden layers. We set learning rate as 1.0 and use stochastic gradient descent model to learn the parameters.\nWe evaluate all algorithms on the gold testing sets, evaluating in terms of tagging accuracy. Following standard practice in POS tagging, we re-\n6https://github.com/clab/cnn\n7\n601\n602\n603\n604\n605\n606\n607\n608\n609\n610\n611\n612\n613\n614\n615\n616\n617\n618\n619\n620\n621\n622\n623\n624\n625\n626\n627\n628\n629\n630\n631\n632\n633\n634\n635\n636\n637\n638\n639\n640\n641\n642\n643\n644\n645\n646\n647\n648\n649\n651\n652\n653\n654\n655\n656\n657\n658\n659\n660\n661\n662\n663\n664\n665\n666\n667\n668\n669\n670\n671\n672\n673\n674\n675\n676\n677\n678\n679\n680\n681\n682\n683\n684\n685\n686\n687\n688\n689\n690\n691\n692\n693\n694\n695\n696\n697\n698\n699\nda nl de el\nit pt es sv\nVERB\nNOUN PRON\nADJ ADV ADP CONJ\nDET\n.\nNUM\nPRT\nX\nVERB\nNOUN PRON\nADJ ADV ADP CONJ\nDET\n.\nNUM\nPRT\nX\nV E R B N O U N P R O N A D J A D V A D P C O N J D E T . N U M P R T X V E R B N O U N P R O N A D J A D V A D P C O N J D E T . N U M P R T X V E R B N O U N P R O N A D J A D V A D P C O N J D E T . N U M P R T X V E R B N O U N P R O N A D J A D V A D P C O N J D E T . N U M P R T X\n1.0\n-1.0\n1.0\n-1.0\nFigure 3: Noise transformation matrix A between POS tags and noised (projection) outputs, shown as columns and rows, respectively, for the 8 languages.\nport results using per-token accuracy, i.e., the fraction of predicted tags that exactly match the gold standard tags. Note that for all our experiments, we work with the universal POS tags and accordingly accuracy is measured against the gold tags after automatic mapping into the universal tagset."
    }, {
      "heading" : "4.3 Results",
      "text" : "First, we present the results in the eight simulation languages in Table 1. For most of languages, our method is better than Duong et al. (2014a) and the three naive BiLSTM baselines. Directly training on projected data hurts the performance, e.g., compare BiLSTM Projected and BiLSTM Ann+Proj. BiLSTM Annotated mostly outperforms MaxEnt Supervised, but both methods are worse than Duong et al. and our BiLSTM+noise layer, which both use the projected data more effectively. The result shows the noise layer provides a better use of the noisy projected data, improving the POS tagging accuracy.\nWe show the noise layer for the different languages in Figures 3. The blue (dark) cells in the grids denote values that are most highly weighted. Note the strong diagonal, showing that the tags are mostly trusted, although there is also evidence of considerable noise. The worst case is in Swedish (sv) with many weak values on the diagonal. In\nthis case, PRT and X appear to be confused for one another. The white grids are also important, showing tag combinations that the model learns to ignore, such as NUM vs DET in Italian (it) and NOUN vs PRON in Spanish (es) and Swedish (sv). It shows these types are not confused. The tokens that are NUM in Italian (it) are seldom projected as DET. Overall, the level of noise looks to be modest, which might not come as a surprise given the large clean parallel corpus for learning word alignments.\nNow we present the results for two low-resource languages, Malagasy and Kinyarwanda which both have much smaller parallel corpora. The results in Table 2 show that our method works better than all others in both languages, with a similar pattern of results as for the eight simulation languages. Note that our method outperforms the state of the art on both languages (Duong et al., 2014a; Garrette and Baldridge, 2013).\nTo better understand the effect of the noise layer, we present the learned transformation matrices A in Figure 4. Note the strong diagonal for Malagasy in Figure 4, showing that each tag is most likely to map to itself, however there are also many high magnitude off diagonal elements. For instance nouns map to not just noun, but also adjective and number, but never pronoun (which\n8\n701\n702\n703\n704\n705\n706\n707\n708\n709\n710\n711\n712\n713\n714\n715\n716\n717\n718\n719\n720\n721\n722\n723\n724\n725\n726\n727\n728\n729\n730\n731\n732\n733\n734\n735\n736\n737\n738\n739\n740\n741\n742\n743\n744\n745\n746\n747\n748\n749\n751\n752\n753\n754\n755\n756\n757\n758\n759\n760\n761\n762\n763\n764\n765\n766\n767\n768\n769\n770\n771\n772\n773\n774\n775\n776\n777\n778\n779\n780\n781\n782\n783\n784\n785\n786\n787\n788\n789\n790\n791\n792\n793\n794\n795\n796\n797\n798\n799\nMalagasy Kinyarwanda 1.0\n-1.0\nFigure 4: Noise transformation matrix A between POS tags and noised (projection) outputs, shown as columns and rows, respectively, for the two low-resource languages.\nModel Accuracy Malagasy Kinyarwanda BiLSTM Annotated 81.5 76.9 BiLSTM Projected 67.2 61.9 BiLSTM Ann+Proj 78.6 73.2 MaxEnt Supervised 80.0 76.4 Duong et al. 85.3 78.3 BiLSTM+noise layer 86.3 82.5 Garrette et al. 81.2 81.9\nTable 2: The POS tagging accuracy for various models in Malagasy and Kinyarwanda. The top results of the second part are taken from (Duong et al., 2014a), evaluated on the same data split.\nare presumably well aligned.) Comparing results of Malagasy and Kinyarwanda in Figure 4, we can see the amount of noise is much greater in Kinyarwanda. This tallies with the performance results, in which we get stronger results and a greater improvement on Malagasy from using projection data, where we had more parallel data."
    }, {
      "heading" : "5 Conclusion",
      "text" : "In this paper, we presented a technique for exploiting noisy cross-lingual projected annotations alongside a small amount of annotation data, in the context of POS tagging. To utilize both sources of data, we proposed a new model based on a bidirectional long short term memory recurrent neural network, with a layer for explicitly handling noisy projection labels. In two real low-resource languages, our methods outperform other algorithms. Our technique is general, and is likely to prove\nuseful for exploiting other noisy annotations such as distant supervision and crowd-sources annotations, and with other modelling approaches."
    } ],
    "references" : [ {
      "title" : "Many languages, one parser",
      "author" : [ "Waleed Ammar", "George Mulcaire", "Miguel Ballesteros", "Chris Dyer", "Noah A Smith." ],
      "venue" : "arXiv preprint arXiv:1602.01595.",
      "citeRegEx" : "Ammar et al\\.,? 2016",
      "shortCiteRegEx" : "Ammar et al\\.",
      "year" : 2016
    }, {
      "title" : "Part of speech tagging in context",
      "author" : [ "Michele Banko", "Robert C Moore." ],
      "venue" : "Proceedings of the 20th international conference on Computational Linguistics, page 556. Association for Computational Linguistics.",
      "citeRegEx" : "Banko and Moore.,? 2004",
      "shortCiteRegEx" : "Banko and Moore.",
      "year" : 2004
    }, {
      "title" : "Conll-x shared task on multilingual dependency parsing",
      "author" : [ "Sabine Buchholz", "Erwin Marsi." ],
      "venue" : "Proceedings of the Tenth Conference on Computational Natural Language Learning, pages 149–164. Association for Computational Linguistics.",
      "citeRegEx" : "Buchholz and Marsi.,? 2006",
      "shortCiteRegEx" : "Buchholz and Marsi.",
      "year" : 2006
    }, {
      "title" : "Unsupervised part-of-speech tagging with bilingual graph-based projections",
      "author" : [ "Dipanjan Das", "Slav Petrov." ],
      "venue" : "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1,",
      "citeRegEx" : "Das and Petrov.,? 2011",
      "shortCiteRegEx" : "Das and Petrov.",
      "year" : 2011
    }, {
      "title" : "Simpler unsupervised pos tagging with bilingual projections",
      "author" : [ "Long Duong", "Paul Cook", "Steven Bird", "Pavel Pecina." ],
      "venue" : "ACL (2), pages 634– 639.",
      "citeRegEx" : "Duong et al\\.,? 2013",
      "shortCiteRegEx" : "Duong et al\\.",
      "year" : 2013
    }, {
      "title" : "What can we get from 1000 tokens? a case study of multilingual pos tagging for resource-poor languages",
      "author" : [ "Long Duong", "Trevor Cohn", "Karin Verspoor", "Steven Bird", "Paul Cook." ],
      "venue" : "EMNLP, pages 886–897. Citeseer.",
      "citeRegEx" : "Duong et al\\.,? 2014a",
      "shortCiteRegEx" : "Duong et al\\.",
      "year" : 2014
    }, {
      "title" : "What can we get from 1000 tokens? a case study of multilingual pos tagging for resource-poor languages",
      "author" : [ "Long Duong", "Trevor Cohn", "Karin Verspoor", "Steven Bird", "Paul Cook." ],
      "venue" : "Proceedings of the 2014 Conference on Empirical Methods in Nat-",
      "citeRegEx" : "Duong et al\\.,? 2014b",
      "shortCiteRegEx" : "Duong et al\\.",
      "year" : 2014
    }, {
      "title" : "Learning a part-of-speech tagger from two hours of annotation",
      "author" : [ "Dan Garrette", "Jason Baldridge." ],
      "venue" : "HLT-NAACL, pages 138–147. Citeseer.",
      "citeRegEx" : "Garrette and Baldridge.,? 2013",
      "shortCiteRegEx" : "Garrette and Baldridge.",
      "year" : 2013
    }, {
      "title" : "Em can find pretty good hmm pos-taggers (when given a good start)",
      "author" : [ "Yoav Goldberg", "Meni Adler", "Michael Elhadad." ],
      "venue" : "ACL, pages 746–754.",
      "citeRegEx" : "Goldberg et al\\.,? 2008",
      "shortCiteRegEx" : "Goldberg et al\\.",
      "year" : 2008
    }, {
      "title" : "Speech recognition with deep recurrent neural networks",
      "author" : [ "Alan Graves", "Abdel-rahman Mohamed", "Geoffrey Hinton." ],
      "venue" : "Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on, pages 6645–6649. IEEE.",
      "citeRegEx" : "Graves et al\\.,? 2013",
      "shortCiteRegEx" : "Graves et al\\.",
      "year" : 2013
    }, {
      "title" : "Cross-lingual dependency parsing based on distributed representations",
      "author" : [ "Jiang Guo", "Wanxiang Che", "David Yarowsky", "Haifeng Wang", "Ting Liu." ],
      "venue" : "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the",
      "citeRegEx" : "Guo et al\\.,? 2015",
      "shortCiteRegEx" : "Guo et al\\.",
      "year" : 2015
    }, {
      "title" : "A representation learning framework for multi-source transfer parsing",
      "author" : [ "Jiang Guo", "Wanxiang Che", "David Yarowsky", "Haifeng Wang", "Ting Liu" ],
      "venue" : null,
      "citeRegEx" : "Guo et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Guo et al\\.",
      "year" : 2016
    }, {
      "title" : "A resource-light approach to russian morphology: Tagging russian using czech resources",
      "author" : [ "Jiri Hana", "Anna Feldman", "Chris Brew." ],
      "venue" : "EMNLP, pages 222–229.",
      "citeRegEx" : "Hana et al\\.,? 2004",
      "shortCiteRegEx" : "Hana et al\\.",
      "year" : 2004
    }, {
      "title" : "Conditional random fields: Probabilistic models for segmenting and labeling sequence data",
      "author" : [ "John Lafferty", "Andrew McCallum", "Fernando CN Pereira" ],
      "venue" : null,
      "citeRegEx" : "Lafferty et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Lafferty et al\\.",
      "year" : 2001
    }, {
      "title" : "Wiki-ly supervised part-of-speech tagging",
      "author" : [ "Shen Li", "Joao V Graça", "Ben Taskar." ],
      "venue" : "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1389–1398. As-",
      "citeRegEx" : "Li et al\\.,? 2012",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2012
    }, {
      "title" : "Maximum entropy markov models for information extraction and segmentation",
      "author" : [ "Andrew McCallum", "Dayne Freitag", "Fernando CN Pereira." ],
      "venue" : "ICML, volume 17, pages 591–598.",
      "citeRegEx" : "McCallum et al\\.,? 2000",
      "shortCiteRegEx" : "McCallum et al\\.",
      "year" : 2000
    }, {
      "title" : "Multi-source transfer of delexicalized dependency parsers",
      "author" : [ "Ryan McDonald", "Slav Petrov", "Keith Hall." ],
      "venue" : "Proceedings of the conference on empirical methods in natural language processing, pages 62–72. Association for Computational Linguistics.",
      "citeRegEx" : "McDonald et al\\.,? 2011",
      "shortCiteRegEx" : "McDonald et al\\.",
      "year" : 2011
    }, {
      "title" : "Universal dependency annotation for multilingual parsing",
      "author" : [ "Ryan T McDonald", "Joakim Nivre", "Yvonne QuirmbachBrundage", "Yoav Goldberg", "Dipanjan Das", "Kuzman Ganchev", "Keith B Hall", "Slav Petrov", "Hao Zhang", "Oscar Täckström" ],
      "venue" : null,
      "citeRegEx" : "McDonald et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "McDonald et al\\.",
      "year" : 2013
    } ],
    "referenceMentions" : [ {
      "referenceID" : 15,
      "context" : "Automatic POS tagging has been wildly successful on many rich resource languages using supervised learning over large training corpora (McCallum et al., 2000; Lafferty et al., 2001; Ammar et al., 2016).",
      "startOffset" : 135,
      "endOffset" : 201
    }, {
      "referenceID" : 13,
      "context" : "Automatic POS tagging has been wildly successful on many rich resource languages using supervised learning over large training corpora (McCallum et al., 2000; Lafferty et al., 2001; Ammar et al., 2016).",
      "startOffset" : 135,
      "endOffset" : 201
    }, {
      "referenceID" : 0,
      "context" : "Automatic POS tagging has been wildly successful on many rich resource languages using supervised learning over large training corpora (McCallum et al., 2000; Lafferty et al., 2001; Ammar et al., 2016).",
      "startOffset" : 135,
      "endOffset" : 201
    }, {
      "referenceID" : 7,
      "context" : "However, learning POS taggers for low-resource languages from small amounts of annotated data is very challenging (Garrette and Baldridge, 2013; Duong et al., 2014a).",
      "startOffset" : 114,
      "endOffset" : 165
    }, {
      "referenceID" : 5,
      "context" : "However, learning POS taggers for low-resource languages from small amounts of annotated data is very challenging (Garrette and Baldridge, 2013; Duong et al., 2014a).",
      "startOffset" : 114,
      "endOffset" : 165
    }, {
      "referenceID" : 3,
      "context" : "Parallel data allows annotation from the high-resource language to be projected across alignments to the low-resource language, which has been shown to be effective for several language processing tasks including POS tagging (Yarowsky et al., 2001; Das and Petrov, 2011; Duong et al., 2013), named entity recognition (Wang and Manning, 2013) and dependency parsing (McDonald et al.",
      "startOffset" : 225,
      "endOffset" : 290
    }, {
      "referenceID" : 4,
      "context" : "Parallel data allows annotation from the high-resource language to be projected across alignments to the low-resource language, which has been shown to be effective for several language processing tasks including POS tagging (Yarowsky et al., 2001; Das and Petrov, 2011; Duong et al., 2013), named entity recognition (Wang and Manning, 2013) and dependency parsing (McDonald et al.",
      "startOffset" : 225,
      "endOffset" : 290
    }, {
      "referenceID" : 17,
      "context" : ", 2013), named entity recognition (Wang and Manning, 2013) and dependency parsing (McDonald et al., 2013).",
      "startOffset" : 82,
      "endOffset" : 105
    }, {
      "referenceID" : 3,
      "context" : "Although cross-lingual POS projection is popular it has several problems, including noise from poor word alignments (Täckström et al., 2013; Das and Petrov, 2011) and cross-lingual syntactic divergence (Duong et al.",
      "startOffset" : 116,
      "endOffset" : 162
    }, {
      "referenceID" : 4,
      "context" : ", 2013; Das and Petrov, 2011) and cross-lingual syntactic divergence (Duong et al., 2013).",
      "startOffset" : 69,
      "endOffset" : 89
    }, {
      "referenceID" : 5,
      "context" : "5% on Kinyarwanda, exceeding the state-of-the-art results (Duong et al., 2014a).",
      "startOffset" : 58,
      "endOffset" : 79
    }, {
      "referenceID" : 1,
      "context" : "Knowledgebases such as dictionaries are one possible source of information, which can be used to to inform or constrain models, such as limiting the search space for POS tagging (Banko and Moore, 2004; Goldberg et al., 2008; Li et al., 2012).",
      "startOffset" : 178,
      "endOffset" : 241
    }, {
      "referenceID" : 8,
      "context" : "Knowledgebases such as dictionaries are one possible source of information, which can be used to to inform or constrain models, such as limiting the search space for POS tagging (Banko and Moore, 2004; Goldberg et al., 2008; Li et al., 2012).",
      "startOffset" : 178,
      "endOffset" : 241
    }, {
      "referenceID" : 14,
      "context" : "Knowledgebases such as dictionaries are one possible source of information, which can be used to to inform or constrain models, such as limiting the search space for POS tagging (Banko and Moore, 2004; Goldberg et al., 2008; Li et al., 2012).",
      "startOffset" : 178,
      "endOffset" : 241
    }, {
      "referenceID" : 3,
      "context" : "For example, parallel data has been used for named entity recognition (Wang and Manning, 2013) based on the observation that named entities are most often preserved in translation; and also in syntactic tasks such as POS tagging (Yarowsky et al., 2001; Das and Petrov, 2011; Duong et al., 2013) and dependency parsing (McDonald et al.",
      "startOffset" : 229,
      "endOffset" : 294
    }, {
      "referenceID" : 4,
      "context" : "For example, parallel data has been used for named entity recognition (Wang and Manning, 2013) based on the observation that named entities are most often preserved in translation; and also in syntactic tasks such as POS tagging (Yarowsky et al., 2001; Das and Petrov, 2011; Duong et al., 2013) and dependency parsing (McDonald et al.",
      "startOffset" : 229,
      "endOffset" : 294
    }, {
      "referenceID" : 17,
      "context" : ", 2013) and dependency parsing (McDonald et al., 2013).",
      "startOffset" : 31,
      "endOffset" : 54
    }, {
      "referenceID" : 16,
      "context" : "Some successful applications using language relatedness information are dependency parsing (McDonald et al., 2011), where a parser is estimated from a source, resource-rich language, but then applied to a target, low-resource language, and POS tagging (Hana et al.",
      "startOffset" : 91,
      "endOffset" : 114
    }, {
      "referenceID" : 12,
      "context" : ", 2011), where a parser is estimated from a source, resource-rich language, but then applied to a target, low-resource language, and POS tagging (Hana et al., 2004) where parts of the tagger are estimated from the source language.",
      "startOffset" : 145,
      "endOffset" : 164
    }, {
      "referenceID" : 6,
      "context" : "Parallel data therefore appears to be the most realistic additional source of information for developing NLP systems for low-resource languages (Yarowsky et al., 2001; Duong et al., 2014b; Guo et al., 2016; Guo et al., 2015), and here we primarily investigate methods to exploit parallel texts.",
      "startOffset" : 144,
      "endOffset" : 224
    }, {
      "referenceID" : 11,
      "context" : "Parallel data therefore appears to be the most realistic additional source of information for developing NLP systems for low-resource languages (Yarowsky et al., 2001; Duong et al., 2014b; Guo et al., 2016; Guo et al., 2015), and here we primarily investigate methods to exploit parallel texts.",
      "startOffset" : 144,
      "endOffset" : 224
    }, {
      "referenceID" : 10,
      "context" : "Parallel data therefore appears to be the most realistic additional source of information for developing NLP systems for low-resource languages (Yarowsky et al., 2001; Duong et al., 2014b; Guo et al., 2016; Guo et al., 2015), and here we primarily investigate methods to exploit parallel texts.",
      "startOffset" : 144,
      "endOffset" : 224
    }, {
      "referenceID" : 3,
      "context" : "Duong et al. (2014b) proposed an approach using a maximum entropy classifier trained on 1000 tagged tokens, and used projected tags as auxiliary outputs.",
      "startOffset" : 0,
      "endOffset" : 21
    }, {
      "referenceID" : 3,
      "context" : "Das and Petrov (2011) used parallel data and exploited graph-based label propagation to expand the coverage of labelled tokens.",
      "startOffset" : 0,
      "endOffset" : 22
    }, {
      "referenceID" : 3,
      "context" : "Das and Petrov (2011) used parallel data and exploited graph-based label propagation to expand the coverage of labelled tokens. Our work is closest to Duong et al. (2014a), and we share the same evaluation setting, which we",
      "startOffset" : 0,
      "endOffset" : 172
    }, {
      "referenceID" : 6,
      "context" : "Although the POS tags can be projected, given sentence and word-alignments, direct projection has several issues and results in very noisy and unreliable annotations (Yarowsky et al., 2001; Duong et al., 2014b).",
      "startOffset" : 166,
      "endOffset" : 210
    }, {
      "referenceID" : 5,
      "context" : "Previous works either used the majority projected POS tag for a token or used a default value to represent the token (Duong et al., 2014a; Täckström et al., 2013).",
      "startOffset" : 117,
      "endOffset" : 162
    }, {
      "referenceID" : 9,
      "context" : "The BiLSTM offers access to both the left and right lexical contexts around a given word (Graves et al., 2013), which are likely be of considerable use in POS tagging where context of central importance.",
      "startOffset" : 89,
      "endOffset" : 110
    }, {
      "referenceID" : 5,
      "context" : "The top results of the second part are taken from (Duong et al., 2014a), evaluated on the same data split.",
      "startOffset" : 50,
      "endOffset" : 71
    }, {
      "referenceID" : 6,
      "context" : "Following prior work (Duong et al., 2014b), we retain only one-to-one alignments.",
      "startOffset" : 21,
      "endOffset" : 42
    }, {
      "referenceID" : 3,
      "context" : "As we show in the following section, and as confirmed in many studies (Täckström et al., 2013; Das and Petrov, 2011) the directly projected labels are very noisy and it is unwise to use the tags directly.",
      "startOffset" : 70,
      "endOffset" : 116
    }, {
      "referenceID" : 3,
      "context" : ", 2013; Das and Petrov, 2011) the directly projected labels are very noisy and it is unwise to use the tags directly. We further filter the noise using the approach of Yarowsky et al. (2001) which selects sentences with the highest sentence alignment scores from IBM model 3.",
      "startOffset" : 8,
      "endOffset" : 191
    }, {
      "referenceID" : 2,
      "context" : "For the simulation experiments, we use the CoNLL data (Buchholz and Marsi, 2006) as annotated data for eight languages.",
      "startOffset" : 54,
      "endOffset" : 80
    }, {
      "referenceID" : 4,
      "context" : "take the first 1,000 tagged tokens for training and the remaining data is split equally between development and testing sets, following Duong et al. (2014a). For the real-world experiments, we use the Malagasy and Kinyarwanda data from Garrette and Baldridge (2013), who showed that a small annotated dataset could be collected very cheaply, requiring less than 2 hours of non-expert time to tag 1000 tokens.",
      "startOffset" : 136,
      "endOffset" : 157
    }, {
      "referenceID" : 4,
      "context" : "take the first 1,000 tagged tokens for training and the remaining data is split equally between development and testing sets, following Duong et al. (2014a). For the real-world experiments, we use the Malagasy and Kinyarwanda data from Garrette and Baldridge (2013), who showed that a small annotated dataset could be collected very cheaply, requiring less than 2 hours of non-expert time to tag 1000 tokens.",
      "startOffset" : 136,
      "endOffset" : 266
    }, {
      "referenceID" : 4,
      "context" : "take the first 1,000 tagged tokens for training and the remaining data is split equally between development and testing sets, following Duong et al. (2014a). For the real-world experiments, we use the Malagasy and Kinyarwanda data from Garrette and Baldridge (2013), who showed that a small annotated dataset could be collected very cheaply, requiring less than 2 hours of non-expert time to tag 1000 tokens. This constitutes a reasonable demand for cheap portability to other low-resource languages. We use the datasets from Garrette and Baldridge (2013), constituting training sets of 383 sentences and 5,294 tokens in Malagasy and 196 sentences and 4,882 tokens for Kinyarwanda.",
      "startOffset" : 136,
      "endOffset" : 556
    }, {
      "referenceID" : 7,
      "context" : "(Garrette and Baldridge, 2013), which showed good results on the two low-resource languages.",
      "startOffset" : 0,
      "endOffset" : 30
    }, {
      "referenceID" : 4,
      "context" : "2 Setup and baselines We compare our algorithm with several baselines, including the state-of-the-art algorithm from Duong et al. (2014a), a two-output maxent model, their reported baseline method of a supervised maximum entropy model trained on the annotated data, and our BiLSTM POS tagger trained directly from the annotated and/or projected data (denoted BiLSTM Annotated, Projected and Ann+Proj for the model trained on union of the two datasets).",
      "startOffset" : 117,
      "endOffset" : 138
    }, {
      "referenceID" : 5,
      "context" : "Note that our method outperforms the state of the art on both languages (Duong et al., 2014a; Garrette and Baldridge, 2013).",
      "startOffset" : 72,
      "endOffset" : 123
    }, {
      "referenceID" : 7,
      "context" : "Note that our method outperforms the state of the art on both languages (Duong et al., 2014a; Garrette and Baldridge, 2013).",
      "startOffset" : 72,
      "endOffset" : 123
    }, {
      "referenceID" : 4,
      "context" : "For most of languages, our method is better than Duong et al. (2014a) and the three naive BiLSTM baselines.",
      "startOffset" : 49,
      "endOffset" : 70
    }, {
      "referenceID" : 5,
      "context" : "The top results of the second part are taken from (Duong et al., 2014a), evaluated on the same data split.",
      "startOffset" : 50,
      "endOffset" : 71
    } ],
    "year" : 2016,
    "abstractText" : "Cross lingual projection of linguistic annotation suffers from many sources of bias and noise, leading to unreliable annotations that cannot be used directly. In this paper, we introduce a novel approach to sequence tagging that learns to correct the errors from cross-lingual projection using an explicit noise layer. This is framed as joint learning over two corpora, one tagged with gold standard and the other with projected tags. We evaluated with only 1000 tokens tagged with gold standard tags, along with more plentiful parallel data. Our system equals or exceeds the state-of-the-art on eight simulated lowresource settings, as well as two real lowresource languages, Malagasy and Kinyarwanda.",
    "creator" : "TeX"
  }
}