{
  "name" : "129.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Semi-supervised Convolutional Networks for Translation Adaptation with Tiny Amount of In-domain Data",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "1 000\n012\n013\n014\n015\n016\n017\n018\n019\n020\n021\n022\n023\n024\n025\n026\n027\n028\n029\n030\n031\n032\n033\n034\n035\n036\n037\n038\n039\n040\n041\n042\n043\n044\n045\n046\n047\n048\n049\n050\n051\n064\n065\n066\n067\n068\n069\n070\n071\n072\n073\n074\n075\n076\n077\n078\n079\n080\n081\n082\n083\n084\n085\n086\n087\n088\n089\n090\n091\n092\n093\n094\n095\n096\n097\n098\n099\n100\n101\n102\n103"
    }, {
      "heading" : "1 Introduction",
      "text" : "Statistical machine translation (SMT) systems are trained on bilingual parallel and monolingual data. The training corpora typically come from different sources, and vary across topics, genres, dialects, authors’ written styles, etc., which are usually referred as “general domain” training data. Here the word “domain” is often used to indicate some combination of all above and other possible hidden factors (Chen et al., 2013). At run time, the\ncontent to be translated may come from a different domain. Due to the mismatch in “domains”, it is possible to achieve better performance by adapting the SMT system to the test domain (in-domain). However, manually creating training data to match the test domain is not a preferred solution, because 1) sometimes the test domain is not known when training the model, and it could change from sentence to sentence; 2) even if the test domain is pre-determined, the resources required and slow turnaround in data collection process will still delay the system development process. Therefore, training data selection is widely used for domain adaptation in statistical machine translation (Zhao et al., 2004; Lü et al., 2007; Yasuda et al., 2008; Moore and Lewis, 2010; Axelrod et al., 2011; Duh et al., 2013; Axelrod et al., 2015). Data selection techniques select monolingual or bilingual data that are similar to the indomain seed data based on some criteria, which are incorporated into the training data. The most successful data selection approaches (Moore and Lewis, 2010; Axelrod et al., 2011) train n-gram language models on in-domain text to select similar sentences from the large general-domain corpora according to the cross entropy. Furthermore, (Duh et al., 2013) obtained some gains by extending these approaches from n-gram models to recurrent neural network language models (Mikolov et al., 2010). To train the in-domain language model, a reasonable size in-domain data set, which typically includes several thousands of sentences, is required. In (Axelrod et al., 2011; Duh et al., 2013), the sizes of the in-domain data sets are 30K and over 100K sentences respectively. However, we do not always have access to large or even medium amounts of in-domain data. With the growth of social media, new domains have emerged which need machine translation but\n2\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n123\n124\n125\n126\n127\n128\n129\n130\n131\n132\n133\n134\n135\n136\n137\n138\n139\n140\n141\n142\n143\n144\n145\n146\n147\n148\n149\n150\n151\n152\n153\n154\n155\n156\n157\n158\n159\n160\n161\n162\n163\n164\n165\n166\n167\n168\n169\n170\n171\n172\n173\n174\n175\n176\n177\n178\n179\n180\n181\n182\n183\n184\n185\n186\n187\n188\n189\n190\n191\n192\n193\n194\n195\n196\n197\n198\n199\n200\n201\n202\n203\n204\n205\n206\n207\nwhich have very limited in-domain data, maybe just a few hundred sentence pairs. What’s more, if one wishes to build a large scale topic-specific MT system with hundreds of topics, it is prohibitively expensive to collect tens of thousands of in-domain sentences for each topic.\nIn this paper, we try to address this challenge, i.e., domain adaptation with very limited amounts of in-domain data. Inspired by the success of convolutional neural networks (CNNs) applied to image and text classification (Krizhevsky et al., 2012; Kim, 2014; Johnson and Zhang, 2015a; Johnson and Zhang, 2015b), we propose to use CNN to classify training sentence pairs as in-domain or out-of-domain sentences. To overcome the problem of limited in-domain data, we propose to augment the original model with semi-supervised convolutional neural networks for domain classification.\nConvolutional neural networks (CNNs) (LeCun and Bengio, 1998) are feed-forward neural networks that exploit the internal structure of data through convolution layers; each computation unit processes a small region of the input data. CNN has been very successful on image classification. When applying it to text input, the convolution layers process small regions of a document, i.e., a sequence of sentences or words. CNN has been gaining attention, and is now used in many text classification tasks (Kalchbrenner et al., 2014; Zeng et al., 2014; Johnson and Zhang, 2015b; Yin and Schütze, 2015; Wang et al., 2015).\nIn many of these studies, the first layer of the network converts words to word embeddings using table lookup. The word embeddings are either trained as part of CNN training, or pre-trained (thus fixed during model training time) on an additional unlabled corpus. The later is termed semi-supervised CNN. Given tiny amounts of indomain data, the information learned in these pretrained word embeddings is very helpful.\nWe use a small amount of in-domain data, such as the development set, as the positive sample and randomly select the same number of sentences from the general-domain training data as the negative sample to form the training sample for training the CNN classification model. This is a typical supervised learning setting. To compensate the limit of in-domain data size, we use word2vec (Mikolov et al., 2013) to learn the word embedding from a large amount of general-domain data.\nTogether with the labeled data, these word embeddings are fed to the convolution layer as additional input to train the final classification model. This is a semi-supervised framework. The learned models are then used to classify each sentence in the general-domain training data based on their domain relevance score. The top N sentence pairs are selected to train the SMT system. We carry out experiments on 4 different language directions with 9-15M sentence pairs in each direction. The test domains include short message (sms), tweets, and Facebook posts, etc. The experimental results show that our method is able to select a small amount of training data that is used to create a system which outperforms baseline systems trained with all the general-domain data. For example, we obtain over 3.1 BLEU improvement on the Chinese-to-English sms task with around 3% of the whole training data. Experiments also show that we can reduce the size of the in-domain sample to around 100 sentences and still obtain a 2.1 BLEU improvement."
    }, {
      "heading" : "2 Related Work",
      "text" : ""
    }, {
      "heading" : "2.1 SMT adaptation techniques",
      "text" : "Domain adaptation to SMT systems has recently received considerable attention. Based on the availability of in-domain bilingual or monolingual training data, there are several adaptation scenarios. Different domain adaptation techniques, including self-training, data selection, data weighting, etc., have been developed for different scenarios. Self-training (Ueffing and Ney, 2007; Schwenk, 2008; Bertoldi and Federico, 2009) uses generaldomain bilingual parallel data and in-domain monolingual data. An MT system is first trained on bilingual general-domain data, then it is used to translate in-domain monolingual data. The resulting target sentences or bilingual sentence pairs are then used as additional training data for language model or translation model training. Some early data selection approaches (Zhao et al., 2004; Lü et al., 2007; Moore and Lewis, 2010) use in-domain monolingual data to select monolingual or bilingual data that are similar to the indomain data according to some criterion. By contrast, (Axelrod et al., 2011; Duh et al., 2013; Axelrod et al., 2015) search for bilingual parallel sentences using the difference in language model perplexity between two language models trained on\n3\n209\n210\n211\n212\n213\n214\n215\n216\n217\n218\n219\n220\n221\n222\n223\n224\n225\n226\n227\n228\n229\n230\n231\n232\n233\n234\n235\n236\n237\n238\n239\n240\n241\n242\n243\n244\n245\n246\n247\n248\n249\n250\n251\n252\n253\n254\n255\n256\n257\n258\n259\n260\n261\n262\n263\n264\n265\n266\n267\n268\n269\n270\n271\n272\n273\n274\n275\n276\n277\n278\n279\n280\n281\n282\n283\n284\n285\n286\n287\n288\n289\n290\n291\n292\n293\n294\n295\n296\n297\n298\n299\n300\n301\n302\n303\n304\n305\n306\n307\n308\n309\n310\n311\nin-domain and out-domain data, respectively. Data weighting approaches weight each data item according to its relevance to the in-domain data. Mixture model adaptation (Foster and Kuhn, 2007; Foster et al., 2010; Sennrich, 2012; Foster et al., 2013) assumes that the general-domain data can be clustered to several sub-corpora, with some parts that are not too far from test domain. It combines sub-models trained on different sub-corpus data sets linearly or log-linearly with different weights. Vector space model adaptation (Chen et al., 2013) has the same assumption, and it weights each phrase pair based on vector space model (VSM). (Chen et al., 2014) improved the VSM adaptation by extending it to distributed VSM and grouped VSM. Instance weighting adopts a rich set of features to compute weights for each instance in the training data; it can be applied to sentence pairs (Matsoukas et al., 2009) or phrase pairs (Foster et al., 2010). If in-domain comparable data are available, (Daume III and Jagarlamudi, 2011; Irvine et al., 2013) propose mining translations from the comparable data to translate out-of-vocabulary (OOV) words and capture new senses for the new test domains. (Dou and Knight, 2012; Zhang and Zong, 2013) learn bilingual lexical or phrase tables from in-domain monolingual data with a decipherment method, then incorporate them into the SMT system. All the above approaches assume that either there is an in-domain (mono-lingual, parallel, or comparable) data set with a reasonable size available, or that some sub-corpora are closer to the test domain than others. There is no previous work considering the scenario where only a tiny amount of in-domain data is available: this is the scenario we address in this paper."
    }, {
      "heading" : "2.2 CNNs for text classification",
      "text" : "In a text classification task, key phrases (or ngrams) can help in determining the class of the text, regardless of their locations in the text. For example, the word “desktop” in a sentence may indicate this sentence has computers as its topic; the phrase “not satisfactory” may indicate that the sentiment of the entire sentence is negative. This kind of strong local information about the class of a text can appear in different regions in the input. Convolutional neural networks (CNNs) are useful for text classification because convolutional and\npooling layers allow the model to find such local indicators, wherever they are in the text. Recently, CNNs have shown promising results on many text classification tasks, such as sentiment analysis (Kalchbrenner et al., 2014; Kim, 2014), topic and sentiment classification (Johnson and Zhang, 2015a; Johnson and Zhang, 2015b), paraphrase identification (Yin and Schütze, 2015), entity relation type classification (Zeng et al., 2014; dos Santos et al., 2015), short-text classification (Wang et al., 2015), event extraction and detection (Chen et al., 2015; Nguyen and Grishman, 2015), question understanding and answering (Dong et al., 2015), and box-office prediction based on reviews (Bitvai and Cohn, 2015), etc. Within the CNN architecture, people also use word embeddings for text classification. (Kalchbrenner et al., 2014) proposes a CNN framework with multiple convolution layers, with latent, dense and low-dimensional word embeddings as inputs. (Kim, 2014) defines a one-layer CNN architecture with comparable performance to (Kalchbrenner et al., 2014). The word embeddings input to the CNN can be pre-trained, and treated as fixed input, or tuned for a specific task. (Johnson and Zhang, 2015b) extends their “one-hot” CNN in (Johnson and Zhang, 2015a) to take region embeddings trained on unlabeled data as CNN input. CNNs that input word embeddings trained on unlabeled data are considered to be semi-supervised CNNs."
    }, {
      "heading" : "3 Semi-supervised CNN",
      "text" : "A CNN is a feed-forward network consisting of convolutional and pooling layers. Each neuron in the convolutional layer of a CNN processes a segment of input signals, which could be a region in an image or a window of words in a sentence. The convolution layer consists of a set of kernels that compute the dot product between different segments of the input. The kernel associated with the l-th segment of the input x computes:\nσ(W · wl(x) + b), (1)\nwhere wl(x) ∈ Rq is the input window vector that represents the l-th segment of data. Weight matrix W ∈ Rm×q and bias vector b ∈ Rm are shared by all the kernels in the same layer, and are learned during the training process. Because the convolution kernel allows interaction between different parts of the input, it reduces\n4\n313\n314\n315\n316\n317\n318\n319\n320\n321\n322\n323\n324\n325\n326\n327\n328\n329\n330\n331\n332\n333\n334\n335\n336\n337\n338\n339\n340\n341\n342\n343\n344\n345\n346\n347\n348\n349\n350\n351\n352\n353\n354\n355\n356\n357\n358\n359\n360\n361\n362\n363\n364\n365\n366\n367\n368\n369\n370\n371\n372\n373\n374\n375\n376\n377\n378\n379\n380\n381\n382\n383\n384\n385\n386\n387\n388\n389\n390\n391\n392\n393\n394\n395\n396\n397\n398\n399\n400\n401\n402\n403\n404\n405\n406\n407\n408\n409\n410\n411\n412\n413\n414\n415\nthe requirement to select features by hand. Important features in a sentence are automatically selected with pooling, which is a form of non-linear down-sampling. It takes the maximum or the average value observed in each of the d dimension vectors over different windows. As a result, information from multiple d dimension vectors is kept in a single d dimensional vector. At training time, both the weight vectors and the bias vectors are learned with stochastic gradient ascent."
    }, {
      "heading" : "3.1 One-hot CNN",
      "text" : "When applying CNN to NLP tasks, the first layer of the network takes word embeddings as input. Word embeddings can be pre-trained using tools such as word2vec (Mikolov et al., 2013) or GloV e (Pennington et al., 2014), in which case a table lookup is enough. Alternatively, these vectors can be learned from scratch as a step in the network training process. When there are enough in-domain data, training in-domain word embeddings is meaningful. However, when the in-domain data are limited, the word embeddings learned from these data are unreliable. In this case, the input sentence x can be represented with one-hot vectors where each vector’s length is the vocabulary size, value 1 at index i indicates word i appears in the sentence, and 0 indicates its absence. A CNN with one-hot vector input is called “one-hot CNN” (Johnson and Zhang, 2015a). wl(x) can be either a concatenation of one-hot vectors, in which the order of concatenation is the same as the word order in the sentence, or it can be a bag-of-word/n-gram vector. The bag-of-word (BOW) representation loses word order information but is more robust to data sparsity. In (Johnson and Zhang, 2015a), a CNN whose input being BOW representation is called bow-CNN while input with concatenation of vectors is called seq-CNN. The window size and stride (distance between the window centers) are meta-parameters. σ in Equation 1 is a component-wise non-linear function such as ReLU. Thus, each kernel generates anm-dimensional vector wherem is the number of weight vectors or neurons. These vectors from all the windows of each sentence are aggregated by the pooling layer, by either componentwise maximum (max pooling) or average (average pooling), then used by the top layer as features for classification."
    }, {
      "heading" : "3.2 Semi-supervised CNN",
      "text" : "Although the size of the in-domain data is normally small, the unlabeled data from general domains are much larger and easier to obtain. To exploit large amounts of unlabeled data, we adopt a semi-supervised learning framework similar to (Johnson and Zhang, 2015b). It first learns word embedding from unlabeled data, then generates the text segment embedding based on these unsupervised word embeddings. Both the one-hot vectors from the labeled data and the segment embeddings from unlabeled data are combined to train the CNN classifier. The word embeddings map each word to a realvalued, dense vector (Bengio et al., 2003). Word embeddings are often learned with an unsupervised learning paradigm: each dimension of the continuous word embeddings aims at capturing a latent feature, reflecting certain syntactic and semantic meanings of the word. A widely used approach for generating useful word embeddings was developed by (Mikolov et al., 2013). This method learns the word embeddings such that the likelihood of generating a word based on its contexts (or generating the context of a given word, aka “skip-gram” model) is maximized. It speeds up the training with the hierarchical softmax strategy and a simplified learning objective, which scales very well to very large training corpora. We adopt the skip-gram model, which intuitively learns a classifier that predicts words conditioned on the central word’s vector representation. An advantage of such distributed representations is that words that have similar contexts, and therefore similar syntactic and semantic properties, will tend to be near one another in the low-dimensional vector space. Given the word embeddings trained from unlabeled data, a sentence is represented as a sequence of d-dimensional vectors, which is the input to a convolution network that generates feature vectors for each text segment. The segment vectors and one-hot vectors are fed into another convolution layer, which outputs the classification labels. The second network is trained with the labeled indomain/out-domain data. Therefore, Equation 1 is replaced with:\nσ(W · wl(x) + V · ul(x) + b), (2)\nwhere wl(x) is the one-hot vector obtained from segment l in a sentence, and ul(x) is the embed-\n5\n417\n418\n419\n420\n421\n422\n423\n424\n425\n426\n427\n428\n429\n430\n431\n432\n433\n434\n435\n436\n437\n438\n439\n440\n441\n442\n443\n444\n445\n446\n447\n448\n449\n450\n451\n452\n453\n454\n455\n456\n457\n458\n459\n460\n461\n462\n463\n464\n465\n466\n467\n468\n469\n470\n471\n472\n473\n474\n475\n476\n477\n478\n479\n480\n481\n482\n483\n484\n485\n486\n487\n488\n489\n490\n491\n492\n493\n494\n495\n496\n497\n498\n499\n500\n501\n502\n503\n504\n505\n506\n507\n508\n509\n510\n511\n512\n513\n514\n515\n516\n517\n518\n519\nding learned from the unlabeled data (general domain training data), applied to the same segment. We train this model with the labeled data. We update the weights W, V, bias b, and the top-layer parameters so that the designated loss function is minimized on the labeled training data."
    }, {
      "heading" : "4 Adaptation based on data selection",
      "text" : "We use the in-domain data from the translation task as positive samples, and randomly select the same number of sentences from the general domain data as negative samples. We train the CNN model on the positive and negative samples with the one-hot CNN or semi-supervised CNN described previously. The trained CNN model is then used to classify the sentence pairs in the general domain data. The sentence pairs with high in-domain scores are selected to train the machine translation system. We classify the source sentence and target sentences separately. The CNN model computes two scores for each sentence pair. The sentence pairs are selected based on the source scores, target scores or the sum of source and target scores. Experiments show that selection based on the sum of the source and target scores achieves the best performance. We empirically determine the number of selected in-domain sentences for each MT system based on experimental results on a separate validation set. When selecting the negative samples, we either randomly sample from the whole data pool, or select from the sentences which have been labeled as negative in the first round classification. Additional experiments show that the results from these two methods are very similar, so we sample the negative samples from the whole general domain for simplicity."
    }, {
      "heading" : "5 Experiments",
      "text" : "Our goal is to adapt the MT system when only a tiny amount of in-domain data is available. So in our experiments, we did not consider any domain information about the training data, such as the source of each corpus. What we have is a small development set (dev) and one or more test sets (test) which are in the same domain."
    }, {
      "heading" : "5.1 Data setting",
      "text" : "We carried out experiments in four different data settings. All four have large amounts of bilin-\ngual training data: 9-15M sentences. The first two involve translation into English (en) from Chinese (zh) and Arabic (ar), while the last two involve translation from English to Spanish (es) and Chinese. The training data are all publicly available, either from LDC1 and transcriptions of TED talks2, where the data are the mixture of newswire, web crawl, UN proceedings and TED talks, etc., or from WMT3, where the data are the mixture of Europarl, web crawl, news-commentary, and UN proceedings, etc. The dev and test sets are “short messages (sms)” for the first task, which are also available from LDC; “tweets” for the second task; publicly available “Facebook post” for the remaining two tasks. The last three tasks are from social media - an intriguing new area of application for MT - where in-domain parallel training data are seldom publicly available. Table 1 summarizes the statistics of the training, dev, and test data for all the test sets."
    }, {
      "heading" : "5.2 Experiment setup",
      "text" : "We experiment with two CNN-based data selection strategies:\n1. ohcnn: Data selection by supervised one-hot CNN (Section 3.1)\n2. sscnn: Data selection by semi-supervised CNN (Section 3.2)\nWe employ the dev set as in-domain data. All the supervised CNN models are trained with the in-domain dev data as positive examples and an equal number of randomly selected generaldomain sentences as negative examples. All the meta-parameters of the CNN are tuned on heldout data; we generate both bow-regions and seqregions and input them to the CNN. We set the region size to 5 and stride size to 1. The nonlinear function we chose is “ReLU”, the number of weight vectors or neurons is 500. The pooling method is component-wise maximum (max pooling). We use the online available CNN toolkit conText4. To train the general domain word embedding, we used word2vec5. The size of the vector was set to 300. We also generate wordembedding-based bow-regions and seq-regions as additional input to the CNN.\n1https://catalog.ldc.upenn.edu/ 2https://wit3.fbk.eu/ 3http://statmt.org/wmt15/ 4http://riejohnson.com/cnn download.html 5https://code.google.com/archive/p/word2vec/\n6\n521\n522\n523\n524\n525\n526\n527\n528\n529\n530\n531\n532\n533\n534\n535\n536\n537\n538\n539\n540\n541\n542\n543\n544\n545\n546\n547\n548\n549\n550\n551\n552\n553\n554\n555\n556\n557\n558\n559\n560\n561\n562\n563\n564\n565\n566\n567\n568\n569\n570\n571\n572\n573\n574\n575\n576\n577\n578\n579\n580\n581\n582\n583\n584\n585\n586\n587\n588\n589\n590\n591\n592\n593\n594\n595\n596\n597\n598\n599\n600\n601\n602\n603\n604\n605\n606\n607\n608\n609\n610\n611\n612\n613\n614\n615\n616\n617\n618\n619\n620\n621\n622\n623\nlanguage zh2en ar2en en2es en2zh test domain sms tweets facebook facebook train origin LDC&TED LDC&TED WMT LDC&TED train size 12.20M 8.97M 15.23M 12.20M dev size 6,016 1,000 800 650 test size 3,282 1,500 3,378 3,343\nTable 1: Summary of the data. “sms” means “short message”. “facebook” means “Facebook post”. Data is given as the number of sentence pairs, “M” represents “million”. The tasks “zh2en” and “en2zh” use the same training data.\nWe compared with four baselines for each task. The first baseline SMT system is trained using all general-domain data. The other three systems are trained with data selected with different LM-based data selection methods as same as in (Duh et al., 2013)6. The four baselines are:\n1. alldata: All general-domain data.\n2. ngram: Data selection by 3-gram LMs with Witten-Bell 7 smoothing (Axelrod et al., 2011)\n3. rnnlm: Data selection by recurrent neural network LM, with the RNNLM Toolkit (Duh et al., 2013)\n4. comblm: Data selection by the combined LM using ngram & rnnlm (equal weight) (Duh et al., 2013).\nAll systems are trained with a standard phrasebased SMT system with standard settings, i.e., GIZA++ alignment, phrase table Kneser-Ney smoothing, hierarchical reordering models, target side 4-gram language model, and “gigaword” 5- gram language model for systems with English as the target language, etc."
    }, {
      "heading" : "5.3 Experimental results",
      "text" : "We evaluated the system using BLEU (Papineni et al., 2002) score on the test set. Following (Koehn, 2004), we use the bootstrap resampling test to do significance testing. Table 2 summarizes the results and numbers of the selected sentences for each task. First, we can see that all the data selection methods improved the performance over the baseline “alldata” with much less\n6The code and scripts for the three baselines are available at http://cl.naist.jp/ kevinduh/a/acl2013/\n7For small amounts of data, Witten-Bell smoothing had performed better than Kneser-Ney smoothing in our experiments\ntraining data (only around 2.5% to 10% of the whole training data). Consistent with (Duh et al., 2013), the three LM based data selection all got improvements, where “rnnlm” obtained better performance than the “ngram” on average. It is not clear that combining the two language model methods (“comblm”) yields further improvement. While the one-hot CNN method “ohcnn” obtained similar improvement as the three LM-based methods on average. The semi-supervised CNN (sscnn) achieved the best performance for all the tasks: its improvements over the “alldata” baseline are 3.1, 1.4, 0.7 and 1.4 BLEU score respectively. It beats “ohcnn” by about 0.5 BLEU point on average. There are two results worth noticing. First, task 1 (zh2en sms task) obtained very high BLEU improvement through data selection. This is because in this task, there is a 120K in-domain subset within the general-domain data. If we train a system on this in-domain data set, we get 25.7 BLEU on the test set. The LM-based methods did not beat this “in-domain data only (indata)” baseline, while the semi-supervised CNN method performed significantly better than this baseline at p < 0.05 level. Second, for the other three tasks, there is no in-domain data component in the general-domain data (that we know of). Even in this case, we achieved up to 1.4 BLEU improvement, which demonstrates the effectiveness of our method: it can select highly suitable in-domain sentences, even when the in-domain data is very limited. In our second experiment, we examine how many labeled samples are needed to train a strong CNN classifier to select theMT training in-domain data. Fixing the number of MT training sentence pairs to 300K that will be selected by the CNN, we reduce the CNN training data from 6,000 down to 100 sentence pairs in steps. The performance of the resulting MT systems for all five data selection\n7\n625\n626\n627\n628\n629\n630\n631\n632\n633\n634\n635\n636\n637\n638\n639\n640\n641\n642\n643\n644\n645\n646\n647\n648\n649\n650\n651\n652\n653\n654\n655\n656\n657\n658\n659\n660\n661\n662\n663\n664\n665\n666\n667\n668\n669\n670\n671\n672\n673\n674\n675\n676\n677\n678\n679\n680\n681\n682\n683\n684\n685\n686\n687\n688\n689\n690\n691\n692\n693\n694\n695\n696\n697\n698\n699\n700\n701\n702\n703\n704\n705\n706\n707\n708\n709\n710\n711\n712\n713\n714\n715\n716\n717\n718\n719\n720\n721\n722\n723\n724\n725\n726\n727\nzh2en ar2en en2es en2zh #sent BLEU #sent BLEU #sent BLEU #sent BLEU\nalldata 12.2M 22.9 8.9M 17.6 15.2M 26.8 12.2M 10.0 ngram 300K 25.3** 800K 18.2** 1600K 26.9 400K 10.5* rnnlm 300K 25.6** 800K 18.4** 1600K 27.0 400K 10.5*\ncomblm 400K 25.7** 800K 18.4** 1400K 27.0 500K 10.4* ohcnn 300K 25.3** 700K 18.2* 1200K 27.1* 400K 11.0**+ sscnn 300K 26.0**+ 700K 19.0**++ 1300K 27.5**++ 300K 11.4**++\nTable 2: Summary of the results. Data size is given as number of sentence pairs. The number of selected in-domain sentences is determined by the performance on held-out data. “M” represents million, “K” represents thousand. */** means result is significantly better than the “alldata” baseline at p < 0.05 or p < 0.01 level, respectively. +/++ means result is significantly better than the best LM-based method at p < 0.05 or p < 0.01 level, respectively.\nFigure 1: The performance on zh2en sms task with different numbers of in-domain sentences to train LM-based vs. CNN-based classifiers, which are then used to select 300K sentence pairs for MT system training. X-axis is the number of in-domain sentences, Y-axis is BLEU score.\n8\n729\n730\n731\n732\n733\n734\n735\n736\n737\n738\n739\n740\n741\n742\n743\n744\n745\n746\n747\n748\n749\n750\n751\n752\n753\n754\n755\n756\n757\n758\n759\n760\n761\n762\n763\n764\n765\n766\n767\n768\n769\n770\n771\n772\n773\n774\n775\n776\n777\n778\n779\n780\n781\n782\n783\n784\n785\n786\n787\n788\n789\n790\n791\n792\n793\n794\n795\n796\n797\n798\n799\n800\n801\n802\n803\n804\n805\n806\n807\n808\n809\n810\n811\n812\n813\n814\n815\n816\n817\n818\n819\n820\n821\n822\n823\n824\n825\n826\n827\n828\n829\n830\n831\nmethods is shown in Figure 1. From Figure 1, we can see that all the data selection methods obtained improvement compared to the “alldata” baseline. When the in-domain training sample is more than 1600 sentence pairs, all the data selection methods obtain reasonable and comparable improvement, while “sscnn” is better than the best LM-based method by 0.3-0.5 BLEU. However, when the in-domain training sample is less than 800 sentence pairs, the difference between the “sscnn” and other methods gets bigger, and CNN-based methods get more stable results than the LM-based methods get. For instance, when the in-domain set increases from 400 to 800, the LM-based methods did not get an improvement; “ngram” and “comblm” even got a small loss on BLEU score. When the in-domain sample is reduced to 100 sentence pairs, the LM-based methods only get a small improvement over the baseline, while the “ohcnn” got a 1.2 BLEU score improvement over the baseline and “sscnn” got a 2.1 BLEU improvement over the baseline. Thus, even if we have no domain knowledge about the training data, when we have only 100 sentences in the test domain, the semi-supervised CNN classifier can still select a good in-domain subset and achieve good performance. We obtained 2.1 BLEU improvement even when we randomly select only 100 in-domain sentence pairs to train the classification model. Is this just because we luckily sampled a good part of the in-domain data? We repeated the “100 in-domain sentence pairs experiment” three times for our most effective method - “sscnn” - by sampling three different in-domain sets from the whole 6,016-sentence dev set. The average BLEU score we got is 25.03, and the standard deviation is 0.12. This means that our algorithm is quite stable even when the in-domain set is very small."
    }, {
      "heading" : "5.4 Discussion",
      "text" : "Why do semi-supervised convolutional neural networks perform so well for data selection? We think there are two main reasons. The first one is that convolution captures the important domain information of the words in the window, and the max-pooling operation combines the vectors which, as a result, focuses on the most important “features” in the sentence. Even a highly domainspecific sentence normally contains both domainspecific words and general-domain words. For\nexample, in “I have a Dell desktop and a Macbook laptop”, the words “Dell, laptop, Macbook, laptop” are from the computer domain, while the words “I, have, a, and” are general. However, the topic of this sentence is decided by the domain specific words, not the general-domain words. If the properties of the words “Dell, laptop, Macbook, laptop” are kept and highlighted, classification will be more accurate for this sentence. The second reason is the use of word embedding learned from the whole general-domain data. A very important advantage of word embedding is that words that have similar meaning will tend to be grouped together in the vector space. If the word “Lenovo” in the test sentence is not seen in the labeled data, it would be difficult for LMbased models to classify sentences like “I prefer choosing a Lenovo machine” as computer-domain sentence. However, the word embeddings learned from much larger unlabeled data ensure that the word embedding of “Lenovo” is close to that of “Dell”. According to the domain of its neighbor words, the CNN model can still label this sentence as belonging to the computer domain. This property is particularly useful for fast or fine grained adaptation, where obtaining large amount of indomain samples may be slow or too expensive."
    }, {
      "heading" : "6 Conclusions and future work",
      "text" : "Domain adaptation with only a tiny amount of in-domain data is a hard problem. In this paper, we proposed to use a semi-supervised convolutional neural network (CNN) to train the domain classification model, then use the CNN to select the data which is most similar to the test domain. Experiments on large data condition SMT tasks showed that this outperforms state-of-the-art language-model-based data selection methods significantly. Particularly when the size of the indomain data is small, semi-supervised CNN classifier can still select in-domain bilingual sentences to train an adapted SMT system. In future work, we plan to 1) apply this approach to select the data from large size target language corpus, such as the “Gigaword” corpus, for language model training; 2) use the source sentences of the test set to select the data for online dynamic adaptation."
    } ],
    "references" : [ {
      "title" : "Domain adaptation via pseudo in-domain data",
      "author" : [ "Amittai Axelrod", "Xiaodong He", "Jianfeng Gao" ],
      "venue" : null,
      "citeRegEx" : "Axelrod et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Axelrod et al\\.",
      "year" : 2011
    }, {
      "title" : "Data selection with fewer words",
      "author" : [ "Amittai Axelrod", "Philip Resnik", "Xiaodong He", "Mari Ostendorf." ],
      "venue" : "Proceedings of the Tenth Workshop on Statistical Machine Translation, pages 58–65, Lisbon, Portugal, September.",
      "citeRegEx" : "Axelrod et al\\.,? 2015",
      "shortCiteRegEx" : "Axelrod et al\\.",
      "year" : 2015
    }, {
      "title" : "A neural probabilistic language model",
      "author" : [ "Yoshua Bengio", "Réjean Ducharme", "Pascal Vincent", "Christian Janvin." ],
      "venue" : "J. Mach. Learn. Res., 3:1137–1155, March.",
      "citeRegEx" : "Bengio et al\\.,? 2003",
      "shortCiteRegEx" : "Bengio et al\\.",
      "year" : 2003
    }, {
      "title" : "Domain adaptation for statistical machine translation with monolingual resources",
      "author" : [ "Nicola Bertoldi", "Marcello Federico." ],
      "venue" : "Proceedings of the 4th Workshop on Statistical Machine Translation, Athens, March. WMT.",
      "citeRegEx" : "Bertoldi and Federico.,? 2009",
      "shortCiteRegEx" : "Bertoldi and Federico.",
      "year" : 2009
    }, {
      "title" : "Non-linear text regression with a deep convolutional neural network",
      "author" : [ "Zsolt Bitvai", "Trevor Cohn." ],
      "venue" : "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Lan-",
      "citeRegEx" : "Bitvai and Cohn.,? 2015",
      "shortCiteRegEx" : "Bitvai and Cohn.",
      "year" : 2015
    }, {
      "title" : "Vector space model for adaptation in statistical machine translation",
      "author" : [ "Boxing Chen", "Roland Kuhn", "George Foster." ],
      "venue" : "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1285–",
      "citeRegEx" : "Chen et al\\.,? 2013",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2013
    }, {
      "title" : "A comparison of mixture and vector space techniques for translation model adaptation",
      "author" : [ "Boxing Chen", "Roland Kuhn", "George Foster." ],
      "venue" : "Proceedings of AMTA, Vancouver, Canada, Oct.",
      "citeRegEx" : "Chen et al\\.,? 2014",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2014
    }, {
      "title" : "Event extraction via dynamic multi-pooling convolutional neural networks",
      "author" : [ "Yubo Chen", "Liheng Xu", "Kang Liu", "Daojian Zeng", "Jun Zhao." ],
      "venue" : "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the",
      "citeRegEx" : "Chen et al\\.,? 2015",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2015
    }, {
      "title" : "Domain adaptation for machine translation by mining unseen words",
      "author" : [ "Hal Daume III", "Jagadeesh Jagarlamudi." ],
      "venue" : "ACL 2011.",
      "citeRegEx" : "III and Jagarlamudi.,? 2011",
      "shortCiteRegEx" : "III and Jagarlamudi.",
      "year" : 2011
    }, {
      "title" : "Question answering over freebase with multicolumn convolutional neural networks",
      "author" : [ "Li Dong", "Furu Wei", "Ming Zhou", "Ke Xu." ],
      "venue" : "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th Interna-",
      "citeRegEx" : "Dong et al\\.,? 2015",
      "shortCiteRegEx" : "Dong et al\\.",
      "year" : 2015
    }, {
      "title" : "Classifying relations by ranking with convolutional neural networks",
      "author" : [ "Cicero dos Santos", "Bing Xiang", "Bowen Zhou." ],
      "venue" : "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint",
      "citeRegEx" : "Santos et al\\.,? 2015",
      "shortCiteRegEx" : "Santos et al\\.",
      "year" : 2015
    }, {
      "title" : "Large scale decipherment for out-of-domain machine translation",
      "author" : [ "Qing Dou", "Kevin Knight." ],
      "venue" : "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages",
      "citeRegEx" : "Dou and Knight.,? 2012",
      "shortCiteRegEx" : "Dou and Knight.",
      "year" : 2012
    }, {
      "title" : "Adaptation data selection using neural language models: Experiments in machine translation",
      "author" : [ "Kevin Duh", "Graham Neubig", "Katsuhito Sudoh", "Hajime Tsukada." ],
      "venue" : "Proceedings of the 51st Annual Meeting of the Association for Computational Lin-",
      "citeRegEx" : "Duh et al\\.,? 2013",
      "shortCiteRegEx" : "Duh et al\\.",
      "year" : 2013
    }, {
      "title" : "Mixturemodel adaptation for SMT",
      "author" : [ "George Foster", "Roland Kuhn." ],
      "venue" : "Proceedings of the ACL Workshop on Statistical Machine Translation, Prague, June. WMT.",
      "citeRegEx" : "Foster and Kuhn.,? 2007",
      "shortCiteRegEx" : "Foster and Kuhn.",
      "year" : 2007
    }, {
      "title" : "Discriminative instance weighting for domain adaptation in statistical machine translation",
      "author" : [ "George Foster", "Cyril Goutte", "Roland Kuhn." ],
      "venue" : "Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP), Boston.",
      "citeRegEx" : "Foster et al\\.,? 2010",
      "shortCiteRegEx" : "Foster et al\\.",
      "year" : 2010
    }, {
      "title" : "Simulating discriminative training for linear mixture adaptation in statistical machine translation",
      "author" : [ "George Foster", "Boxing Chen", "Roland Kuhn." ],
      "venue" : "MT Summit, Nice, France.",
      "citeRegEx" : "Foster et al\\.,? 2013",
      "shortCiteRegEx" : "Foster et al\\.",
      "year" : 2013
    }, {
      "title" : "Monolingual marginal matching for translation model adaptation",
      "author" : [ "Ann Irvine", "Chris Quirk", "Hal Daumé III." ],
      "venue" : "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1077–1088, Seattle, Washington,",
      "citeRegEx" : "Irvine et al\\.,? 2013",
      "shortCiteRegEx" : "Irvine et al\\.",
      "year" : 2013
    }, {
      "title" : "Effective use of word order for text categorization with convolutional neural networks",
      "author" : [ "Rie Johnson", "Tong Zhang." ],
      "venue" : "Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Hu-",
      "citeRegEx" : "Johnson and Zhang.,? 2015a",
      "shortCiteRegEx" : "Johnson and Zhang.",
      "year" : 2015
    }, {
      "title" : "Semi-supervised convolutional neural networks for text categorization via region embedding",
      "author" : [ "Rie Johnson", "Tong Zhang." ],
      "venue" : "C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural Information Processing",
      "citeRegEx" : "Johnson and Zhang.,? 2015b",
      "shortCiteRegEx" : "Johnson and Zhang.",
      "year" : 2015
    }, {
      "title" : "A convolutional neural network for modelling sentences",
      "author" : [ "Nal Kalchbrenner", "Edward Grefenstette", "Phil Blunsom." ],
      "venue" : "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages",
      "citeRegEx" : "Kalchbrenner et al\\.,? 2014",
      "shortCiteRegEx" : "Kalchbrenner et al\\.",
      "year" : 2014
    }, {
      "title" : "Convolutional neural networks for sentence classification",
      "author" : [ "Yoon Kim." ],
      "venue" : "CoRR, abs/1408.5882.",
      "citeRegEx" : "Kim.,? 2014",
      "shortCiteRegEx" : "Kim.",
      "year" : 2014
    }, {
      "title" : "Statistical significance tests for machine translation evaluation",
      "author" : [ "Philipp Koehn." ],
      "venue" : "Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing (EMNLP), Barcelona, Spain.",
      "citeRegEx" : "Koehn.,? 2004",
      "shortCiteRegEx" : "Koehn.",
      "year" : 2004
    }, {
      "title" : "Imagenet classification with deep convolutional neural networks",
      "author" : [ "Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E. Hinton." ],
      "venue" : "F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger, editors, Advances in Neural Information Processing Systems",
      "citeRegEx" : "Krizhevsky et al\\.,? 2012",
      "shortCiteRegEx" : "Krizhevsky et al\\.",
      "year" : 2012
    }, {
      "title" : "Convolutional networks for images, speech, and time series",
      "author" : [ "Yann LeCun", "Yoshua Bengio." ],
      "venue" : "Michael A. Arbib, editor, The Handbook of Brain Theory and Neural Networks, pages 255–258. MIT Press, Cambridge, MA, USA.",
      "citeRegEx" : "LeCun and Bengio.,? 1998",
      "shortCiteRegEx" : "LeCun and Bengio.",
      "year" : 1998
    }, {
      "title" : "Improving Statistical Machine Translation Performance by Training Data Selection and Optimization",
      "author" : [ "Yajuan Lü", "Jin Huang", "Qun Liu." ],
      "venue" : "Proceedings of the 2007 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
      "citeRegEx" : "Lü et al\\.,? 2007",
      "shortCiteRegEx" : "Lü et al\\.",
      "year" : 2007
    }, {
      "title" : "Discriminative corpus weight estimation for machine translation",
      "author" : [ "Spyros Matsoukas", "Antti-Veikko I. Rosti", "Bing Zhang." ],
      "venue" : "Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing (EMNLP), Singapore.",
      "citeRegEx" : "Matsoukas et al\\.,? 2009",
      "shortCiteRegEx" : "Matsoukas et al\\.",
      "year" : 2009
    }, {
      "title" : "Recurrent neural network based language model",
      "author" : [ "Tomáš Mikolov", "Martin Karafiát", "Lukáš Burget", "Jan Černocký", "Sanjeev Khudanpur." ],
      "venue" : "Proceedings of the 11th Annual Conference of the International Speech Communication Association (IN-",
      "citeRegEx" : "Mikolov et al\\.,? 2010",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2010
    }, {
      "title" : "Efficient estimation of word representations in vector space",
      "author" : [ "Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean." ],
      "venue" : "CoRR, abs/1301.3781.",
      "citeRegEx" : "Mikolov et al\\.,? 2013",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2013
    }, {
      "title" : "Intelligent selection of language model training data",
      "author" : [ "Robert C. Moore", "William Lewis." ],
      "venue" : "ACL 2010.",
      "citeRegEx" : "Moore and Lewis.,? 2010",
      "shortCiteRegEx" : "Moore and Lewis.",
      "year" : 2010
    }, {
      "title" : "Event detection and domain adaptation with convolutional neural networks",
      "author" : [ "Thien Huu Nguyen", "Ralph Grishman." ],
      "venue" : "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference",
      "citeRegEx" : "Nguyen and Grishman.,? 2015",
      "shortCiteRegEx" : "Nguyen and Grishman.",
      "year" : 2015
    }, {
      "title" : "BLEU: A method for automatic evaluation of Machine Translation",
      "author" : [ "Kishore Papineni", "Salim Roukos", "Todd Ward", "WeiJing Zhu." ],
      "venue" : "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL), pages 311–318,",
      "citeRegEx" : "Papineni et al\\.,? 2002",
      "shortCiteRegEx" : "Papineni et al\\.",
      "year" : 2002
    }, {
      "title" : "Glove: Global vectors for",
      "author" : [ "Jeffrey Pennington", "Richard Socher", "Christopher D. Manning" ],
      "venue" : null,
      "citeRegEx" : "Pennington et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Pennington et al\\.",
      "year" : 2014
    }, {
      "title" : "Investigations on largescale lightly-supervised training for statistical machine translation",
      "author" : [ "Holger Schwenk." ],
      "venue" : "IWSLT 2008.",
      "citeRegEx" : "Schwenk.,? 2008",
      "shortCiteRegEx" : "Schwenk.",
      "year" : 2008
    }, {
      "title" : "Perplexity minimization for translation model domain adaptation in statistical machine translation",
      "author" : [ "Rico Sennrich." ],
      "venue" : "EACL 2012.",
      "citeRegEx" : "Sennrich.,? 2012",
      "shortCiteRegEx" : "Sennrich.",
      "year" : 2012
    }, {
      "title" : "Wordlevel confidence estimation for machine translation",
      "author" : [ "Nicola Ueffing", "Hermann Ney." ],
      "venue" : "Computational Linguistics, 33(1):9–40.",
      "citeRegEx" : "Ueffing and Ney.,? 2007",
      "shortCiteRegEx" : "Ueffing and Ney.",
      "year" : 2007
    }, {
      "title" : "Semantic clustering and convolutional neural network for short text categorization",
      "author" : [ "Peng Wang", "Jiaming Xu", "Bo Xu", "Chenglin Liu", "Heng Zhang", "Fangyuan Wang", "Hongwei Hao." ],
      "venue" : "Proceedings of the 53rd Annual Meeting of the Association for",
      "citeRegEx" : "Wang et al\\.,? 2015",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2015
    }, {
      "title" : "Method of selecting training data to build a compact and ef?cient translation model",
      "author" : [ "Keiji Yasuda", "Ruiqiang Zhang", "Hirofumi Yamamoto", "Eiichiro Sumita." ],
      "venue" : "International Joint Conference on Natural Language Processing.",
      "citeRegEx" : "Yasuda et al\\.,? 2008",
      "shortCiteRegEx" : "Yasuda et al\\.",
      "year" : 2008
    }, {
      "title" : "Convolutional neural network for paraphrase identification",
      "author" : [ "Wenpeng Yin", "Hinrich Schütze." ],
      "venue" : "Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,",
      "citeRegEx" : "Yin and Schütze.,? 2015",
      "shortCiteRegEx" : "Yin and Schütze.",
      "year" : 2015
    }, {
      "title" : "Relation classification via convolutional deep neural network",
      "author" : [ "Daojian Zeng", "Kang Liu", "Siwei Lai", "Guangyou Zhou", "Jun Zhao." ],
      "venue" : "Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,",
      "citeRegEx" : "Zeng et al\\.,? 2014",
      "shortCiteRegEx" : "Zeng et al\\.",
      "year" : 2014
    }, {
      "title" : "Learning a phrase-based translation model from monolingual data with application to domain adaptation",
      "author" : [ "Jiajun Zhang", "Chengqing Zong." ],
      "venue" : "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long",
      "citeRegEx" : "Zhang and Zong.,? 2013",
      "shortCiteRegEx" : "Zhang and Zong.",
      "year" : 2013
    }, {
      "title" : "Language model adaptation for statistical machine translation with structured query models",
      "author" : [ "Bing Zhao", "Matthias Eck", "Stephan Vogel." ],
      "venue" : "Proceedings of the International Conference on Computational Linguistics (COLING) 2004, Geneva, Au-",
      "citeRegEx" : "Zhao et al\\.,? 2004",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2004
    } ],
    "referenceMentions" : [ {
      "referenceID" : 5,
      "context" : "Here the word “domain” is often used to indicate some combination of all above and other possible hidden factors (Chen et al., 2013).",
      "startOffset" : 113,
      "endOffset" : 132
    }, {
      "referenceID" : 40,
      "context" : "Therefore, training data selection is widely used for domain adaptation in statistical machine translation (Zhao et al., 2004; Lü et al., 2007; Yasuda et al., 2008; Moore and Lewis, 2010; Axelrod et al., 2011; Duh et al., 2013; Axelrod et al., 2015).",
      "startOffset" : 107,
      "endOffset" : 249
    }, {
      "referenceID" : 24,
      "context" : "Therefore, training data selection is widely used for domain adaptation in statistical machine translation (Zhao et al., 2004; Lü et al., 2007; Yasuda et al., 2008; Moore and Lewis, 2010; Axelrod et al., 2011; Duh et al., 2013; Axelrod et al., 2015).",
      "startOffset" : 107,
      "endOffset" : 249
    }, {
      "referenceID" : 36,
      "context" : "Therefore, training data selection is widely used for domain adaptation in statistical machine translation (Zhao et al., 2004; Lü et al., 2007; Yasuda et al., 2008; Moore and Lewis, 2010; Axelrod et al., 2011; Duh et al., 2013; Axelrod et al., 2015).",
      "startOffset" : 107,
      "endOffset" : 249
    }, {
      "referenceID" : 28,
      "context" : "Therefore, training data selection is widely used for domain adaptation in statistical machine translation (Zhao et al., 2004; Lü et al., 2007; Yasuda et al., 2008; Moore and Lewis, 2010; Axelrod et al., 2011; Duh et al., 2013; Axelrod et al., 2015).",
      "startOffset" : 107,
      "endOffset" : 249
    }, {
      "referenceID" : 0,
      "context" : "Therefore, training data selection is widely used for domain adaptation in statistical machine translation (Zhao et al., 2004; Lü et al., 2007; Yasuda et al., 2008; Moore and Lewis, 2010; Axelrod et al., 2011; Duh et al., 2013; Axelrod et al., 2015).",
      "startOffset" : 107,
      "endOffset" : 249
    }, {
      "referenceID" : 12,
      "context" : "Therefore, training data selection is widely used for domain adaptation in statistical machine translation (Zhao et al., 2004; Lü et al., 2007; Yasuda et al., 2008; Moore and Lewis, 2010; Axelrod et al., 2011; Duh et al., 2013; Axelrod et al., 2015).",
      "startOffset" : 107,
      "endOffset" : 249
    }, {
      "referenceID" : 1,
      "context" : "Therefore, training data selection is widely used for domain adaptation in statistical machine translation (Zhao et al., 2004; Lü et al., 2007; Yasuda et al., 2008; Moore and Lewis, 2010; Axelrod et al., 2011; Duh et al., 2013; Axelrod et al., 2015).",
      "startOffset" : 107,
      "endOffset" : 249
    }, {
      "referenceID" : 28,
      "context" : "The most successful data selection approaches (Moore and Lewis, 2010; Axelrod et al., 2011) train n-gram language models on in-domain text to select similar sentences from the large general-domain corpora according to the cross entropy.",
      "startOffset" : 46,
      "endOffset" : 91
    }, {
      "referenceID" : 0,
      "context" : "The most successful data selection approaches (Moore and Lewis, 2010; Axelrod et al., 2011) train n-gram language models on in-domain text to select similar sentences from the large general-domain corpora according to the cross entropy.",
      "startOffset" : 46,
      "endOffset" : 91
    }, {
      "referenceID" : 12,
      "context" : "Furthermore, (Duh et al., 2013) obtained some gains by extending these approaches from n-gram models to recurrent neural network language models (Mikolov et al.",
      "startOffset" : 13,
      "endOffset" : 31
    }, {
      "referenceID" : 26,
      "context" : ", 2013) obtained some gains by extending these approaches from n-gram models to recurrent neural network language models (Mikolov et al., 2010).",
      "startOffset" : 121,
      "endOffset" : 143
    }, {
      "referenceID" : 0,
      "context" : "In (Axelrod et al., 2011; Duh et al., 2013), the sizes of the in-domain data sets are 30K and over 100K sentences respectively.",
      "startOffset" : 3,
      "endOffset" : 43
    }, {
      "referenceID" : 12,
      "context" : "In (Axelrod et al., 2011; Duh et al., 2013), the sizes of the in-domain data sets are 30K and over 100K sentences respectively.",
      "startOffset" : 3,
      "endOffset" : 43
    }, {
      "referenceID" : 22,
      "context" : "Inspired by the success of convolutional neural networks (CNNs) applied to image and text classification (Krizhevsky et al., 2012; Kim, 2014; Johnson and Zhang, 2015a; Johnson and Zhang, 2015b), we propose to use CNN to classify training sentence pairs as in-domain or out-of-domain sentences.",
      "startOffset" : 105,
      "endOffset" : 193
    }, {
      "referenceID" : 20,
      "context" : "Inspired by the success of convolutional neural networks (CNNs) applied to image and text classification (Krizhevsky et al., 2012; Kim, 2014; Johnson and Zhang, 2015a; Johnson and Zhang, 2015b), we propose to use CNN to classify training sentence pairs as in-domain or out-of-domain sentences.",
      "startOffset" : 105,
      "endOffset" : 193
    }, {
      "referenceID" : 17,
      "context" : "Inspired by the success of convolutional neural networks (CNNs) applied to image and text classification (Krizhevsky et al., 2012; Kim, 2014; Johnson and Zhang, 2015a; Johnson and Zhang, 2015b), we propose to use CNN to classify training sentence pairs as in-domain or out-of-domain sentences.",
      "startOffset" : 105,
      "endOffset" : 193
    }, {
      "referenceID" : 18,
      "context" : "Inspired by the success of convolutional neural networks (CNNs) applied to image and text classification (Krizhevsky et al., 2012; Kim, 2014; Johnson and Zhang, 2015a; Johnson and Zhang, 2015b), we propose to use CNN to classify training sentence pairs as in-domain or out-of-domain sentences.",
      "startOffset" : 105,
      "endOffset" : 193
    }, {
      "referenceID" : 23,
      "context" : "Convolutional neural networks (CNNs) (LeCun and Bengio, 1998) are feed-forward neural networks that exploit the internal structure of data through convolution layers; each computation unit processes a small region of the input data.",
      "startOffset" : 37,
      "endOffset" : 61
    }, {
      "referenceID" : 19,
      "context" : "CNN has been gaining attention, and is now used in many text classification tasks (Kalchbrenner et al., 2014; Zeng et al., 2014; Johnson and Zhang, 2015b; Yin and Schütze, 2015; Wang et al., 2015).",
      "startOffset" : 82,
      "endOffset" : 196
    }, {
      "referenceID" : 38,
      "context" : "CNN has been gaining attention, and is now used in many text classification tasks (Kalchbrenner et al., 2014; Zeng et al., 2014; Johnson and Zhang, 2015b; Yin and Schütze, 2015; Wang et al., 2015).",
      "startOffset" : 82,
      "endOffset" : 196
    }, {
      "referenceID" : 18,
      "context" : "CNN has been gaining attention, and is now used in many text classification tasks (Kalchbrenner et al., 2014; Zeng et al., 2014; Johnson and Zhang, 2015b; Yin and Schütze, 2015; Wang et al., 2015).",
      "startOffset" : 82,
      "endOffset" : 196
    }, {
      "referenceID" : 37,
      "context" : "CNN has been gaining attention, and is now used in many text classification tasks (Kalchbrenner et al., 2014; Zeng et al., 2014; Johnson and Zhang, 2015b; Yin and Schütze, 2015; Wang et al., 2015).",
      "startOffset" : 82,
      "endOffset" : 196
    }, {
      "referenceID" : 35,
      "context" : "CNN has been gaining attention, and is now used in many text classification tasks (Kalchbrenner et al., 2014; Zeng et al., 2014; Johnson and Zhang, 2015b; Yin and Schütze, 2015; Wang et al., 2015).",
      "startOffset" : 82,
      "endOffset" : 196
    }, {
      "referenceID" : 27,
      "context" : "To compensate the limit of in-domain data size, we use word2vec (Mikolov et al., 2013) to learn the word embedding from a large amount of general-domain data.",
      "startOffset" : 64,
      "endOffset" : 86
    }, {
      "referenceID" : 34,
      "context" : "Self-training (Ueffing and Ney, 2007; Schwenk, 2008; Bertoldi and Federico, 2009) uses generaldomain bilingual parallel data and in-domain monolingual data.",
      "startOffset" : 14,
      "endOffset" : 81
    }, {
      "referenceID" : 32,
      "context" : "Self-training (Ueffing and Ney, 2007; Schwenk, 2008; Bertoldi and Federico, 2009) uses generaldomain bilingual parallel data and in-domain monolingual data.",
      "startOffset" : 14,
      "endOffset" : 81
    }, {
      "referenceID" : 3,
      "context" : "Self-training (Ueffing and Ney, 2007; Schwenk, 2008; Bertoldi and Federico, 2009) uses generaldomain bilingual parallel data and in-domain monolingual data.",
      "startOffset" : 14,
      "endOffset" : 81
    }, {
      "referenceID" : 40,
      "context" : "Some early data selection approaches (Zhao et al., 2004; Lü et al., 2007; Moore and Lewis, 2010) use in-domain monolingual data to select monolingual or bilingual data that are similar to the indomain data according to some criterion.",
      "startOffset" : 37,
      "endOffset" : 96
    }, {
      "referenceID" : 24,
      "context" : "Some early data selection approaches (Zhao et al., 2004; Lü et al., 2007; Moore and Lewis, 2010) use in-domain monolingual data to select monolingual or bilingual data that are similar to the indomain data according to some criterion.",
      "startOffset" : 37,
      "endOffset" : 96
    }, {
      "referenceID" : 28,
      "context" : "Some early data selection approaches (Zhao et al., 2004; Lü et al., 2007; Moore and Lewis, 2010) use in-domain monolingual data to select monolingual or bilingual data that are similar to the indomain data according to some criterion.",
      "startOffset" : 37,
      "endOffset" : 96
    }, {
      "referenceID" : 0,
      "context" : "By contrast, (Axelrod et al., 2011; Duh et al., 2013; Axelrod et al., 2015) search for bilingual parallel sentences using the difference in language model perplexity between two language models trained on",
      "startOffset" : 13,
      "endOffset" : 75
    }, {
      "referenceID" : 12,
      "context" : "By contrast, (Axelrod et al., 2011; Duh et al., 2013; Axelrod et al., 2015) search for bilingual parallel sentences using the difference in language model perplexity between two language models trained on",
      "startOffset" : 13,
      "endOffset" : 75
    }, {
      "referenceID" : 1,
      "context" : "By contrast, (Axelrod et al., 2011; Duh et al., 2013; Axelrod et al., 2015) search for bilingual parallel sentences using the difference in language model perplexity between two language models trained on",
      "startOffset" : 13,
      "endOffset" : 75
    }, {
      "referenceID" : 13,
      "context" : "Mixture model adaptation (Foster and Kuhn, 2007; Foster et al., 2010; Sennrich, 2012; Foster et al., 2013) assumes that the general-domain data can be clustered to several sub-corpora, with some parts that are not too far from test domain.",
      "startOffset" : 25,
      "endOffset" : 106
    }, {
      "referenceID" : 14,
      "context" : "Mixture model adaptation (Foster and Kuhn, 2007; Foster et al., 2010; Sennrich, 2012; Foster et al., 2013) assumes that the general-domain data can be clustered to several sub-corpora, with some parts that are not too far from test domain.",
      "startOffset" : 25,
      "endOffset" : 106
    }, {
      "referenceID" : 33,
      "context" : "Mixture model adaptation (Foster and Kuhn, 2007; Foster et al., 2010; Sennrich, 2012; Foster et al., 2013) assumes that the general-domain data can be clustered to several sub-corpora, with some parts that are not too far from test domain.",
      "startOffset" : 25,
      "endOffset" : 106
    }, {
      "referenceID" : 15,
      "context" : "Mixture model adaptation (Foster and Kuhn, 2007; Foster et al., 2010; Sennrich, 2012; Foster et al., 2013) assumes that the general-domain data can be clustered to several sub-corpora, with some parts that are not too far from test domain.",
      "startOffset" : 25,
      "endOffset" : 106
    }, {
      "referenceID" : 5,
      "context" : "Vector space model adaptation (Chen et al., 2013) has the same assumption, and it weights each phrase pair based on vector space model (VSM).",
      "startOffset" : 30,
      "endOffset" : 49
    }, {
      "referenceID" : 6,
      "context" : "(Chen et al., 2014) improved the VSM adaptation by extending it to distributed VSM and grouped VSM.",
      "startOffset" : 0,
      "endOffset" : 19
    }, {
      "referenceID" : 25,
      "context" : "Instance weighting adopts a rich set of features to compute weights for each instance in the training data; it can be applied to sentence pairs (Matsoukas et al., 2009) or phrase pairs (Foster et al.",
      "startOffset" : 144,
      "endOffset" : 168
    }, {
      "referenceID" : 14,
      "context" : ", 2009) or phrase pairs (Foster et al., 2010).",
      "startOffset" : 24,
      "endOffset" : 45
    }, {
      "referenceID" : 16,
      "context" : "If in-domain comparable data are available, (Daume III and Jagarlamudi, 2011; Irvine et al., 2013) propose mining translations from the comparable data to translate out-of-vocabulary (OOV) words and capture new senses for the new test domains.",
      "startOffset" : 44,
      "endOffset" : 98
    }, {
      "referenceID" : 11,
      "context" : "(Dou and Knight, 2012; Zhang and Zong, 2013) learn bilingual lexical or phrase tables from in-domain monolingual data with a decipherment method, then incorporate them into the SMT system.",
      "startOffset" : 0,
      "endOffset" : 44
    }, {
      "referenceID" : 39,
      "context" : "(Dou and Knight, 2012; Zhang and Zong, 2013) learn bilingual lexical or phrase tables from in-domain monolingual data with a decipherment method, then incorporate them into the SMT system.",
      "startOffset" : 0,
      "endOffset" : 44
    }, {
      "referenceID" : 19,
      "context" : "Recently, CNNs have shown promising results on many text classification tasks, such as sentiment analysis (Kalchbrenner et al., 2014; Kim, 2014), topic and sentiment classification (Johnson and Zhang, 2015a; Johnson and Zhang, 2015b), paraphrase identification (Yin and Schütze, 2015), entity relation type classification (Zeng et al.",
      "startOffset" : 106,
      "endOffset" : 144
    }, {
      "referenceID" : 20,
      "context" : "Recently, CNNs have shown promising results on many text classification tasks, such as sentiment analysis (Kalchbrenner et al., 2014; Kim, 2014), topic and sentiment classification (Johnson and Zhang, 2015a; Johnson and Zhang, 2015b), paraphrase identification (Yin and Schütze, 2015), entity relation type classification (Zeng et al.",
      "startOffset" : 106,
      "endOffset" : 144
    }, {
      "referenceID" : 17,
      "context" : ", 2014; Kim, 2014), topic and sentiment classification (Johnson and Zhang, 2015a; Johnson and Zhang, 2015b), paraphrase identification (Yin and Schütze, 2015), entity relation type classification (Zeng et al.",
      "startOffset" : 55,
      "endOffset" : 107
    }, {
      "referenceID" : 18,
      "context" : ", 2014; Kim, 2014), topic and sentiment classification (Johnson and Zhang, 2015a; Johnson and Zhang, 2015b), paraphrase identification (Yin and Schütze, 2015), entity relation type classification (Zeng et al.",
      "startOffset" : 55,
      "endOffset" : 107
    }, {
      "referenceID" : 37,
      "context" : ", 2014; Kim, 2014), topic and sentiment classification (Johnson and Zhang, 2015a; Johnson and Zhang, 2015b), paraphrase identification (Yin and Schütze, 2015), entity relation type classification (Zeng et al.",
      "startOffset" : 135,
      "endOffset" : 158
    }, {
      "referenceID" : 38,
      "context" : ", 2014; Kim, 2014), topic and sentiment classification (Johnson and Zhang, 2015a; Johnson and Zhang, 2015b), paraphrase identification (Yin and Schütze, 2015), entity relation type classification (Zeng et al., 2014; dos Santos et al., 2015), short-text classification (Wang et al.",
      "startOffset" : 196,
      "endOffset" : 240
    }, {
      "referenceID" : 35,
      "context" : ", 2015), short-text classification (Wang et al., 2015), event extraction and detection (Chen et al.",
      "startOffset" : 35,
      "endOffset" : 54
    }, {
      "referenceID" : 7,
      "context" : ", 2015), event extraction and detection (Chen et al., 2015; Nguyen and Grishman, 2015), question understanding and answering (Dong et al.",
      "startOffset" : 40,
      "endOffset" : 86
    }, {
      "referenceID" : 29,
      "context" : ", 2015), event extraction and detection (Chen et al., 2015; Nguyen and Grishman, 2015), question understanding and answering (Dong et al.",
      "startOffset" : 40,
      "endOffset" : 86
    }, {
      "referenceID" : 9,
      "context" : ", 2015; Nguyen and Grishman, 2015), question understanding and answering (Dong et al., 2015), and box-office prediction based on reviews (Bitvai and Cohn, 2015), etc.",
      "startOffset" : 73,
      "endOffset" : 92
    }, {
      "referenceID" : 4,
      "context" : ", 2015), and box-office prediction based on reviews (Bitvai and Cohn, 2015), etc.",
      "startOffset" : 52,
      "endOffset" : 75
    }, {
      "referenceID" : 19,
      "context" : "(Kalchbrenner et al., 2014) proposes a CNN framework with multiple convolution layers, with latent, dense and low-dimensional word embeddings as inputs.",
      "startOffset" : 0,
      "endOffset" : 27
    }, {
      "referenceID" : 20,
      "context" : "(Kim, 2014) defines a one-layer CNN architecture with comparable performance to (Kalchbrenner et al.",
      "startOffset" : 0,
      "endOffset" : 11
    }, {
      "referenceID" : 19,
      "context" : "(Kim, 2014) defines a one-layer CNN architecture with comparable performance to (Kalchbrenner et al., 2014).",
      "startOffset" : 80,
      "endOffset" : 107
    }, {
      "referenceID" : 18,
      "context" : "(Johnson and Zhang, 2015b) extends their “one-hot” CNN in (Johnson and Zhang, 2015a) to take region embeddings trained on unlabeled data as CNN input.",
      "startOffset" : 0,
      "endOffset" : 26
    }, {
      "referenceID" : 17,
      "context" : "(Johnson and Zhang, 2015b) extends their “one-hot” CNN in (Johnson and Zhang, 2015a) to take region embeddings trained on unlabeled data as CNN input.",
      "startOffset" : 58,
      "endOffset" : 84
    }, {
      "referenceID" : 27,
      "context" : "Word embeddings can be pre-trained using tools such as word2vec (Mikolov et al., 2013) or GloV e (Pennington et al.",
      "startOffset" : 64,
      "endOffset" : 86
    }, {
      "referenceID" : 31,
      "context" : ", 2013) or GloV e (Pennington et al., 2014), in which case a table lookup is enough.",
      "startOffset" : 18,
      "endOffset" : 43
    }, {
      "referenceID" : 17,
      "context" : "A CNN with one-hot vector input is called “one-hot CNN” (Johnson and Zhang, 2015a).",
      "startOffset" : 56,
      "endOffset" : 82
    }, {
      "referenceID" : 17,
      "context" : "In (Johnson and Zhang, 2015a), a CNN whose input being BOW representation is called bow-CNN while input with concatenation of vectors is called seq-CNN.",
      "startOffset" : 3,
      "endOffset" : 29
    }, {
      "referenceID" : 18,
      "context" : "To exploit large amounts of unlabeled data, we adopt a semi-supervised learning framework similar to (Johnson and Zhang, 2015b).",
      "startOffset" : 101,
      "endOffset" : 127
    }, {
      "referenceID" : 2,
      "context" : "The word embeddings map each word to a realvalued, dense vector (Bengio et al., 2003).",
      "startOffset" : 64,
      "endOffset" : 85
    }, {
      "referenceID" : 27,
      "context" : "A widely used approach for generating useful word embeddings was developed by (Mikolov et al., 2013).",
      "startOffset" : 78,
      "endOffset" : 100
    }, {
      "referenceID" : 12,
      "context" : "The other three systems are trained with data selected with different LM-based data selection methods as same as in (Duh et al., 2013)6.",
      "startOffset" : 116,
      "endOffset" : 134
    }, {
      "referenceID" : 0,
      "context" : "ngram: Data selection by 3-gram LMs with Witten-Bell 7 smoothing (Axelrod et al., 2011)",
      "startOffset" : 65,
      "endOffset" : 87
    }, {
      "referenceID" : 12,
      "context" : "rnnlm: Data selection by recurrent neural network LM, with the RNNLM Toolkit (Duh et al., 2013)",
      "startOffset" : 77,
      "endOffset" : 95
    }, {
      "referenceID" : 12,
      "context" : "comblm: Data selection by the combined LM using ngram & rnnlm (equal weight) (Duh et al., 2013).",
      "startOffset" : 77,
      "endOffset" : 95
    }, {
      "referenceID" : 30,
      "context" : "3 Experimental results We evaluated the system using BLEU (Papineni et al., 2002) score on the test set.",
      "startOffset" : 58,
      "endOffset" : 81
    }, {
      "referenceID" : 21,
      "context" : "Following (Koehn, 2004), we use the bootstrap resampling test to do significance testing.",
      "startOffset" : 10,
      "endOffset" : 23
    }, {
      "referenceID" : 12,
      "context" : "Consistent with (Duh et al., 2013), the three LM based data selection all got improvements, where “rnnlm” obtained better performance than the “ngram” on average.",
      "startOffset" : 16,
      "endOffset" : 34
    } ],
    "year" : 2016,
    "abstractText" : "In this paper, we propose a method which uses semi-supervised convolutional neural networks (CNNs) to select in-domain training data for statistical machine translation. This approach is particularly effective when only tiny amounts of in-domain data are available. The in-domain data and randomly sampled general-domain data are used to train a data selection model with semi-supervised CNN, then this model computes domain relevance scores for all the sentences in the generaldomain data set. The sentence pairs with top scores are selected to train the system. We carry out experiments on 4 language directions with three test domains. Compared with strong baseline systems trained with large amount of data, this method can improve the performance up to 3.1 BLEU. Its performances are significant better than three state-of-the-art language model based data selection methods. We also show that the in-domain data used to train the selection model could be as few as 100 sentences, which makes finegrained topic-dependent translation adaptation possible.",
    "creator" : "TeX"
  }
}