{
  "name" : "143.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : null,
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "1 000\n011\n012\n013\n014\n015\n016\n017\n018\n019\n020\n021\n022\n023\n024\n025\n026\n027\n028\n029\n030\n031\n032\n033\n034\n035\n036\n037\n038\n039\n040\n041\n042\n043\n044\n045\n046\n047\n048\n049\n061\n062\n063\n064\n065\n066\n067\n068\n069\n070\n071\n072\n073\n074\n075\n076\n077\n078\n079\n080\n081\n082\n083\n084\n085\n086\n087\n088\n089\n090\n091\n092\n093\n094\n095\n096\n097\n098\n099"
    }, {
      "heading" : "1 Introduction",
      "text" : "Vector-space representations of words are widely used in statistical models of natural language. In addition to improving the performance on standard monolingual NLP tasks, shared representation of words across languages offers intriguing possibilities (Klementiev et al., 2012). For example, in machine translation, translating a word never seen in parallel data may be overcome by seeking its vector-space neighbors, provided the embeddings are learned from both plentiful monolingual corpora and more limited parallel data. A second opportunity comes from transfer learning, in which models trained in one language can be deployed in other languages. While previous work has used hand-engineered features that are crosslinguistically stable as the basis model transfer (Zeman and Resnik, 2008; McDonald et al., 2011; Tsvetkov et al., 2014), automatically learned embeddings offer the promise of better generalization at lower cost (Klementiev et al., 2012; Hermann and Blunsom, 2014; Guo et al., 2016). We there-\nfore conjecture that developing estimation methods for massively multilingual word embeddings (i.e., embeddings for words in a large number of languages) will play an important role in the future of multilingual NLP.\nThis paper builds on previous work in multilingual embeddings and makes the following contributions:\n• We propose two dictionary-based methods— multiCluster and multiCCA—for estimating multilingual embeddings which only require monolingual data and pairwise parallel dictionaries, and use them to train embeddings in 59 languages for which these resources are available (§2). Parallel corpora are not required but can be used when available. We show that the proposed methods work well in some settings and evaluation metrics.\n• We adapt QVEC (Tsvetkov et al., 2015)1 to evaluating multilingual embeddings (multiQVEC). We also develop a new evaluation method multiQVEC-CCA which addresses a theoretical shortcoming of multiQVEC (§3). Compared to other intrinsic metrics used in the literature, we show that both multiQVEC and multiQVEC-CCA achieve better correlations with extrinsic tasks.\n• We develop an easy-to-use web portal2 for evaluating arbitrary multilingual embeddings using a suite of intrinsic and extrinsic metrics (§4). Together with the provided benchmarks, the evaluation portal will substantially facilitate future research in this area."
    }, {
      "heading" : "2 Estimating Multilingual Embeddings",
      "text" : "Let L be a set of languages, and let Vm be the set of surface forms (word types) in m ∈ L. Let\n1A method for evaluating monolingual word embeddings. 2http://128.2.220.95/multilingual\n2\n101\n102\n103\n104\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n123\n124\n125\n126\n127\n128\n129\n130\n131\n132\n133\n134\n135\n136\n137\n138\n139\n140\n141\n142\n143\n144\n145\n146\n147\n148\n149\n150\n151\n152\n153\n154\n155\n156\n157\n158\n159\n160\n161\n162\n163\n164\n165\n166\n167\n168\n169\n170\n171\n172\n173\n174\n175\n176\n177\n178\n179\n180\n181\n182\n183\n184\n185\n186\n187\n188\n189\n190\n191\n192\n193\n194\n195\n196\n197\n198\n199\nV = ⋃\nm∈L Vm. Our goal is to estimate a partial embedding function E : L × V 7→ Rd (allowing a surface form that appears in two languages to have different vectors in each). We would like to estimate this function such that: (i) semantically similar words in the same language are nearby, (ii) translationally equivalent words in different languages are nearby, and (iii) the domain of the function covers as many words in V as possible.\nWe use distributional similarity in a monolingual corpus Mm to model semantic similarity between words in the same language. For crosslingual similarity, either a parallel corpus Pm,n or a bilingual dictionary Dm,n ⊂ Vm ×Vn can be used. Our methods focus on the latter, in some cases extracting Dm,n from a parallel corpus.3\nMost previous work on multilingual embeddings only considered the bilingual case, | L |= 2. We focus on estimating multilingual embeddings for | L |> 2 and describe two novel dictionarybased methods (multiCluster and multiCCA). We then describe our baselines: a variant of Coulmance et al. (2015) and Guo et al. (2016) (henceforth referred to as multiSkip),4 and the translation-invariance matrix factorization method (Gardner et al., 2015)."
    }, {
      "heading" : "2.1 MultiCluster",
      "text" : "In this approach, we decompose the problem into two simpler subproblems: E = Eembed ◦ Ecluster, where Ecluster : L×V 7→ C deterministically maps words to multilingual clusters C, and Eembed : C → Rd assigns a vector to each cluster. We use a bilingual dictionary to find clusters of translationally equivalent words, then use distributional similarities of the clusters in monolingual corpora from all languages in L to estimate an embedding for each cluster. By forcing words from different languages in a cluster to share the same embedding, we create anchor points in the vector space to bridge languages.\nMore specifically, we define the clusters as the\n3To do this, we align the corpus using fast align (Dyer et al., 2013) in both directions. The estimated parameters of the word translation distributions are used to select pairs: Dm,n ={ (u, v) | u ∈ Vm, v ∈ Vn, pm|n(u | v)× pn|m(v | u) > τ } , where the threshold τ trades off dictionary recall and precision. We fixed τ = 0.1 early on based on manual inspection of the resulting dictionaries.\n4We developed multiSkip independently of Coulmance et al. (2015) and Guo et al. (2016). One important distinction is that multiSkip is only trained on parallel corpora, while Coulmance et al. (2015) and Guo et al. (2016) also use monolingual corpora.\nconnected components in a graph where nodes are (language, surface form) pairs and edges correspond to translation entries in Dm,n. We assign arbitrary IDs to the clusters and replace each word token in each monolingual corpus with the corresponding cluster ID, and concatenate all modified corpora. The resulting corpus consists of multilingual cluster ID sequences. We can then apply any monolingual embedding estimator; here, we use the skipgram model from Mikolov et al. (2013a)."
    }, {
      "heading" : "2.2 MultiCCA",
      "text" : "Our proposed method (multiCCA) extends the bilingual embeddings of Faruqui and Dyer (2014). First, they use monolingual corpora to train monolingual embeddings for each language independently (Em and En), capturing semantic similarity within each language separately. Then, using a bilingual dictionary Dm,n, they use canonical correlation analysis (CCA) to estimate linear projections from the ranges of the monolingual embeddings Em and En, yielding a bilingual embedding Em,n. The linear projections are defined by Tm→m,n and Tn→m,n ∈ Rd×d; they are selected to maximize the correlation between Tm→m,nEm(u) and Tn→m,nEn(v) where (u, v) ∈ Dm,n. The bilingual embedding is then defined as ECCA(m, u) = Tm→m,nEm(u) (and likewise for ECCA(n, v)).\nIn this work, we use a simple extension (in hindsight) to construct multilingual embeddings for more languages. We let the vector space of the initial (monolingual) English embeddings serve as the multilingual vector space (since English typically offers the largest corpora and wide availability of bilingual dictionaries). We then estimate projections from the monolingual embeddings of the other languages into the English space.\nWe start by estimating, for each m ∈ L \\ {en}, the two projection matrices: Tm→m,en and Ten→m,en; these are guaranteed to be non-singular. We then define the multilingual embedding as ECCA(en, u) = Een(u) for u ∈ Ven, and ECCA(m, v) = T−1en→m,enTm→m,enE\nm(v) for v ∈ Vm,m ∈ L \\ {en}."
    }, {
      "heading" : "2.3 MultiSkip",
      "text" : "Luong et al. (2015b) proposed a method for estimating bilingual embeddings which only makes use of parallel data; it extends the skipgram model of Mikolov et al. (2013a). The skipgram model defines a distribution over words u that occur in a\n3\n201\n202\n203\n204\n205\n206\n207\n208\n209\n210\n211\n212\n213\n214\n215\n216\n217\n218\n219\n220\n221\n222\n223\n224\n225\n226\n227\n228\n229\n230\n231\n232\n233\n234\n235\n236\n237\n238\n239\n240\n241\n242\n243\n244\n245\n246\n247\n248\n249\n250\n251\n252\n253\n254\n255\n256\n257\n258\n259\n260\n261\n262\n263\n264\n265\n266\n267\n268\n269\n270\n271\n272\n273\n274\n275\n276\n277\n278\n279\n280\n281\n282\n283\n284\n285\n286\n287\n288\n289\n290\n291\n292\n293\n294\n295\n296\n297\n298\n299\ncontext window (of size K) of a word v:\np(u | v) = expEskipgram(m, v)>Econtext(m, u)∑\nu′∈Vm expEskipgram(m, v)>Econtext(m, u′)\nIn practice, this distribution can be estimated using a noise contrastive estimation approximation (Gutmann and Hyvärinen, 2012) while maximizing the log-likelihood:∑\ni∈pos(Mm) ∑ k∈{−K,...,−1,1,...,K} log p(ui+k | ui)\nwhere pos(Mm) are the indices of words in the monolingual corpus Mm.\nTo establish a bilingual embedding, with a parallel corpus Pm,n of source language m and target language n, Luong et al. (2015b) estimate conditional models of words in both source and target positions. The source positions are selected as sentential contexts (similar to monolingual skipgram), and the bilingual contexts come from aligned words. The bilingual objective is to maximize:∑ i∈m-pos(Pm,n) ∑ k∈{−K,...,−1,1,...,K} log p(ui+k | ui) + log p(va(i)+k | ui)\n+ ∑\nj∈n-pos(Pm,n) ∑ k∈{−K,...,−1,1,...,K} log p(vj+k | vj) + log p(ua(j)+k | vj)\nwhere m-pos(Pm,n) and n-pos(Pm,n) are the indeces of the source and target tokens in the parallel corpus respectively, a(i) and a(j) are the positions of words that align to i and j in the other language. It is easy to see how this method can be extended for more than two languages by summing up the bilingual objectives for all available parallel corpora."
    }, {
      "heading" : "2.4 Translation-invariance",
      "text" : "Gardner et al. (2015) proposed that multilingual embeddings should be translation invariant. Consider a matrix X ∈ R|V|×|V| which summarizes the pointwise mutual information statistics between pairs of words in monolingual corpora, and let UV> be a low-rank decomposition of X where U,V ∈ R|V|×d. Now, consider another matrix A ∈ R|V|×|V| which summarizes bilingual alignment frequencies in a parallel corpus. Gardner et al. (2015) solves for a low-rank decomposition UV> which both approximates X as well as its\ntransformations A>X, XA and A>XA by defining the following objective:\nminU,V ‖X − UV >‖2 + ‖XA− UV>‖2 + ‖A>X − UV>‖2 + ‖A>XA− UV>‖2\nThe multilingual embeddings are then taken to be the rows of the matrix U."
    }, {
      "heading" : "3 Evaluating Multilingual Embeddings",
      "text" : "One of our contributions is to streamline the evaluation of multilingual embeddings. In addition to assessing goals (i–iii) stated in §2, a good evaluation metric should also (iv) show good correlation with performance in downstream applications and (v) be computationally efficient.\nIt is easy to evaluate the coverage (iii) by counting the number of words covered by an embedding function in a closed vocabulary. Intrinsic evaluation metrics are generally designed to be computationally efficient (v) but may or may not meet the goals (i, ii, iv). Although intrinsic evaluations will never be perfect, a standard set of evaluation metrics will help drive research. By design, standard (monolingual) word similarity tasks meet (i) while cross-lingual word similarity tasks and the word translation tasks meet (ii). We propose another evaluation method (multiQVEC-CCA), designed to simultaneously assess goals (i, ii). MultiQVECCCA extends QVEC (Tsvetkov et al., 2015), a recently proposed monolingual evaluation method, addressing fundamental flaws and extending it to multiple languages. To assess the degree to which these evaluation metrics meet (iv), in §5 we perform a correlation analysis looking at which intrinsic metrics are best correlated with downstream task performance—i.e., we evaluate the evaluation metrics."
    }, {
      "heading" : "3.1 Word similarity",
      "text" : "Word similarity datasets such as WordSim-353 (Agirre et al., 2009) and MEN (Bruni et al., 2014) provide human judgments of semantic similarity. By ranking words by cosine similarity and by their empirical similarity judgments, a ranking correlation can be computed that assesses how well the estimated vectors capture human intuitions about semantic relatedness.\nSome previous work on bilingual and multilingual embeddings focuses on monolingual word similarity to evaluate embeddings (e.g., Faruqui and Dyer, 2014). This approach is limited because\n4\n301\n302\n303\n304\n305\n306\n307\n308\n309\n310\n311\n312\n313\n314\n315\n316\n317\n318\n319\n320\n321\n322\n323\n324\n325\n326\n327\n328\n329\n330\n331\n332\n333\n334\n335\n336\n337\n338\n339\n340\n341\n342\n343\n344\n345\n346\n347\n348\n349\n350\n351\n352\n353\n354\n355\n356\n357\n358\n359\n360\n361\n362\n363\n364\n365\n366\n367\n368\n369\n370\n371\n372\n373\n374\n375\n376\n377\n378\n379\n380\n381\n382\n383\n384\n385\n386\n387\n388\n389\n390\n391\n392\n393\n394\n395\n396\n397\n398\n399\nit cannot measure the degree to which embeddings from different languages are similar (ii). For this paper, we report results on an English word similarity task, the Stanford RW dataset (Luong et al., 2013), as well as a combination of several cross-lingual word similarity datasets (CamachoCollados et al., 2015)."
    }, {
      "heading" : "3.2 Word translation",
      "text" : "This task directly assesses the degree to which translationally equivalent words in different languages are nearby in the embedding space. The evaluation data consists of word pairs which are known to be translationally equivalent. The score for one word pair (l1,w1), (l2,w2) both of which are covered by an embedding E is 1 if cosine(E(l1,w1),E(l2,w2)) ≥ cosine(E(l1,w1),E(l2,w′2))∀w′2 ∈ Gl2 where Gl2 is the set of words of language l2 in the evaluation dataset, and cosine is the cosine similarity function. Otherwise, the score for this word pair is 0. The overall score is the average score for all word pairs covered by the embedding function. This is a variant of the method used by Mikolov et al. (2013b) to evaluate bilingual embeddings."
    }, {
      "heading" : "3.3 Correlation-based evaluation",
      "text" : "We introduce QVEC-CCA—an intrinsic evaluation measure of the quality of word embeddings. Our method is an improvement of QVEC—a monolingual evaluation based on alignment of embeddings to a matrix of features extracted from a linguistic resource (Tsvetkov et al., 2015). We review QVEC, and then describe QVEC-CCA.\nQVEC. The main idea behind QVEC is to quantify the linguistic content of word embeddings by maximizing the correlation with a manuallyannotated linguistic resource. Let the number of common words in the vocabulary of the word embeddings and the linguistic resource be N. To quantify the semantic content of embeddings, a semantic linguistic matrix S ∈ RP×N is constructed from a semantic database, with a column vector for each word. Each word vector is a distribution of the word over P linguistic properties, based on annotations of the word in the database. Let X ∈ RD×N be embedding matrix with every row as a dimension vector x ∈ R1×N . D denotes the dimensionality of word embeddings. Then, S and X are aligned to maximize the cumulative correlation between the aligned dimensions of the two\nmatrices. Specifically, let A ∈ {0, 1}D×P be a matrix of alignments such that aij = 1 iff xi is aligned to sj, otherwise aij = 0. If r(xi, sj) is the Pearson’s correlation between vectors xi and sj, then QVEC is defined as:\nQVEC = maxA:∑j aij≤1 X∑\ni=1 S∑ j=1 r(xi, sj)× aij\nThe constraint ∑\nj aij ≤ 1, warrants that one distributional dimension is aligned to at most one linguistic dimension.\nQVEC has been shown to correlate strongly with downstream semantic tasks (Tsvetkov et al., 2015). However, it suffers from two major weaknesses. First, it is not invariant to linear transformations of the embeddings’ basis, whereas the bases in word embeddings are generally arbitrary (Szegedy et al., 2014). Second, a sum of correlations produces an unnormalized score: the more dimensions in the embedding matrix the higher the score. This precludes comparison of models of different dimensionality. QVEC-CCA simultaneously addresses both problems.\nQVEC-CCA. To measure correlation between the embedding matrix X and the linguistic matrix S, instead of cumulative dimension-wise correlation we employ CCA. CCA finds two sets of basis vectors, one for X> and the other for S>, such that the correlations between the projections of the matrices onto these basis vectors are maximized. Formally, CCA finds a pair of basis vectors v and w such that\nQVEC-CCA = CCA(X>,S>)\n= maxv,w r(X >v,S>w)\nThus, QVEC-CCA ensures invariance to the matrices bases rotation, and since it is a single correlation, it produces a score in [−1, 1]. Both QVEC and QVEC-CCA rely on a matrix of linguistic properties constructed from a manually crafted linguistic resource. We extend both methods to multilingual evaluations—multiQVEC and multiQVECCCA—by constructing the linguistic matrix using supersense tag annotations for English (Miller et al., 1993), Danish (Martı́nez Alonso et al., 2015; Martı́nez Alonso et al., 2016) and Italian (Montemagni et al., 2003)."
    }, {
      "heading" : "3.4 Extrinsic tasks",
      "text" : "In order to evaluate how useful the word embeddings are for a downstream task, we use the em-\n5\n401\n402\n403\n404\n405\n406\n407\n408\n409\n410\n411\n412\n413\n414\n415\n416\n417\n418\n419\n420\n421\n422\n423\n424\n425\n426\n427\n428\n429\n430\n431\n432\n433\n434\n435\n436\n437\n438\n439\n440\n441\n442\n443\n444\n445\n446\n447\n448\n449\n450\n451\n452\n453\n454\n455\n456\n457\n458\n459\n460\n461\n462\n463\n464\n465\n466\n467\n468\n469\n470\n471\n472\n473\n474\n475\n476\n477\n478\n479\n480\n481\n482\n483\n484\n485\n486\n487\n488\n489\n490\n491\n492\n493\n494\n495\n496\n497\n498\n499\nbedding vector as a dense feature representation of each word in the input, and deliberately remove any other feature available for this word (e.g., prefixes, suffixes, part-of-speech). For each task, we train one model on the aggregate training data available for several languages, and evaluate on the aggregate evaluation data in the same set of languages. We apply this for multilingual document classification and multilingual dependency parsing.\nFor document classification, we follow Klementiev et al. (2012) in using the RCV corpus of newswire text, and train a classifier which differentiates between four topics. While most previous work used this data only in a bilingual setup, we simultaneously train the classifier on documents in seven languages,5 and evaluate on the development/test section of those languages. For this task, we report the average classification accuracy on the test set.\nFor dependency parsing, we train the stackLSTM parser of Dyer et al. (2015) on a subset of the languages in the universal dependencies v1.1,6 and test on the same languages, reporting unlabeled attachment scores. We remove all part-ofspeech and morphology features from the data, and prevent the model from optimizing the word embeddings used to represent each word in the corpus, thereby forcing the parser to rely completely on the provided (pretrained) embeddings as the token representation. Although omitting other features (e.g., parts of speech) hurts the performance of the parser, it emphasizes the contribution of the word embeddings being studied."
    }, {
      "heading" : "4 Evaluation Portal",
      "text" : "In order to facilitate future research on multilingual word embeddings, we developed a web portal to enable researchers who develop new estimation methods to evaluate them using a suite of evaluation tasks. The portal serves the following purposes:\n• Download the monolingual and bilingual data we used to estimate multilingual embeddings in this paper,\n• Download standard development/test data sets for each of the evaluation metrics to help re-\n5Danish, German, English, Spanish, French, Italian and Swedish.\n6http://hdl.handle.net/11234/LRT-1478\nsearchers working in this area report trustworthy and replicable results,7\n• Upload arbitrary multilingual embeddings, scan which languages are covered by the embeddings, allow the user to pick among the compatible evaluation tasks, and receive evaluation scores for the selected tasks, and\n• Register a new evaluation data set or a new evaluation metric via the github repository which mirrors the backend of the web portal."
    }, {
      "heading" : "5 Experiments",
      "text" : "Our experiments are designed to show two primary sets of results: (i) how well the proposed intrinsic evaluation metrics correlate with downstream tasks (§5.1) and (ii) which estimation methods work best according to each metric (§5.2). The data used for training and evaluation are available for download on the evaluation portal."
    }, {
      "heading" : "5.1 Correlations between intrinsic vs. extrinsic evaluation metrics",
      "text" : "In this experiment, we consider four intrinsic evaluation metrics (cross-lingual word similarity, word translation, multiQVEC and multiQVECCCA) and two extrinsic evaluation metrics (multilingual document classification and multilingual parsing).\nData: For the cross-lingual word similarity task, we use disjoint subsets of the en-it MWS353 dataset (Leviant and Reichart, 2015) for development (308 word pairs) and testing (307 word pairs). For the word translation task, we use Wiktionary to extract a development set (647 translations) and a test set (647 translations) of translationally-equivalent word pairs in en-it, enda and da-it. For both multiQVEC and multiQVECCCA, we used disjoint subsets of the multilingual (en, da, it) supersense tag annotations described in §3 for development (12,513 types) and testing (12,512 types).\nFor the document classification task, we use the multilingual RCV corpus (en, it, da). For the dependency parsing task, we use the universal dependencies v1.1 (Agić et al., 2015) in three languages (en, da, it).\n7Except for the original RCV documents, which are restricted by the Reuters license and cannot be republished. All other data is available for download.\n6\n501\n502\n503\n504\n505\n506\n507\n508\n509\n510\n511\n512\n513\n514\n515\n516\n517\n518\n519\n520\n521\n522\n523\n524\n525\n526\n527\n528\n529\n530\n531\n532\n533\n534\n535\n536\n537\n538\n539\n540\n541\n542\n543\n544\n545\n546\n547\n548\n549\n561\n562\n563\n564\n565\n566\n567\n568\n569\n570\n571\n572\n573\n574\n575\n576\n577\n578\n579\n580\n581\n582\n583\n584\n585\n586\n587\n588\n589\n590\n591\n592\n593\n594\n595\n596\n597\n598\n599\n(→) extrinsic task document dependency (↓) intrinsic metric classification parsing\nword similarity 0.386 0.007 word translation 0.066 -0.292 multiQVEC 0.635 0.444 multiQVEC-CCA 0.896 0.273\nTable 1: Correlations between intrinsic evaluation metrics (rows) and downstream task performance (columns).\nSetup: To estimate correlations between the proposed intrinsic evaluation metrics and downstream task performance, we train a total of 17 different multilingual embeddings for three languages (English, Italian and Danish). To compute the correlations, we evaluate each of the 17 embeddings (12 multiCluster embeddings, 1 multiCCA embeddings, 1 multiSkip embeddings, 2 translation-invariance embeddings) according to each of the six evaluation metrics (4 intrinsic, 2 extrinsic).8\nResults: Table 1 shows Pearson’s correlation coefficients of eight (intrinsic metric, extrinsic metric) pairs. Although each of two proposed methods multiQVEC and multiQVEC-CCA correlate better with a different extrinsic task, we establish (i) that intrinsic methods previously used in the literature (cross-lingual word similarity and word translation) correlate poorly with downstream tasks, and (ii) that the intrinsic methods proposed in this paper (multiQVEC and multiQVEC-CCA) correlate better with both downstream tasks, compared to cross-lingual word similarity and word translation.9"
    }, {
      "heading" : "5.2 Evaluating multilingual estimation methods",
      "text" : "We now turn to evaluating the four estimation methods described in §2. We use the proposed methods (i.e., multiCluster and multiCCA) to\n8The 102 (17 × 6) values used to compute Pearson’s correlation coefficient are provided in the supplementary material.\n9Although supersense annotations exist for other languages, the annotations are inconsistent across languages and may not be publicly available, which is a disadvantage of the multiQVEC and multiQVEC-CCA metrics. Therefore, we recommend that future multilingual supersense annotation efforts use the same set of supersense tags used in other languages. If the word embeddings are primarily needed for encoding syntactic information, one could use tag dictionaries based on the universal POS tag set (Petrov et al., 2012) instead of supersense tags.\ntrain multilingual embeddings in 59 languages for which bilingual translation dictionaries are available.10 In order to compare our methods to baselines which use parallel data (i.e., multiSkip and translation-invariance), we also train multilingual embeddings in a smaller set of 12 languages for which high-quality parallel data are available.11\nTraining data: We use Europarl en-xx parallel data for the set of 12 languages. We obtain en-xx bilingual dictionaries from two different sources. For the set of 12 languages, we extract the bilingual dictionaries from the Europarl parallel corpora. For the remaining 47 languages, dictionaries were formed by translating the 20k most common words in the English monolingual corpus with Google Translate, ignoring translation pairs with identical surface forms and multi-word translations.\nEvaluation data: Monolingual word similarity uses the MEN dataset in Bruni et al. (2014) as a development set and Stanford’s Rare Words dataset in Luong et al. (2013) as a test set. For the crosslingual word similarity task, we aggregate the RG65 datasets in six language pairs (fr-es, fr-de, enfr, en-es, en-de, de-es). For the word translation\n10The 59-language set is { bg, cs, da, de, el, en, es, fi, fr, hu, it, sv, zh, af, ca, iw, cy, ar, ga, zu, et, gl, id, ru, nl, pt, la, tr, ne, lv, lt, tg, ro, is, pl, yi, be, hy, hr, jw, ka, ht, fa, mi, bs, ja, mg, tl, ms, uz, kk, sr, mn, ko, mk, so, uk, sl, sw }.\n11The 12-language set is {bg, cs, da, de, el, en, es, fi, fr, hu, it, sv}.\n7\n601\n602\n603\n604\n605\n606\n607\n608\n609\n610\n611\n612\n613\n614\n615\n616\n617\n618\n619\n620\n621\n622\n623\n624\n625\n626\n627\n628\n629\n630\n631\n632\n633\n634\n635\n636\n637\n638\n639\n640\n641\n642\n643\n644\n645\n646\n647\n648\n649\n650\n651\n652\n653\n654\n655\n656\n657\n658\n659\n660\n661\n662\n663\n664\n665\n666\n667\n668\n669\n670\n671\n672\n673\n674\n675\n676\n677\n678\n679\n680\n681\n682\n683\n684\n685\n686\n687\n688\n689\n690\n691\n692\n693\n694\n695\n696\n697\n698\n699\ntask, we use Wiktionary to extract translationallyequivalent word pairs to evaluate multilingual embeddings for the set of 12 languages. Since Wiktionary-based translations do not cover all 59 languages, we use Google Translate to obtain enxx bilingual dictionaries to evaluate the embeddings of 59 languages. For QVEC and QVEC-CCA, we split the English supersense annotations used in Tsvetkov et al. (2015) into a development set and a test set. For multiQVEC and multiQVECCCA, we use supersense annotations in English, Italian and Danish. For the document classification task, we use the multilingual RCV corpus in seven languages (da, de, en, es, fr, it, sv). For the dependency parsing task, we use the universal dependencies v1.1 in twelve languages (bg, cs, da, de, el, en, es, fi, fr, hu, it, sv).\nSetup: All word embeddings in the following results are 512-dimensional vectors. Methods which indirectly use skipgram (i.e., multiCCA, multiSkip, and multiCluster) are trained using 10 epochs of stochastic gradient descent, and use a context window of size 5. The translation-invariance method use a context window of size 3.12 We only estimate embeddings for words/clusters which occur 5 times or more in the monolingual corpora. In a postprocessing step, all vectors are normalized to unit length. MultiCluster uses a maximum cluster size of 1,000 and 10,000 for the set of 12 and 59 languages, respectively. In the English tasks (monolingual word similarity, QVEC, QVEC-CCA), skipgram embeddings (Mikolov et al., 2013a) and multiCCA embeddings give identical results (since we project words in other languages to the English vector space, estimated using the skipgram model). The software used to train all embeddings as well as the trained embeddings are available for download on the evaluation portal.13\nWe note that intrinsic evaluation of word embeddings (e.g., word similarity) typically ignores test instances which are not covered by the embeddings being studied. When the vocabulary used in two sets of word embeddings is different, which is often the case, the intrinsic evaluation score for each set may be computed based on a different set\n12Training translation-invariance embeddings with larger context window sizes using the matlab implementation provided by Gardner et al. (2015) is computationally challenging.\n13URLs to software libraries on Github are redacted to comply with the double-blind reviewing of CoNLL.\nof test instances, which may bias the results in unexpected ways. For instance, if one set of embeddings only covers frequent words while the other set also covers infrequent words, the scores of the first set may be inflated because frequent words appear in many different contexts and are therefore easier to estimate than infrequent words. To partially address this problem, we report the coverage of each set of embeddings in square brackets. When the difference in coverage is large, we repeat the evaluation using only the intersection of vocabularies covered by all embeddings being evaluated. Extrinsic evaluations are immune to this problem because the score is computed based on all test instances regardless of the coverage.\nResults [59 languages]. We train the proposed dictionary-based estimation methods (multiCluster and multiCCA) for 59 languages, and evaluate the trained embeddings according to nine different metrics in Table 2. The results show that, when trained on a large number of languages, multiCCA consistently outperforms multiCluster according to all evaluation metrics. Note that most differences in coverage between multiCluster and multiCCA are relatively small.\nIt is worth noting that the mainstream approach of estimating one vector representation per word type (rather than word token) ignores the fact that the same word may have different semantics in different contexts. The multiCluster method exacerbates this problem by estimating one vector representation per cluster of translationally equivalent words. The added semantic ambiguity severely hurts the performance of multiCluster with 59 languages, but it is still competitive with 12 languages (see below).\nResults on [12 languages]. We compare the proposed dictionary-based estimation methods to parallel text-based methods in Table 3. The ranking of the four estimation methods is not consistent across all evaluation metrics. This is unsurprising since each metric evaluates different traits of word embeddings, as detailed in §3. However, some patterns are worth noting in Table 3.\nIn five of the evaluations (including both extrinsic tasks), the best performing method is a dictionary-based one proposed in this paper. In the remaining four intrinsic methods, the best performing method is the translation-invariance method. MultiSkip ranks last in five evaluations,\n8\n701\n702\n703\n704\n705\n706\n707\n708\n709\n710\n711\n712\n713\n714\n715\n716\n717\n718\n719\n720\n721\n722\n723\n724\n725\n726\n727\n728\n729\n730\n731\n732\n733\n734\n735\n736\n737\n738\n739\n740\n741\n742\n743\n744\n745\n746\n747\n748\n749\n750\n751\n752\n753\n754\n755\n756\n757\n758\n759\n760\n761\n762\n763\n764\n765\n766\n767\n768\n769\n770\n771\n772\n773\n774\n775\n776\n777\n778\n779\n780\n781\n782\n783\n784\n785\n786\n787\n788\n789\n790\n791\n792\n793\n794\n795\n796\n797\n798\n799\nTask multiCluster multiCCA multiSkip invariance extrinsic metrics dependency parsing 61.0 [70.9] 58.7 [69.3] 57.7 [68.9] 59.8 [68.6] document classification 92.1 [48.1] 92.1 [62.8] 90.4 [45.7] 91.1 [31.3]\nintrinsic metrics\nmonolingual word similarity 38.0 [57.5] 43.0 [71.0] 33.9 [55.4] 51.0 [23.0] multilingual word similarity 58.1 [74.1] 66.6 [78.2] 59.5 [67.5] 58.7 [63.0]\nword translation 43.7 [45.2] 35.7 [53.2] 46.7 [39.5] 63.9 [30.3] monolingual QVEC 10.3 [98.6] 10.7 [99.0] 8.4 [98.0] 8.1 [91.7]\nmultiQVEC 9.3 [82.0] 8.7 [87.0] 8.7 [87.0] 5.3 [74.7] monolingual QVEC-CCA 62.4 [98.6] 63.4 [99.0] 58.9 [98.0] 65.8 [91.7]\nmultiQVEC-CCA 43.3 [82.0] 41.5 [87.0] 36.3 [75.6] 46.2 [74.7]\nTable 3: Results for multilingual embeddings that cover Bulgarian, Czech, Danish, Greek, English, Spanish, German, Finnish, French, Hungarian, Italian and Swedish. Each row corresponds to one of the embedding evaluation metrics we use (higher is better). Each column corresponds to one of the embedding estimation methods we consider; i.e., numbers in the same row are comparable. Numbers in square brackets are coverage percentages.\nand never ranks first. Since our implementation of multiSkip does not make use of monolingual data, it only learns from monolingual contexts observed in parallel corpora, it misses the opportunity to learn from contexts in the much larger monolingual corpora. Trained for 12 languages, multiCluster is competitive in four evaluations (and ranks first in three).\nWe note that multiCCA consistently achieves better coverage than the translation-invariance method. For intrinsic measures, this confounds the performance comparison. A partial solution is to test only on word types for which all four methods have a vector; this subset is in no sense a representative sample of the vocabulary. In this comparison (provided in the supplementary material), we find a similar pattern of results, though multiCCA outperforms the translation-invariance method on the monolingual word similarity task. Also, the gap (between multiCCA and the translationinvariance method) reduces to 0.7 in monolingual QVEC-CCA and 2.5 in multiQVEC-CCA."
    }, {
      "heading" : "6 Related Work",
      "text" : "There is a rich body of literature on bilingual embeddings, including work on machine translation (Zou et al., 2013; Hermann and Blunsom, 2014; Cho et al., 2014; Luong et al., 2015b; Luong et al., 2015a, inter alia),14 cross-lingual dependency parsing (Guo et al., 2015; Guo et al., 2016), and cross-lingual document classification (Klementiev\n14Hermann and Blunsom (2014) showed that the bicvm method can be extended to more than two languages, but the released software library only supports bilingual embeddings.\net al., 2012; Gouws et al., 2014; Kociskỳ et al., 2014). Al-Rfou’ et al. (2013) trained word embeddings for more than 100 languages, but the embeddings of each language are trained independently (i.e., embeddings of words in different languages do not share the same vector space). Word clusters are a related form of distributional representation; in clustering, cross-lingual distributional representations were proposed as well (Och, 1999; Täckström et al., 2012). Haghighi et al. (2008) used CCA to learn bilingual lexicons from monolingual corpora."
    }, {
      "heading" : "7 Conclusion",
      "text" : "We proposed two dictionary-based estimation methods for multilingual word embeddings, multiCCA and multiCluster, and used them to train embeddings for 59 languages. We characterized important shortcomings of the QVEC previously used to evaluate monolingual embeddings, and proposed an improved metric multiQVEC-CCA. Both multiQVEC and multiQVEC-CCA obtain better correlations with downstream tasks compared to intrinsic methods previously used in the literature. Finally, in order to help future research in this area, we created a web portal for users to upload their multilingual embeddings and easily evaluate them on nine evaluation metrics, with two modes of operation (development and test) to encourage sound experimentation practices."
    } ],
    "references" : [ {
      "title" : "Universal dependencies 1.1. LINDAT/CLARIN digital library at Institute of Formal and Applied Linguistics, Charles University in Prague",
      "author" : [ "Vincze", "Daniel Zeman" ],
      "venue" : null,
      "citeRegEx" : "Vincze and Zeman.,? \\Q2015\\E",
      "shortCiteRegEx" : "Vincze and Zeman.",
      "year" : 2015
    }, {
      "title" : "A study on similarity and relatedness using distributional and WordNet-based approaches",
      "author" : [ "Eneko Agirre", "Enrique Alfonseca", "Keith Hall", "Jana Kravalova", "Marius Paşca", "Aitor Soroa." ],
      "venue" : "Proc. of NAACL, pages 19–27.",
      "citeRegEx" : "Agirre et al\\.,? 2009",
      "shortCiteRegEx" : "Agirre et al\\.",
      "year" : 2009
    }, {
      "title" : "Polyglot: Distributed word representations for multilingual nlp",
      "author" : [ "Rami Al-Rfou", "Bryan Perozzi", "Steven Skiena" ],
      "venue" : "CONLL",
      "citeRegEx" : "Al.Rfou. et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Al.Rfou. et al\\.",
      "year" : 2013
    }, {
      "title" : "Multimodal distributional semantics",
      "author" : [ "Elia Bruni", "Nam-Khanh Tran", "Marco Baroni." ],
      "venue" : "JAIR.",
      "citeRegEx" : "Bruni et al\\.,? 2014",
      "shortCiteRegEx" : "Bruni et al\\.",
      "year" : 2014
    }, {
      "title" : "A framework for the construction of monolingual and cross-lingual word similarity datasets",
      "author" : [ "José Camacho-Collados", "Mohammad Taher Pilehvar", "Roberto Navigli." ],
      "venue" : "Proc. of ACL.",
      "citeRegEx" : "Camacho.Collados et al\\.,? 2015",
      "shortCiteRegEx" : "Camacho.Collados et al\\.",
      "year" : 2015
    }, {
      "title" : "Learning phrase representations using rnn encoder-decoder for statistical machine translation",
      "author" : [ "Kyunghyun Cho", "Bart Van Merriënboer", "Caglar Gulcehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio." ],
      "venue" : "Proc. of",
      "citeRegEx" : "Cho et al\\.,? 2014",
      "shortCiteRegEx" : "Cho et al\\.",
      "year" : 2014
    }, {
      "title" : "Transgram, fast cross-lingual word-embeddings",
      "author" : [ "Jocelyn Coulmance", "Jean-Marc Marty", "Guillaume Wenzek", "Amine Benhalloum." ],
      "venue" : "Proc. of EMNLP.",
      "citeRegEx" : "Coulmance et al\\.,? 2015",
      "shortCiteRegEx" : "Coulmance et al\\.",
      "year" : 2015
    }, {
      "title" : "A simple, fast, and effective reparameterization of IBM Model 2",
      "author" : [ "Chris Dyer", "Victor Chahuneau", "Noah A. Smith." ],
      "venue" : "Proc. of NAACL.",
      "citeRegEx" : "Dyer et al\\.,? 2013",
      "shortCiteRegEx" : "Dyer et al\\.",
      "year" : 2013
    }, {
      "title" : "Transitionbased dependency parsing with stack long shortterm memory",
      "author" : [ "Chris Dyer", "Miguel Ballesteros", "Wang Ling", "Austin Matthews", "Noah A Smith." ],
      "venue" : "Proc. of ACL.",
      "citeRegEx" : "Dyer et al\\.,? 2015",
      "shortCiteRegEx" : "Dyer et al\\.",
      "year" : 2015
    }, {
      "title" : "Improving vector space word representations using multilingual correlation",
      "author" : [ "Manaal Faruqui", "Chris Dyer." ],
      "venue" : "Proc. of EACL.",
      "citeRegEx" : "Faruqui and Dyer.,? 2014",
      "shortCiteRegEx" : "Faruqui and Dyer.",
      "year" : 2014
    }, {
      "title" : "Translation invariant word embeddings",
      "author" : [ "Matt Gardner", "Kejun Huang", "Evangelos Papalexakis", "Xiao Fu", "Partha Talukdar", "Christos Faloutsos", "Nicholas Sidiropoulos", "Tom Mitchell." ],
      "venue" : "Proc. of EMNLP.",
      "citeRegEx" : "Gardner et al\\.,? 2015",
      "shortCiteRegEx" : "Gardner et al\\.",
      "year" : 2015
    }, {
      "title" : "Bilbowa: Fast bilingual distributed representations without word alignments",
      "author" : [ "Stephan Gouws", "Yoshua Bengio", "Greg Corrado." ],
      "venue" : "arXiv preprint arXiv:1410.2455.",
      "citeRegEx" : "Gouws et al\\.,? 2014",
      "shortCiteRegEx" : "Gouws et al\\.",
      "year" : 2014
    }, {
      "title" : "Cross-lingual dependency parsing based on distributed representations",
      "author" : [ "Jiang Guo", "Wanxiang Che", "David Yarowsky", "Haifeng Wang", "Ting Liu." ],
      "venue" : "Proc. of ACL.",
      "citeRegEx" : "Guo et al\\.,? 2015",
      "shortCiteRegEx" : "Guo et al\\.",
      "year" : 2015
    }, {
      "title" : "A representation learning framework for multi-source transfer parsing",
      "author" : [ "Jiang Guo", "Wanxiang Che", "David Yarowsky", "Haifeng Wang", "Ting Liu." ],
      "venue" : "Proc. of AAAI.",
      "citeRegEx" : "Guo et al\\.,? 2016",
      "shortCiteRegEx" : "Guo et al\\.",
      "year" : 2016
    }, {
      "title" : "Noise-contrastive estimation of unnormalized statistical models, with applications to natural image statistics",
      "author" : [ "Michael U Gutmann", "Aapo Hyvärinen." ],
      "venue" : "JMLR.",
      "citeRegEx" : "Gutmann and Hyvärinen.,? 2012",
      "shortCiteRegEx" : "Gutmann and Hyvärinen.",
      "year" : 2012
    }, {
      "title" : "Learning bilingual lexicons from monolingual corpora",
      "author" : [ "Aria Haghighi", "Percy Liang", "Taylor Berg-Kirkpatrick", "Dan Klein." ],
      "venue" : "Proc. of ACL.",
      "citeRegEx" : "Haghighi et al\\.,? 2008",
      "shortCiteRegEx" : "Haghighi et al\\.",
      "year" : 2008
    }, {
      "title" : "Multilingual Models for Compositional Distributional Semantics",
      "author" : [ "Karl Moritz Hermann", "Phil Blunsom." ],
      "venue" : "Proc. of ACL.",
      "citeRegEx" : "Hermann and Blunsom.,? 2014",
      "shortCiteRegEx" : "Hermann and Blunsom.",
      "year" : 2014
    }, {
      "title" : "Inducing crosslingual distributed representations of words",
      "author" : [ "Alexandre Klementiev", "Ivan Titov", "Binod Bhattarai." ],
      "venue" : "Proc. of COLING.",
      "citeRegEx" : "Klementiev et al\\.,? 2012",
      "shortCiteRegEx" : "Klementiev et al\\.",
      "year" : 2012
    }, {
      "title" : "Learning bilingual word representations by marginalizing alignments",
      "author" : [ "Tomáš Kociskỳ", "Karl Moritz Hermann", "Phil Blunsom." ],
      "venue" : "arXiv preprint arXiv:1405.0947.",
      "citeRegEx" : "Kociskỳ et al\\.,? 2014",
      "shortCiteRegEx" : "Kociskỳ et al\\.",
      "year" : 2014
    }, {
      "title" : "Judgment language matters: Towards judgment language informed vector space modeling",
      "author" : [ "Ira Leviant", "Roi Reichart." ],
      "venue" : "arXiv preprint arXiv:1508.00106.",
      "citeRegEx" : "Leviant and Reichart.,? 2015",
      "shortCiteRegEx" : "Leviant and Reichart.",
      "year" : 2015
    }, {
      "title" : "Better word representations with recursive neural networks for morphology",
      "author" : [ "Minh-Thang Luong", "Richard Socher", "Christopher D. Manning." ],
      "venue" : "Proc. of CoNLL.",
      "citeRegEx" : "Luong et al\\.,? 2013",
      "shortCiteRegEx" : "Luong et al\\.",
      "year" : 2013
    }, {
      "title" : "Addressing the rare word problem in neural machine translation",
      "author" : [ "Minh-Thang Luong", "Ilya Sutskever", "Quoc V Le", "Oriol Vinyals", "Wojciech Zaremba." ],
      "venue" : "Proc. of ACL.",
      "citeRegEx" : "Luong et al\\.,? 2015a",
      "shortCiteRegEx" : "Luong et al\\.",
      "year" : 2015
    }, {
      "title" : "Bilingual word representations with monolingual quality in mind",
      "author" : [ "Thang Luong", "Hieu Pham", "Christopher D Manning." ],
      "venue" : "Proc. of NAACL.",
      "citeRegEx" : "Luong et al\\.,? 2015b",
      "shortCiteRegEx" : "Luong et al\\.",
      "year" : 2015
    }, {
      "title" : "Supersense tagging for Danish",
      "author" : [ "Héctor Martı́nez Alonso", "Anders Johannsen", "Sussi Olsen", "Sanni Nimb", "Nicolai Hartvig Sørensen", "Anna Braasch", "Anders Søgaard", "Bolette Sandford Pedersen" ],
      "venue" : "In Proc. of NODALIDA,",
      "citeRegEx" : "Alonso et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Alonso et al\\.",
      "year" : 2015
    }, {
      "title" : "An empirically grounded expansion of the supersense inventory",
      "author" : [ "Héctor Martı́nez Alonso", "Anders Johannsen", "Sussi Olsen", "Sanni Nimb", "Bolette Sandford Pedersen" ],
      "venue" : "In Proc. of the Global Wordnet Conference",
      "citeRegEx" : "Alonso et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Alonso et al\\.",
      "year" : 2016
    }, {
      "title" : "Multi-source transfer of delexicalized dependency parsers",
      "author" : [ "Ryan McDonald", "Slav Petrov", "Keith Hall." ],
      "venue" : "Proc. of EMNLP, pages 62–72.",
      "citeRegEx" : "McDonald et al\\.,? 2011",
      "shortCiteRegEx" : "McDonald et al\\.",
      "year" : 2011
    }, {
      "title" : "Efficient estimation of word representations in vector space",
      "author" : [ "Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean." ],
      "venue" : "Proc. of ICLR.",
      "citeRegEx" : "Mikolov et al\\.,? 2013a",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2013
    }, {
      "title" : "Exploiting similarities among languages for machine translation",
      "author" : [ "Tomas Mikolov", "Quoc V. Le", "Ilya Sutskever." ],
      "venue" : "arXiv preprint arXiv:1309.4168v1.",
      "citeRegEx" : "Mikolov et al\\.,? 2013b",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2013
    }, {
      "title" : "A semantic concordance",
      "author" : [ "George A. Miller", "Claudia Leacock", "Randee Tengi", "Ross T. Bunker." ],
      "venue" : "Proc. of HLT, pages 303–308.",
      "citeRegEx" : "Miller et al\\.,? 1993",
      "shortCiteRegEx" : "Miller et al\\.",
      "year" : 1993
    }, {
      "title" : "Building the italian syntactic-semantic",
      "author" : [ "Simonetta Montemagni", "Francesco Barsotti", "Marco Battista", "Nicoletta Calzolari", "Ornella Corazzari", "Alessandro Lenci", "Antonio Zampolli", "Francesca Fanciulli", "Maria Massetani", "Remo Raffaelli" ],
      "venue" : null,
      "citeRegEx" : "Montemagni et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Montemagni et al\\.",
      "year" : 2003
    }, {
      "title" : "An efficient method for determining bilingual word classes",
      "author" : [ "Franz Joseph Och." ],
      "venue" : "EACL.",
      "citeRegEx" : "Och.,? 1999",
      "shortCiteRegEx" : "Och.",
      "year" : 1999
    }, {
      "title" : "A universal part-of-speech tagset",
      "author" : [ "Slav Petrov", "Dipanjan Das", "Ryan McDonald." ],
      "venue" : "Proc. of LREC.",
      "citeRegEx" : "Petrov et al\\.,? 2012",
      "shortCiteRegEx" : "Petrov et al\\.",
      "year" : 2012
    }, {
      "title" : "Intriguing properties of neural networks",
      "author" : [ "Christian Szegedy", "Wojciech Zaremba", "Ilya Sutskever", "Joan Bruna", "Dumitru Erhan", "Ian Goodfellow", "Rob Fergus." ],
      "venue" : "Proc. of ICLR.",
      "citeRegEx" : "Szegedy et al\\.,? 2014",
      "shortCiteRegEx" : "Szegedy et al\\.",
      "year" : 2014
    }, {
      "title" : "Cross-lingual word clusters for direct transfer of linguistic structure",
      "author" : [ "Oscar Täckström", "Ryan McDonald", "Jakob Uszkoreit." ],
      "venue" : "Proc. of NAACL, pages 477–487.",
      "citeRegEx" : "Täckström et al\\.,? 2012",
      "shortCiteRegEx" : "Täckström et al\\.",
      "year" : 2012
    }, {
      "title" : "Metaphor detection with cross-lingual model transfer",
      "author" : [ "Yulia Tsvetkov", "Leonid Boytsov", "Anatole Gershman", "Eric Nyberg", "Chris Dyer." ],
      "venue" : "Proc. of ACL.",
      "citeRegEx" : "Tsvetkov et al\\.,? 2014",
      "shortCiteRegEx" : "Tsvetkov et al\\.",
      "year" : 2014
    }, {
      "title" : "Evaluation of word vector representations by subspace alignment",
      "author" : [ "Yulia Tsvetkov", "Manaal Faruqui", "Wang Ling", "Guillaume Lample", "Chris Dyer." ],
      "venue" : "Proc. of EMNLP.",
      "citeRegEx" : "Tsvetkov et al\\.,? 2015",
      "shortCiteRegEx" : "Tsvetkov et al\\.",
      "year" : 2015
    }, {
      "title" : "Crosslanguage parser adaptation between related languages",
      "author" : [ "Daniel Zeman", "Philip Resnik." ],
      "venue" : "Proc. of IJCNLP, pages 35–42.",
      "citeRegEx" : "Zeman and Resnik.,? 2008",
      "shortCiteRegEx" : "Zeman and Resnik.",
      "year" : 2008
    }, {
      "title" : "Bilingual word embeddings for phrase-based machine translation",
      "author" : [ "Will Y Zou", "Richard Socher", "Daniel M Cer", "Christopher D Manning." ],
      "venue" : "Proc. of EMNLP, pages 1393–1398.",
      "citeRegEx" : "Zou et al\\.,? 2013",
      "shortCiteRegEx" : "Zou et al\\.",
      "year" : 2013
    } ],
    "referenceMentions" : [ {
      "referenceID" : 17,
      "context" : "In addition to improving the performance on standard monolingual NLP tasks, shared representation of words across languages offers intriguing possibilities (Klementiev et al., 2012).",
      "startOffset" : 156,
      "endOffset" : 181
    }, {
      "referenceID" : 36,
      "context" : "While previous work has used hand-engineered features that are crosslinguistically stable as the basis model transfer (Zeman and Resnik, 2008; McDonald et al., 2011; Tsvetkov et al., 2014), automatically learned embeddings offer the promise of better generalization at lower cost (Klementiev et al.",
      "startOffset" : 118,
      "endOffset" : 188
    }, {
      "referenceID" : 25,
      "context" : "While previous work has used hand-engineered features that are crosslinguistically stable as the basis model transfer (Zeman and Resnik, 2008; McDonald et al., 2011; Tsvetkov et al., 2014), automatically learned embeddings offer the promise of better generalization at lower cost (Klementiev et al.",
      "startOffset" : 118,
      "endOffset" : 188
    }, {
      "referenceID" : 34,
      "context" : "While previous work has used hand-engineered features that are crosslinguistically stable as the basis model transfer (Zeman and Resnik, 2008; McDonald et al., 2011; Tsvetkov et al., 2014), automatically learned embeddings offer the promise of better generalization at lower cost (Klementiev et al.",
      "startOffset" : 118,
      "endOffset" : 188
    }, {
      "referenceID" : 17,
      "context" : ", 2014), automatically learned embeddings offer the promise of better generalization at lower cost (Klementiev et al., 2012; Hermann and Blunsom, 2014; Guo et al., 2016).",
      "startOffset" : 99,
      "endOffset" : 169
    }, {
      "referenceID" : 16,
      "context" : ", 2014), automatically learned embeddings offer the promise of better generalization at lower cost (Klementiev et al., 2012; Hermann and Blunsom, 2014; Guo et al., 2016).",
      "startOffset" : 99,
      "endOffset" : 169
    }, {
      "referenceID" : 13,
      "context" : ", 2014), automatically learned embeddings offer the promise of better generalization at lower cost (Klementiev et al., 2012; Hermann and Blunsom, 2014; Guo et al., 2016).",
      "startOffset" : 99,
      "endOffset" : 169
    }, {
      "referenceID" : 35,
      "context" : "• We adapt QVEC (Tsvetkov et al., 2015)1 to evaluating multilingual embeddings (multiQVEC).",
      "startOffset" : 16,
      "endOffset" : 39
    }, {
      "referenceID" : 10,
      "context" : "(2016) (henceforth referred to as multiSkip),4 and the translation-invariance matrix factorization method (Gardner et al., 2015).",
      "startOffset" : 106,
      "endOffset" : 128
    }, {
      "referenceID" : 6,
      "context" : "We then describe our baselines: a variant of Coulmance et al. (2015) and Guo et al.",
      "startOffset" : 45,
      "endOffset" : 69
    }, {
      "referenceID" : 6,
      "context" : "We then describe our baselines: a variant of Coulmance et al. (2015) and Guo et al. (2016) (henceforth referred to as multiSkip),4 and the translation-invariance matrix factorization method (Gardner et al.",
      "startOffset" : 45,
      "endOffset" : 91
    }, {
      "referenceID" : 7,
      "context" : "To do this, we align the corpus using fast align (Dyer et al., 2013) in both directions.",
      "startOffset" : 49,
      "endOffset" : 68
    }, {
      "referenceID" : 6,
      "context" : "We developed multiSkip independently of Coulmance et al. (2015) and Guo et al.",
      "startOffset" : 40,
      "endOffset" : 64
    }, {
      "referenceID" : 6,
      "context" : "We developed multiSkip independently of Coulmance et al. (2015) and Guo et al. (2016). One important distinction is that multiSkip is only trained on parallel corpora, while Coulmance et al.",
      "startOffset" : 40,
      "endOffset" : 86
    }, {
      "referenceID" : 6,
      "context" : "We developed multiSkip independently of Coulmance et al. (2015) and Guo et al. (2016). One important distinction is that multiSkip is only trained on parallel corpora, while Coulmance et al. (2015) and Guo et al.",
      "startOffset" : 40,
      "endOffset" : 198
    }, {
      "referenceID" : 6,
      "context" : "We developed multiSkip independently of Coulmance et al. (2015) and Guo et al. (2016). One important distinction is that multiSkip is only trained on parallel corpora, while Coulmance et al. (2015) and Guo et al. (2016) also use monolingual corpora.",
      "startOffset" : 40,
      "endOffset" : 220
    }, {
      "referenceID" : 6,
      "context" : "We developed multiSkip independently of Coulmance et al. (2015) and Guo et al. (2016). One important distinction is that multiSkip is only trained on parallel corpora, while Coulmance et al. (2015) and Guo et al. (2016) also use monolingual corpora. connected components in a graph where nodes are (language, surface form) pairs and edges correspond to translation entries in Dm,n. We assign arbitrary IDs to the clusters and replace each word token in each monolingual corpus with the corresponding cluster ID, and concatenate all modified corpora. The resulting corpus consists of multilingual cluster ID sequences. We can then apply any monolingual embedding estimator; here, we use the skipgram model from Mikolov et al. (2013a).",
      "startOffset" : 40,
      "endOffset" : 733
    }, {
      "referenceID" : 9,
      "context" : "2 MultiCCA Our proposed method (multiCCA) extends the bilingual embeddings of Faruqui and Dyer (2014). First, they use monolingual corpora to train monolingual embeddings for each language independently (Em and En), capturing semantic similarity within each language separately.",
      "startOffset" : 78,
      "endOffset" : 102
    }, {
      "referenceID" : 14,
      "context" : "In practice, this distribution can be estimated using a noise contrastive estimation approximation (Gutmann and Hyvärinen, 2012) while maximizing the log-likelihood: ∑",
      "startOffset" : 99,
      "endOffset" : 128
    }, {
      "referenceID" : 20,
      "context" : "To establish a bilingual embedding, with a parallel corpus Pm,n of source language m and target language n, Luong et al. (2015b) estimate conditional models of words in both source and target positions.",
      "startOffset" : 108,
      "endOffset" : 129
    }, {
      "referenceID" : 35,
      "context" : "MultiQVECCCA extends QVEC (Tsvetkov et al., 2015), a recently proposed monolingual evaluation method, addressing fundamental flaws and extending it to multiple languages.",
      "startOffset" : 26,
      "endOffset" : 49
    }, {
      "referenceID" : 1,
      "context" : "1 Word similarity Word similarity datasets such as WordSim-353 (Agirre et al., 2009) and MEN (Bruni et al.",
      "startOffset" : 63,
      "endOffset" : 84
    }, {
      "referenceID" : 3,
      "context" : ", 2009) and MEN (Bruni et al., 2014) provide human judgments of semantic similarity.",
      "startOffset" : 16,
      "endOffset" : 36
    }, {
      "referenceID" : 20,
      "context" : "For this paper, we report results on an English word similarity task, the Stanford RW dataset (Luong et al., 2013), as well as a combination of several cross-lingual word similarity datasets (CamachoCollados et al.",
      "startOffset" : 94,
      "endOffset" : 114
    }, {
      "referenceID" : 26,
      "context" : "This is a variant of the method used by Mikolov et al. (2013b) to evaluate bilingual embeddings.",
      "startOffset" : 40,
      "endOffset" : 63
    }, {
      "referenceID" : 35,
      "context" : "Our method is an improvement of QVEC—a monolingual evaluation based on alignment of embeddings to a matrix of features extracted from a linguistic resource (Tsvetkov et al., 2015).",
      "startOffset" : 156,
      "endOffset" : 179
    }, {
      "referenceID" : 35,
      "context" : "QVEC has been shown to correlate strongly with downstream semantic tasks (Tsvetkov et al., 2015).",
      "startOffset" : 73,
      "endOffset" : 96
    }, {
      "referenceID" : 32,
      "context" : "First, it is not invariant to linear transformations of the embeddings’ basis, whereas the bases in word embeddings are generally arbitrary (Szegedy et al., 2014).",
      "startOffset" : 140,
      "endOffset" : 162
    }, {
      "referenceID" : 28,
      "context" : "We extend both methods to multilingual evaluations—multiQVEC and multiQVECCCA—by constructing the linguistic matrix using supersense tag annotations for English (Miller et al., 1993), Danish (Martı́nez Alonso et al.",
      "startOffset" : 161,
      "endOffset" : 182
    }, {
      "referenceID" : 29,
      "context" : ", 2016) and Italian (Montemagni et al., 2003).",
      "startOffset" : 20,
      "endOffset" : 45
    }, {
      "referenceID" : 15,
      "context" : "For document classification, we follow Klementiev et al. (2012) in using the RCV corpus of newswire text, and train a classifier which differentiates between four topics.",
      "startOffset" : 39,
      "endOffset" : 64
    }, {
      "referenceID" : 7,
      "context" : "For dependency parsing, we train the stackLSTM parser of Dyer et al. (2015) on a subset of the languages in the universal dependencies v1.",
      "startOffset" : 57,
      "endOffset" : 76
    }, {
      "referenceID" : 19,
      "context" : "Data: For the cross-lingual word similarity task, we use disjoint subsets of the en-it MWS353 dataset (Leviant and Reichart, 2015) for development (308 word pairs) and testing (307 word pairs).",
      "startOffset" : 102,
      "endOffset" : 130
    }, {
      "referenceID" : 31,
      "context" : "If the word embeddings are primarily needed for encoding syntactic information, one could use tag dictionaries based on the universal POS tag set (Petrov et al., 2012) instead of supersense tags.",
      "startOffset" : 146,
      "endOffset" : 167
    }, {
      "referenceID" : 3,
      "context" : "Evaluation data: Monolingual word similarity uses the MEN dataset in Bruni et al. (2014) as a development set and Stanford’s Rare Words dataset in Luong et al.",
      "startOffset" : 69,
      "endOffset" : 89
    }, {
      "referenceID" : 3,
      "context" : "Evaluation data: Monolingual word similarity uses the MEN dataset in Bruni et al. (2014) as a development set and Stanford’s Rare Words dataset in Luong et al. (2013) as a test set.",
      "startOffset" : 69,
      "endOffset" : 167
    }, {
      "referenceID" : 34,
      "context" : "For QVEC and QVEC-CCA, we split the English supersense annotations used in Tsvetkov et al. (2015) into a development set and a test set.",
      "startOffset" : 75,
      "endOffset" : 98
    }, {
      "referenceID" : 26,
      "context" : "In the English tasks (monolingual word similarity, QVEC, QVEC-CCA), skipgram embeddings (Mikolov et al., 2013a) and multiCCA embeddings give identical results (since we project words in other languages to the English vector space, estimated using the skipgram model).",
      "startOffset" : 88,
      "endOffset" : 111
    }, {
      "referenceID" : 10,
      "context" : "Training translation-invariance embeddings with larger context window sizes using the matlab implementation provided by Gardner et al. (2015) is computationally challenging.",
      "startOffset" : 120,
      "endOffset" : 142
    }, {
      "referenceID" : 12,
      "context" : ", 2015a, inter alia),14 cross-lingual dependency parsing (Guo et al., 2015; Guo et al., 2016), and cross-lingual document classification (Klementiev",
      "startOffset" : 57,
      "endOffset" : 93
    }, {
      "referenceID" : 13,
      "context" : ", 2015a, inter alia),14 cross-lingual dependency parsing (Guo et al., 2015; Guo et al., 2016), and cross-lingual document classification (Klementiev",
      "startOffset" : 57,
      "endOffset" : 93
    }, {
      "referenceID" : 30,
      "context" : "Word clusters are a related form of distributional representation; in clustering, cross-lingual distributional representations were proposed as well (Och, 1999; Täckström et al., 2012).",
      "startOffset" : 149,
      "endOffset" : 184
    }, {
      "referenceID" : 33,
      "context" : "Word clusters are a related form of distributional representation; in clustering, cross-lingual distributional representations were proposed as well (Och, 1999; Täckström et al., 2012).",
      "startOffset" : 149,
      "endOffset" : 184
    }, {
      "referenceID" : 2,
      "context" : "Al-Rfou’ et al. (2013) trained word embeddings for more than 100 languages, but the embeddings of each language are trained independently (i.",
      "startOffset" : 0,
      "endOffset" : 23
    }, {
      "referenceID" : 2,
      "context" : "Al-Rfou’ et al. (2013) trained word embeddings for more than 100 languages, but the embeddings of each language are trained independently (i.e., embeddings of words in different languages do not share the same vector space). Word clusters are a related form of distributional representation; in clustering, cross-lingual distributional representations were proposed as well (Och, 1999; Täckström et al., 2012). Haghighi et al. (2008) used CCA to learn bilingual lexicons from monolingual corpora.",
      "startOffset" : 0,
      "endOffset" : 434
    } ],
    "year" : 2016,
    "abstractText" : "We introduce new methods for estimating and evaluating embeddings of words in more than fifty languages in a single shared embedding space. Our estimation methods, multiCluster and multiCCA, use dictionaries and monolingual data; they do not require parallel data. Our new evaluation method, multiQVECCCA, is shown to correlate better than previous ones with two downstream tasks (text categorization and parsing). We also describe a web portal for evaluation that will facilitate further research in this area, along with open-source releases of all our methods.",
    "creator" : "TeX"
  }
}